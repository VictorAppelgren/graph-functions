{
  "url": "https://www.forbes.com/sites/conormurray/2025/08/14/roblox-defends-banning-vigilante-users-as-criticism-over-child-safety-grows/",
  "authorsByline": "Conor Murray",
  "articleId": "a48caab77fe64dc7aa5cdbe6fe2f367e",
  "source": {
    "domain": "forbes.com",
    "paywall": true,
    "location": {
      "country": "us",
      "state": "NJ",
      "county": "Hudson County",
      "city": "Jersey City",
      "coordinates": {
        "lat": 40.7215682,
        "lon": -74.047455
      }
    }
  },
  "imageUrl": "https://imageio.forbes.com/specials-images/imageserve/689e3dfa5dd6f83e74d8ed4a/0x0.jpg?format=jpg&crop=3126,1760,x290,y405,safe&height=900&width=1600&fit=bounds",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-14T19:51:16+00:00",
  "addDate": "2025-08-14T19:56:58.295425+00:00",
  "refreshDate": "2025-08-14T19:56:58.295427+00:00",
  "score": 1.0,
  "title": "Roblox Defends Banning 'Vigilante' Users As Schlep Suspension Sparks Backlash",
  "description": "Rep. Ro Khanna, D-Calif., joined a chorus of online anger urging gaming platform Roblox to better protect child users from exploitation.",
  "content": "Roblox published a lengthy statement to its website Wednesday defending its ban on \u201cvigilante\u201d users\u2014Roblox users who try to catch child predators on the gaming platform and report them to authorities\u2014stating these users have taken \u201cactions that are both unacceptable and create an unsafe environment for users.\u201d Roblox acknowledged these users are \u201cwell-intentioned,\u201d but said their actions evolved to become \u201csimilar to actual predators\u201d as they \u201cstarted impersonating children and actively sought to connect with adult users,\u201d and the platform instead urged users to report suspected predators through Roblox\u2019s moderation tools. The company said it published the statement in response to recent debate\u2014a possible reference to controversy over the platform\u2019s ban of popular user Schlep, who says his Roblox vigilante activities have led to the arrests of multiple predators. Khanna said in a TikTok on Wednesday that Roblox is \u201cnot doing enough\u201d to address child predators, and he published a petition on his website urging Roblox to \u201cdo more to protect children.\u201d Forbes has reached out to Roblox for comment.\n\nSchlep is a Roblox gamer and a YouTuber who has more than 790,000 subscribers. Many of his most popular videos, on which he has garnered millions of views, depict him pursuing child predators on the gaming platform. His most popular video, titled \u201cRoblox Predator Gets Arrested!\u201d depicts him, posing as a young user, luring a man he met on Roblox to meet in real life, where he confronts the user with police. Schlep has claimed on X he has helped authorities arrest six Roblox users who appeared to be child predators. Over the weekend, Schlep posted what he says is a cease-and-desist notice from Roblox, notifying him his accounts are suspended because of actions including \u201cengaging in simulated child endangerment conversations,\u201d \u201csharing or soliciting personally identifiable information\u201d and \u201cdirecting users to move conversations off platform,\u201d all of which Roblox says violates its policies. Schlep slammed Roblox\u2019s Wednesday statement in a thread on X, calling it \u201coutrageous\u201d to compare actions taken by \u201cvigilante\u201d users to child predators. Schlep\u2019s ban sparked anger from his supporters online, and on Wednesday night, he shared an image on X of an in-game protest in which Roblox users gathered and said: \u201cFree Schlep.\u201d\n\nRoblox\u2019s moderation policies have long faced criticism, particularly because of its large base of young users. Roblox said in an earnings report in July it had 111.8 million daily active users in the second quarter of 2025, 36% of whom were users under 13. In July 2024, a Bloomberg investigation found police in the United States had arrested at least two dozen users accused of exploiting minors through Roblox since 2018, seven of which were in the past 13 months. The Bloomberg report cited anonymous conversations with nearly two dozen employees, including one moderator who said her team receives hundreds of reports concerning child safety every day, \u201cfar too many for her team to clear.\u201d A Roblox spokesperson disputed these issues to Bloomberg, stating it has a \u201crobust pipeline\u201d of safety features and that \u201ctens of millions of people of all ages have a safe and positive experience on Roblox every single day.\u201d Last week, Roblox began rolling out an AI-powered moderation tool to identify language in user chats that could be indicators of child exploitation.\n\nAs Roblox\u2019s vigilante-banning controversy has unfolded, the company has faced multiple lawsuits over alleged child predators on the gaming platform. On Aug. 4, a California family sued Roblox for negligence, alleging their 10-year-old daughter was kidnapped by a 27-year-old man she met through the game. Police found her more than 250 miles away from her home, the lawsuit states, after the alleged predator directed her to share her address with him on Discord, a messaging platform popular with gamers. The lawsuit says Roblox and Discord are \u201cdirectly responsible\u201d for the kidnapping, alleging the victim would not have been kidnapped if they had \u201cimplemented even the most basic system of screening or age and identity verification, as well as other commonsense safety measures.\u201d Following the lawsuit, a Roblox spokesperson told CBS News: \u201cWe dedicate substantial resources\u2026 to help detect and prevent inappropriate content and behavior, including attempts to direct users off platform, where safety standards and moderation may be less stringent than ours.\u201d A Texas man who says he was \u201cgroomed, extorted, and sexually abused by a man in his late thirties\u201d when he was 11 years old sued Roblox in federal court Wednesday, accusing it of negligence.\n\nRoblox rolls out open-source AI system to protect kids from predators in chats (ABC News)",
  "medium": "Article",
  "links": [
    "https://x.com/RealSchlep/status/1955723386115567890",
    "https://abcnews.go.com/Technology/wireStory/roblox-rolls-open-source-ai-system-protect-kids-124443058",
    "https://www.bloomberg.com/features/2024-roblox-pedophile-problem/",
    "https://x.com/RealSchlep/status/1954255952997478537",
    "https://x.com/RealSchlep/status/1940592596235309437",
    "https://corp.roblox.com/newsroom/2025/08/more-on-removal-of-vigilantes-from-roblox",
    "https://x.com/RealSchlep/status/1955771598193222100",
    "https://act.rokhanna.com/a/save-roblox-petition",
    "https://www.anapolweiss.com/2025-07-30-mood-complaint.pdf",
    "https://s27.q4cdn.com/984876518/files/doc_financials/2025/q2/Q2-25-SH-Letter.pdf",
    "https://youtu.be/eLDfGhu7_P4?feature=shared"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Roblox users",
      "weight": 0.13879177
    },
    {
      "name": "Roblox Predator",
      "weight": 0.12364938
    },
    {
      "name": "Roblox",
      "weight": 0.11144016
    },
    {
      "name": "popular user Schlep",
      "weight": 0.09916824
    },
    {
      "name": "user chats",
      "weight": 0.09649422
    },
    {
      "name": "users",
      "weight": 0.09618805
    },
    {
      "name": "young users",
      "weight": 0.09577357
    },
    {
      "name": "alleged child predators",
      "weight": 0.09410576
    },
    {
      "name": "adult users",
      "weight": 0.09390002
    },
    {
      "name": "child predators",
      "weight": 0.0919322
    }
  ],
  "topics": [
    {
      "name": "Gaming"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/Games/Computer & Video Games/Gaming Reference & Reviews",
      "score": 0.91259765625
    },
    {
      "name": "/Games/Computer & Video Games/Action & Platform Games",
      "score": 0.58203125
    },
    {
      "name": "/Games/Computer & Video Games/Adventure Games",
      "score": 0.513671875
    },
    {
      "name": "/Games/Computer & Video Games/Shooter Games",
      "score": 0.396240234375
    },
    {
      "name": "/Games/Roleplaying Games",
      "score": 0.368408203125
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.32958984375
    },
    {
      "name": "/Games/Computer & Video Games/Massively Multiplayer Games",
      "score": 0.3037109375
    }
  ],
  "sentiment": {
    "positive": 0.04785959,
    "negative": 0.756366,
    "neutral": 0.19577439
  },
  "summary": "Roblox has defended its ban on 'vigilante' users, users who try to catch child predators on the gaming platform, and report them to authorities. The company stated these users' actions were both unacceptable and create an unsafe environment for users. However, it acknowledged that their actions evolved to become \"like actual predators\" as they began impersonating children and sought to connect with adult users. The platform instead encouraged users to report suspected predators through its moderation tools. This statement came in response to controversy over the platform's ban on popular user Schlep, who claims his Roblox vigilante activities have led to the arrests of multiple predators. The suspension sparked anger from his supporters online, with SchleP calling it \"outrageous\" to compare actions by vigilantes to child predators.",
  "shortSummary": "Roblox defends its ban on vigilante users, citing safety concerns and user engagement, amid controversy over child exploitation and safety features.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "a6a9a777cd3d475ba1d5b51335cd2a78",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://corp.roblox.com/newsroom/2025/08/more-on-removal-of-vigilantes-from-roblox",
      "text": "More on our Removal of Vigilantes From Roblox\nVigilante Behavior Creates an Unsafe Environment for Users\n-\nWe are sharing more information about why it was necessary to remove vigilantes from Roblox, and the ways in which we review and act on reports of abuse on Roblox.\n-\nWhile seemingly well-intentioned, the vigilantes we\u2019ve banned have taken actions that are both unacceptable and create an unsafe environment for users.\n-\nSimilar to actual predators, they often impersonated minors, actively approached other users, then tried to lead them to other platforms to have sexually explicit conversations (which is against our Terms of Use).\n-\nAccurate, timely reporting from our community is important. Reporting through the appropriate channels, including our custom-designed reporting tools, immediately and with as much specific information as possible is the best way to help us remove bad actors from Roblox.\n-\nThese reporting tools are designed to capture key metadata and details that cannot be captured from an email or screenshot and enable faster, more effective reviews and more thorough reporting to law enforcement, when warranted.\nOur decision to remove vigilantes from the Roblox platform, as we outlined recently, has raised questions and sparked debate. For transparency, we are sharing more information about the actions we took, why they were necessary, and the ways in which we investigate and act on reports of abuse on Roblox.\nWe realize that no platform is perfect, but we prioritize trust and safety because it\u2019s core to what we do as a company. This is an area where we invest heavily and are always innovating. Helping keep our users safe is a critical part of our vision of connecting a billion people with optimism and civility and is a strategic imperative for our creator community. Our aim is to provide a development platform that allows creators to focus on their craft while we manage the complexities of moderation, fielding user reports, and investigating bad actors.\nEvery day on Roblox, an average of 111.8 million daily active users1 send 6.1 billion chat messages and engage in 1.1 million hours of voice chat across 28 different languages. At the same time, creators upload millions of assets and add thousands more items to our Avatar Marketplace. While the vast majority of these billions of messages and creations are safe and civil, bad actors regularly attempt to evade our moderation systems. That\u2019s why we continue to invest significantly in safety, to help protect users from these bad actors. Thanks to our passionate community of creators and users, we also receive and review more than 1 billion reports every year\u2014these span everything from chat spam, cursing, and cheating to more serious violations. In some cases, these reports aren\u2019t violations at all (users may report things in good faith without fully understanding our policies).\nWhy We Remove Vigilantes\nWe have been monitoring vigilante activity on Roblox for some time. These groups began by reporting safety concerns, commenting on news about Roblox, and challenging us to do better. We appreciated this feedback and used these reports to improve our safety systems. More recently, vigilante activity evolved. Instead of just reporting on safety issues, vigilantes started impersonating children and actively sought to connect with adult users. Those conversations mimicked inappropriate behavior and actively encouraged other users to connect on other social media and messaging platforms\u2014thus bypassing Roblox\u2019s own safety systems.\nThese were not one-off situations and we saw the behavior accelerating across many accounts. This activity created an unsafe environment and normalized behavior that is both unacceptable on Roblox and is against our Terms of Use. Our policies prohibit directing other users off Roblox to another platform through chat and having/simulating sexually explicit conversations. These are serious policy violations that risk removal from the platform.\nThe Importance of Accurate Reporting\nNone of the activity discussed above is acceptable on Roblox. We have teams dedicated to reviewing and investigating the reports we receive. When we find that violations have occurred, we act in accordance with our policies\u2014up to and including permanently removing users from Roblox and reporting to law enforcement when warranted.\nDue to privacy considerations, we cannot inform users whether their reports have led to consequences. We want to protect the privacy of our users even as we work to help keep them safe. We also work with law enforcement, following official legal guidelines around when its appropriate to collaborate with them, and provide information to help them track bad actors across platforms to help keep users safe even beyond Roblox. In 2024, we submitted 24,522 reports (0.12% of the 20.3 million total reports submitted across the industry) to the National Center for Missing and Exploited Children (NCMEC). As part of our strong relationship with NCMEC, we regularly meet to understand how we can provide the most helpful information to law enforcement about these bad actors.\nWhen users observe inappropriate behavior, we ask that they report it immediately through one of our standard reporting channels. On multiple occasions, we\u2019ve found vigilante groups holding their reports to Roblox until after they had coordinated real-life meetups and built their own social media posts. Waiting to report to Roblox or the relevant authorities means alleged bad actors could potentially remain on the platform longer, leaving the community open to additional risk of harm.\nSeparately, we recognize the community\u2019s frustration with how we handle reports of violative behavior that occurs outside of Roblox. These often come to us as screenshots from other social media and messaging applications. We do our best to investigate these reports. However, we can\u2019t act on them unless they can be independently confirmed or we observe similar behavior on Roblox. Acting without verification would open up a significant abuse vector, as bad actors could simply manufacture incriminating evidence to target other users.\nHelp Roblox Remove Bad Actors\nRather than taking actions that violate our policies and potentially creating additional risk, we encourage users to report issues through the official channels so we can investigate quickly and effectively. We\u2019ve designed our reporting tools to capture details and metadata that a screenshot cannot, including object IDs, avatar IDs, and context. This additional information goes a long way toward helping us investigate reported incidents.\nWe offer users multiple entry points to report suspicious behavior. If an incident occurs within a game or experience, users can let us know via the in-game reporting tool. To access this tool, click the Roblox logo in the top left, then click on the flag icon/Report tab.\nProfiles can also be reported outside an experience. To report a user, visit their profile page and click the three dots in the upper-right corner of the profile details (on desktop) or Report Abuse (on mobile browser). Then select Report User from the menu. Please include as much specific information as possible about why you are reporting the user to help with our review. To report an inappropriate chat message, select the gear icon in the upper-right corner of the chat window to open the Chat Details. Click the three dots, then click Report.\nRoblox has a Trusted Flagger program, where close and trusted partners can report serious criminal activity, such as terrorism, violent extremism, or child exploitation, to us for our priority review. Trusted Flaggers are typically reputable third-party organizations (e.g., civil society organizations or nongovernmental organizations) that are publicly renowned as subject-matter experts for the issue on which they are reporting. We\u2019ve made a commitment to such Trusted Flaggers that their reports will be promptly reviewed and, as appropriate, actioned within a short timeframe. We are always looking to expand this program and welcome outreach from interested entities.\nWe know our user and creator communities are as passionate as we are about helping keep Roblox safe. We appreciate the reports, feedback, and discussion. We\u2019re committed to improving and learning from this experience, and we appreciate the community\u2019s efforts to help us make Roblox a safer place for everyone.\n1 As of the quarter ended June 30, 2025."
    },
    {
      "url": "https://abcnews.go.com/Technology/wireStory/roblox-rolls-open-source-ai-system-protect-kids-124443058",
      "text": "Roblox rolls out open-source AI system to protect kids from predators in chats\nRoblox, the online gaming platform wildly popular with children and teenagers, is rolling out an open-source version of an artificial intelligence system it says can help preemptively detect predatory language in game chats\nRoblox, the online gaming platform wildly popular with children and teenagers, is rolling out an open-source version of an artificial intelligence system it says can help preemptively detect predatory language in game chats.\nThe move comes as the company faces lawsuits and criticism accusing it of not doing enough to protect children from predators. For instance, a lawsuit filed last month in Iowa alleges that a 13-year-old girl was introduced to an adult predator on Roblox, then kidnapped and trafficked across multiple states and raped. The suit, filed in Iowa District Court in Polk County, claims that Roblox's design features make children who use it \u201ceasy prey for pedophiles.\u201d\nRoblox says it strives to make its systems as safe as possible by default but notes that \u201cno system is perfect, and one of the biggest challenges in the industry is to detect critical harms like potential child endangerment.\u201d\nThe AI system, called Sentinel, helps detect early signs of possible child endangerment, such as sexually exploitative language. Roblox says the system has led the company to submit 1,200 reports of potential attempts at child exploitation to the National Center for Missing and Exploited Children in the first half of 2025. The company is now in the process of open-sourcing it so other platforms can use it too.\nPreemptively detecting possible dangers to kids can be tricky for AI systems \u2014 and humans, too \u2014 because conversations can seem innocuous at first. Questions like \u201chow old are you?\u201d or \u201cwhere are you from?\u201d wouldn't necessarily raise red flags on their own, but when put in context over the course of a longer conversation, they can take on a different meaning.\nRoblox, which has more than 111 million monthly users, doesn't allow users to share videos or images in chats and tries to block any personal information such as phone numbers, though \u2014 as with most moderation rules \u2014 people constantly find ways to get around such safeguards.\nIt also doesn't allow kids under 13 to chat with other users outside of games unless they have explicit parental permission \u2014 and unlike many other platforms, it does not encrypt private chat conversations, so it can monitor and moderate them.\n\u201cWe\u2019ve had filters in place all along, but those filters tend to focus on what is said in a single line of text or within just a few lines of text. And that\u2019s really good for doing things like blocking profanity and blocking different types of abusive language and things like that,\u201d said Matt Kaufman, chief safety officer at Roblox. \"But when you\u2019re thinking about things related to child endangerment or grooming, the types of behaviors you\u2019re looking at manifest over a very long period of time.\u201d\nSentinel captures one-minute snapshots of chats across Roblox \u2014 about 6 billion messages per day \u2014 and analyzes them for potential harms. To do this, Roblox says it developed two indexes \u2014 one made up of benign messages and, the other, chats that were determined to contain child endangerment violations. Roblox says this lets the system recognize harmful patterns that go beyond simply flagging certain words or phrases, taking the entire conversation into context.\n\u201cThat index gets better as we detect more bad actors, we just continuously update that index. Then we have another sample of what does a normal, regular user do?\" said Naren Koneru, vice president of engineering for trust and safety at Roblox.\nAs users are chatting, the system keeps score \u2014 are they closer to the positive cluster or the negative cluster?\n\u201cIt doesn\u2019t happen on one message because you just send one message, but it happens because of all of your days' interactions are leading towards one of these two,\u201d Koneru said. \u201cThen we say, okay, maybe this user is somebody who we need to take a much closer look at, and then we go pull all of their other conversations, other friends, and the games that they played, and all of those things.\u201d\nHumans review risky interactions and flag to law enforcement accordingly."
    }
  ],
  "argos_summary": "Roblox has defended its ban on 'vigilante' users who attempt to catch child predators on its platform, stating that their actions have become unsafe and similar to those of actual predators. The company encourages users to report suspected predators through its moderation tools instead. This controversy follows recent lawsuits alleging negligence in protecting children from predators on the platform, prompting Roblox to roll out an AI system, Sentinel, designed to detect predatory language in chats. Despite these efforts, critics argue that Roblox is not doing enough to ensure child safety.",
  "argos_id": "UQRP8HVRD"
}