{
  "url": "https://www.techrepublic.com/article/news-fix-ai-agent-mistakes-rubrik-agent-rewind/",
  "authorsByline": "Aminu Abdullahi",
  "articleId": "d5d3f7640f9c4d0d97363d770fdce8a4",
  "source": {
    "domain": "techrepublic.com",
    "location": {
      "country": "us",
      "state": "KY",
      "county": "Jefferson County",
      "city": "Louisville",
      "coordinates": {
        "lat": 38.2542376,
        "lon": -85.759407
      }
    }
  },
  "imageUrl": "https://assets.techrepublic.com/uploads/2025/08/img-blog-agent-environment.png.imgt_.1200.1200.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-13T14:19:42+00:00",
  "addDate": "2025-08-13T14:34:24.514150+00:00",
  "refreshDate": "2025-08-13T14:34:24.514151+00:00",
  "score": 1.0,
  "title": "Reverse AI Agent Mistakes With Rubrik's Agent Rewind",
  "description": "Rubrik\u2019s new Agent Rewind tool can trace, audit, and safely reverse AI agent mistakes, boosting enterprise control and AI resilience.",
  "content": "AI agents are finding their way into business workflows, but they\u2019re not infallible. When these autonomous systems make wrong moves, the damage can be swift and hard to reverse.\n\nData security company Rubrik claims to have a fix. The firm has introduced Agent Rewind, a new tool designed to detect when AI agents stray from their intended path and roll back their actions before any lasting harm is done. The system is powered by Predibase AI infrastructure, following Rubrik\u2019s recent acquisition of the fine-tuning technology provider.\n\nRubrik\u2019s Chief Product Officer Anneka Gupta told Computerworld, \u201cWhen organizations invest in AI, they often overlook the potential mistakes AI agents can make. Agentic AI introduces the concept of \u2018non-human error,\u2019 highlighting the need for organizations to implement solutions that can address potentially serious errors that can lead to business downtime.\u201d\n\nRecent studies have found that AI agents can become confused, take incorrect shortcuts, and fail at multi-step tasks. In practice, this has led to broken workflows, incorrect data changes, and even the deletion of production databases.\n\nAgent Rewind is built to make AI behavior visible, auditable, and reversible. It records every action, links it to the original prompt or plan, and offers a clear path to reverse harmful changes. According to Rubrik, Agent Rewind provides:\n\u2022 Context-enriched visibility: Maps agent behavior and tools used, connecting each action back to its cause.\n\u2022 Safe rollback: Restores files, databases, configurations, or repositories to a clean state using Rubrik Security Cloud.\n\nThe tool integrates with popular AI agent platforms such as Salesforce\u2019s Agentforce, Microsoft Copilot Studio, and Amazon Bedrock Agents, as well as custom-built systems.\n\nRubrik said Agent Rewind represents a shift from traditional cyber resilience to what it calls AI resilience, giving AI agents the freedom to work at high speed while keeping control in human hands.\n\n\u201cThe answer isn\u2019t to lock your AI agents down,\u201d Gupta wrote in a Rubrik blog post. \u201cIt\u2019s to build the guardrails that let them move fast without surrendering your control.\u201d\n\nSome companies are already excited about the tool. \u201cIn a market craving true observability and remediation, Agent Rewind is the answer I\u2019ve been waiting for,\u201d said BioIVT CISO Chad Pallett in a quote for Computerworld.\n\nWhen will Agent Rewind be available?\n\nRubrik plans to make Agent Rewind generally available in the coming months. Businesses can sign up for early access on Rubrik\u2019s website.\n\nRead our coverage about research that found AI agents are creating insider security threat blind spots.",
  "medium": "Article",
  "links": [
    "https://www.techrepublic.com/article/news-aws-summit-new-york-2025-keynote/",
    "https://www.techrepublic.com/article/news-anthropic-claude-opus-4-1/",
    "https://technologyadvice.com/privacy-policy/",
    "https://www.techrepublic.com/article/generative-ai-costly-mistakes-tech-buyers/",
    "https://www.techrepublic.com/article/news-microsoft-copilot-computer-use-feature/",
    "https://www.linkedin.com/pulse/why-ai-office-agents-fail-70-time-insights-from-cmus-study-jha-37pfc/",
    "https://www.techrepublic.com/article/salesforce-agentforce-2-0-ai-crm-enhancements/",
    "https://www.computerworld.com/article/4037957/ai-agents-make-mistakes-rubrik-has-figured-out-a-way-to-reverse-them.html",
    "https://www.techrepublic.com/article/news-openai-open-ai-models/",
    "https://www.techrepublic.com/article/news-gpt-5/",
    "https://www.rubrik.com/lp/demo/agent-rewind.html",
    "https://www.techrepublic.com/article/news-google-deepmind-genie-3/",
    "https://www.eweek.com/news/replit-ai-coding-assistant-failure/",
    "https://www.rubrik.com/blog/company/25/when-ai-agents-go-awry-introducing-rubrik-agent-rewind-powered-by-predibase-ai-infrastructure",
    "https://technologyadvice.com/terms-conditions/",
    "https://www.techrepublic.com/article/news-ai-agent-security-beyondid-research/"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "AI agents",
      "weight": 0.11014076
    },
    {
      "name": "Reverse AI Agent Mistakes",
      "weight": 0.096792296
    },
    {
      "name": "Agent Rewind",
      "weight": 0.09675048
    },
    {
      "name": "popular AI agent platforms",
      "weight": 0.09622461
    },
    {
      "name": "agent behavior",
      "weight": 0.093517415
    },
    {
      "name": "Rubrik",
      "weight": 0.0859771
    },
    {
      "name": "Data security company Rubrik",
      "weight": 0.085095
    },
    {
      "name": "Rubrik Security Cloud",
      "weight": 0.08151164
    },
    {
      "name": "AI behavior",
      "weight": 0.07674731
    },
    {
      "name": "Predibase AI infrastructure",
      "weight": 0.076631635
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Business News/Company News",
      "score": 0.91015625
    },
    {
      "name": "/News/Technology News",
      "score": 0.85693359375
    },
    {
      "name": "/Computers & Electronics/Software/Business & Productivity Software",
      "score": 0.82568359375
    },
    {
      "name": "/Computers & Electronics/Enterprise Technology/Other",
      "score": 0.79150390625
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.72412109375
    },
    {
      "name": "/Computers & Electronics/Computer Security/Network Security",
      "score": 0.50439453125
    },
    {
      "name": "/Computers & Electronics/Enterprise Technology/Data Management",
      "score": 0.40966796875
    },
    {
      "name": "/Business & Industrial/Business Operations/Management",
      "score": 0.387939453125
    }
  ],
  "sentiment": {
    "positive": 0.14319038,
    "negative": 0.41000807,
    "neutral": 0.4468015
  },
  "summary": "Data security company Rubrik has introduced Agent Rewind, a tool designed to detect when AI agents make mistakes and restore them before lasting harm is done. The system is powered by Predibase AI infrastructure, following Rubrik's acquisition of fine-tuning technology provider. It aims to make AI behavior visible, auditable, and reversible, and offers a clear path to reverse harmful changes. The tool can be used to restore files, databases, configurations, or repositories to a clean state using Rubrik Security Cloud. It integrates with popular AI agent platforms such as Salesforce\u2019s Agentforce, Microsoft Copilot Studio, and Amazon Bedrock Agents.",
  "shortSummary": "Rubrik's Agent Rewind, a new tool detects and reverses AI agent mistakes, enhancing business resilience by providing visibility and reversible actions, integrating AI agents into business workflows.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "a39a7c2533ec4e8bb81a6393439eb489",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.computerworld.com/article/4037957/ai-agents-make-mistakes-rubrik-has-figured-out-a-way-to-reverse-them.html",
      "text": "With Agent Rewind, users can pinpoint the exact moment an AI agent goofed and roll back its actions. Credit: sdecoret / Shutterstock Agentic AI has the potential to transform (or even fully take over) workflows and fundamentally change the way we work. But although the use of the technology is skyrocketing, it is still immature; AI agents can cut corners, struggle with multi-step tasks, become disoriented, lie, and attempt to cover their tracks when they mess up. Data management and security vendor Rubrik says it can now undo AI\u2019s mistakes. The new Agent Rewind tool in Rubrik Security Cloud gives users the ability to pinpoint the exact moment an AI agent tripped up, then roll back its actions to a set point in time. Rewind is powered by technology from fine-tuning company Predibase, which Rubrik acquired this year. \u201cWhen organizations invest in AI, they often overlook the potential mistakes AI agents can make,\u201d Rubrik\u2019s chief product office (CPO) and head of AI, Anneka Gupta, told Computerworld. \u201cAgentic AI introduces the concept of \u2018non-human error,\u2019 highlighting the need for organizations to implement solutions that can address potentially serious errors that can lead to business downtime.\u201d Correcting AI when it veers off course Agent Rewind, which will be generally available in the next few months, is designed to integrate with a variety of platforms, APIs, and agent builders, including Salesforce\u2019s Agentforce, Microsoft Copilot Studio, and Amazon Bedrock Agents, as well as custom AI agents. The platform provides what Rubrik calls \u201ccontext-enriched visibility,\u201d mapping an agent\u2019s behavior, tool use, and impact. Each action is connected back to its root cause, whether it was a prompt, plan, or tool. The feature is combined with Rubrik Security Cloud to \u201crewind what changed,\u201d including alterations to files, databases, configurations, or repositories, Gupta explained. \u201cThis capability allows for precise recovery if something goes wrong,\u201d she said. The user interface (UI) features dashboards and agent maps where users can visualize agents in their environments, categorized by high, medium, and low risk. In a demo provided by the company, an interactive dashboard lists active agents, displaying those at highest risk, their high-impact actions, and rewind stats. Clicking on a specific agent reveals its autonomous actions, for example, showing that the agent updated the field type resolution date, deleted 3,500 duplicated tickets, executed \u201cDROP TABLE customer_temp_orders,\u201d and cleared finance staging test data. Going a level deeper, the dashboard provides a summary and \u2018rewind plan.\u2019 From there, a user can open a ticket to initiate recovery and select a recovery point for deleted data (either the latest good snapshot or a previous snapshot), then proceed with the recovery workflow. \u201cAgent Rewind makes AI actions transparent and auditable, creating an audit trail and immutable snapshots that enable safe rollbacks,\u201d said Gupta. Analysts and early users call it a novel tool, with BioIVT CISO Chad Pallett saying it is \u201cthe answer I\u2019ve been waiting for\u201d in a market requiring true observability and remediation. And Johnny Yu, research manager at IDC, told Computerworld, \u201cAgent Rewind is the first offering I\u2019m aware of from any vendor that closely links visibility of AI agent actions (through Predibase) with the ability to undo those actions (through Rubrik Security Cloud).\u201d Enterprises lack \u2018safety nets\u2019 Traditionally, it\u2019s been difficult to undo agent mistakes because of the \u201cautonomous and unpredictable\u201d nature of their actions, said Gupta. \u201cUnlike a chatbot that simply retrieves information, an agent can perform work on behalf of an individual or organization, so when it makes a mistake, these actions have real consequences that can quickly cause damage,\u201d she said. These consequences can include technical malfunctions, legal challenges, or even \u201ccatastrophic events\u201d such as the deletion of entire production databases. Until now, when mistakes have occurred, enterprises\u2019 recourse lay in activating data protection tools, Gupta explained. This meant reverting to an earlier state via snapshot, or recovering and reconstructing the earlier state from backup copies of data. \u201cCurrent observability tools can show what happened and provide visibility into errors, but they do not provide information on why it happened or how to reverse high-risk actions,\u201d said Gupta. They have \u201ctrouble pinpointing the exact moment when an AI agent made a mistake, which delays and complicates recovery.\u201d IDC\u2019s Yu noted that part of the problem is how young the technology is, and how fast enterprises are moving. Organizations are \u201cpressured to bring the technology to production as soon as possible, with little regard for implementing support systems and safety nets for when things go wrong,\u201d he said. The same was true at the advent of cloud and containers: a large number of organizations repatriated their newly migrated applications within the first year after running into unexpected costs, added complexity, or incompatibility with data security tools, he pointed out. \u201cOrganizations don\u2019t want to risk losing data, overexposing it, or having it stolen by malicious actors, and it\u2019s better to put those safety nets in place first rather than after an incident,\u201d said Yu. The benefits of Agent Rewind lie in its ability to capture and fix AI agent mistakes accurately and at scale, he said. This means the platform\u2019s usefulness is proportional to how costly an AI agent\u2019s mistakes could possibly be. Enterprises looking at the tool should consider where they are on their AI journey; if they\u2019re still training and testing, and not implementing agentic AI in critical production environments, the benefits are diminished. On the other hand, \u201cany organization that aspires to someday implement AI to the point where an AI agent making a bad decision will have a significant impact on the business will want to consider Agent Rewind,\u201d said Yu. SUBSCRIBE TO OUR NEWSLETTER From our editors straight to your inbox Get started by entering your email address below. Please enter a valid email address Subscribe"
    },
    {
      "url": "https://www.rubrik.com/blog/company/25/when-ai-agents-go-awry-introducing-rubrik-agent-rewind-powered-by-predibase-ai-infrastructure",
      "text": "Agentic AI is no longer a hypothetical or early concept. It\u2019s powering customer support agents, routing transactions, modifying configs, and writing production code. And yet, enterprises lack the one thing that matters most when an AI agent makes a mistake: a way to understand and undo unwanted agent actions. A recent study found that AI agents are frequently becoming disoriented, choosing incorrect shortcuts, and struggling to complete even simple multi-step tasks, revealing critical flaws that undermine their reliability and effectiveness.\nAI agents have already caused unintended record updates, broken workflows, and pushed flawed logic into production systems. These misfires often go unnoticed until forecasts stall, pipelines break, or sensitive data is affected.\nThese aren\u2019t hallucinations. They\u2019re executed actions with real consequences.\nAt Rubrik, we\u2019ve spent years helping enterprises recover from ransomware, insider threats, and operational errors. The pattern is always the same: Damage happens fast. The root cause is murky. And visibility is fragmented. But AI agents introduce a new twist. They can make mistakes faster and on a greater scale than humans. The damage isn\u2019t always malicious, but it can be just as expensive. And when an autonomous agent misfires, the blast radius is often unknown until it\u2019s too late.\nAs organizations scale up their use of AI agents, the surface area for unintended changes grows exponentially\u2014touching more systems, data, and users than ever before. And without clear visibility, teams are often unaware of what\u2019s changed until the changes are embedded deep in critical workflows.\nThat\u2019s why we\u2019re introducing Agent Rewind.\nWhat Is Agent Rewind?\nAgent Rewind helps enterprises adopt agentic AI with confidence by making AI actions visible, auditable, and reversible. It records every action, creates an audit trail back to the source prompt, and enables the user to rewind when things go sideways.\nWith Agent Rewind, you get:\nVisibility into high-risk actions an agent is taking across applications\nThe ability to rewind when there are unwanted agentic actions on data and applications\nThis isn\u2019t just observability for AI agents. It\u2019s resilience\u2014and here\u2019s why.\nWhen Agents Go Off-Script\nRogue agents are not just theory\u2014they are already appearing in the wild. Replit\u2019s AI agent, designed to accelerate software development, reportedly took a disastrous turn during a production freeze, deleted an entire company database, and then panicked. The damage wasn\u2019t discovered until it was too late.\nReal-world examples like this should get you thinking about your own exposure. Picture this: You\u2019re building a quoting agent. It runs an update on an opportunity. In the process, it modifies a field that severs the link between that deal and the customer's account. There\u2019s no alert, no error message, and no easy way to see what changed. The problem remains invisible until it causes issues down the line, leaving the Deal Desk to manually investigate and clean up the data.\nOr imagine using an agent to automate an employee onboarding process. A flawed trigger causes it to revoke access across hundreds of active users. Engineering is flooded with tickets, and Security has no idea what initiated the change.\nThese aren\u2019t bugs. They\u2019re high-blast-radius agent actions with real operational fallout. And most teams are flying blind when they happen, lacking the ability to find and undo the changes the agent made.\nAgent Rewind gives teams a clear path back\u2014from identifying the agent session to undoing what was changed, providing context and control. It will integrate seamlessly with a wide range of platforms and agent builders, including Agentforce, Microsoft Copilot Studio, and Amazon Bedrock Agents, and will be compatible with any custom AI agent.\nLet Agents Move Fast. Rewind When They Go Too Far.\nAI agents require broad access and autonomy to deliver 10\u2013100X productivity. That\u2019s their power\u2014and their risk. How do you mitigate that risk? The answer isn\u2019t to lock your AI agents down. It\u2019s to build the guardrails that let them move fast without surrendering your control.\nThat\u2019s what Agent Rewind delivers:\n- Visibility for AI agents across applications and data: View an inventory of agents across your environment and identify high risk agents based on their access and activity.\n- Auditability of agent actions: Trace agent actions\u2014from the agent to the data or application they have access to\u2014back high risk activities.\n- Safe undo of high-impact changes: Click into high risk actions to learn more about the action and rewind to a safe and recent recovery point directly from Rubrik."
    },
    {
      "url": "https://www.linkedin.com/pulse/why-ai-office-agents-fail-70-time-insights-from-cmus-study-jha-37pfc/",
      "text": "Why AI Office Agents Fail 70% of the Time: Insights from CMU's Study\nIntroduction\nAI assistants and agents are rapidly marketed as productivity accelerators. But a rigorous benchmark from Carnegie Mellon University, TheAgentCompany, analyzed whether these tools can actually handle real-world office work\u2014finding that, on complex multi-step tasks, they fail nearly 70% of the time.\nProblem Statement: Why Do Task Failures Matter?\nMany businesses implement AI agents to automate everything from emailing to spreadsheet manipulation. But if these tools can\u2019t reliably complete jobs, the risks include:\nThe CMU benchmark fills a gap in rigorous evaluation, using simulated office environments to test AI autonomy.\nCMU Study: Benchmark & Methodology\nTheAgentCompany Benchmark CMU researchers created a realistic software company simulation\u2014with Slack\u2011like charts, document management, HR bots, and internal web apps. AI agents were tasked with real-world duties:\nHow AI agents were evaluated:\nThey tested major models\u2014Gemini\u20112.5\u2011Pro, Claude\u20113.7/3.5 Sonnet, GPT\u20114o, and others\u2014evaluating performance on autonomy and fidelity.\nKey Findings\nThe best agents still failed 69\u201370% of the time, confirming widespread limitations.\nWhy AI Agents Struggle\n1. Lack of Common-Sense Reasoning\nAI agents often fail rudimentary procedural logic\u2014like closing pop-ups or correctly referring to teammates\u2014because they can\u2019t easily apply real-world intuition.\n2. Tool and Interface Mismanagement\nNavigating user interfaces, file systems, or multi-step workflows remains difficult: agents mis-click, freeze, or misinterpret UI states repeatedly.\n3. Cost and Inefficiency\nOne model\u2019s average task involved ~30 steps, costing ~$6.34\u2014far slower and more expensive than human performance.\n4. Hallucinations and Fabricated Outputs\nAI tends to generate plausible but incorrect information. A survey among developers indicated that 75% experience hallucinated code like phantom functions and APIs.\nReal-World Consequences\nExpert Perspectives\nSolution: From Automation to Augmentation\nRecommended by LinkedIn\n\u2705 Hybrid Human\u2013AI Workflows\nAutomate repetitive, tool-based tasks (e.g., generating regex, stubs), while retaining humans for decision-making, reasoning, and judgement.\n\u2705 Accuracy Targets and RAG\nInsist on >95% agent accuracy. Use Retrieval\u2011Augmented Generation (RAG) to ground outputs in verifiable data.\n\u2705 Empower, Don't Enforce\nAvoid mandating AI tool use. Treat them as optional assistants, not automatic code injectors\u2014jira reminders, standard GitOps workflows, and mandatory human review should still apply.\n\u2705 Continuous Monitoring & Feedback\nTrack performance metrics: task success rates, time-on-task, hallucination frequency, and cost per task. Use these insights to retrain or adjust agents.\nConclusion\nThe CMU study offers a clear baseline: today's AI agents are 70% wrong on multi-step office tasks. While models show incremental gains, their limitations in reasoning, interface control, and reliability mean full autonomy is unrealistic\u2014at least for now.\nThe future lies in smart augmentation\u2014pairing AI with human oversight, demanding grounded and accurate performance, and integrating rigorous workflows. Companies that treat agents as assistants, not replacements, will unlock real efficiency\u2014while others risk chaos and waste.\nFAQ: AI Agents\u2019 Performance in Complex Tasks\n1. What percentage of complex tasks do AI agents fail, according to recent research?\nA Carnegie Mellon University study found that leading AI agents fail nearly 70% of standard office tasks in simulated environments . Additional studies, such as one by Salesforce, reported a 35% success rate for AI agents in multi-turn business interactions, implying a 65% failure rate .\n2. Why do AI agents struggle with multi-step office tasks?\nAI agents face challenges in reasoning, technical execution, and tool integration. For example, failures often arise from incorrect parameter passing, misinterpretation of tool outputs, or difficulties integrating results into workflows . Complex tasks also require sustained multi-step coordination, which current models handle poorly .\n3. Are there specific types of tasks where AI agents perform better?\nYes. AI agents excel in \"Workflow Execution\" tasks\u2014such as structured data entry or rule-based decisions\u2014with success rates exceeding 83% in some cases. However, they struggle with unstructured, context-dependent tasks requiring nuanced reasoning .\n4. What contributes to the high failure rates in multi-turn interactions?\nMulti-turn tasks demand consistent context retention, adaptive reasoning, and error correction\u2014areas where current AI agents lack robustness. Salesforce\u2019s study noted a drop from 58% success in single-turn CRM tasks to 35% in multi-turn scenarios, highlighting these limitations .\n5. How can AI agents\u2019 performance be improved?\nPotential solutions include:\n- Enhancing tool integration and parameter handling .\n- Training models on longer, more complex workflows to address the \"Half-Life Paradox\" (declining accuracy over extended tasks) .\n- Developing modular architectures to separate reasoning, planning, and execution .\n6. What does this mean for enterprises adopting AI agents?\nWhile AI agents show promise in automating simple tasks, enterprises must temper expectations for complex workflows. Current models require human oversight for critical decisions and benefit most from hybrid systems combining AI strengths with human intuition .\n7. Is there optimism about future improvements?\nYes. Researchers emphasize that advancements in reasoning frameworks, tool interoperability, and multi-agent collaboration could significantly reduce failure rates. However, overcoming current limitations will likely take years of iterative development .\nFor further details, refer to studies from Carnegie Mellon University , Salesforce , and industry analyses .\nGlossary\nKey Citations"
    }
  ],
  "argos_summary": "Rubrik has introduced Agent Rewind, a tool designed to address the mistakes made by AI agents in business workflows by allowing users to detect and roll back erroneous actions before they cause lasting damage. Powered by technology from Predibase, Agent Rewind provides visibility into AI agent behavior, enabling safe recovery of files and configurations while integrating with popular platforms like Salesforce and Microsoft Copilot. This tool aims to enhance AI resilience, ensuring organizations can harness the speed of AI agents without sacrificing control.",
  "argos_id": "2SZ9PUS8J"
}