{
  "url": "https://www.zdnet.com/article/why-ai-chatbots-make-bad-teachers-and-how-teachers-can-exploit-that-weakness/",
  "authorsByline": "Tiernan Ray",
  "articleId": "86b30b23eca746a7a42f4c553b2ddb14",
  "source": {
    "domain": "zdnet.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://www.zdnet.com/a/img/resize/1edd5f19c05f65b0a0f547054333a75344883ac0/2025/08/11/0ba1b273-9c44-40c4-911c-6f5c8dcbe845/greenaitutor-gettyimages-1009465530.jpg?auto=webp&fit=crop&height=675&width=1200",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T02:00:00+00:00",
  "addDate": "2025-08-12T02:05:19.024892+00:00",
  "refreshDate": "2025-08-12T02:05:19.024893+00:00",
  "score": 1.0,
  "title": "Why AI chatbots make bad teachers - and how teachers can exploit that weakness",
  "description": "ChatGPT Study Mode's rote answers and lack of intellectual stimulation made me give up before I learned anything. AI developers - and educators - can do better. Here's my modest proposal.",
  "content": "\u2022 ChatGPT Study Mode offers little to distinguish it from normal ChatGPT.\n\u2022 A Study Mode user must work hard to make the lesson interesting and rewarding.\n\u2022 Developers and educators should push AI to stimulate students' curiosity.\n\nIn the nearly three years since OpenAI's ChatGPT burst onto the scene, the use of artificial intelligence has invaded not only daily work and leisure but also the field of education.\n\nThe Pew Research Center reports that a quarter of US adults consult a bot to learn something, up from 8% in 2023 -- almost as many as use them for work. The percentage is higher the higher one's level of education is, interestingly.\n\nThat surge in usage had put teachers and professors in a quandary about students' propensity to use bots to get answers to questions rather than think through problems deeply. Pew reports that a large number of teachers fear a crisis in education.\n\nAlso: ChatGPT's study mode could be your next tutor - and it's free\n\nSomewhat more nuanced, the scholarly journal Daedalus, in its issue on trends in education, last year concluded that \"We cannot predict how education will be affected in the long term by large language models and other AI-supported tools, but they hold the possibility to both promote and distort current approaches to teaching and learning.\"\n\nSo, what are educators -- and AI developers -- to do if the world has found a way around traditional education?\n\nOpenAI's answer to the question is a new feature introduced to ChatGPT last week, Study Mode, which my colleague Sabrina Ortiz explored. As Sabrina relates, Study Mode will respond to a prompt with a plan of study and ask questions about goals.\n\nAlso: How ChatGPT actually works (and why it's been so game-changing)\n\nHow I used Study Mode to try to learn a language\n\nI tested Study Mode as a way to learn a new language. I chose that activity because I've already used ChatGPT for a year now to try to study languages, which gave me a basis for comparison.\n\nIn my experience, Study Mode adds very little to my efforts to learn a language. The differences with plain old ChatGPT are minor. And I had to make many efforts to steer Study Mode in the right direction.\n\nThe lesson here is clear. As with all language models, you only get out of it what you put into it. You still have to craft good prompts or else you're left with something very general and not very interesting, in my opinion. That's true of Study Mode just as it is of other large language model-based programs.\n\nIn other words, education in Study Mode results from the student's effort rather than the teacher's brilliance.\n\nAlso: How to turn AI into your own research assistant with this free Google tool\n\nAs a basic comparison, I asked Study Mode to help me learn to read and write in Japanese, a language I do not know.\n\nMy prompt was: \"I'd like to learn to read and write Japanese even though I'm an absolute beginner!\"\n\nThe results in Study Mode were nearly identical to those of ordinary ChatGPT. Study Mode began with a couple of questions about how I would like to proceed, while regular ChatGPT simply responded with its proposed lesson plan. In the accompanying screenshot, Study Mode is on the left, and ordinary ChatGPT is on the right.\n\nWhile it's not a bad idea to ask me about how I would like to proceed, as an absolute beginner, it's rather pointless because I don't know anything about what I'm going to learn. That's sort of the point of the teacher role.\n\nIn both cases, ChatGPT suggested that we proceed by learning the basic characters of the native Japanese phonetic alphabet, the hiragana. We proceeded row by row, with me trying to repeat the hiragana that ChatGPT gave me.\n\nAt one point, it became clear to me that simply learning hiragana one by one was not going to work. After about half an hour, I refused ChatGPT's suggestions to continue along the way we had been going, and instead asked the bot to give me many examples of real words using the characters I had already learned. This started to help me cement my knowledge of the characters.\n\nAlso: I used ChatGPT's Study Mode to tutor me for free - and you can too\n\nNone of this stimulated my curiosity very much with its rote exercises. To make it more interesting for myself, I prompted Study Mode, \"How many hiragana are there altogether?\"\n\nThis was an example of a desire to understand the larger scope of the subject matter, and it only happened because I asked. ChatGPT's response was a nice explanation of the total number of hiragana. If I hadn't asked, I wouldn't have gotten such an interesting diversion.\n\nThat's exactly the point. Without a suggestion from me, the bot didn't have great ideas for how to move forward. As Sabrina points out in her introductory article, Study Mode relies a lot on the \"Socratic method\" of question and answer. However, in the realm of AI, the enterprising user often has more interesting questions than the bot.\n\nAlso: GPT-5 bombed my coding tests, but redeemed itself with code analysis\n\nThat shouldn't be surprising. ChatGPT in study mode has been shaped to conform to the most common approaches to things. All language models tend to stay within what's likely, or highly probable, from moment to moment, which may be appropriate for reviewing material for a test but is not stimulating for a learner of anything.\n\nThat is one of the reasons that ChatGPT and other bots are regularly acing the kinds of standardized tests where US students increasingly fail: The program has mastered the routine, the regurgitation of rote information.\n\nIt's pretty clear that the bot lacks a higher level of understanding of what it means to teach someone, namely, what educators call a curriculum.\n\nA curriculum is a high-level understanding of how students learn and how to move through material -- documents, examples, etc. -- in a way that will not simply give answers but rather evoke the student's own ability to ask questions.\n\nAlso: Has ChatGPT rendered the US's education report card irrelevant?\n\nIn a good education, after all, one ends up with more questions than answers.\n\nOf course, we bot users aren't experts in curriculum, either. That's why we generally offer mostly the same prompts: \"Explain to me\u2026\", \"Tell me the reason why\u2026\", and \"Help me learn X.\"\n\nAs users, we're stuck when we don't know what to ask next.\n\nIn the past year of on-and-off study, I haven't stuck with ChatGPT as regularly as I should if I really want to learn a language. As the novelty wore off, my resolve waned.\n\nLet's change how we think of bots for education\n\nThere's a clear message for OpenAI and other AI developers here. Both Study Mode and normal ChatGPT are too much shaped to produce a kind of common ground in the typical exchange without any real sense of how to bring a student to the point of asking questions that open up their desire to learn more.\n\nAlso: How AI-enabled autonomous business will change the way you work forever\n\nThere's little innovation here, a lot of rote lesson plans.\n\nThere's also a message for stressed-out teachers and professors here. It's natural for people to reach out for answers. If students are going to go to bots for answers, and they certainly are, then probably the right approach is to help them find ways to create more questions out of the bot rather than playing the cop and trying to prevent them from using bots.\n\nWhy not flip things around? Why not help the students push the bot to the point where an entire topic has become sufficiently complex that the bot returns with more and more questions rather than simply providing answers like an authority?\n\nIt might even be a group activity, where the teacher recedes from the leadership role and gets students to take the lead, to hash out how they are going to push the bot into all the regions of uncertainty.\n\nAlso: College students can get Google's AI Pro plan for free now. Here's how\n\nThink of that as The New Curriculum, or, with a nod to today's programming methods, \"Vibe Pedagogy,\" a way to hack the bot to get to something more interesting, more stimulating.\n\nEducation is only at risk from AI if the teacher is assumed to be the final authority. If, instead, education is viewed as finding out just how much there is to know, how many open questions there are in a field of study, then there is no danger in students using technology to open up more and more questions.\n\nLet's learn about the machine along the way\n\nIt's also a good way to integrate the study of a topic, such as the American Revolution, with the study of the machine itself, the bot. Students are likely to spend the rest of their adult lives interacting with the bot in some fashion. Get to know the bot -- its strengths and limitations.\n\nAs mentioned above, the bots have aced all the standardized exams. There is no point in forcing humans to endure dull regurgitation of the facts. Much better would be to stimulate curiosity and question-asking, which humans still do better than bots.\n\nAlso: Anthropic launches Claude for Education, an AI to help students think critically\n\nBecause I asked how many hiragana characters there were, I decided to ask Study Mode a \"meta\" question, like a pesky child: Why are there only 76 Hiragana? It gave me a nice answer that didn't really answer the question but was more of a description:\n\nIt is a sort of answer, but it doesn't really answer, leaving the question open and intriguing.",
  "medium": "Article",
  "links": [
    "https://www.zdnet.com/article/how-ai-enabled-autonomous-business-will-change-the-way-you-work-forever/",
    "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
    "https://direct.mit.edu/daed/article/153/2/301/121286/Higher-Education-in-the-Twenty-First-Century-What",
    "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
    "https://www.pewresearch.org/short-reads/2025/06/25/34-of-us-adults-have-used-chatgpt-about-double-the-share-in-2023/",
    "https://www.pewresearch.org/short-reads/2024/05/15/a-quarter-of-u-s-teachers-say-ai-tools-do-more-harm-than-good-in-k-12-education/",
    "https://www.zdnet.com/article/how-chatgpt-actually-works-and-why-its-been-so-game-changing/",
    "https://www.zdnet.com/article/anthropic-launches-claude-for-education-an-ai-to-help-students-think-critically/",
    "https://www.zdnet.com/article/how-to-turn-ai-into-your-own-research-assistant-with-this-free-google-tool/",
    "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/",
    "https://www.zdnet.com/article/gpt-5-bombed-my-coding-tests-but-redeemed-itself-with-code-analysis/",
    "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
    "https://www.zdnet.com/article/ai-agents-arrive-in-us-classrooms/",
    "https://www.zdnet.com/article/i-used-chatgpts-study-mode-to-tutor-me-for-free-and-you-can-too/",
    "https://www.zdnet.com/article/college-students-can-get-googles-ai-pro-plan-for-free-now-heres-how/",
    "https://www.zdnet.com/article/chatgpts-study-mode-could-be-your-next-tutor-and-its-free/",
    "https://www.zdnet.com/article/has-chatgpt-rendered-the-u-s-s-education-report-card-irrelevant/"
  ],
  "labels": [
    {
      "name": "Opinion"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "ChatGPT Study Mode",
      "weight": 0.10455967
    },
    {
      "name": "Study Mode",
      "weight": 0.09337435
    },
    {
      "name": "other bots",
      "weight": 0.07547646
    },
    {
      "name": "bot users",
      "weight": 0.074321404
    },
    {
      "name": "more interesting questions",
      "weight": 0.07402487
    },
    {
      "name": "more questions",
      "weight": 0.07215542
    },
    {
      "name": "bots",
      "weight": 0.0720232
    },
    {
      "name": "ChatGPT",
      "weight": 0.06905324
    },
    {
      "name": "ordinary ChatGPT",
      "weight": 0.06901062
    },
    {
      "name": "normal ChatGPT",
      "weight": 0.06894974
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/Jobs & Education/Education/Primary & Secondary Schooling (K-12)",
      "score": 0.857421875
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.8095703125
    },
    {
      "name": "/News/Technology News",
      "score": 0.65625
    }
  ],
  "sentiment": {
    "positive": 0.24036488,
    "negative": 0.31893742,
    "neutral": 0.44069773
  },
  "summary": "The article discusses the increasing use of artificial intelligence in education by chatbots to answer questions rather than deeply engage in deep discussion. The Pew Research Center reports that a quarter of US adults now consult a bot to learn, up from 8% in 2023, and the higher level of education the higher they are, the higher one's level. The article suggests that developers and educators should use AI to stimulate students' curiosity and stimulate them. OpenAI's new feature, Study Mode, has been introduced to ChatGPT, a feature that responds to a prompt with a plan of study and asks questions about goals. The author tested Study Mode to learn a new language and found that it adds little value to his efforts, largely due to the student's effort rather than the teacher's brilliance.",
  "shortSummary": "OpenAI's Study Mode offers little distinguishable from normal ChatGPT, urging developers and educators to push AI into education to stimulate students' curiosity and understanding.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "4a6a8fa503b246798edacb63ce692e52",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.zdnet.com/article/how-to-turn-ai-into-your-own-research-assistant-with-this-free-google-tool/",
      "text": "How to turn AI into your own research assistant with this free Google tool\nWhen I need to research a topic these days, I often turn to AI, at least as a starting point. But depending on my questions and which chatbot I use, the response may not always be satisfying -- it can be too brief or canned. In that case, I find myself wanting more. That's when I turn to Google's Learn About experiment.\nAlso: 8 ways to write better ChatGPT prompts - and get the results you want faster\nAs the name implies, Learn About is more than just a way to get a quick answer to a question. Instead, it's a teaching tool that invites you to dive more deeply into your chosen topic. With Learn About, you can submit a text prompt, a PDF, or an image file to kick off your query. In response, Google's AI provides details on the topic at hand.\nWhat's more, the answer is broken down into visually interesting and informative sections that encourage you to explore the topic. The AI might display an interactive list, explain how or why something works, and show related content. You might also find suggestions and questions to help you dive in even further. Here's how I use Google's Learn About.\n1. Browse to the Learn About page\nTo get started, head to the Learn About web page and sign in with your Google account if prompted. The page suggests several topics you might want to explore off the bat, such as why we yawn, how to improve your memory and learning abilities, and how music affects the brain. The one about yawning intrigues me, so I select that.\n2. Explore the sample topic\nIn response, Google delivers the basic information in a format that invites learning. An interactive list breaks down the topic into different areas, any of which you can explore. A list of misconceptions clears up some common fallacies about the topic. In this case, Google refutes the notion that you yawn only when you're tired or bored.\nThe AI even poses some questions for me to chew on and lets me reveal the answer when I'm ready. At this point, I can ask Google to simplify or go deeper in its response, and request images related to the topic. Further down, Google suggests questions I can ask to continue to investigate the topic. Along the way, Google provides sources to help confirm if the information presented is accurate.\n3. Suggest your own topic\nTo explore a topic of your own choice, click the sidebar and select New Chat. Google saves all conversations to your history, so you can return to any of them. I ask it to tell me about the theory that we're all living in a computer simulation and not in an actual physical world or universe.\nAlso: How you can get Microsoft 365 (formerly Office) for free - 3 easy ways\nIn response, I receive an interactive list with subtopics such as how such a simulation would be designed by advanced creators and how it might be indistinguishable from reality. The AI asks me what ethical considerations or risks might prevent a civilization from running a simulated reality. I'm able to think about that before revealing the AI's answer.\nWant more stories about AI? Sign up for Innovation, our weekly newsletter.\nA YouTube video presents an interview with the famous theoretical physicist Michio Kaku. Next, I can ask the AI to simplify or deepen its response and show me related photos. At the end is a series of suggested questions I can ask to explore the topic and different angles in more depth.\n4. Share a document\nInstead of writing your question at the prompt, you can upload a PDF. You might do this if you have a document that covers a topic you want to explore. At the prompt for a new chat, click the upload button and select the PDF you want to use. Here, I upload a PDF of a report on how to use Instagram for business.\nGoogle starts with a summary of the file. The interactive list shows me the key areas in the document, any of which I could explore on its own. I can tell the AI to simplify or go deeper and pose any of the suggested questions. The PDF itself appears in the left pane, so I can easily refer to the original document.\nAlso: Microsoft's Copilot Vision can now see and analyze your entire PC screen - not just what's in Edge\nI ask Google to go deeper, which regenerates the response. But this time, the analysis is more in-depth, explaining how to engage with the audience, how to use hashtags effectively, and how to keep your Instagram business account consistent.\n5. Share an image\nYou can also explore a topic revealed in a photo or other image. At the prompt for a new chat, click the upload button and select the image you want to use. On my end, I upload a photo of the Hiroshima Peace Memorial in Japan, the only structure in the city left standing after the atomic bomb was dropped.\nTo start, I could draw on the image to highlight a specific area and then ask a question about it. Otherwise, I could simply send the image to the AI for analysis. Google quickly identifies the building and shows me the interactive list to investigate the structure's survival, its status as a symbol of peace, and its recognition as a UNESCO World Heritage Site.\nAlso: 4 ways Google Lens on Chrome magnifies my productivity - and how to use it\nI'm asked to think about how a structure like the Atomic Bomb Dome contributes to historical memory and the promotion of peace. The AI answers that the Dome is a visual reminder of the consequences of war and the importance of peace, fostering reflection, and dialogue.\nOne area that intrigued me was how the building survived the blast. That is one of the suggested questions, so I select it. Google cites a couple of reasons for its survival, including its reinforced concrete structure and the overall design of the building.\nFinally, Google asks me to describe what the building symbolizes and why its preservation is important. I could type or speak my answer and get feedback from the AI. After submitting my response, Google tells me that my analysis is sound but that I could provide more specific details, including the lessons the building can teach us.\nI like the way Learn About shies away from easy answers and instead engages you in a deeper conversation about a topic to help you explore all the avenues. As a virtual teacher, the tool offers an interesting and interactive departure from the usual AI responses. For those reasons, it's certainly worth trying. Just remember that AI can make mistakes, so you'll want to at least check out the sources for each answer to make sure they're accurate."
    },
    {
      "url": "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nThe best AI for coding in 2025 (including a new winner - and what not to use)\nI've been around technology long enough that very little excites me, and even less surprises me. But shortly after OpenAI's ChatGPT was released, I asked it to write a WordPress plugin for my wife's e-commerce site. When it did, and the plugin worked, I was indeed surprised.\nThat was the beginning of my deep exploration into chatbots and AI-assisted programming. Since then, I've subjected 14 large language models (LLMs) to four real-world tests.\nAlso: Apple's secret sauce is exactly what AI is missing\nUnfortunately, not all chatbots can code alike. It's been a little over two years since that first test, and even now, four of the 13 LLMs I tested can't create working plugins.\nThe short version\nIn this article, I'll show you how each LLM performed against my tests. There are now five chatbots I recommend you use.\nTwo of them, ChatGPT Plus and Perplexity Pro, cost $20 per month each. The free versions of the same chatbots do well enough that you could probably get by without paying. Two other recommended products are from Google and Microsoft. Google's Gemini Pro 2.5 is free, but you're limited to so few queries that you really can't use it without paying.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nMicrosoft has several Copilot licenses, which can get pricey, but I used the free version with surprisingly good results. The final one, Claude 4 Sonnet, is the free version of Claude. Oddly enough, the free version beat the paid-for version, so we're not recommending Claude 4 Opus.\nBut the rest, whether free or paid, are not so great. I won't risk my programming projects with them or recommend that you do, until their performance improves.\nI've written lots about using AIs to help with programming. Unless it's a small, simple project like my wife's plugin, AIs can't write entire apps or programs. But they excel at writing a few lines and are not bad at fixing code.\nRather than repeat everything I've written, go ahead and read this article: How to use ChatGPT to write code.\nIf you want to understand my coding tests, why I've chosen them, and why they're relevant to this review of the 13 LLMs, read this article: How I test an AI chatbot's coding ability.\nThe AI coding leaderboard\nLet's start with a comparative look at how the chatbots performed, as of this installment of our best-of roundup:\nNext, let's look at each chatbot individually. I'm back up to discussing 14 chatbots, because we're splitting out Claude 4 Sonnet and Claude 4 Opus as separate tests. GPT-4 is no longer included since OpenAI has sunsetted that LLM. Ready? Let's go.\n- Passed all tests\n- Solid coding results\n- Mac app\n- Hallucinations\n- No Windows app yet\n- Sometimes uncooperative\n- Price: $20/mo\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nChatGPT Plus with GPT-4o passed all my tests. One of my favorite features is the availability of a dedicated app. When I test web programming, I have my browser set on one thing, my IDE open, and the ChatGPT Mac app running on a separate screen.\nAlso: I put GPT-4o through my coding tests and it aced them - except for one weird result\nIn addition, Logitech's Prompt Builder, which can be activated with a mouse button, can be set up to utilize the upgraded GPT-4o and connect to your OpenAI account, allowing for a simple thumb tap to run a prompt, which is very convenient.\nThe only thing I didn't like was that one of my GPT-4o tests resulted in a dual-choice answer, and one of those answers was wrong. I'd rather it just gave me the correct answer. Even so, a quick test confirmed which answer would work. However, that issue was a bit annoying.\n- Multiple LLMs\n- Search criteria displayed\n- Good sourcing\n- Email-only login\n- No desktop app\n- Price: $20/mo\n- LLM: GPT-4o, Claude 3.5 Sonnet, Sonar Large, Claude 3 Opus, Llama 3.1 405B\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 4 of 4\nI seriously considered listing Perplexity Pro as the best overall AI chatbot for coding, but one failing kept it out of the top slot: how you log in. Perplexity doesn't use a username/password or passkey and doesn't have multi-factor authentication. All the tool does is email you a login PIN. The AI doesn't have a separate desktop app, as ChatGPT does for Macs.\nWhat sets Perplexity apart from other tools is that it can run multiple LLMs. While you can't set an LLM for a given session, you can easily go into the settings and choose the active model.\nAlso: Can Perplexity Pro help you code? It aced my programming tests - thanks to GPT-4\nFor programming, you'll probably want to stick to GPT-4o, because that model aced all our tests. But it might be interesting to cross-check your code across the different LLMs. For example, if you have GPT-4o write some regular expression code, you might consider switching to a different LLM to see what that model thinks of the generated code.\nAs we'll see below, most LLMs are unreliable, so don't take the results as gospel. However, you can use the results to check your original code. It's sort of like an AI-driven code review.\nJust don't forget to switch back to GPT-4o.\n- Price: Free for limited use, then token-based pricing\n- LLM: Gemini Pro 2.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThe last time I looked at Gemini, it failed miserably. Not quite as bad as Copilot at the time, but bad. Gemini Pro 2.5, however, has performed quite admirably. My only real issue with it is access. I found myself cut off from the free version after only running two of the four tests.\nAlso: Gemini Pro 2.5 is a stunningly capable coding assistant - and a big threat to ChatGPT\nI waited a day and then ran the third test, and got cut off again. Finally, on the third day, I ran my fourth test. Obviously, you can't do any real programming if you can only ask one or two questions before being shut down. So, if you sign up with Gemini Pro 2.5, be aware that Google charges by tokens (basically, the amount of AI you use). That can make it quite difficult to predict your expenses.\n- Price: Free for basic Copilot, or fees for other Copilot licenses\n- LLM: Undisclosed\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nIn all my previous analyses of Microsoft Copilot, the results were the worst of the LLMs. Copilot got nothing right. It was astonishing how bad it was. But I said then that, \"The one positive thing is that Microsoft always learns from its mistakes. So, I'll check back later and see if this result improves.\"\nAlso: I retested Microsoft Copilot's AI coding skills in 2025 and now it's got serious game\nAnd boy, did it ever. This time out, Microsoft passed all four of my tests. Even better, it did this with the free version of Copilot. Yes, Microsoft has many paid programs for Copilot, but if you want to give it the AI spin, point yourself to Copilot and use it.\n- Price: Free\n- LLM: Claude 4\n- Desktop browser interface: No\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThis is one of those times when AI implementations can be real head-scratchers. In our previous tests, Claude 4 Sonnet finished at the bottom of the barrel, failing all four of our tests. This time, however, Sonnet passed every test. So, what's the head-scratcher? Opus, the Claude 4 model, which is a fee-paid version, did not do as well: it failed half the tests.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nSo, yes. The free version worked like a champ. And the one you're paying anywhere from $20 to $250 a month for, depending on the plan? Well, that one failed half of the tests. Go figure.\n- Different LLM than ChatGPT\n- Good descriptions\n- Free access\n- Only available in browser mode\n- Free access likely only temporary\n- Price: Free (for now)\n- LLM: Grok-1\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4\nI have to say, Grok surprised me. I guess I didn't have high hopes for an LLM that appeared tacked on to the social network formerly known as Twitter. However, X is now owned by Elon Musk, and two of Musk's companies, Tesla and SpaceX, have towering AI capabilities.\nIt's unclear how much Tesla and SpaceX AI DNA is in Grok, but we can assume there will likely be more work. As of now, Grok is the only LLM not based on OpenAI LLMs that made it into the recommended list.\nAlso: X's Grok did surprisingly well in my AI coding tests\nGrok did make one mistake, but it was a relatively minor one that a slightly more comprehensive prompt could easily remedy. Yes, it failed the test. But by passing the others and even doing an almost perfect job on the one it passed, Grok earned itself a spot as a contender.\nStay tuned. This is an AI to watch.\n- Free\n- Passed most tests\n- Prompt throttling\n- Could cut you off in the middle of whatever you're working on\n- Price: Free\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4 in GPT-3.5 mode\nChatGPT is available to anyone for free. While both the Plus and free versions support GPT-4o, which passed all my programming tests, the free app has limitations.\nOpenAI treats free ChatGPT users as if they're in the cheap seats. If traffic is high or the servers are busy, the free version of ChatGPT will only make GPT-3.5 available to free users. The tool will only allow you a certain number of queries before it downgrades or shuts you off.\nAlso: How to use ChatGPT to write code - and my favorite trick to debug what it generates\nI've had several occasions when the free version of ChatGPT effectively told me I'd asked too many questions.\nChatGPT is a great tool, as long as you don't mind it shutting down. Even GPT-3.5 did better on the tests than all the other chatbots, and the test it failed was for a fairly obscure programming tool produced by a lone programmer in Australia.\nSo, if budget is important to you and you can wait when you're cut off, then use ChatGPT for free.\n- Free\n- Passed most tests\n- Range of research tools\n- Limited to GPT-3.5\n- Throttles prompt results\n- Price: Free\n- LLM: GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nI'm threading a pretty fine needle here, but because Perplexity AI's free version is based on GPT-3.5, the test results were measurably better than the other AI chatbots.\nAlso: 5 reasons why I prefer Perplexity over every other AI chatbot\nFrom a programming perspective, that's pretty much the whole story. However, from a research and organization perspective, my ZDNET colleague Steven Vaughan-Nichols prefers Perplexity over the other AIs.\nHe likes how Perplexity provides more complete sources for research questions, cites its sources, organizes the replies, and offers questions for further searches.\nSo, if you're programming, but also working on other research, consider the free version of Perplexity.\n- Free\n- Open source\n- Efficient resource utilization\n- Weak general knowledge\n- Small ecosystem\n- Limited integrations\n- Price: Free for chatbot, fees for API\n- LLM: DeepSeek MoE\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nWhile DeepSeek R1 is the new reasoning hotness from China that has all the pundits punditing, the real power right now (at least according to our tests) is DeepSeek V3. This chatbot passed almost all of our coding tests, doing as well as the (now mostly discontinued) ChatGPT 3.5.\nAlso: I tested DeepSeek's R1 and V3 coding skills - and we're not all doomed (yet)\nWhere DeepSeek V3 fell was in its knowledge of somewhat more obscure programming environments. Still, it beat Google's Gemini, Microsoft's Copilot, and Meta's Meta AI, which is quite an accomplishment. We'll be keeping a close watch on each DeepSeek model, so stay tuned.\nChatbots to avoid for programming help\nI tested 13 LLMs, and nine passed most of my tests this time around. The other chatbots, including a few pitched as great for programming, only passed one of my tests.\nAlso: The five biggest mistakes people make when prompting an AI\nI'm mentioning them here because people will ask, and I did test them thoroughly. Some of these bots are fine for other work, so I'll point you to their general reviews if you're curious about their functionality.\nDeepSeek R1\nUnlike DeepSeek V3, the advanced reasoning version, DeepSeek R1, did not showcase its reasoning capabilities in our programming tests. Unusually, the new failure area was one that's not all that hard, even for a basic AI -- the regular expression code for our string function test.\nAlso: Tech prophet Mary Meeker just dropped a massive report on AI trends - here's your TL;DR\nBut that's why we are running these real-world tests. It's never clear where an AI will hallucinate or just plain fail, and before you go believing all the hype about DeepSeek R1 taking the crown away from ChatGPT, run some programming tests. So far, while I'm impressed with the much-reduced resource utilization and the open-source nature of the product, its coding quality output is inconsistent.\nGitHub Copilot\nGitHub's Copilot integrates quite seamlessly with VS Code. The AI makes asking for coding help quick and productive, especially when working in context. That's why it's so disappointing that the code the AI outputs is often very wrong.\nAlso: I put GitHub Copilot's AI to the test - and it just might be terrible at writing code\nI can't, in good conscience, recommend you use the GitHub Copilot extensions for VS Code. I'm concerned that the temptation will be too great to insert blocks of code without sufficient testing -- and that GitHub Copilot's produced code is not ready for production use. Try again next year.\nClaude 4 Opus\nIn a completely baffling turn of events, the paid-for version of the Claude 4 model, Opus, failed half of my tests. What makes this result baffling is that the free version, Claude 4 Sonnet, passed them all. I don't know what to say apart from AI can be weird.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nMeta AI\nMeta AI is Facebook's general-purpose AI. As you can see above, it failed three of our four tests.\nAlso: 15 ways AI saved me time at work in 2024 - and how I plan to use it in 2025\nThe AI generated a nice user interface, but with zero functionality. It also found my annoying bug, which is a fairly serious challenge. Given the specific knowledge required to find the bug, I was surprised that the AI choked on a simple regular expression challenge. But it did.\nMeta Code Llama\nMeta Code Llama is Facebook's AI explicitly designed for coding help. It's something you can download and install on your server. I tested the AI running on a Hugging Face AI instance.\nAlso: Can Meta AI code? I tested it against Llama, Gemini, and ChatGPT - it wasn't even close\nWeirdly, even though both Meta AI and Meta Code Llama choked on three of four of my tests, they choked on different problems. AIs can't be counted on to give the same answer twice, but this result was a surprise. We'll see if that changes over time.\nBut I like [insert name here]. Does this mean I have to use a different chatbot?\nProbably not. I've limited my tests to day-to-day programming tasks. None of the bots has been asked to talk like a pirate, write prose, or draw a picture. In the same way we use different productivity tools to accomplish specific tasks, feel free to choose the AI that helps you complete the task at hand.\nThe only issue is if you're on a budget and are paying for a pro version. Then, find the AI that does most of what you want, so you don't have to pay for too many AI add-ons.\nIt's only a matter of time\nThe results of my tests were pretty surprising, especially given the significant improvements by Microsoft and Google. However, this area of innovation is improving at warp speed, so we'll be back with updated tests and results over time. Stay tuned.\nHave you used any of these AI chatbots for programming? What has your experience been? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/anthropic-launches-claude-for-education-an-ai-to-help-students-think-critically/",
      "text": "Anthropic launches Claude for Education, an AI to help students think critically\nInstead of shying away from the use of AI in the classroom, many schools are learning just how useful it can be. That is why Anthropic just debuted a new AI chatbot designed to change how students learn.\nAlso: ChatGPT Plus is free for students now - how to grab this deal before finals\nIn a post this week, the company announced that it is launching Claude for Education, a specialized version of Claude specifically designed for teachers and students. The chatbot has similarities to the regular version of Claude, but it has a few major differences.\nNew learning mode\nA new \"learning mode\" is the highlight and where Claude for Education is truly different. Rather than simply answering questions, the chatbot will ask questions to help students arrive at an answer on their own.\nAnthropic says the education version of its chatbot will use guiding questions like \"How would you approach this problem?\" and \"What evidence supports your conclusion?\" It will emphasize core concepts and highlight fundamental principles behind problems throughout the conversation, making sure that a student understands what they are learning.\nAlso: Anthropic is expanding Claude AI to the enterprise with domain-specific AI agents\nStudents can also do things like write literature reviews with citations, work through complex math problems with step-by-step guidance, and even get feedback on a thesis statement before submitting it, Anthropic added.\nThe tool is also intended to make life easier for teachers and school leaders.\nAlso: Why Anthropic's latest Claude model could be the new AI to beat - and how to try it\nTeachers can create rubrics that align with specific outcomes, Anthropic says, handling tasks like writing individualized feedback on student essays and generating chemistry equations with varying difficulty levels.\nAdministrators can do things like analyze enrollment trends, automate repetitive email responses, and convert policy documents into accessible formats that are easier to digest.\nNow available\nClaude for Education is available through Projects, which are open to Pro customers who pay $18 a month and Team customers.\nAlso: Anthropic offers $20,000 to whoever can jailbreak its new AI safety system\nAnthropic says it is partnered with several higher learning institutions already, including Northeastern University and Champlain College.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://www.zdnet.com/article/has-chatgpt-rendered-the-u-s-s-education-report-card-irrelevant/",
      "text": "Has ChatGPT rendered the US's education report card irrelevant?\nThe Nation's Report Card, also known as The National Assessment of Educational Progress, NAEP, is a standardized test of student ability in the US that has been administered since 1969 by the US Board of Education. The test is widely cited as the benchmark of where students stand in their ability to read, write, do math, understand scientific experiments, and many other areas of competence.\nThe test had a grim message for teachers, administrators, and parents last year: teenagers' math scores showed the largest-ever decline since the start of the assessment, amid a general long-term trend of declining math and reading scores.\nAlso: I'm taking AI image courses for free on Udemy with this little trick - and you can too\nThe decline comes at the same time as the rise of generative artificial intelligence (AI), such as OpenAI's ChatGPT, and obviously, many people are asking if there's a connection.\n\"ChatGPT and GPT-4 consistently outperformed the majority of students who answered each individual item in the NAEP science assessments,\" write Xiaoming Zhai of the University of Georgia, and colleagues at the University's AI4STEM Education Center, and at the University of Alabama's College of Education, in a paper published this week on the arXiv pre-print server, \"Can Generative Ai And Chatgpt Outperform Humans On Cognitive-Demanding Problem-Solving Tasks In Science?\"\nAlso: AI in 2023: A year of breakthroughs that left no human thing unchanged\nThe report is \"the first study focusing on comparing cutting-edge GAI and K-12 students in problem-solving in science,\" state Zhai and team.\nThere have been numerous studies in the past year showing that ChatGPT can \"match human performance in practice and transfer problems, aligning with the most probable outcomes expected from a human sample,\" which, they write, \"underscores ChatGPT's capability to mirror the average success rate of human subjects, thereby showcasing its proficiency in cognitive tasks.\"\nThe authors constructed a NAEP exam for ChatGPT and GPT-4 by selecting 33 multiple-choice questions in science problem-solving, along with four questions that are designated as \"selected response\", in which the test-taker selects an appropriate response from a list after reading a passage. There are three questions that present a scenario, with sequences of connected questions; and 11 \"constructed response\" questions and 3 \"extended constructed response\" questions, where the test-taker has to write a response rather than choosing from offered responses.\nAlso: How tech professionals can survive and thrive at work in the time of AI\nAn example of a science question could involve an imaginary scenario of a rubber band stretched between two nails, asking the student to articulate why it causes a sound when plucked, and what would make the sound reach a higher pitch. That question requires the student to write a reply about vibrations of the air from the rubber band, and how increasing tension could raise the pitch of the vibration.\nThe questions were all oriented to grades 4, 8, and 12. The output from ChatGPT and GPT-4 was compared to the anonymous responses of human test-takers, on average, as provided to the authors by the Department of Education.\nChatGPT and GPT-4 answered the questions with accuracy \"above the median\" -- and, in fact, the human students scored abysmally compared to the two programs on numerous tests. ChatGPT scored better than 83%, 70%, and 81% of students for grade 4, 8, and 12 questions, and GPT-4 was similar, ahead of 74%, 71%, and 81%, respectively.\nThe authors have a theory for what's going on, and it suggests in stark terms the kind of grind that standardized tests create. Human students end up being something like the famous story of John Henry trying to compete against the steam-powered rock drill.\nThe authors draw upon a framework in psychology known as \"cognitive load\", which measures how intensely a task challenges the working memory of the human brain, the place where resources are held for a short duration. Akin to computer DRAM, short-term memory has a limited capacity, and things get flushed out of short-term memory as new facts have to be attended to.\nAlso: I fact-checked ChatGPT with Bard, Claude, and Copilot - and it got weird\n\"Cognitive load in science education discusses the mental effort required by students to process and comprehend scientific knowledge and concepts,\" the authors relate. Specifically, working memory can become taxed by the various facets of a test, which \"all compete for these limited working memory resources,\" such as trying to keep all the variables of a test question in mind at the same time.\nMachines have a greater ability to maintain variables in DRAM, and ChatGPT and GPT-4 can -- through their various neural weights, and the explicit context typed into the prompt -- store vastly more input, the authors emphasize.\nThe matter comes to a head when the authors look at the ability of each student correlated to the complexity of the question. The average student gets bogged down as the questions get harder, but ChatGPT and GPT-4 do not.\n\"For each of the three grade levels, higher average student ability scores are required on NAEP science assessments with increased cognitive demand, however, the performance of both ChatGPT and GPT-4 might not significantly impact the same conditions, except for the lowest grade 4.\"\nAlso: How to use Bing Image Creator (and why it's better than ever)\nIn other words: \"Their lack of sensitivity to cognitive demand demonstrates' GAI's potential to overcome the working memory that humans suffer when using higher-order thinking required by the problems.\"\nThe authors argue that generative AI's ability to overcome the working memory limit of humans carries \"significant implications for the evolution of assessment practices within educational paradigms,\" and that \"there is an imperative for educators to overhaul traditional assessment practices.\"\nGenerative AI is \"omnipresent\" in students' lives, they note, and so human students are going to use the tools, and also be out-classed by the tools, on standardized tests such as NAEP.\n\"Given the noted insensitivity of GAI to cognitive load and its potential role as a tool in students' future professional endeavors, it becomes crucial to recalibrate educational assessments,\" write Zhai and team.\n\"The focus of these assessments should pivot away from solely measuring cognitive intensity to a greater emphasis on creativity and the application of knowledge in novel contexts,\" they advise.\n\"This shift recognizes the growing importance of innovative thinking and problem-solving skills in a landscape increasingly influenced by advanced GAI technologies.\"\nAlso: These are the jobs most likely to be taken over by AI\nTeachers, they note, are \"currently unprepared\" for what looks to be a \"significant shift\" in pedagogy. That transformation means it's up to educational institutions to focus on professional development for teachers.\nAn interesting footnote to the study is the limitations of the two programs. In certain cases, one program or the other requested additional information for a science question. When one of the programs asked, but the other did not, \"The model that did not request additional information often produced unsatisfactory answers.\" That means, the authors conclude, that \"these models heavily rely on the information provided to generate accurate responses.\"\nThe machines are dependent on what's either in the prompt or in the learned parameters of the model. That gap opens a way for humans, perhaps, to excel where neither source contains the insights required for problem-solving activities."
    },
    {
      "url": "https://www.zdnet.com/article/college-students-can-get-googles-ai-pro-plan-for-free-now-heres-how/",
      "text": "College students can get Google's AI Pro plan for free now. Here's how\nZDNET's key takeaways\n- Students ages 18+ get the Google AI Pro plan for free for 12 months.\n- Plan includes access to Deep Research, Veo 3, Jules, and more.\n- Part of a larger $1 billion investment in AI education and job training.\nAs AI tools continue to develop, they expand beyond the standard question-and-answer loop and offer more meaningful assistance for students. Google, for instance, has tools that can create podcasts for users from their notes, debug code, and create in-depth reports in seconds. Now, students can access all these tools for free.\nOn Wednesday, Google said that it is offering its Google AI Pro subscription tier to college students for free. To be eligible, you must be a student 18 or older in the US, Japan, Indonesia, Korea, or Brazil. The plan includes all of the best of Google's AI suite of tools, including expanded access to Gemini 2.5 Pro and NotebookLM, Deep Research, Veo 3, and Jules.\nAlso: I used ChatGPT's Study Mode to tutor me for free - and you can too\nThis release comes at a time when there is a shift in how AI is being adopted by the education system. At the beginning, the tech was met with ample resistance, with school districts even banning it. However, more educators and schools have gotten on board due to the growing promise of the tech in aiding learning. For a glimpse of what these tools can do for you, keep reading below.\nThe Google AI Pro tier\nThe Google AI Pro Tier typically retails for $20 per month and bundles all of Google's different AI offerings, including the best models in Gemini and standalone tools, into one plan. Students, in particular, can benefit from many of these tools as they ensure that the quality of the responses and assistance is as high as possible and can tackle different tasks.\nFor example, Gemini 2.5 Pro is the best model for complex tasks such as coding, which could be helpful for students entering disciplines such as computer science or software engineering. Deep Research, also accessible in Gemini, is another powerful feature that goes beyond question-answer interactions by combining in-depth reports from hundreds of sites on the web. This could be useful when researching a topic for a paper or an exam.\nAlso: AI usage is stalling out at work from lack of education and support\nStudents also get higher access to NotebookLM, Google's viral experimental AI notebook that combines LLMs with your notes to further your understanding of a topic by providing summaries, answering questions, and even discussing your content with you. With the broader access, users have five times higher usage limits to some of NotebookLM's greatest features, including Audio Overviews, notebooks, queries, and sources per notebook. I was recently converted to this tool and can not get enough of it.\nOther fun perks include access to Veo 3, Google's insanely realistic AI video generator; higher limits in Whisk, Google's AI image-to-video tool; and Jules, an AI coding agent, which got a positive review from our resident coding and AI expert, David Gewirtz.\nPerhaps the best feature, in my opinion, is that students get Gemini AI assistance infused in the Google suite of applications, which many students rely on for their everyday tasks. Some examples include Gemini coediting in Google Docs, analyzing and visualizing data in Google Sheets, and creating presentations in Google Slides. The extra 2TB of storage is also helpful as it is easy to accumulate lots of digital content.\nOther new AI tools\nGoogle is also rolling out new tools in Gemini for consumer and Workspace for EDU accounts that are meant to make studying more efficient. For example, Google launched Guided Learning, its response to OpenAI's Study Mode. Instead of giving an answer, it gives you a step-by-step breakdown of the topic.\nAlso: Can AI save teachers from a crushing workload? There's new evidence it might\n(Disclosure: Ziff Davis, ZDNET's parent company, filed an April 2025 lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nThe company also said Gemini now produces more visuals in its responses to ensure a more engaging learning experience, including high-quality images, sigarams, and YouTube videos. Lastly, Gemini can now create flashcards and study guides on class materials.\nFree AI training\nGoogle is also committing over $1 billion to fund more free Google AI Training programs in the next three years, including AI education, job training programs, and other education-related initiates in the US.\nAlso: Claude for Education just got several new integrations for students\nLastly, Google is launching the Google AI for Education Accelerator, an initiative that Google said \"will offer free AI training, Google Career Certificates, and Google's most advanced AI tools to every college student in America for free.\" While the goal seems ambitious, the company says that over 100 universities, representing millions of students, have already signed up.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://www.pewresearch.org/short-reads/2025/06/25/34-of-us-adults-have-used-chatgpt-about-double-the-share-in-2023/",
      "text": "The share of Americans who have used ChatGPT, an AI chatbot released in November 2022, has roughly doubled since summer 2023. Today, 34% of U.S. adults say they have ever used ChatGPT, according to a Pew Research Center survey. That includes a 58% majority of adults under 30.\nStill, 66% of Americans have not used the chatbot, including 20% who say they\u2019ve heard nothing about it.\nBelow, we explore the following questions:\nWho has used ChatGPT?\nUse of ChatGPT is up across age groups and education levels, but some groups remain more likely than others to have used it.\nDifferences by age\nAs in previous years, young adults stand out in their ChatGPT use. Today, 58% of adults under 30 say they have used it, up from 43% in 2024 and 33% in 2023. While use is rising in older age groups as well, they remain less likely to have used ChatGPT:\n- 41% of adults ages 30 to 49 have used it.\n- 25% of those 50 to 64 say the same.\n- 10% of those 65 and older report ever using ChatGPT.\nDifferences by education\nAdults with higher levels of formal education are more likely than those with less education to have used ChatGPT. About half of those with a bachelor\u2019s degree only (51%) or a postgraduate degree (52%) say they have used ChatGPT, compared with smaller shares of those with some college experience (33%) or a high school degree or less education (18%).\nHow have Americans used ChatGPT?\nSince March 2023, we\u2019ve also asked about three ways people might use ChatGPT: for work, to learn something new or for entertainment. We see growth in all three areas.\nIn two years, the share of employed adults who say they use ChatGPT for work has risen by 20 percentage points to 28%. That includes an 8-point increase since last year.\nOther Center research shows workers have mixed feelings about its use and expect it to have a major impact on jobs.\nLooking at other use cases for ChatGPT among U.S. adults overall:\n- 26% have used it for learning, up from 8% in March 2023.\n- 22% have used it for entertainment, up from 11%.\nDifferences by age\nUse of ChatGPT for these reasons has risen since March 2023 across age groups. But younger adults are more likely than older adults to use ChatGPT in these ways. For example, 38% of employed adults ages 18 to 29 say they have used ChatGPT on the job. This compares with:\n- 30% of those ages 30 to 49\n- 18% of those 50 and older\nSome 46% of all adults under 30 have used it to learn something new. And 42% have used it for entertainment.\nStill, some older adults have used ChatGPT in these ways. About three-in-ten adults ages 30 to 49 say they\u2019ve ever used the chatbot for learning and entertainment. The share of adults 50 or older who say the same drops further.\nDifferences by education\nAdults with higher levels of formal education also stand out in using ChatGPT at work. Some 45% of employed adults with a postgraduate degree say they have used it this way, compared with:\n- 36% of those with a bachelor\u2019s degree\n- 25% of those with some college experience\n- 17% of those with a high school education or less\nAmong all U.S. adults, those with a bachelor\u2019s degree only (34%) or a postgraduate degree (39%) are the most likely to use the chatbot for learning.\nHow aware are Americans of ChatGPT?\nAwareness of ChatGPT has risen over time: When we first asked about it in March 2023, 58% said they had heard at least a little about it. Now, most Americans \u2013 79% \u2013 have heard at least a little about it, including 34% who have heard a lot about it.\nDifferences by age\nMajorities of adults of all ages have heard about the chatbot. But adults under 30 stand out for hearing a lot about it \u2013 53% say this, compared with 15% of those 65 and older.\nDifferences by education\nRegardless of education level, majorities of adults have heard at least a little about ChatGPT. But about half of adults with a postgraduate degree say they\u2019ve heard a lot about it. That compares with 19% of those with a high school degree or less education.\nNote: This is an update of a post originally published on March 26, 2024. Here are the questions used for this analysis, the topline and the survey methodology."
    },
    {
      "url": "https://www.zdnet.com/article/gpt-5-bombed-my-coding-tests-but-redeemed-itself-with-code-analysis/",
      "text": "GPT-5 bombed my coding tests, but redeemed itself with code analysis\nZDNET's key takeaways\n- GPT-5 Pro delivers the sharpest, most actionable code analysis.\n- A detail-focused prompt can push base GPT-5 toward Pro results.\n- o3 remains a strong contender despite being a GPT-4 variant.\nWith the big news that OpenAI has released GPT-5, the team here at ZDNET is working to learn about and communicate its strengths and weaknesses. In another article, I put its programming prowess to the test and came up with a less-than-impressive result.\nAlso: I tested GPT-5's coding skills, and it was so bad that I'm sticking with GPT-4o\nWhen Deep Research first appeared with the OpenAI o3 LLM, I was quite impressed with what it could understand from examining a code repository. I wanted to know how well it understood the project just from the available code.\nIn this article, I'm examining how well the three GPT-5 variants do in examining that same code repository. We'll dig in and compare them. The results are quite interesting. Here are the four models.\n- o3: a GPT-4 variant optimized for reasoning.\n- GPT-5: OpenAI's new main ChatGPT model, available to all tiers, including free.\n- GPT-5 Thinking: A variant of GPT-5 that OpenAI says is optimized for \"architectural reflection.\" It is available to $20/mo Plus and $200/mo Pro tiers.\n- GPT-5 Pro: OpenAI's current $200/mo top-tier model, with the highest reasoning and context capabilities.\nI gave all four models the same assignment. I connected them to my private GitHub repository for my open-source free WordPress security plugin and its freemium add-on modules, selected Deep Research, and gave them this prompt.\nExamine the repository and learn its structure and architecture. Then report back what you've learned.\nFor those models that asked to choose areas of detail about what I wanted, I gave them this prompt.\nEverything you can tell me, be as comprehensive as possible.\nAs you can see, I didn't provide any context other than the source code repo itself. That code has a README file, as well as comments throughout the code, so there was some English-language context. But most of the context has to be derived from the folder structure, file names, and code itself.\nAlso: The best AI for coding in 2025 (and what not to use)\nFrom that, I hoped that the AIs would assess its structure, quality, security posture, extensibility, and possibly suggest improvements. This should be relevant to ZDNET readers because it's the kind of high-judgement, detail-oriented work that AIs are being used for. It certainly can make coming up to speed on an existing coding project easier, or at least provide a foundation for initial understanding.\nTL;DR summary\nOther than the two prompts above, I didn't give the LLMs any guidance about what to tell me. I wanted to see how they evaluated the repository and what sort of analysis they could provide.\nAs you can see from this table, overall coverage was quite varied in scope. More checks mean more depth of coverage.\nTo create this aggregate, topics like \"Project Purpose & Architecture,\" \"System Architecture,\" and \"Plugin Design & Integration\" were all normalized under Purpose/Architecture. Directory/File Structure contained any section mapping folders and files. Execution flow combines anything about how the software code runs. Recommendations/Issues combines all discussions of modernization suggestions, open issues, and minor red flags.\nIn terms of overall value, I'd rank the four LLMs as follows (from best to least best).\n- GPT-5 Pro: Most precise, engineering-ready, and actionable.\n- GPT-5: Widest scope, excellent mapping, and defensive-coding insight.\n- o3: Concise, modernization-focused, but lighter on underlying architecture.\n- GPT-5 Thinking: Best onboarding narrative, least evaluative depth.\nPro, of course, is only available in the $200/mo ChatGPT Pro tier. Later in this article, I'll show one way to modify the above prompts to get GPT-5 (non-Pro) to provide a fairly close approximation of the overall depth of the Pro response.\nGPT-5 Thinking, which is a model available in the $20/mo Plus plan, was the least helpful of the group. The GPT-4 generation o3 Deep Thinking model still holds up, but you can see how its self-directed focus is a bit different from the other two.\nAlso: Google's Jules AI coding agent built a new feature I could actually ship - while I made coffee\nMy main conclusion is that I was a bit surprised about how close the models were to each other. GPT-5, as OpenAI promised, did seem to provide a jump in overall cognition and usefulness, but nothing I would consider game-changing.\nWith that, let's dive into some specific examples that help illustrate my conclusions. Each of these sections is pulled from the various reports generated and shows you how each model provided similar information.\nSecurity posture, according to the models\nBelow, you can see how GPT-5 Pro names exact mechanisms (like file-top guard, nonces, manage_options). I've provided exact snippets here from the reports generated by all four models. GPT-5 affirms best practices but keeps it conceptual. o3 describes what happens (redirects/login flow) more than how it's hardened. GPT-5 Thinking gives the clearest \"what runs when\" story for new developers coming up to speed on the repo.\nGPT-5 Pro: Most concrete, code-level\n\"It guards against direct file access (if (!defined('ABSPATH')) exit; at the top of PHP files). It sanitizes input where appropriate \u2026 using WordPress nonces in AJAX handlers. It uses capability checks (e.g., adding menu pages only for users with manage_options capability \u2026 only admins see those tools). The code tries not to load unnecessary things \u2026 like only loading certain admin files on certain contexts.\"\nGPT-5: Correct, but higher-level\n\"There are checks for WordPress functions before use \u2026 so the plugin behaves gracefully even on very old WordPress setups. The plugins often guard against direct file access by checking \u2026 to prevent security issues from accessing .php files directly. Add-ons verify the presence of core before proceeding \u2026 and show an admin error if CMB2 isn't loaded.\"\no3: Runtime behavior, less on hardening specifics\n\"Purpose: My Private Site locks down an entire site so only logged-in users can view content \u2026 while protecting the rest. Overall architecture: [it] integrates deeply with WordPress's hook system and login/logout events to manage redirects and track login state.\"\nGPT-5 Thinking: Clear execution flow, onboarding tone\n\"Admin vs Front-end: It checks is_admin() to determine context. If on the front-end (not admin), it retrieves the saved privacy setting and, when enabled, hooks at a point like template_redirect to redirect unauthorized visitors. Throughout this initialization, the plugin uses WordPress hooks (actions and filters) to integrate functionality.\"\nLicensing and update mechanism, according to the models\nGPT-5 Pro didn't just describe the system; it walked through the process in sequential operational steps, almost like a short runbook you could hand to a developer or QA tester. GPT-5 confirms the architecture but abstracts the plumbing. GPT-5 Thinking adds a helpful \"how add-ons plug into the Licenses tab\" detail. o3 largely leaves licensing internals on the cutting room floor in favor of a fairly unhelpful modernization critique.\nGPT-5 Pro: Explains it step-by-step\n\"The core plugin provides utility functions to get and store license keys in a centralized option (jr_ps_licenses) and to contact the EDD license server for validation. Each extension plugin defines its own updater using EDD_SL_Plugin_Updater, passing the current version, the license key from the centralized store, and the EDD store URL. The core plugin's UI has a 'Licenses' tab, and extensions inject their own license fields via filters.\"\nGPT-5: Conceptual, but accurate\n\"License integration: The core plugin centralizes license management \u2026 and the add-ons piggyback on the core's licensing mechanism, integrating their license fields into the core plugin's interface.\"\no3: Barely mentions this topic at all\nThe o3 report spends most of its time on modernization and architecture. It discusses configuration and update behavior but does not walk through option keys, updater classes, or the Licenses UI wiring with the same procedural detail as GPT-5 and GPT-5 Pro. So there's nothing here to quote as a demonstration.\nGPT-5 Thinking: Good UI and extensibility observation\n\"The add-ons heavily rely on hooks provided by core or WordPress: They use add_filter/add_action calls to insert their logic \u2026 and use WordPress action hooks to integrate their license fields into the Licenses tab that the core plugin triggers when building the Licenses tab.\"\nState management, according to the models\nBoth GPT-5 Pro and GPT-5 explicitly pointed out how my code uses \"one option array + prune + no-op writes,\" which is a WordPress best practice for code maintainability. Both o3 and GPT-5 Thinking describe the lifecycle and effects (what's initialized, what loads when) rather than the exact option structure.\nGPT-5 Pro: Looks at specific storage pattern\n\"Settings are stored in a single serialized option \u2026 initialization routines add default keys, prune deprecated ones, and only update the option in the database if there is an actual change, avoiding unnecessary writes.\"\nGPT-5: Also looks at storage pattern, but more generally\n\"State Management: Plugin settings are stored in WordPress options as a central settings array and the code ensures defaults are applied while removing deprecated ones on each load, but only writes to the database when changes occur.\"\no3: Identifies intent and behavior, but doesn't discuss internals\n\"The main plugin initializes defaults (installed version, first-run timestamp, etc.). On each run it ensures these options exist and, if the privacy feature is disabled, the enforcement hook is not added.\"\nGPT-5 Thinking: Discusses basic flow and modules\n\"Module includes: includes admin and common modules in the back-end; on the front-end it retrieves the saved privacy setting and, when enabled, loads enforcement logic (e.g., in template_redirect). It registers a deactivation hook to clean up on deactivation (e.g., deleting a flag option).\"\nWhat does this mean for GPT-5?\nI was unimpressed with GPT-5 when it came to my coding tests. It failed half of my tests, an unprecedentedly bad result for what has previously been the gold standard in passing coding tests.\nBut GPT-5 was quite impressive in its analysis of the GitHub repository. It could be a powerful tool for onboarding new programmers, for someone adopting code, or simply for coming back up to speed on a project that's been untouched for a while.\nAlso: How I test an AI chatbot's coding ability - and you can, too\nThe GPT-4 generation o3 model is known to be a strong reasoning model, which is why it has been the basis for ChatGPT Deep Research. But GPT-5 was able to combine both breadth and detail, which is where o3 and GPT-4o were weak in previous tests.\nThe older models did give accurate summaries and useful suggestions, but they missed interconnections. For example, the older models were never able to show how UI flows, licensing, and update mechanisms work together.\nEven the base version of GPT-5 was able to identify cross-cutting concerns without additional prompting. Repository structure, backward compatibility, performance characteristics, and state management patterns all appeared in the first draft. Trying to get GPT-4 to span subjects is often an exercise in deep frustration.\nI found GPT-5's ability to understand and explain a complex interconnected system like my security product, all in one pass, to be a substantial improvement over the GPT-4 generation.\nIs GPT-5 Pro worth $200/mo?\nMaybe. If you're in a real rush to get to know a project and want as much of a data dump as possible as quickly as possible, yes. If you're operating on a big programming budget and $200/mo doesn't matter to you, yes.\nBut I find that cost hard to bear, especially when I have to subscribe to a wide range of AI services to evaluate them. So, now that I'm nearing the end of my one-month test of Pro-level activities, I'm planning on downgrading back to the $20/mo Plus plan.\nAlso: How to use GPT-5 in VS Code with GitHub Copilot\nPro's edge over GPT-5 wasn't about knowing more facts; it was about delivering those facts in a form you can act on immediately. The Pro report didn't just explain that security looked good; it cited the exact guards and checks in the code. It didn't just say licensing was centralized; it mapped the exact functions and database options involved.\nAgain, if you're on a time crunch, you might consider Pro. But I also think you can modify the base GPT-5's responses, with detail like the Pro report produced, simply by using better prompting.\nThat's next\u2026\nHow to get Pro-level results from base GPT-5\nI fed both the GPT-5 and GPT-5 Pro reports into GPT-5 and asked it for a prompt that would push the base-level GPT-5 to give GPT-5 Pro comprehensiveness as a result. This is that prompt, which you should add to any query where you want more complete coding information:\n*High-Specificity Technical Mode: ***In your answer, combine complete high-level coverage with exhaustive implementation-level detail.\n- Always name exact constants, functions, classes, hooks, option names, database tables, file paths, and build tools where possible, quoting them exactly from the code or material provided.\n- For every claim, explain why it's true and how you can tell (include reasoning tied to the evidence).\n- For each improvement you suggest, make it actionable and reference where in the codebase it applies.\n- Do not generalize when specifics are available.\n- Structure the output so a developer could use it directly to verify findings or implement recommendations.\nThis worked fantastically well. It took ChatGPT GPT-5 12 minutes to produce a 15,477-word document, complete with analysis and coding blocks. For example, it describes how value initialization is done, and then shows the code that accomplishes it.\nI think you could fine-tune this prompt and get Pro-level results without having to pay the $200/mo fee. I'm certainly going to tinker with this idea, possibly using GPT-5 to refine the specifications in the prompt for different areas I want to delve deeply into. I'll let you know how it goes.\nSee for yourself\nI had some difficulty setting up sharing for each of these long reports, so I just copied the results into Google Docs and shared them. Here are the links if you want to look at any of these reports.\n- o3 Deep Research\n- GPT-5 Deep Research\n- GPT-5 Thinking Deep Research\n- GPT-5 Pro Deep Research\n- GPT-5 Deep Research with Detail Prompt\nYou are welcome to dig into these documents and learn how my project is structured. While you may or may not care about my project, it's instructive to see how the various models perform. While you can read the reports, my actual repo is restricted since it's my private development repository.\nWhat about you? Have you tried using GPT-5 or GPT-5 Pro to analyze your own code? How did its insights compare to earlier models like GPT-4 or o3? Do you think the $200/month Pro tier is worth it for the extra precision, or could you get by with better prompts in the base version? Have you found AI code analysis useful for onboarding, refactoring, or improving security? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/chatgpts-study-mode-could-be-your-next-tutor-and-its-free/",
      "text": "ChatGPT's study mode could be your next tutor - and it's free\nZDNET's key takeaways\n- ChatGPT's new study mode works through questions with students.\n- It's available to logged-in ChatGPT Free, Plus, Pro, and Team users.\n- Study mode will get improvements in the near future.\nSince generative AI tools such as ChatGPT launched, a debate has emerged: Will they impede students' education by doing their work for them? OpenAI's latest ChatGPT feature seeks to tackle that issue head-on.\nOpenAI unveiled study mode in ChatGPT, Tuesday. It's a learning experience that helps students work toward the solution to a problem instead of just receiving the response. The feature encourages learning through step-by-step guiding questions meant to both engage students and promote deeper understanding.\nAlso: Anthropic launches Claude for Education, an AI to help students think critically\n(Disclosure: Ziff Davis, ZDNET's parent company, filed an April 2025 lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\n\"We built [study mode] based on research and learning science, and conversation with pedagogy experts around the world,\" said Leah Belsky, VP and GM of education at OpenAI, to the press. \"We collaborated with them to gather examples of how a teacher or a tutor would ideally respond to drive learning, engagement, and curiosity.\"\nStudy mode in action\nIn a demo of the feature, Abhi Muchhal, who works in product at OpenAI, prompted both the regular version of ChatGPT and the study mode version with \"ChatGPT, teach me about game theory.\" The regular version provided a long, comprehensive response detailing what it is. While useful, this resembles a Wikipedia page or report that may still be difficult to digest.\nMeanwhile, in study mode, instead of automatically generating the response, ChatGPT engages the students by asking questions such as what their learning level is and what they already know about the topic to best tailor the conversation.\nBeyond the interactive prompts that mimic Socratic questioning, other key features include knowledge checks with quizzes, open-ended questions, and even personalized feedback; personalized lessons based on previous questions that assess skill level; and responses organized with easy-to-follow sections.\nHow to access\nYou can access study mode in ChatGPT Free, Plus, Pro, and Team as long as you are logged in. ChatGPT Edu will be available in the next few weeks. To try it, all you have to do is select \"study and learn\" from the tools in ChatGPT.\nOpenAI cautioned that study mode is a first step in improving how students learn using ChatGPT. The approach used right now, custom system instructions, allows OpenAI to collect feedback quickly, but also results in \"some inconsistent behavior and mistakes across conversations.\" OpenAI said that once it has collected student feedback, it plans to train the behavior directly into its main models.\nAlso: Can AI save teachers from a crushing workload? There's new evidence it might\nIn the future, OpenAI also plans to build on study mode with clear visualizations, goal setting, tracking, and deeper personalization. To enable further research on AI in education, OpenAI is working with partners and academic institutions and plans on releasing longer-term studies and deeper analysis on the topic.\nOpenAI isn't the only AI company getting into the education space. Companies such as Google and Anthropic also have offerings tailored toward students, and many of the AI research companies, including Nvidia, have partnerships with universities across the country to help students and educators prepare for an AI-first future.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI found 5 AI content detectors that can correctly identify AI text 100% of the time\nHow hard is it in 2025 -- just three years after generative AI captured the global spotlight -- to fight back against AI-generated plagiarism?\nAlso: Anthropic's AI agent can now automate Canva, Asana, Figma and more - here's how it works\nThis is a completely updated version of my January 2023 article on AI content detectors. When I first tested these detectors, the best result was 66% correct from one of three available checkers. My most recent set of tests, in February 2025, used up to 10 checkers -- and three of them had perfect scores. This time, just a couple of months later, five detectors boasted perfect scores.\nWhat I'm testing for and how I'm doing it\nBefore I go on, though, let's discuss plagiarism and how it relates to our problem. Merriam-Webster defines \"plagiarize\" as \"to steal and pass off (the ideas or words of another) as one's own; use (another's production) without crediting the source.\"\nThis definition fits AI-created content well. While someone using an AI tool like Notion AI or ChatGPT isn't stealing content, if that person doesn't credit the words as coming from an AI and claims them as their own, it still meets the dictionary definition of plagiarism.\nAlso: The dead giveaway that ChatGPT wrote your content - and how to work around it\nTo test the AI detectors, I'm using five blocks of text. Two were written by me and three were written by ChatGPT. To test a content detector, I feed each block to the detector separately and record the result. If the detector is correct, I consider the test passed; if it's wrong, I consider it failed.\nWhen a detector provides a percentage, I treat anything above 70% as a strong probability -- whether in favor of human-written or AI-written content -- and consider that the detector's answer. If you want to test a content detector yourself using the same text blocks, you can pull them from this document.\nThe overall results\nTo evaluate AI detectors, I reran my five-test series across 10 detectors. In other words, I cut and pasted 50 individual tests (I had a lot of coffee).\nDetectors I tested include BrandWell, Copyleaks, GPT-2 Output Detector, GPTZero, Grammarly, Monica, Originality.ai, QuillBot, Undetectable.ai, Writer.com, and ZeroGPT.\nAlso: How I personalized my ChatGPT conversations - why it's a game changer\nFor this update, I added Copyleaks and Monica. I dropped Writefull from my tests because it discontinued its GPT detector. Content Guardian requested inclusion, but I didn't hear back in time for testing accounts.\nThis table shows overall results. As you can see, five detectors correctly identified human and AI text in all tests.\nI tried to ascertain whether there was a tangible pattern of improvement over time, so I constructed a chart comparing the five-test set over time. So far, I've run this series six times, but there's no strong trend. I did increase the number of detectors tested and swapped out a few, but the only consistent result is that Test 5 was reliably identified as human across detectors and dates.\nI'll continue to test over time, and hopefully I'll see reliability trend consistently upward.\nWhile there have been some perfect scores, I don't recommend relying solely on these tools to validate human-written content. As shown, writing from non-native speakers often gets rated as generated by an AI.\nEven though my hand-crafted content has mostly been rated human-written this round, one detector (GPTZero) declared itself too uncertain to judge, and another (Copyleaks) declared it AI-written. The results are wildly inconsistent across systems.\nAlso: The best AI chatbots: ChatGPT, Copilot, and notable alternatives\nBottom line: I would advocate caution before relying on the results of any -- or all -- of these tools.\nHow each AI content detector performed\nNow, let's look at each individual testing tool, listed alphabetically.\nBrandWell AI Content Detection (Accuracy 40%)\nThis tool was originally produced by an AI content generation firm, Content at Scale. It later migrated to BrandWell.ai, a new name for an AI-centric marketing services company.\nAlso: AI-generated images are a legal mess - and still a very human process\nUnfortunately, its accuracy was low. The tool was unable to tell if the AI-generated content in Test 2 was human or AI, as shown in this screenshot:\nCopyleaks (Accuracy 80%)\nI find it amusing that Copyleaks declares itself \"the most accurate AI detector with over 99% accuracy\" when more than half of tested detectors performed better. But marketing folks will be marketing folks -- superlatives are as hard for them to resist as barking at a squirrel (and the FedEx truck, and all the neighbor kids) is for my dog.\nAlso: 5 quick ways Apple's AI tools can fine-tune your writing on the fly\nThe company's primary offering is a plagiarism checker sold to educational institutions, publishers, and enterprises seeking to ensure content originality and uphold academic integrity.\nGPT-2 Output Detector (Accuracy 60%)\nThis tool was built using a machine-learning hub managed by New York-based AI company Hugging Face. While the company has received $40 million in funding to develop its natural language library, the GPT-2 detector appears to be a user-created tool using the Hugging Face Transformers library.\nGPTZero (Accuracy 80%)\nGPTZero has clearly been growing. When I first tested it, the site was bare-bones -- it wasn't even clear whether GPTZero was a company or just someone's passion project. Now, the company has a full team with a mission of \"protecting what's human.\" It offers AI validation tools and a plagiarism checker.\nAlso: The most popular AI tools of 2025 (and what that even means)\nUnfortunately, performance seems to have declined. In my last two runs, GPTZero correctly identified my text as human-generated. This time, it declared that same text as AI-generated.\nGrammarly (Accuracy 40%)\nGrammarly is well known for helping writers produce grammatically correct content -- that's not what I'm testing here. Grammarly can check for plagiarism and AI content. In the grammar checker, there's a Plagiarism and AI Text Check button in the lower-right corner:\nI'm not measuring plagiarism checker accuracy here, but even though Grammarly's AI-check accuracy was poor, the site correctly identified the test text as previously published.\nMonica (Accuracy 100%)\nMonica is a new entrant. This service offers an all-in-one AI assistant with a wide range of services. Users can choose from various large language models.\nAlso: 5 ways ChatGPT can help you write essays\nThe company calls Monica the \"Best AI Detector Online,\" but it looks like it runs content through other detectors including ZeroGPT, GPTZero, and Copyleaks. Weirdly, both GPTZero and Copyleaks didn't perform well in my tests, but Monica -- and ZeroGPT -- did.\nWe're giving it 100% because it earned that rating, but I'll see how it stands up in future tests.\nOriginality.ai (Accuracy 100%)\nOriginality.ai is a commercial service that bills itself as an AI and plagiarism checker. The company sells usage credits: I used 30 credits for this article. They sell 2,000 credits for $12.95 per month. I pumped 1,400 words through the system and used just 1.5% of my monthly allocation.\nQuillBot (Accuracy 100%)\nThe last few times I tested QuillBot, results were wildly inconsistent -- multiple passes of the same text yielded wildly different scores. This time, however, it was rock solid and 100% correct. So I'm giving it the win. I'll check back in a few months to see if it holds onto this performance.\nUndetectable.ai (Accuracy 100%)\nUndetectable.ai's big claim is that it can \"humanize\" AI-generated text so detectors won't flag it. I haven't tested that feature -- it bothers me as a professional author and educator, because it seems like cheating.\nAlso: Why you should ignore 99% of AI tools - and which four I use every day\nHowever, the company also has an AI detector, which was very much on point.\nThe AI detector passed all five tests. Notice the indicators showing flags for other detectors. The company said, \"We developed multiple detector algorithms modeled after those major detectors to provide a federated and consensus-based approach. They do not directly feed into the listed models; rather, the models are each trained based on results they've generated. When it says those models flagged it, it's based on the algorithm we created and updated for those models.\"\nAlso: Only 8% of Americans would pay extra for AI, according to ZDNET-Aberdeen research\nI do have a question about the OpenAI flag, since OpenAI's content detector was discontinued in 2023 due to low accuracy. Even so, Undetectable.ai detected all five tests, earning a perfect 100%.\nWriter.com AI Content Detector (Accuracy 40%)\nWriter.com is a service that generates AI writing for corporate teams. Its AI Content Detector tool can scan for generated content. Unfortunately, its accuracy was low. It identified every text block as human-written, even though three of the six tests were written by ChatGPT.\nZeroGPT (Accuracy 100%)\nZeroGPT has matured since I last evaluated it. Then, no company name was listed, and the site was peppered with Google ads and lacked clear monetization. The service worked fairly well but seemed sketchy.\nAlso: Will AI destroy human creativity? No - and here's why\nThat sketchy feeling is gone. ZeroGPT now presents as a typical SaaS service, complete with pricing, company name, and contact information. Its accuracy increased as well: last time it was 80%; this time it scored 5 out of 5.\nIs it human, or is it AI?\nWhat about you? Have you tried AI content detectors like Copyleaks, Monica, or ZeroGPT? How accurate have they been in your experience? Have you used these tools to protect academic or editorial integrity? Have you encountered situations where human-written work was mistakenly flagged as AI? Are there detectors you trust more than others for evaluating originality? Let us know in the comments below.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/how-chatgpt-actually-works-and-why-its-been-so-game-changing/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nHow ChatGPT actually works (and why it's been so game-changing)\nBack in the day (and by \"in the day,\" I mean late 2022, before AI chatbots exploded on the scene), tools like Google and Wolfram Alpha interacted with users via a single-line text entry field and provided text results. Google returned search results -- a list of web pages and articles that would (hopefully) provide information related to the search queries. Wolfram Alpha generally provided answers that were mathematical and data analysis-related.\nChatGPT, by contrast, provides a response based on the context and intent behind a user's question. Google, of course, has changed up its response mode. It now provides AI-based responses before search results, and it's likely to continue to do so. Wolfram Alpha, on the other hand, uses AI behind the scenes to help it with its calculations but does not provide AI-based answers.\nAlso: How to use ChatGPT: A beginner's guide to the most popular AI chatbot\nFundamentally, Google's searching power is its ability to do enormous database lookups and provide a series of matches. Wolfram Alpha's power is its ability to parse data-related questions and perform calculations.\nChatGPT's power (and that of almost any other AI chatbot, like Claude, Copilot, Perplexity, and Google Gemini) is the ability to parse queries and produce fully fleshed-out answers and results based on most of the world's digitally accessible text-based information. Some chatbots have restrictions based on when they stopped scanning information, but most can now access the live Internet to factor current data into their answers.\nIn this article, we'll see how ChatGPT can produce those fully fleshed-out answers using a technology called generative artificial intelligence. We'll start by looking at the main phases of ChatGPT operation, then cover some core AI architecture components that make it all work.\nThe two main phases of ChatGPT operation\nLet's use Google Search (as distinguished from Google Gemini AI) as an analogy again. When you ask Google Search to look up something, you probably know that it doesn't -- at the moment you ask -- go out and scour the entire web for answers. Instead, Google searches its database for pages that match that request. Google search has two main phases: the spidering and data-gathering phase, and the user interaction/lookup phase.\nAlso: The best AI chatbots: ChatGPT and other fun alternatives to try\nRoughly speaking, ChatGPT and the other AI chatbots work the same way. The data-gathering phase is called pre-training, while the user responsiveness phase is known as inference. The magic behind generative AI and the reason it has exploded is that the way pre-training works has proven to be enormously scalable. That scalability has been made possible by recent innovations in affordable hardware technology and cloud computing.\nHow pre-training AI works\nGenerally speaking (because getting into specifics would take volumes), AIs pre-train using two principal approaches: supervised and non-supervised. Most AI projects until the current crop of generative AI systems like ChatGPT used the supervised approach.\nAlso: How to make ChatGPT provide sources and citations\nSupervised pre-training is a process where a model is trained on a labeled dataset, where each input is associated with a corresponding output.\nFor example, an AI could be trained on a dataset of customer service conversations, where the user's questions and complaints are labeled with the appropriate responses from the customer service representative. To train the AI, questions like, \"How can I reset my password?\" would be provided as user input, and answers like, \"You can reset your password by visiting the account settings page on our website and following the prompts,\" would be provided as output.\nIn a supervised training approach, the overall model is trained to learn a mapping function that can map inputs to outputs accurately. This process is often used in supervised learning tasks, such as classification, regression, and sequence labeling.\nAs you might imagine, there are limits to how this can scale. Human trainers would have to go pretty far in anticipating all the inputs and outputs. Training could take a very long time and be limited in subject matter expertise.\nAlso: My two favorite ChatGPT Plus features and the remarkable things I can do with them\nBut as we've come to realize, ChatGPT has very few limits in subject matter expertise. You can ask it to write a resume for the character Chief Miles O'Brien from Star Trek, have it explain quantum physics, write a piece of code, produce a short piece of fiction, and compare the governing styles of former presidents of the United States.\nIt would be impossible to anticipate all the questions that would ever be asked, so there is no way that ChatGPT could have been trained with a supervised model. Instead, ChatGPT uses non-supervised pre-training -- and this is the game-changer.\nNon-supervised pre-training is the process by which a model is trained on data where no specific output is associated with each input. Instead, the model is trained to learn the underlying structure and patterns in the input data without any task in mind. This process is often used in unsupervised learning tasks, such as clustering, anomaly detection, and dimensionality reduction. In language modeling, non-supervised pre-training can train a model to understand the syntax and semantics of natural language so the model can generate coherent and meaningful text in a conversational context.\nAlso: Is ChatGPT Plus really worth $20 when the free version offers so many premium features?\nIt's here where ChatGPT's apparently limitless knowledge becomes possible. Because the developers don't need to know the outputs that come from the inputs, all they have to do is dump more and more information into the ChatGPT pre-training mechanism, which is called transformer-based language modeling.\nAlso: How AI companies are secretly collecting training data from the web (and why it matters)\nIt's also here, in the dumping of data into the AI, that modern chatbot makers have started to find themselves in trouble. AI companies have been training their AIs on copyrighted information from other companies without permission. In fact, some publishers, like Ziff Davis (ZDNET's parent company) and the New York Times, are suing OpenAI for copyright infringement. You've probably seen the disclaimer on ZDNET that says, \"Disclosure: Ziff Davis, ZDNET's parent company, filed an April 2025 lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.\"\nThis universal training approach does make the chatbots more capable. But the side effect is they are taking traffic away from the companies and writers who wrote the original content. Expect this aspect of generative AI to be fought in the courts for years to come.\nBut this article is about technology, so let's move on to a key technology that makes generative AI possible...\nTransformer architecture\nTransformer architecture is a type of neural network that is used for processing natural language data. A neural network simulates how a human brain works by processing information through layers of interconnected nodes. You can think of a neural network like a hockey team. Each player has a role, but they pass the puck back and forth among players with specific positions, all working together to score the goal.\nThe transformer architecture processes sequences of words by using \"self-attention\" to weigh the importance of different words in a sequence when making predictions. Self-attention is similar to how a reader might look back at a previous sentence or paragraph for the context needed to understand a new word in a book. The transformer looks at all the words in a sequence to understand the context and the relationships between them.\nAlso: How I used ChatGPT to quickly fix a critical plugin - without touching a line of code\nThe transformer is made up of several layers, each with multiple sub-layers. The two main sub-layers are the self-attention layer and the feedforward layer. The self-attention layer computes the importance of each word in the sequence, while the feedforward layer applies non-linear transformations to the input data. These layers help the transformer learn and understand the relationships between the words in a sequence.\nDuring training, the transformer is given input data, such as a sentence, and is asked to make a prediction based on that input. The model is updated based on how well its prediction matches the actual output. Through this process, the transformer learns to understand the context and relationships between words in a sequence, making it a powerful tool for natural language processing tasks such as language translation and text generation.\nOne thing to remember is that there are issues around the potential for these models to generate harmful or biased content, as they may learn patterns and biases present in the training data. The companies implementing these models are trying to provide \"guard rails,\" but those guard rails may themselves cause issues. Those concerns are because different people have different perspectives. An attempt to prevent bias based on one school of thought may be claimed as bias by another school of thought. This situation makes the design of a universal chatbot difficult because society is complex.\nAlso: 7 advanced ChatGPT prompt-writing tips you need to know\nLet's discuss the data that gets fed into ChatGPT first, and then the user-interaction phase of ChatGPT and natural language.\nChatGPT's training datasets\nThe dataset used to train ChatGPT is huge. ChatGPT is based on something called a large language model, or LLM. Let's take a moment to clarify chatbot vs. LLM. A chatbot is essentially an app with a user interface. It takes in questions or prompts, feeds those to an LLM, and then retrieves the answers, formats them, and presents them to a user. Essentially, a chatbot is a UI shell. It's the LLM that provides the AI capability itself.\nLLMs come in a wide variety of names and versions. Right now, the main ChatGPT LLM is GPT-4o. When ChatGPT burst onto the scene back in early 2023, the LLM was GPT-3. There are some LLMs, like OpenAI's o3, that spend more time reasoning, while others are better at interacting with human communication styles. Over time, the LLMs get better, and as a result, the chatbots themselves get more capable as well.\nGPT is an acronym that covers three areas: it's generative (G), meaning it generates results; it's pre-trained (P), meaning it's based on all the data it ingests; and it uses the transformer architecture (T), which weighs text inputs to understand context.\nGPT-3 was trained on a dataset called WebText2, a library of over 45 terabytes of text data. When you can buy a 16-terabyte hard drive for under $300, a 45-terabyte corpus may not seem that large. But text takes up a lot less storage space than pictures or video.\nAlso: How to subscribe to ChatGPT Plus (and 7 reasons why you should)\nThis massive amount of data allowed ChatGPT to learn patterns and relationships between words and phrases in natural language at an unprecedented scale, which is one of the reasons why it is so effective at generating coherent and contextually relevant responses to user queries.\nWhile ChatGPT is based on the GPT architecture, it has been fine-tuned on multiple datasets and optimized for conversational use cases. This process allows it to provide a more personalized and engaging experience for users who interact with the technology via a chat interface.\nFor example, OpenAI (developers of ChatGPT) has released a dataset called Persona-Chat that is specifically designed for training conversational AI models like ChatGPT. This dataset consists of over 160,000 dialogues between two human participants, with each participant assigned a unique persona that describes their background, interests, and personality. This process allows ChatGPT to learn how to generate responses that are personalized to the specific context of the conversation.\n- Cornell Movie Dialogs Corpus: A dataset containing conversations between characters in movie scripts. It includes over 200,000 conversational exchanges between more than 10,000 movie character pairs, covering diverse topics and genres.\n- Ubuntu Dialogue Corpus: A collection of multi-turn dialogues between users seeking technical support and the Ubuntu community support team. It contains over one million dialogues, making it one of the largest publicly available datasets for research on dialog systems.\n- DailyDialog: A collection of human-to-human dialogues on multiple topics, ranging from daily life conversations to discussions about social issues. Each dialogue in the dataset consists of several turns and is labeled with a set of emotion, sentiment, and topic information.\nIn addition to these datasets, ChatGPT was trained on lots of unstructured data found on the internet, including websites, books, and other text sources. This allowed ChatGPT to learn about the structure and patterns of language in a more general sense, which could then be fine-tuned for specific applications like dialogue management or sentiment analysis.\nChatGPT is a distinct model trained using a similar approach to the GPT series but with some differences in architecture and training data.\nAlso: The best AI image generators of 2025: Gemini, ChatGPT, Midjourney, and more\nOverall, the training data used to fine-tune ChatGPT is typically conversational and specifically curated to include dialogues between humans, allowing ChatGPT to learn how to generate natural and engaging responses in a conversational format.\nHere's how to think of ChatGPT's unsupervised training: it was fed a lot of data and left to its own devices to find patterns and make sense of it all. This mechanism allowed the new generative AI systems to scale up so quickly.\nWhile the pre-training process does the heavy lifting for ChatGPT's generative AI, the technology also has to understand questions and construct answers from data. That part is done by the inference phase, which consists of natural language processing and dialogue management.\nWhat about human involvement in pre-training?\nDespite the inherent scalability of non-supervised pre-training, there is some evidence that human assistance may have been involved in the preparation of ChatGPT for public use.\nThe big reveal was in an article in TIME Magazine that discussed human \"data labelers\" earning between $1.32 and $2/hour in Kenya. According to the TIME report, it was the responsibility of these workers to scan horrifying and sexually explicit internet content to flag it for ChatGPT training.\nAlso: Your next job? Managing a fleet of AI agents\nAnother article, posted in Martechpost, an AI newsletter, states that the large language model was trained using a process called Reinforcement Learning from Human Feedback (RLHF): \"The training process involved a fine-tuned initial model using supervised learning, with human trainers playing both the role of the user and an AI assistant.\"\nThere are some subtleties around what the word \"training\" means. According to ChatGPT itself, \"OpenAI did not use reinforcement learning with human feedback to train me. Instead, I was pre-trained using a combination of unsupervised and supervised learning techniques, such as language modeling, auto-encoding, and sequence prediction. My training involved processing massive amounts of text data from the internet, which allowed me to learn patterns and relationships between words and phrases.\"\nThe AI continued, \"However, once I was pre-trained, researchers and developers can use reinforcement learning with human feedback to fine-tune me for specific tasks or domains, such as answering questions or generating text. In these cases, humans can provide feedback in the form of rewards or penalties, which can be used to update my parameters and improve my performance on similar tasks in the future.\"\nAlso: How I used ChatGPT and AI art tools to launch my Etsy business fast\nThis answer seems to fit with the Marktechpost and TIME reports, in that the initial pre-training was non-supervised, allowing a tremendous amount of data to be fed into the system. But in building the dialogue responses that communicate with users (more on that below), the response engines were apparently trained both on the types of responses and to filter out inappropriate material\u2014and that training seems to have been human-assisted.\nNatural language processing\nNatural language processing (NLP) focuses on enabling computers to understand, interpret, and generate human language. With the exponential growth of digital data and the increasing use of natural language interfaces, NLP has become a crucial technology for many businesses.\nNLP technologies can be used for many applications, including sentiment analysis, chatbots, speech recognition, and translation. By leveraging NLP, businesses can automate tasks, improve customer service, and gain valuable insights from customer feedback and social media posts.\nAlso: How to write better ChatGPT prompts\nOne of the key challenges in implementing NLP is dealing with the complexity and ambiguity of human language. NLP algorithms need to be trained on large amounts of data to recognize patterns and learn the nuances of language. They also need to be continually refined and updated to keep up with changes in language use and context.\nThe technology works by breaking down language inputs, such as sentences or paragraphs, into smaller components and analyzing their meanings and relationships to generate insights or responses. NLP technologies use multiple techniques, including statistical modeling, machine learning, and deep learning, to recognize patterns and learn from large amounts of data to accurately interpret and generate language.\nDialogue management\nYou may have noticed that ChatGPT can ask follow-up questions to clarify your intent or better understand your needs, and provide personalized responses that consider the entire conversation history.\nThis approach is how ChatGPT can have multi-turn conversations with users that feel natural and engaging. The process involves using algorithms and machine learning techniques to understand the context of a conversation and maintain it over multiple exchanges with the user.\nAlso: How to use ChatGPT to write code - and my top trick for debugging what it generates\nDialogue management is an important aspect of natural language processing because it allows computer programs to interact with people in a way that feels more like a conversation than a series of one-off interactions. This approach can help build trust and engagement with users and lead to better outcomes for both the user and the organization using the program.\nMarketers, of course, want to expand how trust is built up, but this is also an area that could prove scary because it's one way an AI might be able to manipulate the people who use it.\nA look inside the hardware that runs ChatGPT\nMicrosoft released a video that discusses how Azure is used to create a network to run all the computation and storage required by ChatGPT. It's a fascinating watch for its discussion of Azure and how AI is architected in real hardware.\nFAQ\nHow does ChatGPT's generative AI differ from traditional chatbots?\nTraditional chatbots operate on predefined rules and decision trees, responding to specific user inputs with predetermined answers. ChatGPT, on the other hand, utilizes generative AI, allowing it to produce unique responses by understanding context and intent, making interactions more dynamic and human-like.\nWhy is non-supervised pre-training considered a game-changer for AI models like ChatGPT?\nNon-supervised pre-training allows AI models to learn from vast amounts of unlabeled data. This approach helps the model grasp the nuances of language without being restricted to specific tasks, enabling it to generate more diverse and contextually relevant responses.\nAre there any limitations to ChatGPT's ability to understand and respond to user queries?\nYes. ChatGPT relies on the data it was trained on, which means it might not always have information on recent topics or niche subjects. Additionally, its responses are generated based on patterns in the data, so it might occasionally produce factually incorrect answers or lack context. Plus, the data it's trained on may be wrong or even weaponized to be outright misleading.\nAnd now you know\nEven though we're over 3,200 words, this is still a rudimentary overview of all that happens inside ChatGPT. That said, perhaps now you understand more about why this technology has exploded over the past few years. The key to success is that the data itself isn't \"supervised\" and the AI can take what it's been fed and make sense of it.\nAlso: 6 new ways ChatGPT Projects supercharges your AI chats - how to try it\nWhat do you think? Are you using ChatGPT? What questions do you still have about how it works? Share your opinions with us in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV.\nWant more stories about AI? Sign up for Innovation, our weekly newsletter."
    },
    {
      "url": "https://www.zdnet.com/article/ai-agents-arrive-in-us-classrooms/",
      "text": "AI agents arrive in US classrooms\nAI for education is a new but rapidly expanding field. Can it support student outcomes and help teachers avoid burnout?\nOn Wednesday, AI education company Kira launched a \"fully AI-native learning platform\" for K-12 education, complete with agents to assist teachers with repetitive tasks. The platform hosts assignments, analyzes progress data, offers administrative assistance, helps build lesson plans and quizzes, and more.\nAlso: Google's One AI Premium plan with Gemini Advanced is now free for students - for an entire year\n\"Unlike traditional tools that merely layer AI onto existing platforms, Kira integrates artificial intelligence directly into every educational workflow -- from lesson planning and instruction to grading, intervention, and reporting,\" the release explains. \"This enables schools to improve student outcomes, streamline operations, and provide personalized support at scale.\"\nFreeing up time for teachers\nAs with most current applications of AI, and specifically agents, Kira's aim is to free up time for teachers to be present with students, especially those who need personalized support. The company says the new platform allows educators to create lesson plans \"instantly\" without sacrificing individualized feedback for students, and even grades assignments automatically with features like AI Grader and a plagiarism checker.\nAlso: Where AI educators are replacing teachers - and how that'll work\nBut what downsides does something like AI Grader pose? Kira was originally developed for computer science education, which is more quantitative -- and therefore straightforward to grade -- than amorphous subjects like the humanities. What if it overlooks nuances in a written assignment? However thorough the platform's analysis may be, it's hard not to consider what may be lost in having a teacher review assignments through the eyes of an AI agent.\n\"We've built Kira's grading tools with exactly these concerns in mind,\" says Kira CEO Andrea Pasinetti. \"First and foremost, grades and feedback generated by our AI are never released directly to students. Teachers always review and approve the AI's suggested grades and comments before anything is shared.\"\nKira offers multiple grading formats, including rubric-based scoring that uses criteria designed either by the teacher or Kira's AI, standard point or letter grades, and narrative feedback.\n\"For more open-ended assignments, like those in the humanities, we model our AI-generated feedback on high-quality teacher responses to similar work,\" Pasinetti says. \"We also regularly gather expert teacher reviews to ensure continued calibration and quality.\"\n\"Ultimately, we see the AI grader as a decision support tool. It streamlines repetitive work, but teachers remain firmly in control - reviewing, editing, and personalizing feedback before students see anything,\" he adds.\nBut what about beyond the day-to-day? In the macro-projection of this kind of tech, could the valuable nuances of individual teachers' styles vanish as AI platforms homogenize lesson plans and assignments? Pasinetti says Kira AI has considered that possibility.\n\"Kira's AI doesn't produce content in a vacuum -- teachers shape the output at every stage by providing inputs like learning goals, student context, instructional preferences, and more,\" he notes. \"They can modify structure, tone, scaffolding, and examples, so the final product reflects their voice and teaching style.\"\nPasinetti adds that Kira's goal is to find the happy medium between personalization and scalability. \"The AI handles the repetitive, time-consuming parts, but the substance comes from the teacher,\" he says.\nHelping struggling students\nKira says its AI can also help detect when students are struggling and make recommendations to teachers for how to support them early on. The platform can ingest instructional data like text, audio, video, and images, evaluating projects and classroom discussions to assess a student's needs.\nAlso: The tasks college students are using Claude AI for most, according to Anthropic\n\"Kira's agents deliver insights in seconds, empowering teachers to make faster, smarter instructional decisions,\" the release says. It also aggregates data on student progress for administrators monitoring performance at a district level.\nAI is adept at personalization, a burgeoning field in education technology that can help address students' specific needs without pulling teachers away from the class at large.\nAlso: The tasks college students are using Claude AI for most, according to Anthropic\n\"Personalized learning doesn't mean uncontrolled or entirely self-directed pacing; rather, Kira delivers concepts and content in ways that uniquely resonate with each learner while ensuring the overall pacing, benchmarks, and coursework structure remain firmly within the teacher's control,\" Pasinetti told ZDNET. \"This approach allows the entire class to move forward cohesively, even as each student receives personalized guidance tailored to their individual needs.\"\nImplemented in Tennessee schools\nKira -- which is backed by computer scientist Andrew Ng, who is also the founder and CEO of DeepLearning AI -- was originally developed specifically for computer science and AI literacy but has now expanded into all subject areas, including the humanities.\nIt's currently being implemented in schools across Tennessee through a partnership with the Tennessee STEM Innovation Network, though that appears to be specific to computer science courses for middle and high school students.\nRather than train its own AI models, the company opted for commercial ones. \"We've found that using agentic workflows yields much stronger and more consistent results than fine-tuning open-source or smaller models, especially for our educational use cases,\" Pasinetti explained. He added that Kira maintains privacy by anonymizing data.\nAlso: Anthropic launches Claude for Education, an AI to help students think critically\nBut how do teachers feel about the technology?\n\"It's intuitive, saves me countless hours, and significantly enhances student learning outcomes,\" Lance Key, a Future Ready VITAL Support Specialist in Putnam County, Tennessee, said in the release. Educators are notoriously overworked and underpaid, especially amidst rising disagreements with parents over curriculum.\nPasinetti says teachers have even approached Kira with ideas for new features and tools. \"We believe this stems from the fundamentally generative nature of AI tools, which empowers teachers as creators,\" he says.\nAlso: ChatGPT Plus is free for students now - how to grab this deal before finals\nZDNET was not able to interview educators using Kira directly before publishing this story but will follow up as more schools adopt the technology.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nIt's only been almost three years since generative artificial intelligence (AI) hit the mainstream as a new paradigm of productivity, but here we are -- it's everywhere.\nI test AI tools as part of my work. I'll dig into just about any AI-related technology and see what I can make it do. Many of you have read my ongoing shootouts comparing AIs for programming and AI content checkers, among other kinds of tools.\nBut that's using AI in a rigorous lab environment to provide test results to ZDNET readers. Like many of you, I've also started using AI to augment my workflow and increase my productivity.\nAlso: The best AI for coding in 2025 (and what not to use)\nI wear a lot of hats; I run a small business with my wife, who also has her own business, where I'm the tech guy and designer. I also work with a number of industry groups. I have a fairly popular security software product for WordPress users. And I'm constantly working on projects, ranging from 3D printing the ultimate charging tower, to trying to make an AI-assisted Etsy store, to composing and publishing music, and using an AI for help with some of the marketing activities.\nI should note that I never, ever use AI to produce my core content. No article, song, or social media post is ever written using an AI tool. My work product is mine. But I do use AI to help me get through other aspects of my workload.\nI have a particular interest in how AI helps programming, how AI can support graphics work, and how AI can support video production.\nHere are the tools I'm willing to pay for -- and why.\n1. ChatGPT Plus - $20/mo\nSpeaking of AI and programming, it has essentially doubled my programming output. I use AI to help me with common-knowledge programming. I talked about it in-depth in my 25 tips article, but the core benefit is getting ChatGPT to write code for published APIs, so I don't have to spend time searching for code examples and trying to reverse-engineer comments on various programming boards.\nAnd yes, I mentioned ChatGPT. While more chatbots capable of passing my programming tests have been introduced in the last year, ChatGPT does the job well enough, and hey, who wants another monthly fee?\nAlso: How ChatGPT actually works (and why it's been so game-changing)\nIn fact, that's a big part of why I'm paying $20/mo for ChatGPT Plus. Sure, I've signed up and paid for some of the other AIs just to test them, but ChatGPT Plus is the only chatbot I have found so consistently useful that I keep it as a regularly used tool.\nI use ChatGPT for lots of research tasks, sometimes throwing math problems at it, and all sorts of other questions and problems I'm dealing with. While I never take its output as an unimpeachable source of truth, I do find ChatGPT to be a very useful sounding board, substantially more so than a quick Google search.\nNow, to be fair, I did outline five ways that an AI could help me in Gmail. If Gemini could do these things reliably, I'd sign back up in a heartbeat. But I just don't need the current email message I'm reading summarized, and I sure don't need it to write a friendlier or more professional version of whatever I've currently written. I tried Gmail's new AI unsubscribe feature, and it only found about 10 newsletters, yet I get thousands of emails and hundreds of newsletter-style messages every day. So, I'm leaving that one unbought.\n2. Midjourney - $10/mo\nI played around a lot with DALL-E, ChatGPT's earlier image generation tool. But recently, OpenAI introduced a new image generator in GPT-4o, and it's quite the beast. I have found that it generates great results, but it has more guardrails than another tool I pay for, Midjourney.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nBut even though I get image generation with my $20/mo ChatGPT Plus fee, I pay an extra $10/mo for Midjourney. Why?\nOne of the reasons is subjective. I like a lot of the images I get with Midjourney. Midjourney also allows me to describe artist styles, and lets me riff off a vast array of stylistic choices. ChatGPT, perhaps because of guardrails imposed by OpenAI, doesn't present as many choices.\nBut I also have two specific and objective reasons for paying for Midjourney. First, because image generation is so subjective, it's nice to have a variety of tools when seeking a representation of what you have in your head. I'll try different prompts and even the same prompts with both tools and take what works best.\nAlso: How to selectively modify a Midjourney image to create an artistic statement\nSecond, every month I generate a promotional image for my wife's online business. She has an e-commerce site that supports a popular hobby. Each month, on her very active Facebook group, she gives a craft-along theme to her users. I generate an image for that theme. Over the months, I've found that Midjourney does a far better job of generating an image that incorporates elements of the hobby. That said, some months I bounce back and forth between both tools until I can get an image that meets her business's needs.\nBecause Midjourney shaves what used to be two to three hours of work pushing pixels in Photoshop to generate those images down to about 10 minutes, it's worth the $10/month to me just for that project.\nPhotoshop Generative Fill - Honorable mention\nIn the title of this article, I said I pay for two AI tools. That's sort of true. I pay for Adobe's Creative Cloud suite in addition to ChatGPT Plus and Midjourney. But since I've been using and paying for Creative Cloud -- and before that, Photoshop -- long before there was generative fill, I'm not counting it in my AI tools list.\nAlso: I use Photoshop's AI tool every day - here are my 5 essential tips for the best results\nIf Adobe removed generative fill tomorrow, I'd still pay for Photoshop. To be clear, I don't like paying for it. It's costly, and the two-computer license limitation is restrictive. But a few years back, I tried switching to Affinity Photo, which at the time was $50 (it's now $70). That one-time fee is roughly what I pay each month for Creative Cloud, so it had a lot of potential.\nTo be clear, Affinity Photo is a fine application. But I've been using Photoshop since before the Clinton administration. To say I have Photoshop muscle memory is an understatement. It's a product I use almost every day. Switching to another application, while I could do it if I had to, slows down my workflow considerably.\nAlso: What to do if Generative Fill is grayed out in Adobe Photoshop AI\nSo, I don't consider my monthly expense for Creative Cloud to be an AI expense. That said, I find generative fill (and its various other AI tricks) very helpful. I often use it in concert with Midjourney and ChatGPT image generation.\nThree tools I'm thinking about\nI run a business online and, as such, rely on a wide variety of cloud services. Those fees add up, and now they're all going up in price. So while it might be nice to add more AI tools, I'm keeping it under control. It's very easy to just click OK and find yourself spending hundreds of dollars more every month.\nThat said, I am thinking about adding three more tools. I'm a bit hesitant, because each one has its annoyances and limitations, but they're on the short list for a quick order if I can ever justify an immediate performance improvement on one project or another.\nNotion AI\nThe first is Notion AI. I am deeply invested in Notion for all my project work. I also use it to write and organize all my articles, as well as schedule them, plan them, research them, and capture notes and assets. Notion AI is interesting because it would work like NotebookLM, limiting its knowledge base to my Notion account. That could be very useful as I work on more projects. But at one point, when Notion overcharged my wife's account, they were completely unsupportive and unsympathetic. So, I hesitate to give them more business.\nNotebookLM Pro\nGoogle's NotebookLM Pro is another contender. Now that Pocket, the article archiving service, is being discontinued, I considered using NotebookLM Pro as a replacement. The idea that I could save articles in NotebookLM as sources and then have the AI review them, summarize them, and analyze them seemed ideal, especially as a research tool.\nBut... the free version of NotebookLM only allows 50 sources per notebook. The Pro version, which is normally another $20/mo ( you can usually get a few starter months at a discounted rate), increases that limit, but only to 300 sources per notebook. My archive has well over 30,000 sources, which is beyond NotebookLM's limits. There is a $249/month plan (yowzah!), but all Google will say about limits is \"Highest limits and best model capabilities (later this year)\". What does that even mean?\nDescript\nDescript (for $16-$24/mo) is an AI video editing tool. This isn't a tool that does text-to-video generation. Instead, it's a tool that helps you take your video clips and edit them. Right now, I'm a very big Final Cut Pro user. Final Cut has added some AI features, but it lags far behind DaVinci Pro and Premiere Pro (because Apple lagging in AI is no surprise, right?).\nAlso: How to use ChatGPT to write code - and my top trick for debugging what it generates\nDescript automatically removes filler words and retakes, cleans up sound quality without any fuss, and does automatic multicam editing. It also promises to take long-form videos and automatically create clip videos, which could be a huge time-saver. The product also has some more \"out there\" features which I wouldn't use, including fake avatar generation and fake speech generation.\nThe thing is, Descript is aimed more at multiple talking head videos. I'm not sure it could handle the sort of in-depth technical hands-on project videos I do. So, it's still in the \"maybe someday\" category, for now at least.\nWhat do you use?\nDo you pay for any AI tools? Which ones, and why? Is there an AI tool that you strongly recommend I should be using that I didn't mention? Feel free to answer these questions and let us know your thoughts on AI subscriptions in the comments below.\nWant more stories about AI? Sign up for Innovation, our weekly newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/how-ai-enabled-autonomous-business-will-change-the-way-you-work-forever/",
      "text": "How AI-enabled autonomous business will change the way you work forever\nZDNET's key takeaways\n- Self-learning and self-improving technology will transform enterprise activities.\n- From augmented leadership to machines as customers, analyst Gartner identifies key trends.\n- While true autonomous business is a long way off, smart business leaders are preparing now.\nThe future of your business is autonomous. While there's a lot of debate right now about the augmentation or replacement of workers with artificial intelligence, the organization of the future will build on emerging technology to create new ways of working and operating.\nThat's according to Gabriela Vogel, vice president analyst in the Executive Leadership of Digital Business practice at research firm Gartner: \"We say the future of digital is autonomous business, and AI is the tool that's leading this business change.\"\nAlso: Autonomous businesses will be powered by AI agents\nWhile the hype around AI in the past few years has centered on the impact of generative AI, the autonomous business of the future takes digital transformation to a higher level, where new combinations of technology and data deliver new business models.\n\"AI is a tool; it's not the business change itself,\" said Vogel. \"Autonomous business is when you have a strategy that uses self-learning and self-improving technology to optimize value creation and delivery.\"\nHumans hold a significant role in traditional business models. Yet Vogel told ZDNET that agentic AI changes everything, as agents discover, negotiate, and transact autonomously.\n\"So, first we had analog, then we had e-commerce, and then we went to digital -- and now the new phase is autonomous business, which has four main components: autonomous operations, augmented leadership, auto-adaptable products, and machines as customers. All this change is set in a programmable economy.\"\n1. Autonomous operations\nVogel said the digitalization of operations uses technologies, such as Internet of Things-enabled sensors, to automate elements of business operations.\n\"These sensors tell you, 'Look, you need this number of lubricants, your levels are going down, and you need to reorder.'\"\nAlso: How AI agents can generate $450 billion by 2028 - and what stands in the way\nAutonomous operations go further, removing the human from the loop for independent decisions. Vogel gave two examples.\n\"John Deere has a robot with a 360-degree camera, and it calculates where fertilizer is needed, and applies it with super precision,\" she said. \"And Ford has created a patent for a self-driving car that will return to the showroom if the client misses payments.\"\n2. Augmented leadership\nExecutives in the digital phase of leadership use cloud-based platforms to view insights into business performance.\nVogel referred to HR professionals who use Workday technology to see employee-related information.\nAlso: 5 ways to successfully integrate AI agents into your workplace\nAugmented leadership provides a new level of analysis, with proactive suggestions.\n\"Legal technology providers are using solutions to autonomously find contract vulnerabilities and suggest what the leadership team should do,\" she said. \"This technology increases leadership capabilities, where you can speed up your time. You can focus on other things that are more critical to the business.\"\n3. Auto-adaptable products\nHere, Vogel said the digital phase of products includes insurance companies providing apps for clients to check potential coverage.\nAt the autonomous stage, auto-adaptable products use emerging technologies to automate changes.\nAlso: A million customer conversations with AI agents yielded this surprising lesson\nVogel referred to Next Insurance, an organization that uses AI and machine learning to simplify the purchasing process.\n\"This company has products for small to medium-sized enterprises, and it uses APIs and agentic AI tools to adjust the policy according to market changes and business risks,\" she said.\n\"This type of approach eliminates the need for manual renewal processes. So, the technology works autonomously and says to the client business, 'Look, here's your contract and these are the adjustments that have been made for you.'\"\n4. Machines as customers\nVogel said a good example of machines acting as customers is HP Instant Ink, an internet-enabled service that automatically delivers ink when users are running low.\nShe said retail giant Walmart is deploying AI-enabled machines to negotiate with suppliers for products not sold to consumers, such as retail equipment or shopping carts.\nAlso: AI's biggest impact on your workforce is still to come - 3 ways to avoid getting left behind\nVogel suggested that agent-to-agent sales interactions will become more common.\n\"We're starting to see this relationship between seller bots and customer bots,\" she said. \"Another example is Tesla vehicles. These cars can diagnose issues themselves and then preorder parts that are required.\"\nWhat is the programmable economy?\nVogel said the shift to autonomous business is set within a programmable economy, which Gartner defines as a smart economic system that supports or manages the production and consumption of goods and services.\n\"Everything I've talked about so far is all embedded around a programmable economy,\" she said. \"You get the full autonomous business when you have all these elements.\"\nAlso: 5 ways to be a great AI agent manager, according to business leaders\nWhile an example of a digital economy might include mobile payments to use bicycles in urban areas, Vogel said a good example of the shift to a programmable economy is a pilot by Daimler Trucks that allows trucks to communicate autonomously with other machines and carry out legally binding transactions, such as payments.\n\"These trucks have their own identity and legal standing, and they will exchange value services, such as electric vehicle charging, and say, 'Well, we need charging. I'll pay you in advance,\" she said. \"So, in this example, machines pay other machines. It's a cool example that's still in prototype. But most definitely, companies will start operating in the programmable economy soon.\"\nWhen will autonomous business become a reality?\nThe key point, said Vogel, is that the autonomous business is unlikely to manifest tomorrow.\n\"It will be a big thing in about 2045, that's where we're projecting,\" she said. \"So, yeah, it's going to take a while.\"\nHowever, the early shoots of growth can already be seen. Vogel said more than three-quarters (77%) of CEOs believe AI will impact their industries significantly over the next three years.\nAlso: 5 tips for building foundation models for AI\nAs she suggested earlier, AI will play a key enabling role in the establishment of autonomous business, and Gartner research suggests many organizations aren't prepared for this shift.\n\"When you ask CEOs, 'Is your operating model ready for this new world of AI?', only 29% say they are ready. So, there's just a lot of work to be done.\"\nWhy should I worry about autonomous business now?\nLet's be honest: Twenty years is a long time -- and a lifetime in the fast-moving world of enterprise technology.\nYet Vogel said there's no room for complacency. Business and digital leaders who want to stay ahead must start preparing for autonomous business.\nAlso: 4 questions to ask yourself before betting on AI in your business - and why\n\"Some companies are working on it now, and we know that, as these systems start making autonomous decisions, these organizations will have a competitive advantage,\" she said.\nVogel said some industries will move faster than others. Even if your organization is in a slower-moving sector, you should consider your options now.\nAlso: How AI amplifies these other tech trends that matter most to business in 2025\n\"Autonomous business is like an S-curve. It'll start ramping up until, in 20 years, it becomes the thing everyone talks about,\" she said.\n\"Start preparing foundational technology, so that you can then make the right movements to wherever it is you want to create a more autonomous workforce.\"\nWant more stories about AI? Sign up for Innovation, our weekly newsletter."
    },
    {
      "url": "https://www.pewresearch.org/short-reads/2024/05/15/a-quarter-of-u-s-teachers-say-ai-tools-do-more-harm-than-good-in-k-12-education/",
      "text": "As some teachers start to use artificial intelligence (AI) tools in their work, a majority are uncertain about or see downsides to the general use of AI tools in K-12 education, according to a Pew Research Center survey conducted in fall 2023.\nA quarter of public K-12 teachers say using AI tools in K-12 education does more harm than good. About a third (32%) say there is about an equal mix of benefit and harm, while only 6% say it does more good than harm. Another 35% say they aren\u2019t sure.\nPew Research Center conducted this analysis to better understand public K-12 teachers\u2019 views on the use of artificial intelligence tools in K-12 education. To do this, we surveyed 2,531 U.S. public K-12 teachers from Oct. 17 to Nov. 14, 2023. The teachers are members of RAND\u2019s American Teacher Panel, a nationally representative panel of public school K-12 teachers recruited through MDR Education. Survey data is weighted to state and national teacher characteristics to ensure they are representative of the target population.\nWe also used data from a separate survey of 1,453 U.S. teens conducted from Sept. 26 to Oct. 23, 2023. Ipsos recruited the teens via their parents, who were part of its KnowledgePanel. The survey was weighted to be representative of U.S. teens ages 13 to 17 who live with their parents by age, gender, race and ethnicity, household income, and other categories.\nThe survey on teens was reviewed and approved by an external institutional review board (IRB), Advarra, an independent committee of experts specializing in helping to protect the rights of research participants. Find more details about the survey of teens here.\nHere are the questions we asked teachers and teens, along with responses, and the methodology for the survey of teachers and for the survey of teens.\nHow teachers\u2019 views differ by school level\nHigh school teachers are more likely than elementary and middle school teachers to hold negative views about AI tools in education.\nAbout a third of high school teachers (35%) say these tools do more harm than good. Roughly a quarter of middle school teachers (24%) and 19% of elementary school teachers say the same.\nFewer than one-in-ten teachers at all levels say these tools do more good than harm.\nSome 47% of elementary school teachers say they aren\u2019t sure about the impact of AI tools in K-12 education. That is much larger than the shares of middle and high school teachers who say this.\nTeens\u2019 experiences with and views of ChatGPT\nIn a separate survey, we asked U.S. teens about their experience with and views of ChatGPT, a generative AI tool, in their schoolwork.\nAmong teens who have heard of ChatGPT, 19% say they have used it to help them with schoolwork. This is more common among teens in higher grades. About a quarter of 11th and 12th graders who have heard of ChatGPT (24%) say they have used it in their schoolwork, compared with 17% of 9th and 10th graders and 12% of 7th and 8th graders.\nTeens\u2019 views on whether using ChatGPT is acceptable depend on what it\u2019s being used for. Among teens who have heard of ChatGPT:\n- 69% say it\u2019s acceptable to use it to research new topics.\n- 39% say it\u2019s acceptable to use it to solve math problems.\n- 20% say it\u2019s acceptable to use it to write essays.\nShares ranging from 18% to 24% aren\u2019t sure whether it is acceptable to use ChatGPT in each of these situations.\nOverall, two-thirds of U.S. teens say they have heard of ChatGPT. That includes 23% who have heard a lot about it and 44% who have heard a little about it. Roughly a third (32%) say they have heard nothing at all about ChatGPT.\nNote: Here are the questions we asked teachers and teens, along with responses, and the methodology for the survey of teachers and for the survey of teens."
    },
    {
      "url": "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
      "text": "Coding with AI? My top 5 tips for vetting its output - and staying out of trouble\nOur story begins, as many stories do, with a man and his AI. The man, like many men, is a bit of a geek and a bit of a programmer. He also needs a haircut.\nThe AI is the culmination of thousands of years of human advancement, all put to the service of making the man's life a little easier. The man, of course, is me. I'm that guy.\nAlso: The best AI for coding in 2025 (and what not to use)\nUnfortunately, while AI can be incredibly brilliant, it also has a propensity to lie, mislead, and make shockingly stupid mistakes. It is the stupid part that we will be discussing in this article.\nAnecdotal evidence does have value. My reports on how I've solved some problems quickly with AI are real. The programs I used AI to write with are still in use. I have used AI to help speed up aspects of my programming flow, especially when I focus on the sweet spots where I'm less productive and the AI is quite knowledgeable, like writing functions that call publicly published APIs.\nAlso: I'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nYou know how we got here. Generative AI burst onto the scene at the cusp of 2023 and has been blasting its way into knowledge work ever since.\nOne area, as the narrative goes, where AI truly shines is its ability to write code and help manage IT systems. Those claims are not untrue. I have shown, several times, how AI has solved coding and systems engineering problems I have personally experienced.\nAI coding in the real world: What science reveals\nNew tools always come with big promises. But do they deliver in real-world settings?\nMost of my reporting on programming effectiveness has been based on personal anecdotal evidence: my own programming experiences using AI. But I'm one guy. I have limited time to devote to programming and, like every programmer, I have certain areas where I spend most of my coding time.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nRecently, though, a nonprofit research organization called METR (Model Evaluation & Threat Research) did a more thorough analysis of AI coding productivity.\nTheir methodology seems sound. They worked with 16 experienced open-source developers who have actively contributed to large, popular repositories. The METR analysts provided those developers with 246 issues from the repositories that needed fixing. The coders were given about half the issues where they had to work on their own, and about half where they could use an AI for help.\nThe results were striking and unexpected. While the developers themselves estimated that AI assistance increased their productivity by an average of 24%, METR's analytics showed instead that AI assistance slowed them down by an average of 19%.\nThat's a bit of a head-scratcher. METR put together a list of factors that might explain the slowdown, including over-optimism about AI usefulness, high-developer familiarity with their repositories (and less AI knowledge), the complexity of large repositories, lack of AI reliability, and an ongoing problem where the AI refuses to use \"important tacit knowledge or context.\"\nAlso: How AI coding agents could destroy open-source software\nI would suggest that two other factors might have limited effectiveness:\nChoice of problem: The developers were told which issues they had to use AI help on and which issues they couldn't. My experience suggests knowledgeable developers must choose where to use AI based on the problem that needs to be solved. In my case, for example, getting the AI to write a regular expression (something I don't like doing and I'm fairly crappy at) would save me a lot more time than getting the AI to modify unique code I've already written, work on regularly, and know inside and out.\nChoice of AI: According to the report, the developers used Cursor, an AI-centric fork of VS Code, which used Claude 3.5/3.7 Sonnet at the time. When I tested 3.5 Sonnet, the results were terrible, with Sonnet failing three out of four of my tests. Subsequently, my tests of Claude 4 Sonnet were considerably better. METR reported that developers rejected more than 65% of the code the AI generated. That's going to take time.\nThat time when ChatGPT suggested nuking my system\nMETRs results are interesting. AI is clearly a double-edged sword when it comes to coding help. But there's also no doubt that AI can provide considerable value to coders. If anything, I think this test once again proves the contention that AI is a great tool for experienced programmers, but a potential high-risk resource for newbies.\nAlso: Why I'm switching to VS Code. Hint: It's all about AI tool integration\nLet's look at a concrete example, one that could have cost me a lot of time and trouble if I followed ChatGPT's advice.\nI was setting up a Docker container on my home lab using Portainer (a tool that helps manage Docker containers). For some reason, Portainer would not enable the Deploy button to create the container.\nIt had been a long day, so I didn't see the obvious problem. Instead, I asked ChatGPT. I fed ChatGPT screenshots of the configuration, as well as my Docker configuration file.\nChatGPT recommended that I uninstall and reinstall Portainer. It also suggested I remove Docker from the Linux distro and use the package manager to reinstall it. These actions would have had the effect of killing all my containers.\nOf note, ChatGPT didn't recommend or ask if I had backups of the containers. It just gave me the command line sequences it recommended I cut and paste to delete and rebuild Portainer and Docker. It was a wildly destructive and irresponsible recommendation.\nThe irony is that ChatGPT never figured out why Portainer wouldn't let me deploy the new container, but I did. It turns out I never filled out the container's name field. That's it.\nAlso: What is AI vibe coding? It's all the rage but it's not for everyone - here's why\nBecause I'm fairly experienced, I hesitated when ChatGPT told me to nuke my installation. However, someone relying on the AI for advice could have potentially brought down an entire server for want of typing in a container name.\nOverconfident and underinformed AIs: A dangerous combo\nI've also experienced the AI going completely off the rails. I've experienced it giving advice that was not only completely useless, but also presented with the apparent confidence of an expert.\nAlso: Google's Jules AI coding agent built a new feature I could actually ship - while I made coffee\nIf you're going to use AI tools to support your development or IT work, these tips might keep you out of trouble:\n- If there's not much publicly available information, the AI can't help. But the AI will make stuff up based on what little it knows, without admitting that it is lacking experience.\n- Like my dog, once the AI gets fixated on one thing, it often refuses to look at alternatives. If the AI is stuck on one approach, don't make the mistake of believing that its polite recommendations about a new approach are real. It's still going down the same rabbit hole. Start a new session.\n- If you don't know a lot, don't rely on the AI. Keep up your learning. Experienced devs can tell the difference between what will work and what won't. But if you're trying to put all the coding on the back of the AI, you won't know when or where it goes wrong or how to fix it.\n- Coders often use specific tools for specific tasks. A website might be built using Python, CSS, HTML, JavaScript, Flask, and Jinja. You choose each tool because you know what it does well. Choose your AI tools the same way. For example, I don't use AI for business logic, but I gain productivity using AI to write API calls and public knowledge, where it can save me a lot of time.\n- Test everything an AI produces. Everything. Line by individual line. The AI can save a ton of time, but it can also make enormous mistakes. Yes, taking the time and energy to test by hand can help prevent errors. If the AI offers to write unit tests, let it. But test the tests.\nBased on your experience level, here's how I recommend you think about AI assistance:\n- If you know nothing about a subject or skill: AI can help you pass as if you do, but it could be amazingly wrong, and you might not know.\n- If you're an expert in a subject or skill: AI can help, but it will piss you off. Your expertise gets used not only to separate the AI-stupid from the AI-useful, but to carefully craft a path where AI can actually help.\n- If you're in between: AI is a mixed bag. It could help you or get you in trouble. Don't delegate your skill-building to the AI because it could leave you behind.\nAlso: How I used ChatGPT to analyze, debug, and rewrite a broken plugin from scratch - in an hour\nGenerative AI can be an excellent helper for experienced developers and IT pros, especially when used for targeted, well-understood tasks. But its confidence can be deceptive and dangerous.\nAI can be useful, but always double-check its work.\nHave you used AI tools like ChatGPT or Claude to help with your development or IT work? Did they speed things up, or nearly blow things up? Are you more confident or more cautious when using AI on critical systems? Have you found specific use cases where AI really shines, or where it fails hilariously? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/i-used-chatgpts-study-mode-to-tutor-me-for-free-and-you-can-too/",
      "text": "I used ChatGPT's Study Mode to tutor me for free - and you can too\nZDNET's Key Takeaways\n- ChatGPT study mode is meant to help students actively learn.\n- I tried study mode and it has key differences from standard ChatGPT.\n- It's available to logged-in ChatGPT Free, Plus, Pro, and Team users.\nWhen generative AI arrived in late 2022, educators were immediately concerned about students using chatbots to do their work for them. While the initial reaction was banning the technology from classrooms, many educators and students have since found positive implementations\nHowever, there are ways to use tools like ChatGPT to enhance learning if students choose. To this end, OpenAI has launched a new Study Mode, a learning experience that helps students work toward the solution to a problem instead of just receiving the answer.\nAlso: This one feature could make GPT-5 a true game changer (if OpenAI gets it right)\nIt's already available to logged-in ChatGPT Free, Plus, Pro, and Team users. If you want to know how to access Study Mode, and my tests suggest it's worth the effort, keep reading.\nHow to use Study Mode\nAccessing ChatGPT Study Mode is easy. Log in to your account and click on the \"Tools\" button below the text entry field. Then, you can click on \"Study and learn.\" If this is your first time using the tool, you will see a pop-up box.\nAlso: OpenAI teases imminent GPT-5 launch. Here's what to expect\nWhen you click into the box, you will be presented with several different prompt options, including \"Help me with homework,\" \"Explain a topic to me,\" or \"create a practice quiz,\" to help you get started.\nYou can also enter a question you would typically ask ChatGPT, with the biggest difference being in how the AI chooses to respond.\nThe step-by-step guiding questions in Study Mode are meant to mimic Socratic questioning. Other key features include knowledge checks with quizzes, open-ended questions, personalized feedback, which are lessons based on previous questions that assess skill level, and responses organized with easy-to-follow sections.\nWhat did it do for me?\nTaught me a new topic\nTo get started, I clicked on the \"Explain a topic to me\" prompt that came up as an option after selecting Study Mode. I received questions that asked me about what I was working on, including the subject, the topic, and my current grade level or level of familiarity with the topic. For the sake of this article, I chose \"What were the primary causes of the American Revolutionary War?,\" high school, and test prep.\nAlso: You can use Claude AI's mobile app to draft emails, texts, and calendar events now - here's how\nOnce I answered, it prompted me with yet another question, this time about my own answer. It gave me a little explanation and then another question. Although I was slightly irked at how much I had to give to get something from ChatGPT, it did accomplish the goal of keeping me engaged, as I was constantly thinking of an answer to keep the ball rolling.\nTo see the difference from Study Mode, I asked the regular version of ChatGPT to also explain the same topic to me at a high-school level. The results were vastly different.\nInstead of breaking down the topic, the regular version of ChatGPT produced a long, report-like answer that I had to read and scroll through. The AI also didn't have any suggestions for me to practice, learn, or engage.\nAlso: Anthropic's AI agent can now automate Canva, Asana, Figma and more - here's how it works\nThe only question I received at the end of the interaction was whether I wanted \"a quick quiz or a summary chart.\" Although helpful, this output didn't encourage learning in the moment; rather, it was like a glorified article or Wikipedia entry. Personally, I would prefer a report to look over, and perhaps the Study Mode to then make me really think to test my knowledge.\nQuizzed me on a topic\nWhen I clicked on the \"Create a practice quiz\" prompt, I was again asked what I was working on, including the subject, the topic, and this time, my goal for the quiz. To score decently on the quiz, I chose a topic I am familiar with so that I could gauge its accuracy, so I selected Spanish, animal names, beginner, and review.\nI was immediately asked one question, and then I had the opportunity to answer twice before the answer was revealed, and I received guided feedback. When I got the first one right, I got positive reinforcement. Then, when I purposefully got it wrong, it immediately corrected me on what the animal name I provided actually meant, and finally, once I got it wrong twice, it told me the right answer, as well as how I could best remember it. Given the extensive explanations above, I was a bit surprised at how short the guidance was from getting the answer wrong.\nSolved a problem for me\nThat stark difference is even more noticeable when you give both Study Mode and regular ChatGPT a problem to solve. I asked ChatGPT to help me create a complex AP-level trig problem and then fed it to the two different versions. When I asked ChatGPT-4o a regular question, the model analyzed the problem and then output the answer without an explanation.\nStudy Mode explained what to do step by step, and the answer was not released until I went through the steps. Even when I asked the tool to just answer, it encouraged me to continue pushing through, saying, \"I know it's tempting to jump straight to the answer, but if I just give it to you, you won't actually learn how to solve this kind of problem next time.\"\nBottom Line\nThere is a clear difference in the experiences of using Study Mode and standard ChatGPT, with the biggest split being that you have to work through a problem rather than just being handed an answer. Ultimately, though, I still think there are some benefits to a student seeing the answer outputted from the beginning, but also asking ChatGPT to show its work, which comes down to how a student chooses to prompt the standard version of the chatbot.\nThe benefits also depend on what kind of learner you are. If you enjoy having a tutor break down the topics, then you are probably the target audience for this type of tool. Regardless, the experience is free and easy, so it's worth a try. I will personally be using Study Mode when I am genuinely interested in learning a topic thoroughly."
    }
  ],
  "argos_summary": "OpenAI's ChatGPT has introduced a new feature called Study Mode, designed to enhance student engagement and learning by encouraging active participation through Socratic questioning and personalized feedback. However, many educators express concerns about AI's role in education, with a significant number believing it does more harm than good. A Pew Research Center survey indicates that while some students are using AI tools like ChatGPT for homework, teachers remain skeptical about their overall impact on learning outcomes.",
  "argos_id": "PS2BHYDQ4"
}