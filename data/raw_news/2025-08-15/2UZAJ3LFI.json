{
  "url": "https://www.forbes.com/councils/forbesbusinesscouncil/2025/08/15/ai-assessment-and-the-future-of-academic-integrity-insights-for-education-leaders/",
  "authorsByline": "AyoOluwa Nihinlola",
  "articleId": "80616f09a7284eb0a10d01a2055b97a9",
  "source": {
    "domain": "forbes.com",
    "paywall": true,
    "location": {
      "country": "us",
      "state": "NJ",
      "county": "Hudson County",
      "city": "Jersey City",
      "coordinates": {
        "lat": 40.7215682,
        "lon": -74.047455
      }
    }
  },
  "imageUrl": "https://imageio.forbes.com/specials-images/imageserve/689df37029a6632667721572/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-15T13:45:00+00:00",
  "addDate": "2025-08-15T13:54:45.416323+00:00",
  "refreshDate": "2025-08-15T13:54:45.416324+00:00",
  "score": 1.0,
  "title": "AI, Assessment And The Future Of Academic Integrity",
  "description": "To navigate today's challenges, educational leaders should focus less on policing AI misuse and more on transforming how learning is measured.",
  "content": "AyoOluwa Nihinlola, Chief Content Officer at The uLesson Group, building future-forward learning products across Africa.\n\nArtificial intelligence (AI) is reshaping how students engage with education. From tutoring support to language translation, AI tools are helping students access knowledge faster and more flexibly than ever before. But alongside these benefits, a complex challenge is emerging: How do we, as edtech and education leaders, maintain academic integrity when AI can generate complete assignments, solve problems and compose essays in seconds?\n\nRecent reports about universities and schools around the world suggest a rising trend in the misuse of generative AI for coursework. In the U.K., Guardian research found that confirmed cases of cheating using AI tools in higher education rose more than threefold between the 2022-23 and 2023-24 school years. Educators in the U.S. and elsewhere have also expressed concerns about the potential for AI misuse.\n\nBut these breaches of academic standards aren\u2019t only the result of students making poor choices. They also expose a deeper structural issue, one rooted in the way we design and evaluate learning itself.\n\nFor decades, assessments have rewarded students for producing correct answers, often under timed conditions. The structure is simple: Retrieve facts, apply procedures and generate the expected response. Success, in this model, is about knowing what and how quickly you can answer.\n\nBut I believe that model is increasingly outdated. In a world where information is abundant and accessible and where AI tools can generate those same answers in real time, the effectiveness and relevance of traditional assessments are being called into question.\n\nIf students can bypass the effort of learning simply by using AI tools to generate responses that meet assignment requirements, perhaps the problem lies not only with behavior but also with the system itself.\n\nThe Shift From Answers To Inquiry\n\nThis moment offers an opportunity for leaders in education not just to enforce academic integrity but also to reimagine it.\n\nI encourage forward-thinking educators and institutions to embrace a new paradigm: assessing students not only on what they know, but on how they think. That means designing learning experiences that prioritize inquiry, reasoning and original thought and giving students credit for the quality of the questions they ask, not just the answers they provide.\n\nAsking questions is a sign of deep engagement. It reflects understanding, curiosity and a desire to explore. And in the age of AI, when answers are easily generated, the value of a well-framed question becomes even more significant.\n\nIn my experience, students who learn to ask thoughtful, relevant and probing questions demonstrate:\n\u2022 A clear grasp of what they do and don\u2019t understand.\n\u2022 The ability to connect and synthesize ideas.\n\u2022 An openness to challenge assumptions and explore complexity.\n\nThese are the very skills that I think will define success in the future of work, and they\u2019re nearly impossible to replicate with AI alone.\n\nIronically, AI can also help reinforce integrity by supporting this new assessment model. Advances in natural language processing allow systems to evaluate the complexity and relevance of student-generated questions. Feedback can be delivered in real time, helping learners refine their thinking. AI dashboards can help educators spot trends in inquiry and adjust their teaching accordingly.\n\nInstead of using AI only as a monitoring or enforcement tool, we can use it to promote reflective, inquiry-based learning at scale.\n\nWhat Educators And EdTech Leaders Can Do\n\nTo navigate this shift, educational leaders should focus less on policing misuse and more on transforming how learning is measured.\n\nHere are four actions that support academic integrity in the AI age:\n\u2022 Redesign assignments to emphasise critical thinking, reasoning and problem-solving over rote answers.\n\u2022 Incorporate inquiry-based tasks where students generate and reflect on questions.\n\u2022 Leverage AI tools for formative feedback, especially on process and question quality.\n\u2022 Encourage transparency by having students reflect on how and when AI tools were used in their work.\n\nThis approach doesn\u2019t ignore the challenges posed by AI; it addresses them by designing learning experiences that are more meaningful, more human and more resilient.\n\nThe future of academic integrity won\u2019t be protected by stricter rules alone. It will be secured through better design and by creating learning environments where students are recognized for how they think, how they inquire and how they grow.\n\nWhen we shift from an answer-based system to an inquiry-driven one, I think we can not only reduce the appeal of academic shortcuts but also elevate the purpose of education itself.\n\nBecause in a world where answers are abundant, it\u2019s the questions we ask that will truly set us apart.\n\nis the foremost growth and networking organization for business owners and leaders.",
  "medium": "Article",
  "links": [
    "https://councils.forbes.com/forbesbusinesscouncil?utm_source=forbes.com&utm_medium=referral&utm_campaign=forbes-links&utm_content=in-article-ad-links",
    "https://www.insidehighered.com/news/tech-innovation/artificial-intelligence/2024/07/29/students-and-professors-expect-more?utm",
    "https://www.theguardian.com/education/2025/jun/15/thousands-of-uk-university-students-caught-cheating-using-ai-artificial-intelligence-survey",
    "https://ulesson.com/",
    "https://councils.forbes.com/qualify?utm_source=forbes.com&utm_medium=referral&utm_campaign=forbes-links&utm_term=fbc&utm_content=in-article-ad-links"
  ],
  "labels": [
    {
      "name": "Opinion"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "AI tools",
      "weight": 0.09403044
    },
    {
      "name": "AI misuse",
      "weight": 0.08376222
    },
    {
      "name": "students",
      "weight": 0.079844065
    },
    {
      "name": "AI",
      "weight": 0.07838541
    },
    {
      "name": "AI dashboards",
      "weight": 0.07696548
    },
    {
      "name": "Academic Integrity",
      "weight": 0.0739967
    },
    {
      "name": "academic integrity",
      "weight": 0.0739967
    },
    {
      "name": "learning experiences",
      "weight": 0.07024635
    },
    {
      "name": "question",
      "weight": 0.064607225
    },
    {
      "name": "questions",
      "weight": 0.064607225
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/Jobs & Education/Education/Primary & Secondary Schooling (K-12)",
      "score": 0.7705078125
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.74755859375
    },
    {
      "name": "/Jobs & Education/Education/Colleges & Universities",
      "score": 0.71337890625
    },
    {
      "name": "/News/Technology News",
      "score": 0.66064453125
    },
    {
      "name": "/Jobs & Education/Education/Other",
      "score": 0.328369140625
    }
  ],
  "sentiment": {
    "positive": 0.11104584,
    "negative": 0.574078,
    "neutral": 0.31487617
  },
  "summary": "AyoOluwa Nihinlola, Chief Content Officer at The uLesson Group, has written about the future of academic integrity in the face of increasing misuse of artificial intelligence (AI) tools in education. She argues that the current model of assessment rewards students for producing correct answers, but is outdated in a world where information is abundant and accessible. Instead of using AI as a monitoring tool, educators should use it to promote reflective, inquiry-based learning at scale. This shift towards academic integrity requires leaders to design learning experiences that prioritise inquiry, reasoning, and original thought, rather than just answers. Nihanlola suggests that AI can support this new assessment model and use natural language processing to evaluate student-generated questions in real time.",
  "shortSummary": "Artificial intelligence is transforming education by providing fast, context-based assessments, and encouraging deeper inquiry-based learning, despite concerns over academic integrity being misused.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "62689e249ca84da3beb4f7964e92efbc",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.theguardian.com/education/2025/jun/15/thousands-of-uk-university-students-caught-cheating-using-ai-artificial-intelligence-survey",
      "text": "Thousands of university students in the UK have been caught misusing ChatGPT and other artificial intelligence tools in recent years, while traditional forms of plagiarism show a marked decline, a Guardian investigation can reveal.\nA survey of academic integrity violations found almost 7,000 proven cases of cheating using AI tools in 2023-24, equivalent to 5.1 for every 1,000 students. That was up from 1.6 cases per 1,000 in 2022-23.\nFigures up to May suggest that number will increase again this year to about 7.5 proven cases per 1,000 students \u2013 but recorded cases represent only the tip of the iceberg, according to experts.\nThe data highlights a rapidly evolving challenge for universities: trying to adapt assessment methods to the advent of technologies such as ChatGPT and other AI-powered writing tools.\nIn 2019-20, before the widespread availability of generative AI, plagiarism accounted for nearly two-thirds of all academic misconduct. During the pandemic, plagiarism intensified as many assessments moved online. But as AI tools have become more sophisticated and accessible, the nature of cheating has changed.\nThe survey found that confirmed cases of traditional plagiarism fell from 19 per 1,000 students to 15.2 in 2023-24 and are expected to fall again to about 8.5 per 1,000, according to early figures from this academic year.\nThe Guardian contacted 155 universities under the Freedom of Information Act requesting figures for proven cases of academic misconduct, plagiarism and AI misconduct in the last five years. Of these, 131 provided some data \u2013 though not every university had records for each year or category of misconduct.\nMore than 27% of responding universities did not yet record AI misuse as a separate category of misconduct in 2023-24, suggesting the sector is still getting to grips with the issue.\nMany more cases of AI cheating may be going undetected. A survey by the Higher Education Policy Institute in February found 88% of students used AI for assessments. Last year, researchers at the University of Reading tested their own assessment systems and were able to submit AI-generated work without being detected 94% of the time.\nDr Peter Scarfe, an associate professor of psychology at the University of Reading and co-author of that study, said there had always been ways to cheat but that the education sector would have to adapt to AI, which posed a fundamentally different problem.\nHe said: \u201cI would imagine those caught represent the tip of the iceberg. AI detection is very unlike plagiarism, where you can confirm the copied text. As a result, in a situation where you suspect the use of AI, it is near impossible to prove, regardless of the percentage AI that your AI detector says (if you use one). This is coupled with not wanting to falsely accuse students.\n\u201cIt is unfeasible to simply move every single assessment a student takes to in-person. Yet at the same time the sector has to acknowledge that students will be using AI even if asked not to and go undetected.\u201d\nStudents who wish to cheat undetected using generative AI have plenty of online material to draw from: the Guardian found dozens of videos on TikTok advertising AI paraphrasing and essay writing tools to students. These tools help students bypass common university AI detectors by \u201chumanising\u201d text generated by ChatGPT.\nDr Thomas Lancaster, an academic integrity researcher at Imperial College London, said: \u201cWhen used well and by a student who knows how to edit the output, AI misuse is very hard to prove. My hope is that students are still learning through this process.\u201d\nHarvey* has just finished his final year of a business management degree at a northern English university. He told the Guardian he had used AI to generate ideas and structure for assignments and to suggest references, and that most people he knows used the tool to some extent.\n\u201cChatGPT kind of came along when I first joined uni, and so it\u2019s always been present for me,\u201d he said. \u201cI don\u2019t think many people use AI and then would then copy it word for word, I think it\u2019s more just generally to help brainstorm and create ideas. Anything that I would take from it, I would then rework completely in my own ways.\n\u201cI do know one person that has used it and then used other methods of AI where you can change it and humanise it so that it writes AI content in a way that sounds like it\u2019s come from a human.\u201d\nAmelia* has just finished her first year of a music business degree at a university in the south-west. She said she had also used AI for summarising and brainstorming, but that the tools had been most useful for people with learning difficulties. \u201cOne of my friends uses it, not to write any of her essays for her or research anything, but to put in her own points and structure them. She has dyslexia \u2013 she said she really benefits from it.\u201d\nThe science and technology secretary, Peter Kyle, told the Guardian recently that AI should be deployed to \u201clevel up\u201d opportunities for dyslexic children.\nTechnology companies appear to be targeting students as a key demographic for AI tools. Google offers university students a free upgrade of its Gemini tool for 15 months, and OpenAI offers discounts to college students in the US and Canada.\nLancaster said: \u201cUniversity-level assessment can sometimes seem pointless to students, even if we as educators have good reason for setting this. This all comes down to helping students to understand why they are required to complete certain tasks and engaging them more actively in the assessment design process.\n\u201cThere\u2019s often a suggestion that we should use more exams in place of written assessments, but the value of rote learning and retained knowledge continues to decrease every year. I think it\u2019s important that we focus on skills that can\u2019t easily be replaced by AI, such as communication skills, people skills, and giving students the confidence to engage with emerging technology and to succeed in the workplace.\u201d\nA government spokesperson said it was investing more than \u00a3187m in national skills programmes and had published guidance on the use of AI in schools.\nThey said: \u201cGenerative AI has great potential to transform education and provides exciting opportunities for growth through our plan for change. However, integrating AI into teaching, learning and assessment will require careful consideration and universities must determine how to harness the benefits and mitigate the risks to prepare students for the jobs of the future.\u201d\n*Names have been changed."
    },
    {
      "url": "https://www.insidehighered.com/news/tech-innovation/artificial-intelligence/2024/07/29/students-and-professors-expect-more?utm",
      "text": "You have /5 articles left.\nSign up for a free account or log in.\nWhile instructors and students see the potential of generative artificial intelligence\u2014which can be used for everything from creating rubrics to getting study-guide help\u2014they also see the potential for a rise in cheating aided by the technology.\nAccording to a report released today and shared first with Inside Higher Ed by publishing firm Wiley, most instructors (68 percent) believe generative AI will have a negative or \u201csignificantly\u201d negative impact on academic integrity.\nWhile faculty concerns about the use of AI to cheat are nothing new, the study also polled more than 2,000 students\u2014who agreed that generative AI will boost cheating potential. Nearly half of them (47 percent) said it is easier to cheat than it was last year due to the increased use of generative AI, with 35 percent pointing toward ChatGPT specifically as a reason.\nThe numbers were not particularly surprising to Lyssa Vanderbeek, vice president of courseware at Wiley. \u201cAcademic integrity and cheating have been around forever,\u201d she said. \u201cIt\u2019s not surprising that it\u2019s increased because of the fast evolution of these generative AI tools and their wide availability, but it\u2019s not a new challenge; it\u2019s been around for a long time.\u201d\nIt\u2019s important to note that the survey\u2014which polled 850 instructors along with the 2,000-plus students\u2014did not specifically define \u201ccheating,\u201d which some could view as fact-checking an assignment while others think it would only include writing an entire paper through ChatGPT.\nVanderbeek said she has seen a more open dialogue about cheating between professors and students in the classroom.\n\u201cOne thing we\u2019ve noticed with instructors is discussing in the classroom what cheating is and normalizing getting help\u2014and looking at productive ways to get help,\u201d she said, \u201cversus it being, \u2018Where do you cross the line with cheating?\u2019\u201d\nWhen OpenAI\u2019s ChatGPT first hit the scene in November 2022, it immediately drew concerns from academics that believed it could be used for cheating. In an Inside Higher Ed survey released earlier this year, nearly half of university provosts said they are concerned about generative AI\u2019s threat to academic integrity, with another 26 percent stating they are \u201cvery\u201d or \u201cextremely\u201d concerned.\nMany institutions were quick to ban the tools when they first launched but have loosened the restrictions as the technology\u2014and attitudes toward it\u2014has evolved over the past 18 months.\nTechnology and academic experts have often drawn comparisons to similar fears that emerged when Wikipedia was first released in 2001, or in the 1970s when calculators were first widely introduced into classrooms.\nIn the Wiley survey, a majority of professors (56 percent) said they did not think AI had an impact on cheating over the last year, but most (68 percent) did think it would have a negative impact on academic integrity in the next three years.\nOn the flip side, when asked what made cheating more difficult, more than half (56 percent) of students said it was harder to cheat than last year due an uptick in in-person classes and stricter rules and proctoring. Proctoring saw an uptick during the pandemic when courses became remote, and many institutions have kept the practice as classes shifted back to face-to-face.\nStudents believe it is easier to cheat in class compared to last year, largely due to generative AI and ChatGPT.\nWiley\nStudents who stated a strong dislike for generative AI cited cheating as the top reason, with 33 percent stating it made it easier to cheat. Only 14 percent of faculty cited the potential for cheating as a reason for disliking the technology, with their top reasoning (37 percent) being that the technology has a negative impact on critical thinking.\nVanderbeek said she was surprised at the number of students who simply did not trust AI tools\u2014with 36 percent citing that as a reason they don\u2019t use them. Slightly more (37 percent) said they did not use the tools due to concerns their instructor would think they were cheating if they used AI.\nAnd as reported in previous surveys, including Inside Higher Ed\u2019s 2024 provosts\u2019 survey, student use of generative AI greatly outpaced faculty use\u201445 percent of students used AI in their classes in the past year, while only 15 percent of instructors said the same.\nVanderbeek said there are three main approaches institutions can take when looking at keeping academic integrity intact: creating incentives throughout the work process, like giving credit for starting early; introducing randomization on exams so it is harder to find answers online; and providing tools to instructors to identify \u201csuspicious\u201d behavior, like showing copied-and-pasted content or content submitted from overseas IP addresses.\n\u201cThe takeaway is that there is still a lot to learn,\u201d Vanderbeek said. \u201cWe see it as an opportunity: There are probably ways generative AI can help instructors provide learning experiences that they just can\u2019t right now.\u201d"
    }
  ],
  "argos_summary": "Artificial intelligence is reshaping education by enabling rapid access to information, but it also fuels a surge in academic cheating, as shown by UK university data and global surveys. Traditional answer\u2011based assessments are increasingly ineffective when answers can be generated instantly, prompting educators to rethink evaluation toward inquiry, reasoning, and original thought. Experts suggest redesigning assignments, incorporating AI for formative feedback, and rewarding quality questions to uphold integrity while leveraging AI\u2019s benefits. The shift aims to make learning more meaningful and resilient against misuse, emphasizing how students think rather than what they produce.",
  "argos_id": "2UZAJ3LFI"
}