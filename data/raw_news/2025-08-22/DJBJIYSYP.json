{
  "url": "https://www.cnet.com/tech/services-and-software/ai-is-taking-over-our-social-media-feeds-but-maybe-not-how-you-expect/",
  "authorsByline": "Katelyn Chedraoui",
  "articleId": "6bd887934c1d40788afc5d147927d563",
  "source": {
    "domain": "cnet.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "San Francisco",
      "city": "San Francisco",
      "coordinates": {
        "lat": 37.7790262,
        "lon": -122.419906
      }
    }
  },
  "imageUrl": "https://www.cnet.com/a/img/resize/fc74adeacd577548ee59ed84ba7446ab3eccc076/hub/2025/08/21/b6aa584d-13b7-4450-9e6c-167dbe2923ec/social-media-ai-gettyimages-2198976418.jpg?auto=webp&fit=crop&height=675&width=1200",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-22T13:25:03+00:00",
  "addDate": "2025-08-22T13:33:52.317764+00:00",
  "refreshDate": "2025-08-22T13:33:52.317765+00:00",
  "score": 1.0,
  "title": "AI Is Taking Over Our Social Media Feeds, But Maybe Not How You Expect",
  "description": "AI is the new social media intern, even if it isn't creating the posts and images we see on our feeds.",
  "content": "You don't have to be chronically online to know that generative AI has infiltrated nearly every part of our online lives. Social media is no exception: Meta's AI chatbot pushes its way into search on Instagram and Facebook, and Grok offers chat and content creation on X. AI video generation features have emerged on Snapchat, YouTube and TikTok.\n\nBeyond its reach to users, artificial intelligence is increasingly significant behind the scenes as a professional tool for social media brands and creators.\n\nAccording to a new global survey from the social platform management company Metricool, the majority of social media managers (96%) use AI tools to help them with their work. Nearly three-quarters of social media marketers use AI every day.\n\n\"All of us are trying to figure out the best way to use [AI], the right tools, and how to really hone it into our own brand voice,\" said Anniston Ward, US PR events and education manager for Metricool. \"Everyone's trying to understand the best way to use it.\"\n\nWhile AI can bring time-saving benefits to the people behind the posts, generative AI comes with worrisome risks in shaping our online and offline realities. As our favorite brands and creators find new ways to harness AI, it's bound to reignite the debate around how to take advantage of valuable AI use cases while prioritizing human connection.\n\nAn AI-enabled social media future also raises concerns around deterring AI slop -- mass-produced, junky and superficial content that clogs up the web and social media accounts.\n\nHere's how creators are using AI and what pitfalls lurk.\n\nHow AI is used in social media marketing\n\nIn many cases, social media jobs involve several roles in one: content creator, customer service representative, data analyst, trends spotter, and external communications. As teams and budgets shrink, social media professionals are bound to feel more stretched, as they face high expectations to post multiple times a day on several different platforms. The industry is no stranger to burnout.\n\nAnd therein lies the great appeal of AI, which promises to speed up workflows and automate mundane tasks.\n\n\"The reality is, if you're managing multiple accounts and churning out endless content, you do need an extra pair of hands. I think AI has basically become that extra pair,\" said Matt Navarra, a social media industry expert and founder of the Geekout newsletter.\n\nAI can be thought of as a \"super-powered intern,\" Navarra said.\n\nAccording to the Metricool survey, the most common use of AI is content idea generation or brainstorming (78%), followed by writing posts, captions, and copy (72%), and adapting existing text for different tones or channels (68%). Reflecting those use cases, most of the popular AI tools are chatbots. ChatGPT nabbed the top spot, followed by Canva, Gemini and Perplexity.\n\nProfessional photographer Gissel Arbelaez relies heavily on social media to reach new customers for her business in Buenos Aires. To make sure those channels are picture-perfect, she uses AI to correct and improve her English.\n\n\"Since English is my second language and around 70% of the people I work with are English speakers, I need to make sure my grammar is spotless. Nothing goes on my social media without being checked by AI first,\" Arbelaez said via email. She also occasionally turns to AI editing tools in Adobe Creative Cloud, like generative fill and remove.\n\nAI has also come into play among bigger teams focused on social media and marketing. Alba Ben\u00edtez, director and founder of marketing firm Plural Agency, said her team uses AI to unify their knowledge bases and files to \"save us from the small frictions\" and streamline processes.\n\n\"[AI] has freed up mental space for creativity. I can now dedicate more energy to developing fresh projects and pushing our communication further, instead of being stuck in the noise of operations,\" Ben\u00edtez said.\n\nCreating original content through photo and video shoots can be expensive and time consuming. AI can help stretch or adapt one piece of content to work for multiple channels, whether that's clipping a video, resizing visual assets or generating different versions of the same message to match the tone of each platform's audience.\n\nThis behind-the-scenes AI usage isn't immediately apparent in the feeds of scrolling viewers. Just as AI can alleviate administrative burdens for creators, it can also elevate our social media experiences, if managed appropriately.\n\nWhen (and why) not to use AI\n\nAI is not always suitable or useful for social media professionals. Quality is a big concern, with 45% of Metricool's survey respondents reporting it as the primary reason they hold back on AI.\n\nQuality issues can range from chatbots hallucinating and making up false information to more dangerous things like replicating biases in their training data. A content creator wouldn't use an AI-generated product image if the program misspelled the company's name, for example.\n\n\"There's a constant battle of 'Is AI-generated content the same quality as human voices?'\" Ward said.\n\nEven if AI tools improve accuracy and match content quality, maintaining a unique voice and personality is key for big brands and small creators. If they rely too heavily on AI for content creation and editing, they risk losing their individuality. As Navarra put it, AI can draft, but humans must polish.\n\n\"If a brand sounds the same because they're all using the same [AI] model, social media becomes incredibly boring and ceases to be a platform for connection,\" said Navarra.\n\nIf the entirety of your X or Instagram feed is AI-generated garbage, you're more likely to miss posts you find valuable and eventually be persuaded to ditch the platform. Even as social media gets more fragmented, we're still looking to be informed, entertained and connected. Badly done AI threatens that.\n\nApart from AI slop, which is pretty widely hated, there's an inherent risk in using the tech at all. Generative AI is controversial, from worries about job security to legal, ethical and environmental concerns. Using AI for content creation or marketing comes with the risk of alienating an AI-wary audience, especially since not all platforms require labels to be added to AI content, and many can't flag AI usage on their own. It's not just low-quality, biased or misleading AI content that can upset users; it's more subtle AI usage and a lack of disclosures.\n\nRecently, Duolingo announced an internal AI initiative, prioritizing AI over human translators. Vogue included a Guess ad in its July print edition, and readers later learned that the model wasn't real but created with AI. Followers and fans of both brands immediately took to social media to tell the brands directly why they were so unhappy with those pivots to AI.\n\n\"We're all in this limbo period right now where we're pressured to use AI. It does help a lot with the content ideation and generation, but I think there are some missing gaps in how to use it thoughtfully,\" said Ward.\n\nThose gaps can quickly become obvious and detrimental to a brand. To put it in perspective, Arbelaez said all her social media efforts are to build trust with potential and existing customers. Any social media expert will tell you that it's easy to lose an audience's trust and much harder to earn it back.\n\nFinding the right balance of AI for everyone\n\nEvery creator I spoke with highlighted places in their work where they wouldn't use AI. The specific tasks varied, but the common denominator was drawing the line before AI could infringe upon or replace human creativity. Strategy, decision-making and sensitive communications are areas where AI has no place, Ben\u00edtez said. Navarra echoed that sentiment, adding that AI might be the intern, but it shouldn't be the creative director.\n\nWe're in a new reality where the internet seems to be as much human as AI. While AI slop is pretty widely hated, there is a new spectrum gauging how much AI we will tolerate on our feeds. A big part of that is if we know AI is being used, whether the platform labels it as such or the creator discloses it themselves.\n\nThere is a not-small segment of social media users who won't tolerate any AI. Some are totally pro AI. Finding the right balance is the challenge for social media managers.\n\nFor the rest of us, we have to hope and trust that brands and creators understand that we don't want them all to sound and look the same.\n\n\"Social media's always been about connection, and I think AI can help with the media part, but the social part, the trust, the humor, the empathy, that's still human,\" said Navarra. \"Brands that remember that will be the ones that serve their customers well and win.\"",
  "medium": "Article",
  "links": [
    "https://www.milkkarten.net/p/state-of-social-media-survey",
    "https://www.marketingbrew.com/stories/2024/05/20/marketing-budgets-shrinking-gartner-cmo-report",
    "https://www.cnet.com/news/social-media/how-were-bringing-back-the-social-part-of-social-media/",
    "https://geekout.mattnavarra.com/subscribe",
    "https://metricool.com/social-media-ai-report/#link={%22role%22:%22standard%22,%22href%22:%22https://metricool.com/social-media-ai-report/%22,%22target%22:%22%22,%22absolute%22:%22%22,%22linkText%22:%22a new global survey%22}",
    "https://www.linkedin.com/company/plural-consulting/",
    "https://www.cnet.com/tech/services-and-software/heres-how-you-can-create-ai-videos-in-youtube-shorts-thanks-to-google-veo/",
    "https://www.cnet.com/tech/services-and-software/he-got-us-talking-to-alexa-now-he-wants-to-kill-off-ai-hallucinations/",
    "https://www.instagram.com/wander.portraits/",
    "https://www.cnet.com/tech/services-and-software/features/ai-data-centers-are-coming-for-your-land-water-and-power/",
    "https://www.cnet.com/home/internet/what-is-the-dead-internet-theory/",
    "https://www.cnet.com/tech/services-and-software/metas-first-llamacon-shows-the-tech-giants-still-playing-catch-up/",
    "https://www.cnet.com/tech/services-and-software/were-all-copyright-owners-why-you-need-to-care-about-ai-and-copyright/",
    "https://www.cnet.com/tech/services-and-software/shopify-duolingo-workers-face-a-new-gen-ai-reality-at-work-is-your-job-next/",
    "https://www.linkedin.com/in/alba-benitez-social-media-estrategia/",
    "https://www.cnet.com/ai-atlas/",
    "https://www.cnet.com/tech/services-and-software/snapchats-new-ai-video-filters-add-foxes-and-flowers/",
    "https://techcrunch.com/2025/08/03/the-uproar-over-vogues-ai-generated-ad-isnt-just-about-fashion/",
    "https://www.cnet.com/tech/services-and-software/the-new-ai-buzzword-is-slop-and-its-messing-with-you-what-to-watch-out-for/",
    "https://www.cnet.com/tech/services-and-software/i-tried-tiktoks-new-ai-video-generator-its-all-kinds-of-glitchy/"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "AI content",
      "weight": 0.103640124
    },
    {
      "name": "AI tools",
      "weight": 0.09322153
    },
    {
      "name": "social media brands",
      "weight": 0.09245008
    },
    {
      "name": "generative AI",
      "weight": 0.09101803
    },
    {
      "name": "social media",
      "weight": 0.09021254
    },
    {
      "name": "AI",
      "weight": 0.09020583
    },
    {
      "name": "AI usage",
      "weight": 0.08945502
    },
    {
      "name": "AI slop",
      "weight": 0.089072116
    },
    {
      "name": "AI editing tools",
      "weight": 0.08855495
    },
    {
      "name": "social media marketing",
      "weight": 0.08739361
    }
  ],
  "topics": [
    {
      "name": "Media"
    },
    {
      "name": "AI"
    },
    {
      "name": "Social Media"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.775390625
    },
    {
      "name": "/Online Communities/Social Networks",
      "score": 0.70166015625
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.64306640625
    },
    {
      "name": "/Business & Industrial/Advertising & Marketing/Marketing",
      "score": 0.51220703125
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.37158203125
    }
  ],
  "sentiment": {
    "positive": 0.10213216,
    "negative": 0.5486277,
    "neutral": 0.34924015
  },
  "summary": "A new survey by social platform management company Metricool has revealed that artificial intelligence is becoming increasingly significant as a professional tool for social media brands and creators. The majority of social media managers (96%) use AI tools to help their work, and nearly three-quarters of 75 social media marketers use AI daily. However, there are risks in harnessing AI for shaping online and offline realities, including potential mass-produced, junky content that clogs up web and social media accounts. The most common use of AI is content idea generation or brainstorming (78%) followed by writing posts, captions, and copy (72%), and adapting existing text for different tones or channels (68%). Most popular AI tools are chatbots. Despite this, quality of quality of content and user experience is still a concern.",
  "shortSummary": "Artific AI is rapidly transforming social media, offering tools like Meta's AI chatbot and Gissel Arbelaez's social media marketing, but risks remain amid its growth.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "03940f17cd154ac29a38ba0c509b30dc",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.cnet.com/tech/services-and-software/i-tried-tiktoks-new-ai-video-generator-its-all-kinds-of-glitchy/",
      "text": "AI is encroaching on a new area of social media. TikTok on Tuesday announced the new feature AI Alive, which lets creators animate photos for TikTok stories into short video clips using generative AI. The feature is rolling out in the US this week.\nMy experience using AI Alive has been a mixed bag. The first time I tried it, it took nearly 5 minutes to generate a video, and for 2 of those minutes, it kept saying there were only 10 seconds left. The results ranged from acceptable, at best, to downright horrifying. TikTok also seemed to struggle with object permanence.\nThese are a couple of the videos I made with the new TikTok feature. In the first, I wanted to add a dog to my picture of sunny Tybee Island in Georgia, but TikTok took the wheel and decided to make the dog fly in from nowhere, instead of using my directive in the prompt to have the dog run in on the ground.\nIn another video, AI replaced existing elements, unprompted. My original poster of a ram became something of a horror scene, with the now rather scary-looking beast leaping through the page -- I'd simply instructed AI Alive to animate the existing ram and have it jump off the poster. And I don't know why TikTok's feature ultimately decided to replace the original poster with weird AI gibberish. That was unprompted, and the final frame of the video kind of reminds me of an ad for a scary-clown movie.\nThere were lots of weird glitches throughout my testing. I think I could've fixed some of those blunders with edited prompts, but you get only five attempts per day, a disappointingly low limit.\nThe AI video model powering the new feature was built by TikTok, with certain elements supported by open-source technology. Given that TikTok is first and foremost a social media company, not an AI developer, it makes sense that it's taking advantage of some open-source AI tech.\nTikTok's AI Alive videos will automatically have a label added to them denoting that they're AI-generated, and as part of TikTok's partnership with the Coalition for Content Provenance and Authenticity (C2PA), similar markers will be embedded in the metadata of the videos.\nThough the feature itself is meh, this announcement tells us about what TikTok imagines as its future with AI. Many social media platforms have undergone an AI makeover over the past few years, none more so than Instagram and Facebook with Meta AI. TikTok has launched some AI features, including avatars for professional creators and behind-the-scenes AI tools for marketers. But this is its first general-purpose and widely available AI feature. It could mark the beginning of TikTok's AI era.\nFor a company that's been mired in privacy concerns for years, fueling federal legislation, a Supreme Court case and multiple presidential stays to keep the app online in the US, TikTok's choice to dive deeper into AI is noteworthy. Generative AI has its own myriad of privacy concerns, and for image and video generators, people often raise questions about how the models are trained and how they process users' data. TikTok's privacy policy doesn't have a dedicated AI section, but it says TikTok can use information you give it to \"improve and develop the platform and conduct product development,\" which could include AI models.\nI'm struggling to imagine an essential use case for this feature for TikTok creators, but it's probably worth playing around to see if it could work for you. If you want to try it out, here's how to get going:\nHow to animate your TikTok photos with AI\n- Open TikTok and navigate to your profile. Tap the blue plus sign on your profile pic.\n- Upload a photo or take a new picture using the camera.\n- On the left side menu, tap AI Alive. It's under the text option, above stickers.\n- Write your prompt. Choose one of TikTok's suggestions for the best results.\n- Finish editing your video however you want.\n- Post your story or save it to your camera roll.\nWriting a good AI prompt is the key to success. This is true for all AI image and video generators, but in my testing, TikTok's AI seems especially sensitive. When you're writing your prompt, put the most important elements at the beginning. You can check out our full guide to writing effective AI image prompts for more tips.\nFor more, check out these CapCut alternatives and our top picks for AI image generators."
    },
    {
      "url": "https://www.milkkarten.net/p/state-of-social-media-survey",
      "text": "The platform 92% of social marketers consider a priority\nPart one of the Very Online Survey results.\nA few weeks ago we sent out the Very Online Survey with an aim to gather results on what it\u2019s really like to work in social media right now. We received over 825 responses from social media professionals across industries\u2014ranging from those working on big and small accounts alike. Today we\u2019re sharing part one of the results. We\u2019ll be covering topics like:\nWhich type of post is working best on brand accounts right now\nThe top three priority platforms (we were surprised by number two!)\n15 brand accounts that exemplify great social\nThe platform 32.5% of social marketers think is the hardest to crack\nPlus lots more!\nOkay, let\u2019s get into it.\n- Rachel Karten and Mitch Goldstein\nPlatform Playbook\nIn this section we\u2019ll dive into all of the insights around the platforms we post on.\n92% of social media marketers consider Instagram a priority platform\nInstagram remains the frontrunner priority platform (92%) for most social marketers, but a perhaps surprising second place: LinkedIn (52%) beat out TikTok by 2%. We\u2019ve seen LinkedIn on the rise for the last year (recession indicator?) and more and more brands are finding creative ways to show up on the platform like Apple TV+ creating an account for Lumon Industries, Notion\u2019s big influencer push, and Figma\u2019s educational content. Plus we saw the platform\u2019s impact when this post from Duolingo went viral and potentially changed the trajectory of the brand. This will be an interesting graph to track over time.\nBrands are leaving Twitter for good\n36% of respondents have launched a new brand account on a new platform in the last six months, with the most common new platform being Bluesky. That tracks given that of the 59% of social pros who reported moving brand accounts away from a platform this year, the most common answer was X/Twitter due to brand safety, ROI, and performance concerns. \u201cElon\u201d was mentioned 29 times in responses in this section.\nOther platforms brands are joining include TikTok, YouTube, and Threads. Substack was only mentioned 21 times, but I\u2019d almost guarantee that answer would be higher if we sent out the survey today.\n32.5% of social marketers say they have trouble cracking TikTok\nSuccess on TikTok remains elusive, with 32.5% of respondents ranking it the hardest platform to crack right now. Anecdotally, brands seem to have a tough time maintaining traction on the platform, often referring to themselves in \u201cTikTok Jail\u201d. Sure, there are viral blips but creating a cohesive, always-engaging strategy is not easy. Plus the pressure to stay on (or, ideally, ahead of) trends makes it a complicated medium for brands to find measurable success on.\n60% of social marketers would choose Instagram if they could only post on one platform for the rest of the year\nPerhaps it is that struggle to crack TikTok that led almost 60% of our survey respondents to opt towards Instagram if they had to limit themselves to one platform for the rest of the year. An important factor worth weighing is the flexibility of the platform\u2014with Stories, Reels, carousels, DMs, Broadcast Channels, and static image posts the platform allows creativity to come through across different formats and hit different KPIs compared to TikTok or LinkedIn. Sure, social marketers might complain about Instagram (a lot), but it\u2019s clear the platform plays a big role in the overall brand social ecosystem.\nPost Performance\nIn this section we\u2019ll take a look at the post formats and strategies that are driving results.\nCarousels work\nShort-form video (3:00 or less) continues to be the dominant format for brand social right now, with 66.9% of respondents marking the format as a top performer. However, it looks like 2025 might be the year of the Carousel post, with 70.3% of respondents saying they are a best performer, eking out short-form video. You can see examples of high performing carousels here, here, and here.\nBeyond format, respondents pointed towards memes, relatable posts, editorialized content, serialized video formats, and human-led informational content as what\u2019s working on their brand accounts right now. \u201cEducational\u201d was mentioned 31 times, \u201chumor\u201d was mentioned 28 times, \u201ccollab posts\u201d were mentioned 15 times, and \u201crage bait\u201d was mentioned twice.\nMost social professionals look at other accounts for inspiration\nWhile keeping up with trends is part of the job, our survey shows that we\u2019re also keeping tabs on other brand accounts too. From gut checks on what memes are relevant to ensuring we\u2019re differentiating our messaging, most social media professionals are keeping an eye on other brands\u2019 channels as much as their own.\nWe asked what brand you think exemplifies \u201cgreat social\u201d, these were the top 15 responses\u2026\nSomewhat unsurprisingly, the brands social professionals think are doing it the best are ones you\u2019ve likely heard of before. Duolingo continues to dominate marketing headlines and the National Park Service has a great sense of humor. It\u2019s interesting to note that none of the top 15 brands are B2B\u2014although honorary shoutout to Semrush, a SaaS platform that ranked 17th. Finally, it\u2019s great to see Morning Brew mentioned here. There are plenty more established news and media companies with way more resources that could have taken their slot, but it\u2019s a testament to how much that team prioritizes social-first storytelling.\nIf you want to learn more about the people behind these brands, Link in Bio has interviewed a handful. You can find interviews with Duolingo, MERIT, National Park Service, Morning Brew, Away, and Topicals.\nTrends aren\u2019t everything\nAll of that being said, most respondents skewed away from creating content solely focused on memes or trending moments. Social media management is a business, after all, and not all trends or memes are going to help achieve business goals or other metrics you may be held up against.\nVibe Check\nIn this section we\u2019ll cover how social media marketers are feeling right now.\n51% of respondents feel they are worse off professionally when compared to last year\nWith an average rating of 4.4 out of 10, most respondents (51%) feel that they are worse off professionally compared to last year. Only 7.7% of respondents answered this question with an 8 or higher, while 16.6% answered with a 2 or lower. Basically, everyone is pretty \u201cmeh\u201d about how they\u2019re feeling in their job right now.\nThe word \u201coverwhelmed\u201d was mentioned over 80 times\nOverwhelmed, exhausted, tired, and burnout were the most common sentiments shared when we asked to describe how your teams are feeling.\nWhen discussing challenges, responses ranged from issues with creative blocks to dealing with red tape approval processes, getting client approvals for more envelope-pushing ideas, and managing one\u2019s time most effectively. We heard from a lot of you that you\u2019re seeing increased and larger asks from you and your teams without an increase in resources to match.\n\u201cBrands are drowning in a sea of sameness\u201d\nWe gave respondents an option to leave us a voicemail with how they are feeling about the state of the industry. Here\u2019s one social marketer\u2019s take.\nSocial media teams are losing resources and budget\nWe hear all of the time how important social media is becoming within the wider world of marketing\u2014yet budgets and resources haven\u2019t quite caught up. While 61% of respondents reported changes to their budgets and resources, 58% of those said it was a decrease rather than an increase. Between tariffs and economic uncertainty, it might just be a general downward trend across all industries\u2014but it\u2019s something to keep an eye on.\nWe all need to touch grass\nA few weeks ago, we shared that the average screen time reported was 7.4 hours a day. We got some more responses since then and the average has inched down to 7.33 hours a day of screen time. Look, we\u2019ll take it. We got some submissions from people who average even more than that, to which we recommend touching some grass and/or throwing your phone into the sea, and we also saw responses of an hour or less per day, of which we are very jealous.\nFinal Thoughts\nWe closed the survey asking social media professionals what they think is holding them back from making the type of content they feel in their gut would do really well. The most common response we got was a lack of time. Whether it's a feeling of constant crunch, or pressure to get posts out the door, or simply being spread too thin managing multiple channels and accounts\u2014social media managers simply don\u2019t have enough time in the working day to do the things they think could make their work a lot better.\nAnother theme was a lack of resources, both in budget or in headcount, especially in regards to making video content. Not having dedicated creative staff to help write, produce, and edit videos when the expectations are high for quality and timeliness is very relatable. The word \u201cbudget\u201d was mentioned over 80 times in this section.\nThe other common refrain: leadership still just doesn\u2019t \u201cget it\u201d when it comes to social media. Brand marketing leaders can be very risk averse, and many responses mentioned getting conflicting messages when it comes to how the brand should be showing up on social versus how the brand wants to be perceived overall.\nWe also gave some space for venting, given the state of the world the last few months\u2014on top of the constant churn of the industry. Themes included the challenges of being \u201ctoo online,\u201d concerns about mental health having to face some of the less savory sides of the web for work, and whether or not AI is coming for all of our jobs. You know, water cooler talk. We hope that sharing the results of this survey helps reinforce that you aren\u2019t alone in these feelings. [A note from Mitch: having seen first-hand the community and support network that has arisen around this newsletter in the Discord is proof of concept enough that your peers are able and willing to lend a hand, share advice, or be a sounding board. Even if they don\u2019t work directly alongside you, there is a very caring community of smart social media professionals out there!]\nWe\u2019ll have more to share from the survey soon, including a breakdown of all the gear that fellow social industry folks are using, the software making jobs easier, how your peers are (or aren\u2019t) using AI in their work, and how much brands are spending on influencer marketing. Until then, if you have any questions about the results we\u2019ve shared so far, please don\u2019t hesitate to reach out and ask!\nI want to quickly thank Mitch Goldstein, who designed, ran, and analyzed this survey. We\u2019ve now worked on a handful of projects together for Link in Bio, and I\u2019m so grateful for his knowledge. His understanding of this industry and ability to translate data into useful insights made today\u2019s newsletter what it is.\nFinally, you can support free resources like this one with a paid Link in Bio subscription!\nIt\u2019s likely an educational expense at your company\u2014here\u2019s a template for you to use when asking your manager.\nThis is so good, thank you survey respondents! Also the person who left the voicemail is spot on and I totally agree that the internet needs a open and close hours for real. I've been thinking a lot about this as a pursue more offline hobbies and how certain things like reading a book or a newspaper have an end, you can finish them. With the internet the algorithm is constantly feeding you stuff so you never have to leave and stop scrolling.\nAlso LinkedIn has a been a sleeper network for engagement and conversions for a while now! Whenever I've activated it for brands we've seen great results. On a personal note, it has been a better driver for traffic and readership to my substack than Instagram. I've also gained new subscribers!\nYes! I loved the way this information was laid out so huge s/o to Mitch!!!\nThe touches with messages screenshots & the VM were so great, adding to the UX.\nI hope everyone gets the budget & dream team they need for some amazing content but we have each other to get through this for now."
    },
    {
      "url": "https://www.cnet.com/home/internet/what-is-the-dead-internet-theory/",
      "text": "It's no surprise that the rise of artificial intelligence is sparking debates among experts. Moreover, whether you use ChatGPT or Google Gemini, generative AI is increasingly being integrated into our daily lives. It's only fair to ask: Could AI take over the internet? Some members of the online community reckon it already has. This old online theory is on the rise again, and it all has to do with Shrimp Jesus. (Disclosure: Ziff Davis, CNET's parent company, in April filed a lawsuit against OpenAI, the owner of ChatGPT, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nIf you don't know what I'm talking about, that's the infamous AI-generated Facebook image that, along with variations, has been floating around the net since the image first surfaced in March of 2024. At first glance, Shrimp Jesus appeared to be your standard, human-made meme. But it was actually the jumping-off point for Facebook AI art slop -- a proliferation of AI-generated memes like the Challah Horse, the 386-year-old granny baking her own birthday cake, and the random wooden cars (to name just a few).\nThe flood of these pictures has reignited discussions about a conspiracy theory that cropped up in 2021, called the Dead Internet Theory. If you frequently use TikTok, Instagram or Facebook, you may've already seen examples of these kinds of images, without knowing it. I write about the internet for a living, and I only recently heard about the theory. Researching it led me down a rabbit hole I struggled to emerge from. So, what is the Dead Internet Theory? And how does it parallel the rise of artificial intelligence?\nLocating local internet providers\nThe origins of the Dead Internet Theory\nThe Dead Internet Theory first emerged in 2021 on the online forums, 4chan and Wizardchan. People took to these forums claiming that the internet died in 2016 and that AI bots mostly run the content we now see online. This theory also supports the possibility that AI is being used to manipulate the public due to a much larger and sinister agenda. These posts were pieced together in a lengthy thread and published on another online forum called Agora Road's Macintosh Cafe. Be aware, the thread can be easily accessed online, but I did not link to it due to the obscene language in the post.\nUser IlluminatiPirate wrote, \"The internet feels empty and devoid of people. It is also devoid of content.\"\nLocating local internet providers\nNow, years later, this conspiracy is seeing the light of day again with a rise of TikTok creators dissecting the theory and finding examples to support it. One creator, with a username of SideMoneyTom, posted a video in March 2024, showing examples of different Facebook accounts posting variations of AI-generated images of Jesus. These images provide little traffic online, yet they can still easily proliferate your feed. Like many other online creators, SideMoneyTom echoed the same sentiment: These Facebook accounts are run by AI bots and create all content. To better understand this theory, it helps to know how generative AI works.\nGenerative AI uses artificial intelligence systems that produce new content in the form of stories, images, videos, music and even software code. According to Monetate, \"Generative AI uses machine-learning algorithms and training data to generate new, plausibly human-passing content.\" With the launch of ChatGPT in 2022, chatbots have become all the rage these days, with tech giants like Google, Apple and MetaAI creating a slew of AI tools for their products.\nNow, back to Shrimp Jesus. If you feed specific data and prompts to a chatbot, you'll find that these images are \"human-passing.\" Emphasis on \u201cpassing.\u201d Images created by chatbots are certainly known to have their faults.\n\"While large pretrained systems such as LLMs [large language models] have made impressive advancements in their reasoning capabilities, more research is needed to guarantee correctness and depth of the reasoning performed by them,\" AI experts wrote in a report by the Association for the Advancement of Artificial Intelligence.\nHowever, Shrimp Jesus and other AI-generated images aren't the only things online believers use to substantiate this theory.\nYou could be speaking to bots, not actual people\nIf you spend enough time on social media, you'll see odd things in the comments section of certain posts, like repetitive replies from accounts that are irrelevant to the post. These comments are often strange and don't make sense. Last winter, Bluesky subscribers took to Reddit to complain about being plagued by reply bots that were politely and annoyingly argumentative.\nOne Bluesky user flagged the common signs to spot these reply bots and what to do when encountering them. Some indications you're experiencing a bot are when the account is new and has many replies to different posts, as seen from this Bluesky reply bot account.\nHow to spot an AI bot\n- An account with a short bio, a bio that is too specific or no bio at all.\n- An account with no photos or only AI-generated photos.\n- An account that's relatively new.\n- An account with few or no followers.\n- An account with an odd followers-to-likes ratio. (If they have 10K followers but their posts receive 50 to 100 likes.)\n- An account that posts scammy comments.\nAccording to cybersecurity company Imperva's 2024 Bad Bot report, nearly half of all internet traffic came from bots in 2023, a 2% increase from the previous year. Imperva characterizes Bad Bots as automated software programs that perform malicious activities on websites. These bots can take sensitive information, perform account takeovers and initiate cyberattacks or DDoS. That report also highlights that the rapid adoption of generative AI and other LLMs has increased the number of simple bad bots because \"less technical individuals can now write basic bot scripts.\"\nThe report notes that the US saw a rise in bad-bot attacks in 2023, accounting for 47% of all bot activity globally. According to Imperva, the US is the most targeted country for bad-bot traffic worldwide. Bad-bot attacks aren't limited to the internet and online communication. They can affect several industries. For instance, a rise in bad-bot traffic can be seen in the gaming industry; among telecommunications and internet service providers; in the computing and IT sector; and in travel.\nGenerative AI growth has accelerated in recent years, but so have the fears and concerns surrounding these changes, including their impact on the environment. According to recent data from the Pew Research Center, AI experts were more likely than Americans to believe that AI will positively affect the US in the next 20 years. Data shows that over 47% of experts are excited about using AI daily, versus 11% of the public. That same report also highlights that over 51% of US adults have been concerned about the growth of AI since 2021.\nThe internet is transforming, not dying\nRegarding the growing concerns over whether the internet is dead, Sofie Hvitved, technology futurist and senior advisor at the Copenhagen Institute of Future Studies, believes that the internet is not dead, but evolving.\n\"I think the internet, as it looks like now, will die, but it has been dying for a long time, in that sense,\" Hvitved said.\n\"It's transforming into something else and decomposing itself into a new thing, so we have to figure out how to make new solutions and better algorithms\u2026 making it better and more relevant to us as humans.\"\nIn 2024, a NewsGuard audit report revealed that generative AI tools were used to spread Russian propaganda in over 3.6 million articles. NewsGuard also found that AI chatbots were used to create false narratives online from a Russian misinformation news site. To that point, Hvitved emphasized that these issues stemming from AI do not signify that the internet is dead but instead force us to address how we can improve these AI tools.\n\"Since there are large language models, and you know, AI feeds on all the information it can gather, it can start polluting the LLMs and pollute the data, which is a huge problem,\" said Hvitved.\nThe online community and its growing concerns\nThe Dead Internet Theory isn't dying anytime soon. Online discourse surrounding the idea isn't limited to TikTok. It's also found a home in multiple Reddit threads.\nOne Reddit user wrote, \"AI chatbots are going to be catastrophic for so many people's mental health.\" But research to back this up has been mixed. Some point to how AI chatbots can effectively reduce the severity of mental health concerns for people from different demographics and backgrounds. According to a report from the National Library of Medicine, chatbots have reduced the severity of mental health concerns for people in rural communities, shift workers with accessibility issues, students with anxiety and stress and healthcare workers.\nOn the other hand, certain studies show that AI chatbots could be detrimental to young children and their development. A report from the Journal of Pediatrics highlights that AI chatbots fail to address the mental health issues children face, and that they could undermine the pediatrics process.\nAnother Reddit user posted, \"Considering that we are just at the beginning of AI, especially its capabilities with video, I'd say there's a real chance that it will destroy the usefulness of the internet and make it dead.\"\nOther people echo that sentiment by adding that the ratio of AI content to human content will change dramatically over the next few years. One even compiled a list of over 130 examples of subreddit threads on the internet that consisted of comments and posts generated by AI bots.\nCould AI shape a new digital internet culture?\nAccording to the Harvard Business Review, generative AI could primarily threaten content created by independent writers, artists, musicians and podcasters. That said, one looming question following the Dead Internet Theory is whether AI will completely replace human-made content. If so, how will this shape internet culture?\nHvitved is also the Head of Media at the Copenhagen Institute for Future Studies and specializes in examining the relationship between emerging technologies like AI and their impact on communication. She has a take on the future of a new internet culture as AI use increases.\n\"Maybe the static element of the internet is going to die. So we have articles, static pages and web pages you must scroll through, but is that the death of the internet? I don't think so.\"\nShe believes this new internet culture could mean more relevant content for broadband users.\n\"That kind of contextual internet, knowledge graphs, real-time summaries and interactive microformats, that's something these [AI] agents can go out and pick from to create something specialized for you.\"\nThis new internet culture will emphasize AI's ability to tailor unique content for each user and may mean abandoning the concept of shared spaces and communities.\n\"We have to pay attention to echo chambers or diving into your own little worlds that only you would understand. We won't have any shared reality anymore,\" Hvitved said.\nSo, is the internet really dead?\nIf you've watched films like The Terminator, Blade Runner or Wall-E, you know there's always been a fascination with robots and whether they will take over the world one day. The resurgence of the Dead Internet Theory is just the latest evidence of that ongoing discourse. One could argue that AI shaping a new internet culture would mean the death of the internet as we know it. But this doesn't imply that the internet will just disappear. To echo what AI expert Sofie Hvitved conveyed, the internet may eventually evolve into something new. With the rapid growth of AI in our day-to-day lives, there's no question this is transforming the digital landscape. But is the internet dead? As a broadband writer working with numerous hard-working CNET writers daily, I can testify that it's alive.\nThe Dead Internet Theory FAQs\nWhat is the Dead Internet Theory?\nThe Dead Internet Theory emerged in 2021 from online conspiracy theorists on forums like 4chan and Wizardchan. It suggests that the internet died in 2016 and that the content we see online is run mainly by AI bots. The Dead internet Theory also suggests that AI is being used to manipulate the public due to a much larger and sinister agenda.\nWhat are examples of the Dead Internet Theory?\nTikTok creators note the increased number of Facebook bot accounts creating AI-generated images, with Shrimp Jesus and other variations of this image being the most infamous. This image also became the jumping-off point for Facebook AI art slop to spread online, with newly generated AI memes including the Challah Horse, a 386-year-old granny baking her own birthday cake and random wooden cars. In addition, followers also use this theory to explain the spread of bot accounts filling the comment sections across different social media platforms.\nWhat does generative AI mean?\nGenerative AI uses artificial intelligence systems to create new content, including stories, images, videos, music and software code. The way it works is you feed specific prompts and data to a chatbot, and it creates a particular output for you. Examples of generative AI include chatbots suich as ChatGPT, Preplexity, Google Gemini and Claude by Anthropic -- a CNET Editors' Choice for the best overall AI chatbot.\nTo learn more, read CNET's guide to 29 ways you can make Generative AI work for you."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/the-new-ai-buzzword-is-slop-and-its-messing-with-you-what-to-watch-out-for/",
      "text": "Fake images of former and current world leaders getting arrested. Glue as a pizza topping. AI-generated images that just can't stop adding extra fingers to hands. It's junk, and now there's a catch-all term for bad, useless or misleading artificial intelligence: \"slop.\" The term is spreading across tech blogs, mainstream media and Reddit, where countless threads point out egregious instances of AI gone wrong.\nIf slop sounds familiar both as a term and in its meaning, that may be because it's a cousin of spam, which emerged way back in 1993 as a word for unwanted, often auto-generated emails that have been clogging up digital inboxes for decades.\nAI's growing power means that its ability to create new text, images, video and other types of content and throw them onto the web without much, if any, human interaction could lead to more and more slop clogging up fake web pages, social media accounts, message boards and anywhere else we dwell online.\nDon't fall for slop\nOne problem with bad AI, however, is that people may not be able to tell it apart from legitimate content. When AI \"hallucinates,\" or offers up bad or out-of-context information, it's not always obvious.\nSometimes AI can be misled by satirical or purposefully misleading data pulled from websites or other sources, or it can simply be biased by the type of data it's been trained on.\nRead more: Glue in Pizza? Eat Rocks? Google's AI Search Is Mocked for Bizarre Answers\nIt's can be hard to verify whether an image or video is faked by AI sometimes, and with text, it's not always clear how the information is being sourced. It's always worth making sure that information offered up by, say ChatGPT is current and that it's been sourced from a reputable site or set of data.\nOther things you can do to avoid falling into the slop:\nStay sharp, and look for AI quirks: Strange phrasing and irrelevant tangents can be signs of AI-written text. Look for unusual facial movements and bizarre background blending when examining video or photos that look suspicious.\nWhere is it from? Check the source. Is this information posted by The New York Times, or a site you've never heard of?\nCheck it out: Google the post's information if you're suspicious, and look for backup from recognized authorities.\nWe may not like it. We may grow to be overwhelmed by it very, very soon. But at least now there's a name for all this slop.\nRead more: AI Misinformation: How It Works and Ways to Spot It"
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/heres-how-you-can-create-ai-videos-in-youtube-shorts-thanks-to-google-veo/",
      "text": "Creators looking to play around with AI video tech are in for a Valentine's Day treat. YouTube Shorts has new AI video capabilities, thanks to Google's AI video model, Veo 2, being integrated into the video platform.\nIn September at its Made on YouTube event, YouTube first said Veo would add more firepower to its existing Dream Screen tools. This week, the company announced the new tools are now available for folks in the US, Canada, Australia and New Zealand. The new features let you create short, silent AI clips to include in your video, and you can record yourself in front of an AI-generated background image or video.\nGoogle's AI policy when you use AI on Shorts says YouTube \"collects your prompts, related content, and your feedback\" to develop YouTube's services. All AI videos are marked with Google's SynthID, an invisible watermark that designates that it was created by generative AI.\nAI has been slowly but steadily creeping into our daily social media experiences. Professional creators and businesses have seen AI-powered updates behind the scenes for some time, and now regular users are seeing more of the tech. When Meta integrated its AI across its social platforms, users quickly noticed (and complained about) how prevalent it was on Instagram, Facebook, Messenger and WhatsApp. TikTok, though busy dealing with other challenges, has also been rolling out AI avatars and other features for creators.\nAs AI video tech becomes more accessible and refined, it's likely to appear a lot more frequently in our video-first social media environments. YouTube integrating Google Veo is just one of the first examples of this, and creators' and users' responses to it will be telling about the future of AI-video on social.\nIf you want to try out the new YouTube AI video tools for yourself, here's how.\nHow to create AI backgrounds for YouTube Shorts\nTo begin, open the YouTube app and tap the plus button to start creating a new Short.\nHere's how you can create an AI-generated background in a new Shorts video.\n- Go to the menu on the right and tap Green screen.\n- Tap the star background (it should be the first or second option), and agree to the AI policy if prompted.\n- Enter your prompt describing the kind of background you want. Don't worry about being too detailed -- the more, the better.\n- Tap Create.\n- Tap the variation you want or tap Try again to generate more options.\n- Once you have an image you like, tap Use image or Create video.\n- Record your video with the new AI background.\nOnce you're finished, tap the check mark and upload your video like normal. The AI-generated background videos aren't super long, so you might get cut off while you're recording. In my testing, I found it was easiest to break down my script into shorter clips and record several of them instead of recording in one take and risk getting cut off.\nHow to create AI clips with YouTube Shorts\nTo create an entirely new clip with AI, tap the plus sign to begin creating a new video and follow these steps.\n- Go to your media library (tap Add on the lower left side).\n- Tap the Create button at the top of the screen (it has a sparkle icon).\n- Enter your prompt and tap Create.\n- Choose from the variations it provides or tap Try again to generate more options.\n- Tap Use image or Create video.\n- Tap Continue, trim to desired length and tap Done.\nFor more, check out what we know about Adobe's AI video generator and ChatGPT's AI video generator, Sora."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/shopify-duolingo-workers-face-a-new-gen-ai-reality-at-work-is-your-job-next/",
      "text": "Most of us get the same basic questions in our employee performance reviews, even if we work totally different jobs: What did you accomplish in the last year? What are your opportunities for improvement? But here's one you might not have seen before: How did you use generative AI at work?\nSomething like that question might be on the next performance reviews for at least one employer. In a memo posted online after it leaked and was reported on by CNBC and others, Shopify CEO Tobi Lutke said using AI in the workplace is no longer optional at the e-commerce software firm, which employed about 8,100 people at the end of 2024.\n\"Using AI effectively is now a fundamental expectation of everyone at Shopify,\" Lutke wrote in the memo.\nGen AI tools like OpenAI's ChatGPT and Google's Gemini are increasingly being touted as game-changers at the office, with business leaders saying they can make employees more efficient. At the same time, that transformation has raised concerns that these tools will replace humans, leading to fewer jobs. A recent Pew Research Center survey found 64% of American adults expected AI growth would lead to fewer jobs. As I've covered AI's role in the changing workplace, this tension between improved efficiency and possible job losses has come up again and again.\nShopify is one company emphasizing gen AI in the workplace, but it isn't the only one. Duolingo CEO Luis von Ahn told employees in an all-hands email shared on LinkedIn that the language-learning company is going \"AI-first.\" Hiring decisions (including for contractors) will be decided in part based on whether AI can do that work.\n\"Being AI-first means we will need to rethink much of how we work,\" von Ahn wrote. \"Making minor tweaks to systems designed for humans won't get us there.\"\nWhat happens when your boss adds \"use AI\" to your job responsibilities?\nWill AI at work lead to fewer jobs?\nLutke's memo emphasized the importance of Shopify's employees tinkering with AI and spelled out certain requirements, including sharing what they've learned about using AI tools. He also said teams would need to demonstrate why AI can't meet needs before asking for more resources or to hire new employees.\nSimilar requirements appeared in von Ahn's memo to Duolingo workers. Still, he said, the change \"isn't about replacing Duos with AI\" but about providing workers with the tools to do more creative work. A Duolingo spokesperson said the company has not changed its full-time employee headcount based on the move.\nThese memos show one potential impact of gen AI on the availability of jobs: Companies will be less willing to hire if that work can be done by AI instead.\nThat fear is widely shared, with more Americans worried than hopeful about AI's impact on jobs, according to a separate Pew survey released in February that focused on Americans' thoughts on AI at work.\nDespite the widespread fears, Nicole Sahin, CEO and founder of G-P, a firm that provides global employment services, told me she still sees companies hiring workers in line with what would be expected in a growing labor market.\n\"Companies are definitely hiring people and they can't find enough talent,\" she said. \"I don't feel that hiring is slowing down.\"\nWhat is changing, perhaps, is that the people who are being hired for the kinds of jobs that can be done alongside gen AI tools are being hired based on their ability to be creative and versatile with that technology, Sahin said.\nWhen AI is an expectation at work\nThe Shopify memo and its expectation around AI use is \"the beginning of the new normal,\" Sahin said. G-P released a survey this week of 2,850 global executives and 500 US HR professionals, with 91% of executives reporting they're scaling up AI efforts at their companies.\nSahin said she sees the issue as one where companies expect workers to be willing to experiment and be creative with technology. \"The willingness to be nimble is extremely important,\" she said.\nExperts say the expanding use of gen AI in the workplace is changing the skills employees need to thrive. Many workers, including those in entry-level positions, will need to rely more on subject matter expertise and judgment rather than the skills to do tasks that can be done by an AI tool instead.\nMost workers in the February Pew survey said they don't use AI chatbots at all or use them rarely, and only 16% reported using AI in their jobs.\nEven younger workers generally aren't using AI in their jobs. A Gallup survey released this week asked Gen Z adults about their use of gen AI in the workplace. Only 30% said they used it for work, and more than half said their workplace didn't have a formal AI policy. The survey found 29% said AI doesn't exist for their work and 36% said the risks outweighed the benefits in their jobs.\nJust because you can or do use AI at work doesn't mean it's worth it. A report this month by the consultancy firm Coastal found half of the business leaders it surveyed said they've seen no measurable return on investment from AI, and only 21% reported proven outcomes. Coastal attributed this gap between hype and results to the disconnect between experimentation and strategy.\n\"Without clear business alignment or defined outcomes, AI risks staying stuck in the 'interesting but isolated' category,\" the Coastal report said.\nThe problem with AI at work\nGen AI systems like ChatGPT may be able to generate answers to a wide variety of queries, but they aren't answering those things the same way a human would. For one, they're prone to errors known as hallucinations -- essentially making stuff up instead of acknowledging they don't know the answer.\nThat makes it essential to use AI wisely and not trust its answers as always being correct. Especially large, general language models like ChatGPT are trained on a vast amount of data, not all of it good or relevant to your job.\nThose kinds of models \"really should not be used for work,\" Sahin said. \"When you're thinking about using AI in business, it can't hallucinate, it can't get things wrong.\"\nIn the workplace, you want specialized tools that are less likely to hallucinate and are easier to verify and correct, she said. Workers need to be able to detect those issues and fix them in order to use AI well.\nAt Shopify, learning those skills is just part of the job now, Lutke wrote. \"Frankly, I don't think it's feasible to opt out of learning the skill of applying AI in your craft; you are welcome to try, but I want to be honest. I cannot see this working out today, and definitely not tomorrow.\""
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/snapchats-new-ai-video-filters-add-foxes-and-flowers/",
      "text": "We're long gone from the days when the most popular Snapchat filters were the simple, adorable puppy dog face and the iconic early 2010s rainbow-vomiter. Now, Snapchat is taking a step forward in its AI journey. The photo-messaging app announced Wednesday that it is releasing new generative AI-powered video lenses for its premium users.\nThe announcement of the new filters isn't what's noteworthy, since any aspiring developer can use Snapchat's Lens Studio to create and share AR filters. What's interesting is that these new lenses are powered by Snap's own in-house generative AI video models. Rather than augmenting something that already exists, like many filters do, the lenses are using generative AI to add completely new objects to your videos and animate those objects.\nThree new AI filters are available now as part of the launch: a raccoon filter and fox filter (which create and add animals to your shot) and a spring flowers filter, which is a zoom-out feature that reveals a bouquet of flowers. It's a step forward for a social media company that's shown itself to be invested in AR and AI.\nThe new filters are available to folks on Snapchat's platinum plan ($15 per month). Paying for a premium version of Snapchat might seem unnecessary, but people who are already subscribed may have an interest in taking advantage of Snap's AI tools. The platform has added -- and paywalled -- a number of AI tools in the past few years. Snap's AI chatbot, powered by ChatGPT, is available to everyone, but if you have a paid subscription, you can customize it. Generative AI lenses like these are also part of Snapchat Plus' premium plans.\nSnapchat is one of the only social media companies that also has smart glasses (alongside Meta, with its Ray Ban smart specs). The compatibility of the glasses with the Snapchat app on phones is one thing that sets Snap apart from its smart glasses competitors, CNET reviewer Scott Stein noted. But the design is unpolished, Stein wrote: \"The Spectacles in their current form are chunky and much odder than any glasses I'd ever put on my face.\"\nThe release of the new AI lenses is another example of how the integration of AI across social media is ramping up. Meta flooded Instagram and Facebook with its Meta AI when it was released last year, and it continues to use the public content from its US users to train its models. Google teased its AI video capabilities with a newly released AI video background generator on YouTube Shorts. TikTok, despite its many recent legal challenges, also has introduced new AI avatars for creators.\nHow to use Snapchat's new AI filters\nIf you're a premium Snapchatter, here's how you can find the new raccoon, fox and spring flowers lenses. Remember that you won't be able to access the generative AI-powered lenses until you're a paying Snapchat user. Snap said it plans to release more lenses, but you can find the three initial ones right now.\n- Open Snapchat.\n- Tap the down arrow on the left side menu and tap AI Snaps.\n- If the filters don't pop up, scroll through the Lens until you see them.\n- Tap the Lens you want to use and hit record/capture.\nFor more, check out our top picks for AI image generators and all the AI inside the new Photoshop iPhone app."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/were-all-copyright-owners-why-you-need-to-care-about-ai-and-copyright/",
      "text": "Most of us don't think about copyright very often in our daily lives. But in the age of generative AI, it has quickly become one of the most important issues in the development and outputs of chatbots and image and video generators. It's something that affects all of us because we're all copyright owners and authors.\nSadly, copyright and AI are something of a mess. The race to develop the most advanced AI models shows no sign of slowing anytime soon. In order to create those next-gen models, tech companies are looking for lots of high-quality, human-generated content. They need these works to make their AI models better, whether that's giving a chatbot a more lifelike personality or an image generator more artistic styles to reference. On the flip side, AI enthusiasts might be wondering if it's possible to receive copyright protection for AI-enabled creative works.\nMost AI companies have been very vague about what content they use, which has led to more than 30-plus lawsuits winding their way through US courts. You might have heard of some of the most notable, like the New York Times v. OpenAI, in which the publisher alleges that ChatGPT used reporters' stories verbatim without proper attribution or permission. (Disclosure: Ziff Davis, CNET's parent company, in April filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.) Meta's also been in hot water recently, as The Atlantic reported and published a searchable database of all the copyrighted and potentially pirated books the company allegedly used without permission to train its AI.\nI spend a lot of time thinking about copyright and AI in my work reporting on AI creative services. I've interviewed intellectual property lawyers, spoken with lots of concerned creators and spent way too much time breaking down legalese from government agencies. I've used that experience to make this guide on what you need to know about copyright in the age of AI, which we'll keep it updated as things change.\nWhat is copyright?\nCopyright is a set of expressed rights that protect \"original works of authorship fixed in any tangible medium of expression, now known or later developed, from which they can be perceived, reproduced or otherwise communicated,\" according to the Copyright Act of 1976.\nIn other words, copyright is a legal protection that gives original authors the rights to and control over their original works. Copyright protection can apply to books, art, music, movies, computer programs, blogs, architectural designs, plays, choreography and more. We're all copyright owners. As the US Copyright Office puts it: \"Once you create an original work and fix it, like taking a photograph, writing a poem or blog or recording a new song, you are the author and the owner.\"\nThere are a couple of ways copyright intersects with AI. On the output side, people who use AI services like chatbots and image generators want to know whether their AI-enabled work is eligible for copyright protection. On the development side, there are a lot of concerns about AI companies using copyrighted material illegally. Here's what we know so far.\nCan I copyright an image or text I generated with AI?\nAs with many legal questions, the answer is: It depends.\nOur guidance on this question comes primarily from the US Copyright Office, the federal agency in charge of administering copyrights. The Office has released a series of reports on AI and copyright with its latest guidance. In the second report, the Office maintained its position that images and videos that are entirely generated by AI are not eligible for copyright protection.\nHowever, there are a number of generative AI editing tools now available. These tools aren't used for wholesale creation, but they use gen AI to do things like add or remove objects, de-age actors or refine audio and video. You can still register and potentially receive copyright protection for AI-edited content, but you have to disclose your AI use. In the public record portal, you can see in the notes how people used AI in the creation of their copyrighted work.\nCan copyrighted content be used to train AI?\nThe basic premise in copyright law is that the rights holder -- usually the original creator, sometimes in other cases it can be a person's employer -- can decide how they want their works used. In many cases, owners choose to license their content; this lets people use copyrighted work, for a fee, with proper attribution. So if a copyright owner wants to give an AI company permission to use their content to train AI models, there's nothing wrong or illegal about that. Many publishers, including the Financial Times and Axel Springer brands, have struck multimillion-dollar deals with AI companies to do just that.\nIssues arise when AI companies potentially use copyrighted content without first receiving permission from the copyright holders. And that's what creators are alleging happened in many lawsuits, including a class action lawsuit led by concept artist Karla Ortiz against Stability AI. There are currently more than 30 active lawsuits between AI companies and creators over copyright concerns.\nDecades of copyright law precedent say that such a use, without permission, is not allowed. Some of the creators are alleging that the tech companies infringed on their copyrights. Infringement occurs when a copyrighted work is \"reproduced, distributed, performed, publicly displayed, or made into a derivative work\" without the permission of the copyright holder, as the Copyright Office defines it.\nIt will be up to the courts to decide whether the use of copyrighted material in AI development reaches the threshold of infringement. In the meantime, many tech companies are trying to pursue an alternate solution: A fair use exception.\nWhat is fair use, and what does it have to do with AI?\nThe fair use doctrine is a fundamental part of copyright law, part of the Copyright Act of 1976. Fair use lets people use copyrighted content without the holder's express permission for specific purposes. In the pre-AI era, fair-use cases included a teacher using a copyrighted book for educational purposes or a reporter referencing copyrighted work in news coverage. There are four factors that help determine whether someone's use can qualify as a fair use, including:\nThe purpose of the use: How would the person using copyrighted material be using it? Commercial interests -- whether someone can make money off the use -- are important here.\nThe nature of the copyrighted work: What is the actual format of the disputed work -- is it factual like a newspaper article or highly creative like artwork?\nThe amount and substantiality of the use: How much of a copyrighted work does someone want to use? Even if it's only a little bit, if it's the \"heart of the work,\" that might not be eligible for a fair use defense.\nThe effect on the market: By using a copyrighted work in a proposed way, is that going to be competing with the original author? And what effect will that have on the greater market?\nThere are questions about every factor when it comes to fair use and AI, Christian Mammen, an intellectual property lawyer and San Francisco office managing partner at Womble Bond Dickinson, told me in an interview. There's also a debate about whether the fair use factors apply to the AI input, output or both. \"Does that apply on the input side, where you take the whole work in this training data, or does it apply on the output side, where there may be an unrecognizable, tiny bit of influence by any particular work in the output?\" Mammen said.\nTech companies are pushing hard for a fair use exception because it would allow them to use copyrighted content without contacting every rights holder and paying licensing fees. For companies like OpenAI and Google, which have already spent billions of dollars on development, a fair use exception would save considerable time and money. Google said that fair use would allow it to continue innovating quickly; OpenAI took a parallel approach and said that unimpeded AI innovation is a matter of national security.\nGiving tech companies carte blanche to run amok with copyrighted content isn't something creators are excited about. In March, over 400 writers, actors and directors signed an open letter asking the Trump administration not to give OpenAI and Google a fair use exception. They wrote that Google and OpenAI \"are arguing for a special government exemption so they can freely exploit America's creative and knowledge industries, despite their substantial revenues and available funds. There is no reason to weaken or eliminate the copyright protections that have helped America flourish.\"\nThe Copyright Office essentially punted on the issue of fair use, saying in its third report that there could be cases where a fair-use case could be made, but there are times when it wouldn't meet the necessary criteria. Without federal legislation, it's likely we'll have to wait for some or all of these court decisions to set new legal precedent for copyright and fair use in the age of AI.\nWhat does all of this mean for the future?\nCopyright owners are in a bit of a holding pattern for now. But beyond the legal and ethical implications, copyright in the age of AI raises important questions about the value of creative work, the cost of innovation and the ways in which we need or ought to have government intervention and protections.\nThere are two distinct ways to view the US's intellectual property laws, Mammen said. The first is that these laws were enacted to encourage and reward human flourishing. The other is more economically focused; the things that we're creating have value, and we want our economy to be able to recognize that value accordingly.\n\"For most of our history, the humanistic approach and the industrial policy approach have been fairly well aligned,\" Mammen said. But generative AI has highlighted the different approaches to copyright and IP.\n\"Do these laws exist primarily as an issue of industrial economic policy, or do they exist as part of a humanistic approach that values and encourages human flourishing by rewarding human creators?\" Mammen asked. \"At the highest, most abstract level, I'd say that is one of the questions that's being forced by these debates.\""
    },
    {
      "url": "https://www.linkedin.com/company/plural-consulting/",
      "text": "El deseo sexual no desaparece. Cambia de forma, de ritmo, de voz. Y a veces, lo que m\u00e1s necesitamos no es que nos expliquen c\u00f3mo recuperarlo, sino que nos hablen como si supieran lo que estamos sintiendo. En este nuevo spot para Libicare\u00ae ONE de PROCARE HEALTH, creamos un espacio donde muchas mujeres nos dijeron: \u201cme pasa igual\u201d. Una mujer. Una historia. Una necesidad de volver a sentir. Quisimos hablar de eso sin pudor, sin drama y sin adornos. Una historia que nombra, muestra y celebra. Porque el deseo no tiene fecha de caducidad. Solo pide que lo escuchen. Desde Plural, trabajamos cada plano y cada palabra con el mismo cuidado con el que se abre una conversaci\u00f3n pendiente. Y cuando, tras el estreno, m\u00e1s del 75% de mujeres se sintieron reflejadas, supimos que la emoci\u00f3n no era solo intuici\u00f3n: era conexi\u00f3n. Gracias Roser Duran & equipo por confiar en nosotros para acompa\u00f1aros en trazar nuevos horizontes en la comunicaci\u00f3n con la paciente.\nPlural | Agencia de comunicaci\u00f3n\nAdvertising Services\nBarcelona, Barcelona 835 followers\nComunicar no es decir m\u00e1s. Es decir bien. Estrategia y creatividad para marcas que quieren conectar con intenci\u00f3n.\nAbout us\nDise\u00f1amos estrategias de comunicaci\u00f3n que piensan en negocio y se activan con creatividad. En Plural trabajamos con marcas que quieren comunicar con intenci\u00f3n, no solo estar presentes. Acompa\u00f1amos a responsables de comunicaci\u00f3n y marketing que buscan un equipo con criterio, capaz de traducir la estrategia de marca en acciones concretas, sostenidas y con sentido. Nuestro enfoque combina estrategia, contenido y direcci\u00f3n creativa para construir una comunicaci\u00f3n clara, pr\u00e1ctica y alineada con el momento. No entendemos la comunicaci\u00f3n como un conjunto de acciones aisladas, sino como un sistema vivo que se ajusta, se aprende y se afina en el tiempo. Creemos en una comunicaci\u00f3n: \u2022 Que tiene una estrategia detr\u00e1s \u2022 Que baja a tierra y se activa \u2022 Que no vive solo en campa\u00f1as puntuales \u2022 Que es pr\u00e1ctica, clara, real \u2022 Que conecta con las personas y hace crecer el negocio Vehiculamos la estrategia de marca a trav\u00e9s de contenidos y canales que conectan de verdad con su audiencia. No trabajamos para que las marcas hablen m\u00e1s, sino para que sean escuchadas con intenci\u00f3n y coherencia. \u00bfQu\u00e9 hacemos? \u2022 Estrategia de comunicaci\u00f3n y contenido \u2022 Direcci\u00f3n creativa y campa\u00f1as \u2022 Branding y tono de voz \u2022 Gesti\u00f3n de redes sociales \u2022 Producci\u00f3n de contenido \u2022 Comunicaci\u00f3n corporativa \u2022 Consultor\u00eda y acompa\u00f1amiento de marca Si est\u00e1s en ese punto de \u201cnecesitamos ordenar y enfocar c\u00f3mo comunicamos\u201d, escribenos. Podemos ayudarte.\n- Website\n-\nhttps://plural.agency/\nExternal link for Plural | Agencia de comunicaci\u00f3n\n- Industry\n- Advertising Services\n- Company size\n- 2-10 employees\n- Headquarters\n- Barcelona, Barcelona\n- Type\n- Privately Held\n- Founded\n- 2019\n- Specialties\n- Comunicaci\u00f3n, Estrategia de marca, Creatividad, SEM, SEO, Social Media, Creaci\u00f3n de contenidos, Marketing de contenidos, Dise\u00f1o gr\u00e1fico, Influencer Marketing, Email Marketing, and Branding\nLocations\n-\nPrimary\nGet directions\nCarrer de Roger de Ll\u00faria 22, 1-2\n1\u00ba2\u00aa\nBarcelona, Barcelona 08010, ES\nEmployees at Plural | Agencia de comunicaci\u00f3n\nUpdates\n-\nEl dise\u00f1o sin estrategia es solo ruido. Y la comunicaci\u00f3n sin intenci\u00f3n, se pierde. En un momento en que los algoritmos afinan lo visual hasta el agotamiento y la IA multiplica f\u00f3rmulas sin alma, en Plural apostamos por parar, pensar y construir con criterio. \ud83d\udc49 En este art\u00edculo compartimos nuestra mirada sobre la campa\u00f1a de Blanc!mad 2025 de Blanc! y el valor de una estrategia de comunicaci\u00f3n que no solo acompa\u00f1a al dise\u00f1o, sino que lo sostiene y lo potencia. \ud83d\udc49 https://lnkd.in/dya5raGG\n-\nDesde Plural, desarrollamos junto a PROCARE HEALTH una campa\u00f1a de concienciaci\u00f3n con motivo del D\u00eda Internacional del VPH. El objetivo: visibilizar una infecci\u00f3n que afectar\u00e1 al 80% de la poblaci\u00f3n sexualmente activa\u2026 y romper con el estigma que, todav\u00eda hoy, recae especialmente sobre las mujeres. \u26a0\ufe0f Aunque cada vez hablamos m\u00e1s de salud y autocuidado, el Virus del Papiloma Humano sigue siendo un tab\u00fa. Muchas mujeres viven su diagn\u00f3stico en silencio, sin compartirlo con su entorno por miedo, verg\u00fcenza o culpa. \ud83c\udfa5 Para cambiar esto, lanzamos una campa\u00f1a gr\u00e1fica en las calles de Barcelona y Madrid, con mensajes directos y sin filtros. Y frente a los carteles, activamos un experimento social: preguntamos a personas del p\u00fablico objetivo cu\u00e1nto sab\u00edan realmente sobre el VPH. \u00bfEl resultado? Conversaciones espont\u00e1neas, necesarias y llenas de verdad. \ud83d\udca5 La informaci\u00f3n empodera. El estigma se rompe hablando. Y a veces, todo empieza con un cartel en la calle.\n-\n+1\n-\nHay producciones que huelen a romero, lavanda y ganas de hacerlo bonito. As\u00ed vivimos cada sesi\u00f3n con Henna Morena: cuidando cada detalle, trabajando en equipo y disfrutando del proceso. Y s\u00ed, confirmamos: Paula Granell Rey tiene el superpoder de hacer que hasta el caos del BTS quede precioso. \ud83d\udcf8 Ayer nos pusimos manos a la obra para producir contenido para redes y preparar el lanzamiento de una de las pr\u00f3ximas novedades de la marca. Lo que se viene\u2026 huele muy bien. Cliente Henna Morena Direcci\u00f3n de comunicaci\u00f3n - Imma Padilla\n-\nYa est\u00e1 aqu\u00ed \ud83d\udc4f\ud83c\udffb el episodio del podcast de FemFet\u00e9n! en el que entrevistan a Alba Ben\u00edtez Campos, co-fundadora y Directora de Comunicaci\u00f3n de nuestra agencia Plural Agency (https://plural.agency/). Una conversaci\u00f3n sincera sobre la comunicaci\u00f3n digital, la estrategia, el emprendimiento y las dificultades de mantenerse fiel a los propios valores en el mundo de la comunicaci\u00f3n. Os invitamos a escucharlo aqu\u00ed \ud83d\udc47\ud83c\udffb\ud83d\udc96 https://lnkd.in/dhKsJyWZ\nT2E2 - Alba Ben\u00edtez - Sin estrategia no hay comunicaci\u00f3n efectiva\nhttps://www.youtube.com/"
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/he-got-us-talking-to-alexa-now-he-wants-to-kill-off-ai-hallucinations/",
      "text": "If it weren't for Amazon, it's entirely possible that instead of calling out to Alexa to change the music on our speakers, we might have been calling out to Evi instead. That's because the tech we know today as Amazon's smart assistant started out life with the name of Evi (pronounced ee-vee), as named by its original developer, William Tunstall-Pedoe.\nThe British entrepreneur and computer scientist was experimenting with artificial intelligence before most of us had even heard of it. Inspired by sci-fi, he \"arrogantly\" set out to create a way for humans to talk to computers way back in 2008, he said at SXSW London this week.\nArrogant or not, Tunstall-Pedoe's efforts were so successful that Evi, which launched in 2012 around the same time as Apple's Siri, was acquired by Amazon and he joined a team working on a top-secret voice assistant project. What resulted from that project was the tech we all know today as Alexa.\nThat original mission accomplished, Tunstall-Pedoe now has a new challenge in his sights: to kill off AI hallucinations, which he says makes the technology highly risky for all of us to use. Hallucinations are the inaccurate pieces of information and content that AI generates out of thin air. They are, said Tunstall-Pedoe, \"an intrinsic problem\" of the technology.\nThrough the experience he had with Alexa, he learned that people personify the technology and assume that when it's speaking back to them it's thinking the way we think. \"What it's doing is truly remarkable, but it's doing something different from thinking,\" said Tunstall-Pedoe. \"That sets expectations\u2026 that what it's telling you is true.\"\nInnumerable examples of AI generating nonsense show us that truth and accuracy are never guaranteed. Tunstall-Pedoe was concerned that the industry isn't doing enough to tackle hallucinations, so formed his own company, Unlikely AI, to tackle what he views as a high-stakes problem.\nAnytime we speak to an AI, there's a chance that what it's telling us is false, he said. \"You can take that away into your life, take decisions on it, or you put it on the internet and it gets spread by others, [or] used to train future AIs to make the world a worse place.\"\nSome AI hallucinations have little impact, but in industries where the cost of getting things wrong -- in medicine, law, finance and insurance, for example -- inaccurately generated content can have severe consequences. These are the industries that Unlikely AI is targeting for now, said Tunstall-Pedoe\nUnlikely AI uses a mix of deep tech and proprietary tech to ground outputs in logic, minimizing the risk of hallucinations, as well as to log the decision-making process of algorithms. This makes it possible for companies to understand where things have gone wrong, when they inevitably do.\nRight now, AI can never be 100% accurate due to the underlying tech, said Tunstall-Pedoe. But advances currently happening in his own company and others like it mean that we're moving towards a point where accuracy can be achieved.\nFor now, Unlikely AI is mainly being used by business customers, but eventually Tunstall-Pedoe believes it will be built into services and software all of us use. The change being brought about by AI, like any change, presents us with risks, he said. But overall he remains \"biased towards optimism\" that AI will be a net positive for society."
    },
    {
      "url": "https://www.cnet.com/news/social-media/how-were-bringing-back-the-social-part-of-social-media/",
      "text": "Gabbie Romano is a top contributor to the \"Bagels Who Discuss\" Facebook Group, an inclusive place for folks in the Chapel Hill-Durham area in North Carolina. That means Romano is one of the most active members of the private group, sharing posts and commenting on others to provide advice, recommendations and support, which is the group's purpose. But she wasn't always so active in Facebook Groups like Bagels.\nOver the past few years, Romano noticed some changes while using other social media outlets, specifically Instagram. Comments under creators' posts seemed meaner and more critical than before, and it was getting hard to be around. She found herself comparing herself to others and going down rabbit holes, which wasn't good for her mental health.\n\"I end up in a mindless scroll spiral that never feels good but is hard to get out of,\" she said.\nThat's what led Romano to delete her Instagram app. Now, she primarily uses Facebook Groups, which is where we connected. She also uses subreddits, where she finds people with similar interests as hers, including local foodie and hiking groups as well as an interior design \"ask anything\" group.\nRomano's experience is just one example of many, as some social media users have migrated to and adopted new, smaller spaces online. I've noticed this trend in my own life and work as a social media reporter. So, I explored how big this trend is, how it's manifesting and whether these small spaces are here to stay by talking to some experts.\nWhat are small social media platforms?\nSmall social media groups are exactly what they sound like -- spaces online meant to connect people in smaller groups, instead of pushing them to explore content from all over. They're fairly easy to find, too. Subreddits and Facebook Groups are two common examples of smaller spaces on bigger platforms. These groups are designated corners within larger platforms that are meant to encourage smaller pools of users to post, share and connect. It can be easier to join spaces like these when you're already on the platform -- there's no need to create a new account.\nDiscord is a great example of this pattern in action. It started as a voice chat service for gamers but evolved into a big platform that hosts 200 million monthly active users, as of May 2024. According to a Discord spokesperson, 80% of communications on the platform are in smaller group servers. Instead of being a virtual global town square, Discord is a large platform that gives its users the ability to connect more one-on-one by joining specific community servers, like Manchester City football superfans. Users can also create their own server for their friends and take advantage of the group chat functionality to get around international texting fees and Apple's blue versus Android's green bubble debacle.\nIndependent, topic-specific platforms are also becoming more popular. For film fans, Letterboxd exploded in popularity during the pandemic and has steadily grown its user base since then. It has 10 million users today, up from 4.1 million in 2021 and 1.8 million in 2020, according to The Washington Post. The fan fiction platform Archive of Our Own -- AO3 -- has over 11 million stories, uniting global audiences around specific interests, whether that's rewriting the ending of Game of Thrones or authoring new non-canon stories for other fandoms.\nInvite-only apps like Lapse, which was the No. 1 free app in the Apple App Store for several months in 2023, encourage you to connect with a smaller group of your friends. Even apps like Nextdoor, which connects neighbors in the same geographic area, are becoming more common. Nextdoor has 88 million neighbors in 330,000 neighborhoods -- and more importantly, 75% of its users report that the platform helps them feel more connected to their community.\nWhile these apps have many users, those folks are finding smaller ecosystems within the larger whole. On Letterboxd, users connect with smaller groups through favorite movies and by leaving reviews or following friends and favorite film critics. On AO3, it's by fandom and category or tags on stories, with a niche category to suit everyone. On Lapse and Nextdoor, those spaces are specifically designed for people to connect with the people already in their lives.\nWhy people are using small social platforms\nThere are a lot of reasons why people might leave big platforms -- mental health for one. There's also the impact of social media sites on our productivity and attention spans, and a desire to avoid doomscrolling. There are also plenty of reasons why someone might join a smaller online community, including the appeal of exclusivity, avoiding ads and taking a break from news cycles. But the main motivation that came up over and over was a desire for community.\nOriginally, platforms like Facebook were supposed to build and host communities. But that's not what they are today.\n\"A lot of the social platforms right now are really prioritizing discovery and entertainment,\" said Rachel Karten, social media marketing expert and creator of the Link In Bio newsletter. Leaning into entertainment content helps big platforms keep users engaged and revenue flowing, Karten explained. But people are still \"...seeking out places where they can find community.\"\nThat's where niche online communities pop up -- whether they're in a pocket of space on a larger platform or a dedicated smaller space. In these small communities, people are united under a shared goal, interest, location or other commonality. In many instances, the people in these rooms also share the same values and beliefs. Those build the norms in a small space, said Ethan Zuckerman, researcher and professor at the University of Massachusetts at Amherst.\nBecause the group, rather than the overarching platform, decides what is and isn't acceptable behavior, it can open the group up to sharing on a deeper level. \"Those spaces can be really valuable for people to explore sensitive topics and find support from different people,\" said Zuckerman. Groups can also decide to be more stringent with their community guidelines compared to those of individual platforms.\nTake a mental health and substance abuse support group, for example. The people in those groups may want everyone in the space to be at least similarly aligned with their views. They also might find a smaller space less intimidating to share, especially if the group emphasizes the importance of being respectful, supportive and compassionate. This all can build a sense of safety and security that's much harder to find on bigger platforms, if it exists at all.\n\"[People] want to be in places where they have trust in the cultural dynamics of the space that they're in. They just don't want to be on the receiving end of an algorithm,\" said Deepti Doshi, co-director of New_ Public, a community-driven research laboratory focused on digital public infrastructure.\nBeyond just individual people seeking community, these smaller spaces can bring folks together on a societal level. One example Doshi calls out is how in the wake of thousands of local newspapers closing, these digital spaces can be good alternatives to traditional news outlets for disseminating local news and information. \"Without these local institutions stepping into this role of weaving our [societal] fabric together, we need to reinvent\u2026digital spaces are sprouting up to fill this gap,\" she said.\nSmall online spaces aren't perfect\nNot all small spaces are healthy, though. These niche communities aren't immune to issues that bigger platforms face, particularly when it comes to creating echo chambers and normalizing potentially dangerous ideas, whether that's misinformation or conspiracy theories.\nThe very thing that can draw someone to a small online community is what can make it dangerous. \"Their problem is homophily -- they end up with a lot of people who feel the same way, think the same way. They're not as good for bridging or for sharing ideas across boundaries,\" Zuckerman warns.\nAnd that matters, especially as election season heats up and social media platforms gear up in kind. For example, Instagram recently changed all users' settings to automatically limit political content from users' feeds. Even if small spaces wanted to do something like that, they don't have the same kind of broad oversight and technical firepower that big platforms do.\nZuckerman wrote in an op-ed earlier this year that the concern with small spaces is that they could be too insulated from opposing points of view or outside scrutiny. When there's no pushback, extreme points of view -- especially political ones -- can be normalized and draw people down into rabbit holes that are hard to escape.\nDoshi echoed these concerns, pointing out that these small platforms aren't really built with the intention of helping people create connections across differences. \"If we want to take advantage of this trend of people moving into these small spaces, we need to complement that with a movement to ensure that these small spaces are actually healthy.\"\nIn this fight, group administrators or moderators will be vital. Bigger platforms have entire teams dedicated to community management and safety, but in smaller online spaces, those responsibilities fall to one or a few admins or mods. Beyond setting up the group's online infrastructure, creating the group's community guidelines and monitoring what is being shared, they're also tasked with settling disagreements and eking out punishments when users break the group's rules. As such, Doshi points out that giving the people in these roles the necessary resources and support is one way to keep these small online spaces healthy. Currently, most of the folks in these roles do this on a volunteer basis -- meaning they're never paid for their work, time and emotional labor, which can be significant.\nWhat does this mean for the future of social?\nUltimately, it's unlikely that there will be a mass exodus from these big platforms. Even after X's (formerly Twitter) tumultuous time after Elon Musk bought it in 2022, only 18% of its US users left the platform a year later, according to Variety. That's millions of people, but still less than a fifth of all US users.\nInstead, what's more likely to happen is people will continue to seek and carve out smaller corners of the internet for their friends and find new groups bonded over common, niche interests, whether they're geographically local or made up of a small but global community.\nAs people continue adopting or migrating to smaller, more community-driven online spaces, we should pivot to see these spaces as equally important in our lives as big platforms are, even as their purposes evolve. As Karten put it, TikTok might become the place where things happen, and Discord will be where we go to talk about it. Both are important to our online social ecosystem.\nAnd as Zuckerman put it, \"If we're going to legislate this stuff, it's really important that we actually understand what we're legislating. And the truth is, just looking at social media as all these people united by Twitter under the thumb of Elon Musk, that's just not an accurate picture of social media that people are encountering.\"\nTaking this holistic view of our online social lives can certainly help alleviate fears and concerns as legal challenges to big platforms like TikTok continue. You don't have to worry as much if one platform goes away if you have others to rely on. What's more important is the underlying motivation for why people are seeking out these small places -- and why they aren't currently finding what they need on Instagram, Twitter and other big platforms.\n\"[Main platforms] have sort of lost their way when it comes to community, and many of these platforms were created, literally, with community in mind,\" said Karten. \"So can any of these platforms find their way back? If they don't, then I think it's amazing that we now have alternatives, like Discord and Substack, to find community.\""
    },
    {
      "url": "https://metricool.com/social-media-ai-report/#link={%22role%22:%22standard%22,%22href%22:%22https://metricool.com/social-media-ai-report/%22,%22target%22:%22%22,%22absolute%22:%22%22,%22linkText%22:%22a new global survey%22}",
      "text": "How Social Media Professionals Use AI in 2025 [Report]\nAI isn\u2019t just the future of social media; it\u2019s the engine driving today\u2019s content, strategy, and daily workflows. If you want a real snapshot of how the industry is using artificial intelligence, this is the report you need.\nWe\u2019ve surveyed hundreds of social media managers, freelancers, agency folks, and content creators, and discovered that 96% now use AI for social media tasks, and nearly three-quarters rely on it daily. AI has officially gone from \u201cnice-to-have\u201d to a must-have for virtually every social professional.\nWhat are the most popular AI uses in social media?\nEverything. Social media professionals use AI to brainstorm post ideas (the top use, at 78%) write captions, adapt content to different channels, design graphics, and even automate repetitive work. AI is no longer just a fancy tool for early adopters.\nBut it\u2019s not all about speed. The human touch still matters, 45% of social media professionals say they\u2019re cautious about using more AI because of quality concerns. More than a third admit they don\u2019t track the real performance of their AI-generated content; proof that new tech always comes with new questions.\nDespite the buzz, the hype, and the extremely high levels of adoption, budgets are conservative: half of the respondents rely only on free AI tools, and nearly two-thirds of social media managers have no plans to increase their AI spending this year. Most are focused on getting creative with what they have, finding value in free or low-cost options.\nYou\u2019ll also find quotes, real stats, and actionable benchmarks, like:\n- 79% say AI lets them create more content, faster.\n- 65% use AI for at least half of all their posts.\n- Only 3.6% don\u2019t use AI in their social workflow at all.\nWant the full details? Download the The State of AI in Social Media 2025 Report now:\nSocial media marketing isn\u2019t just about posting\u2026\nWith Metricool, manage your content from start to finish in one place:\nPlan your posts, check out what your competitors are doing, track analytics, and create custom reports all from a single dashboard (no jumping between platforms needed)."
    },
    {
      "url": "https://www.cnet.com/ai-atlas/",
      "text": "Videos\nGoogle Reveals Pixel 10 Devices, White House Launches New TikTok Account and More | Tech Today\nGoogle unveils its latest Pixel lineup at Made by Google, the White House launches a TikTok account ahead of the app's ban deadline and scientists debut a new AI model to better predict solar patterns.\nThe Google Pixel 10 Pro XL's Camera Is So Smart, It Almost Took the Photos for Me\nUp Next\nThe Google Pixel 10 Pro XL's Camera Is So Smart, It Almost Took the Photos for Me\nPixel 10 Is Here! Tech Experts React to Google's Big Reveal\nPixel 10 Is Here! Tech Experts React to Google's Big Reveal\nWatch Jimmy Fallon Demo the Latest Pixel AI Features at the Made by Google Event\nWatch Jimmy Fallon Demo the Latest Pixel AI Features at the Made by Google Event\nRick Osterloh Talks Gemini and Google's AI Future at the Made by Google Event\nRick Osterloh Talks Gemini and Google's AI Future at the Made by Google Event\nGoogle Gemini Is Looking to Get More Personal, Will Apple Delay the iPhone 18? | Tech Today\nGoogle Gemini Is Looking to Get More Personal, Will Apple Delay the iPhone 18? | Tech Today\nNvidia's GeForce On Community Update Highlights New Cloud Gaming Features\nNvidia's GeForce On Community Update Highlights New Cloud Gaming Features\nRain Forest Dangers Created with Google AI\nRain Forest Dangers Created with Google AI\nMy Attempt at AI-Created Irish Dancers with Google Flow\nMy Attempt at AI-Created Irish Dancers with Google Flow\nHumanoid Robot Folds Laundry in New Figure 02 AI Demo\nHumanoid Robot Folds Laundry in New Figure 02 AI Demo\nApple Watch Could Become the Perfect AI Gadget\nApple Watch Could Become the Perfect AI Gadget\nElon Musk to Sue Apple Over App Favoritism, YouTube AI Age Verification Sparks Backlash and More | Tech Today\nElon Musk to Sue Apple Over App Favoritism, YouTube AI Age Verification Sparks Backlash and More | Tech Today\nWhat We Expect From the Made by Google Pixel 10 Event\nWhat We Expect From the Made by Google Pixel 10 Event\nThe Hidden Impact of the AI Data Center Boom\nThe Hidden Impact of the AI Data Center Boom\nChatGPT Users Want the Old Models Back, Intel CEO Goes to the White House & More | Tech Today\nChatGPT Users Want the Old Models Back, Intel CEO Goes to the White House & More | Tech Today\nyour trusted source on ai\nCNET has been covering AI for more than two decades. Now we're bringing you a new wave of expert, unique and helpful insights, through in-depth explainers, hands-on product reviews, how-to posts and more, to help you see how AI fits into your life.\nHelpful AI resources\nFAQs\nWhat is AI, in very basic terms?\nWhat is an AI hallucination?\nWhat is an LLM and how does it fit into AI?\nWhat is an AI agent?\nour ai experts\nOur writers and editors know the subject cold. Here are CNET's leading authorities on AI.\nAI Atlas is 100% human-generated. For more, see\nCNET's AI policy."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/metas-first-llamacon-shows-the-tech-giants-still-playing-catch-up/",
      "text": "If you were like me and were expecting Meta's LlamaCon keynote to drop the reasoning model it teased earlier this month or its teacher model, Behemoth, prepare to be disappointed. The company's first AI developers conference was today, and while we didn't get any new models, there were a couple of announcements that helped Meta catch up in what's become an ultracompetitive, fast race to build generative AI. But there wasn't much in its announcements to help it get ahead.\nEvery big tech company is racing to build a model that can handle complex tasks without requiring a ton of computing power (and thus money) to run. Meta's approach to AI has focused on being open-source, which gives developers a peek behind the curtain at how models are built and trained. Chris Cox, Meta's chief product officer, dropped an updated stat, confirming that there have been 1.2 billion downloads of Llama models to date. Between that and the integrations of Meta AI in Facebook, Instagram and WhatsApp, Meta is certainly a major player in the space -- even if it's sometimes late to the party or does things differently.\nHere's everything Meta released today and where that leaves the company in the future in the AI industry.\nMeta AI, the app\nThe company is rebranding its smart glasses Meta View app into a standalone app for its AI, CEO Mark Zuckerberg confirmed via Instagram a few hours before the keynote.\nYou can download the app now. If you can't find it by searching for \"Meta AI\" (like I couldn't), try searching for \"Meta View\" instead.\nThe app is an extension of its chatbot, with voice-mode capabilities meant to let you chat with Meta AI and a \"social discover feed.\" It's not the same as your Instagram or Facebook feeds; you can't find and follow your friends. Instead, you'll see posts from random users' experience with Meta AI, including AI images they created, prompts they asked, and the chatbot's answers.\nCNBC reported the possibility of a standalone Meta AI app in February, but the choice to convert the Meta View app raises bigger questions about Meta's AI and VR future. \"Meta making a play for another compelling phone app looks like a way to try to draw more people into the ecosystem faster than making a pitch to get glasses,\" my colleague and smart glasses expert Scott Stein wrote.\nLlama 4: Where's the reasoning model?\nMeta did not round out its class of Llama 4 models at LlamaCon; instead, Cox just repeated information we mostly knew about Scout and Maverick. CNET reached out to Meta for the most up-to-date information on the release of Behemoth and the Llama 4 reasoning model Zuckerberg introduced earlier this month, but Meta declined to comment.\nThe models available now in the Llama 4 family are Scout and Maverick. Scout is a smaller model designed to run on one Nvidia H100 GPU (with a 10-million-token context window), and Maverick is the next level up with more power.\nThere was some confusion back when Meta released the benchmarking scores for Llama 4. The company initially said Maverick outperformed OpenAI's GPT-4o. But eagle-eyed experts saw, and the benchmarking organization confirmed, that the Maverick model submitted for testing wasn't the same model people could actually use now; it was \"optimized for conversationality.\" Meta denied training the model on post-testing data, which is a big no-no because that could give the model an unfair edge in benchmarking tests and not accurately assess its performance.\nMeta's AI policy states that it does train its models on information shared on Meta Platforms and with content you share with the chatbot. The company recently ended its opt-out option for European users, so this applies to them as well. You can check out Meta's full privacy policy for more info.\nMeta's Llama API platform\nDevelopers who want to build using Meta AI got good news on Tuesday when Meta announced it is going to begin previewing its Llama API, an upcoming developer platform for Llama application development. Devs can request early, experimental access to Llama 4 fast inference now.\n\"You should be able to take these custom models with you, whenever you want, no locking, ever,\" said Manohar Paluri, Meta's vice president of AI. He also called out that speed, ease of use and customization should be the hallmarks of using the Llama API. The new Llama 4 models, Scout and Maverick, will be included in the API.\nAngela Fan, a research scientist in generative AI at Meta, also highlighted that the API privacy policy is a bit different from the regular Meta AI policy. When you use the API, Meta will not train on the inputs (your prompts and things you upload) or on the outputs (what it spits out). This is good for developers who want to build models for enterprises or businesses but need to ensure the data they upload stays secure.\nWhat's next for Meta AI?\nThe announcements at LlamaCon help Meta catch up to its competitors but doesn't put them ahead of the curve, which might spell trouble for the future. There's still no word on when Meta will release Behemoth or the reasoning model it promised in its Llama 4 drop.\nThe Meta View app is fine, but it really just helps Meta level the playing field. Most of the major AI players, including OpenAI, Claude and Perplexity, already have mobile apps. For Meta smart glasses users, the app's evolution might point to how AI will be at the forefront of those offerings.\nI left the keynote thinking that Meta is consistently late to the AI party -- OpenAI, Google and DeepSeek all have reasoning models already out now. As I wrote in my review of Meta AI last year, there's nothing wrong with being behind if the company comes out swinging. But so far, that doesn't seem to be the case.\nI think the most surprising thing was the social discover feed in the Meta AI app. With all of Meta's expertise in building social platforms, the discover/explore page could be a promising (though unlikely) replacement for people to flood that feed with AI instead of Facebook or Instagram. It's certainly something to watch, especially as Meta updates the app and moves forward with AI.\nFor more, check out our review of the best AI chatbots."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/features/ai-data-centers-are-coming-for-your-land-water-and-power/",
      "text": "From the outside, this nondescript building in Piscataway, New Jersey, looks like a standard corporate office surrounded by lookalike buildings. Even when I walk through the second set of double doors with a visitor badge slung around my neck, it still feels like I'll soon find cubicles, water coolers and light office chatter.\nInstead, it's one brightly lit server hall after another, each with slightly different characteristics, but all with one thing in common -- a constant humming of power.\nThe first area I see has white tiled floors and rows of 7-foot-high server racks protected by black metal cages. Inside the cage structure, I feel cool air rushing from the floor toward the servers to prevent overheating. The wind muffles my tour guide's voice and I have to shout over the noise for him to hear me.\nOutside the structure it's quieter but there's still a white noise that reminds me of the whooshing parents use to get newborn babies to sleep. On the back of the servers, I see hundreds of cords connected -- blue, red, black, yellow, orange, green. In a distant server, green lights are flashing. These machines, dozens of them, are gobbling electricity. In all, this building can support up to 3 megawatts of power.\nThis is a data center. Facilities like it are increasingly common across the US, sheltering the machinery that makes our online lives not only possible, but nearly seamless. Data centers host our photos and videos, stream our Netflix shows, handle financial transactions and so much more. The one I'm visiting, owned by a company called DataBank, is modest in scope. The ones coming in one after another to suburban communities and former farmlands across the US, riding the tidal wave of artificial intelligence's swift advances, are monstrous.\nIt's a building boom based on generative AI. In late 2022, OpenAI launched ChatGPT and within two months it had approximately 100 million users and had spurred a frantic scramble among the biggest tech companies and a host of newborn startups. Now, it has nearly 700 million active users each week and 5 million paying business users. We are inundated with chatbots, image generators and speculation about superintelligence looming in the not-too-distant future. AI is being woven into our everyday lives, from banking and shopping to education and language learning.\nAmazon, Apple, Google, Meta, Microsoft and OpenAI are all spending massive amounts of money to drive that growth. The Trump administration has also made it clear that it wants the US to lead AI innovation across the globe.\n\"We need to build and maintain vast AI infrastructure and the energy to power it,\" the White House said in July in a document called America's AI Action Plan, which calls for streamlined construction permitting and the removal of environmental regulations. \"Simply put, we need to 'Build, Baby, Build!'\"\nBuilding, and building big, is very much on the mind of Meta CEO Mark Zuckerberg. He's been touting his company's plans for an AI data center in Louisiana, nicknamed Hyperion, that would be large enough to cover \"a significant part of the footprint of Manhattan.\"\nAll of that is adding up to an enormous demand for electricity and water to run and cool those new data centers. Generative AI requires energy-intensive training of large language models to do its impressive feats of computing. Meanwhile, a single ChatGPT query uses 10 times more energy than a standard Google search, and with millions of queries every day -- not just from ChatGPT but also from the likes of Anthropic's Claude, Google's Gemini and Microsoft's Copilot -- that's a staggering increase in the stresses on the US electrical grid and local water supplies.\nIn this article:\n\"Data centers are a critical part of the AI production process and to its deployment,\" said Ramayya Krishnan, professor of management science and information systems at Carnegie Mellon University's Heinz College. \"Think of them as AI factories.\"\nBut as data centers grow in size and number, often drastically changing the landscape around them, questions are looming: What are the impacts on the neighborhoods and towns where they're being built? Do they help the local economy or put a dangerous strain on the electric grid and the environment?\nAI growth has caused a data center boom\nOn the outskirts of communities across the country -- and sometimes smack dab in the middle of cities like New York -- giant AI data centers are springing up.\nMeta, for instance, is investing $10 billion into its 4-million-square-foot Hyperion data center, planned to open by 2030. An explosion of construction is likely coming to Pennsylvania. In July, at an energy summit in Pittsburgh attended by President Donald Trump, developers announced upward of $90 billion for AI in the state, including a $25 billion investment from Google.\nPerhaps the most ambitious undertaking is unfolding under the auspices of a new company called the Stargate Project, backed by OpenAI, Oracle, Softbank and others. In late January, on the day that Trump was sworn in to his second term as president, OpenAI said that Stargate would invest $500 billion in AI infrastructure over the next four years.\nAn early signature facility for Stargate, amid reports of early struggles, is a sprawling data center under construction in Abilene, Texas. OpenAI said last month that Oracle had delivered the first Nvidia GB200 racks and that they were being used for \"running early training and inference workloads.\" The publication R&D World has reported that the 875-acre site will eventually require 1.2GW of electricity, or the same amount it would take to power 750,000 homes.\n(Disclosure: Ziff Davis, CNET's parent company, in April filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nCurrently, four tech giants -- Amazon Web Services, Google, Meta and Microsoft -- control 42% of the US data center capacity, according to BloombergNEF. The sky-high spending on AI data centers has become a major contributor to the US economy. Those four companies have spent nearly $100 billion in their most recent quarters on AI infrastructure, with Microsoft investing more than $80 billion into AI infrastructure during the current fiscal year alone.\nNot all data centers in the US handle AI workloads -- Google's data centers, for instance, power services including Google Cloud, Maps, Search and YouTube, along with AI -- but the ones that do can require more energy than small towns. A July report from the US Department of Energy said that AI data centers, in particular, are \"a key driver of electricity demand growth.\"\nFrom 2021 to 2024, the number of data centers in the US nearly doubled, according to report from Frontier Group, the Environment America Research & Policy Center and the U.S. PIRG Education Fund. And according to the National Telecommunications and Information Administration, the need for data centers is expected to increase by 9% each year until at least 2030. By 2035, data centers' US electricity demand is expected to double compared with today's.\nHere's another way to look at it: Speaking before the Senate Commerce Committee in May, Microsoft President Brad Smith said his company estimates that \"over the next decade, the United States will need to recruit and train half a million new electricians to meet the country's growing electricity needs.\"\nAs fast as the AI companies are moving, they want to be able to move even faster. Smith, in that Commerce Committee hearing, lamented that the US government needed to \"streamline the federal permitting process to accelerate growth.\"\nThis is exactly what's happening under the Trump administration. Its AI Action Plan acknowledges that the US needs to \"build vastly greater energy generation\" and lays out a path for getting there quickly. Among its recommendations are creating regulatory exclusions that favor data centers, fast-tracking permit approvals and reducing regulations under the Clean Water Act and the Clean Air Act.\nOne step already taken: The Trump administration rescinded a Biden administration executive order -- outlining the need to ensure AI development and use was done ethically and responsibly -- to reduce \"onerous rules imposed.\"\n'Say no to a data center in our community'\nEarly this year, June Ejk set up the Facebook page called Concerned Clifton Citizens to keep her neighbors informed about the happenings in Clifton Township, Pennsylvania. Now, her main focus is stopping a proposed 1.5GW data center campus from coming to the area that she's called home for the past 19 years.\nThe developer, 1778 Rich Pike, is hoping to build a 34-building data center campus on 1,000 acres that spans Clifton and Covington townships, according to Ejk and local reports. That 1,000 acres includes two watersheds, the Lehigh River and the Roaring Brook, Ejk says, adding that the developer's attorney has said each building would have its own well to supply the water needed.\n\"Everybody in Clifton is on a well, so the concern was the drain of their water aquifers, because if there's that kind of demand for 34 more wells, you're going to drain everybody's wells,\" Ejk says. \"And then what do they do?\"\nEjk, a retired school principal and former Clifton Township supervisor, says her top concerns regarding the data center campus include environmental factors, impacts on water quality or water depletion in the area, and negative effects on the residents who live there.\nHer fears are in line with what others who live near data centers have reported experiencing. According to a New York Times article in July, after construction kicked off on a Meta data center in Social Circle, Georgia, neighbors said wells began to dry up, disrupting their water source.\nThe data center Ejk is hoping to stop hasn't yet been approved -- the developer has to get zoning ordinances amended and signed off on before moving forward -- but Covington Township has shown an interest in the project moving forward. For her part, Ejk has created and shared a \"say no to a data center in our community\" flyer with a call-to-action for her fellow citizens to attend monthly board of supervisors meetings for discussions on the topic.\n\"I worry about the kind of world I'm leaving for my grandchildren,\" Ejk says. \"It's not safer, it's not better, and we're selling out to these big corporations. You know, it's not in their backyard, it's in my backyard.\"\nIf one or both of the townships do decide to move forward with the project, Ejk won't stop there.\n\"I'm going to be telling residents to get your wells tested now, because if, after [the data centers] are built and the quality of your water changes, you will have to have a basis of what changed,\" she said.\n'They have only sold the positives'\nIn Louisiana, some residents are welcoming Meta's planned data center in Richland Parish, the one that Zuckerberg says would cover a large part of Manhattan. Others, like Julie Richmond Sauer, believe it could harm the entire state.\nThe facility will be located between the towns of Rayville, population of roughly 3,300, and Delhi, population 2,500.\n\"It is 2,250 acres of farmland that will never be farmed again,\" Sauer, a registered nurse in central Louisiana, tells me. \"That, of course, is a concern of mine, for my children and my grandchildren one day.\"\nShe also thinks job development, a key selling point for data centers, is often overestimated.\n\"It was sold by our legislators as, 'Hey, we're getting jobs,' which sounds wonderful. 'We're bringing industry in,' which sounds wonderful, but then the more I'm reading, it looks like 500 jobs max,\" Sauer says, who compared the amount with a medium-size hospital.\nLouisiana Economic Development, a state agency, expects the data center to bring in 500 \"direct jobs,\" or permanent ones, to the area, along with 1,000 \"indirect\" jobs and 5,000 construction and temporary jobs at its peak. It's unclear if those construction jobs would go to locals or to workers brought in temporarily from elsewhere. Meanwhile, OpenAI is pitching vastly more jobs for 4.5GW of Stargate data center capacity in the US, should it ever come to pass: 100,000 jobs, \"spread across construction and operations roles.\" But it also acknowledges that the construction jobs would be \"short-term.\"\n\"I just don't think it's enough to sell your soul for,\" Sauer says. \"They have only sold the positives in this and not told the public the negatives, and that's a fact.\"\nShe believes ultimately that the decision on where to put these data centers should fall on a statewide public vote.\nThere are currently more than 5,000 data centers in the US. While no state is completely free of these computing facilities, some states, such as Virginia, have become magnets for them. Ashburn, Virginia, alone boasts 140 data centers of the more than 500 in the state, earning the area the nickname \"Data Center Alley.\"\nTexas and California, meanwhile, have more than 300 each.\nVirginia is attractive for data centers thanks to tax incentives, fiber optic infrastructure and a skilled workforce. Other states are actively trying to attract data centers by offering incentives, too. But concerns are rising regarding these tax breaks and who ends up picking up the bill.\n\"More than 20 states are offering tax breaks to data centers in an effort to incentivize them to come to their state,\" Quentin Good, a policy analyst at Frontier Group, tells me. \"So data centers are often given exemptions on things like the sales tax for all of the equipment that they need to fill up their data centers, and that ultimately falls on taxpayers to pay for the cost of those tax breaks.\"\nHow much energy do AI data centers use?\nNo matter where they're located, all data centers require a lot of power. According to the International Energy Agency, the US accounted for the largest share of global data center electricity consumption in 2024, at 45%.\nThe Trump administration has emphasized the need to strengthen the grid to support the coming tidal wave of data centers. The president has gone so far as to declare the situation a national energy emergency.\n\"The United States is experiencing an unprecedented surge in electricity demand driven by rapid technological advancements, including the expansion of artificial intelligence data centers and an increase in domestic manufacturing,\" an April executive order reads.\nTo combat this issue, the government wants to use all available power sources, monitor the US electricity supply closely and follow the new AI Action Plan.\n\"We've [previously] had really stable electricity demand increases of like 2% or 3%, but with a recent boom in data centers and the electrification of other things, like our homes and our vehicles, the [projected] demand for electricity is starting to jump up dramatically,\" Good says.\nLast month, a report from the Department of Energy warned that updates to the country's electric grid are imperative for grid reliability caused by AI's escalating demands.\n\"Absent intervention, it is impossible for the nation's bulk power system to meet the AI growth requirements while maintaining a reliable power grid and keeping energy costs low for our citizens,\" the report says.\nAI's growth and the need for more data centers to support it are rapidly increasing the stress on the US energy grid. This strain is causing \"a lower system stability,\" the North American Electric Reliability Corporation's 2025 State of Reliability found. The US energy grid, built in the 1960s and '70s, was not designed to handle the energy pull AI is creating.\nAt the end of 2023, the US energy grid -- which supports every request for electricity, from your home's lighting and air conditioning to massive industrial processes -- could handle about 1,189 gigawatts.\nMeta's Hyperion, for example, will have a capacity of 2 gigawatts, or 2,000 megawatts. That's a roughly 30 times greater demand for electricity than at DataBank's EWR2 location.\n\"What we're seeing with new data centers is just the size difference,\" John Moura, NERC's director of reliability assessment and performance analysis, tells me. \"For the past decade, we've probably seen a couple hundred megawatts as kind of your largest ones. Now we see interconnection requests for one or two or, I think I heard about 5-gigawatt requests, and that really changes the fundamentals of how the system is planned.\"\nThe Alliance for Affordable Energy is challenging Meta's Louisiana data center -- calling it \"a power-hungry giant\" -- along with Entergy Louisiana's bid to build three gas plants to power it. Citing expert testimony, the group is sounding the alarm about a potentially debilitating strain on the electric grid and the cost to the citizens of Louisiana.\n\"It's not exactly black and white in terms of who's paying for the [data center's] upgrades that are needed,\" Good says, adding that utilities have an obligation to serve all customers. \"If any customer moves into their service area, they have to meet that customer's needs in terms of electricity.\"\nSo, regardless of the scale of a data center, if they get approved to build in any town, the utility must provide the energy needed to power it. A large customer moving into the area could also cause a \"short-term constraint on the supply of energy.\"\n\"That's going to push utility prices up for everyone who's a customer of that utility,\" Good says.\nA study by Carnegie Mellon University and North Carolina State University, published in June, says that electricity rates could rise 8% on average across the US through 2030 because of increased demand from data centers, along with cryptocurrency generation. Electricity rates in northern Virginia, a hub of data center activity, could jump more than 25%.\nIn a bid for additional energy sources, tech companies are turning to nuclear power as a possible solution, but Moura says nuclear power is still at least \"a couple of years out.\"\n\"In the next five years, there's not too many options to build generation, and so [energy] storage can help, but it's not a source of generation,\" Moura says. Meta has said it will begin using nuclear energy in 2027, with Amazon and Google hoping to use nuclear energy sometime in the 2030s.\nEnvironmental impact\nThe water consumption of these data centers, specifically ones that help power AI, has been top of mind for many. Data centers use water to cool the servers. This use is something that tech companies have tried -- and often failed -- to keep quiet.\nIn 2022, after the newspaper The Oregonian sought records about Google's water use for a data center in The Dalles, the Oregon city sued to stop the paper from releasing the information. Eventually, the paper did receive the information, which revealed that in 2021, the Google data center used a staggering 355 million gallons of water, which is roughly equal to 538 Olympic-size swimming pools.\nThe Oregonian's reporting helped shine a light on the natural resources these data centers need to run, and, maybe more important, it opened the question of whether our finite resources can handle the demand.\nAccording to Google's 2024 environmental report, the company's location that used the most water in 2023 was Council Bluffs, Iowa, home to two data centers, one built in 2007 and the other in 2012. In 2023, the Council Bluffs facilities sucked in 1.3 billion gallons of water from the local water supply. Google spent $1 billion in 2024 to expand the facility, and that year the intake rose to 1.4 billion gallons.\nMeta's 2024 sustainability report doesn't break down water use by data center; it just gives an aggregate number. In 2023, its data centers worldwide took in 1.39 billion gallons of water. Just less than 50% of that was permanently removed from local water sources. Between 2019 and 2023, Meta's data center water withdrawal increased by roughly 43%, but it still uses significantly less water than Google's data centers as a whole.\nWhen data centers consume water, a significant amount evaporates during the cooling process. The remaining water, which is often polluted, is put into the city's wastewater system.\nBoth companies have stated they plan to be \"water positive\" by 2030, meaning they want to return more water to the communities than what the data centers consume through water recycling, reusing and water replenishment projects. However, returning water to the exact source the data center drew from is not always possible. Instead, Google states it attempts to improve additional water sources in the area, restore wetlands and recycle treated wastewater in an effort to counter its water usage.\nAre climate pledges enough?\nEven as big tech companies invest heavily in AI, they also continue to promote their sustainability goals. Amazon, for example, aims to reach net-zero carbon emissions by 2040. Google has the same goal but states it plans to reach it 10 years earlier, by 2030. With AI's rapid advancement, experts no longer know if those climate goals are attainable, and carbon emissions are still rising.\n\"Wanting to grow your AI at that speed and at the same time meet your climate goals are not compatible,\" Good says.\nFor its Louisiana data center, Meta has \"pledged to match its electricity use with 100% clean and renewable energy\" and plans to \"restore more water than it consumes,\" the Louisiana Economic Development statement reads.\nHowever, questions remain around these promises. US Sen. Sheldon Whitehouse of Rhode Island, the top Democrat on the Senate Committee on Environment and Public Works, questioned Meta and Zuckerberg in an official inquiry in May, labeling those climate pledges as \"vague.\" Whitehouse said he believes Meta is putting the need for data centers and natural gas generation \"over climate safety.\" Meta has not yet responded.\nGoogle's 2025 Environmental Report shows a 51% increase in carbon emissions in 2024 compared with 2019, despite its sustainability efforts outlined in the report.\nDataBank, although smaller in scale, also has a sustainability goal tied to its more than 65 locations. It plans to achieve net-zero carbon emissions by 2030.\nJenny Gerson, DataBank's sustainability chief, tells me that DataBank has decreased emissions through \"procuring renewable power on the grid\" and is looking at alternative fuel sources to replace diesel fuel, including hydro-treated vegetable oil.\n\"So instead of pulling more fossil fuels out of the ground and burning them, you're using a plant-based source that has a much shorter carbon cycle and leaving the fossil fuels in the ground,\" Gerson explains.\nDataBank is also prioritizing minimizing energy use by switching to LED lightbulbs throughout its data centers, optimizing air flow to keep cool air around the servers and using closed-loop water systems, \"meaning you fill the loop once, and then whatever water or glycol is in there remains in there, and you do not consume more water,\" she says.\nMicrosoft is currently transitioning new data centers to closed-loop systems.\nOther possible solutions include creating flexible data centers, meaning they can pull less energy from the grid when energy usage in the surrounding community is expected to be high, such as during a heat wave or when severe weather is incoming.\nMeta and Google are founding members of the Electric Power Research Institute's DCFlex initiative, which aims to make more data centers flexible and help the energy grid remain reliable.\n\"Obviously, everyone wants to use the internet, they want to use AI, and we need to do it responsibly,\" Gerson says. \"So how can we as players do that? And a lot of that is making sure we're doing it through renewable power.\"\nIs there a data center near you?\nThere's at least one data center in each US state, and plenty more are on the horizon. If you don't live near one now, there's a good chance you will soon.\nIf you live in an area that isn't prone to natural disasters and boasts natural resources, such as an abundance of water or robust wind, tech companies may be eyeing the spot for an AI factory. Google tells me it has \"a very rigorous process to select sites, which includes factors like proximity to customers and users, local talent, land, a community that's excited to work with us and availability of (or potential to bring new) carbon-free energy.\"\nThe Trump administration's AI Action Plan emphasizes the need for more data centers, electricians and HVAC technicians for the US to win the AI race.\nMany of the new data centers being built are massive and impossible to miss. There will be smaller ones as well, like Databank's EWR2 facility that I visited in Piscataway -- and lots of them. The quiet in the hallways, with the powerful computing servers tucked away behind closed doors, is a stark contrast to the busy, noisy construction activity taking place across the country.\nThose smaller data centers use less power and water, and they employ far fewer people -- and they're often hiding in plain sight.\nVisual Design and Motion | Tharon Green\nArt Director | Jeff Hazelwood\nCreative Director | Viva Tung\nVideo Editors | Dillon Payne, Owen Poole, JD Christison\nProject Manager | Danielle Ramirez\nEditors | Corinne Reichert, Jon Reed\nDirector of Content | Jonathan Skillings"
    },
    {
      "url": "https://techcrunch.com/2025/08/03/the-uproar-over-vogues-ai-generated-ad-isnt-just-about-fashion/",
      "text": "Sarah Murray recalls the first time she saw an artificial model in fashion: It was 2023, and a beautiful young woman of color donned a Levi\u2019s denim overall dress. Murray, a commercial model herself, said it made her feel sad and exhausted.\nThe iconic denim company had teamed up with the AI studio Lalaland.ai to create \u201cdiverse\u201d digital fashion models for more inclusive ads. For an industry that has failed for years to employ diverse human models, the backlash was swift, with New York Magazine calling the decision \u201cartificial diversity.\u201d\n\u201cModeling as a profession is already challenging enough without having to compete with now new digital standards of perfection that can be achieved with AI,\u201d Murray told TechCrunch.\nTwo years later, her worries have compounded. Brands continue to experiment with AI-generated models, to the consternation of many fashion lovers. The latest uproar came after Vogue\u2019s July print edition featured a Guess ad with a typical model for the brand: thin yet voluptuous, glossy blond tresses, pouty rose lips. She exemplified North American beauty standards, but there was one problem \u2014 she was AI generated.\nThe internet buzzed for days, in large part because the AI-generated beauty showed up in Vogue, the fashion bible that dictates what is and is not acceptable in the industry. The AI-generated model was featured in an advertisement, not a Vogue editorial spread. And Vogue told TechCrunch the ad met its advertising standards.\nTo many, an ad versus an editorial is a distinction without a difference.\nTechCrunch spoke to fashion models, experts, and technologists to get a sense of where the industry is headed now that Vogue seems to have put a stamp of approval on technology that\u2019s poised to dramatically change the fashion industry.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil \u2014 just a few of the heavy hitters joining the Disrupt 2025 agenda. They\u2019re here to deliver the insights that fuel startup growth and sharpen your edge. Don\u2019t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech \u2014 grab your ticket now and save up to $600+ before prices rise.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital \u2014 just a few of the heavy hitters joining the Disrupt 2025 agenda. They\u2019re here to deliver the insights that fuel startup growth and sharpen your edge. Don\u2019t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech \u2014 grab your ticket now and save up to $675 before prices rise.\nThey said the Guess ad drama highlights questions arising within creative industries being touched by AI\u2019s silicon fingers: When high-quality creative work can be done by AI in a fraction of the time and cost, what\u2019s the point of humans? And in the world of fashion, what happens to the humans \u2014 the models, photographers, stylists, and set designers \u2014 performing those jobs?\n\u201cIt\u2019s just so much cheaper\u201d\nSinead Bovell, a model and founder of the WAYE organization who wrote about CGI models for Vogue five years ago, told TechCrunch that \u201ce-commerce models\u201d are most under threat of automation.\nE-commerce models are the ones who pose for advertisements or display clothes and accessories for online shoppers. Compared to high-fashion models, whose striking, often unattainable looks are featured in editorial spreads and on runways, they\u2019re more realistic and relatable.\n\u201cE-commerce is where most models make their bread and butter,\u201d Bovell said. \u201cIt\u2019s not necessarily the path to model fame or model prestige, but it is the path for financial security.\u201d\nThat fact is running in direct contrast to the pressure many brands feel to automate such shoots. Paul Mouginot, an art technologist who has worked with luxury brands, said it\u2019s simply expensive to work with live models, especially when it comes to photographing them in countless garments, shoes, and accessories.\n\u201cAI now lets you start with a flat-lay product shoot, place it on a photorealistic virtual model, and even position that model in a coherent setting, producing images that look like genuine fashion editorials,\u201d he told TechCrunch.\nBrands, in some ways, have been doing this for a while, he said. Mouginot, who is French, cited the French retailer Veepee as an example of a company that has used virtual mannequins to sell clothes since at least 2013. Other notable brands like H&M, Mango, and Calvin Klein have also resorted to AI models.\nAmy Odell, a fashion writer and author of a recently published biography on Gwyneth Paltrow, put it more simply: \u201cIt\u2019s just so much cheaper for [brands] to use AI models now. Brands need a lot of content, and it just adds up. So if they can save money on their print ad or their TikTok feed, they will.\u201d\nPJ Pereira, co-founder of AI ad firm Silverside AI, said it really comes down to scale. Every conversation he\u2019s had with fashion brands circles around the fact that the entire marketing system was built for a world where brands produced just four big pieces of content per year. Social media and e-commerce has changed that, and now they need anywhere from 400 to 400,000 pieces; it\u2019s too expensive for brands, especially small ones, to keep up.\n\u201cThere\u2019s no way to scale from four to 400 or 400,000 with just process tweaks,\u201d he added. \u201cYou need a new system. People get angry. They assume this is about taking money away from artists and models. But that\u2019s not what I\u2019ve seen.\u201d\nFrom \u201cdiverse\u201d models to AI avatars\nMurray, a commercial model, understands the cost benefits of using AI models, but only to an extent.\nShe lamented that brands like Levi\u2019s claim AI is only meant to supplement human talent, not take away.\n\u201cIf those [brands] ever had the opportunity to stand in line at an open casting call, they would know about the endless amounts of models, including myself, that would dream of opportunities to work with their brands,\u201d she said. \u201cThey would never need to supplement with anything fake.\u201d\nShe thinks such a shift will impact \u201cnon-traditional\u201d \u2014 think, diverse \u2014 commercial models, such as herself. That was the main problem with the Levi\u2019s ad. Rather than hiring diverse talent, it artificially generated it.\nBovell calls this \u201crobot cultural appropriation,\u201d or the idea that brands can just generate certain, especially diverse, identities to tell a brand story, even if the person who created the technology isn\u2019t of that same identity.\nAnd though Pereira argues that it\u2019s unrealistic to shoot every garment on every type of model, that hasn\u2019t calmed the fears many diverse models have about what\u2019s to come.\n\u201cWe already see an unprecedented use of certain terms in our contracts that we worry indicate that we are possibly signing away our rights for a brand to use our face and anything recognizable as ourselves to train their future AI systems,\u201d Murray said.\nSome see generating likenesses of models as a way forward in the AI era. Sara Ziff, a former model and founder of the Model Alliance, is working to pass the Fashion Workers Act, which would require brands to get a model\u2019s clear consent and provide compensation for using their digital replicas. Mouginot said this lets models appear at several shoots on the same day and possibly generate additional income.\nThat\u2019s \u201cprecious when a sought-after model is already traveling constantly,\u201d he continued. But at the same time, whenever an avatar is hired, human labor is replaced. \u201cWhat few players gain can mean fewer opportunities for many others.\u201d\nIf anything, Bovell said the bar is now higher for models looking to compete with the distinctive and the digitized. She suggested that models use their platforms to build their personal brands, differentiate themselves, and work on new revenue streams like podcasting or brand endorsements.\n\u201cStart to take those opportunities to tell your unique human story,\u201d she said. \u201cAI will never have a unique human story.\u201d\nThat sort of entrepreneurial mindset is becoming table stakes across industries \u2014 from journalism to coding \u2014 as AI creates the conditions for the most self-directed learners to rise.\nRoom for another view\nMouginot sees a world where some platforms stop working with human models altogether, though he also believes humans share a desire for the \u201csensual reality of objects, for a touch of imperfection and for human connection.\u201d\n\u201cMany breakthrough models succeed precisely because of a distinctive trait, teeth, gaze, attitude, that is slightly imperfect by strict standards yet utterly charming,\u201d he said. \u201cSuch nuances are hard to erode in zeros and ones.\u201d\nThis is where startup and creative studio Artcare thrives, according to Sandrine Decorde, the firm\u2019s CEO and co-founder. She refers to her team as \u201cAI artisans,\u201d creative people who use tools like Flux from Black Forest Labs to fine-tune AI-generated models that have that touch of unique humanity.\nMuch of the work Decorde\u2019s firm does today involves producing AI-generated babies and children for brands. Employing minors in the fashion industry has historically been a gray area rife with exploitation and abuse. Ethically, Decorde argues, bringing generative AI to children\u2019s fashion makes sense, particularly when the market demand is so high.\n\u201cIt\u2019s like sewing; it\u2019s very delicate,\u201d she told TechCrunch, referring to creating AI-generated models. \u201cThe more time we spend on our datasets and image refinements, the better and more consistent our models are.\u201d\nPart of the work is building out a library of distinctive artifacts. Decorde noted that many AI-generated models \u2014 like the ones created by Seraphinne Vallora, the agency behind Vogue\u2019s Guess ad \u2014 are too homogenous. Their lips are too perfect and symmetrical. Their jawlines are all the same.\n\u201cImagery needs to make an impact,\u201d Decorde said, noting that many fashion brands like to work exclusively with certain models, a desire that has spilled over into AI-generated models. \u201cA model embodies a fashion brand.\u201d\nPereira added that his firm combats homogeneity in AI \u201cwith intention\u201d and warned that as more content gets made by more people who aren\u2019t intentional, all of the output feeds back into computer models, amplifying bias.\n\u201cJust like you would cast for a wide range of models, you have to prompt for that,\u201d he said. \u201cYou need to train [models] with a wide range of appearances. Because if you don\u2019t, the AI will reflect whatever biases it was trained on.\u201d\nAn AI future is promised, but uncertain\nThe usage of AI modeling technology in fashion is mostly still in its experimental phase, Claudia Wagner, founder of modeling booking platform Ubooker, told TechCrunch. She and her team saw the Guess ad and said it was interesting technically, but it wasn\u2019t impactful or new.\n\u201cIt feels like another example of a brand using AI to be part of the current narrative,\u201d she told TechCrunch. \u201cWe\u2019re all in a phase of testing and exploring what AI can add \u2014 but the real value will come when it\u2019s used with purpose, not just for visibility.\u201d\nBrands are getting visibility from using AI \u2014 and the Guess ad is the latest example. Pereira said his firm recently tested a fully AI-generated product video on TikTok that got more than a million views with mostly negative comments.\n\u201cBut if you look past the comments, you see that there\u2019s a silent majority \u2014 almost 20x engagement \u2014 that vastly outnumber the criticism,\u201d he continued. \u201cThe click-through rate was 30x the number of complaints, and the product saw a steep hike in sales.\u201d\nHe, like Wagner, doesn\u2019t think AI models are going away anytime soon. If anything, the process of using AI will be integrated into the creative workflow.\n\u201cSome brands feel good about using fully artificial models,\u201d Pereira said. \u201cOthers prefer starting with real people and licensing their likeness to build synthetic shoots. And some brands simply don\u2019t want to do it \u2014 they worry their audiences won\u2019t accept it.\u201d\nWagner said what is becoming evident is that human talent remains central, especially when authenticity and identity are part of a brand\u2019s story. That\u2019s especially true for luxury heritage brands, which are usually slow to adopt new technologies.\nThough Decorde noted many high-fashion brands are quietly experimenting with AI, Mouginot said many are still trying to define their AI policies and are avoiding fully AI-generated people at the moment. It\u2019s one reason why Vogue\u2019s inclusion of an AI model was such a shock.\nBovell pondered if the ad was Vogue\u2019s way of testing how the world would react to merging high fashion with AI.\nSo far the reaction hasn\u2019t been great. It\u2019s unclear if the magazine thinks it can ride out the backlash.\n\u201cWhat Vogue does matters,\u201d Odell said. \u201cIf Vogue ends up doing editorials with AI models, I think that\u2019s going to make it okay. In the same way the industry was really resistant to Kim Kardashian and then Vogue featured her. Then it was okay.\u201d"
    }
  ],
  "argos_summary": "The rise of generative AI is significantly impacting social media and the fashion industry, with 96% of social media managers now using AI tools for tasks like content creation and strategy. In fashion, brands are increasingly employing AI-generated models for advertising, raising concerns among human models about job security and authenticity. Critics argue that this trend could lead to a homogenization of representation and a loss of human connection in creative industries, while proponents highlight the cost-effectiveness and scalability of AI in meeting the growing demand for content.",
  "argos_id": "DJBJIYSYP"
}