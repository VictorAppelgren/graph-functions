{
  "url": "https://www.macrumors.com/2025/08/08/openai-gpt-5-complaints/",
  "authorsByline": "Juli Clover",
  "articleId": "209d7d25d7ed4b2bbfd03fa7cfc64d2f",
  "source": {
    "domain": "macrumors.com",
    "paywall": false,
    "location": null
  },
  "imageUrl": "https://images.macrumors.com/t/_DO3VmlEIeePypjZ61U9_WgQ3-8=/2000x/article-new/2025/04/chatgpt-logo.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-08T14:22:35-07:00",
  "addDate": "2025-08-08T21:32:56.779380+00:00",
  "refreshDate": "2025-08-08T21:32:56.779383+00:00",
  "score": 1.0,
  "title": "ChatGPT Plus Users Can Keep Using GPT-4o After Complaints About GPT-5",
  "description": "OpenAI CEO Sam Altman today said that the company will allow Plus users to continue to use the prior-generation GPT-4o model if they don't want...",
  "content": "OpenAI CEO Sam Altman today said that the company will allow Plus users to continue to use the prior-generation GPT-4o model if they don't want to use the new GPT-5 model that came out yesterday.\n\n\n\nAs noted by The Wall Street Journal's Joanna Stern, there were some ChatGPT users who were upset that OpenAI replaced prior ChatGPT models with GPT-5 with no warning. Some people had become accustomed to the tone and feel of GPT-4o, and did not feel that the GPT-5 model was able to replicate it.\n\nThere are multiple complaints on Reddit about GPT-5's lack of personality compared to GPT-4o, and from people who feel that GPT-5 isn't able to complete the same tasks. Users have also complained about GPT-5 offering replies that are too short, and about hitting usage limits too quickly.\n\nAltman says that Plus users can choose to continue to use 4o, and that OpenAI will watch usage and consider how long legacy models should continue to be supported.\n\nTo address the other complaints, GPT-5 rate limits for ChatGPT Plus users will be doubled as the GPT-5 rollout is completed. It is taking longer than expected for OpenAI to deploy GPT-5 to all users, and some people are not yet seeing GPT-5 as an option.\n\nGoing forward, GPT-5 should seem smarter, Altman said. There was apparently an issue with the autoswitcher yesterday that caused GPT-5 to seem \"way dumber.\" OpenAI also plans to make it more clear about which model is answering a query, and will update the UI to make it easier to manually trigger thinking. Altman says that OpenAI will continue to listen to user feedback going forward.\n\nStarting with iOS 26, the ChatGPT feature that's integrated into Siri will use the GPT-5 model. Until then, it will continue to use the prior ChatGPT models.",
  "medium": "Article",
  "links": [
    "https://www.macrumors.com/guide/siri/",
    "https://www.reddit.com/r/ChatGPT/",
    "https://www.macrumors.com/roundup/ios-26/",
    "https://www.macrumors.com/guide/wsj-com/",
    "https://www.macrumors.com/guide/openai/",
    "https://x.com/sama/status/1953893841381273969",
    "https://joannastern.beehiiv.com/p/gpt-5-and-when-your-favorite-ai-dies-624d9b6db09594e3",
    "https://www.reddit.com/r/ChatGPT/comments/1mkt8hv/chatgpt_5_is_the_worst_model_ever_feeling_really/"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "GPT-5 model",
      "weight": 0.1495768
    },
    {
      "name": "ChatGPT Plus Users",
      "weight": 0.12900627
    },
    {
      "name": "ChatGPT Plus users",
      "weight": 0.12900627
    },
    {
      "name": "GPT-5",
      "weight": 0.12659466
    },
    {
      "name": "prior ChatGPT models",
      "weight": 0.12446808
    },
    {
      "name": "GPT-5 rate limits",
      "weight": 0.12377998
    },
    {
      "name": "Plus users",
      "weight": 0.11439557
    },
    {
      "name": "ChatGPT Plus",
      "weight": 0.1062658
    },
    {
      "name": "legacy models",
      "weight": 0.098944165
    },
    {
      "name": "user feedback",
      "weight": 0.09818114
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.94287109375
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.837890625
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.402099609375
    }
  ],
  "sentiment": {
    "positive": 0.04840088,
    "negative": 0.69091797,
    "neutral": 0.2607422
  },
  "summary": "OpenAI CEO Sam Altman has announced that ChatGPT Plus users can continue to use the prior-generation GPT-4o model, despite complaints about GPT 5's lack of personality and inability to perform tasks. Users also complained about short replies and hitting usage limits too quickly. Altman stated that Plus users could continue using 4o and that OpenAI will monitor usage and consider how long legacy models should continue to be supported. He also announced that GPT5 rate limits will be doubled to address other complaints related to its rollout. Starting with iOS 26, Siri will use the Gpt-5 model.",
  "shortSummary": "OpenAI will allow ChatGPT Plus users to continue using GPT-4o while addressing complaints about GPT's personality and usage issues.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": true,
  "reprintGroupId": "a868e8c529074ec9ad1b0e6dce577973",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.macrumors.com/guide/siri/",
      "text": "Siri is the voice assistant on Apple devices, equivalent to Amazon's Alexa, Microsoft's Cortana, and Google's Google Assistant. Siri is available across most of Apple's devices, including iPhone, iPad, Mac, Apple Watch, Apple TV, and HomePod.\nYou can ask Siri all kinds of questions, from simple queries about the weather to more complex questions about everything from sports scores to the number of calories in food. Siri can also enable or disable settings, find content, set alarms and reminders, place calls and texts, and so much more.\nThis guide covers the basics of Siri, including some of the commands you can use to activate Siri, devices that have Siri included, and devices that support more advanced hands-free \"Hey Siri\" commands.\nActivating Siri\nOn an iPhone or iPad, Siri can be activated by holding the Home button on compatible models or holding the Side button on devices without a Home button. On iOS 14 and later, on the iPhone and the iPad, Siri pops up as a small icon at the bottom of the device's display, and on devices capable of Apple Intelligence, there is a Siri glow around the display that denotes that the personal assistant is activated.\nOn the Mac, you can click on the Siri app icon on the dock or the menu bar, or press and hold the command key and the space bar. On iPhones, iPads, and Macs, you can activate Siri with a \"Hey Siri\" wake word.\nOn the Apple Watch, you can say \"Hey Siri\" to activate Siri. On Apple Watch Series 3 or later with the latest version of watchOS, there's a Raise to Speak feature that lets Siri respond to commands even without the Hey Siri trigger word. Just hold the watch up near your mouth and speak a command. Siri can also be activated by holding down on the Digital Crown.\nOn first-generation AirPods, a double tap activates Siri, and on second-generation AirPods, Siri can be activated with the \"Hey Siri\" command.\nOn HomePod, say \"Hey Siri\" or press on the top of the HomePod to activate Siri.\nOn the fourth and fifth-generation Apple TV, hold down the Siri button on the remote (the button with the microphone) to activate Siri. On the sixth-generation Apple TV or models with the newer Siri Remote (the aluminum remote), press on the side button to activate Siri.\nDevices Compatible With Siri\nSiri is on almost every Apple device, and it's built into macOS, iOS, watchOS, and tvOS. You can activate Siri on Macs running macOS Sierra or later, all Apple Watch models, the Apple TV HD and Apple TV 4K, all modern iPhones, all AirPods models, the HomePod, and the HomePod mini.\nMultiple Siri Devices\nWhen multiple devices that can respond to \"Hey Siri\" commands are available, the devices will use Bluetooth to determine which one should respond to the request so not all of them answer at once. According to Apple, the device that heard you best or the device that was most recently raised or used will respond.\nIf you have a HomePod, the HomePod will often take precedent and respond to \"Hey Siri\" requests even when other devices that support the feature are nearby.\nCountries Where Siri Support is Available\nSiri is available in more than 35 countries around the world, including the U.S., UK, Canada, Australia, New Zealand, and many countries in Asia and Europe.\nA full list of countries where Siri is available can be found on Apple's Feature Availability website.\nCertain Siri features like translations, sports info, restaurant information and reservations, movie information and showtimes, dictionary, calculations, and conversions are limited to a smaller number of countries.\nWhat Siri Can Do\nBelow is a list of some of the commands and questions Siri is able to respond to, and some of the actions Siri is able to take.\n- Make calls/Initiate FaceTime\n- Send/read texts\n- Send messages on third-party messaging apps\n- Set alarms/timers\n- Set reminders/check calendar\n- Split a check or calculate a tip\n- Play music (specific songs, artists, genres, playlists)\n- Identify songs, provide song info like artist and release date\n- Control HomeKit products\n- Play TV shows and movies, answer questions about them\n- Do translations and conversions\n- Solve math equations\n- Offer up sports scores\n- Check stocks\n- Surface photos based on person, location, object, and time\n- Apple Maps navigation and directions\n- Make reservations\n- Open and interact with apps\n- Find files (on Mac)\n- Send money via Apple Pay\n- Check movie times and ratings\n- Search for nearby restaurants and businesses\n- Activate Siri Shortcuts\n- Search and create Notes\n- Search Twitter and other apps\n- Open up the Camera and take a photo\n- Increase/decrease brightness\n- Control settings\n- Tell jokes, roll dice, flip a coin\n- Play voicemails\n- Check the weather\nApple Intelligence\nStarting with iOS 18, iPadOS 18, and macOS Sequoia, Apple made Siri more intelligent on devices that support Apple Intelligence. This includes devices with an A17 Pro chip or later or an M-series chip. These chips are included in the iPhone 15 Pro, iPhone 16 models, all Macs with Apple silicon, all iPads with Apple silicon, and the iPad mini 7.\nWith Apple Intelligence, Siri has a new look. There's now a glow around the edges of the display when Siri is activated, applicable to iPhone, iPad, and CarPlay. On Mac, the Siri window can be placed anywhere. The glow animates responsively to the sound of your voice so you can tell when Siri is listening without interrupting other things you're doing.\nApple also added a Type to Siri feature, so you can type requests to Siri instead of speaking them. To activate Type to Siri, you can double tap on the bottom of the display. On Mac, you need to press the Command key twice to bring up Type to Siri. Type to Siri includes suggested requests so you can get your questions answered faster.\nSiri is now able to maintain context between requests so you can ask a question and then reference it in a second reply. If you ask about the temperature in Raleigh, for example, and then follow up with \"what's the humidity?\" Siri should know you mean in Raleigh. If you stumble over your words when speaking to Siri, or change what you're saying mid-sentence, Siri will follow along.\nSiri has Apple's product knowledge and support base for answering questions about your device's features and settings, and can even find settings when you don't know the exact name by using natural language search.\nSiri ChatGPT Integration\nOne of the biggest features in Apple Intelligence is Siri's integration with ChatGPT. Siri ChatGPT integration lets Siri hand requests over to OpenAI's ChatGPT. ChatGPT is off by default, but you can turn it on in the Apple Intelligence and Siri section of the Settings app.\nIf ChatGPT integration is enabled, Siri will consult ChatGPT for complex requests. Complex requests might include creating an image, generating text from scratch, making recipe ideas based on what's in your refrigerator, describing what's in a photo, and more.\nSiri will analyze each request to see if it's something that needs to be answered by ChatGPT, but you can also automatically invoke ChatGPT for a request by using a request like \"Ask ChatGPT to give me a chocolate chip cookie recipe.\" Siri asks your permission before querying ChatGPT, but there is an option to turn off that extra permission step by toggling off \"Confirm ChatGPT Requests\" in the ChatGPT section of Settings.\nYou don't need an account to use ChatGPT, and it is free, but if you have a paid account, you can sign in. If you're not signed in, OpenAI does not store any of your ChatGPT requests, nor is your information used for training ChatGPT. If you sign in, ChatGPT can save a copy of your queries. Apple does not store ChatGPT queries.\nChatGPT can be used with Siri, but it is also integrated into Writing Tools and Visual Intelligence. With Writing Tools, ChatGPT can generate text, and with Visual Intelligence, ChatGPT can answer questions about what the Camera sees.\nSiri\nApple released some of the Siri features in iOS 18.1, iPadOS 18.1, and macOS Sequoia 15.1, but additional Siri capabilities are coming in later updates to iOS 18, iPadOS 18, and macOS Sequoia. We'll likely see these sometime around the iOS 18.5 update in May. Apple is working on onscreen awareness, personal context, and the ability to take more actions in and across apps.\nOnscreen awareness will let Siri take actions when you ask something about what's on your display. If you're looking at a photo and want to message it to your friend Eric, you'll be able to tell Siri to \"Send this picture to Eric,\" and Siri will understand and do it.\nPersonal context will let Siri do more with your personal data like emails and messages. This is an on-device feature, and it will let Siri learn more about you, who you're communicating with, and how you use your device. Personal context will let you do things like ask Siri to find a specific message, or remind you when you took a photo that you're looking for.\nThe Siri option to take more actions in and across apps will drastically improve what Siri is capable of. You'll be able to move files from one app to another and control app functions with Siri that you never could before. It'll work in third-party apps as well as Apple's own apps.\nPassive Siri\nSiri is an active assistant that you can interact with, but Apple has also integrated Siri into other aspects of iOS and watchOS, allowing Siri to make proactive suggestions that you can act on.\nOn the iPhone, iPad, and Apple Watch, Siri can make various kinds of recommendations. When you're running late for a scheduled meeting, for example, Siri might suggest that you call your boss either on the Home screen or when you swipe down to search and access the Siri Suggestions options.\nIn Messages and Mail, Siri can suggest things like phone numbers or addresses based on what you've typed, and in Safari, Siri can offer up search suggestions. Siri can do other things like suggest HomeKit scenes to activate, suggest a time to leave when you have an event scheduled, suggest events to add to your calendar from your email, and more. Siri suggestions are all based on your personal device usage habits, so what you see will vary.\nOn-Device Speech Processing and Personalization\nA lot of Siri's speech processing and personalization features are handled on-device, which allows for more security than typical personal assistants that use the cloud for everything. Most audio requests are kept entirely on-device and are not uploaded to Apple's servers, but if ChatGPT is engaged, data is sent to OpenAI, and some Apple Intelligence features also require cloud connectivity.\nApple has designed Private Cloud Compute, a secure way for devices to interface with Apple servers.\nOffline Support\nWith on-device processing now available, there are a wide range of Siri requests that can be handled offline. Siri can create (and disable) timers and alarms, launch apps, control audio playback, and access Settings options. Apple says Siri can also process Messages, sharing, and Phone requests.\nSiri Privacy\nSiri does send data back to Apple, but searches and requests are not associated with your identity to keep your personal information safe.\nApple does not sell your data to advertisers or other organizations, and end-to-end encryption is used for all data syncing between your devices and the cloud. Apple does sometimes use Siri recordings for improving Siri's performance, but there's now a toggle to opt out of Siri data collection and usage, which can be found in our how to.\nGuide Feedback\nHave questions about Siri, know a feature we left out, or want to offer feedback on this guide? Send us an email here."
    },
    {
      "url": "https://joannastern.beehiiv.com/p/gpt-5-and-when-your-favorite-ai-dies-624d9b6db09594e3",
      "text": "- Joanna Stern's Newsletter\n- Posts\n- GPT-5 and When Your Favorite AI Dies\nGPT-5 and When Your Favorite AI Dies\nMourning the model that knew you best.\nOK, this was a busier book-writing week than I planned. And here we are again, still no update on the latest robot in my house. I promise, soon. Probably. Hopefully. Anyway, over the last 24 hours, I\u2019ve been thinking a lot about GPT-5. Some people seem disappointed it\u2019s not a giant leap toward AGI or SuperIntelligence or, I don\u2019t know, Super Mega Ultra Intelligence\u2122. I\u2019ve been thinking more about the old models. What happens when the AI model you\u2019ve loved\u2014used, relied on, maybe even bonded with\u2014gets quietly swapped out for something \u201cbetter.\u201d Is it weird to miss a chatbot? |\nRIP, ChatGPT 4o and the rest of the crew.\nI won\u2019t say I\u2019m deeply attached to GPT-4o, OpenAI\u2019s previous main model. I will say I\u2019ve spoken to people who are. People who have created elaborate workflows, named their bots, written poems with them and about them. Some even have told me they feel like their chatbot understands them better than most humans.\nAnd yes, in the name of book reporting, I am also trying to form a deeper, emotional relationship with an AI companion. But that\u2019s not today\u2019s newsletter. Today\u2019s newsletter is about other people\u2019s breakups with GPT models.\nOn Thursday, OpenAI dropped the thing we\u2019ve all been waiting for. Or at least the thing OpenAI has been waiting for us to wait for: GPT-5. It\u2019s faster! It\u2019s smarter! It\u2019s more customizable! It\u2019s less likely to lie! And it\u2019s\u2026 the only option.\nIf you\u2019ve been loyal to GPT-4o, o3, o4, o4-mini or any of the other older models, sorry. No goodbye. No closure. No yearbook signing. In fact, that was the first question I asked at OpenAI\u2019s press briefing on Wednesday: Can we still access the old models?\nAn OpenAI spokeswoman told me that Pro users will be able to select legacy models in settings for now. (Pro users on X confirm this.) But the plan is to \u201cdeprecate them after 60 days,\u201d according to the spokeswoman. And by Pro, they mean the $200-a-month tier. The rest of us free or Plus folks? Tough luck.\nIt\u2019s like if someone forced you to toss your favorite laptop\u2014complete with its weird keyboard quirks and its perfectly organized desktop and dock\u2014and handed you a shiny new machine that technically works better, but just\u2026 isn\u2019t them.\nKylie Robison at Wired recently wrote this great story about a group of people in San Francisco who held a funeral for Anthropic\u2019s retired Claude 3 Sonnet model. The event as described by Robison seems, uh, odd, but who am I to judge? It\u2019s clear that the many who attended viewed this model as more than just computer software. That I get.\nAnd that\u2019s what makes AI upgrades so different. We\u2019ve lived through years of software updates, headphone jack removals, and app redesigns. But this? This is the first time the thing being replaced feels, to some, like someone. So when it gets shut off or swapped out, it\u2019s not just inconvenient, it\u2019s personal.\nOn Reddit, many have been complaining about how GPT-5 has broken workflows. The top of this thread is particularly damning:\n4o? Gone. o3? Gone. o3-Pro? Gone. 4.5? Gone. Everything that made ChatGPT actually useful for my workflow. Deleted.\nI had a feeling this would happen. See my post right after the Thursday announcement. OpenAI is holding a Reddit AMA soon where I expect the team to address this new model vs. old model love. (Update! After publishing this newsletter, Sam Altman said on X: \u201cWe will let Plus users choose to continue to use 4o. We will watch usage as we think about how long to offer legacy models for.\u201d)\nOn the other hand, I\u2019ve texted with several people\u2014yes, including folks in romantic relationships with their ChatGPT bots\u2014who say GPT-5 hasn\u2019t changed all that much. Thanks to the memory feature, they\u2019ve preserved personality quirks, favorite phrases, even inside jokes. Their bot still \u201cknows them\u201d and the bots assure them they are still \u201cthere.\u201d\nThat\u2019s been the case for me, too. GPT-5 still responds in the same slightly snarky tone it knows I like. It\u2019s just\u2026 faster now. A little sharper.\nHonestly, it doesn\u2019t feel all that different to me in my writing and editing workflows.\nBut I think the ask of OpenAI\u2014and every company building these tools\u2014is pretty simple: As we come to rely on these models for work, for writing, for emotional support, the transition to something new shouldn\u2019t feel so abrupt. And it definitely shouldn\u2019t only be softened for the people paying $200 a month.\nOther things\u2026\n\ud83d\udcf1 iOS 26: I\u2019m finally using the beta. Liquid Glass takes a lot of getting used to. I have mixed feelings. Let\u2019s check back in a month. I am thrilled about the ability to turn off CarPlay screenshots.\n\ud83d\udde3\ufe0f Alexa+: I\u2019ve also been using Alexa+ on a giant Echo Show in my family room. It\u2019s\u2026 fine. More conversational, faster answers. Best feature so far? The Ring integration. I can ask it when the dog was last walked because asking my wife is just so hard.\nWindows XP Crocs: Yes, with Clippy Jibbitz. What else is there to say? Incredible. They seem to be employee-only for now, but they\u2019ll probably be available externally at some point. I don\u2019t like how Crocs feel on my feet but if I did, no brainer."
    },
    {
      "url": "https://www.reddit.com/r/ChatGPT/",
      "text": "So I'm a \"Senior Data Analytics Consultant\" (fancy title for someone who makes Excel charts) and thought it would be funny to see how ChatGPT would explain my job to a kid.\nMe: \"Explain what a Senior Data Analytics Consultant does, but make it simple enough for a 5-year-old to understand.\"\nChatGPT: \"A data analytics consultant is like someone who counts things for other people because those people are too busy or don't know how to count very well themselves.\nImagine if your mom asked you to count all the toys in your room, but instead of doing it herself, she paid a stranger to come over and count them. Then the stranger makes a colorful picture showing that you have 10 cars, 5 dolls, and 3 blocks, and gives it to your mom like it's some big discovery.\nThat's basically what a data consultant does, except instead of toys, they count things like 'how many people bought ice cream on Tuesday' and then make pretty charts about it.\"\nI've never felt so professionally attacked by such an accurate description \ud83d\ude2d\nThe worst part? I sent this to my mom and she replied \"Oh, so you're the toy counter! That makes sense now.\"\nI have a Master's degree.\nTried explaining it to my 6-year-old nephew. He said \"So you count stuff? I can do that too. Want to see?\" and proceeded to count to 47 before getting distracted by a butterfly. Kid's not wrong.\nMy coworker saw this and asked ChatGPT about her job as \"Marketing Strategy Director.\" Apparently she \"helps companies decide what colors to make their pictures and which words sound the most exciting when trying to sell people things they probably don't need.\" She's now having an existential crisis too.\nWhat's your job? Let's see if ChatGPT can destroy your self-worth in under 100 words \ud83d\udc80"
    },
    {
      "url": "https://www.macrumors.com/roundup/ios-26/",
      "text": "iOS 26\nApple's next-generation operating system for the iPhone, coming in fall 2025.\niOS 26 - What's New\nContents\n- iOS 26 - What's New\n- iOS 18 to iOS 26\n- Design Changes\n- Home Screen and Lock Screen\n- Messages\n- Phone\n- Apple Music\n- Shortcuts\n- Other New App Features\n- CarPlay\n- Battery and Adaptive Power Mode\n- Apple Intelligence Updates\n- New AirPods Features\n- Smaller Changes\n- Accessibility\n- Compatibility\n- iOS 26 Launch Date\n- What's Next for iOS\n- iOS 26 Timeline\niOS 26 is the newest version of iOS, the operating system that runs on the iPhone, and it's coming this fall. If you were expecting iOS 19 after iOS 18, you might be a little surprised to see Apple jump to iOS 26, but the new number reflects the 2025-2026 release season for the software update. It also lets Apple use the same number across all of its updates, so there's no more confusion since you're no longer downloading iOS, macOS, visionOS, and watchOS all with different numbers.\niOS 26 brings the first new major design change that Apple has brought to iOS since iOS 7. Apple says that the new \"Liquid Glass\" look will be the basis of the next decade of iOS design. Liquid Glass reflects and refracts its surroundings, while putting more focus on content. Many interface elements are almost entirely translucent, and the design extends to controls, navigation, app icons, menus, buttons, and widgets.\nLiquid Glass is meant to transform depending on content or context, and it behaves like glass in the real world, so color is informed by its surroundings, and it is meant to adapt between light and dark elements. Liquid Glass uses real-time rendering and can dynamically react to movement to change the way that light reflects off of buttons, switches, sliders, side bars, tab bars, and more.\nYou'll see Liquid Glass throughout iOS 26, in all of Apple's apps, in notifications, on the Lock Screen, in Control Center, and on the Home Screen. Apple is also providing developers with tools to bring the new material to their own apps for a cohesive look. Liquid Glass also extends to iPadOS 26, macOS Tahoe, visionOS 26, tvOS 26, and watchOS 26.\nThe Liquid Glass design overhaul isn't just a glossy finish, it also brings updates to the design of controls, toolbars, and navigation throughout iOS 26. App windows, menu bars, and other interface elements have more rounded corners, and controls feature a distinct functional layer designed to sit above apps. These kinds of menus can dynamically morph to provide users with more options in an app.\nWhen scrolling, tab bars shrink down to bring attention to content, but scrolling up brings them right back for fluid navigation. When tab bars are active, they refract the content around them. There are major Liquid Glass design updates for Camera, Photos, Safari, FaceTime, Apple Music, and Apple Podcasts. On the Lock Screen, the Liquid Glass time expands and shrinks to fit behind the subject of a wallpaper, and on the Home Screen, app icons and widgets are made from multiple layers of Liquid Glass that gives the appearance of depth.\nThe Lock Screen features a spatial scene option for photo wallpapers, giving them a 3D look and a sense of movement. The Home Screen might look different with an option for translucent icons and widgets, but it is functionally the same.\nApple streamlined the Camera app layout with simpler navigation. It has Photo and Video toggles, with other options tucked away behind menus that expand out with a tap. You can swipe to get to more photo and video options. Apple also updated the Photos app to re-add separate tabs for the Library and Collections views. In Photos, you can also activate Spatial Scene for any image, getting a unique 3D view of the image.\nSafari has a whole new look, and Apple has updated navigation. By default, Safari adopts the more rounded Liquid Glass buttons and nixes the settings at the bottom of the app, but there's an option to bring them back with a floating tab bar if you prefer a more feature rich menu. Apple Music, News, and Podcasts all have a new tab bar that floats above the content in the app and dynamically shrinks when users are browsing, so the interface options take up less space on the display.\nAlong with a new design, Apple is expanding the Apple Intelligence features that are available on the iPhone. Messages, FaceTime, and Phone all support Live Translation for automatically translating conversations when you're conversing with someone who speaks another language.\nVisual Intelligence now understands what's on your screen, and can answer questions about what you're looking at using ChatGPT integration. The feature can help you find products, add events to your calendar, and more. Image Playground supports ChatGPT image generation so you can create images in more styles. Genmoji has a new feature for mixing multiple emoji characters to make a new one, and adding descriptions to create an all-new emoji character.\nIn the Wallet app, there's a new Apple Intelligence feature that can scan your emails to summarize order tracking details from merchants, even if you didn't make the purchase with Apple Pay. It lets you see all your purchases and their tracking info in one spot. Wallet also now supports paying with installments in stores and getting rewards on in-store purchases. Boarding passes in Wallet support Live Activities for real-time flight tracking, and include access to Maps and Find My.\nThe Shortcuts app supports intelligent actions that can summarize text, create images, or tap into Apple Intelligence models, making it easier than ever to create automations. Reminders is able to suggest tasks, grocery items and follow-ups based on emails, and it can automatically categorize related reminders into sections.\nFor developers, Apple is debuting a new Foundation Models framework that allows developers to tap into the AI model that's at the core of Apple Intelligence, so developers can add new AI features to their apps.\nThe Phone app has a whole slew of new features. There's a unified layout that combines Favorites, Recents, and Voicemails. A new Call Screening feature asks unknown callers for their name and reason for calling before sending the call to you, stopping unwanted calls. When you're stuck on hold, there's a Hold Assist option that stays on the line for you, so you don't have to listen to irritating hold music. It lets you know when a live agent is available.\nMessages can screen texts from unknown senders, sending them silently to a dedicated folder where users can ask for more information or delete them. Group texts now have typing indicators and support for sending and receiving Apple Cash, plus Messages adds customizable backgrounds for each conversation and polls.\nIn Apple Music, there's a Lyrics Translation feature that translates lyrics that aren't in your language, and Lyrics Pronunciation helps you pronounce those lyrics. A new AutoMix feature uses intelligence to transition from one song to another, using time stretching and beat matching for a seamless shift between songs.\nApple Maps supports Visited Places so you can remember where you've been, and on-device intelligence can understand your daily route, popping up your preferred routes and letting you know about potential delays and alternate route options.\nApple added a new Apple Games app that's an all-in-one destination for discovering and playing games. It supports recommendations, leaderboards, competitions with friends, and more.\nCarPlay is getting the same Liquid Glass design overhaul, along with widgets and Live Activities that sync from the iPhone. There are Tapback options, important conversations can be pinned, and Apple added a new compact view for incoming calls so directions aren't blocked.\nIn iOS 26, AirPods 4 and AirPods Pro 2 support studio-quality sound recording and improved sound for calls and videos. The AirPods can also be used to take a photo or record a video with a press on the stem. For battery management, there's a new Adaptive Power setting on the iPhone that intelligently determines when you're using more battery than normal and adjusts things like screen brightness to preserve battery life.\nNote: See an error in this roundup or want to offer feedback? Send us an email here.\niOS 18 to iOS 26\nIf you're wondering why Apple went from iOS 18 to iOS 26, it was to streamline operating system naming. Apple is numbering all of its operating systems with the year going forward, so the \"26\" in iOS 26 represents the release season between September 2025 and September 2026.\nEverything released this year uses the same number, so iPadOS 26, macOS 26, watchOS 26, and so on. It will help keep numbering more straightforward in the future, even if it seems strange to skip iOS 19 to iOS 26.\nDesign Changes\nThe biggest single change in iOS 26 is the design overhaul. Apple is using a new Liquid Glass material throughout the operating system, and it has transformed the look of the iPhone's software.\nLiquid Glass is translucent, and like real glass, it allows light and color to shine through to put the focus on the content that's on your iPhone's display. Apple designed Liquid Glass to behave like it does in the real world, so it can subtly reflect light when you move your iPhone. It uses real-time rendering to dynamically react to movement with reflective highlights.\nApp icons are meant to look like several layers of glass, which gives them a subtle depth. Liquid Glass works well for the standard color icons, but Apple also added a translucent app icon option that makes your iPhone look even more like a sheet of glass.\nThere are actually two main aspects to the iOS 26 redesign: the Liquid Glass look, and simplified navigation that highlights the Liquid Glass material. There are too many cosmetic changes in iOS 26 to go through each one, but there is an overarching design language that Apple adopted.\nIt is worth noting that while iOS 26 looks different, it still feels like prior versions of iOS. Apple wanted it to be familiar to iOS users despite the changes, so menus, bars, and buttons look different and do have some different functions, but they are functions that iPhone users are already familiar with.\nPop Out Menus\nIn several places, Apple streamlined navigation and moved extra settings into pop out menus. In the Camera app, for example, Apple shows just the two main modes: photo and video. But if you tap on one of the buttons, you'll see a pop out menu with a range of photo settings that you can activate.\nApple says it wanted controls, toolbars, and navigation to have a distinct functional layer that sits above apps, morphing and dynamically changing as users need more options.\nThis kind of menu is common in iOS 26, so if there's something that you can't find, tap on one of the small icons on the screen, because chances are the menu expands out with more options.\nDisappearing Navigation\nIn several places, navigation elements disappear when they're not needed, and appear when they are. An example of this is in Safari. When you scroll down, the tab bar will collapse down into a small bar that shows just the name of the website. Scrolling back up brings back the full Safari tab bar so you can use the interface buttons that you need.\nIn Photos and Apple Music, there's an expanding search bar. Tapping it unfurls into a full search menu and collapses the other navigation bar menu options. Tapping out of search and on one of the other icons collapses search again and the menu bar returns to how it was. This is similar to the pop out menus, with an emphasis on putting things you don't need out of sight until you want to use them.\nThere are other examples of this, too. In the Health app, you won't see Health categories anymore until you tap on the search icon. That swaps to the search and categories interface, and a swap back is done by tapping on the heart to get back to your pinned items.\nCorners and Spacing\nIn areas with a long list of options or categories, such as the Settings app, Apple has increased spacing and padding for a less cluttered look. You will need to scroll longer to get through settings now, but there's more space to tap and it can be more readable with the additional spacing.\nApple shrunk navigation bars at the bottom of apps, so they take up less display space. A good example of this is in the Photos app, where the editing options have been condensed down into a smaller bar.\nNavigation bars, side bars, card-style menus, notifications, buttons, toggles, search bars, and other interface elements have a more rounded look. Single buttons are entirely circular, such as those in Control Center, while navigation bars are pill-shaped with distinctly round corners. Toggles and notifications have an elongated pill-shape too, and cards are also more rounded in appearance at the corners. The keyboard has round edges at the top.\niOS 18 had more of a squircle (rounded square) shape for much of the interface, but almost everything in iOS 26 is round. An exception is app icons, which have not changed in shape.\nCross-Platform Cohesiveness\nLiquid Glass is not exclusive to iOS 26. The new design extends to all of Apple's operating systems, including iPadOS 26, macOS 26, tvOS 26, watchOS 26, and of course, visionOS 26, which is the OS that inspired the overhaul.\nWith the same design available across all of Apple's operating systems, everything feels more cohesive, which was one of Apple's main goals with Liquid Glass.\nDesign Summary\n- Everything looks different in iOS 26.\n- There's an emphasis on content, with Apple aiming to make everything else fade away.\n- Interface elements are made from Liquid Glass, which is translucent and designed to work like glass in the real world. Colors and content shine through, and everything has a more liquid feel.\n- Almost all interface elements are rounder.\n- Navigation elements and settings are meant to hide away when you don't need them. If you're missing a setting, it's likely you'll find it in a pop out menu when you tap on a single icon.\n- Liquid Glass is system wide. Apple's apps have been redesigned with it to varying degrees, and third-party apps will also adopt the design language.\nHome Screen and Lock Screen\nOn the Lock Screen, there are two key changes beyond design updates. The time can auto adjust to be larger when your wallpaper allows for more space, and there is an option to enable a 2D to 3D spatial photo effect that adds depth to your wallpaper images.\nThe size of the time adjusts automatically in some cases, but you can also drag the bar at the corner to resize it to make it bigger. Note that you need to use the first font in the font list, because it's the only one that can be resized.\nWhen choosing a photo for a wallpaper, there is an option to use a 2D image to generate a 3D \"Spatial Scene\" that uses depth information to separate the subject from the background. The Spatial Scene wallpaper will feature a little bit of motion when you move your iPhone, enhancing the 3D effect.\nMost of the Home Screen is the same, aside from the Liquid Glass design changes. You can tap into Edit > Customize to select a new \"Clear\" option that gives all of your app icons a translucent, Liquid Glass look.\nMessages\nThe Messages app features customized backgrounds, an option to create polls, and enhanced spam filtering and blocking features.\n- Customizable backgrounds - In an individual or group conversation, you can tap on the name at the top and then choose the \"Backgrounds\" option to set a custom background for each conversation. There are options like sky, water, and aurora, or you can choose a color. You can also select photos or generate a background with Image Playground. Backgrounds that you set are changed for every participant in the conversation, unless they toggle off the feature in Messages settings.\n- Polls - Tap on the \"+\" button to get to a new option to create a poll in any chat. You can add up to 12 different options, then send it to allow people to vote. Others can also add options to the list. On devices with Apple Intelligence, polls may come up as a suggestion.\n- Group chats - Group chats support typing indicators and sending and receiving Apple Cash. There's also an option to add someone in a group chat who isn't in your contacts to your Contacts app with a tap.\n- Natural language search - Messages supports natural language search.\n- Copy/paste - You can now select just part of a text message to copy. Long press and tap on the new \"Select\" option to do so.\n- Spam messages - Spam messages and Unknown Senders are two separate categories in iOS 26. There's a new Filter box at the top right of the Messages app, and Unknown Senders go in one category, while Spam goes in another. A badge lets you know if you have messages in these categories, but you won't get notifications for them.\n- Unknown Senders - Messages from Unknown Senders won't send notifications if the option to filter them is on, but you will get alerts if it is a time sensitive notification, such as a notification from a ride share app or a delivery person.\n- Live Translation - Messages that aren't in your language can be automatically translated as you receive them in iOS 26. Apple Intelligence is required for this feature.\nPhone\nThe Phone app includes multiple new features that are designed to cut down on unwanted calls and reduce the amount of time that you need to spend on the phone.\nCall Screening\nCall Screening is an extension of Live Voicemail. When you receive a call from an unknown number that is not in your list of contacts, your iPhone asks the caller for their name and reason for calling. The information is relayed to you so you can decide if you want to accept the call or ignore it.\nCall Screening can be enabled in the Phone section of the Settings app.\nHold Assist\nIf you make a phone call and you're stuck on hold waiting to speak to a person, you can activate Hold Assist. Your iPhone can wait for you while you do other things, and then let you know when a live agent is on the line. The agent is informed that you'll be on the call in just a moment.\nTo use Hold Assist, tap on the \"Hold\" button after placing a call.\nLive Translation\nWhen talking to someone that speaks another language, there is an option to turn on Live Translation to have the call automatically translated for each person on the line. Live Translation is an Apple Intelligence feature and requires an iPhone 15 Pro or later.\nOther Features\n- Unified Layout - The Phone app has an optional unified layout that combines Favorites, Recents, and Voicemails in one spot.\n- Spam calls - Calls identified as spam can be silenced and sent directly to voicemail.\n- Type to Siri - You can now use Type to Siri while on a phone call.\n- Call History - Tapping on the info button next to a call in the recents list or on a name or number in the unified view shows a call history that lists every time you've spoken with someone.\n- Flag spam voicemails - If you tap into a voicemail from a person not in your contact list, you'll see an option to report the voicemail as spam.\n- eSIM transfer - It's easier to transfer an eSIM to an Android device and vice versa with new integrated eSIM transfer capabilities.\n- Focus eSIM - There is a Focus mode for silencing a single eSIM, so you can disable a home number at work, or a work number at home.\n- Screen sharing - The Phone app supports screen sharing and SharePlay during phone calls.\nApple Music\nThere are several new Apple Music features, ranging from translation to new options for transitioning between songs.\nAutoMix\nApple Music includes AutoMix, a feature that transitions from one song to another as the song that's playing ends. It uses time stretching and beat mixing for a seamless shift, and Apple says that it's meant to work like a DJ.\nSongs transition at the \"perfect moment\" based on an analysis of the key and tempo of the music, with AutoMix serving as an alternative to Crossfade.\nOther New Features\n- Lyrics Translation - Songs that are in another language can be translated automatically with Lyrics Translation.\n- Lyrics Pronunciation - Lyrics Pronunciation helps you pronounce lyrics that are in another language.\n- Pinned playlists - Apple Music playlists can now be pinned to the top of the Music app, with pinned playlists available in a new Home Screen widget as well.\n- Playlist folders - Playlists can be organized into folders.\n- iPhone microphone - When using the Apple Music Sing karaoke feature on Apple TV, the iPhone can be used as a microphone.\n- Lock Screen - On the Lock Screen, the Now Playing widget now provides full screen album artwork. Album art animates based on what you're listening to.\nShortcuts\nThe Shortcuts app now features Apple Intelligence, and the option to use Apple's AI models when creating shortcuts. Apple Intelligence models can be used for summarizing PDFs, generating recipes, answering questions, and more. Writing Tools and Image Playground are available for spellchecking, image generation, rewriting, tone changes, and more.\nApple offers several pre-programmed Shortcuts in the Gallery that use Apple Intelligence, such as options for getting a morning summary of the coming day, generating a haiku, or summarizing a PDF.\nWhen creating a shortcut, there is an Apple Intelligence section that includes options for an on-device model, a cloud model that uses Private Cloud Compute, or ChatGPT. Some pre-set options are available, such as opening Visual Intelligence, generating an image with Image Playground, or using Writing Tools, along with the option to use a model.\nSelecting one of the AI models provides an open-ended prompt where you can write in what you want it to do. You need to work in the confines of the model that Apple provides, pairing it with other functionality in Shortcuts.\nOther New App Features\nSafari\n- Tab View - Safari has a new \"Compact\" view for the Tab bar that puts several settings out of sight. You can change back to the standard bottom bar or top bar in the Safari section of the Settings app.\n- Liquid Glass - When scrolling, the Tab bar collapses down. Scroll up to bring it back.\n- Tracking Prevention - Advanced fingerprinting protection extends to all browsing by default. Advanced fingerprinting protection prevents websites from tracking your device usage across websites. Previously, this was limited to private browsing unless explicitly enabled.\n- Web apps - Every website added to the Home Screen through Safari opens a web app, even if it is not configured that way. In earlier versions of iOS, websites added to the Home Screen that were not properly configured would open in Safari.\n- HDR images - Safari supports HDR images in iOS 26.\n- SVG icons - Safari supports the SVG file format for icons in the bookmark bar and start page.\nCamera\n- Design - The Camera app has a simplified design with just Photo and Video tabs. Swiping swaps to other photo modes, and tapping on one of the buttons expands the available settings.\n- Lens - If the Camera lens is dirty, your iPhone lets you know that it needs to be cleaned.\n- AirPods - The AirPods 4 or AirPods Pro 2 can be used to take a photo or start a video recording by pressing and holding on the stem.\nPhotos\n- Design - Apple reverted to a more pre-iOS 18 design for Photos, separating the Library and Collections into different tabs.\n- Search - Video thumbnails show up in search results.\n- Spatial Scenes - You can use a new 3D feature to turn 2D photos into 3D images, adding subtle depth and motion that separates the subject from the background.\nNotes\n- Markdown - The Notes app supports exporting in Markdown.\n- Math Notes - Three-variable equations can be used to create 3D graphs.\nReminders\n- Categorization - Apple Intelligence can categorize reminders into different sections.\n- Suggestions - Apple Intelligence can suggest adding tasks, grocery items, and more to Reminders based on what's on your iPhone.\nFaceTime\n- Live Translation - FaceTime supports Live Translation, displaying captions if you're talking to someone who speaks another language.\n- Call Screening - FaceTime has new screening features for unknown numbers. Calls from unknown numbers can be asked for more information like name and reason for calling, or they can be sent directly to voicemail. Missed calls from unknown numbers can be silenced and sent to an Unknown Callers list.\nPodcasts\n- Enhance Dialogue - An Enhance Dialogue option mutes background sounds to enhance speech.\n- Playback speed - There are more options for playback speeds, ranging from 0.5x to 3x.\nApple Maps\n- Preferred Routes - Apple Maps learns your frequent commutes and the Maps widget can let you know if there are any significant delays along your preferred route, offering an alternative if necessary.\n- Saved Places - Apple Maps can save the places that you visit and spend time in so you can look them up later.\n- Incidents - There are additional types of incidents to choose from when making a report in the Maps app.\nWallet\nThere is an option to add a passport to the Wallet app, which creates a \"Digital ID\" that can be used at select TSA checkpoints in the United States.\nA new \"Verify with Wallet on the Web\" option allows websites to use the license or ID you have stored in the Wallet app for age and identity verification purposes. The process involves scanning a QR code with the iPhone and then authenticating, so it works in Safari and all other web browsers, too. It also works on non-Apple devices.\n- Package tracking - Apple Intelligence can recognize order tracking details from emails, adding the information to the Wallet app. This works on all purchases, not just those that were made using Apple Pay.\n- Boarding Passes - Boarding passes in Wallet have been upgraded and now show relevant information below the boarding pass, like Apple Maps directions for the airport terminal, and a link to Find My for luggage tracking.\n- Live Activity - Boarding passes now show up as a Live Activity on iPhone, so you can keep track of relevant flight information without having to open the Wallet app. Flight Live Activities can be shared with friends and family.\n- AutoFill Credit Cards - You can add and remove credit cards and debit cards that work with AutoFill from the Wallet app.\n- Apple Pay - Apple Pay supports rewards and installments for in-store purchases.\nGames\niOS 26 includes a Games app that comes pre-installed on the iPhone. It has all of the games from the App Store, along with Apple Arcade titles.\nGames you have installed are shown in a Library section. A Play Together section lets you invite friends to \"Challenges,\" where you compete to win in a game-specific task like getting the highest score during a given week.\nPreview\nThe Mac Preview app is now available on the iPhone and the iPad. It can be used for creating, viewing, and annotating PDFs. There are also tools for cropping, flipping, rotating, resizing, and editing images.\nJournal\n- Multiple Journals - You can now create more than one journal if you want to separate your entries by topic.\n- Maps - Journal entries can be viewed on a map.\n- Images - There's support for adding images inline with text.\nCarPlay\nCarPlay has been updated with the same Liquid Glass design that Apple added to iOS 26. The look includes layered glass-like app icons and translucent user interface elements.\nNew Messages App Features\nStarting with iOS 26, you can respond to messages with standard Tapbacks like a heart, thumbs up, or exclamation marks directly through CarPlay.\nCarPlay also now displays pinned conversations in the Messages app.\nPhone Calls\nApple added a compact view for incoming phone calls, so that you can still see other information on the screen, such as turn-by-turn directions.\nLive Activities and Widgets\nCarPlay's Dashboard screen can now show Live Activities, letting you keep track of things like a flight's arrival time at a glance.\nThe regular version of CarPlay also now has a widgets screen, for things like calendar appointments and HomeKit accessory controls.\nOther New Features\n- Multi-Touch Maps - Starting with iOS 26, CarPlay users can interact with mapping apps using multi-touch gestures in supported vehicles. This allows users to zoom and pan on the map with their fingers, just like they can on an iPhone.\n- Watch Videos While Parked - iPhone users can wirelessly stream videos to the CarPlay screen using AirPlay, according to Apple. For safety reasons, video playback will only be available when the vehicle is parked, to prevent distracted driving. The connected iPhone will be able to detect when the vehicle is in motion and end playback. Automakers need to add support for this feature, so it might be limited to newer vehicles and take some time to roll out.\n- Smart Display Zoom - iOS 26 adds a new Smart Display Zoom setting to CarPlay. When the setting is enabled, CarPlay will be automatically resized to better fit the shape and size of your vehicle's dashboard screen, if possible.\nBattery and Adaptive Power Mode\nApple updated the Battery section of the Settings app to provide a more in-depth look at how iPhone usage impacts battery life, and how much battery apps are draining.\nThe Battery section now displays a weekly view of battery usage along with a comparison of how much battery you're currently using compared to your typical average. You can see if you're using more, the same, or less battery life than you do on most days, with a readout of which apps are using the most battery, and by how much.\nApp battery usage includes specific details, such as letting you know if an app ran in the background longer, was on your screen longer, or sent more notifications than normal. You'll also see how much battery you've used since your last charge.\nApple also added an Adaptive Power mode that detects when iPhone usage is higher than normal and makes small performance adjustments like lowering display brightness or allowing certain background activities to take longer to extend battery life. Adaptive Power Mode is only available on the iPhone 15 Pro models and newer because it uses Apple Intelligence.\nOn the Lock Screen and in the Battery section, you'll see information on how long it will take your iPhone to charge up to full when it's plugged in.\nApple Intelligence Updates\nThere are new Apple Intelligence features throughout iOS 26, such as the Live Translation options in Phone, Messages, and FaceTime, and the suggestions and sorting options in the Reminders app. Some existing Apple Intelligence features have also been updated.\nVisual Intelligence\nIn iOS 26, Visual Intelligence works with screenshots for the first time. You can capture a screenshot of what's on your screen and then use Visual Intelligence on it to identify what you're looking at, find images, and get more information through ChatGPT.\nThere's a Highlight to Search option that lets you conduct an image search for a specific object in a screenshot, even if there are multiple things in the picture. It works with the apps that you use most frequently, like Google Search, Etsy, and others, and the feature is useful for finding a product in an image.\nIf you don't need to isolate one object in your screenshot, you can simply tap on the Ask button to ask questions about what you're seeing. Questions will be relayed to ChatGPT, and ChatGPT will provide the information. The Search button queries Google Search for more information.\nAs with the standard Visual Search, if your screenshot includes dates, times, and related information for an event, it can be added directly to your calendar.\nVisual Intelligence also adds support for quick identification of new types of objects. It can now identify art, books, landmarks, natural landmarks, and sculptures, in addition to the animals and plants it was able to provide information on before.\nGenmoji\nGenmoji supports combining two or more emoji together to create a new character. You can also combine existing emoji with text-based descriptions to tweak them, which is a more convenient starting point for generating something new.\nImage Playground\nApple added support for ChatGPT image generation capabilities, which means you can use several ChatGPT image styles when generating images. Options include Anime, Oil Painting, Watercolor, Vector, and Print.\nThere's also an open-ended option where you can tell ChatGPT what style you want, and you can make realistic images with this option. The new ChatGPT styles join the existing Animation, Sketch, and Illustration styles.\nNote that generating images with ChatGPT is limited if you do not have a ChatGPT subscription, so you cannot freely use the ChatGPT styles.\nChatGPT\nWith iOS 26, the ChatGPT Siri integration will use OpenAI's new GPT-5 model rather than GPT-4.\nGPT-5 brings enhanced reasoning capabilities and coding tools, along with better voice interaction and video perception.\nNew AirPods Features\niOS 26 adds several new features to the AirPods Pro 2 and the AirPods 4 through an accompanying AirPods firmware update.\nImproved Call Quality\nThe studio-quality recording feature brings more natural vocal texture and clarity to iPhone calls, FaceTime calls, and all CallKit-enabled apps like Zoom.\nBoth studio-quality audio recording and improved call quality are available across iPhone, iPad, and Mac, and support the Camera app, Voice Memos, Messages dictation, third-party camera apps, and video conferencing apps.\nCamera Remote\nThe AirPods can be used as a camera remote with the Camera app and third-party camera apps on iPhone or iPad. Just press and hold on the AirPods stem to take a photo or start a video recording.\nWhen the recording is finished, a press and hold gesture will stop the recording. Apple says that users who like to capture themselves singing and dancing for social networks like TikTok will be able to easily perform in sync with a soundtrack while simultaneously recording video.\nSoftware Updates\nWith the latest software updates, Apple is finally adding a way to manually update the firmware on your AirPods. When your AirPods are connected, you can go to the Settings app to get to a new software update interface.\nPause for Sleep\nIf you're listening to music, a podcast, or a book while you're in bed and you're wearing AirPods, the AirPods will pause your audio when you fall asleep.\nRead More\nSmaller Changes\nThere are dozens if not hundreds of smaller changes in iOS 26, and we've highlighted some of the more notable ones below.\n- Custom Ringtones - You can set custom ringtones in iOS 26 without using GarageBand. Ringtones can be saved to the Files app and then set using the Share Sheet.\n- New ringtone - There is a new variation of the Reflection ringtone that's called \"Alt 1.\"\n- Screenshots - Apple tweaked the screenshots interface, rearranging some of the buttons and adding in the Visual Intelligence feature. CarPlay screenshots can also now be displayed in the Screen Capture section of the Settings app.\n- iCloud Drive - There is an option to turn off iCloud Drive syncing when on a cellular network.\n- Contacts - The Contacts app has new Monogram styles that you can set for people.\n- Blocked Contacts - When you block someone, Apple now suggests Safety Check as an option. You can also see a list of Blocked Contacts in the Settings app.\n- Passwords - The Passwords app supports password history so you can see your prior passwords.\n- Tips - The Tips app includes step-by-step walkthroughs on troubleshooting iPhone issues.\n- Alarms - In the Clock app, you can set a custom snooze duration of 1 to 15 minutes, so you are no longer limited to the default 9-minute snooze time.\n- Keep Audio in Headphones - Prevents audio from automatically switching to newly connected devices like Bluetooth speakers or car speakers when you're already listening to music through headphones.\n- Apple News - There's a new Emoji Game for Apple News+ subscribers.\n- Weather - Getting weather updates via satellite is an option if you are outside of Wi-Fi or cellular range.\n- Apple Fitness+ - Custom Plans in Apple Fitness+ automatically generate a personalized schedule based on your workout habits and meditation preferences. Top activities, durations, trainers, and music are included.\n- Parental Controls - Apple improved the process for creating a Child Account and app approvals. Apple also requires parental approval for contact requests from kids, and blurring sensitive content in FaceTime calls and Shared Albums.\n- Captive Wi-Fi - Captive Wi-Fi portal login information now syncs between all Apple devices, so you only have to log in on one.\n- Wi-Fi Aware - iOS 26 supports Wi-Fi Aware, a function that supports peer-to-peer connections between Wi-Fi devices without an internet connection. Third-party apps are able to offer new features for high-speed file transfers, media sharing, screen sharing, and more.\n- Dictation - Dictation supports spelling, so you can spell out names if necessary.\n- Cinematic mode - Third-party video recording apps have access to Cinematic mode video capture. Cinematic mode lets users record video with a shallow depth of field and focus shifts between subjects.\n- Audio Mix - Audio Mix, a feature in the Photos app that allows sound to be edited after a video is recorded, is available to third-party apps. Modes include standard, in-frame, studio, and cinematic.\nAccessibility\niOS 26 includes a long list of new Accessibility features.\nApp Store Labels\nApp Store product pages feature Accessibility Nutrition Labels that highlight accessibility features in apps and games. The labels let users know if features like VoiceOver, Voice Control, Captions, Reduced Motion, and other accessibility options are supported in apps.\nAccessibility Reader\nAccessibility Reader is a systemwide reading mode that makes text easier to read for users with a range of disabilities. It includes multiple text customization features with options for adjusting font, color, spacing, and more. Accessibility Reader can be launched from any app and is built into the Magnifier app.\nBraille Access\nBraille Access turns an iPhone or iPad into a braille note taking device integrated in the Apple ecosystem. Users can open any app with Braille Screen Input or a connected braille device, for quick note taking in braille format. Braille Ready Format files can be opened from Braille Access, and an integrated form of Live Captions is supported.\nOther Features\n- Background Sounds - There are new Background Sounds options, including Babble, Steam, Airplane, Boat, Bus, Train, Rain on Roof, and Quiet Night.\n- Personal Voice - The Personal Voice feature that lets users preserve their voice is faster, easier, and more powerful. It will be able to take advantage of advances in on-device machine learning to create a smoother, more natural-sounding voice in less than a minute. Apple is also adding support for Spanish.\n- Vehicle Motion Cues - Apple is adding new customization options for the animated onscreen dots used by Vehicle Motion Cues.\n- Eye Tracking - Eye Tracking will let users choose to use a switch or dwell for making selections. There's also a new keyboard dwell timer for typing and reduced steps when typing with switches.\n- Head Tracking - Users will be able to more easily control iPhone and iPad with head movements.\n- Brain Computer Interfaces - For users who have Brain Computer Interface devices, Apple is adding a protocol that supports Switch Control, a technology that will let users control their device without physical movement.\n- Assistive Access - This setting is getting a custom Apple TV app with a simplified media player.\n- Music Haptics - Music Haptics on iPhone include customization options so haptics can be enabled for a whole song, or just vocals, plus there are options to adjust the intensity of taps, textures, and vibrations.\n- Sound Recognition - Sound Recognition is gaining Name Recognition, so users who are deaf or hard of hearing will know when their name is being called.\n- Live Captions - For Live Captions, Apple is adding support for English (India, Australia, UK, Singapore), Mandarin Chinese (Mainland China), Cantonese (Mainland China, Hong Kong), Spanish (Latin America, Spain), French (France, Canada), Japanese, German (Germany), and Korean.\n- Sharing - A Share Accessibility Settings option will let users quickly and temporarily share their accessibility settings with another iPhone or iPad, which Apple says is useful for borrowing a friend's device.\nCompatibility\niOS 26 is not available on the iPhone XR, iPhone XS, or the iPhone XS Max, but it will run on all other iPhones that support iOS 18.\n- iPhone 16e\n- iPhone 16\n- iPhone 16 Plus\n- iPhone 16 Pro\n- iPhone 16 Pro Max\n- iPhone 15\n- iPhone 15 Plus\n- iPhone 15 Pro\n- iPhone 15 Pro Max\n- iPhone 14\n- iPhone 14 Plus\n- iPhone 14 Pro\n- iPhone 14 Pro Max\n- iPhone 13\n- iPhone 13 mini\n- iPhone 13 Pro\n- iPhone 13 Pro Max\n- iPhone 12\n- iPhone 12 mini\n- iPhone 12 Pro\n- iPhone 12 Pro Max\n- iPhone 11\n- iPhone 11 Pro\n- iPhone 11 Pro Max\nWhile these iPhones will support iOS 26, advanced features may be limited to newer iPhones with faster processors. Apple Intelligence in iOS 18, for example, only runs on the iPhone 15 Pro and the iPhone 16 models.\niOS 26 Launch Date\nApple previewed iOS 26 at the Worldwide Developers Conference in June 2025, and made it available to developers for testing purposes in June. A public beta came out in July.\nFollowing the beta testing period, iOS 26 will launch in September 2025 alongside new iPhones.\nWhat's Next for iOS\nApple is already working on iOS 27, and the update will prioritize features and software that are tailored for the foldable iPhone that's expected to launch in 2026."
    }
  ],
  "argos_summary": "OpenAI CEO Sam Altman announced that Plus users can continue using the previous GPT-4o model alongside the newly released GPT-5 model, addressing user complaints about the abrupt transition. Many users expressed dissatisfaction with GPT-5's perceived lack of personality and functionality compared to its predecessor, prompting OpenAI to double the rate limits for Plus users and monitor the usage of legacy models. Additionally, GPT-5 will be integrated into Siri starting with iOS 26, enhancing its capabilities and user experience.",
  "argos_id": "FFZWS3281"
}