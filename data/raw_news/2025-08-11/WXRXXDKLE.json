{
  "url": "https://appleinsider.com/articles/25/08/11/new-ringtones-and-app-launch-speed-up-whats-new-in-ios-26-beta-6",
  "authorsByline": "Marko Zivkovic",
  "articleId": "c54df7610bf84ee79e56427e49df31a4",
  "source": {
    "domain": "appleinsider.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "Santa Clara County",
      "city": "Cupertino",
      "coordinates": {
        "lat": 37.3228934,
        "lon": -122.0322895
      }
    }
  },
  "imageUrl": "https://photos5.appleinsider.com/gallery/64688-134776-cropped-beta6-xl.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-11T19:15:00+00:00",
  "addDate": "2025-08-11T20:58:37.865875+00:00",
  "refreshDate": "2025-08-11T20:58:37.865876+00:00",
  "score": 1.0,
  "title": "New in iOS 26 beta 6: Onboarding sequence, ringtones, and more",
  "description": "The sixth developer beta of iOS 26 has arrived, and it introduces an onboarding sequence, along with six additional iPhone ringtones. Here's what's new.",
  "content": "The sixth developer beta of iOS 26 has arrived, and it introduces an onboarding sequence, along with six additional iPhone ringtones. Here's what's new.\n\nOn Monday, a week after the debut of the fifth developer beta, Apple released iOS 26 developer beta 6. The update increments the build number to 23A5318c, up from the previous 23A5308g.\n\nAs a whole, the iOS 26 update introduced a variety of meaningful upgrades, including improvements to Image Playground, Shortcuts, and new features for the Messages and Phone apps.\n\nAlong with a dedicated Games app, Apple unveiled a Foundation Models framework that lets developers utilize Apple Intelligence tools in third-party apps, while Visual Intelligence now supports screenshots. Some of these enhancements are ideal for creative work on iPhone, while others are arguably better for business users.\n\nStill, iOS 26 is largely known for its controversial \"Liquid Glass\" design language, which is used across all of the company's platforms. The software features dynamic user interface elements that mimic the look of real-world glass, replacing the flat aesthetic used from iOS 7 through iOS 18.\n\nThe sixth developer beta of iOS 26 builds upon the design choices introduced in prior releases through updates to animations and UI elements. There's even a new sequence detailing the most noteworthy changes of iOS 26.\n\nMonday's developer beta features an entirely new onboarding sequence. Through a series of animated splash screens, Apple details the key changes within iOS 26, namely its \"Liquid Glass\" design language.\n\nThe macOS Tahoe beta got a similar onboarding video, along with an updated splash screen for the Photos app.\n\nThe intro sequence highlights the customization options of iOS 26, as well as the dynamic user interface elements that were introduced as part of the \"Liquid Glass\" redesign. Apple also emphasizes how iOS 26 makes searching within apps significantly easier through UI changes.\n\nWith iOS 26 developer beta 6, Apple altered the animations used when applications are launched. The new animations are imperceptibly faster, and they now feature a genie-type effect, making them somewhat reminiscent of iPadOS.\n\nApple also fixed the way priority notifications are displayed, eliminating a cutoff bug that was present in earlier developer betas of iOS 26.\n\nThe Lock Screen clock, meanwhile, has received an improved \"Liquid Glass\" effect, more closely resembling what Apple previewed during WWDC 2025. Some of the changes in iOS 26 beta 6, however, have more to do with sounds rather than imagery.\n\nBy opening the Settings app and navigating to Sounds & Haptics > Ringtone, you'll see six new options under the \"Reflection\" ringtone. The melodies offer different takes on the existing Reflection ringtone, and they're no less recognizable than the original, which is still the default iPhone ringtone.\n\nThe different \"Reflection\" ringtone variants in iOS 26 developer beta 6 are labeled as follows:\n\nThe iOS 26 update itself also makes it much easier to add custom iPhone ringtones. The company's decision to include a new ringtone variant goes well with its improved customization options. Apple first added an alternate version of its \"Reflections\" ringtone with the second developer beta of iOS 26.\n\niOS 26 developer beta 6, meanwhile, removed a toggle for the Camera app that was added in the previous beta. The fifth developer beta featured a \"Camera Mode Switching\" toggle that let users swipe through camera modes like they did with prior iOS releases, disabling the navigation method implemented with iOS 26.\n\nWith iOS 18, for instance, users were able to swipe through camera modes as though they were interacting with a dial. iOS 26, meanwhile, replaced this with a loupe-type element that's arguably more clunky. Unfortunately, Apple has now made it impossible to revert to the previous method of navigation without downgrading to iOS 18.\n\nOverall, iOS 26 developer beta 6 offers a few new ringtones, but not much else beyond quality-of-life improvements. Apple deploys new developer betas of iOS nearly every week or two, meaning that we'll likely see additional features and changes with subsequent software releases.",
  "medium": "Article",
  "links": [
    "https://appleinsider.com/articles/25/06/10/ios-26-vs-ios-18-is-apples-liquid-glass-a-true-redesign",
    "https://appleinsider.com/articles/25/08/05/apple-seeds-fifth-developer-betas-of-ios-26-ipados-26",
    "https://photos5.appleinsider.com/gallery/64688-134777-cropped-SplashScreens-xl.jpg",
    "https://appleinsider.com/inside/ipados",
    "https://appleinsider.com/inside/wwdc",
    "https://appleinsider.com/articles/25/06/09/apples-new-and-sweeping-user-interface-design-is-called-liquid-glass",
    "https://appleinsider.com/articles/25/06/12/custom-ringtones-are-now-slightly-easier-to-add-in-ios-26",
    "https://appleinsider.com/articles/25/06/09/apple-brings-live-translation-to-imessage-phone-calls-and-more",
    "https://appleinsider.com/articles/25/06/11/ios-26-brings-new-chatgpt-powered-styles-to-genmoji-and-image-playground",
    "https://appleinsider.com/articles/25/07/04/five-best-ios-26-features-that-will-help-you-be-more-creative?utm_source=newsletter",
    "https://www.youtube.com/c/appleinsider?sub_confirmation=1",
    "https://appleinsider.com/articles/25/08/11/apple-puts-out-its-sixth-developer-betas-of-ios-26-ipados-26",
    "https://appleinsider.com/articles/25/06/09/ios-26-is-here-with-liquid-glass-redesign-new-camera-and-apple-intelligence-promises",
    "https://appleinsider.com/inside/ios",
    "https://appleinsider.com/articles/24/06/10/apples-image-playground-is-a-new-system-wide-ai-powered-image-generation-tool",
    "https://appleinsider.com/articles/25/06/23/whats-new-in-ios-26-beta-2-new-ringtone-control-center-tweak-recovery-assistant-and-more",
    "https://i.ytimg.com/vi/UV3oLx7_NFE/maxresdefault.jpg",
    "https://appleinsider.com/inside/apple-intelligence",
    "https://photos5.appleinsider.com/gallery/64688-134779-cropped-ringtonez-xl.jpg",
    "https://appleinsider.com/articles/25/08/05/new-in-ios-26-beta-5-camera-and-mail-toggles-apple-watch-display-leak-more",
    "https://appleinsider.com/articles/25/06/09/apples-games-app-is-a-dedicated-place-for-iphone-gaming",
    "https://appleinsider.com/articles/25/06/27/five-productivity-enhancing-ios-26-features-that-are-perfect-for-business-users?utm_source=newsletter",
    "https://appleinsider.com/articles/25/06/10/visual-intelligence-in-ios-26-makes-screenshots-useful-not-just-saved",
    "https://appleinsider.com/inside/iphone",
    "https://appleinsider.com/inside/ios-26",
    "https://appleinsider.com/articles/25/06/09/apple-intelligence-opened-up-to-all-developers-with-foundation-models-framework",
    "https://appleinsider.com/inside/ios-26/tips/inside-photos-in-ios-26-macos-26----refinements-in-apples-image-and-video-management-tool",
    "https://appleinsider.com/inside/macos-tahoe",
    "https://appleinsider.com/inside/ios-18"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "new developer betas",
      "weight": 0.11987056
    },
    {
      "name": "earlier developer betas",
      "weight": 0.10718812
    },
    {
      "name": "iOS",
      "weight": 0.10295929
    },
    {
      "name": "prior iOS releases",
      "weight": 0.10200906
    },
    {
      "name": "iOS 26 developer beta",
      "weight": 0.08083303
    },
    {
      "name": "Apple Intelligence",
      "weight": 0.080523215
    },
    {
      "name": "developers",
      "weight": 0.07941775
    },
    {
      "name": "Apple Intelligence tools",
      "weight": 0.078652084
    },
    {
      "name": "custom iPhone ringtones",
      "weight": 0.0785798
    },
    {
      "name": "Apple",
      "weight": 0.07582506
    }
  ],
  "topics": [],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.89453125
    },
    {
      "name": "/Computers & Electronics/Software/Operating Systems",
      "score": 0.88525390625
    },
    {
      "name": "/Internet & Telecom/Mobile & Wireless/Mobile Phones",
      "score": 0.6474609375
    },
    {
      "name": "/Internet & Telecom/Mobile & Wireless/Mobile Apps & Add-Ons",
      "score": 0.3271484375
    }
  ],
  "sentiment": {
    "positive": 0.28605986,
    "negative": 0.1761396,
    "neutral": 0.5378005
  },
  "summary": "Apple has released the sixth developer beta of iOS 26, which includes an onboarding sequence, six additional iPhone ringtones, and a Foundation Models framework for developers to use Apple Intelligence tools in third-party apps. The update also introduced improvements to Image Playground, Shortcuts, and features for the Messages and Phone apps. Despite these changes, iOS 26 is largely known for its \"Liquid Glass\" design language, which is used across all platforms. The beta 6 also includes a new onboarding video highlighting the key changes within iOS 26. The company's decision to include a new ringtone variant aligns with its improved customization options.",
  "shortSummary": "The sixth iOS beta features a new onboarding sequence, enhanced graphics, and six additional iPhone ringtones, enhancing user experience and functionality with the \"Liquid Glass\" design.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "d81d7527b0cf4d16bea3e7f920bbde79",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://appleinsider.com/articles/25/08/11/apple-puts-out-its-sixth-developer-betas-of-ios-26-ipados-26",
      "text": "Apple has moved on to its sixth round of developer betas, with new builds available for iOS 26, iPadOS 26, macOS 26 Tahoe, watchOS 26, tvOS 26, and visionOS 26.\nThe sixth batch arrives after the fifth, which arrived on August 5. The fourth landed on July 22, the third appeared on July 7 for iOS 26, iPadOS 26, watchOS 26, macOS 26 Tahoe, and visionOS 26, but tvOS 26, arrived one day later on July 8.\n- iOS 26 and iPadOS 26 beta 5 is build 23A5318c, replacing 23A5308g\n- watchOS 26 beta 5 is build 23R5340a, replacing 23R5328g\n- macOS Tahoe 26 beta 5 is build 25A5338b, replacing 25A5327h\n- visionOS 26 beta 5 is build 23M5322b, replacing 23M5311g\n- tvOS 26 beta 5 is build 23J5339a, replacing 23J5327g\nAlong these betas, Apple also introduced second release candidate builds for macOS 15.7 (24G210) and macOS 14.8 (23J10), and a sixth beta for HomePod Software 256, build 23J5339a.\nThe main fall release includes big changes, including the new cross-platform Liquid Glass aesthetic. It consists of a largely glass-based interface with transparent elements throughout the operating system and Apple's first-party apps.\nOther changes in iOS 26 include a new battery management system, an overhauled camera app, ChatGPT integration tweaks, and AirPods feature updates.\nFor iPadOS 26, it is more productivity focused with an updated Files app, Preview, and window management changes. The macOS Tahoe changes include the Phone app, Clipboard History, and a reworking of Spotlight.\nThe fifth iOS 26 developer beta added a new mode switching toggle to the Camera app, new splash screens for Apple's apps, more bouncy animations, and more app icon tweaks. There was also an alleged image-based leak indicating a change in resolution and screen size for teh Apple Watch Ultra 3.\nThe '26 betas aren't the only ones Apple is currently testing. It has been running a second track for current-gen operating system betas.\nAppleInsider and Apple strongly insist against users installing test operating systems or beta software onto primary or \"mission-critical\" hardware. Due to the increased risk of data loss and other issues, beta participants should use secondary or non-essential hardware and ensure they have sufficient backups of their critical data at all times.\nMembers of the public wanting to try out the features of the inbound generation should really use the public betas instead.\nFind any changes in the new builds? Reach out to us on Twitter at @AppleInsider or @Andrew_OSU, or send Andrew an email at [email protected]."
    },
    {
      "url": "https://appleinsider.com/articles/25/06/09/ios-26-is-here-with-liquid-glass-redesign-new-camera-and-apple-intelligence-promises",
      "text": "Apple has launched iOS 26 at WWDC, with big enhancements to the user interface with Liquid Glass, a new Camera app, and a Photos app rework.\nJust as expected for a WWDC keynote, the 2025 edition has seen the launch of a new version of iOS. However, unlike the previous versions, Apple has gone for a big name change, by going for iOS 26 instead of iOS 19.\nIt was reasoned in rumor reports that it is a way to bring all of its operating systems to the same version number, to avoid confusion. It is also one that is year-based since it will only be officially released in 2025 for a few months and it will be 2026 for most of its existence.\nBig design changes\nThe new name is accompanied by a new look, as Apple attempts to bring a more unified appearance to its ecosystem.\nTaking design cues from visionOS, Apple has brought a more glass-like appearance to the iPhone, referred to as \"Liquid Glass. There are more glossy and edge-lit textures in view, as well as a more bubble-like appearance to everything.\nThis all starts with the lock screen with a new dynamically adjusting glass-like font for wallpapers. Those wallpapers can also be converted into a Spatial Photo, while the wallpaper can also be switched for animated album art from currently-playing Apple Music tracks.\nApp adjustments\nThe changes aren't limited to the Home Screen and general interface, as some apps will get a bunch of changes too.\nThe Camera app is getting a UI refresh to simplify controls. Previous iterations of the app have been loaded up with more controls, making it harder to navigate over time.\nSimplifying the interface should help more people take photographs or record videos on their mobile devices. You literally get two options now: Photo or Video.\nThe camera controls are still there but with lots of them hidden in a top bar, such as to quickly switch between formats for an image.\nAnother big app to get changes is Safari, which benefits from the same glass-like appearance as the rest of iOS. Functionally, it will be similar to the previous version, but the glass-like UI will be a major alteration to the core app.\nYou're now getting full-screen webpages, with a floating tab and address bar above the content.\nThis full-screen experience is extended to FaceTime, which also makes the controls disappear during a call. You also get new contact posters on the FaceTime homepage.\nThe Phone app hasn't had that many changes in its lifetime, but it will in iOS 26. The app gains a new unified layout to combine contacts, recent calls, and voicemails into a single window, making it faster for users to call a contact.\nThere's also Call Screening, which will help by automatically answering calls from unknown numbers and getting the caller's name and reason for calling. Once that information has been given, only then will the iPhone ring and display the details, so the user can choose whether to answer it or not.\nHold Assist can automatically detect hold music and keep your place in the line, while not keeping you hanging around and waiting.\nMessages gets custom backgrounds and updates to Group Chats. You can now set up a poll, with Messages using AI to suggest polls you can use.\nThe group chats can also include requests to send and receive Apple Cash. Group chat also gets typing indicators.\nMessages also benefits from spam detection, options to screen new message senders, and an expanded use of Genmoji that uses ChatGPT images.\nApple Music benefits from lyric translations, including pronunciation guides. Meanwhile, Automix will automatically beat matches between tracks.\nFor Maps, users can see new daily commute features, with the app learning your preferred routes. They will then be offered in Maps direction queries.\nVisited Places will detect where you've gone, which can help you know where you have been in the past. Users can also remove the locations if they wish.\nThe Apple Wallet now has over 20 car brands that work with Car Key support. More are on the way, with Porsche being one of the big inbound automotive names.\nApple also mentioned the continuing work on Digital ID for travelers. Flight status widgets are also on the way.\nApple also introduced the Games app, a standalone app from the App Store.\nApple Intelligence\nThe big alteration this time is Apple's allowance for third-party developers to gain access to its models. The change will make it so that developers can tap into Apple Intelligence features and the models that run them, from within their apps.\nThis change could be crucial in enabling the construction of more apps with AI, as it lets developers take advantage of the on-device processing capabilities. Cloud-based Apple Intelligence processing is still around, but allowing for on-device processing of AI functions for apps could be a big move for the future.\nMore consumer-facing, Live Translation will use AI to translate text and speech from others live, in apps other than just translate. For example, you can see transcripts of others speaking to you in a FaceTime call, or in a phone call, participants could hear an AI-generated voice after they finished speaking.\nNaturally, there's an API developers can use with it.\nVisual Intelligence has also been extended to the iPhone screen. It's possible to search for something you're looking at on your iPhone, with your iPhone.\nTaking a screenshot brings up Visual Intelligence tools at the bottom right. You can search for images but also use advanced features, such as extracting date and time information from an online event and adding them to the Calendar.\nAll new iOS, same arrival time\nBased on previous form, Apple should be bringing out a developer beta for iOS 26 later on Monday, as it starts the testing process. A public beta is unlikely to be made available for a number of weeks, as the initial developer betas are considered more risky to use and not intended for public use.\nThe formal release to the public will occur in the fall, coinciding with the release of the next iPhone generation, iPhone 17.\nThis story is breaking, refresh often for the most current information"
    },
    {
      "url": "https://appleinsider.com/inside/ios-18",
      "text": "iOS 18\nAll about iOS 18\nTable of Contents\nApple revealed iOS 18 during WWDC on June 10, 2024. The new iOS is packed with updates for every iPhone that supports the release, plus exclusive Apple Intelligence features for iPhone 15 Pro and the entire iPhone 16 lineup.\nAll eyes may have been on Apple's AI efforts, but those were held for iOS 18.1 and only for a limited number of users. The more significant updates for most users center on customization, privacy controls, and new cross-app functionality.\nEverything new in iOS 18:\n- Free placement of icons and widgets on the Home Screen within the pre-set grid\n- Dark mode icons and tinted icons for more uniform Home Screen styling\n- Lock Screen buttons for Flashlight and Camera can be replaced with other apps and shortcuts\n- Control Center gets pages, customized layouts, and third-party app access\n- Photos app is redesigned with a unified view, custom layout, and more\n- Messages has new text effects, RCS support, and emoji tapbacks\n- Mail will get new sorting options later in 2024\n- Safari has Highlights that show page summaries, Maps locations, or Apple Music links\n- An all-new Passwords app\n- Lock or hide apps\nThese features are launching across all compatible iPhones. However, Apple did reserve Apple Intelligence for devices running A17 Pro and later, meaning iPhone 15 Pro, iPhone 15 Pro Max, and all iPhone 16 models.\nApple revealed iOS 26 during WWDC 2025, which features a full redesign using Liquid Glass, additional Apple Intelligence features, and improvements to social apps. It is a big shift that relies heavily on the processing power of modern iPhone chips that will be hard for competitors to replicate.\nMore customization\nA significant portion of the iOS 18 portion of WWDC was centered around user customization. The Home Screen, Lock Screen, Control Center, and even some apps like Photos all have customization options.\nThe iPhone Home Screen has been a structured grid of icons since the device's inception. That hasn't changed beyond adding widgets, but now users can leave blank spaces in the grid for even more custom screens.\nUsers that spend time theming their Home Screen with different colors and icons will be happy to hear that it is easier than ever. Icons can be set to a dark mode, including Apple's, so they have a dark background and colorful icon.\nIf a color tint is desired, it can be applied to the dark mode icons and widgets so that everything has a color overlay. Developers can submit special layered icons to ensure the effect is pleasant when applied.\nThe Lock Screen buttons for flashlight and camera can be replaced with different app launchers, Shortcuts, and other system features. It even works on a per-Focus basis.\nThe biggest change to customization occurred in Control Center. Users can now freely place icons on up to 10 pages of Control Center.\nThese buttons can be a 1x1 square or expand to take up an entire page, like the Music button. Home controls, device controls, and even third-party app functions can be added to Control Center.\nMessages upgrades & RCS\nApple is finally adopting RCS, which means sending text messages to Android users will see a vast improvement. The Rich Communication Services standard works over the internet instead of older phone signals still used by SMS.\nWhen Apple users communicated using SMS, it meant downgrading photos and videos to tiny pixelated media suitable for the old-school communication standard. With RCS, full-sized images and video with HDR can be sent over the network.\nRCS also means users will be able to have more rich group chats, see typing indicators, and have access to cross-platform message reactions.\nApple also introduced new Messages features like text formatting, per-word animations, and an option to schedule messages called Send Later. Images and emoji will be able to be generated using Image Playground as well.\nApple Intelligence\nApple Intelligence uses on device models to offer things like Writing Tools, which can proofread text and offer different styles to make it sound more professional. In some cases, the user can hand requests off device to Private Cloud Compute servers for privacy-preserving Apple LLMs or optionally to ChatGPT.\nThere's also Image Playground, which can be used to generate emoji for use in Messages. Images can also be generated, but on a limited basis with animated themes.\nSiri is also being given a big upgrade thanks to Apple Intelligence. On-device command processing will be much better, even when the user stumbles over a command or makes a mistake.\nHowever, it appears that Apple will delay the release of the new Siri by several months. The significant undertaking of changing how Siri works for billions of daily requests will take until later in 2025 in an iOS 19 release.\nDevelopers will have to build support for Apple Intelligence, but Apple has made it straightforward by tying the features to existing app intent structures. While there are already new Siri features in beta, the full version with app intent tie ins will take time.\nApps with Apple Intelligence Siri support coming:\n- Books\n- Calendar\n- Camera\n- Contacts\n- Files\n- Freeform\n- Keynote\n- Magnifier\n- News\n- Notes\n- Photos\n- Reminders\n- Safari\n- Stocks\n- Settings\n- Voice Memos\nThe initial launch of Apple Intelligence took place with iOS 18.1 and it included Writing Tools, system wide summaries, and Photos Clean Up. More features are arriving with each point update.\nThe new app intent system that will let Siri have on-screen context for commands is expected to fully launch sometime in 2025. Apple has already asked developers to begin work on the new feature in iOS 18.2.\nPhotos Clean Up\nThe AI powered object removal feature in Photos arrived in a beta of iOS 18.1. It works similarly to third-party apps with repair tools or Google's Magic Eraser, but it runs on Apple Intelligence, on device.\nUsers that want to use the feature in iOS 18.1 will see a small eraser icon in the photo editor. The first time this is tapped, it will download the tool.\nPhotos with easily removed objects or other removal suggestions will show up with rainbow-colored and shiny material on top. Tapping these objects will automatically remove the highlighted region.\nOtherwise, objects can be removed by drawing a circle around an object or coloring in the object. The AI will attempt to understand what the image should look like without the removed item, then rebuild the area to some effect.\nResults vary based on the size of the object and what surrounds it. Complex backgrounds or ones without a reference to what should be behind what you're removing may result in a bad outcome.\niOS 18.2\nThe second wave of Apple Intelligence features included ChatGPT integration, Visual Intelligence for iPhone 16, and Image Playground. The other previously released tools also got a few updates with iOS 18.2.\nSiri can pass information provided by the user to ChatGPT privately and securely. Simply ask Siri to do so in the prompt when speaking or typing to Siri.\nVisual Intelligence also has a tie in to ChatGPT by giving users the ability to send data to ChatGPT directly from the camera. Another option exists to send camera output to Google reverse image search.\nImage Playground is a big part of the release, if a bit odd for Apple. The images generated can be made from text prompts or photos from the user's library.\nGenmoji is an offshoot of Image Playground and it gives users the ability to create an emoji by describing it. It appears as a new button on the keyboard when in the emoji picker.\niOS 18.3 launched in January 2025 with no new user-facing features. Apple did address concerns with notification summaries by making them italicized and removing news apps from the feature.\niOS 18.4\nApple released iOS 18.4 to the public on March 31, 2025 with a handful of user-facing features. Apple Intelligence was meant to get an upgrade that added more context through app intents, but it was delayed into the next year.\nApple News+ users get a new food and recipes section, Apple Intelligence gets Priority Notificaitons, and there are several new Shortcuts actions. There's also a handful of new emoji that will help drive adoption of the update.\niOS 18.5 & iOS 18.6\niOS 18.5 didn't have any user-facing features beyond a new opt-in system for on-device Apple Intelligence training. Users that opt into providing device analytics to Apple will also provide polling results that help train AI while preserving user privacy via Differential Privacy.\niOS 18.6 was a bug fix update and may be the last major update before iOS 26 launches in September.\niOS 18 release date\nApple released iOS 18 to the public on September 16, 2024. While the initial update contained all of the new customization options, the Apple Intelligence features didn't arrive until iOS 18.1, and ChatGPT, Genmoji, and Visiual Intelligence arrived in iOS 18.2.\nEverything below this point was written before WWDC 2024 and contains rumors and speculation surrounding the release. It will remain in this page for reference.\niOS 18 rumor cycle\nIt's no secret, Apple is going to have a big artificial intelligence focus in 2024 starting with WWDC. Every operating system, including iOS 18, will have AI features throughout, and some information about these rumored features has already been leaked.\nApple will focus on privacy and security with its on-device AI tools. Some rumors indicate Apple may be looking into server-side AI, but that may not be ready for iOS 18.\nFeatures will focus on small models that run without connecting to the internet unless necessary. Tools in Safari, Notes, the and Messages app will enhance basic interactions.\nOther features will likely be announced and updated, like more widget options, customization tools, and changes to HomeKit.\nThe following information has been obtained from anonymous people familiar with Apple's plans for iOS 18 or from other leaks and rumors that have been reported.\nPrivacy is paramount\nApple sees privacy as a fundamental human right. So, expect the company's AI strategy for iOS 18 to have a central theme around privacy and data control.\nExisting tools that use large language models (LLM) or generative AI tend to rely on sucking up a lot of information freely available on the web or consumer's device. These data sets and the prompts provided by users are used to continue training the models, which leads to privacy concerns.\nApple is expected to focus on training the models separate from the user's devices and data. When a model is used, it will use data available on the device to make decisions, but that user data will remain on the device and not become part of the larger model.\nThere has been some discussion of Apple offering paid access to LLMs made by other companies, but these would come with a warning about data privacy. An AI-focused App Store could be introduced.\nSiri and Spotlight with generative AI\nAn Apple-made algorithm codenamed Ajax has been rumored to have generative AI capabilities in iOS 18. It could be used to provide improved responses from Siri, Spotlight, and other system-level search tools like those in Messages.\nAjax will be able to learn from user data found in Files, Contacts, Messages, and apps exposed to Spotlight to quickly find specific content buried deep across the system and provide summaries or direct links. The on-device model will be able to generate responses to queries about user data without an internet connection.\nApple isn't looking to introduce chatbot capabilities, so don't expect ChatGPT-like interactions with Siri. However, the search tools will be able to do more than the \"result from Wikipedia\" that frustrates many users today.\nThe generative AI assistant could help with texting by providing summaries of conversations. For example, if you've been away from a group chat and return to find hundreds of unread messages, Ajax could tell you what you missed in a quick summary.\nIntelligent Browsing\nNot much is known about Intelligent Browsing just yet other than the option exists. It appears to rely, in part, on Apple's generative AI called Ajax.\nThe user will have to enable Intelligent Browsing in iOS 18 manually. It will then be able to provide information as the user is browsing, like webpage summaries or image search tools.\nThe image search functionality is in the works, but it may not make it for the iOS 18 release day. It apparently builds on the Visual Lookup feature in Photos and will enable users to perform actions on photos found on the web.\nAnother new tool is coming to Safari, but it isn't clear if it will have AI-focused capabilities. It is a tool called Web Eraser, and it can remove elements of a page by tapping them.\nPhotos Clean Up\nAnother Apple AI feature in iOS 18 will be focused on photo retouching. Clean Up will be able to remove objects from a photo using generative AI.\nThe feature will differ from conventional repair and removal tools, which rely on machine learning to determine how to remove an object. Generative AI will be able to better understand what is in a photo and what should be behind an object for more accurate object removal and photo retouching.\nApple could introduce other features like generative fill, but it isn't clear if that will arrive when iOS 18 debuts. The Photos app on Mac already has a repair tool, and it appears that Clean Up replaces that entirely.\nVoice transcription and summary\nThe Notes app will be getting Voice Memos integration, and both applications are getting AI capabilities. The on-device AI in iOS 18 will be able to take a Voice Memo, provide a voice memo transcription that is searchable, and generate a summary.\nUsers will be able to open the Notes app and start an audio recording while taking notes simultaneously. The feature is available in third-party apps already, but Apple's melding of Voice Memos and Notes may Sherlock those.\nOnce a recording has been completed, users will be able to ask questions about the content of the recording. For example, if you missed a specific part of a lecture, ask for when that topic occurred and a summary of it.\nApple Music Passthrough and Smart Transitions\nA new feature called \"Smart Transitions\" is expected to replace or enhance the existing crossfade function. It would use an understanding of the current song and upcoming song to determine how to best transition between them.\nThe existing crossfade function works the same as it always has \u2014 it simply starts playing a song a few seconds before the previous song ends.\nAnother feature called Passthrough is coming, though nothing is known about the feature beyond appearing as a setting in Apple Music and QuickTime. It seems to be associated with Dolby Atmos.\nMerging apps\nA pattern has emerged from various insider details about iOS 18 \u2014 cross-app functionality is spreading. The Calculator is going to appear in Notes, the Calendar app will have a Reminders view, and Voice Memo recordings will also get added to Notes.\nIt isn't clear if these are the only new integrations coming with the updated operating system, but it shows how Apple's first-party apps continue to evolve. Being able to take notes with an intelligent calculator function could Sherlock some of the popular notes-meets-math apps like Soulver.\nThe Calendar and Reminders integration won't be as in-depth as apps like Fantastical, but having a universal view of all tasks could be enough to bring more people into Apple's free apps. Sherlocking doesn't always have to do with being the best option, it can happen by being the good-enough default.\nBy integrating different functionality across the operating system, Apple may push more users to fall back to first-party apps. If a user can't pick the default calculator, for example, they're more likely to default to Apple's apps. Apps like Apple Music and Safari have come under antitrust scrutiny for similar system-level Apple-only functionality.\nUI changes throughout iOS 18\nThere are several rumors around how Apple might tweak the look and feel of iOS, but nothing is certain yet. The Settings app could be rearranged completely with prioritization of certain elements and new groupings based on functionality.\nThe Home Screen could get another change that allows free placement of icons and widgets. Apple has locked users to a grid that must be filled in top to bottom, leading to users coming up with clever design techniques like blank icons.\nWhile apps have been able to offer alternative app icons for years, there could be even further customization options soon. Users can already build a Shortcut with a custom icon that launches an app, but doing so removes basic functionality from the launcher like long press quick actions. Enabling customers to choose any image for app icons would be a significant change.\nOne exploit found the ability to animate icons, which could add yet another element of customization. While icons animating continuously might create chaos, Apple could choose a more stable route. Apps like Calendar and Clock are able to show accurate information by updating regularly, so such a feature could finally come to third-party icons.\niOS 18 release date\nApple will reveal iOS 18 during WWDC, which is being held June 10, 2024. It will be announced alongside iPadOS 18, tvOS 18, watchOS 11, macOS 15, and visionOS 2.\nAfter a brief beta period over the summer, Apple will release iOS 18 to the public shortly after the iPhone 16 launch in September."
    },
    {
      "url": "https://appleinsider.com/inside/ios",
      "text": "iOS\nAll about iOS\nTable of Contents\nIntroduced in 2007 for the iPhone, iOS is the highly used and well-known operating system for Apple's mobile devices. The software is also used to power the iPod Touch. It powered the iPad as well until the introduction of iPadOS.\nApple co-founder and former CEO Steve Jobs initially envisioned the operating system as \u201ciPhone runs OS X\u201d in its January 2007 unveiling. It was thought that leveraging the Mac's operating system for iPhone OS would enable developers to create apps relatively easily, without needing to relearn a new programming language or significantly changing their development practices.\nThough it initially only ran applications produced by Apple, the launch of a software development kit in March 2008 was followed by the launch of the App Store in July 2008. The ability to develop apps and sell them through the App Store created the modern-day app economy, with billions of dollars being paid to developers each month from sales of apps in the digital marketplace, as well as in-app purchases.\nName Changes\nWhen the iPhone first became available, the operating system was known as \u201ciPhone OS,\u201d following the naming convention of Mac OS X. By 2010, Apple had rebranded the operating system to use the name \"iOS.\"\nApple had to license the iOS name, as Cisco owned the trademark for its own network infrastructure software. This echoes a similar pattern between the two companies for the iPhone name, which was also trademarked by Cisco, though, at that time, Cisco had sued over alleged infringement and prompted a settlement from Apple.\niOS Releases\nAs Apple continues to develop iOS and iPadOS, the company adds more features and functionality to the software over time. The majority of new features are introduced with the main milestone releases, though Apple does deploy some changes throughout the year in version updates.\niOS 19\nApple is expected to reveal iOS 19 during WWDC 2025 on June 9. It will have a focus on improving and expanding Apple Intelligence features.\nSiri could get a significant update that makes its backend based on a large language model (LLM) rather than machine learning. That update may not go live until iOS 19.4 in early 2026.\nCustomization and personalization are likely to continue being a priority for iOS releases. Tying more system controls to Focus Modes and customization features are likely.\nLeaks and rumors point to a significant visual redesign across Apple's operating systems that will bring them closer to visionOS. Initial mockups show glassy elements over buttons and app icons that reflect light at the edges.\niOS 18\nApple revealed iOS 18 during WWDC 2024 with more customization options and social focused features, but the star of the show was Apple Intelligence, Apple's AI initiative.\nThe Home Screen gets more customization options with dark mode icons and the option of empty space. Both were things users were doing on their own with workarounds, but now they are part of the system customization.\nMany small updates were included, like a new Passwords app, a custom Control Center, changeable shortcut buttons on the Lock Screen, and RCS support. The iPhone 15 Pro supports Apple Intelligence and the entire iPhone 16 lineup is expected to support it too.\niOS 17\nFor the fourth release in a row, Apple has emphasized social interactions and device customization. In iOS 17, widgets can now be interacted with on the Home Screen, and changes across all of Apple's social apps emphasize ease of use and whimsy.\nContact Posters take over the incoming call screen and can be shared with mutual contacts automatically. Meeting new people and getting their info is also easier thanks to NameDrop, which enables a quick share of Contact Poster, number, and other pre-approved info with a tap.\nApple's Journal app was also revealed, which will bring in data from various apps and system resources for a complete view of the user's day. It prompts the user to write about their day and create personalized entries.\nThis was a jam-packed release for features and quality-of-life improvements. For example, autocorrect is now powered by a transformer language model.\nEach new update has introduced features announced at WWDC, like iOS 17.1 brought the new Favorites feature to Apple Music, iOS 17.2 added the Journal app, and iOS 17.3 introduced Stolen Device Protection.\nAfter EU regulations forced Apple to open up its platforms, some other changes were made that affected the global user base. One surprise change was the allowance of emulators on iOS for the first time.\niOS 16\nCustomization was yet again the emphasis thanks to the new Lock Screen in iOS 16. Apple took the new social and device management features shown off a year prior and enhanced them further, tying them to more system-wide controls.\nUsers can design a custom Lock Screen with widgets, assign that Lock Screen to a Focus Mode, and specify which Home Screen is tied to that Lock Screen and Focus Mode for even greater customization options. To take it further, Apple also lets users tie Focus Modes to watch faces shown on their Apple Watch, or enables Focus Filters to show only specific content within apps.\nApple also brought SharePlay to iMessage chats, which means users can start a SharePlay session without needing an active FaceTime call. Additional features include new collaboration tools across the iWork suite and Safari.\nAlso, developers get a new notification tool called \"Live Activities\" for showing live updates like delivery options, now playing status, and more. These tie in directly with the Dynamic Island found on the iPhone 14 Pro.\niOS 15\nThe ongoing pandemic was the unsaid inspiration for Apple's iOS 15 release. Social features like improvements to FaceTime, iMessage, and the newly introduced SharePlay showed Apple was aware that people were still unable to see loved ones in person.\nNew privacy controls and personal mindfulness took the stage as well. Hide My Email, Private Relay, and other small additions made iOS more private and secure for users. Focus Modes replaced the blanket Do Not Disturb mode and gave users more control over who could interrupt them and when.\nMachine learning tools were also a big focus of the new operating system update. Text was now selectable in photos across the system, and any photo taken with text is now indexed in Spotlight search.\nAnother small update was called \"Shared With You.\" A system that shows you relevant links sent to you in iMessage across the relevant apps. For example, the Apple News app will show what links were shared and who they were from in a dedicated UI location.\niOS 14\nApple announced iOS 14 at the company's first all-digital WWDC in June 2020. Despite the ongoing problems with the coronavirus and lockdown, Apple managed to put out quite a few new features for its platforms. iOS 14 released on September 16.\nApp Library and Widgets change the entire Home screen experience from top to bottom. Now apps live in the App Library and can be removed from the Home screen without deleting them. Widgets have been freed from the Today View and can be placed anywhere on the app grid.\nApp Clips are small pieces of an app surfaced by an NFC sticker, QR code, or interaction within an app or browser. They appear as cards on the display and contain less than 10MB of data for quick download and interaction. Users can then Sign in with Apple and Apple Pay to quickly complete a transaction without ever downloading an app. It's targeted primarily for uses like scooter or bike rentals, where you need to make a quick transaction on the go.\nOn-device machine learning saw big improvements in iOS 14 as well. Dictation is now handled entirely on the device and has much better accuracy. A new Translate app handles live translation of a discussion in different languages, all offline as well.\niOS 14.1 shipped alongside the iPhone 12 and iPhone 12 Pro. The update added support for the new smartphones along with 10-bit HDR video playback and edit in Photos for iPhone 8 and later.\nApple released iOS 14.2 on November 5, adding a dedicated Shazam button and over 100 new emoji. The new emoji include more inclusive options, food, and objects. The update also included eight new wallpapers, including outdoor scenes and artistic pieces.\niOS 14.3, released in December, adds support for ProRAW. The new photography mode combines for the first time Apple's computational photography with shooting in RAW. Previously, iPhone photographers had to choose between the two modes. The update also adds a new alert to help users update connected HomeKit accessories, rather than manually updating through the manufacturers' apps.\niPadOS Departure\nThe iPad launched with iPhone OS and then later iOS, with the two operating systems having relative feature parity due to the similarity of the two device classes. Over time, Apple introduced changes to iOS that added features just for iPads, including a hefty focus on multitasking functionality.\nWith the launch of iPadOS 13.1 in 2019, Apple made the difference in the operating systems more distinct by rebranding the iPad-specific version of iOS. Even after the changeover, the two operating systems still share a vast majority of their codebases and features, though with iPadOS gaining elements that allow it to take advantage of the larger display.\nThese features include Split View and Slide Over, multitasking features that display more than one app on the screen at once. iPadOS also offers picture-in-picture mode, Scribble for Apple Pencil, and other multitasking elements. Later, changes including Sidecar and external storage support helped make the iPad more conducive to work and productivity and differentiated from iOS.\niOS 13\nReleased in September 2019, iOS 13 introduced quite a few new features, including a Dark Mode that can shift between light and dark themes. The QuickPath Keyboard, similar to Swype and other trace keyboards, allows users to drag their finger across the virtual keys to type words.\nNew iCloud storage support in HomeKit enables recordings from select cameras to be stored on Apple's cloud storage service instead of a manufacturer's servers. Video is encrypted locally before being uploaded to the storage.\nCarPlay gained an overhaul, including a new dashboard view, an updated Apple Music app, and a new Calendar app. It also no longer minimizes a view when the user switches apps on the host iPhone.\nFor iPad users, a new Home screen view uses smaller icons, a new Today View can be locked to the Home screen, and external storage support allows work to be performed on external drives.\n13.1 was unusual as its release date was announced before iOS 13 shipped, and fixed a number of bugs in the original release. Along with officially moving iPads over to iPadOS, the release also added an ETA to Maps, extensive fonts support, and Shortcuts Automations.\n13.2 added Deep Fusion computational photography for the iPhone 11 lineup, an opt-in option for Siri request testing, over 70 new emoji, HomeKit Secure Video, and a number of bug fixes and improvements.\n13.3 added Communication Limits to Screen Time, new layouts for Apple News+ stories, refinements for news stories in the Stocks app, Safari support for FIDO2 keys, extended mouse support including hot corners, and a selection of minor changes.\n13.4 added full mouse and trackpad support intended for its Magic Keyboard accessory for the iPad Pro update, as well as iCloud folder sharing, new Memoji stickers, and Mail toolbar. The release also made it possible for developers to combine macOS and iOS app purchases together.\niOS 12\nApple released iOS 12 on September 17, 2018, five days after its announcements of the iPhone XS, iPhone XS Max, and iPhone XR.\nThe initial milestone release added some new augmented reality functionality, including support for a new USDZ format in collaboration with Pixar for the development of AR experiences. The new Measure app demonstrates the improvements made in ARKit 2, allowing rear cameras and a live view that measure real-world items in 3D space.\nThe release included a greater focus on digital health, with the big addition being Screen Time. The feature is made up of multiple tools to monitor device and app usage, and for users to cut down on their reliance on apps in their everyday life.\nMessages added MeMojis, which allow users to use the TrueDepth camera to map their faces, animating a personalized digital character. In a connected change, Messages also added longer Animojis, as well as the ability to detect if the user is sticking their tongue out or not.\nSiri Shortcuts gives users access to customizable macros, which can link multiple tasks and apps together. Shortcuts can trigger manually, through the share sheet, or in response to a Siri voice command. Other Siri features added in the release include being able to toggle Siri within low-power mode, new Siri accents, and the ability to ask Siri to find passwords.\nThe Photos app was overhauled with improved search and enhanced object and scene recognition. A new \"For You\" tab with improved sharing combines content from the \"Memories\" and \"Share\" tabs, with Photos still generating Memories for users periodically.\nNotifications were updated to allow groups of notifications to be collected together, tidying up sometimes lengthy lists of updates. Updates were made to the Stocks, Voice Memos, and iBooks apps, with the latter renamed Books.\n12.1 brought with it Group FaceTime, allowing up to 32 people, instead of only two parties, to take part in a video conference. 70 new emoji, Dual-SIM support, and a fix for the so-called \"Beautygate\" issue were also included.\n12.2 made over 35 feature changes but largely centered around support for HomeKit smart TVs and AirPlay changes. Apple News+ is also baked into the release, as well as alterations to the Wallet app, an Air Quality Index rating for Maps, support for second-generation AirPods, and four new Animoji characters.\n12.3 was focused on Apple TV app changes, with the app overhauled ahead of the introduction of the Apple TV+ streaming service, and the addition of Channels. More Wallet transaction changes were also included in the release.\n12.4 laid more groundwork for the launch of the Apple Card in the United States, but the update otherwise served as a maintenance release.\niOS 11\nReleased on September 19, 2017, iOS 11 brought a refreshed Control Center, iPad-specific dock and multitasking changes, and a Files app that gives Apple's mobile devices a macOS Finder type of interface.\nControl Center\nOverhauled for the second year in a row, the 2017 update's version of Control Center offered more personalization options than before. Along with the new look, it added the ability to include more controls to the collection, with a maximum of 18.\nThere are seven mandatory items kept in the Control Center: wireless options, music controls, rotation lock, do not disturb, screen mirroring, brightness, and volume. These items cannot be sorted into a different order, though users can change the order of any additional shortcuts.\nIn some cases, it is possible to expand the visible control to bring up more options. For example, a long press of the music controls will bring up a more detailed view, providing the artwork for the currently-playing song, a scrubbable timeline, and a volume control.\niPad dock and multitasking\nThe updated App Dock was improved for iPad and iPad Pro users by being more like the one used in macOS. Up to ten user-defined apps can be added to the dock, depending on the size of the display. A dividing line separates this group with another three recently used apps on the right-hand side of the dock.\nThe dock's recent apps are three Siri-predicted applications, typically including the last three apps not included in the user-defined dock list. Siri may decide to add an app to the trio that it may feel is appropriate, such as an app for a connected device.\nThe recent-apps area can also include Handoff apps. This occurs when another Apple device is nearby with an active Handoff-supported app.\nWhile it is visible from the Home screen, the App Dock is hidden while apps are in use. You can summon it by swiping up from the bottom edge of the screen. A longer swipe will bring up the updated App Switcher screen, also triggerable by a double-tap of the Home button. Open apps appear in a tiled interface, accessible by tapping and closed by swiping the image away.\nThe updated Dock is also useful for multitasking, as it is possible to drag one of the docked apps into Slide Over or Split View alongside the currently-running app. In Slide Over mode, the second app floats above the first in its own window, which can be moved around the screen to where it is needed.\nWith two apps on screen, users can now drag and drop content between apps. For example, an image from the Photos app can be dragged over to an email composition, with the image then added as an attachment to that message. This functionality also works for text and other file types.\nFor some apps, touching and holding it in the App Dock can bring up a list of recently used files, which can be opened directly with a tap or dragged into the current app.\nIt is possible to have up to four apps visible onscreen at the same time, using a combination of Split View, Slide Over, and a fourth app using the video picture in picture feature. On older iPads, this is possible, but only the Slide Over app is interactive, while the background tasks are grayed out.\nFiles\nFiles provides a Finder-style interface for files stored on the iPhone or iPad. It makes iOS file organization closer to that of macOS. You can view files within a hierarchy and tag them. You can also sort by name, date, and size, with the appropriate app opening up when a file is selected.\nThe app is not limited to files on the local device, as it is capable of connecting to cloud storage services. Alongside iCloud Drive, it can also connect to third-party services including Box, Google Drive, and Dropbox, with files downloaded and uploaded when necessary.\nWhen you long-press on the Files app in the App Dock, a list of recent files appears in a dialog box, with files able to be dragged into the current application. Files can also be dragged between the Files app and another app when used in Slide Over or Split View modes.\nOther additions\nThe 2017 update also included the following:\n- ARKit developer toolkit for augmented-reality applications\n- Do Not Disturb while Driving\n- Maps: indoor navigation and lane guidance\n- HEIF photo compression\n- H.265 codec for video compression\niOS 10\nApple released iOS 10 on September 13, 2016. The update centered around an overhaul of the Messages app, SiriKit, and Memories in the Photos app.\nMessages\nAt the time iOS 10 launched, Apple said that Messages was by far the heaviest used app on iOS. The updated iOS 10 version included emoji-related enhancements, dynamic text bubbles, and rich links with images automatically integrated into chats.\nMore importantly for the app, though, was the addition of a SDK and app store for Messages. The SDK and app store allows \"iMessage Apps\" to hook into the main app, allowing users to extend the Messages functionality and add graphic embellishments, such as \"Super Mario Run\" Stickers to chat at little or no cost.\niOS 10 also introduced full-screen effects into Messages. For example, you can send a message with fireworks in the background behind user-input text bubbles.\nSiri\nLike Messages, Siri was opened up to developers in iOS 10, allowing discrete app control through Apple's digital assistant.\nNotable third-party Apps with Siri controls baked in at launch time were Pinterest, LinkedIn, Square Cash, LookLive, Uber, and Lyft.\nAdditionally, Apple swapped out some other technologies with a deep neural network, for enhanced voice interpretation, and better Siri responses.\nHome app for HomeKit\nApple introduced a dedicated Home app inside iOS 10, giving people a central location to manage and control HomeKit accessories and allow control outside the house.\nPrior to the Home app, full HomeKit functionality required third-party apps, generally produced by individual hardware makers. While some of the vendor-specific apps could control devices made by other vendors, most couldn't.\nHome works on iPhones, iPads, and the Apple Watch. Starting with iOS 10, iPads could serve as a hub for remote control while outside the range of a local network, something previously restricted to Apple TVs.\nControl Center\nAn integral feature in iOS, the Control Center look and feel was refreshed in the 2016 release, with some features moved around. The Wi-Fi, Bluetooth, Do Not Disturb, orientation lock, flashlight, and brightness controls were kept on the main Control Center screen.\nAirPlay was modified to \"AirPlay Screen.\" Audio AirPlay features were moved to the new Music control pane.\nNight Shift controls moved to front-and-center, with a much larger button for activation.\nMusic controls were removed from the main panel and invoked by a swipe to the left. A second swipe to the left would bring up the HomeKit Control Center, with one-stop access to all of a user's accessories displayed.\nApple pre-installed app hiding\nIn response to user complaints over many years, iOS 10 finally let people partially remove apps native to the operating system.\nApps that could be partially removed, but not utterly stricken, were Calculator, Calendar, Compass, Contacts, FaceTime, Find My Friends, Home, iBooks, iCloud Drive, iTunes Store, Mail, Maps, Music, News, Notes, Podcasts, Reminders, Stock, Tips, Videos, Voice Memos, Watch, and Weather.\nThe apps aren't totally purged, and are re-installed through the App Store. Apple notes that deleting everything will only free up 150MB, however, the removal of 21 icons from the phone may be worth more to users than the freed space.\nImproved notifications and lock screen\nThe lock screen and home screen in iOS 10 gave users quick access to time sensitive information with less interaction than before.\nNotifications were redesigned, with clearer bubbles containing time stamps and the source of the notification. In conjunction with raise to wake, a user need only pick up the phone to see a notification, rather than press a button to activate the phone.\nOther features\niOS 10 also added the following:\n- Voicemail transcription\n- Better Apple Music selection and discovery\n- Fast camera app launch\n- RAW photo support, with capture of RAW images in iPhone 6s and above\n- Automatic storage optimization\n- Flashlight intensity adjustment\n- Maps improvements\n- Copy and paste between iOS 10 and macOS Sierra\n- Apple Pay on the web\n- Revamped News app\niOS 9\nIn September 2015, Apple launched iOS 9. The update brought more advanced iPad multitasking, the News app's debut, search and Siri enhancements, and a variety of technical changes including better battery life.\niPad multitasking and home screen changes\niOS 9 introduced Split View, which runs two iPad apps side-by-side. Two other iPad multitasking options, Slide Over and Picture in Picture, also first appeared in this update. The former lets users open a second app without exiting the first, while Picture in Picture allows compatible video to keep playing in a smaller window.\nOther major additions were a new search screen to the left of the home screen. The update added pre-populated info from apps and contacts based on past habits and a news feed and points of interest based on location. This \"proactive\" approach extended to other aspects of the OS \u2014 a Mail message with a flight reservation, for instance, could be used create a Calendar event, which would then send out a notification to leave for the airport based on traffic congestion.\nSiri contextual intelligence\nSiri added the ability to find photos and videos using criteria like dates and locations. It could also set a reminder based on what's currently onscreen with a phrase like \"remind me about this tonight.\"\nApple app updates\niOS' built in Notes app was enhanced with things like checklists, attachments, and sketching, while Maps was updated to restore public transit directions.Passbook was renamed as Wallet and given support for store credit and rewards cards. The update also replaced Newsstand with Apple News. The app centralizes articles into one place but with custom formatting for major partner publications.\nBattery life\nOn a technical level, Apple promised that installing the update would add up to an hour of extra battery life. The company also made various security improvements and trimmed down the amount of storage iOS updates need during installation. While iOS 8 install could require up to 4.58 gigabytes of free space, an equivalent iOS 9 download will need only about 1.3GB.\niOS 8\nApple revealed the eighth version of its mobile operating system at WWDC 2014. The update included new features, enhanced versions of popular assets like Siri, and deeper integration with OS X 10.10 Yosemite.\nCamera API\nIn this update, the company opened up its camera APIs for the first time, effectively offering third-party app developers complete manual control of the iPhone and iPad's imaging system.\nHealth\nNew apps like Health and HomeKit debuted in iOS 8. Based on HealthKit, a framework that hooks into third-party fitness and wellness apps, the Health app aggregates relevant activity and fitness data in a single repository. Users can enter information into Health, which can then ferry the data off to respective apps tapping into the hub's API. This two-way street opens the door for developers to create close-knit software that functions seamlessly with iOS.\nDuring the WWDC keynote, Apple gave the example of a partnership with the Mayo Clinic, which built an app to monitor a user's blood pressure measurements and automatically inform doctors if a reading looks suspicious without leaving the Health app.\nHomeKit\nHomeKit is a one-stop shop for all things connected. Apple partnered with a variety of brands to offer control of so-called \"smart home\" products like Internet-connected thermostats, lighting, appliances and even garage doors. The system hooks into Siri, which is able to receive commands to select from \"scenes,\" or groups of device settings predefined by the user.\nSiri\nApple updated Siri with Shazam song recognition integration and the ability to make purchases from the iTunes store.\nQuickType\nQuickType is a new predictive text input system that automatically recognizes the type of message being written, to whom and in what context. QuickType suggests what words should be used next based on contextual clues, including conversation styles that may switch between work, friends, family and more.\nThird-party keyboards\nIn addition to QuickType, this update was the first to allow the installation of system-wide third-party keyboards that can be kept offline for user privacy.\nMessages\nMessages also gained a few tricks like the ability to silence group chats, or leave them altogether. Voice messages and video could also be sent inline with text, while SMS texts will show up on Macs.\nMac integration\nIntegration with OS X 10.10 Yosemite was a big part of iOS 8. Users were first able to place and receive phone calls on their Mac, transport edited emails and documents via Handoff and create instant hotspots, among other new capabilities.\niOS 7\nApple launched iOS 7 in September 2013. The update brought a bevy of new features and changes that greatly enhanced the mobile experience and laid groundwork for future updates.\nFlat design\nThe iOS 7 user interface overhaul was a striking departure from past aesthetics. Following the departure of software lead Scott Forstall, the new Jony Ive-influenced flat design replaced Forstall's preferred skeumorphic appearance.\nStarting with the Lock Screen, there were a multitude of changed elements, including the \"slide to unlock\" bar, which went away this generation. Users still needed to \"slide\" or swipe right to unlock the iPhone, but the animation was modified to move an entire layer of the screen instead of just a small slider. The Lock Screen also faded in from black when the iPhone woke up.\nNotification Center's translucent panel popped into view with some added physics, as it \"thuds\" to the bottom of the screen, bouncing back as if rebounding from a fall.\nSwiping up from the opposite end of the screen brings the new Control Center into view, with the window gliding to just below the clock before slightly retracting in a very \"rubber-bandy\" movement. This panel, also accessible from anywhere in the OS, doesn't rely on magnitudes of motion, meaning it bounces back the same degree, no matter how fast or slow the swipe.\nPhotos\nOne of the biggest application overhauls in iOS 7 was the Photos app, which Apple redesigned to automate picture organization and take full advantage of Retina displays.\nThis update first organized the Photos application into three menu options: Photos, Shared, and Albums. The default was Photos, where pictures were automatically organized to allow users to more easily find the shot they're looking for.\nAt the macro level, photos were presented based on the year they were captured. A summary of the year appeared to the right, showing where the pictures were taken, and offering a nice recap of places the user may have traveled.\nTaking advantage of the iPhone's Retina display, tiny thumbnails of the images are presented with just enough detail to get an idea of what the picture is. Users can hold their thumb over the tiny images to view a larger thumbnail, and release their finger to pull up that particular image.\niTunes Radio\niTunes Radio became official in iOS 7, offering functionality and performance that were virtually identical to Pandora. The feature was later folded into Apple Music, which debuted two years later.\nSiri\nSiri, Apple's voice-driven personal assistant, became more helpful with iOS 7. This update first allowed Siri to control settings such as Bluetooth, Wi-Fi, and even screen brightness. By invoking Siri, users could issue a command such as \"increase the brightness,\" or \"turn off Bluetooth.\" Users could also enable or disable the new built-in flashlight functionality.\nWhen asked to turn on \"Airplane Mode,\" Siri would warn users that it will no longer be functional, as the software required an Internet connection to operate.\nSettings that are changeable are accompanied by onscreen controls that a user can manually change by tapping. For functions that Siri is not able to accomplish, such as enabling \"Personal Hotspot\", disabling LTE, or turning off location services, the system provides a quick link to the respective section in the Settings application.\nSiri also gained new, more natural sounding voices, and the option to choose a male voice as well.\nApp Store\nThe daily routine of manually installing application updates became a thing of the past in this update. Discovering new software also get easier, thanks to the enhanced capabilities of Apple's App Store in iOS 7.\nUsers annoyed by the seemingly omnipresent red update badge on the App Store icon particularly appreciated iOS 7's changes. The App Store began to automatically check for an install updates in the background when the feature is enabled.\nUsers could also control the new auto-update functionality in the \"iTunes & App Stores\" section of the iOS Settings application. There, Updates, Apps and Music can all be enabled or disabled under the \"Automatic Downloads\" section. As in earlier iOS builds, users can also decide whether auto-downloads are allowed to use cellular data.\nCamera\nApple's Camera app in iOS 7 added some features reminiscent of Instagram in an update that unified and simplified the user interface.\nSwitching between modes now brought up a Cover Flow-like flick control of the various modes, positioned above the capture button.\nIn this update, HDR capture was activated or disabled by tapping on the blue onscreen HDR indicator, rather than being hidden in a menu (along with Panorama capture) as was previously the case. When off, the HDR indicator went grey.\nApple's new Camera app photo filters, accessed by tapping on the grey overlapping circles, likely reminded users of Instagram, which popularized the idea of applying effects to photos to enhance them before posting to its social network of image feeds.\nWeather\nOne of the most significant aesthetic changes in iOS 7 was found in the iPhone's native Weather application, which was redesigned with moving three-dimensional graphics illustrating current conditions.\nThe Weather icon no longer had a static indicator of 73 degrees. That potentially confusing decision, which lasted for years on the iPhone home screen, was removed in iOS 7, and the new icon simply shows a cartoonish sun partly covered by a cloud.\nUpon opening the application, the changes were immediately apparent: The entire background became an animation mimicking the current weather conditions. On a mostly sunny day, clouds would slowly drift by, while thunderstorms would bring down strikes of lightning from the virtual sky.\nThe animations even reflected the current time, with darker nighttime animations and brighter conditions during the daylight as clouds float or snow falls.\nMessages\nWhile it wasn't given as drastic of a redesign as some other native iOS 7 applications, Apple's Messages update sported a tweaked look and some subtle but useful new features.\nThe feel of messages changed in iOS 7, as each text bubble seemed to have its own \"weight\" when scrolling. As the bubbles move when the page is scrolled, they will pull apart, only to come back together when scrolling is stopped, with a gravity-like effect applied to the items on screen.\nA new Contact button in the upper right corner of any text messages quickly brought up options to call or FaceTime the person being texted. This is a change from iOS 6, when users had to scroll to the top of a conversation to access those options.\nWhen using group messaging, if a person has a picture associated with their contact information on the iPhone, it will appear in a small circle next to their chat bubbles. Users who don't have pictures will have their first and last initial displayed.\nMore detailed message timestamps can also be viewed through a hidden new feature in iOS 7. Simply swiping and holding to the left will push sent messages to the side, and bring in specific message-by-message timestamps from off the screen. Letting go of the screen releases the page and throws the timestamps back offscreen.\niOS 6\niOS 6 launched in September 2012. The update replaced Google Maps with the first iteration of Apple Maps. It also added Siri improvements, Facebook integration, shared Photo Streams, and Passbook.\nMaps\niOS 6 included Apple Maps for the first time. The mapping and navigation software came pre-installed in the update, replacing the previously pre-installed Google Maps. Apple Maps included vector-based map elements for smooth graphics and text, and fluid panning, tilting and zooming.\nTurn-by-turn navigation functioned as expected, offering guided directions with spoken directions. Flyover brought photo-realistic interactive 3D views, and real-time traffic information kept you updated on your ETA and time-saving alternate routes.\nSiri\nThe 2012 update brought Siri to the third-generation iPad. It added support for Spanish, Italian, Korean, Mandarin and Cantonese languages. Apple also updated its digital assistant with localized touches in 15 countries while also adding Facebook and Twitter posting abilities.\nFollowing this update, Siri would be available on every new iPhone and iPad Apple released. It had debuted a year earlier as an iPhone 4s exclusive.\nFacebook integration\nBuilt-in Facebook integration launched with this update. It added a system-wide Facebook sign-in that allowed posting from Notification Center, Siri, and Facebook-enabled apps, including Photos, Safari and Maps. Friends' contact info would automatically update as they changed it on their Facebook profiles.\nApple eventually removed system-wide social-media logins in iOS 11. The company pointed to iOS share sheets as an alternative.\nShared Photo Streams\nAs an early expansion of iCloud, iOS 6 added Shared Photo Streams. The feature allowed users to select photos to share with friends, who will receive the images on their devices instantly.\nPassbook\nPassbook \u2014 which let you scan your iPhone or iPod touch to use a coupon, store card, concert or flight tickets, or hotel check-in \u2014 also debuted that generation.\nPassbook was rebranded as Apple Wallet in iOS 9.\niOS 5\nLaunching in October 2011, iOS 5 was the first version to include iCloud and Notification Center, among other significant features and improvements.\niCloud\nAlthough iCloud has evolved considerably since its launch, it was a groundbreaking service in 2011. It released with features like iTunes in the Cloud, Photo Stream, and Documents in the Cloud, keeping data in sync between iPhones, iPads, and Macs.\niMessage\nThe 2011 update marked the first appearance of iMessage, Apple's proprietary messaging platform. Built into the Messages app, the service allowed Apple device users to message each other using internet data rather than SMS. It added enhanced messaging features like typing indicators, read receipts, and multimedia messaging support.\nSiri\nSiri also debuted in iOS 5. However, it was limited at launch to the iPhone 4s, perhaps as a marketing strategy to help sell the otherwise incremental hardware update.\nNotification banners\nThis was the first update to include notification banners. Previously, iOS had used alert-style notifications, presenting a pop-up box in the center of the screen. The subtler banner design signified the increase in user notifications as the operating system evolved over time.\nOTA updates\nPrior to iOS 5, software updates required users to connect an iPhone or iPad to iTunes on a Mac or PC. Wireless updates arrived in iOS 5, pushing firmware upgrades over the air. Along with iCloud, this change aimed to remove the desktop computer as a central and necessary component of Apple's mobile-device ecosystem.\niOS 4\nLaunching in 2010, iOS 4 was the first version to include the \"iOS\" branding. Previously, Apple's mobile operating system had been called \"iPhone OS.\" The new naming scheme followed soon after the iPad's debut, defining the software as spanning across multiple device categories.\nMultitasking\nThis was the first version that brought any form of multitasking to Apple's mobile devices. The initial version added the app switcher \u2014 accessed by double-tapping the home button \u2014 and limited background functionality for VOIP, location, and audio apps.\nFolders and wallpapers\nThe 2010 update introduced home screen folders and custom wallpapers. Before this update, users had no way to organize app icons apart from re-ordering them. Folders allowed users to fit many more apps into less home screen space.\nWallpapers \u2014 including both Apple's and custom user wallpapers \u2014 allowed users to customize their devices beyond the iPhone's previous plain black background. This coincided with the iPhone 4's Retina display, which upped the handset's pixel density to 326 PPI.\nWallpapers had first appeared on the iPad in version 3.2, several months before the iOS 4 announcement.\nFaceTime\nLaunching alongside the iPhone 4, which added a front-facing camera to Apple's smartphone, FaceTime made its debut in iOS 4. The video-calling service allowed Apple users with capable hardware to have face-to-face conversation on their mobile devices. Before this, users had primarily associated video-calling with desktop apps like Skype.\nOther features\niOS 4 also added the following:\n- System-wide spell checking\n- iBooks app for iPhone\n- Unified Mail inbox\n- Game Center\niOS 3 (iPhone OS 3)\nApple released iOS 3, called \"iPhone OS 3\" at the time, at WWDC 2009.\nCopy/paste\nWhile it may be difficult for today's smartphone users to imagine lacking it, iOS 3 was the first version to include copy-cut-paste capabilities.\nVideo recording\niOS 3 also brought video recording to the iPhone for the firs time. At launch, the feature was exclusive to the iPhone 3Gs.\nMMS\nThe 2009 update also added support for Multimedia Messaging Service (MMS). This allowed iPhone owners to send videos, pictures, contacts, locations, and voice recordings in the Messages app.\nVoice memos\niOS 3 added the Voice Memos app, letting users dictate audio recordings.\nSpotlight\nThis update offered Spotlight system-wide search for the first time.\niOS 2 (iPhone OS 2)\nIn 2008, Apple launched the first annual update to its iPhone and iPod touch software.\nApp Store\nPerhaps the most significant feature addition in iOS history, Apple added the App Store in iPhone OS 2. This marked the first time users could install third-party apps officially.\nPreviously, iPhones could only run web apps with home screen shortcut icons. Only jailbroken iPhones had been able to run native apps from non-Apple developers.\nThe App Store addition launched an entirely new app economy, netting developers billions of dollars in revenue and changing how users interact with their smartphones. Apps made the iPhone less like a phone with smarts and more like a pocket computer that was also a phone.\nApple gave the Mail app an overhaul, allowing for push notifications for the first time.\nMaps\nMaps, which still used Google Maps for its data, added Google Street View in this update.\niOS 1 (iPhone OS 1)\nApple's first mobile operating system designed around touch was announced for the original iPhone in 2007.\nWhen Apple announced the first iPhone, Jobs told the audience:\n\"[It has] software that\u2019s at least five years ahead of what\u2019s on any other phone. Now how do we do this? Well, we start with a strong foundation. iPhone runs OS X.\"\nThe company later revised its description, naming its mobile software \"iPhone OS.\" Only in 2010, after the iPad arrived running a big-screen variant of the same operating system, did the company begin calling the software \"iOS.\"\nThe beginning of a revolution\nThis initial version of iOS was the first time the public had used now-ubiquitous smartphone features like pinch and spread to zoom, onscreen keyboards, and natural scrolling.\nMany other phones of that era had used physical navigation methods, like the BlackBerry Pearl's trackball or the Motorola Razr's arrow buttons. Some niche devices had already offered multitouch screens, but the iPhone and iPhone OS was the first with a highly polished version of it in a mass-market device.\nJobs described the first iPhone as a \"widescreen iPod with touch controls,\" a \"revolutionary mobile phone,\" and a \"breakthrough Internet communicator.\"\nApps\nThe iPhone didn't yet run native third-party apps. At the time, Apple instructed users to run and install web apps.\niPhone OS 1 provided customers' first glimpses of the mobile Safari web browser, the YouTube and Maps apps through a partnership with Google, and the iPod app for playing music and video. Pre-installed apps also included Phone, Weather, Calendar, Clock, Calculator, Photos, Stocks, Notes, and Settings.\nThe lack of native third-party apps at launch led some users to hack their iPhones in a warranty-voiding process known as \"jailbreaking.\" In future updates, Apple would add features like copy/paste, MMS, do not disturb, group texting, and full-background multitasking that had debuted in the jailbreaking community.\niTunes\niPhone OS 1 required users to set up and sync their devices with a desktop Mac or PC running iTunes, much like the incredibly popular iPods of that era. Only when iCloud arrived in iOS 5 did the iPhone begin to gain full independence from iTunes."
    },
    {
      "url": "https://appleinsider.com/articles/25/06/09/apples-new-and-sweeping-user-interface-design-is-called-liquid-glass",
      "text": "All of Apple's operating systems have received a redesigned user interface called \"Liquid Glass,\" featuring translucent elements with rounded corners, and an all-around new look.\nOn June 9, at Apple's annual Worldwide Developers' Conference, the iPhone maker unveiled a series of design changes that have been implemented across all software platforms.\nThe company's goal was the creation of a unified design language that would lead to a harmonious experience when moving between different Apple products. The new design is available on iOS 26, iPadOS 26, macOS Tahoe 26, watchOS 26, and even tvOS 26.\nThe operating systems now have a similar look across the board, with a glass-like aesthetic inspired by visionOS. Apple's new \"Liquid Glass\" material behaves like real-world glass, particularly in the way that it refracts light and reacts to movement dynamically with specular highlights. Apple says it uses real-time rendering to achieve these effects\nIt adjusts based on the content you're watching, making it somewhat reminiscent of the blur effects introduced with iOS 7. The new material extends to various user interface elements, including buttons, switches, and more.\nLiquid Glass is used across new dynamic operating system elements that adjust according to the user's needs, allowing for a more intuitive experience. This means that tab bars can shrink and expand as needed. User interface elements designed for rectangular displays have now now feature rounded corners, much like Apple's more recent hardware releases.\nThe new Liquid Glass design language extends to the entirety of Apple's operating systems, including the Control Center, Lock Screen, Notification Center, Lock Screen, and widgets. iOS 26 features new Home Screen icons that were made using multiple layers of Liquid Glass, and there's even a new Clear look, in addition to the existing Light and Dark modes.\nThe Clear look is available on macOS Tahoe as well, making it so that both the Dock, its apps, and the Menu Bar all become transparent. This makes the display appear larger, according to Apple. On iOS, the Lock Screen clock now uses the same Liquid Glass material and it adapts to the image chosen by the user. The clock shrinks and expands as needed.\nDevelopers will also have access to an updated set of APIs, which will allow them to use the new Liquid Glass design for their own applications.\nApple says the new design blurs the lines between hardware and software, and explains that Liquid Glass was made through the close collaboration of the company's hardware and software development teams. Apple called the new material its \"broadest design update ever.\"\nStill, the redesigned user interface looks and feels familiar, and is a far cry from the circular app icons that were rumored ahead of WWDC."
    },
    {
      "url": "https://appleinsider.com/inside/wwdc",
      "text": "WWDC\nAll about WWDC\nTable of Contents\nWWDC is an Apple event that takes place over five days, with the keynote address on the first day. The keynote has become increasingly popular among non-developers due to the presentation and the hype it generates.\nBefore the COVID-19 pandemic, Apple would invite thousands of developers to attend the conference in person. Attendees would fill the Steve Jobs Theater on the Apple Park campus to catch a glimpse of the future and get a chance to interact with Apple engineers face-to-face.\nAfter the threat of the pandemic was understood, Apple pivoted to a digital-only conference in 2020. The keynote presentation was filled with panning drone shots, high-quality editing, and fast-moving segments. All sessions and other keynotes were digital as well, with sessions taking place via Webex video chats.\nThe 2021 WWDC was digital-only as well due to the ongoing pandemic. With the shift back to normalcy in 2022, Apple relied on a hybrid approach.\nAt each WWDC, Apple unveils its latest operating system updates, software changes, and Apple Intelligence upgrades. Though the conference is meant to be dedicated to developers, Apple sometimes sneaks in hardware or service updates as well.\nUpdates are expected for the following operating systems:\nThe following developer tools are also usually updated:\nThe keynote address isn't able to reveal every change and update to all of Apple's platforms, so the remainder of the week is dedicated to sessions. These sessions cover all the new features and documentation surrounding what updates developers will need to perform before the software's fall release.\nApple has been known to announce some details ahead of WWDC to keep the conference focused on developers. The keynote is often packed to the brim with software details, so some hardware features or service updates are announced via a press release before the event.\nThe company has diverted from its usual announcement cycle to reveal hardware or services during a WWDC keynote before. Some notable exceptions included Apple Music in 2015, HomePod in 2017, the M2 MacBook Air in 2022, and Apple Vision Pro in 2023.\nWWDC 2025\nJune 9, 2025\nThe biggest redesign since iOS 7 was revealed during WWDC 25, and along with it, every OS was renamed to have version number 26. The Liquid Glass design opened up a lot of new tweaks and changes across the ecosystem.\nApple Intelligence didn't get any real upgrades in capability, but new features were added. Live Translation appears in Messages, FaceTime, and the Music app, while Image Playground has a ChatGPT option.\nOperating systems expected:\nNo hardware was announced, so no Apple Vision Pro updates or Mac Pro with M3 Ultra. Apple Intelligence took a back seat, and there was almost no mention of Apple's work on the app intent-based Siri.\niOS and iPadOS saw some of the biggest changes across the ecosystem. iPadOS has a new multitasking system that adds a Menu Bar and traffic lights, while iOS gained more functionality in several apps.\nWWDC 2024\nJune 10, 2024\nApple held WWDC 2024 to announce the usual range of operating system updates. But instead of surprising with new hardware, the company finally unveiled its plans for Apple Intelligence.\nThe trend of adding new customization options to iOS and iPadOS continued, while Apple meshed some app features together as well. Despite AI catching everyone's attention, it was still a feature-filled set of OS updates.\nOperating systems announced:\nSome expected an M3 Ultra and updates to the Mac Studio and Mac Pro, but that didn't happen. It seems Apple will skip M3 Ultra and wait for M4 Ultra in 2025.\nApple Intelligence focused on local models that run on-device, but can call out to a Private Cloud Compute server run by Apple if more power is needed. Users will benefit from a more intelligent Siri, Writing Tools, and Image Playground.\nWWDC 2023\nJune 5-9\nApple continued its trend of announcing social and customization features across its operating systems. A few surprises were also revealed, like the Apple Vision Pro and the Mac Pro with Apple Silicon.\nOperating system releases\nRumors had suggested 2023 would be a quiet year for software, but Apple pushed back on that notion with interactive widgets on iOS, a redesigned watchOS, and an all-new platform called visionOS. Developers are in for a busy summer as they prepare for spatial computing.\nWWDC 2022\nJune 6-10\nThis hybrid in-person and digital event focused on customization in iOS and developer APIs. Stage Manager stole the conversation as a new multitasking feature for iPad and Mac.\nUpdates announced\nApple also announced the M2 processor and M2 MacBook Air during the keynote. This was a surprise, as the M1 still hadn't arrived in the Mac Pro and never would.\nWWDC 2021\nJune 7-11\nThis digital-only event focused on social features and privacy. Cross-platform features were also enhanced thanks to Universal Control and SharePlay.\nUpdates announced\nApple also introduced Focus Mode, a feature that replaces Do Not Disturb with refined controls over what notifies you when. Other improvements include bringing Shortcuts to macOS and free widget placement in iPadOS.\nWWDC 2020\nJune 22-26\nThe ongoing pandemic created a lot of uncertainty going into June 2020, but Apple managed to come out swinging with a high-quality pre-recorded event. Since many of the features are worked on over the previous year, Apple didn't have any time to prep for work-from-home-focused releases.\nUpdates announced\n- iOS 14\n- iPadOS 14\n- macOS Big Sur\n- watchOS 7\n- tvOS 14\nApple continued the trend of pushing more iOS-like features to the Mac and unveiled App Tracking Transparency. Now, apps must notify users when they are going to track them, what data is collected, and how it is used.\nMost importantly, Apple announced it would transition the Mac to custom Apple Silicon, away from Intel. The transition would take two years at most and bring ARM to the Mac.\nWWDC 2019\nJune 3-7\nThere were some surprises outside of the usual operating system updates during the 2019 developer conference. Apple revealed iPadOS, the new operating system for the iPad that takes advantage of the larger display. It also shared a preview of the Mac Pro and Pro Display XDR, a top-end Mac for professionals that would debut later in the year.\nUpdates announced\n- iOS 13\n- iPadOS 13\n- macOS Catalina\n- watchOS 7\n- tvOS 14\nOther new features included SideCar, which enables using iPads as an external display for the Mac. Also, Apple Watch gained menstrual cycle tracking."
    },
    {
      "url": "https://appleinsider.com/articles/25/08/05/new-in-ios-26-beta-5-camera-and-mail-toggles-apple-watch-display-leak-more",
      "text": "The fifth developer beta of iOS 26 has arrived, and it brings an additional setting for the Camera app, along with some hidden details about a future Apple Watch Ultra. Here's what's new.\nOn Tuesday, two weeks after the debut of the fourth developer beta, Apple released iOS 26 developer beta 5. The update increases the build number to 23A5308g, replacing 23A5297i.\nAs a whole, the iOS 26 update introduced a variety of useful enhancements, including improvements to Image Playground, Shortcuts, and new features for the Messages and Phone apps.\nAlong with a dedicated Games app, Apple implemented a Foundation Models framework that enables developers to utilize Apple Intelligence tools in third-party apps, while Visual Intelligence now supports screenshots. Some of these new features are ideal for creative work on iPhone, while others are arguably better for business users.\nStill, iOS 26 is primarily known for the controversial \"Liquid Glass\" design language, which is used across all of the company's platforms. The software features dynamic user interface elements that mimic the look of real-world glass, replacing the flat aesthetic used from iOS 7 through iOS 18.\nThe fifth developer beta of iOS 26 builds upon the design choices introduced with prior releases, through updated animations and system icons. Surprisingly, though, the update also contains an Apple Watch display size that doesn't correspond to any known model.\niOS 26 beta 5 reveals new Apple Watch screen size\nThe operating system features an Apple Watch-related image with a resolution of 422 by 514 pixels. For comparison's sake, the current Apple Watch Ultra 2 has a resolution of 410 by 502, which is somewhat smaller.\nThe new image could be related to the Apple Watch Ultra 3. If its screen retains the same physical size of 1.92 inches diagonally, the pixel density will grow from 335.83 pixels per inch on the Apple Watch Ultra 2 to 344.58 ppi on the Apple Watch Ultra 3.\nHowever, if the pixel density is maintained at 335.83 ppi, the diagonal measurement of the Apple Watch Ultra 3 would have to be 1.98 inches, or 3.1% bigger. This ultimately means the device could have a slimmer bezel, while a change in the physical size of the watch seems unlikely.\nOther assets found within the fifth developer beta of iOS 26 correspond to existing products. Apple did update some of the icons and animations within the operating system, though, and there are even a few new splash screens.\nNew splash screens, updated app icons, and bouncy OS animations\nTuesday's developer beta introduces a redesigned AirDrop icon that more closely aligns with the established \"Liquid Glass\" aesthetic. Animations used throughout the operating systems were also tweaked, albeit ever-so-slightly. The fifth developer beta of macOS Tahoe also has a new icon for hard drives.\nThe animations in the fifth developer beta of iOS 26 are more responsive and bouncy, relative to the ones from previous developer betas. This change extends to the passcode screen and can be seen when swiping through different pages in the Control Center.\nUnlike the third and fourth developer betas of iOS 26, however, Tuesday's software update doesn't alter the \"Liquid Glass\" material. As a result, most of the operating system looks about the same. Select interface elements were updated with the new material, though it's hardly a noticeable change.\nWhen editing the Home Screen, for instance, the minus buttons displayed on app icons now use Apple's \"Liquid Glass\" material. With iOS 26 developer beta 5, Apple also added new splash screens for the Apple Music, Journal, and Notes apps. The update does include more meaningful changes, however.\nNew toggles for the Camera and Mail apps\nThe fifth developer beta of iOS 26 features a new Mode Switching option for the Camera app. Found in the Settings app, the new toggle labeled Classic Mode Switching restores the old way of navigating through the different modes in the Camera app.\nWith iOS 18, for instance, users were able to swipe through camera modes as though they were interacting with a dial. iOS 26, meanwhile, replaced this with a loupe-type element that's arguably more clunky. Thankfully, Apple has made it possible to revert to the previous method of navigation without downgrading to iOS 18.\nThe Mail app, meanwhile, has been updated so that the Select button is once again visible. It's at the top left of the screen, right next to the ellipsis icon. There's also a new toggle that lets you revert swipe direction.\nOverall, the fifth developer beta of iOS 26 delivers a few useful enhancements, but nothing groundbreaking. Apple deploys new developer betas of iOS nearly every two weeks, meaning that we'll likely see additional features and changes with subsequent software releases."
    },
    {
      "url": "https://appleinsider.com/articles/25/06/27/five-productivity-enhancing-ios-26-features-that-are-perfect-for-business-users?utm_source=newsletter",
      "text": "While the new glass-like design may be the most visible change within iOS 26, the operating system also has five features that might be particularly appealing for business users.\niOS 26 made its debut on June 9 at WWDC 2025, in a relatively subdued keynote event. While Apple put a strong emphasis on its cross-platform \"Liquid Glass\" design language, there's more to iOS 26 than meets the eye.\nSome of the upgrades and improvements in iOS 26 allow you to express your creativity more easily, like the new ChatGPT-powered styles for Image Playground. Other features, meanwhile, will help you get work done, and they might be especially useful for those in the business world.\nPhone screening and voicemail spam reporting\nWith iOS 26, Apple is stepping up its fight against spam calls and voice messages through improvements and new options in the Phone app.\nThe iPhone maker has rolled out a new Call Screening feature, which saves you the hassle of answering calls from unknown numbers. It makes things easier, as you don't need to manually verify whether or not the person on the other line is someone you want to speak with.\nInstead, when an unknown number calls, your iPhone will prompt the caller to provide a name and a reason for calling. That information is then relayed to the end user, allowing for quick decision-making with effectively no effort.\nApple's Call Screening feature helps filter interruptions, such as telemarketers and scammers, without blocking unknown phone numbers indiscriminately.\nThe call screening feature is especially useful if your phone number is publicly available and affiliated with a business, organization, or other legal entity.\nThe Phone app in iOS 26 also lets you report spam voicemails directly to Apple. If you get a voicemail from an unknown number, tapping on the message now reveals a \"Report Spam\" button.\nYou now have the option to report it and keep the voicemail or report it and delete it. Either way, the message is flagged and sent to Apple for review.\nThese reports don't automatically block the caller. You'll still need to take that extra step manually, just like before. But the information could be used to improve Apple's filtering algorithms, especially if a large number of users flag similar messages.\nPolls in Messages\nWhile the Messages app also has a similar spam-detection feature, it's not the only improvement the app received with iOS 26.\nThere's now a new option to create polls within group chats. These in-app polls allow you to propose options and cast votes, without the hassle of downloading a separate app. It's all baked into iMessage.\nWith the new polling feature, it's possible to add multiple options, and all members of the group chat can vote, with results appearing in real time. The in-app poll capability is meant to be quick and intuitive, meaning that using it is fairly straightforward.\nApple's polling feature also leverages Apple Intelligence, the company's on-device AI software, available on the iPhone 15 Pro and newer. When Apple Intelligence detects plan-related questions, you'll automatically see an option to create a poll.\nFor instance, if someone writes \"What movie should we see tonight?\" the Messages app will prompt the user to set up a poll with suggested titles. This only works with iMessage, however, as the in-app poll feature is not available for SMS or cross-platform chats.\nWhile apps like Telegram and WhatsApp have had polling features for years, their presence in the Message app makes things much easier for end-users, who no longer need to deal with third-party apps just for polling options.\nThe in-app poll feature will allow for near-instant decision making, whether you're discussing a business strategy with coworkers or making plans with friends.\nLive Translation is now a system-wide feature\nAlso available in Messages is Apple's new Live Translation feature, which helps users break down language barriers in real time.\nThe company's Live Translation feature is powered by on-device AI processing models. It works across first-party apps like FaceTime, Messages, and Phone. There's even a new Call Translation API that developers can use for third-party applications.\nFor example, the Live Translation feature can immediately translate text into other languages as you type out a message in iMessage. As texts in other languages come in, the Apple Intelligence feature can instantly translate them for you.\nIn FaceTime, the feature provides live captions during video calls. For audio-only calls, it can translate and speak the conversation aloud.\nThe feature provides real-time, on-device interpretation of conversations without sending data to the cloud. However, you will need an iPhone 15 Pro or newer to use Live Translation, as the feature requires an Apple Intelligence-compatible device.\nThe supported languages vary by app. In Messages, live translation works with English (U.S., UK), French, German, Italian, Japanese, Korean, Portuguese, Spanish, and Chinese Simplified.\nFor Phone and FaceTime, support is narrower at launch. It's limited to English (U.S., UK), French, German, Portuguese, and Spanish. Apple says more languages will be added by the end of 2025.\nLive Translation is a meaningful upgrade for business users working across borders. It's also great for tourists or for communicating with family members from different parts of the world.\nUnlike existing standalone apps, Apple's solution is embedded in everyday communication tools that are already present in iOS. The company's Live translation doesn't rely on cloud-based processing the way Google and Samsung's features do, either.\nMessages now has typing indicators for group chats\nAlong with Live Translation and enhanced spam-detection features, Apple's Messages app has gained another long-overdue improvement \u2014 Typing indicators.\nWhile communication applications such as Slack, Discord, Facebook Messenger, and WhatsApp have all had typing indicators for years, the feature was notably absent from iMessage.\nWith iOS 26, however, you'll finally be able to know who's typing at any given moment. This will make group communication significantly easier, with interactions being visible in real-time. It also works in one-on-one chats.\nThis feature is great for business users with multiple iMessage group chats. It makes it easier to control the flow of a conversation, and offers insight into who's actively participating, or who might be hesitating to provide input, or an idea.\nShortcuts are now more powerful with Apple Intelligence\niOS 26 brings Shortcuts and Apple Intelligence closer together, allowing you to complete tasks with AI much more quickly.\nAll of the Apple Intelligence tools so far are now available in what Apple calls Intelligent Actions.\nIn the first and second developer betas of iOS 26, the main actions are:\n- Change the tone of text\n- Make list from text\n- Make table from text\n- Proofread text\n- Rewrite text\n- Summarize text\n- Use model\nThat last is potentially the most significant because it lets Shortcuts users specify which model of AI they want to use. The options here are:\n- Private Cloud Compute\n- On-Device\n- Extension\n- Ask Each Time\nPrivate Cloud Compute leverages Apple's privacy-enabled cloud-based processing systems, while On-Device uses the locally stored Apple Intelligence LLM. Extension currently refers to ChatGPT, but it could allow for other AI model options in the future, such as Google Gemini.\nAsk Each Time understandably lets users choose a model every time a particular shortcut is used.\nIntelligent Actions can be used independently or alongside traditional Shortcut options, which can greatly simplify workflows. Instead of having to navigate to Writing Tools whenever text alteration or summarization is needed, for instance, a shortcut can help you make a text more concise in just a few clicks.\nApple's example is an impressive one that has a student sharing their notes and an audio recording of a lecture into a shortcut. The shortcut then uses existing actions to transcribe the audio, and then the new Intelligent Actions to compare that to the notes.\nSimilarly, a shortcut could be used to add the date and time to text, then summarize it all, and email the summary to someone.\nThe new-and-improved Shortcuts app offers endless possibilities, and Intelligent Actions are sure to benefit students and business users alike, given that meetings could be processed like lectures in Apple's example.\nOverall, iOS 26 offers a multitude of new features that will help you get work done more easily. Whether it's the Live Translation feature for communicating with international associates or the Call Screening capability, which filters out spam callers, there's something for just about everyone.\nApple's macOS Tahoe and iPadOS 26 share some of the productivity features with iOS 26, but the two opearating systems also have platform-specific enhancements that are just as impressive."
    },
    {
      "url": "https://appleinsider.com/articles/25/06/10/ios-26-vs-ios-18-is-apples-liquid-glass-a-true-redesign",
      "text": "With iOS 26, Apple unveiled a unified design language with translucent elements that mimic the look of real-world glass. Here's how it compares to iOS 18.\nOn June 9, at its annual Worldwide Developers' Conference, the iPhone maker finally unveiled the long-rumored visionOS-style redesign we were all waiting for. The company's latest operating systems all received a revamped user interface with a new material dubbed 'Liquid Glass.'\nApple says that Liquid Glass uses real-time rendering to imitate the way glass refracts light, and explains that the new material reacts to movement dynamically with specular highlights. It's used across various user interface elements, including buttons, switches, app icons, the Lock Screen, Control Center, and more.\nThe company called Liquid Glass its \"broadest design update ever,\" but the claim is a bit of an exaggeration. Apple compared the redesign to iOS 7, saying that it \"sets the stage for the next era\" of its products, even though the change is nowhere near as drastic as it was back in 2013.\niOS 26 vs iOS 18: 'Liquid Glass' feels like a derivative change rather than a fresh new look\nMore than a decade ago, with the release of iOS 7, Apple phased out its iconic skeuomorphic design language. Gone were the hyper-realistic icons and app designs that mimicked real-world objects, most notably in iBooks and Calendar. The company switched it all out in favor of a flat design with bright colors and dynamic blur effects.\nThat design language stuck with iOS for the next eleven years, but its influence still lingers even in iOS 26. The operating system has retained the distinct color palette introduced with iOS 7, though its app icons have received a few visual tweaks. Even the all-new Liquid Glass material bears some resemblance to the blur effect introduced in iOS 7 and used through iOS 18.\nThe cross-platform design aspect of iOS 26 isn't anything new either \u2014 Apple has tried to unify its operating system designs before. Years ago, iOS 7 and macOS 10.10 Yosemite were early incarnations of the company's design unification efforts.\nmacOS Big Sur is the most obvious example, as Apple's desktop operating system gained square app icons and a redesigned Dock, both reminiscent of iOS and iPadOS. Previous releases of macOS maintained a distinct set of icons and UI elements that set them apart from Apple's mobile OS releases.\nDespite all the hype, other operating systems have used arguably similar glass-like transparency effects in the past. Windows Vista and Windows 7, for instance, featured a visually distinct Aero theme, which some users have compared to the newly announced iOS 26.\nMicrosoft phased out its iconic Aero interface with Windows 8, though, meaning that it hasn't been in use for over a decade. Relative to the Aero theme, Apple's implementation is much better at emulating real glass, as the Liquid Glass effects are dynamic rather than static.\nOverall, Apple's latest Liquid Glass material arguably represents consistency rather than true innovation, given Apple's previous design unification efforts. It's in line with what Apple and other manufacturers have done in the past, rather than something that has never been done before. It may not be up to everyone's liking.\nThough iOS 26 leaves a lot to be desired, the operating system does have a few areas where it truly stands out.\niOS 26 vs iOS 18: Where Apple's latest OS truly shines\niOS 26 introduces an entirely new \"Clear\" look that makes Home Screen apps fully transparent. It's an interesting choice, but not exactly groundbreaking either.\nIt builds upon the customization options introduced with prior iOS versions, such as the Light, Dark, and Tinted options that were already available in iOS 18. One benefit of the new Clear look is that users no longer have to rely on jailbreak tweaks to achieve transparent Home Screen icons, as they once did with Cydia tweaks such as WinterBoard and similar tools.\nAnother key change with iOS 26 is the introduction of dynamic elements that can increase or decrease depending on the user's needs. These upgraded context menus and tab bars utilize Apple's new Liquid Glass look, replacing the rectangular and often white UI elements found in previous iOS releases.\nYou'll notice the new UI elements across various system applications, including the App Store and Apple News. In the News app, for instance, the tab bar moves out of the way when you're scrolling, providing an almost full-screen experience that prioritizes the content you're trying to read. It's a neat change, overall.\nThe dynamic user interface elements allow for greater consistency across system applications and make navigation easier. Still, it's unlikely that the average user will notice the difference, given that iOS has been a mix of blur effects and rounded corners for years.\nThe Liquid Glass material is also noticeable in the Safari app. The new material is used for the URL bar and back buttons.\nThe Camera app now has a simplified user interface, and its buttons feature rounded corners as well. It makes for a useful change, unlike most of the redesign-related alterations in iOS 26.\nEven so, the new user interface elements wouldn't have looked out of place, even if they were added years ago. As for why this type of design wasn't implemented earlier, hardware limitations are a possible explanation.\nApple says that its Liquid Glass material was created through the close cooperation of its hardware and software teams. The software takes advantage of the improved hardware available in Apple's latest A18 and A18 Pro chips, which have the necessary processing power to achieve these glass-like effects.\nOlder hardware would likely struggle with Liquid Glass, so it's not much of a surprise that iOS 26 dropped support for the 2018 iPhone XR and iPhone XS. Years ago, when the iPhone 4 received iOS 7, the device never got any of its impressive blur effects.\nEnabling the blur effects through jailbreak tweaks revealed just how poorly the device performed, and a similar scenario likely would have affected 2018 iPhone models with iOS 26.\niOS 26 vs iOS 18: Why Apple may have opted for a redesign\nThough rumors of an operating system redesign have been floating around for at least a year, Apple may have chosen 2025 for a specific reason. The redesign is little more than a fresh coat of paint, but the company may have used it to hide imperfections, so to speak.\nTo be more specific, Apple's iOS 26 redesign serves as the perfect distraction from its Apple Intelligence debacle. Siri still lacks the personal context and in-app awareness features that were promised a year ago at WWDC 2024, and this very issue is the subject of two separate lawsuits filed against the company.\nIn short, Apple over-promised and failed to deliver, and the company was reportedly embarrassed about it, behind closed doors. With that in mind, it's not much of a surprise that WWDC 2025 was relatively light in terms of Apple Intelligence features. Sure, there's a new Foundation Models framework and an improved Shortcuts app, but not much else.\nApple may have wanted users to focus on the new glass-like design more than anything else, which is why it was featured at the beginning of the WWDC 2025 keynote. The company even went so far as to show off some of the tools presumably used during development \u2014 physical lenses and magnifying glasses in the shape of iOS user interface elements.\nThe distraction aspect alone, however, wouldn't have been enough to justify the redesign. During the keynote on June 9, Apple said that Liquid Glass would set the stage for future products, and the company may have had a specific device in mind. There have been rumors of an all-glass iPhone, with no display bezels, a curved frame, and no camera cutout.\nIt's been rumored that iOS 26 would serve as an indicator of what future products strive toward, that the operating system will influence the look of new hardware.\nSpecifically, the 20th anniversary iPhone is said to have the codename \"Glasswing,\" referring to a type of butterfly with translucent wings. It's set to debut in 2027, so we'll know soon enough if Apple's software influenced its hardware, and to what extent."
    },
    {
      "url": "https://appleinsider.com/articles/25/06/12/custom-ringtones-are-now-slightly-easier-to-add-in-ios-26",
      "text": "Apple is making it easier for iPhone owners to add their own custom ringtones, but the change in iOS 26 is only a slight improvement versus iOS 18.\nAdding ringtones to the iPhone is almost always an investment in time or money. Apple really wants its users to buy new tones via the Tone Store, charging for brief snatches of music from popular musical artists.\nThe alternative is to spend time and effort creating your own custom ringtones. We have written guides about it before, with it requiring the user to make an audio file that lasts up to 30 seconds in Garageband, exporting as a ringtone, then adding it to their iPhone's ringtone list.\nThis is a lot of effort for the average user to undertake. However, in iOS 26, it seems that Apple's taken a step to make it a little bit easier.\nA very small step.\nSimple-ish\nThe first developer beta includes a reasonably simple way to add a custom ringtone. The key is to select the file in an app and use the Share option.\nWithin the list should be an entry for \"Use as Ringtone.\" If it's not immediately visible, it may also appear under the More button as an extra option.\nOnce selected, the ringtone will appear under the main ringtone list under Settings. It appears at the top, just like other custom ringtones.\nWhile it is theoretically possible for the option to appear in the Share sheet whenever it is being used with a compatible audio file, it seems to be a little bit hit and miss.\nFor testing purposes, AppleInsider's created a custom sub-30-second MP3 file on a Mac using Audacity, AirDropping it to the iPhone, then using the Share option within Files. That worked, however using the same file in other locations, such as an attachment in Notes for example, didn't work.\nThis Sharing option also doesn't automatically turn Apple Music tracks into ringtones, either. You'll have to find a way to make custom files, or pay Apple for the official tones.\nCould be worse\nThough the discovery is a relatively small improvement for Apple when it comes to using custom ringtones, it's still a bit of a step forward for the company.\nFor a start, you no longer have to use GarageBand to export a ringtone, since other audio files will work fine. You can use other audio tools to make the MP3 file, or even find a file online if you want, and it should still work.\nMore importantly, it's an option within the Share sheet, which should mean it could be accessed throughout the iOS environment, so long as you are using an acceptable file.\nIt may not be as easy as buying a ringtone from Apple directly, but it's a tiny bit better than what users had before."
    },
    {
      "url": "https://appleinsider.com/inside/macos-tahoe",
      "text": "macOS Tahoe\nAll about macOS Tahoe\nTable of Contents\nApple finally revealed macOS Tahoe during WWDC 2025. The new Liquid Glass design and updated versioning to macOS 26 make this a kind of realignment with the rest of the ecosystem.\nWhile the visual redesign is impressive, the focus in the keynote was on a new Spotlight experience. App intents allow users to take actions directly from Spotlight, and the search interface has been vastly improved with intelligent sorting and filtering.\nMore Continuity features were added, like Live Activities from iPhone. Also, the Phone app with its updated design is now available on Mac for the first time.\nThe Phone app works via Continuity with a nearby iPhone. However, it may also be a precursor to Apple including a C-series modem in their Mac hardware. At the least, it enables users to have convenient access to their Phone call history and other information.\nmacOS Tahoe features\nThe redesign may be the main focus and most obvious upgrade for macOS Tahoe, but there are plenty of new features across the operating system. New Files updates, a Games app, Journal, and new developer APIs are also present.\nSpotlight also saw some key improvements like searchable actions from within the app that is currently open, executable actions based on app intents, and a clipboard history. It's a big update that may be enough for casual users, but power users will continue to rely on apps like Alfred.\nSome feature highlights in macOS Tahoe:\n- Liquid Glass changes the look and feel of macOS\n- New Phone app\n- Live Activities shared from iPhone via Continuity\n- Spotlight gets a big upgrade for proactive and intelligent suggestions\n- Take action directly from Spotlight thanks to app intents\n- Live Translation across the system, like in Messages, FaceTime, and Apple Music\n- Apple Intelligence comes to Shortcuts\n- Image Playground and Genmoji get new styles and ChatGPT support\n- Reminders gains Apple Intelligence suggestions and sorting\n- Apple Games app adds discovery and social tools to one central location\n- Game Overlay enables easy access to system settings for games\n- Safari is redesigned with a floating, rounded tab layout\n- Messages gains backgrounds, polls, and group chat typing indicators\n- Journal is now on Mac\n- Photos gets more customization, new tab design with Liquid Glass\n- FaceTime gets a new landing page with Contact Posters\n- Notes gains import and export of Markdown files\n- Passwords gets a history view to access old passwords\nmacOS Tahoe's Finder icon\nApple briefly changed the Finder icon quite dramatically, at least from a historian's perspective. The white and blue sides swapped in macOS Tahoe beta 1, but the outcry was enough to push Apple to make a change.\nThe complaints reached executive ears and apparently struck a chord, so beta 2 changed the icon to have the historic color scheme. However, the icon has still changed significantly due to the left side being a smaller \"mask\" format versus a 50/50 face.\nThe dark mode icon is controversial as well, though it is difficult to tell how Apple should have handled that design. It features a black color on the left and a dark blue on the right with a gradient blue-to-black smile.\nThe WWDC keynote has barely concluded, and there are a lot of details to uncover about all of Apple's latest operating systems. Stay tuned for more details on this page for macOS Tahoe.\nEverything below this point was written before WWDC 2025. The rumors refer to macOS 16, which was the expected name before Apple shifted to the new version numbering.\nThe Mac operating system is quite mature and rarely gets significant updates, but the rumored redesign may push macOS 16 in a new direction. Apple will undoubtedly provide a place name in California for the release, but that won't be known until WWDC on June 9.\nSo far, the leaks have focused on iOS 19 and a potential redesign that will bring operating systems closer to the visionOS glass and transparency aesthetic. Mockups show reflective buttons and windows across system apps.\nSince the design unification is happening across all operating systems, it is likely that macOS will see similar changes to its UI. It isn't yet known how far the changes will go, but macOS 16 could look dramatically different from macOS Sequoia.\nBeyond design changes, there's not much else that can be predicted beyond polishing existing apps and systems. The new app tiling system and Stage Manager could be updated, and System Preferences could continue to be tweaked.\nApple Intelligence is likely to be a significant focus of the developer conference as well. The delayed contextual features will likely be shown off again, but hopefully with more polish.\nAlso, expect Apple to further expand features it introduced in macOS Sequoia and iOS 18, like iPhone mirroring. Stage Manager and window management could get more polish as well.\nmacOS 16 accessibility updates\nApple has made it a habit to announce accessibility features for upcoming operating systems ahead of WWDC. There's nothing here hinting at an operating system redesign, but there are a lot of great quality-of-life updates for users that need them.\nThe new features include:\n- Accessibility Nutrition Labels on the App Store\n- Magnifier for Mac\n- Braille Access\n- Accessibility Reader\n- Live captions on Apple Watch\n- Live Recognition in Apple Vision Pro\nAccessibility Nutrition Labels give users an overview of what features are compatible with a given app in the App Store. It could help push some apps to adopt features in order to help promote them as accessible apps.\nBraille access is a big update, bringing support for braille across the system like taking notes or transcribing conversations. Braille Access also works as an app launcher and Braille Ready Format file support.\nAccessibility Reader lets users adjust font size, color, spacing, and other settings. It is available within any app, including the Magnifier app.\nMore features are coming to Apple Watch and Apple Vision Pro as well. Plus, Apple plans to update existing features.\n- Eye Tracking on iPhone and iPad\n- Head Tracking to control devices with head movements\n- Switch Control for Brain Computer Interfaces\n- Assistive Access for the Apple TV app\n- Customizable Music Haptics on iPhone\n- Sound Recognition gains Name Recognition\n- Voice Control for Xcode\n- New languages in Live Captions\n- Large Text in CarPlay\nThe features are expected as a part of iOS 19, macOS 16, visionOS 3, tvOS 19, and watchOS 12. They could arrive in the initial release or in a point one or two update before the end of 2025.\nmacOS 16 will be revealed during WWDC 2025 on June 9."
    },
    {
      "url": "https://appleinsider.com/inside/apple-intelligence",
      "text": "Apple Intelligence\nAll about Apple Intelligence\nTable of Contents\nMachine learning led to more powerful technologies people ultimately dubbed \"artificial intelligence.\" While it is mostly a misnomer based on science fiction, Apple eventually began to embrace the term until it moved past it with Apple Intelligence.\nApple CEO Tim Cook will tell you that Apple Intelligence isn't named because of the \"AI\" that came before it. Instead, he'll insist that it was given the name that best described the technology.\nRegardless, Apple Intelligence is Apple's take on generative technologies that have taken the world by storm. OpenAI, Google, and others have flooded the market with their imperfect implementations in the hope of wrestling away some early market share.\nDespite pundit declarations that Apple was behind and would never catch up, the company has had a hand in machine intelligence for over a decade. Now, finally, Apple has chosen to appease these complainers by introducing a more nuanced version of the technology.\nA limited set of features like Writing Tools and the new Siri animation became available as of iOS 18.1, released in October 2024.\niOS 18.2 released on December 11, 2024. It includes Image Playground, ChatGPT integration, Visual Intelligence for iPhone 16, and Genmoji.\nApple released iOS 18.3 in January 2025 with few updates focused on AI. The company announced that the app intent system that would create a more contextually aware Apple Intelligence and Siri is delayed into the coming year.\nWhat's next for Apple Intelligence\nApple Intelligence is an on-device model with custom prompts depending on the mode it is being used in, like Writing Tools or Image Playground. Siri will get smarter thanks to Apple Intelligence, integrations with ChatGPT, and third-party app intents, but it still doesn't have an LLM backend.\nSiri may have new features that let it understand user prompts better and will soon gain a better understanding of what's on the display, but these are AI parts in a machine learning product, not a full overhaul. Such an overhaul of Siri's backend may come, but not until sometime in 2026.\nA rumor suggests Apple will rebuild Siri with an LLM backend that will fundamentally change the assistant into a full-on chatbot similar to ChatGPT. That wasn't announced during WWDC 2025, but Apple may be holding back on pre-announcing features until they are closer to being ready.\nMeanwhile, users are still waiting on the more contextual Siri and Apple Intelligence promised with iOS 18. That feature set was delayed and may not appear until early 2026 in a version of iOS 26.\nAnother rumor says Apple may abandon using Apple Intelligence as the backend for Siri and opt for something built by OpenAI or Anthropic. However, it seems more likely that this rumor suggests Apple is working to bring new models to Private Cloud Compute rather than replacing their own.\nIn essence, it would mean users could call out to private and secure versions of ChatGPT, Claude, Gemini, and Apple Intelligence via Private Cloud Compute. Previous rumors called this a sort of AI App Store where users could choose the models and access any or all of them from iPhone, iPad, and Mac.\niOS 26 and AI updates\nApple Intelligence was the focus of WWDC 2024 and mentioned constantly throughout the keynote, so it is understandable to believe Apple forgot about it during WWDC 2025. There was a brief mention at the top of the 2025 keynote and new features sprinkled throughout, but it's still a big year for Apple's AI efforts.\nDevelopers get access to Apple Intelligence via Apple's new Foundation Models framework. That means developers can perform tasks using Apple's on-device, private, and secure models instead of having to pay for an external model that sucks up user data.\nShortcuts gets new Apple Intelligence functions, enabling users to add steps for including Writing Tools or calling out to the Private Cloud Compute model directly. Responses and results can be fed back into the Shortcut for complex actions.\nVisual Intelligence is now available via the screenshot action. Users can screenshot objects, event posters, or text and search Google or ask ChatGPT to take action on the item.\nImage Playground and Genmoji can now be generated using ChatGPT as a prompt. The ChatGPT tool inside of the app has presets and lets users type out descriptions for manipulating an image.\nApple Watch got some AI action thanks to Workout Buddy in watchOS 26. A virtual assistant will now provide encouragement while working out and generate voice output based on available data.\nLive Translation\nApple devices will now provide translation in various systems across the ecosystem. In addition to the translation features already available for webpages in Safari and the Translate app, Apple has added automatic and Live Translation to other apps.\nOne of the features includes Live Translaton of lyrics in Apple Music. Some songs will show the English equivalent of a lyrics while others will provide a pronunciation guide \u2014 there's a UI option to toggle it on and off.\nLive Translation is also available in Messages, Phone, and FaceTime. Calls can be translated back and forth to both users on the call to help overcome language barriers when needed.\nConcerns regarding Apple Intelligence\nSo-called artificial intelligence hit the market running and has been iterated at a full sprint since. The explosive growth of the AI industry relied on having access to mountains of data gathered from the internet and its users.\nSome companies, like Google, had a strong foundation to train their models thanks to the literal mountains of data collected from users. However, there wasn't any way to predict exactly how models would react to learning from the trove of human-produced data.\nThe result, so far, has been chatbots and search engines that hallucinate because of poorly sourced data from non-factual sources. Replies to searches and chats can sometimes result in funny suggestions like glue on pizza, but other times result in something potentially dangerous.\nOther competitors, like OpenAI's ChatGPT, release updates that seem to lean into the meme culture of the internet. The image generation tool became viral as users created Studio Ghibli-inspired art based on photos they fed the tool.\nApple Intelligence is a group of foundational models built to run either at a smaller scale for iPhone, iPad, and Mac or at twice the size or bigger on a server. It is a testament to Apple's vertical integration of hardware and software.\nSince the models are local to the user's device, they can access sensitive data like contacts, photos, and location without the user needing to worry about compromising that data. Everything gathered by the Appel AI never leaves the device and isn't used to train the model.\nIn the event a request can't be run on the device, it can be sent to a server owned by Apple, running Apple Silicon with a Secure Enclave. All data sent off the device is encrypted and treated with the same protections it would have if it stayed local. This server-side technology is called Apple Cloud Compute.\nEven with privacy and security at its foundation, Apple Intelligence still had to be trained on something. Apple purchased licensed content for some of the training, but other data was sourced from Applebot, a web scraper that has existed since 2015 for surfacing Spotlight search data.\nThere is an ethical conundrum surrounding Apple's model training practices, but the company has assured that it has taken steps to ensure all public data is freely available on the web, lacks copyrighted or personal content, and is filtered for low-quality content. It's a small reassurance, given other companies had no regard for such precautions.\nThere has also been some concern about Apple Intelligence and the environment. On-device models don't have an impact on Apple's green energy initiatives, and server-side computation is performed on Apple Silicon, which is powered by green energy sources.\nApple Intelligence launch features\nApple Intelligence is made up of several models that have specific training to accomplish different tasks with minimal risk of error or hallucinations. There were several planned features at launch, with more arriving over 2024 and 2025 with iOS 18, iPadOS 18, and macOS Sequoia.\nWriting Tools works anywhere text entry is supported across the device's operating system. It analyzes text to proofread for errors, change the tone of the text to be more professional, or summarize the text.\nPriority Notifications analyze incoming notifications to ensure only the most important are at the top, and they are summarized too. It ensures messages, deliveries, and other important information is available at a glance.\nData summarization is everywhere in the supported operating systems. Summarize web pages, emails, text threads, and more.\nApple has come under fire due to notification summaries sometimes combining different news headlines into one that's wrong, confusing, or suggests someone is dead that isn't. As a result, notifications that are summarized will get an updated UI element to ensure users know it is an AI summary and not a headline.\nImage Playground is a app from Apple that generates images like emoji or cartoon-styled art. There is a standalone app, but the function appears in different locations, such as in iMessage. It was included in iOS 18.2 with mixed reviews as the results are not flattering or useful in their launch state.\nApple has more AI features separate from its proprietary systems thanks to a partnership with OpenAI. They are off by default, but if enabled, users can send some requests to ChatGPT. Every request must be screened and approved by the user, and all data from the interaction is discarded.\nUsers can to carry out more natural conversations with Siri, even if they make a mistake and correct themselves mid sentence. And as long as the user asks questions within the same relative timeframe, Siri will remember context from previous queries.\nMore advancements are coming to Siri later thanks to a planned update involving app intents.\nApp intents & contextual AI\nSiri is set to get a huge boost from Apple Intelligence by having access to data presented by the various on-device models. The smart assistant is more knowledgeable about the user, their plans, who they're talking to, and what data is within apps.\nThe voice interactions with Siri will primarily serve as a way to activate Apple Intelligence features from anywhere. However, Siri will have additional abilities thanks to app intents providing context for what is visible on the display.\nApps with Apple Intelligence Siri support:\n- Books\n- Calendar\n- Camera\n- Contacts\n- Files\n- Freeform\n- Keynote\n- Magnifier\n- News\n- Notes\n- Photos\n- Reminders\n- Safari\n- Stocks\n- Settings\n- Voice Memos\nThe upgrade to Siri could take some time. Rumors suggested Apple would not release the new Siri until iOS 18.4 sometime in spring 2025, but that has been delayed \u2014 likely an iOS 26 release.\nIt's Glowtime\nApple's iPhone 16 event occured on September 9, 2024 and had a clear theme around Apple Intelligence. The \"Glowtime\" name is a reference to the new Siri glow, which was a core part of the event.\nThe entire iPhone 16 lineup can take advantage of Apple Intelligence features. The A18 and A18 Pro have a more powerful neural engine, and the new devices are what Apple calls the first iPhones designed from the ground up for AI.\nThe Visual Intelligence features attached to the Camera Control button was also revealed. It is an exclusive AI feature for the iPhone 16 lineup.\niPhone 16 supercycle\nAnalysts expect Apple to have a record release cycle with iPhone 16 thanks to Apple Intelligence. Anyone that doesn't own an iPhone 15 Pro or iPhone 15 Pro Max, which is most people, will have to upgrade for access to Apple's AI.\nThat means 2024 was expected to be a significant year for iPhone sales similar to the 5G boom and the bigger iPhone craze launched with iPhone 6 Plus. Consumers know about AI like ChatGPT and want access to it, and Apple's promise of private, on-device models could have been enticing.\nHowever, evidence showed that while demand was strong for the iPhone 16 lineup, a supercycle didn't happen. It could be attributed to the slow rollout of AI features or lack of overtly exciting party tricks at launch.\nApple has since toned down its approach to AI and advertising the features. WWDC 2025 had Apple Intelligence sprinkled throughout, but it definitely wasn't front and center like it was in 2024.\nThe iPhone 17 lineup will likely have more AI features associated with them, but this time it seems they will only be ones available at launch. Apple was clearly burned from announcing features that weren't ready for prime time and likely won't make that mistake again anytime soon.\nVisual Intelligence\nPress and hold on the Camera Control button on any iPhone 16 and the Visual Intelligence experience will launch. It acts as a Google Lens-like feature that lets the iPhone \"see\" the world and interact with different elements.\nPoint the camera at a concert poster to add the concert to the user's calendar. Or, launch directly into the visual lookup feature and check dog breeds or flower names just by taking a photo.\nTwo buttons at the bottom will take whatever is in the viewfinder and pass it to Google for search or ChatGPT for parsing. As is standard with Apple Intelligence and AI on the iPhone, all interactions with AI is user controlled.\nVisual Intelligence was later spread to the iPhone 15 Pro and iPhone 16e via the Action button. Apple upgraded the feature to include it in the screenshot tool with iOS 26.\nApple Intelligence requirements\nApple claims that Apple Intelligence couldn't exist until it could run locally on a device, and that wasn't possible until the A17 Pro. So, the available devices for the technology are very limited.\nThe base requirements appear to be tied to the size of the Neural Engine and the amount of RAM. The iPhone 15 Pro and iPhone 15 Pro Max have 8GB of RAM and run the A17 Pro with a sizeable Neural Engine.\nThe launch of the iPhone 16 lineup added four more devices that support Apple Intelligence, which could spur demand.\nMacs and iPads can run Apple Intelligence as long as they have an M-series processor. The desktop-class processor has always had a large Neural Engine and enough RAM at 8GB minimum for the chipset.\nApple Intelligence release date\nApple Intelligence launched to the public with iOS 18.1, iPadOS 18.1, and macOS Sequoia 15.1 on October 28, 2024. The initial features included Writing Tools, Photos Clean Up, and system-wide summaries.\niOS 18.2 arrived in December 2024 with Image Playground, ChatGPT integration, and Visual Intelligence. More features are delayed until iOS 26.\nEverything below this point is based on pre-WWDC 2024 rumors and leaks. It has been preserved for reference.\nPre-announcement AI rumors\nApple is known to adopt its own marketing terms to describe existing phenomenons, like calling VR or MR by the in-house term \"spatial computing.\" It seemed like Apple was going to lean into Artificial Intelligence, or AI, as a term, but it is expected to add a twist by calling it \"Apple Intelligence.\"\nWhatever Apple calls it, the result is the same. There will be system-wide tools that run using generative technologies that are much more advanced than the machine learning algorithms they'll replace or augment.\nApple may reveal plans for a server-side LLM during WWDC, but rumors suggest it isn't ready for prime time. Instead, the focus will be on local models made by Apple that can call out to third-party server-side LLMs like ChatGPT.\nLocal Apple Intelligence\nOpenAI's ChatGPT and Google's Gemini Large Language Models (LLMs) have one thing in common \u2014 they are gigantic models trained on every ounce of available data on the internet that live in servers.\nThe \"Large\" in LLM is literal, as these models can't live on something like an iPhone or Mac. Instead, users call the models and their various versions through the cloud via APIs. That requires data to leave the user's device and head to a server they don't control.\nServer-side models are a must for such enormous data sets, but they come at the cost of privacy and security. It may be harmless to ask an LLM to generate a photo or write an essay about historical events, but asking it to perform a budget may cross a line.\nApple hopes to address these types of concerns by providing more limited local models across the iPhone, iPad, Mac, and Apple Vision Pro. The pre-trained models will serve specific purposes and will contain very limited but specialized data sets.\nThe on-device models will learn based on user data. The data will never leave the device without explicit permission.\nUpgrading Siri\nA part of local Apple Intelligence will be providing significant upgrades to Siri. Apple's assistant is expected to become much more conversational and understand contexts better.\nA specific model, likely based on the \"Apple Ask\" pre-trained model that's been tested internally, will be the driver behind Siri. Its limited data set is said to be a protection against hallucinations, which plague LLMs like Google Gemini and ChatGPT.\nUsers can ask Siri to perform many tasks across Apple-made apps, from simple to complex. It isn't yet known if an API will allow developers to target this new Siri, but it is likely.\nApps with Apple Intelligence Siri support:\n- Books\n- Calendar\n- Camera\n- Contacts\n- Files\n- Freeform\n- Keynote\n- Magnifier\n- News\n- Notes\n- Photos\n- Reminders\n- Safari\n- Stocks\n- Settings\n- Voice Memos\nMany Siri functions in these apps involve general navigation and search. Like opening a specific book or creating a new slide.\nIt seems many of the functions found in the new Siri commands are derived from previously available accessibility options that could control the device via voice. This melding of features will provide more control for all users, not just ones relying on accessibility options.\nApple Intelligence at WWDC\nAll will be revealed during WWDC 2024. Apple is expected to reveal Apple Intelligence during its keynote, where iOS 18, iPadOS 18, macOS 15, tvOS 18, watchOS 11, and visionOS 2 will also be announced."
    },
    {
      "url": "https://appleinsider.com/articles/25/07/04/five-best-ios-26-features-that-will-help-you-be-more-creative?utm_source=newsletter",
      "text": "Creative work gets a major upgrade in iOS 26, with on-device tools that let you generate custom images, tweak your tone, and organize your ideas more naturally.\nApple's iOS 26 brings a deeper focus on creativity by expanding the tools you already use every day. While many of these features started in earlier updates, the newest version adds more power, flexibility, and relevance to creative work on iPhone.\nWhether you're sketching a character, rewriting a story, or organizing your thoughts, these features help you move ideas forward without getting in the way.\nImage Playground adds new styles for fast visual creation\nImage Playground was first introduced in iOS 18.2. It's built into apps like Messages and Notes, letting you create images using short prompts.\nWith iOS 26, you get new visual styles through ChatGPT, making it easier to explore different aesthetics for mockups, concept art, and more.\nYou don't have to open a separate app or export files. The generated images can be used instantly inside your conversations or notes. Everything is processed on your device using Apple Intelligence, so your input stays private.\nImage Playground is available on iPhone 15 Pro, iPhone 15 Pro Max, and all iPhone 16 models running iOS 26.\nGenmoji lets you invent emoji that feel personal\nGenmoji, which debuted in iOS 18.2, is making a comeback in iOS 26 with enhanced creative tools. In the iOS 26 beta, users can now combine up to six concepts, including text prompts, emojis, stickers, or previous Genmoji, to create entirely new and unique designs.\nThe interface has been reorganized to group input tabs into themes such as Expressions, Costumes, Accessories, and Places. Themes make it easier to design custom sticker packs based on a specific mood or idea.\nThese Genmoji show up in your emoji keyboard and work like any other emoji in Messages. They're especially useful if you're developing a character, creating a cast of expressions, or just want a reaction image no one else has.\nEverything runs on-device and requires an iPhone with Apple Intelligence support: iPhone 15 Pro, iPhone 15 Pro Max, or any iPhone 16 model.\nWriting Tools now support more apps and ideas\nWriting Tools, first introduced in iOS 18.1, now appear in more places across iOS 26. You'll find them in Notes, Mail, and other supported apps, with Apple also opening up the Apple Intelligence API to third-party developers.\nThat means creative writing apps, journaling tools, or blog platforms could soon support the same rewrite, tone shift, and summarization features already built into Apple's own apps. These features are currently available in Apple's apps.\nThese tools are especially helpful for refining drafts, experimenting with voice, or shaping story structure. You can rephrase a sentence to sound more casual or more formal, tighten up a paragraph, or turn a stream of thoughts into a cleaner outline.\nSuggestions appear in context, and you're free to accept, edit, or ignore them.\nWriting Tools requires Apple Intelligence, which is available in beta on iPhone 15 Pro, iPhone 15 Pro Max, and all iPhone 16 models.\nYour device must be running iOS 26 and set to one of the supported languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Japanese, Korean, or Chinese (Simplified).\nPhotos gets a new layout and spatial storytelling features\nPhotos in iOS 26 has been redesigned with a cleaner layout and new ways to organize your library. The app now centers around two main tabs.\n- Library, which shows your full photo collection.\n- Collections, which automatically groups images by themes like trips, people, or time periods.\nThese changes simplify navigation and surface the most important content. Photos is great for organizing references, revisiting projects, or gathering visual inspiration.\nA new creative feature is the new spatial scene option. You can now bring a single photo to life using the same 3D layering technology found in visionOS. The result is a depth-enhanced image that feels more immersive.\nAll of these updates are available to users with iOS 26, no special hardware required for the redesigned interface. Spatial scene support may depend on device capabilities.\nJournal adds structure with categories and maps\nThe Journal app becomes more organized in iOS 26. You can now create multiple journals for different topics, like creative writing, a dream journal, or travel notes.\nThere's also a new map view that shows where you were when you wrote each entry, if location data is available. Maps add context to your writing and help you recall experiences tied to specific places.\nThese new Journal features are available to all iPhones running iOS 26 and do not require Apple Intelligence.\nDevice compatibility and release timeline\nApple Intelligence features in iOS 26, such as Image Playground, Genmoji, Writing Tools, and enhanced photo search, have specific requirements.\n- iPhone 15 Pro, iPhone 15 Pro Max, or any iPhone 16 model\n- iOS 26, currently in developer beta\n- Siri and device language set to one of these: English, French, German, Italian, Portuguese (Brazil), Spanish, Japanese, Korean, or Chinese (Simplified)\nThe developer beta of iOS 26 is currently available. The public beta is expected in July, while the final release is scheduled for fall 2025."
    },
    {
      "url": "https://www.youtube.com/c/appleinsider?sub_confirmation=1",
      "text": "- Svenska\n- Deutsch\n- English\n- Espa\u00f1ol\n- Fran\u00e7ais\n- Italiano\n- Alla spr\u00e5k\n- Afrikaans\n- az\u0259rbaycan\n- bosanski\n- catal\u00e0\n- \u010ce\u0161tina\n- Cymraeg\n- Dansk\n- Deutsch\n- eesti\n- EnglishUnited Kingdom\n- EnglishUnited States\n- Espa\u00f1olEspa\u00f1a\n- Espa\u00f1olLatinoam\u00e9rica\n- euskara\n- Filipino\n- Fran\u00e7aisCanada\n- Fran\u00e7aisFrance\n- Gaeilge\n- galego\n- Hrvatski\n- Indonesia\n- isiZulu\n- \u00edslenska\n- Italiano\n- Kiswahili\n- latvie\u0161u\n- lietuvi\u0173\n- magyar\n- Melayu\n- Nederlands\n- norsk\n- o\u2018zbek\n- polski\n- Portugu\u00easBrasil\n- Portugu\u00easPortugal\n- rom\u00e2n\u0103\n- shqip\n- Sloven\u010dina\n- sloven\u0161\u010dina\n- srpski (latinica)\n- Suomi\n- Ti\u1ebfng Vi\u1ec7t\n- T\u00fcrk\u00e7e\n- \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac\n- \u0431\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f\n- \u0431\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438\n- \u043a\u044b\u0440\u0433\u044b\u0437\u0447\u0430\n- \u049b\u0430\u0437\u0430\u049b \u0442\u0456\u043b\u0456\n- \u043c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438\n- \u043c\u043e\u043d\u0433\u043e\u043b\n- \u0420\u0443\u0441\u0441\u043a\u0438\u0439\n- \u0441\u0440\u043f\u0441\u043a\u0438\n- \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430\n- \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8\n- \u0570\u0561\u0575\u0565\u0580\u0565\u0576\n- \u05e2\u05d1\u05e8\u05d9\u05ea\n- \u0627\u0631\u062f\u0648\n- \u0627\u0644\u0639\u0631\u0628\u064a\u0629\n- \u0641\u0627\u0631\u0633\u06cc\n- \u12a0\u121b\u122d\u129b\n- \u0928\u0947\u092a\u093e\u0932\u0940\n- \u092e\u0930\u093e\u0920\u0940\n- \u0939\u093f\u0928\u094d\u0926\u0940\n- \u0985\u09b8\u09ae\u09c0\u09af\u09bc\u09be\n- \u09ac\u09be\u0982\u09b2\u09be\n- \u0a2a\u0a70\u0a1c\u0a3e\u0a2c\u0a40\n- \u0a97\u0ac1\u0a9c\u0ab0\u0abe\u0aa4\u0ac0\n- \u0b13\u0b21\u0b3c\u0b3f\u0b06\n- \u0ba4\u0bae\u0bbf\u0bb4\u0bcd\n- \u0c24\u0c46\u0c32\u0c41\u0c17\u0c41\n- \u0c95\u0ca8\u0ccd\u0ca8\u0ca1\n- \u0d2e\u0d32\u0d2f\u0d3e\u0d33\u0d02\n- \u0dc3\u0dd2\u0d82\u0dc4\u0dbd\n- \u0e44\u0e17\u0e22\n- \u0ea5\u0eb2\u0ea7\n- \u1019\u103c\u1014\u103a\u1019\u102c\n- \u1781\u17d2\u1798\u17c2\u179a\n- \ud55c\uad6d\uc5b4\n- \u65e5\u672c\u8a9e\n- \u7b80\u4f53\u4e2d\u6587\n- \u7e41\u9ad4\u4e2d\u6587\n- \u7e41\u9ad4\u4e2d\u6587\u9999\u6e2f\n- Svenska\n- Deutsch\n- English\n- Espa\u00f1ol\n- Fran\u00e7ais\n- Italiano\n- Alla spr\u00e5k\n- Afrikaans\n- az\u0259rbaycan\n- bosanski\n- catal\u00e0\n- \u010ce\u0161tina\n- Cymraeg\n- Dansk\n- Deutsch\n- eesti\n- EnglishUnited Kingdom\n- EnglishUnited States\n- Espa\u00f1olEspa\u00f1a\n- Espa\u00f1olLatinoam\u00e9rica\n- euskara\n- Filipino\n- Fran\u00e7aisCanada\n- Fran\u00e7aisFrance\n- Gaeilge\n- galego\n- Hrvatski\n- Indonesia\n- isiZulu\n- \u00edslenska\n- Italiano\n- Kiswahili\n- latvie\u0161u\n- lietuvi\u0173\n- magyar\n- Melayu\n- Nederlands\n- norsk\n- o\u2018zbek\n- polski\n- Portugu\u00easBrasil\n- Portugu\u00easPortugal\n- rom\u00e2n\u0103\n- shqip\n- Sloven\u010dina\n- sloven\u0161\u010dina\n- srpski (latinica)\n- Suomi\n- Ti\u1ebfng Vi\u1ec7t\n- T\u00fcrk\u00e7e\n- \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac\n- \u0431\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f\n- \u0431\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438\n- \u043a\u044b\u0440\u0433\u044b\u0437\u0447\u0430\n- \u049b\u0430\u0437\u0430\u049b \u0442\u0456\u043b\u0456\n- \u043c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438\n- \u043c\u043e\u043d\u0433\u043e\u043b\n- \u0420\u0443\u0441\u0441\u043a\u0438\u0439\n- \u0441\u0440\u043f\u0441\u043a\u0438\n- \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430\n- \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8\n- \u0570\u0561\u0575\u0565\u0580\u0565\u0576\n- \u05e2\u05d1\u05e8\u05d9\u05ea\n- \u0627\u0631\u062f\u0648\n- \u0627\u0644\u0639\u0631\u0628\u064a\u0629\n- \u0641\u0627\u0631\u0633\u06cc\n- \u12a0\u121b\u122d\u129b\n- \u0928\u0947\u092a\u093e\u0932\u0940\n- \u092e\u0930\u093e\u0920\u0940\n- \u0939\u093f\u0928\u094d\u0926\u0940\n- \u0985\u09b8\u09ae\u09c0\u09af\u09bc\u09be\n- \u09ac\u09be\u0982\u09b2\u09be\n- \u0a2a\u0a70\u0a1c\u0a3e\u0a2c\u0a40\n- \u0a97\u0ac1\u0a9c\u0ab0\u0abe\u0aa4\u0ac0\n- \u0b13\u0b21\u0b3c\u0b3f\u0b06\n- \u0ba4\u0bae\u0bbf\u0bb4\u0bcd\n- \u0c24\u0c46\u0c32\u0c41\u0c17\u0c41\n- \u0c95\u0ca8\u0ccd\u0ca8\u0ca1\n- \u0d2e\u0d32\u0d2f\u0d3e\u0d33\u0d02\n- \u0dc3\u0dd2\u0d82\u0dc4\u0dbd\n- \u0e44\u0e17\u0e22\n- \u0ea5\u0eb2\u0ea7\n- \u1019\u103c\u1014\u103a\u1019\u102c\n- \u1781\u17d2\u1798\u17c2\u179a\n- \ud55c\uad6d\uc5b4\n- \u65e5\u672c\u8a9e\n- \u7b80\u4f53\u4e2d\u6587\n- \u7e41\u9ad4\u4e2d\u6587\n- \u7e41\u9ad4\u4e2d\u6587\u9999\u6e2f\nInnan du forts\u00e4tter till YouTube\nVi anv\u00e4nder cookies och data f\u00f6r att\n- leverera och underh\u00e5lla Googles tj\u00e4nster\n- sp\u00e5ra avbrott och skydda mot spam, bedr\u00e4geri och otill\u00e5ten anv\u00e4ndning\n- m\u00e4ta m\u00e5lgruppsengagemang och webbplatsstatistik s\u00e5 att vi kan analysera hur v\u00e5ra tj\u00e4nster anv\u00e4nds och f\u00f6rb\u00e4ttra tj\u00e4nsternas kvalitet.\nOm du v\u00e4ljer knappen Godk\u00e4nn alla anv\u00e4nder vi \u00e4ven cookies och data f\u00f6r att\n- utveckla och f\u00f6rb\u00e4ttra nya tj\u00e4nster\n- leverera annonser och m\u00e4ta hur effektiva de \u00e4r\n- visa anpassat inneh\u00e5ll utifr\u00e5n dina inst\u00e4llningar\n- visa anpassade annonser utifr\u00e5n dina inst\u00e4llningar\nOm du v\u00e4ljer knappen Avvisa alla anv\u00e4nder vi inte cookies i dessa ytterligare syften.\nInneh\u00e5ll och annonser utan anpassning p\u00e5verkas bland annat av vad du tittar p\u00e5 f\u00f6r tillf\u00e4llet och din plats (annonser visas utifr\u00e5n din ungef\u00e4rliga plats). Inneh\u00e5ll och annonser med anpassning kan \u00e4ven omfatta s\u00e5dant som videorekommendationer, en anpassad YouTube Hem-sida och anpassade annonser utifr\u00e5n tidigare aktivitet, till exempel vad du tittar p\u00e5 och s\u00f6ker efter p\u00e5 YouTube. Vi anv\u00e4nder \u00e4ven cookies och data f\u00f6r att anpassa upplevelsen efter l\u00e4mplighet f\u00f6r din m\u00e5lgrupp, om till\u00e4mpligt.\nV\u00e4lj knappen Fler alternativ f\u00f6r mer information, till exempel om hur du hanterar dina integritetsinst\u00e4llningar. Du kan \u00e4ven bes\u00f6ka g.co/privacytools n\u00e4r som helst."
    }
  ],
  "argos_summary": "Apple has released the sixth developer beta of iOS 26, introducing a new onboarding sequence and six additional ringtones. The update enhances various features, including improvements to Image Playground, Shortcuts, and the Messages and Phone apps, while showcasing the controversial 'Liquid Glass' design language. This beta also includes a new toggle for the Camera app, allowing users to revert to the classic mode switching, and fixes for notification display issues. Overall, iOS 26 aims to improve user experience with a focus on customization and productivity.",
  "argos_id": "WXRXXDKLE"
}