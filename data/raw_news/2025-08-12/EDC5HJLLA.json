{
  "url": "https://www.inc.com/sam-blum/sam-altman-open-ai-bubble-is-here/91226419",
  "authorsByline": "Sam Blum",
  "articleId": "23fe6d7d0e1e4e5aa1ea57bf2469bd04",
  "source": {
    "domain": "inc.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "AZ",
      "county": "Pima County",
      "city": "Tucson",
      "coordinates": {
        "lat": 32.1988848,
        "lon": -110.8218543
      }
    }
  },
  "imageUrl": "https://img-cdn.inc.com/image/upload/f_webp,q_auto,c_fit/vip/2025/08/ai-bubble-sam-altman-inc-2214110034.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T21:00:39+00:00",
  "addDate": "2025-08-12T21:17:40.414083+00:00",
  "refreshDate": "2025-08-12T21:17:40.414084+00:00",
  "score": 1.0,
  "title": "Did Sam Altman Accidentally Admit That The AI Bubble Is Here?",
  "description": "A recent CNBC interview with the OpenAI CEO shows that tech leaders are changing how they judge AI models.",
  "content": "A recent CNBC interview with the OpenAI CEO shows that tech leaders are changing how they judge AI models.\n\nOpenAI CEO Sam Altman, who has served for years as the AI revolution\u2019s unofficial hypeman, previously wrote that his company knows how to achieve Artificial General Intelligence (AGI)\u2014a term technologists use to describe super sophisticated AI. Now, he\u2019s echoing other prominent tech researchers who are throwing cold water on the AI hype train. During an appearance on CNBC on Monday, Altman sought to temper expectations about the development of AI that can surpass human capabilities.\n\nAs the leading companies in Silicon Valley race to achieve the milestone, Altman said, the term AGI has become too muddled. \u201cI think it\u2019s not a super useful term,\u201d the CEO explained. \u201cI think the point of all of this is it doesn\u2019t really matter and it\u2019s just this continuing exponential of model capability that we\u2019ll rely on for more and more things. Altman\u2019s interview may reveal that the breathless hype surrounding AI may not produce the monumental breakthroughs its architects have promised. Other recent research authored by the biggest companies in Silicon Valley indicates a similar outlook. In June, Apple published a study that saw advanced models, across the spectrum from Large Reasoning Models (LRMs) to Large Language Models (LLMs), experience \u201ctotal collapse\u201d when confronted with complex tasks. Also in June, researchers from Nvidia found that AI agents trained on data from Small Language Models (SLMs) can perform tasks at a similar level of mastery as those based on LLMs. What\u2019s more, SLM agents require less energy and computational power, and are therefore vastly more economical.\n\nPerhaps, Altman was compelled to slow his roll due to recent events. Last week, OpenAI and Altman were subjected to a chorus of derision online after the company\u2019s newest model, GPT-5, debuted as a dud. Altman previously claimed it would possess \u201cPhD level intelligence\u201d in almost every area. At the same time, the cost to run large models like ChatGPT are enormous. Altman told CNBC last week that the company\u2019s annual recurring revenue is on track to pass $20 billion this year, but OpenAI is not yet profitable. For years, critics and some investors have warned that the AI frenzy is on a similar trajectory as the dot-com bubble. The economics seem fuzzy at best, but the largest AI companies are unlikely to take a financial hit due to U.S. government subsidies, says Amba Kak, co-executive director of the AI Now Institute, a policy organization.\n\n\u201cThere\u2019s a way in which the government is coming out and almost committing to underwrite this market no matter what,\u201d she adds, referencing the Trump administration\u2019s AI Action Plan, which frames the race to develop frontier models as an existential battle between the US and China. \u201cWinning the AI race will usher in a new golden age of human flourishing, economic competitiveness, and national security for the American people,\u201d the White House wrote in its AI directive. Over 30 states currently offer subsidies for companies building AI data centers and the White House has issued executive orders streamlining the permitting process for building them.",
  "medium": "Article",
  "links": [
    "https://www.whitehouse.gov/presidential-actions/2025/07/accelerating-federal-permitting-of-data-center-infrastructure/",
    "https://www.cnbc.com/2025/08/11/sam-altman-says-agi-is-a-pointless-term-experts-agree.html",
    "https://www.cnbc.com/2025/08/08/chatgpt-gpt-5-openai-altman-loss.html",
    "https://www.naiop.org/research-and-publications/magazine/2024/Winter-2024-2025/development-ownership/an-overview-of-state-data-center-related-tax-incentives/",
    "https://arxiv.org/pdf/2506.02153",
    "https://www.inc.com/sam-blum/doubling-lifespans-and-superintelligence-ai-ceos-are-saying-some-wild-stuff-is-any-of-it-true/91139142",
    "https://www.inc.com/sam-blum/todays-ai-investment-frenzy-echoes-the-dot-com-bubble.html",
    "https://incbestinbusiness.secure-platform.com/bib/",
    "https://www.inc.com/sam-blum/new-warnings-ai-bubble-when-could-it-burst.html",
    "https://www.wired.com/story/openai-gpt-5-backlash-sam-altman/",
    "https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf",
    "https://blog.samaltman.com/reflections"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "AI agents",
      "weight": 0.09153665
    },
    {
      "name": "AI",
      "weight": 0.087365456
    },
    {
      "name": "AI data centers",
      "weight": 0.08727316
    },
    {
      "name": "AI models",
      "weight": 0.08414138
    },
    {
      "name": "OpenAI CEO Sam Altman",
      "weight": 0.08221647
    },
    {
      "name": "large models",
      "weight": 0.078092836
    },
    {
      "name": "model capability",
      "weight": 0.07486992
    },
    {
      "name": "Sam Altman",
      "weight": 0.074586675
    },
    {
      "name": "advanced models",
      "weight": 0.07275343
    },
    {
      "name": "frontier models",
      "weight": 0.072597615
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Business"
    },
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.94921875
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.9052734375
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.67822265625
    },
    {
      "name": "/News/Business News/Other",
      "score": 0.45068359375
    }
  ],
  "sentiment": {
    "positive": 0.090925,
    "negative": 0.58371335,
    "neutral": 0.32536167
  },
  "summary": "OpenAI CEO, Sam Altman, has stated that the development of AI can surpass human capabilities and that the term \"Artificial General Intelligence (AGI) has become too muddled. This sentiment may have been echoed by other prominent tech researchers who have also dismissed the AI hype train. Recent research by Apple, Nvidia, and the AI Now Institute indicates a shift in thinking about AI. However, the cost to run large models like ChatGPT is high, and Altman recently faced criticism online after his latest model, GPT-5, debuted as a dud. Despite this, the largest AI companies are unlikely to take a financial hit due to government subsidies.",
  "shortSummary": "OpenAI CEO Sam Altman acknowledged the AI bubble, downplaying the potential for advanced models and government subsidies, amid mixed reactions and ongoing criticism.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "349bfa275a824b8da02599df30838c3b",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://incbestinbusiness.secure-platform.com/bib/",
      "text": "National Recognition\nEarn distinction from Inc. as one of America\u2019s Best in Business and automatically be considered for Inc.\u2019s prestigious Company of the Year award!\ndouble-click to edit, do not edit in source\nThe Inc. Best in Business awards celebrate the projects and initiatives that were true business wins for your company over the past year. Whether it is about a new innovation, a standout marketing campaign, a creative use of AI, or a bold move that paid off, we want to hear your story.\nTell us about a successful project or business win and find your company among the winners that will be featured on Inc.com and in the pages of Inc. magazine. Hundreds of companies will be named to the Best in Business list, with even more recognized in several standout categories.\nNow\u2019s your chance to earn national\u2014and global\u2014recognition for the success you\u2019ve had. Submit your project today and let the world see what makes your company the best in business.\nFor over 40 years, Inc. magazine has been devoted to recognizing America\u2019s most dynamic businesses and honoring the great things they do. This year, hundreds of companies will make the cut and be honored in print and online. Honorees in 2025 will enjoy the following benefits:\nEarn distinction from Inc. as one of America\u2019s Best in Business and automatically be considered for Inc.\u2019s prestigious Company of the Year award!\nBe featured in the Winter issue of Inc. magazine, get a dedicated company profile on Inc.com, and receive national and local media coverage.\nEvery application will be seen and evaluated directly by Inc.\u2019s editors, who will source stories and articles directly from the honorees and applicant pool.\nShow your current employees that all of their long days and nights of hard work are paying off, and improve recruiting opportunities with prospective employees.\nApplying is simple! Fill out the online application, where you will enter a few details about your company and answer three questions about your company\u2019s achievement:\nDescribe a specific project, initiative, or innovation your organization achieved over the past year that is noteworthy.\nExplain how the outcome of this project is a win for your company, leadership team, or industry, and how it sets you apart from your competitors.\nCite some metrics over the past 12 months, directly related to this project, that show positive business outcomes resulting in a win.\nYou will then select which business categories you\u2019d like to apply for\u2014the more categories you apply to, the higher the chances of being recognized. You can see a list of award categories below. That\u2019s it!\nApply Now\nPreferred-Rate Deadline: August 15\nAll applicants must first apply to the prestigious Best in Business main list\u2014celebrating hundreds of companies for standout projects and initiatives over the past 12 months. Then, boost your chances for recognition by adding any of our exclusive award categories, with multiple winners honored in each.\nCelebrating AI projects and initiatives that have delivered tangible results\u2014whether through increased efficiency, cost savings, improved customer experiences, or new revenue opportunities\u2014 by demonstrating clear, measurable wins for the organization.\nCelebrating successful projects or initiatives built without external funding\u2014highlighting the creativity, resilience, and resourcefulness of founders and teams.\nRecognizing the branding, guerrilla marketing, pop-up, experiential, and social media campaigns of upstart companies that have successfully challenged industry leaders and won devoted communities of customers.\nRecognizing successful projects or initiatives that resulted from the partnership of two or more companies.\nHonoring projects or initiatives that have successfully built new communities or deepened engagement within existing ones\u2014fostering connection, participation, and lasting value for their members.\nRecognizing outstanding projects or initiatives from family-owned businesses.\nRecognizing projects or initiatives that successfully attracted investment or were a direct result of investment.\nRecognizing groundbreaking innovations, inventions, or products of all types that have delivered meaningful outcomes, marking them as true wins worth celebrating.\nCelebrating bold brand marketing and other strategies and campaigns that truly moved the needle. Advertising, brand marketing, digital marketing, and performance marketing will be recognized in this category.\nCelebrating projects or initiatives that have made a measurable, positive impact on society, whether by addressing social challenges, advancing equity, improving well-being, or fostering sustainable change in communities.\nHonoring social media campaigns or innovations that have driven significant results, such as increased engagement, brand awareness, audience growth, or business impact.\nGet recognized as one of the top companies in your region, whether you\u2019re leading in the Mid-Atlantic, Midwest, Northeast, Pacific, Rocky Mountain, Southeast, or Southwest.\nWhether you\u2019re a scrappy startup or a powerhouse enterprise, get recognized for achieving excellence at your scale: Small and Mighty (0-49 employees), Medium (50-99 employees), Large (100-499 employees), Extra Large (500+ employees).\nWhether you\u2019re building momentum or leading your market, get recognized for what you\u2019ve accomplished at your revenue level: Lean and Mean (under $5 million in gross revenue), Prosperous and Thriving ($5 million to $50 million in gross revenue), Robust and Powerful ($50 million and up in gross revenue).\nFrom rising stars to legacy leaders, showcase how your company is making its mark at every stage of growth: On the Rise (0-4 years in business), Established Excellence Companies (5-14 years in business), Legacy Companies (15+ years in business).\nHonoring outstanding leaders who have successfully guided a key project or initiative, delivering significant results for their organization through strategic vision, effective execution, and impactful leadership.\nThe early-rate deadline is Friday, July 18, at 11:59 p.m. PT.\nThe preferred-rate deadline is Friday, August 15, at 11:59 p.m. PT.\nThe final deadline to apply is Friday, September 12, at 11:59 p.m. PT.\nAll applicants will be notified via email if they were chosen for the list.\nWe\u2019ll send you a complimentary honoree toolkit to help you promote this incredible honor.\nAll Inc. Best in Business honorees will appear in the Winter issue of Inc. magazine and on Inc.com\nPreferred-Rate Deadline: August 15\nThe Inc. Best in Business awards are open to all companies\u2014public, private, nonprofit, U.S.-based, and international. Applicants must apply to the Main List to showcase standout work across industries, and may apply to optional additional categories for more visibility.\nInc. editors will review all entries. Honorees will be announced on Inc.com in December 2025 and in the Winter 2025/2026 issue of Inc. magazine. Applicants will be notified by mid-November 2025 whether they have made the list.\nSee your win immortalized in pages of the Winter issue of Inc. magazine, get a dedicated company profile on Inc.com, and receive national and local media coverage.\n2024 List"
    },
    {
      "url": "https://www.cnbc.com/2025/08/08/chatgpt-gpt-5-openai-altman-loss.html",
      "text": "OpenAI CEO Sam Altman on Friday said the artificial intelligence company should prioritize growth and its investments in training and compute \"for a long time,\" even if it delays its path to profitability.\nLast year, OpenAI expected about $5 billion in losses on $3.7 billion in revenue. OpenAI's annual recurring revenue is now on track to pass $20 billion this year, but the company is still losing money.\n\"As long as we're on this very distinct curve of the model getting better and better, I think the rational thing to do is to just be willing to run the loss for quite a while,\" Altman told CNBC's \"Squawk Box\" in an interview Friday following the release of GPT-5.\nGPT-5 is the company's latest and most advanced large-scale AI model and was released on Thursday.\nThe model is available to everyone, including free users, and OpenAI said it's smarter, faster and \"a lot more useful,\" particularly across domains like writing, coding and health care.\nEarlier this week, OpenAI released two open-weight language models for the first time since it rolled out GPT-2 in 2019. Those models were built to serve as lower-cost options that developers, researchers and companies can easily run and customize.\nThese models are expensive to develop and build. But investors don't seem to mind.\nOpenAI is currently in talks with investors about a potential stock sale at a valuation of roughly $500 billion, as CNBC previously reported. Thrive Capital, an investor in OpenAI, could lead the potential round.\nAltman said if OpenAI wanted to, it could become profitable sooner than he originally thought. But for now, since the private company remains free from the pressures of the public markets, it will continue to spend on training and compute.\n\"It's nice not to be public,\" Altman said."
    },
    {
      "url": "https://www.wired.com/story/openai-gpt-5-backlash-sam-altman/",
      "text": "OpenAI\u2019s GPT-5 model was meant to be a world-changing upgrade to its wildly popular and precocious chatbot. But for some users, last Thursday\u2019s release felt more like a wrenching downgrade, with the new ChatGPT presenting a diluted personality and making surprisingly dumb mistakes.\nOn Friday, OpenAI CEO Sam Altman took to X to say the company would keep the previous model, GPT-4o, running for Plus users. A new feature designed to seamlessly switch between models depending on the complexity of the query had broken on Thursday, Altman said, \u201cand the result was GPT-5 seemed way dumber.\u201d He promised to implement fixes to improve GPT-5\u2019s performance and the overall user experience.\nGiven the hype around GPT-5, some level of disappointment appears inevitable. When OpenAI introduced GPT-4 in March 2023, it stunned AI experts with its incredible abilities. GPT-5, pundits speculated, would surely be just as jaw-dropping.\nJoin our next subscriber-only livestream on Thursday, August 14, to chat all things GPT-5 with Will Knight, Kylie Robison, and Reece Rogers.\nOpenAI touted the model as a significant upgrade, with PhD-level intelligence and virtuoso coding skills. A system to automatically route queries to different models was meant to provide a smoother user experience. (It could also save the company money by directing simple queries to cheaper models.)\nSoon after GPT-5 dropped, however, a Reddit community dedicated to ChatGPT filled with complaints. Many users mourned the loss of the old model.\n\u201cI\u2019ve been trying GPT5 for a few days now. Even after customizing instructions, it still doesn\u2019t feel the same. It\u2019s more technical, more generalized, and honestly feels emotionally distant,\u201d wrote one member of the community in a thread titled \u201cKill 4o isn\u2019t innovation, it\u2019s erasure.\u201d\n\u201cSure, 5 is fine\u2014if you hate nuance and feeling things,\u201d another Reddit user wrote.\nOther threads complained of sluggish responses, hallucinations, and surprising errors.\nAltman promised to address these issues by doubling GPT-5 rate limits for ChatGPT Plus users, improving the system that switches between models, and letting users specify when they want to trigger a more ponderous and capable \u201cthinking mode.\u201d \u201cWe will continue to work to get things stable and will keep listening to feedback,\u201d the CEO wrote on X. \u201cAs we mentioned, we expected some bumpiness as we roll out so many things at once. But it was a little more bumpy than we hoped for!\u201d\nErrors posted on social media do not necessarily indicate that the new model is less capable than its predecessors. They may simply suggest the all-new model is tripped up by different edge cases than prior versions. OpenAI declined to comment specifically on why GPT-5 sometimes appears to make simple blunders.\n| Got a Tip? |\n|---|\n| Are you a current or former OpenAI employee who wants to talk about what's happening? We'd like to hear from you. Using a nonwork phone or computer, contact the reporter securely on Signal at wak.01. |\nThe backlash has sparked a fresh debate over the psychological attachments some users form with chatbots trained to push their emotional buttons. Some Reddit users dismissed complaints about GPT-5 as evidence of an unhealthy dependence on an AI companion.\nIn March, OpenAI published research exploring the emotional bonds users form with its models. Shortly after, the company issued an update to GPT-4o after it became too sycophantic.\n\u201cIt seems that GPT-5 is less sycophantic, more \u201cbusiness\u201d and less chatty,\u201d says Pattie Maes, a professor at MIT who worked on the study. \u201cI personally think of that as a good thing, because it is also what led to delusions, bias reinforcement, etc. But unfortunately many users like a model that tells them they are smart and amazing and that confirms their opinions and beliefs, even if [they are] wrong.\u201d\nAltman indicated in another post on X that this is something the company wrestled with in building GPT-5.\n\u201cA lot of people effectively use ChatGPT as a sort of therapist or life coach, even if they wouldn\u2019t describe it that way,\u201d Altman wrote. He added that some users may be using ChatGPT in ways that help improve their lives while others might be \u201cunknowingly nudged away from their longer term well-being.\u201d"
    },
    {
      "url": "https://blog.samaltman.com/reflections",
      "text": "The second birthday of ChatGPT was only a little over a month ago, and now we have transitioned into the next paradigm of models that can do complex reasoning. New years get people in a reflective mood, and I wanted to share some personal thoughts about how it has gone so far, and some of the things I\u2019ve learned along the way.\nAs we get closer to AGI, it feels like an important time to look at the progress of our company. There is still so much to understand, still so much we don\u2019t know, and it\u2019s still so early. But we know a lot more than we did when we started.\nWe started OpenAI almost nine years ago because we believed that AGI was possible, and that it could be the most impactful technology in human history. We wanted to figure out how to build it and make it broadly beneficial; we were excited to try to make our mark on history. Our ambitions were extraordinarily high and so was our belief that the work might benefit society in an equally extraordinary way.\nAt the time, very few people cared, and if they did, it was mostly because they thought we had no chance of success.\nIn 2022, OpenAI was a quiet research lab working on something temporarily called \u201cChat With GPT-3.5\u201d. (We are much better at research than we are at naming things.) We had been watching people use the playground feature of our API and knew that developers were really enjoying talking to the model. We thought building a demo around that experience would show people something important about the future and help us make our models better and safer.\nWe ended up mercifully calling it ChatGPT instead, and launched it on November 30th of 2022.\nWe always knew, abstractly, that at some point we would hit a tipping point and the AI revolution would get kicked off. But we didn\u2019t know what the moment would be. To our surprise, it turned out to be this.\nThe launch of ChatGPT kicked off a growth curve like nothing we have ever seen\u2014in our company, our industry, and the world broadly. We are finally seeing some of the massive upside we have always hoped for from AI, and we can see how much more will come soon.\nIt hasn\u2019t been easy. The road hasn\u2019t been smooth and the right choices haven\u2019t been obvious.\nIn the last two years, we had to build an entire company, almost from scratch, around this new technology. There is no way to train people for this except by doing it, and when the technology category is completely new, there is no one at all who can tell you exactly how it should be done.\nBuilding up a company at such high velocity with so little training is a messy process. It\u2019s often two steps forward, one step back (and sometimes, one step forward and two steps back). Mistakes get corrected as you go along, but there aren\u2019t really any handbooks or guideposts when you\u2019re doing original work. Moving at speed in uncharted waters is an incredible experience, but it is also immensely stressful for all the players. Conflicts and misunderstanding abound.\nThese years have been the most rewarding, fun, best, interesting, exhausting, stressful, and\u2014particularly for the last two\u2014unpleasant years of my life so far. The overwhelming feeling is gratitude; I know that someday I\u2019ll be retired at our ranch watching the plants grow, a little bored, and will think back at how cool it was that I got to do the work I dreamed of since I was a little kid. I try to remember that on any given Friday, when seven things go badly wrong by 1 pm.\nA little over a year ago, on one particular Friday, the main thing that had gone wrong that day was that I got fired by surprise on a video call, and then right after we hung up the board published a blog post about it. I was in a hotel room in Las Vegas. It felt, to a degree that is almost impossible to explain, like a dream gone wrong.\nGetting fired in public with no warning kicked off a really crazy few hours, and a pretty crazy few days. The \u201cfog of war\u201d was the strangest part. None of us were able to get satisfactory answers about what had happened, or why.\nThe whole event was, in my opinion, a big failure of governance by well-meaning people, myself included. Looking back, I certainly wish I had done things differently, and I\u2019d like to believe I\u2019m a better, more thoughtful leader today than I was a year ago.\nI also learned the importance of a board with diverse viewpoints and broad experience in managing a complex set of challenges. Good governance requires a lot of trust and credibility. I appreciate the way so many people worked together to build a stronger system of governance for OpenAI that enables us to pursue our mission of ensuring that AGI benefits all of humanity.\nMy biggest takeaway is how much I have to be thankful for and how many people I owe gratitude towards: to everyone who works at OpenAI and has chosen to spend their time and effort going after this dream, to friends who helped us get through the crisis moments, to our partners and customers who supported us and entrusted us to enable their success, and to the people in my life who showed me how much they cared. [1]\nWe all got back to the work in a more cohesive and positive way and I\u2019m very proud of our focus since then. We have done what is easily some of our best research ever. We grew from about 100 million weekly active users to more than 300 million. Most of all, we have continued to put technology out into the world that people genuinely seem to love and that solves real problems.\nNine years ago, we really had no idea what we were eventually going to become; even now, we only sort of know. AI development has taken many twists and turns and we expect more in the future.\nSome of the twists have been joyful; some have been hard. It\u2019s been fun watching a steady stream of research miracles occur, and a lot of naysayers have become true believers. We\u2019ve also seen some colleagues split off and become competitors. Teams tend to turn over as they scale, and OpenAI scales really fast. I think some of this is unavoidable\u2014startups usually see a lot of turnover at each new major level of scale, and at OpenAI numbers go up by orders of magnitude every few months. The last two years have been like a decade at a normal company. When any company grows and evolves so fast, interests naturally diverge. And when any company in an important industry is in the lead, lots of people attack it for all sorts of reasons, especially when they are trying to compete with it.\nOur vision won\u2019t change; our tactics will continue to evolve. For example, when we started we had no idea we would have to build a product company; we thought we were just going to do great research. We also had no idea we would need such a crazy amount of capital. There are new things we have to go build now that we didn\u2019t understand a few years ago, and there will be new things in the future we can barely imagine now.\nWe are proud of our track-record on research and deployment so far, and are committed to continuing to advance our thinking on safety and benefits sharing. We continue to believe that the best way to make an AI system safe is by iteratively and gradually releasing it into the world, giving society time to adapt and co-evolve with the technology, learning from experience, and continuing to make the technology safer. We believe in the importance of being world leaders on safety and alignment research, and in guiding that research with feedback from real world applications.\nWe are now confident we know how to build AGI as we have traditionally understood it. We believe that, in 2025, we may see the first AI agents \u201cjoin the workforce\u201d and materially change the output of companies. We continue to believe that iteratively putting great tools in the hands of people leads to great, broadly-distributed outcomes.\nWe are beginning to turn our aim beyond that, to superintelligence in the true sense of the word. We love our current products, but we are here for the glorious future. With superintelligence, we can do anything else. Superintelligent tools could massively accelerate scientific discovery and innovation well beyond what we are capable of doing on our own, and in turn massively increase abundance and prosperity.\nThis sounds like science fiction right now, and somewhat crazy to even talk about it. That\u2019s alright\u2014we\u2019ve been there before and we\u2019re OK with being there again. We\u2019re pretty confident that in the next few years, everyone will see what we see, and that the need to act with great care, while still maximizing broad benefit and empowerment, is so important. Given the possibilities of our work, OpenAI cannot be a normal company.\nHow lucky and humbling it is to be able to play a role in this work.\n(Thanks to Josh Tyrangiel for sort of prompting this. I wish we had had a lot more time.)\n[1]\nThere were a lot of people who did incredible and gigantic amounts of work to help OpenAI, and me personally, during those few days, but two people stood out from all others.\nRon Conway and Brian Chesky went so far above and beyond the call of duty that I\u2019m not even sure how to describe it. I\u2019ve of course heard stories about Ron\u2019s ability and tenaciousness for years and I\u2019ve spent a lot of time with Brian over the past couple of years getting a huge amount of help and advice.\nBut there\u2019s nothing quite like being in the foxhole with people to see what they can really do. I am reasonably confident OpenAI would have fallen apart without their help; they worked around the clock for days until things were done.\nAlthough they worked unbelievably hard, they stayed calm and had clear strategic thought and great advice throughout. They stopped me from making several mistakes and made none themselves. They used their vast networks for everything needed and were able to navigate many complex situations. And I\u2019m sure they did a lot of things I don\u2019t know about.\nWhat I will remember most, though, is their care, compassion, and support.\nI thought I knew what it looked like to support a founder and a company, and in some small sense I did. But I have never before seen, or even heard of, anything like what these guys did, and now I get more fully why they have the legendary status they do. They are different and both fully deserve their genuinely unique reputations, but they are similar in their remarkable ability to move mountains and help, and in their unwavering commitment in times of need. The tech industry is far better off for having both of them in it.\nThere are others like them; it is an amazingly special thing about our industry and does much more to make it all work than people realize. I look forward to paying it forward.\nOn a more personal note, thanks especially to Ollie for his support that weekend and always; he is incredible in every way and no one could ask for a better partner."
    },
    {
      "url": "https://www.cnbc.com/2025/08/11/sam-altman-says-agi-is-a-pointless-term-experts-agree.html",
      "text": "OpenAI CEO Sam Altman said artificial general intelligence, or \"AGI,\" is losing its relevance as a term as rapid advances in the space make it harder to define the concept.\nAGI refers to the concept of a form of artificial intelligence that can perform any intellectual task that a human can. For years, OpenAI has been working to research and develop AGI that is safe and benefits all humanity.\n\"I think it's not a super useful term,\" Altman told CNBC's \"Squawk Box\" last week, when asked whether the company's latest GPT-5 model moves the world any closer to achieving AGI. The AI entrepreneur has previously said he thinks AGI could be developed in the \"reasonably close-ish future.\"\nThe problem with AGI, Altman said, is that there are multiple definitions being used by different companies and individuals. One definition is an AI that can do \"a significant amount of the work in the world,\" according to Altman \u2014 however, that has its issues because the nature of work is constantly changing.\n\"I think the point of all of this is it doesn't really matter and it's just this continuing exponential of model capability that we'll rely on for more and more things,\" Altman said.\nAltman isn't alone in raising skepticism about \"AGI\" and how people use the term.\nDifficult to define\nNick Patience, vice president and AI practice lead at The Futurum Group, told CNBC that though AGI is a \"fantastic North Star for inspiration,\" on the whole it's not a helpful term.\n\"It drives funding and captures the public imagination, but its vague, sci-fi definition often creates a fog of hype that obscures the real, tangible progress we're making in more specialised AI,\" he said via email.\nOpenAI and other startups have raised billions of dollars and attained dizzyingly high valuations with the promise that they will eventually reach a form of AI powerful enough to be considered \"AGI.\" OpenAI was last valued by investors at $300 billion and it is said to be preparing a secondary share sale at a valuation of $500 billion.\nLast week, the company released GPT-5, its latest large language model for all ChatGPT users. OpenAI said the new system is smarter, faster and \"a lot more useful\" \u2014 especially when it comes to writing, coding and providing assistance on health care queries.\nBut the launch led to criticisms from some online that the long-awaited model was an underwhelming upgrade, making only minor improvements on its predecessor.\n\"By all accounts it's incremental, not revolutionary,\" Wendy Hall, professor of computer science at the University of Southampton, told CNBC.\nAI firms \"should be forced to declare how they measure up to globally agreed metrics\" when they launch new products, Hall added. \"It's the Wild West for snake oil salesmen at the moment.\"\nA distraction?\nFor his part, Altman has admitted OpenAI's new model misses the mark of his own personal definition of AGI, as the system is not yet capable of continuously learning on its own.\nWhile OpenAI still maintains artificial general intelligence as its ultimate goal, Altman has said it's better to talk about levels of progress toward this state of general intelligence rather than asking if something is AGI or not.\n\"We try now to use these different levels ... rather than the binary of, 'is it AGI or is it not?' I think that became too coarse as we get closer,\" the OpenAI CEO said during a talk at the FinRegLab AI Symposium in November 2024.\nAltman still expects AI to achieve some key breakthroughs in specific fields \u2014 such as new math theorems and scientific discoveries \u2014 in the next two years or so.\n\"There's so much exciting real-world stuff happening, I feel AGI is a bit of a distraction, promoted by those that need to keep raising astonishing amounts of funding,\" Futurum's Patience told CNBC.\n\"It's more useful to talk about specific capabilities than this nebulous concept of 'general' intelligence.\""
    },
    {
      "url": "https://arxiv.org/pdf/2506.02153",
      "text": "%PDF-1.5\n%\ufffd\ufffd\ufffd\ufffd\n1 0 obj\n<< /Metadata 3 0 R /Names 4 0 R /OpenAction 5 0 R /Outlines 6 0 R /PageMode /UseOutlines /Pages 7 0 R /Type /Catalog >>\nendobj\n2 0 obj\n<< /Author (Peter Belcak; Greg Heinrich; Shizhe Diao; Yonggan Fu; Xin Dong; Saurav Muralidharan; Yingyan Celine Lin; Pavlo Molchanov) /Creator (arXiv GenPDF \\(tex2pdf:\\)) /DOI (https://doi.org/10.48550/arXiv.2506.02153) /License (http://creativecommons.org/licenses/by/4.0/) /PTEX.Fullbanner (This is pdfTeX, Version 3.141592653-2.6-1.40.25 \\(TeX Live 2023\\) kpathsea version 6.3.5) /Producer (pikepdf 8.15.1) /Title (Small Language Models are the Future of Agentic AI) /Trapped /False /arXivID (https://arxiv.org/abs/2506.02153v1) >>\nendobj\n3 0 obj\n<< /Subtype /XML /Type /Metadata /Length 1755 >>\nstream\nSmall Language Models are the Future of Agentic AIPeter BelcakGreg HeinrichShizhe DiaoYonggan FuXin DongSaurav MuralidharanYingyan Celine LinPavlo Molchanovhttp://creativecommons.org/licenses/by/4.0/cs.AI\nendstream\nendobj\n4 0 obj\n<< /Dests 8 0 R >>\nendobj\n5 0 obj\n<< /D [ 9 0 R /Fit ] /S /GoTo >>\nendobj\n6 0 obj\n<< /Count 9 /First 10 0 R /Last 11 0 R /Type /Outlines >>\nendobj\n7 0 obj\n<< /Count 17 /Kids [ 12 0 R 13 0 R 14 0 R ] /Type /Pages >>\nendobj\n8 0 obj\n<< /Kids [ 15 0 R 16 0 R 17 0 R 18 0 R 19 0 R 20 0 R ] /Limits [ (Doc-Start) (subsection.B.3) ] >>\nendobj\n9 0 obj\n<< /Annots [ 21 0 R 22 0 R 23 0 R 24 0 R 25 0 R 26 0 R 27 0 R 28 0 R 29 0 R ] /Contents [ 30 0 R 31 0 R ] /MediaBox [ 0 0 612 792 ] /Parent 12 0 R /Resources 32 0 R /Type /Page >>\nendobj\n10 0 obj\n<< /A 33 0 R /Next 34 0 R /Parent 6 0 R /Title 35 0 R >>\nendobj\n11 0 obj\n<< /A 36 0 R /Count -3 /First 37 0 R /Last 38 0 R /Parent 6 0 R /Prev 39 0 R /Title 40 0 R >>\nendobj\n12 0 obj\n<< /Count 6 /Kids [ 9 0 R 41 0 R 42 0 R 43 0 R 44 0 R 45 0 R ] /Parent 7 0 R /Type /Pages >>\nendobj\n13 0 obj\n<< /Count 6 /Kids [ 46 0 R 47 0 R 48 0 R 49 0 R 50 0 R 51 0 R ] /Parent 7 0 R /Type /Pages >>\nendobj\n14 0 obj\n<< /Count 5 /Kids [ 52 0 R 53 0 R 54 0 R 55 0 R 56 0 R ] /Parent 7 0 R /Type /Pages >>\nendobj\n15 0 obj\n<< /Kids [ 57 0 R 58 0 R 59 0 R 60 0 R 61 0 R 62 0 R ] /Limits [ (Doc-Start) (appendix.A) ] >>\nendobj\n16 0 obj\n<< /Kids [ 63 0 R 64 0 R 65 0 R 66 0 R 67 0 R 68 0 R ] /Limits [ (appendix.B) (cite.huang2020unsupervised) ] >>\nendobj\n17 0 obj\n<< /Kids [ 69 0 R 70 0 R 71 0 R 72 0 R 73 0 R 74 0 R ] /Limits [ (cite.invisible2025slm) (cite.workos2025secureagents) ] >>\nendobj\n18 0 obj\n<< /Kids [ 75 0 R 76 0 R 77 0 R 78 0 R 79 0 R 80 0 R ] /Limits [ (cite.xue2024powerinfer) (section*.15) ] >>\nendobj\n19 0 obj\n<< /Kids [ 81 0 R 82 0 R 83 0 R 84 0 R 85 0 R 86 0 R ] /Limits [ (section*.16) (subsection.A.1) ] >>\nendobj\n20 0 obj\n<< /Kids [ 87 0 R ] /Limits [ (subsection.A.2) (subsection.B.3) ] >>\nendobj\n21 0 obj\n<< /A << /D (cite.cloudera2025aiagents) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 159.836 196.894 171.791 205.641 ] /Subtype /Link /Type /Annot >>\nendobj\n22 0 obj\n<< /A << /D (cite.loucks2024autonomous) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 386.065 175.076 398.02 183.823 ] /Subtype /Link /Type /Annot >>\nendobj\n23 0 obj\n<< /A << /D (cite.marketus2025agenticai) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 400.984 174.976 412.939 183.823 ] /Subtype /Link /Type /Annot >>\nendobj\n24 0 obj\n<< /A << /D (cite.masterman2024landscape) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 463.272 147.679 475.227 156.525 ] /Subtype /Link /Type /Annot >>\nendobj\n25 0 obj\n<< /A << /D (cite.luo2025large) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 478.19 147.778 490.145 156.525 ] /Subtype /Link /Type /Annot >>\nendobj\n26 0 obj\n<< /A << /D (cite.masterman2024landscape) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 270.368 104.042 282.323 112.889 ] /Subtype /Link /Type /Annot >>\nendobj\n27 0 obj\n<< /A << /D (cite.dairai2024llmagents) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 285.182 104.142 297.137 112.889 ] /Subtype /Link /Type /Annot >>\nendobj\n28 0 obj\n<< /A << /D (cite.masterman2024landscape) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 141.594 82.224 153.549 91.071 ] /Subtype /Link /Type /Annot >>\nendobj\n29 0 obj\n<< /A << /S /URI /URI (https://arxiv.org/abs/2506.02153v1) >> /BS << /W 0 >> /NM (fitz-L0) /Rect [ 12 231.02002 32 560.98 ] /Subtype /Link >>\nendobj\n30 0 obj\n<< /Filter /FlateDecode /Length 140 >>\nstream\nx\ufffdE\ufffd\ufffd\n1E\ufffd\ufffd\ufffd\ufffd@\ufffd<\ufffd\ufffdq!\ufffd\ufffd\u03a1;qQ\ufffd\ufffd\ufffd*\ufffd\ufffd\ufffd\ufffdQ\ufffd\ufffdp\ufffd\\x\ufffd*!\ufffdc\ufffdiN\ufffd\ufffd(\ufffd :Lf\ufffdV\ufffd\ufffd\n\ufffd\ufffd\ufffd(\ufffd\u909d\ufffdv\ufffd\ufffd\ufffdu\ufffd\ufffd\"p\ufffd\ufffd>\ufffd*jJ\ufffd\ufffd\ufffd:[\ufffd\ufffdYH\u020eA\ufffdJ\ufffd\ufffd{;\ufffdFE\ufffd\ufffdh\ufffd\ufffd<}\ufffdN\ufffd\ufffd*&}\nendstream\nendobj\n31 0 obj\n<< /Filter /FlateDecode /Length 3373 >>\nstream\nx\u069dZ[\ufffd\u06f6~?\ufffdB/\ufffd\ufffdf,\ufffd \ufffd[\ufffd\ufffd$NRg\ufffd[7>\ufffde?@%\ufffd\ufffdH\ufffd\ufffd*\ufffd\ufffd\ufffdb\ufffd\ufffdt\ufffd\ufffd<\ufffd\ufffdB`\ufffdX\ufffd~{\ufffd\ufffd\ufffd~-\ufffd\ufffd\ufffd\ufffd_\ufffdh!\"\ufffdY\ufffd\ufffd\ufffdH\ufffd\ufffdM\ufffd\"]\u0230\u0213E[.v\ufffd\ufffd\ufffd\ufffd\ufffdwY\ufffdY\ufffdD-\ufffdv!\ufffd\ufffd\"\ufffd\ufffdH\ufffd\ufffdi\ufffd\ufffd|8\ufffdZ\ufffd\ufffd$\nu\ufffd\ufffd\ufffd\ufffd\u047bf[V\ufffdu\ufffdy\ufffd>\ufffd\ufffd\ufffdn\ufffd\ufffdf\ufffd\ufffdW\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd.?=\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdiR\ufffdIJ\ufffd\ufffd-\ufffd\ufffd\ufffda\ufffd\ufffd\ufffdlW\ud562E\ufffd\ufffd0\ufffdMi\ufffd\ufffd\ufffd(Fb\ufffd\ufffd2\ufffd\ufffd\ufffd\ufffdee_\ufffd|\ufffd\ufffde\ufffd\u045f\ufffd\ufffd\ufffd\ufffd\ufffdr\ufffd\ufffdE&s\u069b\ufffd0S9\ufffdB\ufffdv\ufffd\ufffdU\ufffd\ufffd!\ufffd\ufffd\u0272\ufffd\ufffd\ufffd{\ufffd\ufffd\ufffd\ufffd\u052d\ufffd\ufffd0\ufffd\ufffd\ufffdq\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd=\ufffd0M~i9#\ufffd\ufffd% h\ufffd\ufffd^\ufffd\ufffd\ufffdD\ufffd\ufffd\ufffd/\ufffd\u023e\ufffdw+\ufffd\ufffd_\ufffd+ea\ufffd] u\u021dX\ufffd\ufffd\ufffde\ufffd_\ufffdrbX\ufffd\ufffdA\ufffd\ufffd\ufffd\ufffdQ\ufffd\ufffd\ufffd\u015f\ufffd6\ufffd^F2L\ufffd?{}SV\ufffdv\ufffd\ufffdh\ufffda\ufffd\ufffd;\ufffd\\V\ufffd63R\ufffd\ufffdOw\ufffd\u0121L3\ufffd \ufffdm\u073e_\n\u0626K\ufffdx\ufffd\ufffd6]7\ufffd\ufffd\u02ddc2*\ufffdn\ufffd]`s\ufffdE\nb\ufffd\ufffd\ufffd\ufffd&@\ufffd*T\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdo\ufffd~\ufffd\ufffd\ufffdXv\ufffdn\ufffdD\ufffdB\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdC\ufffd3\ufffd+ku{\ufffd\ufffd\ufffd\ufffdu\u05db~\ufffdP\ufffdi\ufffd\ufffd\ufffd7\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdI\ufffd&\ufffdg\ufffd\ufffd\ufffdp&*\ufffd\ufffd&\ufffd\ufffd\ufffd\\1[\ufffd\ufffdMs%9I\u06f7\ufffda\ufffdb\ufffdy\ufffd\ufffdZw}\ufffd7\ufffdE\ufffdk\ufffd\ufffd\ufffd!U\ufffdO\ufffd0O\ufffdE\ufffd\ufffd|\ufffdG\ufffdW\ufffd\ufffd*\ufffdct\ufffd8\ufffd\ufffd\ufffdQ=>\ufffd\ufffd\ufffd\n\ufffd\u046d]\ufffdC\ufffdj\ufffdZm\ufffdr\ufffdkvM\ufffd,H\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdq\ufffd\ufffd\ufffd^\ufffd\ufffd\ufffdp\ufffdJ\ufffd\ufffdT\ufffd\ufffdj\ufffd\ufffd\ufffdy\ufffdlD,\ufffdyP\ufffd\ufffd\n\ufffd\ufffd)\ufffd\ufffd\ufffd\ufffdg\ufffdu`\ufffd{\ufffdf\ufffdm\ufffd\ufffd\ufffdt\ufffdL\ufffd\ufffd\ufffd\u0717e\ufffd\ufffd\ufffdP\ufffd1\ufffdN\ufffd\ufffdq]\ufffd6\ufffd\ufffd\ufffdn\ufffda\n\ufffd\ufffd\ufffd\u038e\ufffd\u00d6 \ufffd\ufffdEp\ufffd1\ufffda\ufffde\ufffd\ufffd!\ufffd\ufffd\ufffdto\ufffd:\\\ufffdd\ufffd\ufffd'\ufffd\u0199Z\ufffdz\ufffd\ufffd_\ufffd\ufffdX?\ufffdI\ufffd9\ufffdv\ufffd/\ufffd\ufffd0\ufffd+\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\\2\ufffd \ufffdS\ufffd@\ufffdu\ufffde\ufffd/B\ufffdj\ufffd\ufffd\ufffd9\ufffd\ufffdQ\u00f9tho~u\ufffd\ufffd\ufffd\u06a4O\ufffd\ufffdl\ufffdhc\ufffd1E\ufffd\ufffd\ufffdV\ufffd;\u0471x\ufffdcqJ\ufffdOO\ufffd47\ufffd\u042d\ufffd\ufffd\ufffd:X\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd0\ufffd/k%\ufffd)bY(\ufffd-O%L\ufffd8\ufffd@\ufffd\ufffd\ufffdV\ufffdy6\ufffd\ufffd{x\ufffdr6\ufffd\ufffdv\ufffd\u05b8\ufffdz\ufffdU\n)>\ufffd/\ufffd\ufffd\ufffd\u013eZ \ufffdy\ufffdz\ufffdq\ufffd\ufffd\nNMg\ufffd4\ufffd\ufffd\ufffdv\ufffd09 FV\ufffd0\ufffd\ufffd\ufffdd\ufffd.v\ufffd\ufffdS\ufffd,\ufffd\ufffd<\ufffd*Vat\ufffd1\ufffd\n;\ufffd\ufffd\ufffd(\ufffd([u~\ufffd\ufffd,Oy\u06e9y\ufffd#\ufffdK\ufffd\ufffd\ufffd@\ufffdLa\ufffd\ufffd-\ufffd\ufffd\ufffdG\ufffd`z\ufffd\ufffdt\ufffdJ\ufffd~\ufffd\ufffd\ufffdaSvd}g \ufffdi\ufffdP\ufffd\ufffd\ufffdl\ufffd\ufffdL\ufffd/3 \u0373\ufffd\ufffd5lz\u0368\ufffdJHK\ufffd&?\ufffd\ufffd?\ufffd\ufffdh\u0499q\ufffdR\ufffd\u052e\ufffd;\ufffdW\ufffd\ufffdl\ufffd;;\ufffd^>\ufffd*\ufffdx \u01f0\ufffd\ufffd>\ufffd\ufffdJ\ufffdT\ufffd{\ufffd\ufffd\ufffdo8\u0189!\ufffd\ufffdJ\ufffd\u0719-\ufffd\ufffd\u1203\ufffdS>`\ufffdq\u043fo\ufffd\ufffd\ufffdzH7\ufffd+k,:\ufffd\ufffdm\ufffd\ufffd9\ufffdrbQ2\ufffd\ufffd\ufffd\u076aoVX\ufffdY\ufffd\ufffdhT\ufffd\ufffd\ufffd$L\ufffds\ufffd\ufffd\ufffd7-|\ufffd\ufffdE\ufffd(\ufffd?\ufffd\ufffd\ufffdV\nb\ufffd\ufffd\ufffd -\ufffd \ufffdJ[D\ufffd\u03fas-7\ufffd+\ufffdv \ufffd\ufffd\ufffd\ufffd\ufffd.\ufffd\ufffd\ufffd*\ufffd\ufffd\ufffd.+{\ufffd\ufffd\ufffdkc\ufffdG\ufffd\ufffd\ufffdE5\ufffd8\ufffd@\ufffd(\ufffd \ufffd$\ufffdD\ufffd2\ufffdM8 F_\ufffd\ufffd\ufffdx\ufffd\ufffd\ufffd\ufffd'qW\ufffd6qs\ufffd-k\n\ufffd\ufffd\ufffd\ufffdLj\ufffd\"\ufffd\ufffd\ufffd\ufffd\ufffdG\ufffd&\ufffdV^b9\u03a1Q\ufffd\ufffdv\ufffd\ufffd\ufffd4E\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u04ae8\ufffd \ufffd\"i\ufffd\ufffd\ufffd2\ufffdv@\ufffdq^\ufffd\ufffd|\n\ufffd<\ufffdD\ufffdIhs\ufffd-|\n\ufffdco\ufffd\ufffdH;\ufffd1|fxm\ufffds \ufffd\ufffdQ\ufffdO\u43a0\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd4\ufffd\ufffd\u0439Y\ufffd\ufffdh\ufffd\ufffd\ufffd\ufffdn\ufffdih_\ufffd:<\"\ufffd,\ufffd\ufffdi\ufffd:\ufffdj\ufffd\ufffd\ufffd\ufffd\ufffd`SM\ufffdw\ufffd]\ufffd\ufffd\ufffd\ufffde\ufffd\u0226NJN6MG\ufffd\ufffdk\ufffd>Z\ufffdx:\u05dep\ufffd4\ufffd\ufffd\ufffd \ufffdoZ\ufffd\ufffdOh\ufffd\ufffdn(b\ufffdc\ufffd5kB\ufffd\ufffd\ufffd6D\ufffd\ufffd\ufffd\ufffd\u05b5\ufffd\ufffdT+.\ufffd0v\ufffd\u051b_\ufffd\u021b\u030cB\ufffd\ufffdX\ufffd\ufffd\ufffd\ufffd~\u0211b\\\ufffdN\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u00fa2\ufffdu\ufffd\ufffd6\ufffd\ufffd\ufffd\ufffd@\ufffdMmD\u0769A\ufffd\ufffd\ufffd\ufffd;9\ufffd5\ufffdy\ufffdT\ufffd\ufffd\ufffd]\ufffd\ufffd\ufffd+\ufffd\ufffd^W\ufffd\ufffduWW\ufffd\u0746Wq$\ufffdB&\ufffd\"\ufffd\ufffd\ufffdW1\"\ufffd2\ufffd(b,Z \u00cf\ufffdN\ufffd\u06d0\ufffd\ufffd\ufffdW\ufffdL\ufffd\ufffd-;\ufffdE,\ufffd0\ufffd\ufffd\ufffdp\ufffd\ufffd\ufffdEG<\u01eeAN\ufffd\ufffd\ufffd%\ufffd/\ufffd'{\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdq99\ufffd\ufffd\ufffdt\ufffd\\ \ufffd\ufffdG\ufffd\ufffd\ufffd\ufffdnh\ufffd\ufffd\ufffd\ufffd\ufffd(\ufffdL\ufffdg\ufffd\ufffd\ufffdt\ufffdz9\ufffd\ufffddR|\ufffd\ufffd<\u030a\ufffd,\ufffd\ufffd\ufffd'\ufffd\ufffd\ufffdv\ufffdk\\[M\n\ufffd}\ufffd\\\ufffd\ufffd8\ufffd\ufffd\u05ad\ufffd\ufffdH}V'8\ufffdH\\\ufffdL\ufffd\ufffd\ufffdb~}\ufffd\ufffd\ufffd\ufffd\ufffde 8\ufffd2\ufffd\ufffd\ufffd\u01a9\ufffd\ufffd\ufffd=\ufffdi\ufffd@\nWE\ufffd(\ufffd\ufffdv#zg*\ufffd \ufffd\ufffd\u0739\ufffd\ufffdR\u03b6\ufffd\ufffd\ufffd,\ufffd\ufffd\u066aO\ufffd\ufffdT\ufffdU\u01f5\ufffd\u0784z#\ufffd\u0316\ufffd!Uj?S[\ufffdPL\ufffdEv\n\ufffd\ufffd\u04ad\ufffd5\ufffd\ufffd$\u03398;\ufffd\ufffd\ufffd\ufffd4\ufffd~\ufffd\ufffdw\ufffd4\ufffd\ufffd:\ufffdR\ufffda\u03edm\ufffdKG\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdM\ufffdL3M\ufffd\ufffdX[\ufffd\ufffdB<\ufffd\ufffd\ufffdCl\ufffd\ufffd\ufffd\ufffdsz>%\\\ufffd\ufffd\ufffd\ufffd\ufffdY\\f\ufffdR\ufffd\u00e5\ufffd\ufffd\ufffd\ufffdQy@\ufffd6qs\ufffd\ufffd\ufffdW\ufffd\ufffd\ufffd\ufffd5)y)\ufffd?\ufffd,\ufffd\ufffd0N\ufffd\ufffdMT~sc\ufffda\ufffd\ufffd\ufffd\ufffdfeH\ufffd\ufffd%\ufffdc\ufffd*\ufffd\ufffd>9\ufffdv\ufffd\ufffd|\ufffd1\ufffd\ufffd&\ufffd`\ufffd\ufffd\ufffd\ufffd*\ufffd\ufffd2\ufffddT\ufffd`\ufffd!}a\u476e\ufffdQ\ufffd\ufffd~\ufffd\u04f5_\ufffd\ufffd\ufffd \u46aaa\ufffd\ufffd\ufffd=\u063c@\ufffdg[#\ufffdY\ufffd%\ufffd\ufffd\ufffd\ufffd5\ufffdm\ufffd1\ufffd\ufffd}\ufffd&\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdKn\ufffd\ufffdk\ufffd\ufffd\ufffd\ufffdC\ufffd\ufffd\ufffd\ufffd\ufffd\u04a9`(\ufffdmF\ufffdQ|\ufffd\ufffdo*[\ufffdcO\ufffd4\ufffdu0\ufffd\ufffdMu\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdK\ufffd\ufffdQ]\ufffd\ufffd\ufffdT\ufffd\ufffd\ufffd\ufffdWe\ufffd\u03e2r\ufffd\ufffd\ufffdHC@\ufffdr,n\ufffd\\\ufffdqi\ufffd\ufffd.Z\ufffds\ufffdz\ufffdS\u05ba-!e{\ufffd\ufffd\ufffd\ufffd}^L\ufffd[\ufffdp;\ufffd \u05bc=\ufffdG]\ufffd\ufffd@&\ufffdF\ufffd\ufffd\ufffd.eo\ufffd\ufffdRwMm\ufffdg\u031b\ufffd\"\ufffd\ufffd|\ufffd\ufffd\u00d56\ufffd\ufffd\ufffd\ufffd_X\ufffdQi'\ufffd9\ufffd\ufffd\ufffdr\ufffdJ\ufffd,3\ufffd\ufffdg5?cb\ufffd~Y\ufffdeHf\ufffd\ufffd\u00df\ufffd\ufffd[\ufffdn(!\ufffdJ\u0317\ufffd!\ufffd\u061fO\ufffd\ufffd\ufffdKpH\ufffd\ufffdu\n.B\ufffd\ufffd1\ufffd\ufffd\u0657\ufffd\ufffd\u01e1\ufffd\"|\ufffd\u0446w\ufffdl\ufffd \ufffd\ufffd.|\ufffdN\ufffdM\ufffd\n\ufffd\ufffd\ufffdF(\ufffdy\ufffd\u2672\u079eS;\ufffd\ufffdr%\ufffd\ufffd\ufffd[\ufffd\u07d6\u0215:P\ufffdj\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffdV\ufffd\ufffdF\ufffd\ufffd\ufffd\ufffd\ufffd,\ufffd\ufffd\ufffd\u079b\ufffd\ufffd\ufffd\u034d\ufffd\ufffde8\ufffdx\ufffd2}T\ufffd\ufffdp\ufffd3\ufffd\ufffdBrd!\ufffd\ufffd\ufffd\ufffd\ufffd\n\ucbfam\ufffd\ufffd\ufffdj\ufffd\ufffd\ufffd\ufffd\ufffd\u05ab\ufffd\ufffd\ufffdM\ufffdV\ufffd\ufffd\ufffd\u03cf\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdk\ufffd\ufffd\nendstream\nendobj\n32 0 obj\n<< /Font << /F23 88 0 R /F26 89 0 R /F53 90 0 R /F79 91 0 R /F85 92 0 R /F94 93 0 R /Times-Roman 94 0 R >> /ProcSet [ /PDF /Text ] >>\nendobj\n33 0 obj\n<< /D (section.1) /S /GoTo >>\nendobj\n34 0 obj\n<< /A 95 0 R /Count -3 /First 96 0 R /Last 97 0 R /Next 98 0 R /Parent 6 0 R /Prev 10 0 R /Title 99 0 R >>\nendobj\n35 0 obj\nendobj\n36 0 obj\n<< /D (appendix.B) /S /GoTo >>\nendobj\n37 0 obj\n<< /A 100 0 R /Next 101 0 R /Parent 11 0 R /Title 102 0 R >>\nendobj\n38 0 obj\n<< /A 103 0 R /Parent 11 0 R /Prev 101 0 R /Title 104 0 R >>\nendobj\n39 0 obj\n<< /A 105 0 R /Count -2 /First 106 0 R /Last 107 0 R /Next 11 0 R /Parent 6 0 R /Prev 108 0 R /Title 109 0 R >>\nendobj\n40 0 obj\nendobj\n41 0 obj\n<< /Annots [ 110 0 R 111 0 R 112 0 R 113 0 R 114 0 R 115 0 R 116 0 R 117 0 R 118 0 R 119 0 R 120 0 R 121 0 R 122 0 R ] /Contents 123 0 R /MediaBox [ 0 0 612 792 ] /Parent 12 0 R /Resources 124 0 R /Type /Page >>\nendobj\n42 0 obj\n<< /Annots [ 125 0 R 126 0 R 127 0 R 128 0 R 129 0 R 130 0 R 131 0 R 132 0 R 133 0 R 134 0 R 135 0 R ] /Contents 136 0 R /MediaBox [ 0 0 612 792 ] /Parent 12 0 R /Resources 137 0 R /Type /Page >>\nendobj\n43 0 obj\n<< /Annots [ 138 0 R 139 0 R 140 0 R 141 0 R 142 0 R 143 0 R 144 0 R 145 0 R 146 0 R 147 0 R 148 0 R 149 0 R 150 0 R 151 0 R ] /Contents 152 0 R /Group 153 0 R /MediaBox [ 0 0 612 792 ] /Parent 12 0 R /Resources 154 0 R /Type /Page >>\nendobj\n44 0 obj\n<< /Annots [ 155 0 R 156 0 R 157 0 R 158 0 R 159 0 R 160 0 R 161 0 R 162 0 R 163 0 R 164 0 R 165 0 R 166 0 R 167 0 R 168 0 R 169 0 R 170 0 R 171 0 R 172 0 R 173 0 R 174 0 R 175 0 R 176 0 R 177 0 R 178 0 R 179 0 R ] /Contents 180 0 R /MediaBox [ 0 0 612 792 ] /Parent 12 0 R /Resources 181 0 R /Type /Page >>\nendobj\n45 0 obj\n<< /Annots [ 182 0 R 183 0 R 184 0 R 185 0 R 186 0 R 187 0 R 188 0 R 189 0 R 190 0 R 191 0 R 192 0 R 193 0 R 194 0 R ] /Contents 195 0 R /MediaBox [ 0 0 612 792 ] /Parent 12 0 R /Resources 196 0 R /Type /Page >>\nendobj\n46 0 obj\n<< /Annots [ 197 0 R 198 0 R 199 0 R 200 0 R 201 0 R 202 0 R 203 0 R 204 0 R 205 0 R 206 0 R 207 0 R 208 0 R 209 0 R 210 0 R 211 0 R 212 0 R 213 0 R 214 0 R 215 0 R 216 0 R 217 0 R 218 0 R 219 0 R 220 0 R ] /Contents 221 0 R /MediaBox [ 0 0 612 792 ] /Parent 13 0 R /Resources 222 0 R /Type /Page >>\nendobj\n47 0 obj\n<< /Annots [ 223 0 R 224 0 R 225 0 R 226 0 R 227 0 R 228 0 R 229 0 R 230 0 R 231 0 R 232 0 R 233 0 R 234 0 R 235 0 R 236 0 R 237 0 R 238 0 R 239 0 R 240 0 R 241 0 R 242 0 R 243 0 R 244 0 R 245 0 R 246 0 R 247 0 R 248 0 R 249 0 R 250 0 R 251 0 R 252 0 R 253 0 R 254 0 R 255 0 R 256 0 R 257 0 R ] /Contents 258 0 R /MediaBox [ 0 0 612 792 ] /Parent 13 0 R /Resources 259 0 R /Type /Page >>\nendobj\n48 0 obj\n<< /Annots [ 260 0 R 261 0 R 262 0 R 263 0 R 264 0 R 265 0 R 266 0 R 267 0 R 268 0 R 269 0 R 270 0 R 271 0 R 272 0 R 273 0 R 274 0 R 275 0 R 276 0 R 277 0 R 278 0 R 279 0 R 280 0 R ] /Contents 281 0 R /MediaBox [ 0 0 612 792 ] /Parent 13 0 R /Resources 282 0 R /Type /Page >>\nendobj\n49 0 obj\n<< /Contents 283 0 R /MediaBox [ 0 0 612 792 ] /Parent 13 0 R /Resources 284 0 R /Type /Page >>\nendobj\n50 0 obj\n<< /Contents 285 0 R /MediaBox [ 0 0 612 792 ] /Parent 13 0 R /Resources 286 0 R /Type /Page >>\nendobj\n51 0 obj\n<< /Contents 287 0 R /MediaBox [ 0 0 612 792 ] /Parent 13 0 R /Resources 288 0 R /Type /Page >>\nendobj\n52 0 obj\n<< /Annots [ 289 0 R 290 0 R ] /Contents 291 0 R /MediaBox [ 0 0 612 792 ] /Parent 14 0 R /Resources 292 0 R /Type /Page >>\nendobj\n53 0 obj\n<< /Annots [ 293 0 R 294 0 R ] /Contents 295 0 R /MediaBox [ 0 0 612 792 ] /Parent 14 0 R /Resources 296 0 R /Type /Page >>\nendobj\n54 0 obj\n<< /Annots [ 297 0 R 298 0 R 299 0 R 300 0 R 301 0 R 302 0 R 303 0 R 304 0 R ] /Contents 305 0 R /MediaBox [ 0 0 612 792 ] /Parent 14 0 R /Resources 306 0 R /Type /Page >>\nendobj\n55 0 obj\n<< /Contents 307 0 R /MediaBox [ 0 0 612 792 ] /Parent 14 0 R /Resources 308 0 R /Type /Page >>\nendobj\n56 0 obj\n<< /Contents 309 0 R /MediaBox [ 0 0 612 792 ] /Parent 14 0 R /Resources 310 0 R /Type /Page >>\nendobj\n57 0 obj\n<< /Limits [ (Doc-Start) (Item.13) ] /Names [ (Doc-Start) 311 0 R (Item.1) 312 0 R (Item.10) 313 0 R (Item.11) 314 0 R (Item.12) 315 0 R (Item.13) 316 0 R ] >>\nendobj\n58 0 obj\n<< /Limits [ (Item.14) (Item.19) ] /Names [ (Item.14) 317 0 R (Item.15) 318 0 R (Item.16) 319 0 R (Item.17) 320 0 R (Item.18) 321 0 R (Item.19) 322 0 R ] >>\nendobj\n59 0 obj\n<< /Limits [ (Item.2) (Item.24) ] /Names [ (Item.2) 323 0 R (Item.20) 324 0 R (Item.21) 325 0 R (Item.22) 326 0 R (Item.23) 327 0 R (Item.24) 328 0 R ] >>\nendobj\n60 0 obj\n<< /Limits [ (Item.25) (Item.3) ] /Names [ (Item.25) 329 0 R (Item.26) 330 0 R (Item.27) 331 0 R (Item.28) 332 0 R (Item.29) 333 0 R (Item.3) 334 0 R ] >>\nendobj\n61 0 obj\n<< /Limits [ (Item.30) (Item.4) ] /Names [ (Item.30) 335 0 R (Item.31) 336 0 R (Item.32) 337 0 R (Item.33) 338 0 R (Item.34) 339 0 R (Item.4) 340 0 R ] >>\nendobj\n62 0 obj\n<< /Limits [ (Item.5) (appendix.A) ] /Names [ (Item.5) 341 0 R (Item.6) 342 0 R (Item.7) 343 0 R (Item.8) 344 0 R (Item.9) 345 0 R (appendix.A) 346 0 R ] >>\nendobj\n63 0 obj\n<< /Limits [ (appendix.B) (cite.agarwal2024delift) ] /Names [ (appendix.B) 347 0 R (cite.aashima2024slmvsllm) 348 0 R (cite.abbyy2024smallvslarge) 349 0 R (cite.abdin2024phi) 350 0 R (cite.adyog2025deepseek) 351 0 R (cite.agarwal2024delift) 352 0 R ] >>\nendobj\n64 0 obj\n<< /Limits [ (cite.ai-dynamo-dynamo) (cite.brennan2012adversarial) ] /Names [ (cite.ai-dynamo-dynamo) 353 0 R (cite.allal2025smollm2smolgoesbig) 354 0 R (cite.berkeley-function-calling-leaderboard) 355 0 R (cite.blakeman2025nemotron) 356 0 R (cite.borgeaud2022retro) 357 0 R (cite.brennan2012adversarial) 358 0 R ] >>\nendobj\n65 0 obj\n<< /Limits [ (cite.cai2024flextron) (cite.das2025security) ] /Names [ (cite.cai2024flextron) 359 0 R (cite.chatrtx2024) 360 0 R (cite.chui2022stateai) 361 0 R (cite.cloudera2025aiagents) 362 0 R (cite.dairai2024llmagents) 363 0 R (cite.das2025security) 364 0 R ] >>\nendobj\n66 0 obj\n<< /Limits [ (cite.deepseekai2025deepseekr1incentivizingreasoningcapability) (cite.dynamo2025) ] /Names [ (cite.deepseekai2025deepseekr1incentivizingreasoningcapability) 365 0 R (cite.dettmers2023qlora) 366 0 R (cite.diao2025climb) 367 0 R (cite.ding2023parameter) 368 0 R (cite.dong2024hymba) 369 0 R (cite.dynamo2025) 370 0 R ] >>\nendobj\n67 0 obj\n<< /Limits [ (cite.esg2024inferencing) (cite.grandview2025llm) ] /Names [ (cite.esg2024inferencing) 371 0 R (cite.evans2025llmsvsslms) 372 0 R (cite.ferguson2003coarse) 373 0 R (cite.fu2024amoeballm) 374 0 R (cite.google-a2a) 375 0 R (cite.grandview2025llm) 376 0 R ] >>\nendobj\n68 0 obj\n<< /Limits [ (cite.harrisonclarke2024llmslms) (cite.huang2020unsupervised) ] /Names [ (cite.harrisonclarke2024llmslms) 377 0 R (cite.hernandez2021scaling) 378 0 R (cite.hoffmann2022training) 379 0 R (cite.hu2021lora) 380 0 R (cite.hu2022lora) 381 0 R (cite.huang2020unsupervised) 382 0 R ] >>\nendobj\n69 0 obj\n<< /Limits [ (cite.invisible2025slm) (cite.liu2023deja) ] /Names [ (cite.invisible2025slm) 383 0 R (cite.jungherr2023artificial) 384 0 R (cite.kudugunta2023matformer) 385 0 R (cite.kumar2025large) 386 0 R (cite.liu2005comparative) 387 0 R (cite.liu2023deja) 388 0 R ] >>\nendobj\n70 0 obj\n<< /Limits [ (cite.liu2024dora) (cite.mann2025dynamo) ] /Names [ (cite.liu2024dora) 389 0 R (cite.loucks2024autonomous) 390 0 R (cite.lu2024small) 391 0 R (cite.luo2025large) 392 0 R (cite.mace1981brain) 393 0 R (cite.mann2025dynamo) 394 0 R ] >>\nendobj\n71 0 obj\n<< /Limits [ (cite.marketus2025agenticai) (cite.miehling2025agentic) ] /Names [ (cite.marketus2025agenticai) 395 0 R (cite.masterman2024landscape) 396 0 R (cite.mehta2024energy) 397 0 R (cite.meta2025llama3_3) 398 0 R (cite.metomic2025aiagents) 399 0 R (cite.miehling2025agentic) 400 0 R ] >>\nendobj\n72 0 obj\n<< /Limits [ (cite.morganstanley2025genai) (cite.radhakrishnan2023certified) ] /Names [ (cite.morganstanley2025genai) 401 0 R (cite.naveed2023comprehensive) 402 0 R (cite.phi22023) 403 0 R (cite.planck2018results) 404 0 R (cite.polo2024tinybenchmarks) 405 0 R (cite.radhakrishnan2023certified) 406 0 R ] >>\nendobj\n73 0 obj\n<< /Limits [ (cite.rees1997before) (cite.song2024powerinfer) ] /Names [ (cite.rees1997before) 407 0 R (cite.sainz2024open) 408 0 R (cite.schopf1993microfossils) 409 0 R (cite.seda2024cloudllm) 410 0 R (cite.shone2024explore) 411 0 R (cite.song2024powerinfer) 412 0 R ] >>\nendobj\n74 0 obj\n<< /Limits [ (cite.subramanian2025small) (cite.workos2025secureagents) ] /Names [ (cite.subramanian2025small) 413 0 R (cite.synergy2025smallvslarge) 414 0 R (cite.thamm2024trustworthy) 415 0 R (cite.toolformer2023) 416 0 R (cite.wang2024comprehensive) 417 0 R (cite.workos2025secureagents) 418 0 R ] >>\nendobj\n75 0 obj\n<< /Limits [ (cite.xue2024powerinfer) (cite.zewe2025llmsemantic) ] /Names [ (cite.xue2024powerinfer) 419 0 R (cite.yadav2025ai) 420 0 R (cite.yan2024protecting) 421 0 R (cite.yao2024tau) 422 0 R (cite.yu2024privacy) 423 0 R (cite.zewe2025llmsemantic) 424 0 R ] >>\nendobj\n76 0 obj\n<< /Limits [ (cite.zhang2024inference) (figure.caption.2) ] /Names [ (cite.zhang2024inference) 425 0 R (cite.zhang2024xlam) 426 0 R (cite.zhou2022leasttomost) 427 0 R (cite.zhou2023instruction) 428 0 R (cite.zier2025dynamo) 429 0 R (figure.caption.2) 430 0 R ] >>\nendobj\n77 0 obj\n<< /Limits [ (noticebox.caption.1) (page.13) ] /Names [ (noticebox.caption.1) 431 0 R (page.1) 432 0 R (page.10) 433 0 R (page.11) 434 0 R (page.12) 435 0 R (page.13) 436 0 R ] >>\nendobj\n78 0 obj\n<< /Limits [ (page.14) (page.3) ] /Names [ (page.14) 437 0 R (page.15) 438 0 R (page.16) 439 0 R (page.17) 440 0 R (page.2) 441 0 R (page.3) 442 0 R ] >>\nendobj\n79 0 obj\n<< /Limits [ (page.4) (page.9) ] /Names [ (page.4) 443 0 R (page.5) 444 0 R (page.6) 445 0 R (page.7) 446 0 R (page.8) 447 0 R (page.9) 448 0 R ] >>\nendobj\n80 0 obj\n<< /Limits [ (section*.10) (section*.15) ] /Names [ (section*.10) 449 0 R (section*.11) 450 0 R (section*.12) 451 0 R (section*.13) 452 0 R (section*.14) 453 0 R (section*.15) 454 0 R ] >>\nendobj\n81 0 obj\n<< /Limits [ (section*.16) (section*.21) ] /Names [ (section*.16) 455 0 R (section*.17) 456 0 R (section*.18) 457 0 R (section*.19) 458 0 R (section*.20) 459 0 R (section*.21) 460 0 R ] >>\nendobj\n82 0 obj\n<< /Limits [ (section*.22) (section*.6) ] /Names [ (section*.22) 461 0 R (section*.23) 462 0 R (section*.3) 463 0 R (section*.4) 464 0 R (section*.5) 465 0 R (section*.6) 466 0 R ] >>\nendobj\n83 0 obj\n<< /Limits [ (section*.7) (section.3) ] /Names [ (section*.7) 467 0 R (section*.8) 468 0 R (section*.9) 469 0 R (section.1) 470 0 R (section.2) 471 0 R (section.3) 472 0 R ] >>\nendobj\n84 0 obj\n<< /Limits [ (section.4) (subsection.2.2) ] /Names [ (section.4) 473 0 R (section.5) 474 0 R (section.6) 475 0 R (section.7) 476 0 R (subsection.2.1) 477 0 R (subsection.2.2) 478 0 R ] >>\nendobj\n85 0 obj\n<< /Limits [ (subsection.2.3) (subsection.3.5) ] /Names [ (subsection.2.3) 479 0 R (subsection.3.1) 480 0 R (subsection.3.2) 481 0 R (subsection.3.3) 482 0 R (subsection.3.4) 483 0 R (subsection.3.5) 484 0 R ] >>\nendobj\n86 0 obj\n<< /Limits [ (subsection.3.6) (subsection.A.1) ] /Names [ (subsection.3.6) 485 0 R (subsection.3.7) 486 0 R (subsection.4.1) 487 0 R (subsection.4.2) 488 0 R (subsection.4.3) 489 0 R (subsection.A.1) 490 0 R ] >>\nendobj\n87 0 obj\n<< /Limits [ (subsection.A.2) (subsection.B.3) ] /Names [ (subsection.A.2) 491 0 R (subsection.B.1) 492 0 R (subsection.B.2) 493 0 R (subsection.B.3) 494 0 R ] >>\nendobj\n88 0 obj\n<< /BaseFont /FYGEPU+CMR7 /FirstChar 49 /FontDescriptor 495 0 R /LastChar 50 /Subtype /Type1 /ToUnicode 496 0 R /Type /Font /Widths 497 0 R >>\nendobj\n89 0 obj\n<< /BaseFont /SRDPYF+CMMI7 /FirstChar 59 /FontDescriptor 498 0 R /LastChar 59 /Subtype /Type1 /ToUnicode 499 0 R /Type /Font /Widths 500 0 R >>\nendobj\n90 0 obj\n<< /BaseFont /XVDDFF+SFTT1000 /Encoding 501 0 R /FirstChar 45 /FontDescriptor 502 0 R /LastChar 121 /Subtype /Type1 /ToUnicode 503 0 R /Type /Font /Widths 504 0 R >>\nendobj\n91 0 obj\n<< /BaseFont /OBHAAA+NimbusRomNo9L-Medi /Encoding 505 0 R /FirstChar 2 /FontDescriptor 506 0 R /LastChar 150 /Subtype /Type1 /ToUnicode 507 0 R /Type /Font /Widths 508 0 R >>\nendobj\n92 0 obj\n<< /BaseFont /SOVQXF+NimbusRomNo9L-Regu /Encoding 505 0 R /FirstChar 2 /FontDescriptor 509 0 R /LastChar 243 /Subtype /Type1 /ToUnicode 510 0 R /Type /Font /Widths 511 0 R >>\nendobj\n93 0 obj\n<< /BaseFont /OVRDOR+NimbusRomNo9L-ReguItal /Encoding 505 0 R /FirstChar 2 /FontDescriptor 512 0 R /LastChar 122 /Subtype /Type1 /ToUnicode 513 0 R /Type /Font /Widths 514 0 R >>\nendobj\n94 0 obj\n<< /BaseFont /Times-Roman /Encoding /WinAnsiEncoding /Subtype /Type1 /Type /Font >>\nendobj\n95 0 obj\n<< /D (section.2) /S /GoTo >>\nendobj\n96 0 obj\n<< /A 515 0 R /Next 516 0 R /Parent 34 0 R /Title 517 0 R >>\nendobj\n97 0 obj\n<< /A 518 0 R /Parent 34 0 R /Prev 516 0 R /Title 519 0 R >>\nendobj\n98 0 obj\n<< /A 520 0 R /Count -7 /First 521 0 R /Last 522 0 R /Next 523 0 R /Parent 6 0 R /Prev 34 0 R /Title 524 0 R >>\nendobj\n99 0 obj\nendobj\n100 0 obj\n<< /D (subsection.B.1) /S /GoTo >>\nendobj\n101 0 obj\n<< /A 525 0 R /Next 38 0 R /Parent 11 0 R /Prev 37 0 R /Title 526 0 R >>\nendobj\n102 0 obj\nendobj\n103 0 obj\n<< /D (subsection.B.3) /S /GoTo >>\nendobj\n104 0 obj\nendobj\n105 0 obj\n<< /D (appendix.A) /S /GoTo >>\nendobj\n106 0 obj\n<< /A 527 0 R /Next 107 0 R /Parent 39 0 R /Title 528 0 R >>\nendobj\n107 0 obj\n<< /A 529 0 R /Parent 39 0 R /Prev 106 0 R /Title 530 0 R >>\nendobj\n108 0 obj\n<< /A 531 0 R /Next 39 0 R /Parent 6 0 R /Prev 532 0 R /Title 533 0 R >>\nendobj\n109 0 obj\nendobj\n110 0 obj\n<< /A << /D (cite.grandview2025llm) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 406.173 676.214 418.128 685.061 ] /Subtype /Link /Type /Annot >>\nendobj\n111 0 obj\n<< /A << /D (cite.yadav2025ai) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 387.756 665.305 399.712 674.152 ] /Subtype /Link /Type /Annot >>\nendobj\n112 0 obj\n<< /A << /D (cite.morganstanley2025genai) /S /GoTo >> /Border [ 0 0 1 ] /C [ 0 1 0 ] /H /I /Rect [ 177.2 621.669 189.155 630.515 ] /Subtype /Link /Type /Annot >>\nendobj\n113 0 obj\n<< /A << /D (section.2) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 142.166 570.496 149.109 581.509 ] /Subtype /Link /Type /Annot >>\nendobj\n114 0 obj\n<< /A << /D (section.3) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 215.166 570.496 222.11 581.509 ] /Subtype /Link /Type /Annot >>\nendobj\n115 0 obj\n<< /A << /D (section.4) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 310.082 570.496 317.026 581.509 ] /Subtype /Link /Type /Annot >>\nendobj\n116 0 obj\n<< /A << /D (section.5) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 449.053 548.678 455.927 559.582 ] /Subtype /Link /Type /Annot >>\nendobj\n117 0 obj\n<< /A << /D (section.6) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 179.974 527.233 186.963 537.763 ] /Subtype /Link /Type /Annot >>\nendobj\n118 0 obj\n<< /A << /D (section.7) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 353.331 527.233 360.32 537.763 ] /Subtype /Link /Type /Annot >>\nendobj\n119 0 obj\n<< /A << /D (appendix.B) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 298.733 505.041 307.371 515.945 ] /Subtype /Link /Type /Annot >>\nendobj\n120 0 obj\n<< /A << /D (appendix.A) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 326.41 362.868 335.452 373.772 ] /Subtype /Link /Type /Annot >>\nendobj\n121 0 obj\n<< /A << /D (Item.3) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 234.036 129.006 248.203 139.885 ] /Subtype /Link /Type /Annot >>\nendobj\n122 0 obj\n<< /A << /D (Item.5) /S /GoTo >> /Border [ 0 0 1 ] /C [ 1 0 0 ] /H /I /Rect [ 251.192 129.006 265.359 139.885 ] /Subtype /Link /Type /Annot >>\nendobj\n123 0 obj\n<< /Filter /FlateDecode /Length 3651 >>\nstream\nx\u0695ZK\ufffd\ufffd6\ufffd\ufffdW\ufffdh+\"\ufffdNNd\ufffd\ufffd\ufffd,`f3\ufffdI\ufffdD\ufffdJd\ufffd+J\ufffd\ufffd\ufffd\ufffd[\ufffd*R\ufffd\ufffd`\nS_U\ufffd\ufffd\ufffd\ufffd:\u069dw\ufffd\ufffd\ufffdD\ufffd\ufffd\ufffdo\ufffd\ufffd\ufffdHweXf2\ufffd}8\ufffdDE\ufffd\ufffdvb'\ufffdb\ufffd\ufffd(\ufffd\ufffd|\ufffd\ufffd\ufffd\ufffd{\ufffd\ufffd\ufffdA&E\ufffd\u65f7\ufffdP}s\ufffd~\ufffd\ufffdX\ufffd\ne\ufffdo\ufffdn\ufffd\"YW\ufffd^\ufffd+u7J\ufffd\ufffd^54z\ufffdW\ufffd\ufffdy/\ufffd@\ufffd\"\ufffd\ufffdU\ufffd^\ufffd\ufffdW|\ufffd\ufffd(\ufffd\ufffd\u02a3\ufffd\ufffd6\ufffd^\ufffd\ufffd5\ufffd\ufffdg\ufffd\ufffd\ufffdf\ufffd\ufffdgZe\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdEaYxRfe\nY\ufffd\ufffdg\u056b\ufffd\ufffdZ=\ufffd\ufffdT\ufffd\ufffd!\ufffd\ufffd\ufffd\u00e5\ufffd\ufffd7\ufffd`\ufffd\ufffd=\ufffdg:\ufffdC\ufffd:e\ufffd4J\ufffd\u0406\ufffdUK\ufffd\u341e\ufffd\ufffd\ufffd\ufffdPR\ufffd\ufffd\ufffd\ufffd44\ufffd\ufffd\ufffd\ufffd2\ufffd\ufffdz\ufffd\ufffd\ufffd\ufffd>\ufffde W\ufffd% w\u068b(\ufffd\ufffd gH<@\ufffdR\ufffd$h\ufffdo\ufffd\ufffdN\ufffd\ufffd0\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdW\ufffdG=Ux\ufffd\ufffd5\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd}8\ufffdI\ufffd2>^\ufffdN\ufffdn\ufffdk5\ufffd\ufffd\ufffdQ\ufffd\ufffdg\\\ufffd\ufffd\ufffdAY\ufffd \u0182\ufffd\ufffd\ufffdJ_\ufffd<cAr\ufffd`\ufffd\ufffd\ufffdj\ufffdZ\ufffd\u9c42\ufffd\u069an\ufffd\ufffd\ufffd\ufffdd\ufffd\ufffde_\ufffd\ufffd\ufffd\ufffdk5\ufffdK\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdD\ufffd4\u030e=5[\ufffd\ufffd\ufffdL\ufffd\ufffd\ufffdN\ufffd\ufffdK\ufffd<Y\ufffd:\ufffd\u0336B$F\ufffdr5\ufffdw\ufffd\ufffd2b\ufffd\ufffdVq\ufffd\ufffd\ufffd+Hc\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdWK\ufffd\ufffdI\ufffd\ufffdb,N\ufffd\ufffd3nu7\ufffd\n5\ufffd\ufffd4Vz\ufffdz\ufffdG\ufffdgvEc7\ufffd\ufffdH\ufffd \u034d\"RV\ufffd\ufffd\ufffd\ufffd\u02adWU\ufffd\ufffdZ\ufffd&\ufffd\ufffd\ufffdx}\ufffd\\\ufffd\ufffd\ufffd0N\ufffd\ufffdq\ufffd\ufffdk\ufffdB\ufffdk\ufffd.\":\ufffd\ufffd\ufffd\u06b4\ufffd\u056d\ufffdkT\u0577\ufffd#\\\ufffd\ufffdaRJZ\ufffdE)\ufffd!\ufffdk\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd~\ufffdY\ufffd)j]\ufffd\nA\ufffd\ufffdV\ufffd\ufffdZ\ufffd&\ufffdU\ufffdf\ufffd\u00cd\ufffd%\ufffd \ufffd\ufffd\ufffd\ufffd\ufffdx#\ufffdf\ufffdjye?=r\ufffd$ \ufffd\"&\ufffd\\tJ\ufffd\ufffd\ufffd\ufffd\u05a8\ufffd]Wj\ufffd+\n\ufffda\ufffd\ufffd'\ufffd\ufffd\ufffd\ufffd\ufffdh!NiP\ufffd\ufffdt\ufffd\ufffd\ufffd\ufffdl(8\ufffd\u0200o\ufffd\ufffdO\ufffdM\ufffd\ufffdY\ufffdf\ufffdjZ\ufffd\ufffd\ufffd\nbqfyB\ufffd\ufffd\ufffd\ufffd\ufffd\\kw1\ufffdD\ufffdK\ufffd~+7\ufffd\ufffd\ufffd\ufffdA\ufffd\ufffds7A \ufffda\ufffd\u07aa\ufffd#2f0\ufffd\ufffd\ufffdi\ufffd\ufffdv\ufffd\ufffdpk\ufffdiz1\ufffd\ufffd:\ngS\ufffdR';\ufffd\ufffd)\ufffd\ufffd> >d\ufffd\ufffdeR\ufffdy\ufffd\ufffd\ufffd\ufffd[\ufffd\ufffd(\ufffd 5\u040b45?\ufffd1\ufffd?\ufffd\ufffd*kgQ\ufffdyF\u02fc\ufffd)\ufffdY\ufffd)s\ufffda\ufffd\ufffd^\ufffdp\ufffdU=\ufffd{\ufffd\ufffdo\ufffd\ufffdpm{\ufffd!~\ufffd\ufffd\ufffdkn\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd#&qc-\ufffdu\ufffd\ufffdXu\ufffdh\ufffd\ufffd\ufffd\ufffdP\ufffd \ufffd%8j\ufffdP\ufffd\ufffd\ufffd\ufffdN\ufffd39\ufffd\ufffd1\ufffd\ufffd\ufffd-\ufffd\ufffd\ufffdA\n<\\mg5m^\ufffd\ufffd\ufffd%7\ufffdD\u0390%7\u03ac\ufffd\ufffd\ufffd\ufffd\ufffd\\\ufffdy2\ufffdv\ufffdDm\ufffd\ufffd\ufffd"
    },
    {
      "url": "https://www.naiop.org/research-and-publications/magazine/2024/Winter-2024-2025/development-ownership/an-overview-of-state-data-center-related-tax-incentives/",
      "text": "Even before the advent of generative artificial intelligence (AI), policymakers were quickly discerning that their states\u2019 economic prosperity was linked to the ability of private businesses to store, use and process data. This first realization often came in conjunction with a second one \u2014 that states were falling behind projected levels of demand. According to CBRE, during the first quarter of 2024. The cost of space is still rising and vacancies are \u201cnegligible,\u201d according to an April report in The Wall Street Journal.\nDemand looks set to outstrip supply for the foreseeable future. The industry faces multiple constraints, including the scarcity of raw materials and labor, potential shortages of electricity and a formidable permitting process in many jurisdictions. Additionally, data centers are expected to deliver a larger range of distributed services. This is especially evident in the context of emerging technologies \u2014 such as those that power autonomous vehicles or so-called smart factories \u2014 that require low latency, large amounts of data and real-time responses. These requirements are difficult to satisfy in a centralized, cloud-based architecture. In the future, a data center network\u2019s geographical distribution \u2014 and not just its scale \u2014 will likely be a critical factor for the implementation of emerging technologies.\nOne of the most consequential tools to spur development involves taxes at the state level. Husch Blackwell\u2019s 50-state survey of data center tax incentives summarizes these various state-level initiatives and identifies key differentiating features that could affect the economic viability of projects.\nCurrently, 36 states have some kind of legislation authorizing tax incentives for new data center development. Some states have been using data center tax incentives for over a decade, but the approach has gathered momentum, especially since AI-related stories have captured the public\u2019s imagination.\nAs more states crafted legislation, significant variations emerged in how they address key issues, including:\nCertain ancillary issues \u2014 such as job creation thresholds or security mandates \u2014 appear highly prioritized by some states and unmentioned by others, demonstrating the divergent objectives and priorities.\nWhile nearly all of the legislation included in the survey takes up similar concerns, there is no standard template for how incentives are structured. State laws of this kind are the products of idiosyncratic local conditions and personalities. A common temptation is to view the collection of state tax incentives along the political spectrum from \u201cred\u201d to \u201cblue,\u201d but that sometimes papers over policies that do not fit neatly into a comprehensive \u2014 or comprehensible \u2014 political point of view. Tax incentives for data centers defy many conventional political labels, and one can find supporters and detractors at all points along the political spectrum.\nEach state\u2019s policy must be viewed as a whole to appreciate how it might influence developments throughout the project\u2019s life cycle. A good place to start is the particulars of the incentive structure itself \u2014 the kinds of exemptions included and their duration. Some states have been explicit in limiting the period of time that incentives run, usually ranging from 10 to 50 years. Additionally, the duration can flex depending on the nature of the investment. Larger investments sometimes get a longer runway, and new facilities sometimes get the benefit of a longer period than improvements to existing facilities. Several states have not defined a sunset date on incentives.\nJust as important as the duration of the incentives is what they purport to cover. Most states have bundled exemptions, and it is important to appreciate what is in the bundle and what is excluded from state to state. Even within the same state, different items qualify for different kinds of exemptions. In Georgia, for example, the purchase and use of high-technology data center equipment to be incorporated or used in a high-technology data center are exempt from state and local sales and use tax; however, the state\u2019s sales and use tax exemptions are subject to different subsections of the law and have different triggers.\nThe investment thresholds from state to state also offer interesting points of differentiation. Some states have a single threshold level that is applied to all projects; others have tiered levels that tie back to a range of factors, including lower levels for rural areas or new construction, and levels that differ according to the type of investment made. All of these variables should receive the careful attention of tax incentive counsel at the earliest possible point in the project timeline.\nWith so much scrutiny aimed at tax incentives generally, it is not surprising to see the presence of requirements baked into legislation that mandate certain community benefits. Of note, several states have specific job-creation thresholds for qualifying projects, and as with other provisions, these vary greatly. Like the investment thresholds, the job-creation requirements are sometimes tied to other provisions. For instance, Nevada\u2019s legislation requires 10 new jobs to qualify for the 10-year abatement; however, the 20-year abatement requires 50 jobs. Additionally, some states require that jobs created cannot be subject to workforce reductions for a specific time period.\nThese might seem like modest requirements, but data centers \u2014 even large ones \u2014 do not require a large workforce to operate. When job-creation requirements are tied to the operation of data centers rather than their construction, the requirements might be hard to meet.\nAdditionally, provisions often target not just the number of jobs but a variety of other metrics. These typically include mandated salary/wage levels (many use county or state averages as benchmarks), mandated health insurance coverage levels, and requirements that enterprises use state residents for the construction of projects.\nOther tax incentive-related mandates selectively put into place by states \u2014 almost appearing as legislative afterthoughts \u2014 could have a significant impact on projects. For instance, Illinois requires data centers to become carbon neutral within two years after being placed into service. Minnesota defines qualified facilities as having \u201csophisticated\u201d fire suppression systems and \u201cenhanced\u201d security. Some of these ancillary requirements are negligible to the overall cost structure, but some are material or, at the least, undefined in terms of cost. Project developers and investors should be careful not to overlook their impact.\nThe presence of data center-specific tax incentives can be an opportunity for improving a project\u2019s cost structure, but misconstruing key provisions of tax incentive legislation can have damaging consequences after capital has been committed and shovels are in the ground. Additionally, it is important to confirm with localities the presence of general incentives that can also apply to data center projects.\nHusch Blackwell\u2019s 50-state survey is a starting point and a useful reference tool, but it is just a snapshot in time. Priorities \u2014 and the laws that aim to reflect the same \u2014 change over time.\nJake Remington and Rod Carter are partners at the law firm Husch Blackwell."
    },
    {
      "url": "https://www.whitehouse.gov/presidential-actions/2025/07/accelerating-federal-permitting-of-data-center-infrastructure/",
      "text": "By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered:\nSection 1. Policy and Purpose. My Administration has inaugurated a golden age for American manufacturing and technological dominance. We will pursue bold, large-scale industrial plans to vault the United States further into the lead on critical manufacturing processes and technologies that are essential to national security, economic prosperity, and scientific leadership. These plans include artificial intelligence (AI) data centers and infrastructure that powers them, including high\u2011voltage transmission lines and other equipment. It will be a priority of my Administration to facilitate the rapid and efficient buildout of this infrastructure by easing Federal regulatory burdens.\nIn addition, my Administration will utilize federally owned land and resources for the expeditious and orderly development of data centers. This usage will be done in a manner consistent with the land\u2019s intended purpose \u2014 to be used in service of the prosperity and security of the American people.\nSec. 2. Definitions. For purposes of this order:\n(a) \u201cData Center Project\u201d means a facility that requires greater than 100 megawatts (MW) of new load dedicated to AI inference, training, simulation, or synthetic data generation.\n(b) \u201cCovered Components\u201d means materials, products, and infrastructure that are required to build Data Center Projects or otherwise upon which Data Center Projects depend, including:\n(i) energy infrastructure, such as transmission lines, natural gas pipelines or laterals, substations, switchyards, transformers, switchgear, and system protective facilities;\n(ii) natural gas turbines, coal power equipment, nuclear power equipment, geothermal power equipment, and any other dispatchable baseload energy sources, including electrical infrastructure (including backup power supply) constructed or otherwise used principally to serve a Data Center Project;\n(iii) semiconductors and semiconductor materials, such as wafers, dies, and packaged integrated circuits;\n(iv) networking equipment, such as switches and routers; and\n(v) data storage, such as hardware storage systems, software for data management and protection, and integrated services that work with public cloud providers.\n(c) \u201cCovered Component Project\u201d means infrastructure comprising Covered Components, or a facility with the primary purposes of manufacturing or otherwise producing Covered Components.\n(d) \u201cQualifying Project\u201d means:\n(i) a Data Center Project or Covered Component Project for which the Project Sponsor has committed at least $500 million in capital expenditures as determined by the Secretary of Commerce;\n(ii) a Data Center Project or Covered Component Project involving an incremental electric load addition of greater than 100 MW;\n(iii) a Data Center Project or Covered Component Project that protects national security; or\n(iv) a Data Center Project or Covered Component Project that has otherwise been designated by the Secretary of Defense, the Secretary of the Interior, the Secretary of Commerce, or the Secretary of Energy as a \u201cQualifying Project\u201d.\n(e) \u201cProject Sponsor\u201d means the lead sponsor providing financial and other support for a Data Center Project or Covered Component Project, as determined by the Secretary of Defense, the Secretary of the Interior, the Secretary of Commerce, or the Secretary of Energy, as appropriate.\n(f) \u201cSuperfund Site\u201d means any site where action is being taken pursuant to 42 U.S.C. 9604, 9606, or 9620.\n(g) \u201cBrownfield Site\u201d means a site as defined in 42 U.S.C. 9601(39).\nSec. 3. Encouraging Qualifying Projects. The Secretary of Commerce, in consultation with the Director of the Office of Science and Technology Policy (OSTP) and other relevant executive departments and agencies (agencies), shall launch an initiative to provide financial support for Qualifying Projects, which could include loans and loan guarantees, grants, tax incentives, and offtake agreements. All relevant agencies shall identify and submit to the Director of OSTP any such relevant existing financial support that can be used to assist Qualifying Projects, consistent with the protection of national security.\nSec. 4. Revocation of Executive Order 14141. Executive Order 14141 of January 14, 2025 (Advancing United States Leadership in Artificial Intelligence Infrastructure), is hereby revoked.\nSec. 5. Efficient Environmental Reviews. (a) Within 10 days of the date of this order, each relevant agency shall identify to the Council on Environmental Quality any categorical exclusions already established or adopted by such agency pursuant to the National Environmental Policy Act (NEPA), reliance on and adoption of which by agencies (pursuant to 42 U.S.C. 4336 and 4336c) could facilitate the construction of Qualifying Projects.\n(b) The Council on Environmental Quality shall coordinate with relevant agencies on the establishment of new categorical exclusions to cover actions related to Qualifying Projects that normally do not have a significant effect on the human environment. Agencies shall, for purposes of establishing these categorical exclusions, rely on any sufficient basis to do so as each such agency determines.\n(c) Consistent with 42 U.S.C. 4336e(10)(B)(iii), loans, loan guarantees, grants, tax incentives, or other forms of Federal financial assistance for which an agency lacks substantial project-specific control and responsibility over the subsequent use of such financial assistance shall not be considered a \u201cmajor Federal action\u201d under NEPA. For purposes of this order, Federal financial assistance representing less than 50 percent of total project costs shall be presumed not to constitute substantial Federal control and responsibility.\nSec. 6. Efficiency and Transparency Through FAST\u201141. (a) The Executive Director (Executive Director) of the Federal Permitting Improvement Steering Council (FPISC) may, within 30 days of the date that a project is identified to FPISC by a relevant agency, designate a Qualifying Project as a transparency project pursuant to 42 U.S.C. 4370m-2(b)(2)(A)(iii) and section 41003 of the Fixing America\u2019s Surface Transportation Act (Public Law 114-94, 129 Stat. 1312, 1747) (FAST-41). Within 30 days of receiving such agency notification, the Executive Director may publish Qualifying Projects on the Permitting Dashboard established under section 41003(b) of FAST-41, including schedules for expedited review.\n(b) In consultation with Project Sponsors, the Executive Director shall expedite the transition of eligible Qualifying Projects from transparency projects to FAST-41 \u201ccovered projects\u201d as defined by 42 U.S.C. 4370m(6)(A). To the extent that a Qualifying Project does not meet the criteria set forth in 42 U.S.C. 4370m(6)(A)(i) or (iii), FPISC may consider all other available options to designate the project a covered project under 42 U.S.C. 4370m(6)(A)(iv).\nSec. 7. Streamlining of Permitting Review. (a) The Administrator of the Environmental Protection Agency shall assist in expediting permitting on Federal and non-Federal lands by developing or modifying regulations promulgated under the Clean Air Act (42 U.S.C. 7401 et seq.); the Clean Water Act (33 U.S.C. 1251 et seq.); the Comprehensive Environmental Response, Compensation, and Liability Act (42 U.S.C. 9601 et seq.); the Toxic Substances Control Act (15 U.S.C. 2601 et seq.); and other relevant applicable laws, in each case, that impact the development of Qualifying Projects.\n(b) The Administrator of the Environmental Protection Agency shall, consistent with the Environmental Protection Agency\u2019s statutory authorities, expeditiously identify Brownfield Sites and Superfund Sites for use by Qualifying Projects. As part of this effort, within 180 days of the date of this order, the Administrator of the Environmental Protection Agency shall develop guidance to help expedite environmental reviews for qualified reuse and assist State governments and private parties to return such Brownfield Sites and Superfund Sites to productive use as expeditiously as possible.\nSec. 8. Biological and Water Permitting Efficiencies. (a) Upon identification of sites by the Secretary of the Interior and the Secretary of Energy as described in section 9 of this order, the action agency, as identified through the process described in the Endangered Species Act (16 U.S.C. 1531-1544) (ESA), shall initiate consultation under section 7 of the ESA with the Secretary of the Interior, the Secretary of Commerce, or both with respect to common construction activities for Qualifying Projects that will occur over the next 10 years at a programmatic level. The Secretary of the Interior and the Secretary of Commerce shall utilize programmatic consultation to ensure timely and efficient completion of such consultation.\n(b) Within 180 days of the date of this order, the Secretary of the Army, acting through the Assistant Secretary of the Army for Civil Works, shall review the nationwide permits issued under section 404 of the Clean Water Act of 1972 (33 U.S.C. 1344) and section 10 of the Rivers and Harbors Appropriation Act of 1899 (33 U.S.C. 403) to determine whether an activity-specific nationwide permit is needed to facilitate the efficient permitting of activities related to Qualifying Projects.\nSec. 9. Federal Lands Availability. (a) The Department of the Interior and the Department of Energy shall, after consultation with industry and further in consultation with the Department of Commerce as to the Project Sponsors to which relevant authorizations shall be granted, offer appropriate authorizations for sites identified by the Secretary of the Interior or the Secretary of Energy, as applicable and appropriate for the relevant uses, consistent with 42 U.S.C. 2201, 42 U.S.C. 7256, 43 U.S.C. 1701 et seq., and all other applicable law.\n(b) The Secretary of Defense shall, pursuant to 10 U.S.C. 2667 or other applicable law and as and when the Secretary of Defense deems it necessary or desirable, identify suitable sites on military installations for Covered Component infrastructure uses and competitively lease available lands for Qualifying Projects to support the Department of Defense\u2019s energy, workforce, and mission needs, subject to security and force protection considerations.\nSec. 10. General Provisions. (a) Nothing in this order shall be construed to impair or otherwise affect:\n(i) the authority granted by law to an executive department or agency, or the head thereof; or\n(ii) the functions of the Director of the Office of Management and Budget relating to budgetary, administrative, or legislative proposals.\n(b) This order shall be implemented consistent with applicable law and subject to the availability of appropriations.\n(c) This order is not intended to, and does not, create any right or benefit, substantive or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person.\n(d) The costs for publication of this order shall be borne by the Department of Energy.\nDONALD J. TRUMP\nTHE WHITE HOUSE,\nJuly 23, 2025."
    }
  ],
  "argos_summary": "OpenAI CEO Sam Altman recently expressed skepticism about the term 'Artificial General Intelligence' (AGI), suggesting it has become less useful as AI capabilities rapidly evolve. In a CNBC interview, he emphasized the importance of focusing on the continuous improvement of AI models rather than the elusive goal of AGI. This shift in perspective comes amid criticism of OpenAI's latest model, GPT-5, which some users found underwhelming compared to expectations. Altman acknowledged the need for OpenAI to prioritize growth and investment in AI development, even at the cost of profitability.",
  "argos_id": "EDC5HJLLA"
}