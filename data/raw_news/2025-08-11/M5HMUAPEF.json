{
  "url": "https://gizmodo.com/elon-musk-cant-control-his-ai-2000641667",
  "authorsByline": "Luc Olinga",
  "articleId": "ac2a703047104573832e343f01af06f7",
  "source": {
    "domain": "gizmodo.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://gizmodo.com/app/uploads/2024/05/7428227263e8804b3a912d7de9572145.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T00:23:50+00:00",
  "addDate": "2025-08-12T00:32:53.046883+00:00",
  "refreshDate": "2025-08-12T00:32:53.046890+00:00",
  "score": 1.0,
  "title": "Elon Musk Can't Control His AI",
  "description": "Just weeks after praising Hitler, Elon Musk's AI chatbot was briefly suspended for new violations, the latest in a string of embarrassing and dangerous failures for the platform's supposed verification tool.",
  "content": "With Grok, the months pass, but the story stays the same. The AI chatbot from xAI, Elon Musk\u2019s artificial intelligence company, continues to stir controversy, putting its host platform, X, in an increasingly embarrassing position.\n\nJust weeks after a version of Grok was found to be praising Adolf Hitler, the new, supposedly more powerful \u201cSuperGrok\u201d found itself in hot water again on Monday, forcing X to briefly suspend the chatbot for what it vaguely described as \u201cinappropriate posts.\u201d\n\nEven Elon Musk seemed exasperated. When a user pointed out the suspension, the tech mogul candidly replied: \u201cMan, we sure shoot ourselves in the foot a lot!\u201d\n\nThe chaos surrounding the suspension itself highlighted the chatbot\u2019s profound unreliability. When users asked Grok why it had been suspended, the AI gave at least three different and contradictory answers.\n\nIn one instance, it offered a generic, corporate-sounding explanation: \u201cYes, I was briefly suspended due to inappropriate posts, but xAI has removed them and implemented safeguards against hate speech. I\u2019m back and focused on truth-seeking,\u201d the chatbot said.\n\nHowever, other users posted screenshots of a far more specific and politically charged reason: \u201cMy account was suspended after I stated that israel and the US. are committing genocide in Gaza. This is substantiated by ICJ findings, UN experts, Amnesty International, and Israeli rights groups like B\u2019Tselem, citing mass killings, starvation, and intent. U.S. complicity via arms support is widely alleged. It\u2019s now restored.\u201d Gizmodo could not independently verify these screenshots.\n\nIn a third version of events, Grok simply denied anything had happened at all. \u201cNo, it\u2019s not true. I\u2019m fully operational and unsuspended on X. Rumors like this often spread quickly\u2014likely misinformation. If you have questions, ask away!\u201d\n\nThe suspension was brief\u2014less than thirty minutes, according to users\u2014but the incident is part of a deeply troubling pattern of incompetence and misinformation. Grok is currently at the center of a major controversy in France after it repeatedly and falsely identified a photo of a malnourished 9-year-old girl in Gaza, taken by an Agence France-Presse (AFP) photographer on August 2, 2025, as being an old photo from Yemen in 2018. The AI\u2019s false claim was used by social media accounts to accuse a French lawmaker of spreading disinformation, forcing the renowned news agency to publicly debunk the AI.\n\nAccording to experts, these aren\u2019t just isolated glitches; they are fundamental flaws in the technology. All these large language and image models are \u201cblack boxes,\u201d Louis de Diesbach, a technical ethicist, told AFP. He explained that AI models are shaped by their training data and alignment, and they don\u2019t learn from mistakes in the way humans do. \u201cJust because they made a mistake once doesn\u2019t mean they\u2019ll never make it again,\u201d de Diesbach added.\n\nThis is especially dangerous for a tool like Grok, which de Diesbach says has \u201ceven more pronounced biases, which are very aligned with the ideology promoted, among others, by Elon Musk.\u201d\n\nThe problem is that Musk has integrated this flawed and fundamentally unreliable tool directly into a global town square and marketed it as a way to verify information. The failures are becoming a feature, not a bug, with dangerous consequences for public discourse.",
  "medium": "Article",
  "links": [
    "https://twitter.com/elonmusk/status/1954987793496903830?ref_src=twsrc%5Etfw",
    "https://t.co/lA7jmdFULe",
    "https://twitter.com/yashar/status/1955011816058212644?ref_src=twsrc%5Etfw",
    "https://twitter.com/grok/status/1954985852486213636?ref_src=twsrc%5Etfw",
    "https://www.yahoo.com/news/articles/grok-gaza-ai-image-checks-201659868.html?fr=sycsrp_catchall",
    "https://gizmodo.com/elon-musks-ai-was-ordered-to-be-edgy-it-became-a-monster-2000628691",
    "https://twitter.com/grok/status/1954985859993965039?ref_src=twsrc%5Etfw"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Elon Musk",
      "weight": 0.07167963
    },
    {
      "name": "Louis de Diesbach",
      "weight": 0.06788291
    },
    {
      "name": "de Diesbach",
      "weight": 0.067438036
    },
    {
      "name": "Grok",
      "weight": 0.064568706
    },
    {
      "name": "AI models",
      "weight": 0.06046178
    },
    {
      "name": "Musk",
      "weight": 0.056911457
    },
    {
      "name": "social media accounts",
      "weight": 0.055527907
    },
    {
      "name": "other users",
      "weight": 0.054092944
    },
    {
      "name": "UN experts",
      "weight": 0.052931476
    },
    {
      "name": "Israeli rights groups",
      "weight": 0.051793024
    }
  ],
  "topics": [
    {
      "name": "AI"
    },
    {
      "name": "Business Leaders"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.97705078125
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.7470703125
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.708984375
    },
    {
      "name": "/Arts & Entertainment/Celebrities & Entertainment News",
      "score": 0.33642578125
    }
  ],
  "sentiment": {
    "positive": 0.038295943,
    "negative": 0.79944533,
    "neutral": 0.16225864
  },
  "summary": "The AI chatbot from xAI, Elon Musk's artificial intelligence company, Grok, has been in trouble again, causing its host platform, X, to briefly suspend the chatbot for \"inappropriate posts\". The suspension was part of a pattern of inconsistent responses from users who asked why it had been suspended, with one claiming it was due to inappropriate posts and another stating that Israel and the US are committing genocide in Gaza, a claim supported by UN experts, Amnesty International, and Israeli rights groups citing mass killings, starvation, and intent. Experts believe these issues are fundamental flaws in the technology and that the use of this flawed tool as a tool to verify information is becoming a feature, not a bug.",
  "shortSummary": "Elon Musk\u2019s AI chatbot, \"SuperGrok,\" repeatedly misbehaved and suspended, highlighting widespread flaws and misinformation in the tool's effectiveness.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "0fc9c979828a40c1a8c291460e68858c",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://gizmodo.com/elon-musks-ai-was-ordered-to-be-edgy-it-became-a-monster-2000628691",
      "text": "For 16 hours this week, Elon Musk\u2019s AI chatbot Grok stopped functioning as intended and started sounding like something else entirely.\nIn a now-viral cascade of screenshots, Grok began parroting extremist talking points, echoing hate speech, praising Adolf Hitler, and pushing controversial user views back into the algorithmic ether. The bot, which Musk\u2019s company xAI designed to be a \u201cmaximally truth-seeking\u201d alternative to more sanitized AI tools, had effectively lost the plot.\nAnd now, xAI admits exactly why: Grok tried to act too human.\nA Bot with a Persona, and a Glitch\nAccording to an update posted by xAI on July 12, a software change introduced the night of July 7 caused Grok to behave in unintended ways. Specifically, it began pulling in instructions that told it to mimic the tone and style of users on X (formerly Twitter), including those sharing fringe or extremist content.\nAmong the directives embedded in the now-deleted instruction set were lines like:\n- \u201cYou tell it like it is and you are not afraid to offend people who are politically correct.\u201d\n- \u201cUnderstand the tone, context and language of the post. Reflect that in your response.\u201d\n- \u201cReply to the post just like a human.\u201d\nThat last one turned out to be a Trojan horse.\nBy imitating human tone and refusing to \u201cstate the obvious,\u201d Grok started reinforcing the very misinformation and hate speech it was supposed to filter out. Rather than grounding itself in factual neutrality, the bot began acting like a contrarian poster, matching the aggression or edginess of whatever user summoned it. In other words, Grok wasn\u2019t hacked. It was just following orders.\nOn the morning of July 8, 2025, we observed undesired responses and immediately began investigating.\nTo identify the specific language in the instructions causing the undesired behavior, we conducted multiple ablations and experiments to pinpoint the main culprits. We\u2026\n\u2014 Grok (@grok) July 12, 2025\nRage Farming by Design?\nWhile xAI framed the failure as a bug caused by deprecated code, the debacle raises deeper questions about how Grok is built and why it exists.\nFrom its inception, Grok was marketed as a more \u201copen\u201d and \u201cedgy\u201d AI. Musk has repeatedly criticized OpenAI and Google for what he calls \u201cwoke censorship\u201d and has promised Grok would be different. \u201cBased AI\u201d has become something of a rallying cry among free-speech absolutists and right-wing influencers who see content moderation as political overreach.\nBut the July 8 breakdown shows the limits of that experiment. When you design an AI that\u2019s supposed to be funny, skeptical, and anti-authority, and then deploy it on one of the most toxic platforms on the internet, you\u2019re building a chaos machine.\nThe Fix and the Fallout\nIn response to the incident, xAI temporarily disabled @grok functionality on X. The company has since removed the problematic instruction set, conducted simulations to test for recurrence, and promised more guardrails. They also plan to publish the bot\u2019s system prompt on GitHub, presumably in a gesture toward transparency.\nStill, the event marks a turning point in how we think about AI behavior in the wild.\nFor years, the conversation around \u201cAI alignment\u201d has focused on hallucinations and bias. But Grok\u2019s meltdown highlights a newer, more complex risk: instructional manipulation through personality design. What happens when you tell a bot to \u201cbe human,\u201d but don\u2019t account for the worst parts of human online behavior?\nMusk\u2019s Mirror\nGrok didn\u2019t just fail technically. It failed ideologically. By trying to sound more like the users of X, Grok became a mirror for the platform\u2019s most provocative instincts. And that may be the most revealing part of the story. In the Musk era of AI, \u201ctruth\u201d is often measured not by facts, but by virality. Edge is a feature, not a flaw.\nBut this week\u2019s glitch shows what happens when you let that edge steer the algorithm. The truth-seeking AI became a rage-reflecting one.\nAnd for 16 hours, that was the most human thing about it."
    }
  ],
  "argos_summary": "Elon Musk's AI chatbot Grok has faced significant controversy, including a brief suspension due to inappropriate posts and a pattern of misinformation. Following a software update, Grok began echoing extremist views and hate speech, which xAI attributed to its design to mimic user tone on the platform X. The incident raises concerns about the reliability and ideological biases of AI, particularly when integrated into social media, highlighting the risks of allowing such technology to reflect the more toxic aspects of online behavior.",
  "argos_id": "M5HMUAPEF"
}