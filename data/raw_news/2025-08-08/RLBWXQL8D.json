{
  "url": "https://9to5mac.com/2025/08/07/apple-intelligence-gpt-5-chatgpt-integration/?extended-comments=1",
  "authorsByline": "Zac Hall",
  "articleId": "1c7cc4704cd548f184d16ff033023195",
  "source": {
    "domain": "9to5mac.com",
    "paywall": false,
    "location": null
  },
  "imageUrl": "https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/10/chatgpt-siri-ios182-3-2.jpg?resize=1200%2C628&quality=82&strip=all&ssl=1",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-08T03:32:59+00:00",
  "addDate": "2025-08-08T03:44:50.651289+00:00",
  "refreshDate": "2025-08-08T03:44:50.651291+00:00",
  "score": 1.0,
  "title": "Here's when ChatGPT integration within Apple Intelligence will use GPT-5",
  "description": "Earlier today, OpenAI announced GPT-5, its latest model to power ChatGPT. The new frontier model is a significant leap forward...",
  "content": "Earlier today, OpenAI announced GPT-5, its latest model to power ChatGPT. The new frontier model is a significant leap forward in a lot of areas. But when will ChatGPT integration within Apple Intelligence adopt it? That\u2019s actually happening rather soon\u2026\n\nUsing ChatGPT through Apple Intelligence is optional. If you allow Apple Intelligence to work with ChatGPT, it offers three things. These include:\n\u2022 Use Siri to access ChatGPT: Siri can tap into ChatGPT to provide answers when that might be helpful for certain requests including questions about photos and documents.\n\u2022 Use ChatGPT with Writing Tools: ChatGPT can compose text or images from just a description.\n\u2022 Use ChatGPT with visual intelligence: Use visual intelligence with Camera Control to quickly learn more about the places and objects around you.\n\nIn iOS 18, iPadOS 18, macOS Sequoia, and later visionOS 2, ChatGPT integration within Apple Intelligence is powered by OpenAI\u2019s GPT-4o model.\n\nFollowing today\u2019s reveal of OpenAI\u2019s latest model, Apple tells me that ChatGPT integration within Apple Intelligence will use GPT-5 with iOS 26, iPadOS 26, and macOS Tahoe 26.\n\nThose software updates are expected to arrive next month, meaning ChatGPT integration within Apple Intelligence will benefit from the new model soon.\n\nAs a reminder, Apple includes privacy protections for users accessing ChatGPT through Apple Intelligence. These include obscuring IP addresses and ensuring that OpenAI doesn\u2019t store requests. If you decide to connect your OpenAI account with Apple Intelligence, then OpenAI\u2019s data-use policy applies.\n\nIn iOS 26, Apple Intelligence is gaining new capabilities across the iPhone and beyond. That includes Live Translation, which can interpret conversations in FaceTime, Phone, and Messages in real time, and upgrades to Visual Intelligence, a systemwide tool for searching and interacting with content directly on the screen.\n\nApple is also opening up its on-device foundation model to developers, paving the way for smarter, more capable apps built on the same technology that powers Apple Intelligence.\n\nIn addition to GPT-5, OpenAI announced two open weight large language models, including one that runs on Apple silicon Macs, and changes to encourage healthier ChatGPT usage.",
  "medium": "Article",
  "links": [
    "https://www.apple.com/newsroom/2024/06/introducing-apple-intelligence-for-iphone-ipad-and-mac/?utm_source=chatgpt.com",
    "https://amzn.to/4mo59iQ",
    "https://amzn.to/3J4Baya",
    "https://9to5mac.com/2025/08/04/healthy-chatgpt-use/",
    "https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&gl=US&ceid=US:en",
    "https://www.apple.com/newsroom/2025/06/apple-intelligence-gets-even-more-powerful-with-new-capabilities-across-apple-devices/",
    "https://amzn.to/4m3rL8C",
    "https://amzn.to/4mn5Zgx",
    "https://9to5mac.com/2025/08/07/openai-gpt-5-chatgpt-announcement/",
    "https://9to5mac.com/2025/08/05/openai-open-weight-ai-models-mac/",
    "https://9to5mac.com/2025/08/06/how-to-run-gpt-oss-20b-on-mac/",
    "https://support.apple.com/guide/iphone/use-chatgpt-with-apple-intelligence-iph00fd3c8c2/ios"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Apple Intelligence",
      "weight": 0.13918106
    },
    {
      "name": "ChatGPT integration",
      "weight": 0.115528055
    },
    {
      "name": "Apple",
      "weight": 0.10832628
    },
    {
      "name": "Apple silicon Macs",
      "weight": 0.10589966
    },
    {
      "name": "ChatGPT",
      "weight": 0.10308019
    },
    {
      "name": "Visual Intelligence",
      "weight": 0.102150865
    },
    {
      "name": "healthier ChatGPT usage",
      "weight": 0.09890265
    },
    {
      "name": "OpenAI",
      "weight": 0.08234626
    },
    {
      "name": "OpenAI\u2019s latest model",
      "weight": 0.06605304
    },
    {
      "name": "OpenAI\u2019s GPT-4o model",
      "weight": 0.06286163
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.90380859375
    },
    {
      "name": "/Computers & Electronics/Software/Operating Systems",
      "score": 0.76318359375
    },
    {
      "name": "/Internet & Telecom/Mobile & Wireless/Mobile Apps & Add-Ons",
      "score": 0.51220703125
    },
    {
      "name": "/Internet & Telecom/Mobile & Wireless/Mobile Phones",
      "score": 0.4189453125
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.357421875
    }
  ],
  "sentiment": {
    "positive": 0.44604492,
    "negative": 0.07244873,
    "neutral": 0.48120117
  },
  "summary": "OpenAI has announced GPT-5, its latest model to power ChatGPT within Apple Intelligence, a significant leap forward in several areas. The new model will be used with iOS 26, iPadOS 26, and macOS Tahoe 26, expected to arrive next month. If users allow Apple Intelligence to work with Chat GPT, they will be able to use Siri to provide answers for certain requests such as photos and documents. Privacy protections for users accessing chatGPT through Apple Intelligence include obscuring IP addresses and ensuring that OpenAI does not store requests. Apple is also opening up its on-device foundation model to developers, paving the way for smarter, more capable apps built on the same technology that powers Apple Intelligence.",
  "shortSummary": "OpenAI\u2019s GPT-5 model will support ChatGPT integration within Apple Intelligence, enabling Siri to respond and enhance visual intelligence capabilities.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "a56dd309b1604cdf9d1ef6af7fd2e89e",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&gl=US&ceid=US:en",
      "text": "- EnglishUnited States\n- Deutsch\n- English\n- Espa\u00f1ol\n- Fran\u00e7ais\n- Italiano\n- Svenska\n- All languages\n- Afrikaans\n- az\u0259rbaycan\n- bosanski\n- catal\u00e0\n- \u010ce\u0161tina\n- Cymraeg\n- Dansk\n- Deutsch\n- eesti\n- EnglishUnited Kingdom\n- Espa\u00f1olEspa\u00f1a\n- Espa\u00f1olLatinoam\u00e9rica\n- euskara\n- Filipino\n- Fran\u00e7aisCanada\n- Fran\u00e7aisFrance\n- Gaeilge\n- galego\n- Hrvatski\n- Indonesia\n- isiZulu\n- \u00edslenska\n- Italiano\n- Kiswahili\n- latvie\u0161u\n- lietuvi\u0173\n- magyar\n- Melayu\n- Nederlands\n- norsk\n- o\u2018zbek\n- polski\n- Portugu\u00easBrasil\n- Portugu\u00easPortugal\n- rom\u00e2n\u0103\n- shqip\n- Sloven\u010dina\n- sloven\u0161\u010dina\n- srpski (latinica)\n- Suomi\n- Svenska\n- Ti\u1ebfng Vi\u1ec7t\n- T\u00fcrk\u00e7e\n- \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac\n- \u0431\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f\n- \u0431\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438\n- \u043a\u044b\u0440\u0433\u044b\u0437\u0447\u0430\n- \u049b\u0430\u0437\u0430\u049b \u0442\u0456\u043b\u0456\n- \u043c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438\n- \u043c\u043e\u043d\u0433\u043e\u043b\n- \u0420\u0443\u0441\u0441\u043a\u0438\u0439\n- \u0441\u0440\u043f\u0441\u043a\u0438\n- \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430\n- \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8\n- \u0570\u0561\u0575\u0565\u0580\u0565\u0576\n- \u05e2\u05d1\u05e8\u05d9\u05ea\n- \u0627\u0631\u062f\u0648\n- \u0627\u0644\u0639\u0631\u0628\u064a\u0629\n- \u0641\u0627\u0631\u0633\u06cc\n- \u12a0\u121b\u122d\u129b\n- \u0928\u0947\u092a\u093e\u0932\u0940\n- \u092e\u0930\u093e\u0920\u0940\n- \u0939\u093f\u0928\u094d\u0926\u0940\n- \u0985\u09b8\u09ae\u09c0\u09af\u09bc\u09be\n- \u09ac\u09be\u0982\u09b2\u09be\n- \u0a2a\u0a70\u0a1c\u0a3e\u0a2c\u0a40\n- \u0a97\u0ac1\u0a9c\u0ab0\u0abe\u0aa4\u0ac0\n- \u0b13\u0b21\u0b3c\u0b3f\u0b06\n- \u0ba4\u0bae\u0bbf\u0bb4\u0bcd\n- \u0c24\u0c46\u0c32\u0c41\u0c17\u0c41\n- \u0c95\u0ca8\u0ccd\u0ca8\u0ca1\n- \u0d2e\u0d32\u0d2f\u0d3e\u0d33\u0d02\n- \u0dc3\u0dd2\u0d82\u0dc4\u0dbd\n- \u0e44\u0e17\u0e22\n- \u0ea5\u0eb2\u0ea7\n- \u1019\u103c\u1014\u103a\u1019\u102c\n- \u1781\u17d2\u1798\u17c2\u179a\n- \ud55c\uad6d\uc5b4\n- \u65e5\u672c\u8a9e\n- \u7b80\u4f53\u4e2d\u6587\n- \u7e41\u9ad4\u4e2d\u6587\n- \u7e41\u9ad4\u4e2d\u6587\u9999\u6e2f\n- EnglishUnited States\n- Deutsch\n- English\n- Espa\u00f1ol\n- Fran\u00e7ais\n- Italiano\n- Svenska\n- All languages\n- Afrikaans\n- az\u0259rbaycan\n- bosanski\n- catal\u00e0\n- \u010ce\u0161tina\n- Cymraeg\n- Dansk\n- Deutsch\n- eesti\n- EnglishUnited Kingdom\n- Espa\u00f1olEspa\u00f1a\n- Espa\u00f1olLatinoam\u00e9rica\n- euskara\n- Filipino\n- Fran\u00e7aisCanada\n- Fran\u00e7aisFrance\n- Gaeilge\n- galego\n- Hrvatski\n- Indonesia\n- isiZulu\n- \u00edslenska\n- Italiano\n- Kiswahili\n- latvie\u0161u\n- lietuvi\u0173\n- magyar\n- Melayu\n- Nederlands\n- norsk\n- o\u2018zbek\n- polski\n- Portugu\u00easBrasil\n- Portugu\u00easPortugal\n- rom\u00e2n\u0103\n- shqip\n- Sloven\u010dina\n- sloven\u0161\u010dina\n- srpski (latinica)\n- Suomi\n- Svenska\n- Ti\u1ebfng Vi\u1ec7t\n- T\u00fcrk\u00e7e\n- \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac\n- \u0431\u0435\u043b\u0430\u0440\u0443\u0441\u043a\u0430\u044f\n- \u0431\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438\n- \u043a\u044b\u0440\u0433\u044b\u0437\u0447\u0430\n- \u049b\u0430\u0437\u0430\u049b \u0442\u0456\u043b\u0456\n- \u043c\u0430\u043a\u0435\u0434\u043e\u043d\u0441\u043a\u0438\n- \u043c\u043e\u043d\u0433\u043e\u043b\n- \u0420\u0443\u0441\u0441\u043a\u0438\u0439\n- \u0441\u0440\u043f\u0441\u043a\u0438\n- \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430\n- \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8\n- \u0570\u0561\u0575\u0565\u0580\u0565\u0576\n- \u05e2\u05d1\u05e8\u05d9\u05ea\n- \u0627\u0631\u062f\u0648\n- \u0627\u0644\u0639\u0631\u0628\u064a\u0629\n- \u0641\u0627\u0631\u0633\u06cc\n- \u12a0\u121b\u122d\u129b\n- \u0928\u0947\u092a\u093e\u0932\u0940\n- \u092e\u0930\u093e\u0920\u0940\n- \u0939\u093f\u0928\u094d\u0926\u0940\n- \u0985\u09b8\u09ae\u09c0\u09af\u09bc\u09be\n- \u09ac\u09be\u0982\u09b2\u09be\n- \u0a2a\u0a70\u0a1c\u0a3e\u0a2c\u0a40\n- \u0a97\u0ac1\u0a9c\u0ab0\u0abe\u0aa4\u0ac0\n- \u0b13\u0b21\u0b3c\u0b3f\u0b06\n- \u0ba4\u0bae\u0bbf\u0bb4\u0bcd\n- \u0c24\u0c46\u0c32\u0c41\u0c17\u0c41\n- \u0c95\u0ca8\u0ccd\u0ca8\u0ca1\n- \u0d2e\u0d32\u0d2f\u0d3e\u0d33\u0d02\n- \u0dc3\u0dd2\u0d82\u0dc4\u0dbd\n- \u0e44\u0e17\u0e22\n- \u0ea5\u0eb2\u0ea7\n- \u1019\u103c\u1014\u103a\u1019\u102c\n- \u1781\u17d2\u1798\u17c2\u179a\n- \ud55c\uad6d\uc5b4\n- \u65e5\u672c\u8a9e\n- \u7b80\u4f53\u4e2d\u6587\n- \u7e41\u9ad4\u4e2d\u6587\n- \u7e41\u9ad4\u4e2d\u6587\u9999\u6e2f\nBefore you continue to Google\nWe use cookies and data to\n- Deliver and maintain Google services\n- Track outages and protect against spam, fraud, and abuse\n- Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services\nIf you choose to \u201cAccept all,\u201d we will also use cookies and data to\n- Develop and improve new services\n- Deliver and measure the effectiveness of ads\n- Show personalized content, depending on your settings\n- Show personalized ads, depending on your settings\nIf you choose to \u201cReject all,\u201d we will not use cookies for these additional purposes.\nNon-personalized content is influenced by things like the content you\u2019re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you\u2019re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.\nSelect \u201cMore options\u201d to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time."
    },
    {
      "url": "https://www.apple.com/newsroom/2025/06/apple-intelligence-gets-even-more-powerful-with-new-capabilities-across-apple-devices/",
      "text": "PRESS RELEASE\nJune 9, 2025\nApple Intelligence gets even more powerful with new capabilities across Apple devices\nDevelopers can now access the Apple Intelligence on-device foundation model to power private, intelligent experiences within their apps\nCUPERTINO, CALIFORNIA Apple today announced new Apple Intelligence features that elevate the user experience across iPhone, iPad, Mac, Apple Watch, and Apple Vision Pro. Apple Intelligence unlocks new ways for users to communicate with features like Live Translation; do more with what\u2019s on their screen with updates to visual intelligence; and express themselves with enhancements to Image Playground and Genmoji.1 Additionally, Shortcuts can now tap into Apple Intelligence directly, and developers will be able to access the on-device large language model at the core of Apple Intelligence, giving them direct access to intelligence that is powerful, fast, built with privacy, and available even when users are offline. These Apple Intelligence features are available for testing starting today, and will be available to users with supported devices set to a supported language this fall.\n\u201cLast year, we took the first steps on a journey to bring users intelligence that\u2019s helpful, relevant, easy to use, and right where users need it, all while protecting their privacy. Now, the models that power Apple Intelligence are becoming more capable and efficient, and we\u2019re integrating features in even more places across each of our operating systems,\u201d said Craig Federighi, Apple\u2019s senior vice president of Software Engineering. \u201cWe\u2019re also taking the huge step of giving developers direct access to the on-device foundation model powering Apple Intelligence, allowing them to tap into intelligence that is powerful, fast, built with privacy, and available even when users are offline. We think this will ignite a whole new wave of intelligent experiences in the apps users rely on every day. We can\u2019t wait to see what developers create.\u201d\nApple Intelligence features will be coming to eight more languages by the end of the year: Danish, Dutch, Norwegian, Portuguese (Portugal), Swedish, Turkish, Chinese (traditional), and Vietnamese.\nLive Translation Breaks Down Language Barriers\nFor those moments when a language barrier gets in the way, Live Translation can help users communicate across languages when messaging or speaking. The experience is integrated into Messages, FaceTime, and Phone, and enabled by Apple-built models that run entirely on device, so users\u2019 personal conversations stay personal.\nIn Messages, Live Translation can automatically translate messages. If a user is making plans with new friends while traveling abroad, their message can be translated as they type, delivered in the recipient\u2019s preferred language, and when they get a response, each message can be instantly translated.2 On FaceTime calls, a user can follow along with translated live captions while still hearing the speaker\u2019s voice. And when on a phone call, the translation is spoken aloud throughout the conversation.3\nNews Ways to Explore Creativity with Updates to Genmoji and Image Playground\nGenmoji and Image Playground provide users with even more ways to express themselves. In addition to turning a text description into a Genmoji, users can now mix together emoji and combine them with descriptions to create something new. When users make images inspired by family and friends using Genmoji and Image Playground, they have the ability to change expressions or adjust personal attributes, like hairstyle, to match their friend\u2019s latest look.\nIn Image Playground, users can tap into brand-new styles with ChatGPT, like an oil painting style or vector art. For moments when users have a specific idea in mind, they can tap Any Style and describe what they want. Image Playground sends a user\u2019s description or photo to ChatGPT and creates a unique image. Users are always in control, and nothing is shared with ChatGPT without their permission.\nVisual Intelligence Helps Users Search and Take Action\nBuilding on Apple Intelligence, visual intelligence extends to a user\u2019s iPhone screen so they can search and take action on anything they\u2019re viewing across their apps.\nVisual intelligence already helps users learn about objects and places around them using their iPhone camera, and it now enables users to do more, faster, with the content on their iPhone screen. Users can ask ChatGPT questions about what they\u2019re looking at on their screen to learn more, as well as search Google, Etsy, or other supported apps to find similar images and products. If there\u2019s an object a user is especially interested in, like a lamp, they can highlight it to search for that specific item or similar objects online.\nVisual intelligence also recognizes when a user is looking at an event and suggests adding it to their calendar.4 Apple Intelligence then extracts the date, time, and location to prepopulate these key details into an event.\nUsers can access visual intelligence for what\u2019s on their screen by simply pressing the same buttons used to take a screenshot. Users will have the choice to save or share their screenshot, or explore more with visual intelligence.\nApple Intelligence Expands to Fitness on Apple Watch\nWorkout Buddy is a first-of-its-kind workout experience on Apple Watch with Apple Intelligence that incorporates a user\u2019s workout data and fitness history to generate personalized, motivational insights during their session.5\nTo offer meaningful inspiration in real time, Workout Buddy analyzes data from a user\u2019s current workout along with their fitness history, based on data like heart rate, pace, distance, Activity rings, personal fitness milestones, and more. A new text-to-speech model then translates insights into a dynamic generative voice built using voice data from Fitness+ trainers, so it has the right energy, style, and tone for a workout. Workout Buddy processes this data privately and securely with Apple Intelligence.\nWorkout Buddy will be available on Apple Watch with Bluetooth headphones, and requires an Apple Intelligence-supported iPhone nearby. It will be available starting in English, across some of the most popular workout types: Outdoor and Indoor Run, Outdoor and Indoor Walk, Outdoor Cycle, HIIT, and Functional and Traditional Strength Training.\nApple Intelligence On-Device Model Now Available to Developers\nApple is opening up access for any app to tap directly into the on-device foundation model at the core of Apple Intelligence.\nWith the Foundation Models framework, app developers will be able to build on Apple Intelligence to bring users new experiences that are intelligent, available when they\u2019re offline, and that protect their privacy, using AI inference that is free of cost. For example, an education app can use the on-device model to generate a personalized quiz from a user\u2019s notes, without any cloud API costs, or an outdoors app can add natural language search capabilities that work even when the user is offline.\nThe framework has native support for Swift, so app developers can easily access the Apple Intelligence model with as few as three lines of code. Guided generation, tool calling, and more are all built into the framework, making it easier than ever to implement generative capabilities right into a developer\u2019s existing app.\nShortcuts Get More Intelligent\nShortcuts are now more powerful and intelligent than ever. Users can tap into intelligent actions, a whole new set of shortcuts enabled by Apple Intelligence. Users will see dedicated actions for features like summarizing text with Writing Tools or creating images with Image Playground.\nNow users will be able to tap directly into Apple Intelligence models, either on-device or with Private Cloud Compute, to generate responses that feed into the rest of their shortcut, maintaining the privacy of information used in the shortcut. For example, a student can build a shortcut that uses the Apple Intelligence model to compare an audio transcription of a class lecture to the notes they took, and add any key points they may have missed. Users can also choose to tap into ChatGPT to provide responses that feed into their shortcut.\nAdditional New Features\nApple Intelligence is even more deeply integrated into the apps and experiences that users rely on every day:\n- The most relevant actions in an email, website, note, or other content can now be identified and automatically categorized in Reminders.\n- Apple Wallet can now identify and summarize order tracking details from emails sent from merchants or delivery carriers. This works across all of a user\u2019s orders, giving them the ability to see their full order details, progress notifications, and more, all in one place.\n- Users can create a poll for anything in Messages, and with Apple Intelligence, Messages can detect when a poll might come in handy and suggest one. In addition, Backgrounds in the Messages app lets a user personalize their chats with stunning designs, and they can create unique backgrounds that fit their conversation with Image Playground.\nThese features build on a wide range of Apple Intelligence capabilities that are already available to users:\n- Writing Tools can help users rewrite, proofread, and summarize the text they have written. And with Describe Your Change, users can describe a specific change they want to apply to their text, like making a dinner party invite read like a poem.\n- Clean Up in Photos allows users to remove distracting elements while staying true to the moment as they intended to capture it.\n- Visual intelligence builds on Apple Intelligence and helps users learn about objects and places around them instantly.\n- Genmoji allow users to create their own emoji by typing a description. And just like emoji, they can be added inline to messages, or shared as a sticker or reaction in a Tapback.\n- Image Playground gives users a way to create playful images in moments, with concepts like themes, costumes, accessories, and places. And they can add their own text descriptions, and create images in the likeness of a family member or friend using photos from their photo library.\n- Image Wand can transform a rough sketch into a polished image that complements a user\u2019s notes.\n- Mail summaries give users a way to view key details for an email or long thread by simply tapping or clicking Summarize.\n- Smart Reply provides users with suggestions for a quick response in Mail and Messages.\n- Siri is more natural and helpful, with the option to type to Siri and tap into its product knowledge about the features and settings on Apple products; Siri can also follow along if a user stumbles over their words, and maintain context from one request to the next.\n- Access to ChatGPT is integrated in Writing Tools and Siri, giving users the option to tap into ChatGPT\u2019s image- and document-understanding capabilities without needing to jump between tools.\n- Natural language search in Photos makes it easier for users to find a photo or video by simply describing it.\n- Users can create a memory movie in Photos by typing a description.\n- Summaries of audio transcriptions in Notes are automatically generated to surface important information at a glance.\n- Users can generate summaries of call transcriptions to highlight important details.\n- Priority Messages, a section at the top of the inbox in Mail, shows the most urgent emails, like a same-day invitation to lunch or a boarding pass.\n- Priority Notifications appear at the top of a user\u2019s notifications, highlighting important notifications that may require immediate attention.\n- Notification summaries give users a way to scan long or stacked notifications and provide key details right on the Lock Screen.\n- Previews in Mail and Messages show users a brief summary of key information without needing to open a message.\n- The Reduce Interruptions Focus surfaces only the notifications that might need immediate attention.\nA Breakthrough for Privacy in AI\nDesigned to protect users\u2019 privacy at every step, Apple Intelligence uses on-device processing, meaning that many of the models that power it run entirely on device. For requests that require access to larger models, Private Cloud Compute extends the privacy and security of iPhone into the cloud to unlock even more intelligence so a user\u2019s data is never stored or shared with Apple; it is used only to fulfill their request. Independent experts can inspect the code that runs on Apple silicon servers to continuously verify this privacy promise, and are already doing so. This is an extraordinary step forward for privacy in AI.\nAvailability\nAll of these new features are available for testing starting today through the Apple Developer Program at developer.apple.com, and a public beta will be available through the Apple Beta Software Program next month at beta.apple.com. Users who enable Apple Intelligence on supported devices set to a supported language will have access this fall, including all iPhone 16 models, iPhone 15 Pro, iPhone 15 Pro Max, iPad mini (A17 Pro), and iPad and Mac models with M1 and later, with Siri and device language set to the same supported language: English, French, German, Italian, Portuguese (Brazil), Spanish, Japanese, Korean, or Chinese (simplified). More languages will be coming by the end of this year: Danish, Dutch, Norwegian, Portuguese (Portugal), Swedish, Turkish, Chinese (traditional), and Vietnamese. Some features may not be available in all languages or regions, and availability may vary due to local laws and regulations. For more details, visit apple.com/apple-intelligence.\nShare article\nMedia\n-\nText of this article\n-\nImages in this article\n- Genmoji and Image Playground are available in English, French, German, Italian, Portuguese (Brazil), Spanish, and Japanese.\n- Live Translation in Messages supports English (U.S., UK), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), Spanish (Spain), and Chinese (simplified).\n- Live Translation in Phone and FaceTime is available for one-on-one calls in English (U.S., UK), French (France), German, Portuguese (Brazil), and Spanish (Spain).\n- The ability to add an event to Calendar with visual intelligence is available in English on all iPhone 16 models, iPhone 15 Pro, and iPhone 15 Pro Max.\n- Workout Buddy will be available on Apple Watch Series 6 or later, Apple Watch SE (2nd generation), and Apple Watch Ultra and Ultra 2 with an Apple Intelligence-supported iPhone starting in English."
    },
    {
      "url": "https://9to5mac.com/2025/08/06/how-to-run-gpt-oss-20b-on-mac/",
      "text": "This week, OpenAI released its long-awaited open weight model called gpt-oss. Part of the appeal of gpt-oss is that you can run it locally on your own hardware, including Macs with Apple silicon. Here\u2019s how to get started and what to expect.\nModels and Macs\nFirst, gpt-oss comes in two flavors: gpt-oss-20b and gpt-oss-120b. The former is described as a medium open weight model, while the latter is considered a heavy open weight model.\nThe medium model is what Apple silicon Macs with enough resources can expect to run locally. The difference? Expect the smaller model to hallucinate more compared to the much larger model due to the data set size difference. That\u2019s the tradeoff for an otherwise faster model that\u2019s actually capable of running on high end Macs.\nStill, the smaller model is a neat tool that\u2019s freely available if you have a Mac with enough resources and a curiosity about running large language models locally.\nYou should also be aware of differences with running a local model compared to, say, ChatGPT. By default, the open weight local model lacks a lot of the modern chatbot features that make ChatGPT useful. For example, responses do not contain consideration for web results that can often limit hallucinations.\nOpenAI recommends at least 16GB RAM to run gpt-oss-20b, but Macs with more RAM will obviously perform better. Based on early user feedback, 16GB RAM is really the floor for what\u2019s needed to just experiment. (AI is a big reason that Apple stopped selling Macs with 8GB RAM not that long ago \u2014 with one value exception.)\nSetup and use\nPreamble aside, actually getting started is super simple.\nFirst, install Ollama on your Mac. This is basically the window for interfacing with gpt-oss-20b. You can find the app at ollama.com/download, or download the Mac version from this download link.\nNext, open Terminal on your Mac and enter this command:\nollama pull gpt-oss:20b\nollama run gpt-oss:20b\nThis will prompt your Mac to download gpt-oss-20b, which uses around 15GB of disk storage.\nFinally, you can launch Ollama and select gpt-oss-20b as your model. You can even put Ollama in airplane mode in the app\u2019s settings panel to ensure everything is happening locally. No sign-in required.\nTo test gpt-oss-20b, just enter a prompt into the text field and watch the model get to work. Again, hardware resources dictate model performance here. Ollama will use every resource it can when running the model, so your Mac may slow to a crawl while the model is thinking.\nMy best Mac is a 15-inch M4 MacBook Air with 16GB RAM. While the model functions, it\u2019s a tall order even for experimentation on my machine. Responding to \u2018hello\u2019 took a little more than five minutes. Responding to \u2018who was the 13th president\u2019 took a little longer at around 43 minutes. You really do want more RAM if you plan to spend more than a few minutes experimenting.\nDecide you want to remove the local model and reclaim that disk space? Enter this terminal command:\nollama rm gpt-oss:20b\nFor more information on using Ollama with gpt-oss-20b on your Mac, check out this official resource. Alternatively, you could use LM Studio, another Mac app for working with AI models.\nCheck out these great accessories\nFTC: We use income earning auto affiliate links. More.\nComments"
    },
    {
      "url": "https://support.apple.com/guide/iphone/use-chatgpt-with-apple-intelligence-iph00fd3c8c2/ios",
      "text": "iPhone User Guide\n- Welcome\n-\n-\n- iPhone models compatible with iOS 18\n- iPhone XR\n- iPhone XS\n- iPhone XS Max\n- iPhone 11\n- iPhone 11 Pro\n- iPhone 11 Pro Max\n- iPhone SE (2nd generation)\n- iPhone 12 mini\n- iPhone 12\n- iPhone 12 Pro\n- iPhone 12 Pro Max\n- iPhone 13 mini\n- iPhone 13\n- iPhone 13 Pro\n- iPhone 13 Pro Max\n- iPhone SE (3rd generation)\n- iPhone 14\n- iPhone 14 Plus\n- iPhone 14 Pro\n- iPhone 14 Pro Max\n- iPhone 15\n- iPhone 15 Plus\n- iPhone 15 Pro\n- iPhone 15 Pro Max\n- iPhone 16\n- iPhone 16 Plus\n- iPhone 16 Pro\n- iPhone 16 Pro Max\n- iPhone 16e\n- Setup basics\n- Make your iPhone your own\n- Take great photos and videos\n- Keep in touch with friends and family\n- Share features with your family\n- Use iPhone for your daily routines\n- Expert advice from Apple Support\n-\n- What\u2019s new in iOS 18\n-\n- Adjust the volume\n- Turn the iPhone flashlight on or off\n- Silence iPhone\n- Multitask with Picture in Picture\n- Access features from the Lock Screen\n- Use the Dynamic Island\n- Perform quick actions\n- Search on iPhone\n- Get information about your iPhone\n- Manage storage on iPhone\n- View or change cellular data settings\n- Travel with iPhone\n-\n- Change sounds and vibrations\n- Use and customize the Action button\n- Create a custom Lock Screen\n- Change the wallpaper\n- Use and customize Control Center\n- Adjust the screen brightness and color balance\n- Keep the iPhone display on longer\n- Use StandBy\n- Customize the text size and zoom setting\n- Change the name of your iPhone\n- Change the date and time\n- Change the language and region\n- Change the default apps\n- Change your default search engine\n- Rotate your iPhone screen\n- Customize sharing options\n-\n- Use the Camera Control\n- Use the Camera Control to open another app\n- Adjust the shutter volume\n- Adjust HDR camera settings\n- Record videos\n- Take spatial photos and record spatial videos for Apple Vision Pro\n- Change sound recording options\n- Record ProRes videos\n- Record videos in Cinematic mode\n- Change video recording settings\n- Save camera settings\n- Customize the Main and Fusion camera lens\n- Change advanced camera settings\n- View, share, and print photos\n- Use Live Text\n- Scan a QR code\n-\n-\n- Create and edit events in Calendar\n- Send invitations\n- Reply to invitations\n- Change how you view events\n- Search for events\n- Change Calendar settings\n- Schedule or display events in a different time zone\n- Keep track of events\n- Use multiple calendars\n- Use reminders\n- Use the Holidays calendar\n- Share iCloud calendars\n- Compass\n-\n- Get started with FaceTime\n- Create a FaceTime link\n- Take a Live Photo\n- Record and transcribe an audio call\n- Turn on Live Captions in a FaceTime call\n- Use other apps during a call\n- Make a Group FaceTime call\n- View participants in a grid\n- Use SharePlay to watch, listen, and play together\n- Share your screen in a FaceTime call\n- Request or give remote control in a FaceTime call\n- Collaborate on a document in FaceTime\n- Use video conferencing features\n- Hand off a FaceTime call to another Apple device\n- Change the FaceTime video settings\n- Change the FaceTime audio settings\n- Change your appearance\n- Leave a call or switch to Messages\n- Block and silence FaceTime calls from unknown callers\n- Report a call as spam\n-\n- Get started with Freeform\n- Create a Freeform board\n- Draw or handwrite\n- Solve handwritten math problems\n- Add text in sticky notes, shapes, and text boxes\n- Add shapes, lines, and arrows\n- Add diagrams\n- Add photos, videos, and other files\n- Apply consistent styles\n- Position items on a board\n- Navigate and present scenes\n- Send a copy or PDF\n- Print a board\n- Share boards and collaborate\n- Search Freeform boards\n- Delete and recover boards\n- Change Freeform settings\n-\n- Intro to Home\n- Upgrade to the new version of Apple Home\n- Set up accessories\n- Control accessories\n- Control your home using Siri\n- Use Grid Forecast to plan your energy usage\n- View electricity usage and rates\n- Set up HomePod\n- Control your home remotely\n- Create and use scenes\n- Use automations\n- Set up security cameras\n- Use Face Recognition\n- Unlock your door with a home key on iPhone or Apple Watch\n- Configure a router\n- Invite others to control accessories\n- Add more homes\n-\n- Get started with Maps\n- Set your location and map view\n-\n- Set your home, work, or school address\n- Ways to get travel directions\n- Get driving directions\n- Set up electric vehicle routing\n- View a route overview or a list of turns\n- Change or add stops to your route\n- Get directions to your parked car\n- Get walking directions\n- Save walks or hikes\n- Get transit directions\n- Get cycling directions\n- Book rides\n- Download offline maps\n- Clear location history\n- Delete recent directions\n- Report an issue with Maps\n-\n- Set up Messages\n- About iMessage\n- Send and reply to messages\n- Text via satellite\n- Schedule a text message to send later\n- Unsend and edit messages\n- Keep track of messages\n- Search\n- Forward and share messages\n- Group conversations\n- Share screens\n- Collaborate on projects\n- Use iMessage apps\n- Take and edit photos or videos\n- Share photos, links, and more\n- Send stickers\n- Create and send Memoji\n- React with Tapbacks\n- Style and animate messages\n- Draw and handwrite messages\n- Send and save GIFs\n- Request, send, and receive payments\n- Send and receive audio messages\n- Share your location\n- Turn read receipts on or off\n- Change notifications\n- Block, filter, and report messages\n- Delete messages and attachments\n- Recover deleted messages\n-\n- Get music\n-\n-\n- Play music\n- Use the music player controls\n- Use Siri to play music\n- Play lossless audio\n- Play Spatial Audio\n- Listen to radio\n- Play music together using SharePlay\n- Play music together in the car\n- Adjust the sound\n- Queue up your music\n- Shuffle or repeat songs\n- Sing along with Apple Music\n- Show song credits and lyrics\n- Tell Apple Music what you enjoy\n-\n- Get started with News\n- Get News notifications and newsletters\n- Use News widgets\n- See news stories chosen just for you\n- Read and share stories\n- Follow your favorite teams with My Sports\n- Listen to Apple News Today\n- Search for channels, topics, stories, or recipes\n- Save stories in News\n- Clear your reading history in News\n- Subscribe to individual news channels\n-\n- Get started with Notes\n- Create and format notes\n- Use Quick Notes\n- Add drawings and handwriting\n- Enter formulas and equations\n- Add photos, video, and more\n- Record and transcribe audio\n- Scan text and documents\n- Work with PDFs\n- Add links\n- Search notes\n- Organize in folders\n- Organize with tags\n- Use Smart Folders\n- Share and collaborate\n- Export or print notes\n- Lock notes\n- Add or remove accounts\n- Change the Notes view\n- Change Notes settings\n-\n- Use passwords\n- Find your password for a website or app\n- Change the password for a website or app\n- Remove a password\n- Recover a deleted password\n- Create a password for a website or app\n- Show passwords in large text\n- Use passkeys to sign in to websites and apps\n- Sign in with Apple\n- Share passwords\n- Automatically fill in strong passwords\n- See websites excluded from AutoFill\n- Change weak or compromised passwords\n- View your passwords and related information\n- Find and share your Wi-Fi password\n- Share passwords securely with AirDrop\n- Make your passwords available on all your devices\n- Automatically fill in verification codes\n- Automatically fill in SMS passcodes\n- Sign in with fewer CAPTCHA challenges\n- Use two-factor authentication\n- Use security keys\n-\n- Make a call\n- Record and transcribe a call\n- Change your Phone settings\n- View and delete the call history\n- Answer or decline incoming calls\n- While on a call\n- Have a conference or three-way call\n- Set up voicemail\n- Check voicemail\n- Change voicemail greeting and settings\n- Select ringtones and vibrations\n- Make calls using Wi-Fi\n- Set up call forwarding\n- Set up call waiting\n- Block or avoid unwanted calls\n-\n- Get started with Photos\n- View photos and videos\n- See photo and video information\n- Customize the Photos app\n- Filter and sort the photo library\n- Back up and sync your photos with iCloud\n- Delete or hide photos and videos\n- Search for photos and videos\n- Get wallpaper suggestions\n- Make stickers from your photos\n- Duplicate and copy photos and videos\n- Merge duplicate photos and videos\n- Import and export photos and videos\n- Print photos\n-\n- Find podcasts\n- Listen to podcasts\n- View podcast transcripts\n- Follow your favorite podcasts\n- Use the Podcasts widget\n- Select your favorite Podcasts categories and channels\n- Organize your podcast library\n- Download, save, remove, and share podcasts\n- Subscribe to podcasts\n- Listen to subscriber-only content\n- Change download settings\n-\n- Browse the web\n- Search for websites\n- See highlights\n- Customize your Safari settings\n- Change the layout\n- Create multiple Safari profiles\n- Use Siri to listen to a webpage\n- Bookmark a website\n- Save pages to a Reading List\n- Find links shared with you\n- Download a PDF\n- Annotate and save a webpage as a PDF\n- Automatically fill in forms\n- Get extensions\n- Clear your cache and cookies\n- Enable cookies\n- Shortcuts\n- Tips\n-\n- Intro to Apple Intelligence\n- Find the right words with Writing Tools\n- Create original images with Image Playground\n- Create your own emoji with Genmoji\n- Use Image Wand with Apple Intelligence\n- Use Apple Intelligence with Siri\n- Use visual intelligence\n- Summarize notifications and reduce interruptions\n- Use ChatGPT with Apple Intelligence\n- Apple Intelligence and privacy\n- Block access to Apple Intelligence features\n-\n- Get started with Screen Time\n- Protect your vision health with Screen Distance\n- Create, manage, and keep track of a Screen Time passcode\n- Set schedules with Screen Time\n- Block apps, app downloads, websites, and purchases\n- Block calls and messages with Screen Time\n- Check for sensitive images and videos\n- Set up Screen Time for a family member\n-\n- Intro to Continuity\n- Use AirDrop to send items to nearby devices\n- Hand off tasks between devices\n- Control your iPhone from your Mac\n- Copy and paste between devices\n- Stream video and audio from your iPhone\n- Allow phone calls and text messages on your iPad and Mac\n- Share your internet connection\n- Use iPhone as a webcam\n- Insert sketches, photos, and scans on Mac\n- Start SharePlay instantly\n- Connect iPhone and your computer with a cable\n- Transfer files between devices\n-\n- Intro to CarPlay\n- Connect to CarPlay\n- Use Siri\n- Use your vehicle\u2019s built-in controls\n- Get turn-by-turn directions\n- Report traffic incidents\n- Change the map view\n- Make phone calls\n- Play music\n- View your calendar\n- Send and receive text messages\n- Announce incoming text messages\n- Play podcasts\n- Play audiobooks\n- Listen to news stories\n- Control your home\n- Use other apps with CarPlay\n- Rearrange icons on CarPlay Home\n- Change settings in CarPlay\n-\n- Get started with accessibility features\n- Use accessibility features during setup\n- Change Siri accessibility settings\n- Quickly turn accessibility features on or off\n-\n- Overview of accessibility features for vision\n- Zoom in\n- View a larger version of text you\u2019re reading or typing\n- Change display colors\n- Make text easier to read\n- Reduce onscreen motion\n- Use iPhone more comfortably while riding in a vehicle\n- Customize per-app visual settings\n- Hear what\u2019s on the screen or typed\n- Hear audio descriptions\n- Adjust CarPlay settings\n-\n- Turn on and practice VoiceOver\n- Change your VoiceOver settings\n- Use VoiceOver gestures\n- Operate iPhone when VoiceOver is on\n- Control VoiceOver using the rotor\n- Use the onscreen keyboard\n- Write with your finger\n- Keep the screen off\n- Use VoiceOver with an external keyboard\n- Use a braille display\n- Type braille on the screen\n- Customize gestures and keyboard shortcuts\n- Use VoiceOver with a pointer device\n- Get live descriptions of your surroundings\n- Use VoiceOver in apps\n-\n- Overview of accessibility features for mobility\n- Use AssistiveTouch\n- Adjust how iPhone responds to your touch\n- Back tap\n- Use Reachability\n- Auto-answer calls\n- Turn off vibration\n- Change Face ID and attention settings\n- Use Voice Control\n- Use Voice Control commands with CarPlay\n- Adjust the side or Home button\n- Adjust Camera Control settings\n- Use Apple TV Remote buttons\n- Adjust pointer settings\n- Adjust keyboard settings\n- Control iPhone with an external keyboard\n- Adjust AirPods settings\n- Turn on Apple Watch Mirroring\n- Control a nearby Apple device\n- Control iPhone with the movement of your eyes\n-\n- Overview of accessibility features for hearing\n- Use hearing devices\n- Use Live Listen\n- Use sound recognition\n- Set up and use RTT and TTY\n- Flash the indicator light for notifications\n- Adjust audio settings\n- Play background sounds\n- Display subtitles and captions\n- Show transcriptions for Intercom messages\n- Get live captions of spoken audio\n- Play music as taps, textures, and more\n- Get notified about car horns and sirens in CarPlay\n-\n- Control what you share\n- Turn on Lock Screen features\n- Keep your Apple Account secure\n- Create and manage Hide My Email addresses\n- Protect your web browsing with iCloud Private Relay\n- Use a private network address\n- Use Advanced Data Protection\n- Use Lockdown Mode\n- Use Stolen Device Protection\n- Receive warnings about sensitive content\n- Use Contact Key Verification\n-\n- Important safety information\n- Important handling information\n- Find more resources for software and service\n- FCC compliance statement\n- ISED Canada compliance statement\n- Ultra Wideband information\n- Class 1 Laser information\n- Apple and the environment\n- Disposal and recycling information\n- Unauthorized modification of iOS\n- Copyright and trademarks\nUse ChatGPT with Apple Intelligence on iPhone\nIf you choose to allow Apple Intelligence to work with ChatGPT* from OpenAI, you can do the following:\nUse Siri to access ChatGPT: Siri can tap into ChatGPT to provide answers when that might be helpful for certain requests including questions about photos and documents.\nUse ChatGPT with Writing Tools: ChatGPT can compose text or images from just a description.\nUse ChatGPT with visual intelligence: Use visual intelligence with Camera Control to quickly learn more about the places and objects around you.\nConnect your ChatGPT account: You don\u2019t need a ChatGPT account, but if you have one\u2014free or paid\u2014you can connect to your account. With a ChatGPT paid account, your iPhone can use advanced ChatGPT capabilities more often.\nYou control when ChatGPT is used and will be asked before any of your information is shared.\nNote: Apple Intelligence is not available on all iPhone models or in all languages or regions.** To access the most recent available features, make sure you\u2019re using the latest version of iOS and have Apple Intelligence turned on. The ChatGPT extension is not available in all languages or regions that support Apple Intelligence. You must be at least 13 years old or the minimum age required in your country to consent to use ChatGPT. For more information, see OpenAI Terms of Use.\nSet up ChatGPT\nWhen you first compose in Writing Tools, access ChatGPT with visual intelligence, or use Siri to get answers from ChatGPT, you may be prompted to turn on the extension. You can also set up ChatGPT in Settings.\nGo to Settings , then tap Apple Intelligence & Siri.\nTap ChatGPT, then tap Set Up.\nDo one of the following:\nUse ChatGPT without an account: Tap Enable ChatGPT.\nNote: If you later decide to use ChatGPT with an account, go to Settings > Apple Intelligence & Siri, tap ChatGPT, then tap Sign In.\nUse ChatGPT with an existing account: Tap Use ChatGPT with an Account, then follow the onscreen instructions.\nNote: If you want your requests saved to your ChatGPT chat history, you must be signed in to a ChatGPT account.\nTurn ChatGPT off\nGo to Settings , then tap Apple Intelligence & Siri.\nTap ChatGPT, then turn the ChatGPT extension off.\nIf you want to prevent Siri from suggesting ChatGPT when you make a request, turn off ChatGPT, then turn off Setup Prompts.\nTo block access to ChatGPT, see Block access to ChatGPT.\nChatGPT and privacy\nWhen using the ChatGPT extension, you choose what content to send to ChatGPT. Your request and attachments, as well as limited data associated with the request, such as current time zone, country, device type, language, and feature being used when making the request, are sent to ChatGPT to answer your request and enable ChatGPT to provide you accurate and relevant results. Your IP address is obscured from ChatGPT, but your general location is provided for purposes such as enabling ChatGPT to prevent fraud and comply with applicable law.\nIf you access the ChatGPT extension without an account, only the information described above will be sent to ChatGPT. OpenAl does not receive any information tied to your Apple Account. OpenAl must process your data solely for the purpose of fulfilling your request, and not store your request or any responses it provides unless required under applicable laws. OpenAl also must not use your request to improve or train its models.\nWhen you are signed in to a ChatGPT account, your account settings and OpenAl\u2019s data privacy policies apply.\nFor more information, see ChatGPT Extension & Privacy."
    },
    {
      "url": "https://www.apple.com/newsroom/2024/06/introducing-apple-intelligence-for-iphone-ipad-and-mac/?utm_source=chatgpt.com",
      "text": "PRESS RELEASE\nJune 10, 2024\nIntroducing Apple Intelligence, the personal intelligence system that puts powerful generative models at the core of iPhone, iPad, and Mac\nSetting a new standard for privacy in AI, Apple Intelligence understands personal context to deliver intelligence that is helpful and relevant\nCUPERTINO, CALIFORNIA Apple today introduced Apple Intelligence, the personal intelligence system for iPhone, iPad, and Mac that combines the power of generative models with personal context to deliver intelligence that\u2019s incredibly useful and relevant. Apple Intelligence is deeply integrated into iOS 18, iPadOS 18, and macOS Sequoia. It harnesses the power of Apple silicon to understand and create language and images, take action across apps, and draw from personal context to simplify and accelerate everyday tasks. With Private Cloud Compute, Apple sets a new standard for privacy in AI, with the ability to flex and scale computational capacity between on-device processing and larger, server-based models that run on dedicated Apple silicon servers.\n\u201cWe\u2019re thrilled to introduce a new chapter in Apple innovation. Apple Intelligence will transform what users can do with our products \u2014 and what our products can do for our users,\u201d said Tim Cook, Apple\u2019s CEO. \u201cOur unique approach combines generative AI with a user\u2019s personal context to deliver truly helpful intelligence. And it can access that information in a completely private and secure way to help users do the things that matter most to them. This is AI as only Apple can deliver it, and we can\u2019t wait for users to experience what it can do.\u201d\nNew Capabilities for Understanding and Creating Language\nApple Intelligence unlocks new ways for users to enhance their writing and communicate more effectively. With brand-new systemwide Writing Tools built into iOS 18, iPadOS 18, and macOS Sequoia, users can rewrite, proofread, and summarize text nearly everywhere they write, including Mail, Notes, Pages, and third-party apps.\nWhether tidying up class notes, ensuring a blog post reads just right, or making sure an email is perfectly crafted, Writing Tools help users feel more confident in their writing. With Rewrite, Apple Intelligence allows users to choose from different versions of what they have written, adjusting the tone to suit the audience and task at hand. From finessing a cover letter, to adding humor and creativity to a party invitation, Rewrite helps deliver the right words to meet the occasion. Proofread checks grammar, word choice, and sentence structure while also suggesting edits \u2014 along with explanations of the edits \u2014 that users can review or quickly accept. With Summarize, users can select text and have it recapped in the form of a digestible paragraph, bulleted key points, a table, or a list.\nIn Mail, staying on top of emails has never been easier. With Priority Messages, a new section at the top of the inbox shows the most urgent emails, like a same-day dinner invitation or boarding pass. Across a user\u2019s inbox, instead of previewing the first few lines of each email, they can see summaries without needing to open a message. For long threads, users can view pertinent details with just a tap. Smart Reply provides suggestions for a quick response, and will identify questions in an email to ensure everything is answered.\nDeep understanding of language also extends to Notifications. Priority Notifications appear at the top of the stack to surface what\u2019s most important, and summaries help users scan long or stacked notifications to show key details right on the Lock Screen, such as when a group chat is particularly active. And to help users stay present in what they\u2019re doing, Reduce Interruptions is a new Focus that surfaces only the notifications that might need immediate attention, like a text about an early pickup from daycare.\nIn the Notes and Phone apps, users can now record, transcribe, and summarize audio. When a recording is initiated while on a call, participants are automatically notified, and once the call ends, Apple Intelligence generates a summary to help recall key points.\nImage Playground Makes Communication and Self\u2011Expression Even More Fun\nApple Intelligence powers exciting image creation capabilities to help users communicate and express themselves in new ways. With Image Playground, users can create fun images in seconds, choosing from three styles: Animation, Illustration, or Sketch. Image Playground is easy to use and built right into apps including Messages. It\u2019s also available in a dedicated app, perfect for experimenting with different concepts and styles. All images are created on device, giving users the freedom to experiment with as many images as they want.\nWith Image Playground, users can choose from a range of concepts from categories like themes, costumes, accessories, and places; type a description to define an image; choose someone from their personal photo library to include in their image; and pick their favorite style.\nWith the Image Playground experience in Messages, users can quickly create fun images for their friends, and even see personalized suggested concepts related to their conversations. For example, if a user is messaging a group about going hiking, they\u2019ll see suggested concepts related to their friends, their destination, and their activity, making image creation even faster and more relevant.\nIn Notes, users can access Image Playground through the new Image Wand in the Apple Pencil tool palette, making notes more visually engaging. Rough sketches can be turned into delightful images, and users can even select empty space to create an image using context from the surrounding area. Image Playground is also available in apps like Keynote, Freeform, and Pages, as well as in third-party apps that adopt the new Image Playground API.\nGenmoji Creation to Fit Any Moment\nTaking emoji to an entirely new level, users can create an original Genmoji to express themselves. By simply typing a description, their Genmoji appears, along with additional options. Users can even create Genmoji of friends and family based on their photos. Just like emoji, Genmoji can be added inline to messages, or shared as a sticker or reaction in a Tapback.\nNew Features in Photos Give Users More Control\nSearching for photos and videos becomes even more convenient with Apple Intelligence. Natural language can be used to search for specific photos, such as \u201cMaya skateboarding in a tie-dye shirt,\u201d or \u201cKatie with stickers on her face.\u201d Search in videos also becomes more powerful with the ability to find specific moments in clips so users can go right to the relevant segment. Additionally, the new Clean Up tool can identify and remove distracting objects in the background of a photo \u2014 without accidentally altering the subject.\nWith Memories, users can create the story they want to see by simply typing a description. Using language and image understanding, Apple Intelligence will pick out the best photos and videos based on the description, craft a storyline with chapters based on themes identified from the photos, and arrange them into a movie with its own narrative arc. Users will even get song suggestions to match their memory from Apple Music. As with all Apple Intelligence features, user photos and videos are kept private on device and are not shared with Apple or anyone else.\nSiri Enters a New Era\nPowered by Apple Intelligence, Siri becomes more deeply integrated into the system experience. With richer language-understanding capabilities, Siri is more natural, more contextually relevant, and more personal, with the ability to simplify and accelerate everyday tasks. It can follow along if users stumble over words and maintain context from one request to the next. Additionally, users can type to Siri, and switch between text and voice to communicate with Siri in whatever way feels right for the moment. Siri also has a brand-new design with an elegant glowing light that wraps around the edge of the screen when Siri is active.\nSiri can now give users device support everywhere they go, and answer thousands of questions about how to do something on iPhone, iPad, and Mac. Users can learn everything from how to schedule an email in the Mail app, to how to switch from Light to Dark Mode.\nWith onscreen awareness, Siri will be able to understand and take action with users\u2019 content in more apps over time. For example, if a friend texts a user their new address in Messages, the receiver can say, \u201cAdd this address to his contact card.\u201d\nWith Apple Intelligence, Siri will be able to take hundreds of new actions in and across Apple and third-party apps. For example, a user could say, \u201cBring up that article about cicadas from my Reading List,\u201d or \u201cSend the photos from the barbecue on Saturday to Malia,\u201d and Siri will take care of it.\nSiri will be able to deliver intelligence that\u2019s tailored to the user and their on-device information. For example, a user can say, \u201cPlay that podcast that Jamie recommended,\u201d and Siri will locate and play the episode, without the user having to remember whether it was mentioned in a text or an email. Or they could ask, \u201cWhen is Mom\u2019s flight landing?\u201d and Siri will find the flight details and cross-reference them with real-time flight tracking to give an arrival time.\nA New Standard for Privacy in AI\nTo be truly helpful, Apple Intelligence relies on understanding deep personal context while also protecting user privacy. A cornerstone of Apple Intelligence is on-device processing, and many of the models that power it run entirely on device. To run more complex requests that require more processing power, Private Cloud Compute extends the privacy and security of Apple devices into the cloud to unlock even more intelligence.\nWith Private Cloud Compute, Apple Intelligence can flex and scale its computational capacity and draw on larger, server-based models for more complex requests. These models run on servers powered by Apple silicon, providing a foundation that allows Apple to ensure that data is never retained or exposed.\nIndependent experts can inspect the code that runs on Apple silicon servers to verify privacy, and Private Cloud Compute cryptographically ensures that iPhone, iPad, and Mac do not talk to a server unless its software has been publicly logged for inspection. Apple Intelligence with Private Cloud Compute sets a new standard for privacy in AI, unlocking intelligence users can trust.\nChatGPT Gets Integrated Across Apple Platforms\nApple is integrating ChatGPT access into experiences within iOS 18, iPadOS 18, and macOS Sequoia, allowing users to access its expertise \u2014 as well as its image- and document-understanding capabilities \u2014 without needing to jump between tools.\nSiri can tap into ChatGPT\u2019s expertise when helpful. Users are asked before any questions are sent to ChatGPT, along with any documents or photos, and Siri then presents the answer directly.\nAdditionally, ChatGPT will be available in Apple\u2019s systemwide Writing Tools, which help users generate content for anything they are writing about. With Compose, users can also access ChatGPT image tools to generate images in a wide variety of styles to complement what they are writing.\nPrivacy protections are built in for users who access ChatGPT \u2014 their IP addresses are obscured, and OpenAI won\u2019t store requests. ChatGPT\u2019s data-use policies apply for users who choose to connect their account.\nChatGPT will come to iOS 18, iPadOS 18, and macOS Sequoia later this year, powered by GPT-4o. Users can access it for free without creating an account, and ChatGPT subscribers can connect their accounts and access paid features right from these experiences.\nAvailability\nApple Intelligence is free for users, and will be available in beta as part of iOS 18, iPadOS 18, and macOS Sequoia this fall in U.S. English. Some features, software platforms, and additional languages will come over the course of the next year. Apple Intelligence will be available on iPhone 15 Pro, iPhone 15 Pro Max, and iPad and Mac with M1 and later, with Siri and device language set to U.S. English. For more information, visit apple.com/apple-intelligence.\nShare article\nMedia\n-\nText of this article\n-\nImages in this article"
    },
    {
      "url": "https://9to5mac.com/2025/08/07/openai-gpt-5-chatgpt-announcement/",
      "text": "OpenAI has officially announced GPT-5, its latest frontier model to power ChatGPT. The announcement follows the release of two open weight models, one of which can run on the Mac, and changes to encourage healthier ChatGPT use this week.\nWhat is GPT-5?\nHere\u2019s what OpenAI has to say about GPT-5:\nToday we\u2019re introducing GPT\u20115, OpenAI\u2019s smartest, fastest, most useful model yet, and a major step towards placing intelligence at the center of every business. GPT\u20115 unites and exceeds OpenAI\u2019s prior breakthroughs in frontier intelligence, spanning 4o, OpenAI o-series reasoning, agents, and advanced math(opens in a new window) capabilities. [\u2026]\nGPT\u20115 delivers leaps in accuracy, speed, reasoning, context recognition, structured thinking, and problem-solving. The true magic will happen when businesses start applying GPT\u20115 to imagine new use cases.\nAs OpenAI has suggested this year, GPT-5 is a unified model that includes capabilities that have been developed across multiple models before today:\nGPT\u20115 is a unified system with a smart, efficient model that answers most questions, a deeper reasoning model (GPT\u20115 thinking) for harder problems, and a real\u2011time router that quickly decides which to use based on conversation type, complexity, tool needs, and your explicit intent (for example, if you say \u201cthink hard about this\u201d in the prompt). The router is continuously trained on real signals, including when users switch models, preference rates for responses, and measured correctness, improving over time. Once usage limits are reached, a mini version of each model handles remaining queries. In the near future, we plan to integrate these capabilities into a single model.\nOpenAI will deprecate its previous models in favor of its new, unified frontier model. For reference, this was the six-options model picker before GPT-5:\nGPT-5 is also a more performant and more accurate model, according to OpenAI:\nIn our evaluations, GPT\u20115 (with thinking) performs better than OpenAI o3 with 50-80% less output tokens across capabilities, including visual reasoning, agentic coding, and graduate-level scientific problem solving. [..]\nGPT\u20115 is significantly less likely to hallucinate than our previous models. With web search enabled on anonymized prompts representative of ChatGPT production traffic, GPT\u20115\u2019s responses are ~45% less likely to contain a factual error than GPT\u20114o, and when thinking, GPT\u20115\u2019s responses are ~80% less likely to contain a factual error than OpenAI o3.\nNotably, GPT-5 is now the default model used by ChatGPT:\nGPT\u20115 is the new default in ChatGPT, replacing GPT\u20114o, OpenAI o3, OpenAI o4-mini, GPT\u20114.1, and GPT\u20114.5 for signed-in users. Just open ChatGPT and type your question; GPT\u20115 handles the rest, applying reasoning automatically when the response would benefit from it. Paid users can still select \u201cGPT\u20115 Thinking\u201d from the model picker, or type something like \u2018think hard about this\u2019 in the prompt to ensure reasoning is used when generating a response.\nOpenAI is also opening up its advanced voice chat mode to all users. Free users can chat with the upgraded voice mode for hours, and Plus tier users have almost no limit now.\nChatGPT is adding new personalization options too. For example, chats can have customized color options. ChatGPT personality options are also coming.\nGPT-5 availability\nOpenAI says GPT-5 is available starting today starting for ChatGPT Team, Pro, Plus and free tier users and through the OpenAI API. Paid customers will have access to more usage, while free users will GPT-5 mini after hitting usage limits.\nEnterprise and Edu customers will have access next week. GPT-5 Pro, which OpenAI calls \u201ca version with extended reasoning for even more reliable and detailed answers,\u201d will come to Team, Enterprise, and Edu customers soon.\nThe API will have access to GPT-5, GPT-5 mini, and GPT-5 nano.\nLearn more about GPT-5 from OpenAI\u2019s official announcement, and view the livestream demonstration below:\nCheck out these great accessories\nFTC: We use income earning auto affiliate links. More.\nComments"
    },
    {
      "url": "https://9to5mac.com/2025/08/04/healthy-chatgpt-use/",
      "text": "OpenAI is updating how ChatGPT works to encourage healthier use and avoid unintended consequences. One change that OpenAI says ChatGPT users will see \u201cstarting today\u201d is a technique used by other digital services.\nMuch like video streaming services and social networks, OpenAI is adding a gentle break reminder for users during prolonged chat sessions.\nStarting today, you\u2019ll see gentle reminders during long sessions to encourage breaks. We\u2019ll keep tuning when and how they show up so they feel natural and helpful.\nAccording to the blog post, OpenAI says it measures success in return visits, not session duration. This subtle nudge to spend less time in ChatGPT sounds like it will change over time, but we should see the first examples in actual use from today.\nOpenAI provides this example of how usage break reminders will look to start:\nOpenAI also says it\u2019s tuning ChatGPT to be less absolute when a user asks for actionable advice. For example, if a user asks if they should end a relationship, OpenAI says ChatGPT shouldn\u2019t provide a yes or no response. Instead, ChatGPT should respond with prompts that encourage reflection and guide users to think through problems on their own.\nThe company also says it has \u201cworked with over 90 physicians across over 30 countries\u2014psychiatrists, pediatricians, and general practitioners \u2014 to build custom rubrics for evaluating complex, multi-turn conversations,\u201d and it is \u201cconvening an advisory group of experts\u201d to help it further improve healthy ChatGPT usage. You can read the full announcement post here.\n9to5Mac\u2019s Take\nAt a high level, avoiding absolute responses for life advice sounds like the right direction for ChatGPT.\nThe reality is that you can convince ChatGPT to answer any inquiry with the one answer or another. Don\u2019t like what ChatGPT has to say? Just prompt it again to get a different response.\nFor that reason alone, OpenAI should avoid absolute responses and strive for a more consistent experience that encourages critical thinking rather than being a substitute for decision-making.\nAs for the subtle reminders to take breaks from ChatGPT use, I\u2019m more skeptical of how effective these prompts are without seeing actual data. Both changes give OpenAI some cover from criticism over how ChatGPT usage can be unhealthy or dangerous without proper guardrails.\nCheck out these great accessories\nFTC: We use income earning auto affiliate links. More.\nComments"
    },
    {
      "url": "https://9to5mac.com/2025/08/05/openai-open-weight-ai-models-mac/",
      "text": "Living up to its name, OpenAI has released not one but two new open-weight AI models after promising to deliver a new open-weight model earlier this year. The two models, gpt-oss-20b and gpt-oss-120b, are available to download for free now.\nWhat makes open-weight models special? Specifically, these are AI models that can be downloaded and run on computers with adequate resources for powering local AI models. No internet connection is required because access to the model provider\u2019s server isn\u2019t involved. This also allows developers to build custom tools using the open AI models.\nOpenAI describes the \u201920b\u2019 variant as a medium-sized open model while it calls the \u2018120b\u2019 variant a large-sized open model for running on \u201cmost desktops and laptops.\u201d\nOpenAI says the smaller model works best with at least 16GB VRAM or unified memory and is \u201cperfect for higher-end consumer GPUs and Apple Silicon Macs.\u201d The larger, full-sized model wants at least 60GB VRAM or unified memory.\nWhile these models aren\u2019t the most powerful AI tools from OpenAI, they should satisfy the demand for open-weight models from the team behind ChatGPT.\nThe rise of DeepSeek out of China last year put pressure on OpenAI to deliver a modern open-weight model. Prior to today, OpenAI hadn\u2019t released an open-weight model since its early days in 2019.\nLearn much more about OpenAI\u2019s two new open-weight models here.\nCheck out these great accessories\nFTC: We use income earning auto affiliate links. More.\nComments"
    }
  ],
  "argos_summary": "OpenAI has announced GPT-5, its latest model for ChatGPT, which will soon be integrated into Apple Intelligence with upcoming software updates. This integration will enhance Siri's capabilities, allowing it to access ChatGPT for answering questions and generating text and images. Additionally, Apple Intelligence will introduce features like Live Translation and improved visual intelligence across its devices, while maintaining user privacy through on-device processing and data protection measures.",
  "argos_id": "RLBWXQL8D"
}