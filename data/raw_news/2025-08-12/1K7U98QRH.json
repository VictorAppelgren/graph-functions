{
  "url": "https://techcrunch.com/2025/08/12/google-vet-raises-8m-for-continua-to-bring-ai-agents-to-group-chats/",
  "authorsByline": "Marina Temkin",
  "articleId": "5d987662f9cd479796306d3d4266b08a",
  "source": {
    "domain": "techcrunch.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "San Francisco",
      "city": "San Francisco",
      "coordinates": {
        "lat": 37.7790262,
        "lon": -122.419906
      }
    }
  },
  "imageUrl": "https://techcrunch.com/wp-content/uploads/2025/08/David-Petrou-Headshot.jpg?resize=1200,800",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T17:15:01+00:00",
  "addDate": "2025-08-12T17:21:12.665597+00:00",
  "refreshDate": "2025-08-12T17:21:12.665599+00:00",
  "score": 1.0,
  "title": "Google vet raises $8M for Continua to bring AI agents to group chats",
  "description": "David Petrou, founding member of Google Goggles and Google Glass, wants to enhance group chats with AI.",
  "content": "In early 2023, David Petrou, a distinguished engineer and a founding member of both Google Goggles and Google Glass, made a surprising move. After more than 17 years at the company, he departed to launch his own startup.\n\n\u201cI was seeing how fast technology was changing, and I felt there are certain ideas that are best explored in the context of a startup,\u201d Petrou told TechCrunch.\n\nHis ultimate idea was to build Continua, a consumer-facing company that uses AI agents to enhance collaboration and interaction in group chats on SMS, iMessage, and Discord.\n\n\u201cThe simple way to think about it is that we\u2019re bringing the power of LLMs to group chats,\u201d Petrou said.\n\nContinua announced on Tuesday that it has raised an $8 million seed round. The funding was led by GV, with additional participation from Bessemer Ventures Partners and a group of angel investors.\n\nWhen developing Continua, Petrou noticed that people would interact with ChatGPT or another LLM, and then would copy and paste what they learned into their group conversation.\n\n\u201cIf you and I are planning a trip, or if we\u2019re trying to figure out what to have for dinner, or what movie to watch, all of these things can be facilitated by an LLM participating in a group chat with us,\u201d Petrou said.\n\nContinua claims its AI agents can reduce group chat chaos by joining conversations and offering helpful information only when it\u2019s needed.\n\nAs the group discusses projects and common plans, Continua can automatically set reminders, launch polls, add calendar invitations, or generate Google documents with checklists and to-do lists.\n\nIf a user forgets details from the group chat, such as the meeting time or location, they can simply direct message Continua to privately ask for the information.\n\nAt first glance, Continua may seem like a straightforward application of AI, but Petrou says that getting LLM to participate in a conversation with multiple humans is a rather complex technical problem. Since most AI models are designed for conversations between a single person and a single assistant, Continua had to fine-tune its technology to understand the dynamics of group chat discussions.\n\nFor instance, group members do not need Continua to respond to everything they write.\n\n\u201cYou want the agent to have social intelligence,\u201d Petrou said. He added that they had to \u201cbreak the LLM\u2019s brain\u201d to naturally integrate the AI into conversations.\n\nUsers can invoke Continua when they need its help or tell the agent to \u201chang back\u201d if it\u2019s chiming in too often.\n\nUsers can get started with Continua by adding its phone number to a group SMS or its username to a Discord chat.\n\nWhile several companies, including Meta and the startup Hey Umai, offer AI agents for conversations, Petrou insists that Continua is most suitable for group interactions.\n\nErik Nordlander, a general partner at GV, said his firm invested in Petrou even before the concept of Continua\u2019s group chat AI had fully taken shape. \u201cDavid is a really brilliant engineer, someone who\u2019s been working with AI since before it was the hot thing.\u201d\n\nAccording to Nordlander, Continua has several potential paths to profitability. The agent is already assisting with event planning and trip booking, which he suggested they could charge for in the future.",
  "medium": "Article",
  "links": [
    "https://www.wired.com/story/from-google-goggles-to-google-lens/",
    "https://techcrunch.com/events/tc-disrupt-2025/?utm_source=tc&utm_medium=ad&utm_campaign=disrupt2025&utm_content=ticketsales&promo=tc_inline_rb&display=",
    "https://continua.ai/"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "group chats",
      "weight": 0.11614165
    },
    {
      "name": "group chat chaos",
      "weight": 0.110004
    },
    {
      "name": "group chat discussions",
      "weight": 0.108710624
    },
    {
      "name": "Continua",
      "weight": 0.10388162
    },
    {
      "name": "group members",
      "weight": 0.099450335
    },
    {
      "name": "group interactions",
      "weight": 0.09674614
    },
    {
      "name": "AI agents",
      "weight": 0.09635533
    },
    {
      "name": "Continua\u2019s group chat AI",
      "weight": 0.09031532
    },
    {
      "name": "David Petrou",
      "weight": 0.07687322
    },
    {
      "name": "AI",
      "weight": 0.073184356
    }
  ],
  "topics": [
    {
      "name": "Venture Capital"
    },
    {
      "name": "AI"
    },
    {
      "name": "Startups"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Business News/Company News",
      "score": 0.98828125
    },
    {
      "name": "/News/Technology News",
      "score": 0.92919921875
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.84228515625
    },
    {
      "name": "/Computers & Electronics/Software/Business & Productivity Software",
      "score": 0.58984375
    },
    {
      "name": "/Computers & Electronics/Enterprise Technology/Other",
      "score": 0.348876953125
    }
  ],
  "sentiment": {
    "positive": 0.22973914,
    "negative": 0.15160753,
    "neutral": 0.61865336
  },
  "summary": "David Petrou, a distinguished engineer and founding member of Google Goggles and Google Glass, has raised $8M for his own startup, Continua, to bring AI agents to group chats. The company uses these agents to enhance collaboration and interaction in group chats on SMS, iMessage, and Discord. The funding was led by GV, Bessemer Ventures Partners, and a group of angel investors. Petrou's vision involves bringing the power of AI to group discussions, helping users navigate tasks such as planning a trip, planning a dinner, or researching a movie. Despite some companies offering AI agents for conversations, Petrou believes Continua is most suitable for group interactions.",
  "shortSummary": "Continua, a startup integrating AI agents into group chats, raises $8m through investment led by GV, aiming for commercial profitability.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "653db3973bb643a19f0e210fc9fdc97b",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.wired.com/story/from-google-goggles-to-google-lens/",
      "text": "Google's first public foray into augmented reality began with an argument in a bar. It was 2008, and David Petrou, a longtime Google engineer, was sitting in a Brooklyn watering hole explaining to his friends how someday, you'd be able to do a search just by pointing your phone's camera at something. He likened it to pointing and asking, what's that? It would be faster and richer than typing, and could help you ask questions you'd never be able to put into words. Based on what he'd seen within Google, Petrou thought the tech could already work. His friends, of course, said he was crazy. They thought computer vision was science fiction.\nPetrou left the bar early and angry, went home, and started coding. Despite having no background in computer vision, and a day job working on Google's Bigtable database system, Petrou taught himself Java so he could write an Android app and immersed himself in Google's latest work on computer vision. After a month of feverish hacking, Petrou had the very first prototype of what would soon become Google Goggles.\nPetrou still has a video of an early demo. He's crammed into a Google conference room with Ted Power, a UX designer, talking into a webcam. Before he starts, Petrou explains what he's working on. \"The idea is generic image annotation, where an image can come in to Google and a number of back-ends can annotate that image with some interesting features.\" Crystal clear, right?\nTo explain, Petrou grabs a G1, Google's then-new Android phone, and takes a photo of a newspaper article about Congressional oversight of ExxonMobil. A moment later, the phone spits back all the article's text, rendered in white text on a black background. It looked like a DOS prompt, not a smartphone app, but it worked impressively\u2014except near the end when it spelled the company Em<onMobile. A few minutes later, Petrou showed a terribly lit photo of Power's desk, littered with books and cables, with a MacBook in the center. The app surveyed the image and returned 10 terms to describe it. Some made sense, like \"room\" and \"interior.\" Others, like \"Nokia,\" less so. Two terms particularly excited Petrou: \"laptop\" and \"MacBook.\" They showed this camera could see objects, and understand them. But still, almost immediately after, Petrou preached caution: \"We are a long way to providing perfect results,\" he said into the webcam.\nThe first versions of Goggles couldn't do much, and couldn't do it very well. But searching the web just by taking a photo still felt like magic. Over the next few years, Google Goggles would capture the imaginations of Google executives and users alike. Before Apple built ARKit and Microsoft made HoloLens, before anyone else began to publicly explore the possibilities of augmented reality, Goggles provided a crucial early example of how smartphones could interact with the real world.\nThen Goggles died. The first great experiment in smartphone AR came and went before anyone else could even copy it.\nRobin Williams used to joke that the Irish discovered civilization, then had a Guinness and forgot where they left it. So it was with Google and smartphone cameras. Nearly a decade ago, Google engineers were working on ideas that you'll now find in Snapchat, Facebook, the iPhone X, and elsewhere. As the tech industry moves towards the camera-first future, in which people talk, play, and work through the lens of their smartphone, Google's now circling back, tapping those same ideas and trying to finish what it started. This time it's hoping it's not too late.\nWhen Petrou first started working on Goggles, he had no idea how many other Googlers were working on the same stuff, and how long they'd been at it. In 2006, Google had acquired a Santa Monica-based company called Neven Vision, which possessed some of the most advanced computer-vision tools anywhere. Google had a particular idea for where to deploy it: in its Picasa photo-sharing app. \"It could be as simple as detecting whether or not a photo contains a person, or, one day, as complex as recognizing people, places, and objects,\" Adrian Graham, Picasa's product manager, wrote in a blog post announcing the acquisition. \"This technology just may make it a lot easier for you to organize and find the photos you care about.\"\nAfter a couple of years, as Neven Vision's tech integrated further into Picasa, founder Hartmut Neven and his team started to think a little bigger. \"We were all inspired by the Terminator movie, when he walks into the bar and everything gets identified,\" says Shailesh Nalawadi, a former product manager on the team and now CEO at Mavin, Inc. \"We thought, 'Hey, wouldn't it be amazing if you could have something like that, match it against a database, and it would tell you what's in that picture?'\"\nEventually the Neven Vision crew met Petrou, and they started working on a better prototype. They built an app that could identify book covers, album art, paintings, landmarks, and lots of other well-known images. You'd take a picture, and after 20 seconds or so of uploading and processing, the app would return search results for whatever you were looking at. It was primitive, but it worked.\nLots of projects within Google start the same way: one person builds something, shows it around, generates enough excitement to get a few more people interested, and they contribute resources to build it out further. For the Goggles team, that happened easily. Almost everyone who saw the app walked away amazed by it. Two execs in particular became high-level champions of the idea: Vic Gundotra, a vice president of engineering, and Alan Eustace, a senior vice president of knowledge. They brought resources, energy, and ambition to Goggles. Googlers started to talk about how great it would be when the app was universal, when it could recognize anything and everything. \"Everyone at Google understood that this was possible, this was familiar, and yet transformative,\" Nalawadi remembers. \"That we were on the cusp of this thing, and it could be done.\" He likens it to self-driving cars: wild and futuristic, but also completely natural. Why shouldn't you be able to point your phone at something and ask, what's that? It felt inherently Google-y.\nGoogle launched Goggles as a public product in December of 2009, at an event at the Computer History Museum down the street from Google's Mountain View campus. The product demoed only had a few features: It could identify landmarks, works of art, and some consumer products, but little else. Google projected both caution and optimism about the product. It was part of Google Labs, and even in the app's setup it told you all the things it couldn't do. But everyone knew the plan. \"Google Goggles today works very well on certain types of objects in certain categories, but it is our goal to be able to visually identify any image over time,\" Gundotra said at the launch. \"Today you have to frame a picture and snap a photo, but in the future you'll simply be able to point to it...and we'll be able to treat it like a mouse pointer for the real world. \"\nInternally, though, the team behind Goggles was staring down a long list of problems with the technology. They knew that mouse-pointer future was years off, if it was even possible. \"We always knew it was more like a research project,\" one former engineer says. Even the most advanced computer vision was still quite primitive, and since Google hadn't yet begun to work deeply with machine learning and neural networks, all Goggles could do was pattern-match a photo against a database.\nSome of the problems weren't even Google's to solve. Smartphone cameras weren't yet great, nor were people very good at using them. And even when people took good photos, there were often lots of potentially interesting things in them; Google couldn't know if you cared about the tree, the bench, the puppy, or the sign in your shot. Text-recognition tech could help identify things, but even that was brand new. Curved or handwritten text challenged the algorithms, as did a model of car or any other object only identifiable by subtle differences. Logos were easy; plants were hard. Barcodes were simple; animals were impossible. Even things that did work just took too long over 3G.\nMost frustrating, Google couldn't even use the thing it did best, the most Terminator-y feature of all: facial recognition. \"If there are six or more pictures of you on the internet that are well-tagged, and you through our system take a seventh picture, you had 90 percent probability of the right answer being in the first ten search results,\" Nalawadi says. But Google knew it couldn't roll out the feature at a time when regulators and consumers were already beginning to worry about how much Google knew about them. Scarred from the launch of Google Buzz a few months earlier, which had been rife with privacy violations, they left facial recognition on the cutting room floor.\nEven as the team hammered away at the many mountainous tasks, Google kept preaching the Goggles gospel. In the summer of 2010, Petrou delivered a keynote address at the Hot Chips conference at Stanford, in which he laid out an even more exciting vision. About halfway through an otherwise deeply technical talk, Petrou flipped to a slide called \"Digression into Augmented Reality.\" The Goggles team had been thinking about AR for a while, it turned out. They figured if your camera could understand what it was seeing, it could potentially add more things into the scene. One former engineer recalled experimenting with how to identify things inside your viewfinder, so that when a car drove through your view, a small AR arrow that said \"Subaru\" might follow the car. Petrou, likewise, imagined a user standing on the famous Abbey Road crosswalk and watching the Beatles re-create their album cover in AR. Or, in another Terminator-inspired thought, he thought of how to amplify certain things in your view as if you're using a thermal camera.\nToward the end of that same talk, Petrou acknowledged what came to be the most important question facing Goggles, which would come to plague every company that worked on AR later. He put up that iconic image from Wall-E, a bunch of uniform-wearing obese people seated in chairs, sipping drinks and staring at screens. \"If this is our future, then maybe AR is not all that important,\" Petrou said. Augmented reality and image search only matter if people care about the world around them, and every trend of screen time says they're increasingly less so.\nThe Goggles team searched constantly for ways to get people using Goggles more often. Goggles became a Sudoku solver, a translation tool, and a barcode scanner, all to give people more reasons to return to the app. Petrou remembers working on a feature called \"Virtual Graffiti,\" where you could draw in AR and leave it somewhere for others to mind. The feature sounds virtually identical to the augmented-reality art Facebook showed off for its Facebook Camera platform in 2017. Google was years earlier to the idea, but never shipped it.\nGoogle continued developing Goggles, but progress soon stalled. The company had promised a full iPhone version of Goggles, but eventually inserted it into the Google app---and then quickly removed the feature. Google hardly talked about Googles after 2011. By 2012, the company had more or less shut down development.\nMost of the people I spoke to had differing ideas about what killed Goggles. One member of the team says they eventually saw the limits of the tech and just gave up. Another says people weren't yet comfortable with the idea of walking around holding their camera up all the time. But there was one other thing, the only one everyone mentioned, that may be the culprit.\nIn 2011, Google filed a patent application for a \"head-mounted display that displays a visual representation of physical interaction with an input interface outside of the field of view.\" That's a whole bunch of words, but the picture told the story: It was Google Glass. The name on the patent? David Petrou.\nPetrou says that \"we never questioned mobile phones\" as a useful place for visual search, but others say the Goggles team always knew smartphones weren't the ideal devices for their tech. Eventually, they figured, users would rather have a gadget they don't have to hold up or manage; a pair of glasses made sense. (Contacts seemed even cooler.) All that tech seemed years away, though, and would require big leaps in processing power, battery efficiency, and internet connectivity. They kept working on smartphones because smartphones worked.\nBut practicality didn't matter to everyone. One former member of the Goggles team told me that in part, Google executives liked Goggles simply because it was \"a whizzy demo.\" Then co-CEOs Larry Page and Sergey Brin loved showing Goggles to people, this person said, because it was new and nifty and futuristic. When Glass came along, promising not just camera-enabled search but a whole new kind of device and platform, Goggles paled in comparison. \"It was an even whizzier demo,\" the former engineer says.\nIndeed, Glass was touted far beyond any other Google product before or since. Brin interrupted a keynote address at the Google I/O conference in 2012 just in time to watch Glass-wearing skydivers fall through the air, land on the roof of the conference center, and ride BMX bikes into the auditorium. In a remarkable video titled \"One day...\" Google showed what a Glass-augmented life might look like. Brin even took Glass to the TED conference in 2013, passionately arguing for a future where gadgets free your eyes, hands, and ears rather than occupying them. Glass offered a complete and enticing view of the future, and inspired many inside and outside Google. Never mind that the tech didn't really work.\nPretty quickly, Nalawadi says, \"I think the momentum shifted to project Glass.\" A few Goggles employees even went to work on the team. Others went elsewhere: to Maps, to YouTube, to Google Now. Some left Google altogether. At some point, Goggles just wasn't a thing anymore. By mid-2014, nobody was left to even update the Android app.\nRight as Google gave up on Goggles, other companies began to see value in the idea. Snapchat launched in 2011 as a tool for sending disappearing messages, but quickly embraced smartphone cameras as a powerful platform. Pinterest hinged on turning images into search queries; pin a chair you like, and Pinterest helped you decorate your house. For Apple, Facebook, and others, augmented reality shifted from sci-fi impossibility to near-future product.\nEven within Google, the underlying technology wasn't going to waste. In fact, it was improving faster than ever. \"We had this big step-function jump because of deep learning,\" says Aparna Chennapragada, a senior director of product at Google. \"The same step-function jump we got with voice, we started seeing in image search.\" Thanks to its investment in AI chips, and Google's company-wide shift to AI thinking, results got better and improved more quickly1. The first result of the shift: Google Photos, with its powerful search and assistive abilities. (Here Google finally got to roll out its facial recognition, too.)\nAfter all these years, most of what held Goggles back has been solved. Smartphone cameras are excellent, as are the context-gathering sensors like gyroscopes and GPS that help anchor a user's position in the world. As a result, billions of users happily open their phone dozens of times a day to share memories, capture receipts, live-stream events, and save things to remember later. The back-end tech is faster, the front-end interfaces are easier. Nobody's wearing face-puters yet, but users don't mind doing it on their phones.\nAll that helps explain what happened in May of 2017, when Google CEO Sundar Pichai took the stage at the I/O developer conference and announced... Goggles again, basically. Only this time it's called Lens. \"Google Lens is a set of vision-based computing abilities that can understand what you're looking at, and help you take action based on that information,\" Pichai said. He gave demos: identifying a type of flower, or automatically connecting to Wi-Fi just by taking a picture of the username and password. So far, so Goggles. Including the fact that none of what worked in that video would be possible in the actual product anytime soon. Right now, Lens does the same things Goggles did in 2010, only much faster.\nIt's easy to wonder if Google squandered a years-long advantage in thinking about how people might want to use their camera. A few people in the company understood that users might someday want to explore the world through the screen of their phone. They might want to point their phone at something to understand it better, and might want to overlay the digital world on top of the physical one. Google may have known it first, but others beat it in the race to build something that captured the hearts and minds of users.\nStill, even if Google could have been earlier to the party, it's still not late. Google does have a huge set of intrinsic advantages, from its search-engine knowledge to its long history of collecting and personalizing data. And Google did learn a few lessons in the Goggles experiment. This time, Lens won't be a standalone app. Instead, the tech will course through lots of Google products. It helps you grab phone numbers or restaurant info from any shot in Google Photos. Soon, it'll be part of Google Assistant, helping you search for anything you need any way you want. Rather than make an app you may never open, Google's putting Lens everywhere you already, with the hope you'll discover it and use it.\nGoogle's made clear that Lens is a long-term bet for the company, and a platform for lots of use cases. Pichai compared Lens to Google's beginnings, how search was only possible because Google understood web pages. Now, it's learning to understand the world. You can bet that next time Google tries to put a computer on your face, Lens will be there. That'll make for quite a demo.\n1UPDATE: This piece now accurately reflects which parts of Google's AI investments directly contributed to its visual search projects."
    },
    {
      "url": "https://techcrunch.com/events/tc-disrupt-2025/?utm_source=tc&utm_medium=ad&utm_campaign=disrupt2025&utm_content=ticketsales&promo=tc_inline_rb&display=",
      "text": "TechCrunch Disrupt 2025\nTechCrunch Disrupt is where you\u2019ll find innovation for every stage of your startup journey. Whether you\u2019re a budding founder with a revolutionary idea, a seasoned startup looking to scale, or an investor seeking the next big thing, Disrupt offers unparalleled resources, connections, and expert insights to propel your venture forward.\nFind innovation for every stage at Disrupt 2025\nFrom idea to IPO, Disrupt 2025 will map out the path for startups to achieve their next major milestone.\nJoin 10,000 startup and VC leaders\nLooking to meet founders, connect with investors, seek advice, or land your next big role? Disrupt is the must-attend event to make it all happen in person.\nBuild and scale your business faster\nDisrupt is more than a startup launchpad \u2014 it\u2019s a growth accelerator. Dive into sessions on scaling, sales, and leadership, and connect with the investors and tech experts who can help take your business to the next level.\nGain insights from today\u2019s tech giants\nTap into the wisdom of founders and tech titans at Disrupt. From actionable tips to hard-won lessons, they\u2019ll share what works (and what doesn\u2019t) to guide you as you build your own path forward.\nDisrupt 2025 speakers\nPartner Sequoia Capital\nChief Technology Officer US Dept of Navy\nCEO and Co-Founder Writer\nChief Product Officer Netflix\nCEO Wayve\nCo-Founder & CEO Box\nFounder and CEO Pinecone\nCo-CEO Waymo\nCo-Founder ElevenLabs\nCaptain of Moonshots X, The Moonshot Factory\nI\u2019ve always thought, \u201cWhat can I do that opens up possibilities?\u201d I grew up in South Africa and went to an Afrikaans high school, and we didn\u2019t speak English at home. But I pushed myself to go to an English-speaking university, and that opened up a door. Then I chose to work for McKinsey, because I thought it would open another door and maybe I\u2019d get a chance to work overseas. I was reading about what was happening in Silicon Valley in the mid 90s, before I came to the U.S. Already, I\u2019m starting to see the beginnings of the internet. Did I fathom how big it would be? Absolutely not. I didn\u2019t know what venture capital was. I didn\u2019t know that I would join a startup. I just had an intuition that I needed to be here. A friend of mine introduced me to Elon in 1999 and I joined PayPal. Then when Mike Moritz asked me to come interview at Sequoia, that was just another door opening. Where might this one lead? Whenever I interview people, I ask about those key moments in somebody\u2019s life where they\u2019ve made career decisions. And I think about companies in the same way\u2014there are these crucible moments that have an enormous bearing on ultimate outcomes.\nRoelof's Sessions\nWhat Sequoia Sees Coming Next\nAs one of the most influential VCs of the modern era, Roelof Botha has seen it all; booms, busts, and billion-dollar breakout bets. In this fireside chat, the Sequoia Capital managing partner opens up about how today\u2019s most ambitious founders are navigating AI, geopolitics, and a shifting capital landscape.\nJustin Fanelli is the Chief Technology Officer for the Department of the Navy and Technical Director of PEO Digital, driving measurable technology improvements and secure, high-performance digital transformation. He champions private-public collaboration to deliver innovation with unprecedented value. Fanelli advises numerous national science and technology boards and has held key roles including Chief Architect for Defense Health, DARPA Service Chiefs Fellow, and Chief Systems Engineer for Joint Command and Control. He teaches at Georgetown and has lectured all over the country at CMU, MIT, Stanford and others. He recently gave a TED Talk on innovation adoption and the Innovation Adoption Kit covered by TechCrunch, Forbes, CSIS and others. Fanelli holds engineering degrees from Penn State and the University of Pennsylvania and is a Senior Executive Fellow at Harvard Kennedy School. He\u2019s been an angel investor, VC and has been privileged to serve on public and private boards. His work has earned national awards including the Etter Award, Fed100, Defense50, and CMMI Project of the Year. He lives in Arlington, VA and enjoys book recommendations.\nJustin's Sessions\nAI and National Security in the High-Stakes Race to Innovate\nFrom defense labs to Wall Street and naval operations, AI is reshaping how countries protect themselves and project power. DARPA\u2019s Kathleen Fisher, Point72\u2019s Sri Chandrasekar, and Navy CTO Justin Fanelli dive into the cutting-edge AI breakthroughs driving security innovation. They\u2019ll discuss what it means for entrepreneurs, investors, and the future of global stability.\nMay Habib is the CEO and co-founder of Writer, a leader and pioneer in enterprise AI. With Writer\u2019s end-to-end AI agent platform, hundreds of companies like Accenture, Mars, Uber, and Vanguard are building and scaling AI agents that are grounded in their company\u2019s data and fueled by Writer\u2019s enterprise-grade LLMs. From faster product launches to deeper financial research to better clinical trials, companies are quickly transforming their most important business processes for the AI era in partnership with Writer. Writer houses the world\u2019s only enterprise-specific AI research lab. Its family of enterprise-grade Palmyra LLMs includes state-of-the-art frontier models, as well as self-evolving, open-source, and domain-specific models. Palmyra models define industry-leading standards for enterprise-grade transparency, reliability, safety, efficiency, and observability. May is an expert in natural language processing and AI-driven language generation. She has led Writer to become one of the world\u2019s fastest-growing generative AI companies, securing its position as a Forbes 50 AI company and inclusion in the World Economic Forum\u2019s Unicorn Community. Founded in 2020 with its headquarters in San Francisco and offices around the globe, Writer is backed by world-leading investors, including Premji Invest, Radical Ventures, ICONIQ Growth, Insight Partners, Balderton, B Capital, Salesforce Ventures, Adobe Ventures, Citi Ventures, IBM Ventures, and others. May and the Writer team have raised over $326M in funding at a valuation of $1.9B. May graduated with high honors in Economics from Harvard University. She is a World Economic Forum Young Global Leader, a Fellow of the Aspen Global Leadership Network, a recipient of Inc.\u2019s Female Founder Award, and one of Worth\u2019s Groundbreaking Women for 2025.\nMay's Sessions\nWriting the Future with AI?\nWhat happens when AI learns to write with purpose, personality, and persuasion? Writer CEO May Habib joins us to talk about the evolving relationship between language and machines and what the rise of generative content means for the future of brand, business, and beyond.\nEunice Kim was named Chief Product Officer in October 2023. She previously led the company\u2019s global Consumer Product Innovation team. Eunice joined Netflix in early 2021 after having spent 10 years in product leadership roles at Google Play and YouTube. Prior to Google, she worked at several tech startups as well as PepsiCo and Adobe Systems. Eunice holds a B.A. from Columbia University and an M.B.A. from the University of Chicago Booth School of Business. She serves on the Board of Directors for Cure CMD.\nEunice's Sessions\nWhat's Next for Netflix and for Streaming Itself\nAs CPO of Netflix, Eunice Kim is steering the future of entertainment for hundreds of millions of users. In this fireside chat, Kim will break down how Netflix is evolving its product strategy\u2014from personalized discovery to global growth, from ad tiers to gaming. We\u2019ll explore how Netflix is adapting to a shifting content landscape, what it means to innovate at massive scale, and what design surprises Netflix has up its sleeve. For anyone building consumer experiences, this will be a masterclass.\nAlex co-founded Wayve in 2017 to reimagine autonomous mobility through embodied intelligence. From his award-winning research at the University of Cambridge, he seized the opportunity to use deep learning to pioneer an entirely new way to solve self-driving. He showed for the first time that it was possible to teach a machine to understand where it is and what\u2019s around it and then give it the \u201cintelligence\u201d to make its own decisions based on what it sees with computer vision. As CEO, Alex is responsible for the company\u2019s overall strategy, primarily focusing on establishing all necessary ingredients to develop and deploy AV2.0 globally. He also works closely with our partners and investors to ensure that our technology is commercially viable and can be widely adopted. Under Alex\u2019s leadership, Wayve is fast becoming one of the most exciting companies in the autonomous vehicle industry. Before founding Wayve, Alex\u2019s passion for autonomous vehicles began as a research fellow at the University of Cambridge, where he earned his PhD in Computer Vision and Robotics. His research has received numerous awards for scientific impact and made significant contributions to the field of computer vision and AI. He was selected on the Royal Academy of Engineering\u2019s SME Leaders Programme and named on the Forbes 30 Under 30 innovators list.\nAlex's Sessions\nDriving Intelligence\nFrom self-driving cars to self-learning systems, Alex Kendall is rethinking how machines perceive and act in the world. The Wayve CEO joins us to explore how real-world autonomy is shaping the next chapter of AI, and why breakthroughs on the road may unlock progress far beyond it.\nAaron Levie is Chief Executive Officer, Cofounder at Box, which he launched in 2005 with CFO and cofounder Dylan Smith. He is the visionary behind the Box product and platform strategy, incorporating the best of secure content collaboration with an intuitive user experience suited to the way people work today. Aaron leads the company in its mission to transform the way people and businesses work so they can achieve their greatest ambitions. He has served on the Board of Directors since April 2005. Aaron attended the University of Southern California from 2003 to 2005 before leaving to found Box.\nAaron's Sessions\nSurvive, Scale, Reinvent: Lessons from a Cloud OG\nAaron Levie built Box before cloud was cool and he\u2019s still standing while competitors have come and gone. Known for his sharp takes and startup instincts, Levie joins us to unpack how to keep innovating inside a public company, what AI really changes for enterprise software, and why reinvention is the name of the game in tech right now. Expect real talk and a playbook for building companies that last.\nEdo Liberty is the founder and CEO of Pinecone whose mission is to make AI knowledgeable. Pinecone is the leading vector database for building accurate and performant AI applications at scale in production. Prior to founding Pinecone, Edo was a Director of Research at AWS and Head of Amazon AI Labs where his team worked on data systems and services including SageMaker and OpenSearch. Before AWS, Edo was a Senior Research Director at Yahoo and Head of Yahoo\u2019s Research Lab in New York. As an adjunct professor at Princeton and Tel Aviv University, Edo taught long-term memory in AI and data mining. His academic work focuses on numerical linear algebra, streaming algorithms, data mining, and mathematical foundations of machine learning. Edo holds a B.Sc in physics and computer science from Tel Aviv University, and a Ph.D. in computer science from Yale. He has authored more than 75 academic papers and patents.\nEdo's Sessions\nWhy the Next Frontier Is Search\nIn a world overflowing with data, finding what matters is everything. Pinecone founder Edo Liberty unpacks why infrastructure, not algorithms, might be the biggest unlock in AI, and what\u2019s coming next in the race to power smarter applications at scale.\nTekedra N. Mawakana is the co-CEO of Waymo, an autonomous driving technology company. As co-CEO, Tekedra oversees the company\u2019s strategy for the wide adoption of the Waymo Driver. She boasts 20+ years of experience advising consumer technology companies to advance their business interests globally. Tekedra currently serves on the Board of Directors for Intuit and the Advisory Council for Boom Technology. She is a social impact-focused angel investor and an Advisor and LP with the Operator Collective.\nTekedra's Sessions\nThe Self-Driving Reality Check\nAutonomous vehicles have been \u201cjust around the corner\u201d for years\u2014until now. Tekedra Mawakana, Co-CEO of Waymo, takes the Disrupt Stage to talk about where AVs actually stand, what it\u2019s taken to get to real deployments, and why the race isn\u2019t just about tech, it\u2019s about trust. From regulation to rider experience to competition with Tesla and Tesla-adjacent hype, this conversation gets real about what\u2019s next in mobility.\nMati Staniszewski is the co-founder and CEO of ElevenLabs, a research company building audio AI tools to solve audio intelligence and make digital interactions feel more human \u2014 with voice as the most direct path to that. Before founding ElevenLabs, Mati worked at Palantir as a Deployment Strategist, managing large-scale implementations across public and private sectors, and at BlackRock, where he helped launch the Aladdin Wealth platform.\nMati's Sessions\nSynthetic Voices and Real Impact\nFrom audiobooks to avatars, synthetic speech is having a moment. ElevenLabs is helping lead the charge. CEO Mati Staniszewski joins us to explore what it takes to build AI that speaks like us and how voice technology is reshaping the creative industries, accessibility, and entertainment.\nDr. Astro Teller currently oversees X, Alphabet\u2019s moonshot factory for building breakthrough technologies and businesses designed to help tackle huge problems in the world. Before joining Google / Alphabet, Astro was the co-founding CEO of Cerebellum Capital, Inc, an investment management firm whose investments are continuously designed, executed, and improved by a software system based on techniques from statistical machine learning. Before his tenure as a business executive, Dr. Teller taught at Stanford University and was an engineer and researcher for Phoenix Laser Technologies, Stanford\u2019s Center for Integrated Systems, and The Carnegie Group Incorporated. Dr. Teller holds a Bachelor of Science in computer science from Stanford University, Masters of Science in symbolic and heuristic computation, also from Stanford University, and a Ph.D. in artificial intelligence from Carnegie Mellon University, where he was a recipient of the Hertz fellowship.\nAstro's Sessions\nMoonshots, AI, and the Future of Alphabet\nFrom self-driving cars to internet balloons to AI-fueled breakthroughs, Astro Teller leads the lab where Alphabet incubates the nearly impossible. In this rare Disrupt stage appearance, he shares what\u2019s actually working inside X, why \u201cfailing fast\u201d isn\u2019t just a mantra, and how moonshots may evolve in the AI age. If you think your startup is ambitious, wait until you hear what he\u2019s launching next.\nMore reasons to attend Disrupt\nFind Your Ticket Type\nFind the ticket type that fits you best with up to $600+ savings. Groups can save up to 30%.\nLatest TechCrunch Disrupt 2025 news\nPress/Media Passes\nEvery year, hundreds of top media outlets cover TechCrunch Disrupt \u2014 from independent reporters to veteran TC hosts. It\u2019s where the brightest voices in tech gather. Follow the steps below to apply for your free media pass.\nPartner with TechCrunch\nTechCrunch offers many ways for partners to engage directly with our attendees before, during, and after the event. Get in touch with us to learn more.\nLocation\nUpcoming TechCrunch events\n-\nGet on waitlist to get exclusive early access to limited tickets!\nTechCrunch Disrupt 2025 is innovation for every stage\n10,000+ tech leaders. 250+ sessions. 200+ speakers. 3 days. 6 stages. One epic experience of insights, strategy, and connections. Save up to $600+ before rates increase.\nSubscribe\nEvent Updates\nGet the latest event announcements, special discounts and other event offers.\nPartner with TechCrunch\nTechCrunch offers many ways for partners to engage directly with our attendees before, during, and after the event. Get in touch with us to learn more."
    }
  ],
  "argos_summary": "David Petrou, a former Google engineer and co-founder of Google Goggles and Google Glass, has launched a new startup called Continua, which focuses on enhancing group chat interactions using AI agents. The company recently raised $8 million in seed funding to develop technology that integrates large language models (LLMs) into group chats on platforms like SMS and Discord, aiming to streamline communication and reduce chaos. Petrou emphasizes the complexity of enabling AI to participate effectively in group discussions, highlighting Continua's potential to assist with planning and reminders.",
  "argos_id": "1K7U98QRH"
}