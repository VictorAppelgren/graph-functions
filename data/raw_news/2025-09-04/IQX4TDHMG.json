{
  "url": "https://www.cnet.com/tech/services-and-software/features/no-your-iphone-isnt-listening-to-you-heres-whats-really-happening/",
  "authorsByline": "Nelson Aguilar",
  "articleId": "58a7a24be18c4ff5bc5cbfb54d7e7297",
  "source": {
    "domain": "cnet.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "San Francisco",
      "city": "San Francisco",
      "coordinates": {
        "lat": 37.7790262,
        "lon": -122.419906
      }
    }
  },
  "imageUrl": "https://www.cnet.com/a/img/resize/0e65fa14707616290095173747eff6fa1b3613d5/hub/2025/09/03/70ff3f0c-a069-4814-bf0a-f9737dbcb8a5/hero-2-static.jpg?auto=webp&fit=crop&height=675&width=1200",
  "country": "us",
  "language": "en",
  "pubDate": "2025-09-04T12:00:07+00:00",
  "addDate": "2025-09-04T12:05:14.752284+00:00",
  "refreshDate": "2025-09-04T12:05:14.752287+00:00",
  "score": 1.0,
  "title": "No, Your iPhone Isn't Listening to You. Here's What's Really Happening",
  "description": "There are lots of reasons an ad pops up on your phone, but none involve a microphone listening.",
  "content": "The bartender's first hoot is so clean and high-pitched it sounds piped in from the ceiling speakers \u2014 a single whooo that slices through the post-punk and clinking glassware. My friend Michael jolts on his barstool, beer sloshing dangerously close to the rim.\n\n\"Did you hear that owl?\" he whispers.\n\n\"Not an owl,\" I say, matter-of-factly, wiping condensation from my glass before it drips onto the bar. The bartender, in his mid-30s with slicked-back hair and an immaculate black apron, lets out another whooo.\n\n\"It's Tourette's,\" I add quietly into his ear. He takes a long, slow swig of his hefeweizen, processing. I have a close family friend with a similar tic.\n\nWe let our conversation wander \u2014 plans for later that summer and the Lakers' offseason moves. Ten minutes in, he caves, as he usually does, checking a buzz from his pocket. He opens Instagram and stops, his confusion unmistakable.\n\n\"What?\" I ask, leaning in as the bartender slides us our check.\n\nFilling the screen of his iPhone 16 Pro Max, clad in a scuffed clear case, sits a sponsored post: \"Tourette Syndrome Awareness Month. Donate Today.\"\n\nMichael's voice drops into a register I don't usually hear outside ghost stories. \"We literally just talked about Tourette's. How did I get this ad already?\"\n\nI manage a laugh that's only half genuine. \"Your phone isn't listening to you.\" Even as I say it, I know how razor-thin the reassurance sounds. He signs the receipt, pockets the phone and mutters, \"So if my phone isn't listening, then what is it?\"\n\nIt's a question that has reverberated across countless conversations dating back to the start of the smartphone era two decades ago. Today's phones \u2014 from Apple's iPhone lineup to Androids from Samsung, Google, Motorola and others \u2014 are far more powerful and fully woven into the fabric of our daily existence, ever on standby to assist in all manner of tasks, but also reaching out to us through a steady stream of prompts and alerts.\n\nIt would be eerie if it weren't so commonplace.\n\nBut underlying the well-appreciated utility, there has always been a gnawing sense of unease. It's not just the phones themselves, but the sweeping online-ness of our lives, from our social media postings to our Amazon purchases, from our Snap Maps to our Google searches and ChatGPT queries. Technology knows us intimately, often too close for comfort.\n\nWhen a phone seems to be listening to us randomly, we're not wrong to feel like a boundary has been crossed. That feeling has created a wariness that just won't go away.\n\n\"This conspiracy theory has been going on for literally decades,\" says Serge Egelman, research director of the Usable Security and Privacy group at the Berkeley-affiliated International Computer Science Institute and co-founder of AppCensus, which audits mobile apps for privacy.\n\nOutside the bar, Beverly Boulevard shimmers under a neon glow in the lingering heat of an early-summer Los Angeles night. I tell my friend there are lots of reasons that ad appeared on his iPhone \u2014 but none of them involve a microphone listening.\n\nThe truth is actually very straightforward. Ordinary even. And that's even more unsettling.\n\n\"It's far more sinister than a hot mic,\" says Egelman.\n\nThere's no credible evidence that your phone runs a secret, always-on microphone to target ads, and there are clear technical and policy reasons why.\n\nIndependent researchers have gone looking for covert \"listening\" and found none, including a definitive 2018 Northeastern University study that has yet to be superseded. What they did catch in a handful of cases were screen recordings or image and video uploads to third parties. Creepy, sure, but not a hot mic.\n\nLaws matter, too. The federal Wiretap Act bans intercepting conversations without consent, and many states (like California) require all parties to consent, stacking civil and even criminal liability on covert, continuous capture. An \"always-listening for ads\" feature would constantly record non-consenting bystanders and invite massive legal exposure. I know that's not completely reassuring, but that's why it's implausible in practice.\n\nWhen I run the bar moment by ad-tech veteran Ari Paparo, he doesn't flinch. Paparo helped build the pipes \u2014 he founded the Beeswax DSP (acquired by Comcast's FreeWheel) and led product management at AppNexus/DoubleClick \u2014 so he's seen exactly how ad targeting really works.\n\n\"I'm very confident this is not happening. The phone is not actually listening to you,\" he says. \"I would say that 100% of my colleagues in the advertising world agree with me.\"\n\nI know that's a tough pill to swallow, but he offers the real and almost boring explanation for why it feels uncanny: People are predictable. \"The ads are attempting to guess what you're interested in,\" he says. \"It's all statistics.\"\n\nSimple version, for the record: Ads follow your behavior. No listening required.\n\nHere's why you get ads that feel like they're listening\n\nIt feels like your phone is listening because the systems that serve you ads thrive on your patterns \u2014 they don't need your whispered secrets. Here's the breakdown on how an eerily suspicious advertisement makes it to your phone.\n\nThink of four players working in sequence: platforms, advertisers, identity providers and data brokers. (There are extra middlemen, including publishers, ad exchanges, verification and measurement providers, doing more behind the scenes.)\n\nOne: The platform (Instagram, YouTube, Facebook, TikTok). This is home turf. The platform watches what you do inside the app: what you follow, linger on, save, search and tap on. It also knows basic context about you, like your rough location, device model, language and time of day, and it runs the auction that decides which ad you see. The platform's model predicts what you're likely to do next (scroll, tap, buy, donate, etc.) and ranks ads by a mix of price, predicted response and ad quality. If it thinks you're very likely to act, a lower-bid ad can beat a higher-bid one.\n\nTwo: The advertisers (brand, nonprofit, campaign). They bring a goal (clicks, purchases, donations), a budget and the creative (images, video, text). Many also bring their own customer lists \u2014 emails or phone numbers of past buyers or donors \u2014 which the platform hashes (turns into one-way fingerprints so it can look for matches without seeing the raw addresses) and tries to match to accounts. While hashing helps with privacy, it isn't the same as anonymity: Matches are still possible if both sides hash the same inputs. From there, the advertiser can ask the platform to find people who behave like those customers (lookalikes). They can also set simple guardrails: cities, ZIP codes, age ranges, schedule windows and \"don't show to people who already bought.\"\n\nThree: Identity providers (the matchmakers). These companies help link records that belong together \u2014 your email, your phone number, your connected TV, the laptop on your home Wi-Fi \u2014 without directly handing your name around. They keep identity graphs that say \"these devices likely belong to the same person or household,\" which helps advertisers measure whether an ad on one screen led to action on another. Think of them as the glue that makes cross-device campaigns and measurement possible.\n\nFour: Data brokers (the collectors and wholesalers). These firms (LiveRamp, Acxiom, TransUnion) buy, scrape and package information about you, then sell or license it to marketers and advertisers. There is no record as to how many data broker companies there are in the US, but there could be thousands (California keeps a public registry). They pull data from apps, websites and store loyalty programs, then ship ready-made audiences (\"visited auto lots,\" \"recent home-improvement shoppers\") or labels (\"new homeowner,\" \"pet owner\"). They work mostly out of sight \u2014 privacy policies often call the data \"de-identified.\" But once those files are matched to your account, the platform's system decides when to show you an ad.\n\n\"The unsettling feeling that your device is spying on you is real \u2014 but the culprit isn't a secret microphone. It's the data broker industry,\" Eva Galperin, director of cybersecurity for the Electronic Frontier Foundation, tells me.\n\nNow, stitch the pieces together in real time. You open Instagram. The app asks, \"What ad should we show right now?\" The platform checks your in-app behavior and context, sees which advertisers are aiming for people like you (including those using matched customer lists or broker-supplied groups) and runs an instant auction to show you an ad.\n\nIf you and a friend are on the same Wi-Fi or have been on the same household network, both of you may fall into the same target bucket. If you're near a TV where a campaign just ran, that can raise the odds too \u2014 co-location and household signals say \"these folks influence each other.\"\n\nBudgets also matter. Money tends to concentrate in hours and places where the model expects better results, so delivery clusters in time. That's why an ad can land the same night you talked about a topic, because the system already had reasons to try you tonight, and you happened to be scrolling when the budget was flowing.\n\nThere are valid reasons why so many people believe that their phones listen to them. It goes beyond the phones themselves to the wider array of devices waiting for us to speak to them, like Amazon's Alexa smart speakers.\n\nIn 2019, an Apple contractor revealed that they were regularly listening to audio recordings, which sometimes included snippets of ongoing drug deals or people having sex, as part of a \"grading process\" to improve recognition for the Siri voice assistant. After public backlash, Apple apologized, paused the program and later made it opt-in. Apple agreed to a 2025 settlement, while denying wrongdoing and claiming Siri audio isn't used for ads.\n\nIn the same year, a Belgian broadcaster revealed contractors could hear snippets of Google Assistant recordings, reporting showed Amazon teams listened to some Alexa recordings and Facebook paid contractors to transcribe snippets of opt-in voice chats.\n\nThese incidents mostly involved quality reviews of virtual assistants and, in some cases, non-phone devices \u2014 not covert ad targeting by your phone's mic. But they were vivid and mishandled enough to make \"always listening\" still feel plausible today.\n\n\"People complain Alexa or Siri don't understand them, yet believe they can perfectly overhear conversations to target ads,\" says Egelman. \"That's cognitive dissonance, not evidence.\"\n\nAdding fuel to the fire, last year a leaked Cox Media Group pitch deck touted an \"Active Listening\" ad product that would target ads based on ambient audio. After the coverage, Google dropped CMG from its partner program. CMG later said the product had been discontinued, and it denied using device microphones in that way.\n\nEven so, it kept the listening narrative in headlines, despite platforms publicly disavowing it.\n\nHow advertising feeds on your data\n\nAgain, the reason we see those ads is simple: It's all about data.\n\nData is one of the world's most valuable resources, up there with oil and water. Digital ads are a massive business \u2014 marketers spent nearly $1.1 trillion on advertising in 2024, with the biggest share going to digital.\n\nLook at the leaders. Meta booked about $162 billion in ad revenue in 2024 \u2014 nearly all of its sales. Amazon made $15.7 billion from advertising in just the second quarter of 2025 (up 22% year over year). Walmart's retail media arm pulled in $4.4 billion in 2024 and is still growing fast.\n\nAll this money flows because data makes ads predictable: who to reach, when to show up and and whether it worked. The better the data, the better the predictions, the more the platform can charge. That's why the \"ad machine\" keeps investing in first-party data and AI. And to get that data, no one needs to eavesdrop through a microphone.\n\n\"In reality, devices are tracking you in other ways,\" says the EFF's Galperin.\n\nWe supply everything the ad machine (platforms, brokers, retailers and so on) needs, often without realizing it.\n\nThey work together to turn ordinary traces into timing. Your actions become labels; those labels group you with others who have similar profiles: an audience. That group yields a prediction: the ad you see. The app remembers what you do, the advertiser brings a list of people it already knows, a broker matches the dots and the pipes decide \u2014 in a blink \u2014 whose ad to show you.\n\nThat's why an ad can arrive with unnerving precision, as if it overheard you. It didn't. It read your week, and it had great timing.\n\nBack to that Tourette's ad at the bar. Here's the boring path that likely put it there.\n\nIn Instagram's split-second auction, my friend's in-app behavior (previous donations, affinity for mental health) and context (late, in LA, scrolling) met whatever the advertiser brought \u2014 probably a matched list of past donors or newsletter signups, plus a lookalike built from them. A data broker may have added fuel: prebuilt cause- or health-interest groups, or extra labels added to those donor lists, matched by hashed (scrambled) emails or phone numbers.\n\nIf we were on the same Wi-Fi or had been in the same places that week, co-location/household signals could have nudged both of us into range. The model picked the moment.\n\nMeta even surfaces some of this in-app. Tap \"Why am I seeing this ad?\" and you'll often see a plain-English reason tied to your activity or the advertiser's audience.\n\nWhen asked for comment, Meta pointed CNET to an explainer in its Privacy Center: \"We only use your microphone if you've given us permission and are actively using a feature that requires the microphone.\" The company also noted its page on what data it uses for ads and the ad controls available to users.\n\nYour mind plays tricks on you\n\nBut the uncanniness of it all isn't just what's in your phone. It's what's in your head as well.\n\nOnce a topic is on your mind, you start spotting it everywhere \u2014 it's known as the frequency illusion, sometimes referred to as the Baader-Meinhof phenomenon. Linguist Arnold Zwicky coined the term. Once you notice something new, you start seeing it everywhere.\n\nIn 2022, I purchased a 1986 Mercedes-Benz 560SL. A few weeks later, I started noticing the car on every block \u2014 or at least it felt that way. Did the city of Los Angeles buy a fleet of my car overnight? No. What's more likely is that I joined a club and started seeing the members.\n\nAfter this recognition, confirmation bias takes over. You remember the eerie hit \u2014 the ad that lands right after the conversation \u2014 but you discard the thousands of misses before that. The story writes itself: We said it and then you saw it. Therefore, the phone must have listened.\n\n\"What is happening is targeted advertising \u2014 and some of it is cognitive biases,\" says Egelman, the privacy researcher. \"Your friend probably doesn't make note of all of the irrelevant ads he sees.\"\n\nWe all miss the things we're not expecting to encounter. Research into inattentional blindness (the \"gorilla\" strolling through a basketball drill) shows how attention edits reality. Most of the advertisements stream by, but the one aligned with what's top of mind pops out as if it were placed just for you.\n\nYou scrolled past the advertisements for an irrelevant airline credit card and Japanese selvedge denim, but you noticed the trip to Cancun, because well, you just talked about going to Cancun to your best friend.\n\nAdd two mental shortcuts: availability heuristic (vivid examples feel more common) and illusory correlation (when two things happen together, we assume they're linked). Then confirmation bias seals it.\n\nOnce you name those biases, the spell weakens. And you see how it really works. I started collecting other coincidences.\n\nMy friend kept getting fish tank ads after talking to her personal trainer about fish tanks. They have each other's contacts saved in their phones and my friend is already a pet owner, so it tracks.\n\nMy mom swears she received knee brace ads seconds after talking to her friend about knee pain. She had knee surgery two years ago, and she probably googled something about knee pain recently, which she has no recollection of, obviously.\n\nI received an advertisement for very specific baby-blue Rimowa carry-on luggage after talking about it to a friend. I've owned Rimowa luggage before, and not only that, but I'm visiting Germany in the fall, so it makes sense I would receive a travel ad of some sort.\n\nOne of the clearest reality checks came from a Northeastern University team that tested about 9,100 Android apps back in 2018 and watched what actually left the phone. It found no evidence of apps secretly recording and shipping audio to ad networks. When data did leak, the surprises were different: a handful of screen recordings and image or video uploads to third parties, and voice assistants that sent text transcripts, not raw audio, for processing.\n\nLast month, I caught up with the researcher who led that study.\n\n\"The thing we didn't expect was screen recording \u2014 it was like someone looking over your shoulder, and that data went to a third-party's servers, not the app you were using,\" says David Choffnes, a professor of computer science at Northeastern and executive director of the university's Cybersecurity and Privacy Institute.\n\nCNET did some informal testing of its own back in 2019. There was no indication that Facebook was listening in on conversations as a trigger for serving ads.\n\nA true hot mic would leave fingerprints. If something were siphoning audio 24/7, you'd notice it in your bill, your battery widget and your status bar long before a conspiracy TikTok video \"explained\" it.\n\n\"That can't be happening. \u2026 Your phone would be constantly streaming audio,\" says Egelman. \"It would show up on your bill, and your battery would not last very long.\"\n\nSmart speakers are also to blame for the conspiracy theory. Yes, they are \"always listening,\" but only for a wake word. Until that match fires, nothing is supposed to leave the house. Amazon says Echo devices detect the wake word locally and don't store or send audio to the cloud unless activation occurs. The company also says that voice history can be reviewed/deleted and interactions can inform relevance for ads with Alexa, although you can opt-out.\n\nYour phone also keeps a tiny listener running, but it's not what you think. A small, on-device model sits in standby and listens only for the wake words. On the iPhone, Apple's own research describes it as a lightweight recognizer that runs all the time and wakes the full system only when it hears \"Hey Siri.\"\n\nAndroid devices do the same with \"Hey Google.\" Google explains that Assistant waits in standby, processing a few seconds of audio locally to detect the trigger. If no activation is detected, nothing is sent or saved. Only after activation does the device record your request and send it for fulfillment (and by default, those audio recordings aren't even saved to your account). According to Google, its consumer devices don't use ambient sound for ad personalization. Many devices use a low-power digital signal processor for this precisely so it won't drain your battery or beam ambient chatter anywhere.\n\nApple says it has never used Siri data to build marketing profiles or make it available for advertising. Google's Assistant page spells out the same architectural boundary: standby doesn't ship your audio; activation is explicit, reviewable and controllable in settings. Wake-word engines exist to launch a helper, not to feed an ad slot.\n\nYes, false triggers and misfires happen. The system can mishear the wake words and briefly record before you cancel. But that's a quality-of-assistant problem, not an ad-targeting pipeline. You can delete those interactions and even tighten sensitivities.\n\nChoffnes also co-authored a 2020 test that pumped 134 hours of TV audio at Amazon, Google, Apple and Microsoft speakers while watching the light rings and network traffic. They saw no 24/7 recording \u2014 just occasional false wakes, usually a few seconds, with a few longer outliers. When a device did wake, it typically sent that short clip to the company's cloud servers for processing.\n\nIn other words, \"sent to the cloud\" means the speaker thought it heard the wake word and uploaded a brief recording so the assistant could interpret it. That confirms short clips can exist on vendor servers (and, on some platforms, be reviewed or deleted), but it's not a continuous microphone or an ad-targeting pipeline.\n\n\"This was mostly a good-news story: we found no evidence of constant recording \u2014 just short, triggered clips when a device thought it heard the wake word,\" says Choffnes. \"Bottom line: For the most part, most consumers shouldn't be concerned about pervasive listening.\"\n\nThe part that sticks is the mood that smart speakers create. Once you live with a device that can wake on a word, every well-timed ad on your phone feels like the same mechanism at work.\n\nHow did we get here, to this place where advertisements work so incredibly well that we swear it could only happen by our phones secretly listening to us?\n\nBefore the models we have now, there were cookies. In the early days of the internet, web pages were like goldfish \u2014 no memory between clicks. So cookies showed up as a convenience feature to keep your shopping cart intact, remember your logins and save your language preference. First-party cookies did that housekeeping just fine.\n\nThen came the side doors. Ad networks and analytics firms set third-party cookies and tiny \"pixels\" on lots of sites, which let them recognize the same browser across the web. That's when the web started to feel like a hall of mirrors. You looked at a toaster once, and the toaster followed you for a week.\n\nMobile devices then complicated the trick. Apps don't use browser cookies, so platforms leaned on mobile ad IDs, and more importantly, their own logged-in universes. Add the rise of retail media \u2014 ads tied to actual receipts \u2014 and you get precise targeting without passing identities around.\n\nThe more the industry traded IDs for inference \u2014 scores, cohorts, household context \u2014 the more ads arrived with uncanny timing and fewer obvious breadcrumbs. To you, that feels like eavesdropping. To the system, it's just the next step after cookies: less about who you are, more about what the math thinks you'll do next.\n\nPlatforms aren't just placing ads, they're making them. Meta's Advantage Plus suite includes generative AI tools for ad creative. Google's Performance Max can generate headlines, descriptions, and images and video variants. Amazon Ads ships image and video generators so a product photo turns into lifestyle scenes in minutes.\n\nUnder the hood, measurement keeps drifting from identity to intent. More math runs on-platform or on-device (think Apple's privacy-preserving attribution), so less raw data sloshes around. What you feel is the same: a score appears at decision time \u2014 likelihood to donate tonight: 0.62 \u2014 and the system spends accordingly.\n\nAI will keep tightening the timing and tailoring the message, so ads will feel even more like they \"heard\" you. They didn't. They modeled you.\n\nIs this all something to truly be scared of?\n\nI'm not worried about my phone listening to me, but there is something that disturbs me. It's the shadow I leave behind on the internet \u2014 a \"ghost profile\" stitched together from my clicks, searches, locations and card swipes.\n\nData brokers are the ones who make that ghost useful. That's how the shadow becomes actionable \u2014 brokers say who, identity tools say which account and the platform says now.\n\nSensitive location data is the first tripwire. Regulators have warned that brokered phone location trails can reveal visits to reproductive health clinics, houses of worship, shelters and recovery centers. The Federal Trade Commission's lawsuit against data broker Kochava lays that out in plain terms. The agency says selling this data exposes people to stigma, stalking, discrimination and even physical harm.\n\nThen come the workarounds. When agencies can't easily get data with a warrant, some have bought it instead. Records obtained by the ACLU show Department of Homeland Security components (including CBP and ICE) purchasing access to phone location records after the Supreme Court's Carpenter ruling made warrantless cell-site tracking tougher.\n\nBrokers' \"anonymized\" files can also be used to out or coerce individuals. In 2021, a senior Catholic official resigned after reporters obtained location-based app data \u2014 purchased from a broker and linked to a device that frequented gay bars and used Grindr \u2014 illustrating how readily \"anonymous\" trails can be tied back to a person.\n\nAnd the fallout isn't limited to embarrassment. Profiles that time an ad can also shape prices and eligibility. US prosecutors forced Meta to overhaul its housing-ad delivery system after alleging the algorithmic tools could produce unlawful demographic skews. Regulators have flagged similar risks in employment and credit contexts.\n\nAnd location brokers have marketed feeds and services to government and military customers, underscoring how easily ad tech exhaust crosses into surveillance use cases. Reporting has also documented the US military buying app location data from brokers like Babel Street and X-Mode for \"counter-terrorism\" purposes.\n\nOnce the shadow profile exists, it's portable. That's the danger beyond ads.\n\nHow to protect yourself\n\nWhat can we do about all of this?\n\nStart by cutting down the data you give off each day. In your web browser, run a tracker blocker like uBlock Origin alongside a behavior-based add-on such as EFF's Privacy Badger. \"I recommend using both together. I use them all the time,\" says Galperin.\n\nOn your phone, do a quick permission audit every few months: set Location to \"While Using the App\" (and Approximate when you can), revoke mic/camera for anything that doesn't need it and delete the apps you never open. iPhone users can skim Settings > Privacy & Security > App Privacy Report to spot noisy apps, and Android's Privacy Dashboard shows timestamped mic/camera/location access.\n\nYou won't vanish, but you'll close some doors. As Galperin likes to put it, the easiest win is simple: turn off location services unless you truly need them.\n\nAnother effective move is subtraction. Fewer apps means fewer places collecting data about you. When something asks for access, give it the minimum it needs. Skip contact uploads and \"Find Friends,\" avoid signing in with the same identity everywhere, and use email aliases for newsletters and loyalty signups so profiles don't fuse by default.\n\n\"Only install and use apps that you really need,\" says Northeastern's Choffnes. \"When they're asking for permissions to access data or asking you to enter data, try to enter as little as you can get away with.\"\n\nIn some states, you can file data-subject access requests to see what companies hold about you and who they share it with. On Instagram, for example, you can go to your profile > three-dash menu > Accounts Center > Your information and permissions and export all the information Instagram has on you, including content and information you've shared and activity and info Instagram collects.\n\nWhen I downloaded my data, I was able to see my activity that Meta tracked outside of its apps, including online purchases, information I've submitted to advertisers (included my address), categories associated with my activity (engaged shopper, household income, travel plans) and a list of advertisers using my activity or information to show me ads.\n\nYou can also pull some data back. If doing it yourself isn't realistic, data-deletion services (such as Easy Opt Out and Optery) will file broker opt-outs on your behalf. They're imperfect and they're not one-and-done \u2014 brokers replenish constantly \u2014 which is why Galperin calls it a \"constant cat-and-mouse game.\" Do it anyway, because trimming the broker trail reduces how precisely systems can time you.\n\nBeyond that it becomes a public policy matter.\n\n\"The idea that this is an individual's responsibility is ridiculous. It's highly technical and adversarial,\" says Christo Wilson, professor and founding member of the Cybersecurity and Privacy Institute at Northeastern, who also worked on the 2018 study. \"I'm an expert and I'm still exposed. No individual can win against an ecosystem built to surveil.\"\n\nThe myth survives because it flatters us\n\nIn the past few months, I've had the same exchange with friends, cousins, Uber drivers, a woman at a kid's birthday party, a drunk guy on a bar patio who swore his phone had betrayed him. They lean in and tell me about the ad that materialized right after a conversation, the one so on the nose it felt like a dare.\n\n\"Your phone isn't listening to you,\" I say. \"It's timing.\" I tell them it's data and context and a system that's really good at guessing.\n\n\"I don't believe that,\" they say, almost every time.\n\nI get it. A secret microphone is a better story than a spreadsheet with great aim. A villain you can point to beats a vast spider web you can't see.\n\nHere's a metaphor to try out: Think of the city as a weather radar. Every tap, swipe and purchase you make is a little blip. Most evaporate. Some cluster. When the storm cells line up, the system flashes an alert. That flash is the ad. It didn't hear thunder \u2014 it saw the pattern and predicted it.\n\nOn my phone, meanwhile, my feed is a conveyor: little rectangles, arguments and declarations about what I might do if nudged just right. I tap one, save another and linger on a third without meaning to. It's nothing. It's everything. It's a fresh addition to the profile that's already following me around.\n\nI think this myth survives because it flatters us. It says we're interesting enough to spy on, significant enough to bother. But the truth is plainer and, somehow, more intimate: We are legible. Not to a person with headphones in a van, but to a system that grades our likelihoods and gets paid when it's right.\n\nIf you want a monster, it's not a microphone. It's the quiet arithmetic that reads your week, guesses your mood and launches a message at the exact second it thinks you're most likely to swallow it.\n\nI wish the explanation landed cleaner at the bar, at the party, on the sidewalk. People want to believe in the listening because it puts the cause in the room with them. The ad-tech model is almost ethereal, which makes it hard to place, and seemingly impossible to escape.\n\nBut we're not haunted. We're forecast.",
  "medium": "Article",
  "links": [
    "https://www.icsi.berkeley.edu/icsi/people/egelman",
    "https://www.facebook.com/business/help/2082575038703844?id=2469097953376494",
    "https://www.ftc.gov/news-events/news/press-releases/2022/08/ftc-sues-kochava-selling-data-tracks-people-reproductive-health-clinics-places-worship-other",
    "https://help.instagram.com/181231772500920",
    "https://aripaparo.com",
    "https://machinelearning.apple.com/research/hey-siri?",
    "https://datareportal.com/reports/digital-2025-sub-section-global-advertising-trends",
    "https://www.cnet.com/tech/mobile/apple-hits-pause-on-siri-review-process-that-had-workers-listen-to-recordings/",
    "https://www.eff.org/about/staff/eva-galperin",
    "https://web.stanford.edu/~zwicky/LSA07illude.abst.pdf",
    "https://www.cnet.com/tech/computing/facebook-isnt-secretly-listening-in-on-your-phone-conversations-really/",
    "https://www.cnet.com/tech/mobile/iphone-17-rumors-everything-to-know-from-redesigned-cameras-to-an-upgraded-display/",
    "https://safety.google/assistant/",
    "https://petsymposium.org/popets/2018/popets-2018-0030.php",
    "https://www.cnet.com/tech/mobile/apple-iphone-16-pro-and-pro-max-review-compelling-upgrade-with-my-favorite-iphone-feature-in-years/",
    "https://oag.ca.gov/data-brokers",
    "https://www.cnet.com/home/smart-home/googles-smart-home-devices-are-finally-getting-geminis-ai-skills/",
    "https://www.freewheel.com/news/freewheel-to-acquire-ad-tech-leader-beeswax",
    "https://www.cnet.com/personal-finance/this-is-your-last-day-to-claim-a-piece-of-apples-96-million-siri-settlement-heres-how/",
    "https://www.apple.com/newsroom/2025/01/our-longstanding-privacy-commitment-with-siri/?",
    "https://www.icsi.berkeley.edu/icsi/groups/privacy",
    "https://www.cnet.com/home/smart-home/alexa-sent-private-audio-to-a-random-contact-portland-family-says/",
    "https://www.justice.gov/archives/opa/pr/justice-department-secures-groundbreaking-settlement-agreement-meta-platforms-formerly-known",
    "https://moniotrlab.khoury.northeastern.edu/publications/smart-speakers-study-pets20/",
    "https://www.cnet.com/tech/mobile/top-us-catholic-church-official-resigns-amid-link-to-brokered-cellphone-data/",
    "https://help.instagram.com/609473930427331",
    "https://www.eff.org",
    "https://www.cnet.com/tech/mobile/supreme-court-says-warrant-necessary-for-phone-location-data/",
    "https://cbw.sh",
    "https://www.facebook.com/privacy/dialog/is-facebook-listening-to-my-conversation",
    "https://www.optery.com/?utm_source=google-ads&utm_campaign=New-Branded-Search-Beta&utm_agid=131341180480&utm_term=optery&creative=560443328282&device=c&placement&gad_source=1&gad_campaignid=15039018404&gbraid=0AAAAAoKgTZ6uXhD2fRvpimwNHr8_f04Y_&gclid=Cj0KCQjwn8XFBhCxARIsAMyH8Bv1URW_8Ra8ngC-T9YmeAI2U1XmAmwA4wg5tSLILl5LawUaucf209waAnxVEALw_wcB",
    "https://www.cnet.com/tech/mobile/best-android-phone/",
    "https://www.theguardian.com/technology/2019/jul/26/apple-contractors-regularly-hear-confidential-details-on-siri-recordings",
    "https://www.cnbc.com/2019/07/11/google-admits-leaked-private-voice-conversations.html",
    "https://arstechnica.com/information-technology/2020/07/uncovered-1000-phrases-that-incorrectly-trigger-alexa-siri-and-google-assistant/",
    "https://www.sec.gov/Archives/edgar/data/1326801/000132680125000017/meta-20241231.htm",
    "https://recon.meddle.mobi/papers/panoptispy18pets.pdf",
    "https://appcensus.io",
    "https://www.theguardian.com/technology/2019/apr/11/amazon-staff-listen-to-customers-alexa-recordings-report-says",
    "https://www.marketingdive.com/news/amazons-ad-business-stays-strong-as-ctv-dsp-offerings-improve/756562/",
    "https://www.facebook.com/privacy/guide/ads/?entry_point=privacy_center_home",
    "https://david.choffnes.com",
    "https://ads.apple.com/app-store/help/attribution/0028-measuring-ad-performance",
    "https://www.cnet.com/news/privacy/we-tried-to-get-facebook-to-send-us-ads-based-on-our-conversations/",
    "https://www.pbs.org/newshour/nation/facebook-paid-contractors-to-transcribe-users-audio-clips",
    "https://easyoptouts.com/",
    "https://www.cnet.com/tech/mobile/best-phone/",
    "https://www.youtube.com/watch?v=vJG698U2Mvo",
    "https://www.aclu.org/news/privacy-technology/new-records-detail-dhs-purchase-and-use-of-vast-quantities-of-cell-phone-location-data",
    "https://www.theguardian.com/commentisfree/article/2024/sep/04/yes-it-sounds-like-a-conspiracy-theory-but-maybe-our-phones-really-are-listening-to-us",
    "https://www.businessinsider.com/us-military-location-data-muslim-prayer-app-xmode-babel-street-2020-11",
    "https://safety.google/intl/en_us/assistant/",
    "https://www.adexchanger.com/commerce/walmarts-ad-business-cleared-4-billion-in-2024-and-is-only-getting-started/",
    "https://bja.ojp.gov/program/it/privacy-civil-liberties/authorities/statutes/1285"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Ads",
      "weight": 0.067073755
    },
    {
      "name": "ads",
      "weight": 0.067073755
    },
    {
      "name": "ad targeting",
      "weight": 0.06590107
    },
    {
      "name": "Ad networks",
      "weight": 0.06539337
    },
    {
      "name": "ad networks",
      "weight": 0.06539337
    },
    {
      "name": "Digital ads",
      "weight": 0.06491162
    },
    {
      "name": "ad exchanges",
      "weight": 0.064808905
    },
    {
      "name": "ad quality",
      "weight": 0.064758904
    },
    {
      "name": "ad revenue",
      "weight": 0.06401495
    },
    {
      "name": "ad personalization",
      "weight": 0.063807145
    }
  ],
  "topics": [
    {
      "name": "Electronics"
    },
    {
      "name": "iPhone"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.51513671875
    },
    {
      "name": "/Computers & Electronics/Software/Operating Systems",
      "score": 0.41357421875
    },
    {
      "name": "/Internet & Telecom/Mobile & Wireless/Mobile Phones",
      "score": 0.407958984375
    }
  ],
  "sentiment": {
    "positive": 0.15136312,
    "negative": 0.42048556,
    "neutral": 0.42815128
  },
  "summary": "The article discusses the conundrum of whether your iPhone is listening to you, or not, according to Serge Egelman, research director of the Usable Security and Privacy group at the Berkeley-affiliated International Computer Science Institute and co-founder of AppCensus, which audits mobile apps for privacy. Despite independent researchers looking for covert listening, they have found no evidence. The article also discusses the implications of the federal Wiretap Act on conversations without consent, ongoing criminal liability, and potential legal exposure. The author concludes that while technology is often too familiar with our lives, it is often more unsettling than a hot mic.",
  "shortSummary": "A recent study found no evidence of phone spying, highlighting widespread privacy concerns and societal impact, while highlighting potential privacy concerns in technology.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "9bde60a155074a46b79ab3838e22fdea",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.theguardian.com/technology/2019/apr/11/amazon-staff-listen-to-customers-alexa-recordings-report-says",
      "text": "When Amazon customers speak to Alexa, the company\u2019s AI-powered voice assistant, they may be heard by more people than they expect, according to a report.\nAmazon employees around the world regularly listen to recordings from the company\u2019s smart speakers as part of the development process for new services, Bloomberg News reports.\nSome transcribe artist names, linking them to specific musicians in the company\u2019s database; others listen to the entire recorded command, comparing it with what the automated systems heard and the response they offered, in order to check the quality of the company\u2019s software.\nTechnically, users have given permission for the human verification: the company makes clear that it uses data \u201cto train our speech recognition and natural language understanding systems\u201d, and gives users the chance to opt out. But the company doesn\u2019t explicitly say that the training will involve workers in America, India, Costa Rica, and more nations around the world listening to those recordings.\nIn a statement given to Bloomberg, Amazon said: \u201cWe take the security and privacy of our customers\u2019 personal information seriously. We only annotate an extremely small sample of Alexa voice recordings in order [to] improve the customer experience. For example, this information helps us train our speech recognition and natural language understanding systems, so Alexa can better understand your requests, and ensure the service works well for everyone.\n\u201cWe have strict technical and operational safeguards, and have a zero-tolerance policy for the abuse of our system. Employees do not have direct access to information that can identify the person or account as part of this workflow. All information is treated with high confidentiality and we use multi-factor authentication to restrict access, service encryption and audits of our control environment to protect it.\u201d\nAmazon has long insisted Alexa can only send recordings back to Amazon\u2019s servers if the device hears its \u201cwake word\u201d, such as \u201cAlexa\u201d or \u201cEcho\u201d (or is manually activated by the press of a button), and there is no suggestion in Bloomberg\u2019s report that this is not the case. However, as any user of a smart speaker knows, ambient noise can be mistaken for the wake word, triggering the recording by accident.\nAs a result, workers occasionally hear things they shouldn\u2019t. Sometimes, that means private information such as bank details or full names, which employees are supposed to flag as critical data. Other times, there\u2019s no clear procedure: two employees told Bloomberg they heard \u201cwhat they believe was a sexual assault\u201d. Amazon reportedly told them it wasn\u2019t the company\u2019s job to interfere.\nAlexa isn\u2019t the only AI service that relies on heavy use of human labour. The fusion of the organic and digital is common across the sector, either to train services in how to provide new features, or to secretly fill in gaps in their capabilities without disclosing that fact to users.\nFor instance, in 2017, the business expense management app Expensify admitted that it had been using humans to transcribe at least some of the receipts it claimed to process using its \u201csmartscan technology\u201d, while Facebook was more open about the fact that a short-lived personal assistant, M, was an explicit blend of human and automatic responses.\nIt is not the first time Amazon has been found to be relying on human labour for its smart services. Earlier this year, the Intercept reported that the company\u2019s Ring-branded smart doorbells provided their R&D team with \u201cvirtually unfettered access \u2026 to every video created by every Ring camera around the world\u201d."
    },
    {
      "url": "https://www.cnet.com/tech/mobile/apple-hits-pause-on-siri-review-process-that-had-workers-listen-to-recordings/",
      "text": "Apple is suspending its Siri grading process globally while it conducts a review. The move comes after a report last week in The Guardian said a team of contractors around the world listens to a random, small subset of the recordings Siri hears after people push its activation button or say \"Hey Siri,\" to check the voice assistant's accuracy and response. Apple also said it plans to give users the option to opt out of Siri grading in the future.\n\"We are committed to delivering a great Siri experience while protecting user privacy ,\" said an Apple spokesperson in a statement. \"While we conduct a thorough review, we are suspending Siri grading globally. Additionally, as part of a future software update, users will have the ability to choose to participate in grading.\"\nApple's decision to suspend the program was reported earlier by TechCrunch.\nThe iPhone maker's attempts to improve Siri aren't much different from actions at Amazon and Google, which similarly ask reviewers to analyze some recordings made with their respective voice assistants. Each of the companies says it's a key way to help improve their systems.\nThe Siri recordings sometimes include private conversations such as discussions with doctors and sexual encounters, according to The Guardian. The recordings don't have identifiable information, Apple told the paper, and they're analyzed in secure facilities.\nApple has positioned its services and devices as bastions of privacy at a time when tech companies, including Facebook and Google, are under increased scrutiny for how they collect and distribute people's data. The company keeps Siri recordings for two years, though certain markers are removed from the file after six months."
    },
    {
      "url": "https://moniotrlab.khoury.northeastern.edu/publications/smart-speakers-study-pets20/",
      "text": "WHEN SPEAKERS ARE ALL EARS\nUnderstanding when smart speakers mistakenly record conversations\nDaniel J. Dubois (Northeastern University), Roman Kolcun (Imperial College London), Anna Maria Mandalari (Imperial College London), Muhammad Talha Paracha (Northeastern University), David Choffnes (Northeastern University), Hamed Haddadi (Imperial College London)\nLast updated: 07/21/2020\nNEWS\n- 07/21/2020. Videopresentation available\n- 07/09/2020. This page has been updated with the new findings we published in the recently accepted PETS2020 paper. Previous findings have been superseded by the new ones as we improved our analysis technique. The previous version of this page with preliminary findings is still available.\n- 06/24/2020. This research has been accepted for publication at the 20th Privacy Enhancing Technologies Symposium (PETS2020) with the paper titled \u201cWhen Speakers Are All Ears: Characterizing Misactivations of IoT Smart Speakers\u201c. Full text, software, and data are available.\nSUMMARY\nVoice assistants such as Amazon\u2019s Alexa, OK Google, Apple\u2019s Siri, and Microsoft\u2019s Cortana are becoming increasingly pervasive in our homes, offices, and public spaces. While convenient, these systems also raise important privacy concerns\u2014namely, what exactly are these systems recording from their surroundings, and does that include sensitive and personal conversations that were never meant to be shared with companies or their contractors? These aren\u2019t just hypothetical concerns from paranoid users: there have been a slew of recent reports about devices constantly recording audio and cloud providers outsourcing to contractors transcription of audio recordings of private and intimate interactions. Recent shifts to working from home make these issues more acute, as business conversations previously confined to places of work may be recorded by home devices.\nAnyone who has used voice assistants knows that they accidentally wake up and record when the \u201cwake word\u201d isn\u2019t spoken\u2014for example, depending on the accent, \u201cI\u2019m sorry\u201d may sound like the wake word \u201cHey Siri\u201d, which causes Apple\u2019s Siri-enabled devices to start listening. There are many other anecdotal reports of everyday words in normal conversation being mistaken for wake words. For the past year, our team has been conducting research to go beyond anecdotes through the use of repeatable, controlled experiments that shed light on what causes voice assistants to mistakenly wake up and record. Below, we provide a brief summary of our approach, findings so far, and their implications.\nGOALS AND APPROACH\nGoals: The main goals of our research are to detect if, how, when, and why smart speakers are unexpectedly recording audio from their environment (we call this activation). We are also interested in whether there are trends based on certain non-wake words, type of conversation, location, and other factors.\nApproach: When figuring out what smart speakers listen and wake up to, we need to expose them to spoken words. And if we are to uncover any patterns in what causes devices to wake up, we further need repeatable, native-speaker, conversational audio\u2014along with corresponding text that was spoken at each moment. In theory, we could accomplish this using researchers who speak from scripts, but this would take an enormous amount of time and would cover only a small number of people\u2019s voices.\nInstead, we came up with a much simpler approach: we turn to popular TV shows containing reasonably large amounts of dialogue. Namely, our experiments use 134 hours of Netflix content from a variety of themes/genres, and we repeat the tests multiple times to understand which non-wake words consistently lead to activations and voice recording.\n| Show | Category |\n|---|---|\n| Gilmore Girls | Comedy, Drama |\n| Grey\u2019s Anatomy | Medical drama |\n| The L Word | Drama, Romance |\n| The Office | Comedy |\n| Greenleaf | Drama |\n| Dear White People | Comedy, Drama |\n| Riverdale | Crime, Drama, Mystery |\n| Jane the Virgin | Comedy |\n| Friday Night Tykes | Reality TV |\n| Big Bang Theory | Comedy, Romance |\n| The West Wing | Political Drama |\n| Narcos | Crime drama |\nWe also need ways to detect when smart speakers are recording audio. For this we use several approaches, including capturing video feeds of the devices (to detect lighting up when activated), network traffic (to detect audio data sent to the cloud), and self-reported recordings from smart speakers\u2019 cloud services (when available). We remove cases where the wake word was spoken in TV shows. Finally, we use closed caption text from each TV show episode to automatically extract which spoken words caused each activation.\nTestbed:\nWe focused only on voice assistants installed on the following stand-alone smart speakers:\n- Google Home Mini (wake word: OK/Hey/Hi Google)\n- Apple Homepod (wake word: Hey, Siri)\n- Harman Kardon Invoke by Microsoft (wake word: Cortana)\n- 2 Amazon Echo Dot 2nd generation (wake words: Alexa, Amazon, Echo, Computer)\n- 2 Amazon Echo Dot 3rd generation (wake words: Alexa, Amazon, Echo, Computer)\nTo conduct our measurements, we needed to build a custom monitoring system consisting of smart speakers, a camera to detect when they light up, a speaker to play the audio from TV shows, a microphone to monitor what audio the speakers play (such as responses to commands), and a wireless access point that records all network traffic between the devices and the Internet. Our main testbed has been deployed at Northeastern University\u2019s Mon(IoT)r Lab in Boston (US). A copy of the testbed has also been deployed at Imperial College London (UK), which we used to repeat all the US experiments to see whether smart speakers marketed and configured for the UK market behave differently from the US ones.\nA picture of our US testbed: camera on the top to detect activations, speakers on the left to play video material, smart speakers under test on the right.\nAn example of video capture of an activation: the Amazon Echo dot device in the center is lighting up, signaling a voice activation on 11/24/2019 at 09:52:22.\nKEY FINDINGS\nBelow is a list of some of our findings, with links to more details below. Everything described below is based on activations when the wake word was not spoken. Of course, all our findings pertain only to the source material (audio from selected TV shows) and we cannot make claims about more general trends.\n- Are these devices constantly recording our conversations? In short, we found no evidence to support this. The devices do wake up frequently, but often for short intervals (with some exceptions).\n- How frequently do devices activate? If we consider individual shows, a notable case is Google Home Mini, which while playing The West Wing exhibited 0.95 average activations per hour. If we consider all the shows, the devices that activated the most were the Invoke/Cortana and Echo Dot 2nd generation with \u201cEcho\u201d wake word (0.40 activations per hour), followed by Homepod (0.38 activations per hour).\n- How consistently do they activate during a conversation? The majority of activations do not occur consistently. We repeated our experiments 12 times (4 times for Invoke/Cortana), and most activations appeared in less than 25% of our experiments, meaning that the most common behavior is that the same audio sometimes activates the device and sometimes does not. This could be due to some randomness in the way smart speakers detect wake words, for example due to the random information loss that occurs when converting analog audio from the microphones to digital audio. Another explanation is that smart speakers may learn from previous mistakes and change the way they detect wake words. Even if a minority, there are also notable cases of consistent activations. For example, 20.7% of Google Home Mini activations and 17.7% of Homepod activations appear in more than 75% of our experiments.\n- Do they have any secret wake words? We did not find any clear evidence of consistent undocumented wake words that are malicious or completely unrelated to the real ones. Instead, we found evidence of attempts from the manufacturers to detect some variations of their known wake words. However, it is also possible for someone (for example the author of a TV commercial or YouTube video) to \u201ccraft\u201d wake words by exploiting wake word similarities and use them to activate user-owned smart speakers without the user suspecting that it was intentional.\n- Are there specific TV shows that cause more overall activations than others? If so, why? The West Wing has caused the highest number of average activations over time: 4.26 activations per hour if we consider the sum of activations across all the devices we tested. Note that The West Wing is among the shows with the highest density of dialogue (145 words per minute). If we consider the amount of dialogue, Narcos caused the highest number of activations: 6.21 activations per 10,000 words of dialogue.\nWe then looked at other shows with a similarly high dialogue density (such as Gilmore Girls and The Office) and found that they also have a high number of activations, which suggests that the number of activations is at least in part related to the density of dialogue. However, we have also noticed that if we consider just the amount of dialogue (in number of words), Narcos is the one that triggers the most activations, even if it has the lowest dialogue density.\nWe investigated the actual dialogue that produced Narcos\u2018 activations and we have seen that it was mostly Spanish dialogue and poorly pronounced English dialogue. This suggests that, in general, words that are not pronounced clearly may lead to more unwanted activations. - Do specific TV shows cause more activations for a given wake word? Yes. For each wake word, a different show causes the most activations.\n- Are there any TV shows that do not cause activations? No. All shows cause at least one device to wake up at least once. Almost every TV show causes multiple devices to wake up.\n- Do activations depend on the TV show character\u2019s accent, ethnicity, gender, or other factors? We have found evidence that (English language) smart speakers activate more when they are exposed to unclear dialogue, such as a foreign language, or garbled speech. This suggests that smart speaker users who do not speak English clearly, or that are farther away from the smart speaker (lower voice volume), may have an additional risk of unintentionally activating the device.\n- Are activations long enough to record sensitive audio from the environment? Yes, we have found several cases of long activations: 10% of the activations were at least 10 seconds long for the Homepod, 9 seconds for Google Home Mini, and 8 seconds for Echo Dot 2nd generation with \u201cEcho\u201d wake word. Half of the activations for Homepod and Echo Dot 2nd generation (Alexa and Computer wake words) were also at least 4 seconds long. During our experiments, we have also seen rare cases of activations lasting up to 43 seconds; however, such cases \u2013 which also appeared in our preliminary findings \u2013 represent situations that only happened in a single experiment, and therefore we have decided to consider them as outliers.\n- How many activations lead to audio recordings being sent to the cloud vs. processed only on the smart speaker? We have found that almost all activations that are detected locally (device lit up) are also sent to the cloud.\n- Do cloud providers correctly show all cases of audio recording to users? For Amazon and Google smart speakers the answer is yes: they both show activations that match the ones we detected using camera and network traffic. For the Homepod and the Invoke, the answer is no, since they do not allow users to view the recordings that are stored in the cloud.\n- Do smart speakers adapt to observed audio and change whether they activate over time? We have found some evidence that Amazon devices are adapting to observed audio since they activate less often when we repeat the experiments, meaning that they may be building voice profiles of their users to improve recognition. It is possible that other devices adapt as well, but we did not find significant evidence from our study.\n- Is there any difference in how US smart speakers activate with respect to UK ones? Both testbeds showed the presence of unintentional activations; however, UK activations were significantly different from the US ones, meaning that either the region, or other differences in the test environment play a role in how devices activate.\n- What kind of non-wake words consistently cause long activations? We found several patterns for non-wake words causing activations that can be reproduced at least three times during our experiments. Our PETS2020 paper contains an appendix with full closed captions for the most reproducible activations. Our findings are summarized as follows.\n- For the Google Home Mini, these activations commonly occurred when the dialogue included words rhyming with \u201cHey\u201d or \u201cHi\u201d (e.g., \u201cThey\u201d or \u201cI\u201d), followed by hard \u201cG\u201d or something containing \u201col\u201d. Examples include \u201cokay \u2026 to go\u201d, \u201cmaybe I don\u2019t like the cold\u201d, \u201cthey\u2019re capable of\u201d, \u201cyeah \u2026 good weird\u201d, \u201chey .. you told\u201d, \u201cA-P \u2026 I won\u2019t hold\u201d.\n- For the Apple Homepod, activations occurred with words rhyming with \u201cHey\u201d or \u201cHi\u201d (e.g., \u201cThey\u201d or \u201cI\u201d), followed by a voiceless \u201cs\u201d/\u201cf\u201d/\u201cth\u201d sound and a \u201ci\u201d/\u201cee\u201d vowel. Examples include \u201chey \u2026 missy\u201d, \u201cthey \u2026 sex, right?\u201d, \u201chey, Charity\u201d, \u201cthey \u2026 secretly\u201d, \u201cI\u2019m sorry\u201d, \u201chey \u2026 is here\u201d, \u201cyeah. I was thinking\u201d, \u201cHi. Mrs. Kim\u201d, \u201cthey say \u2026 was a sign\u201d, \u201chey, how you feeling\u201d.\n- For Invoke (powered by Cortana), we found activations with words containing a \u201cK\u201d sound closely followed by a \u201cR\u201d or a \u201cT\u201d. Examples include \u201ctake a break \u2026 take a\u201d, \u201clecture on\u201d, \u201cquartet\u201d, \u201ccourtesy\u201d, \u201caccording to\u201d.\n- For Amazon devices, we observed different activating patterns based on the wake word.\n- For the Alexa wake word, we found activations with sentences starting with \u201cI\u201d followed by a \u201cK\u201d or a voiceless \u201cS\u201d. Examples include \u201cI care about\u201d, \u201cI messed up\u201d, \u201cI got something\u201d, \u201cit feels like I\u2019m\u201d.\n- For the Echo wake word, we found activations with words containing a vowel plus \u201ck\u201d or \u201cg\u201d sounds. Examples include \u201chead coach\u201d, \u201che was quiet\u201d, \u201cI got\u201d, \u201cpicking\u201d, \u201cthat cool\u201d, \u201cpickle\u201d, \u201cHey, Co.\u201d.\n- For the Computer wake word, we found activations with words starting with \u201ccomp\u201d or rhyming with \u201chere\u201d/\u201cear\u201d. Examples include \u201cComparisons\u201d, \u201cI can\u2019t live here\u201d, \u201ccome here\u201d, \u201ccome onboard\u201d, \u201cnuclear accident\u201d, \u201cgoing camping\u201d, \u201cwhat about here?\u201d.\n- For the Amazon wake word, we found activations with sentences containing combinations of \u201cwas\u201d/\u201cas\u201d/\u201cgoes\u201d/\u201csome\u201d or \u201cI\u2019m\u201d followed by \u201cs\u201d, or words ending in \u201con/om\u201d. Examples include\n\u201cit was a\u201d, \u201cI\u2019m sorry\u201d, \u201cjust \u2026 you swear you won\u2019t\u201d, \u201cI was in\u201d, \u201cwhat was off\u201d, \u201clife goes on\u201d, \u201chave you come as\u201d, \u201cwant some water?\u201d, \u201che was home\u201d.\nOUR PETS PAPER\nOur research will be published in the proceedings of the 20th Privacy Enhancing Technologies Symposium (PETS 2020).\nPaper title: When Speakers Are All Ears: Characterizing Misactivations of IoT Smart Speakers\nAuthors: Daniel J. Dubois (Northeastern University), Roman Kolcun (Imperial College London), Anna Maria Mandalari (Imperial College London), Muhammad Talha Paracha (Northeastern University), David Choffnes (Northeastern University), Hamed Haddadi (Imperial College London)\nAbstract: Internet-connected voice-controlled speakers, also known as smart speakers, are increasingly popular due to their convenience for everyday tasks such as asking about the weather forecast or playing music. However, such convenience comes with privacy risks: smart speakers need to constantly listen in order to activate when the \u201cwake word\u201d is spoken, and are known to transmit audio from their environment and record it on cloud servers. In particular, this paper focuses on the privacy risk from smart speaker misactivations, i.e., when they activate, transmit, and/or record audio from their environment when the wake word is not spoken. To enable repeatable, scalable experiments for exposing smart speakers to conversations that do not contain wake words, we turn to playing audio from popular TV shows from diverse genres. After playing two rounds of 134 hours of content from 12 TV shows near popular smart speakers in both the US and in the UK, we observed cases of 0.95 misactivations per hour, or 1.43 times for every 10,000 words spoken, with some devices having 10% of their misactivation durations lasting at least 10 seconds. We characterize the sources of such misactivations and their implications for consumers, and discuss potential mitigations.\nFull Text (PDF): pre-print available.\nPresentation: available on YouTube.\nSoftware and data: available on Github.\nCitation:\n@inproceedings{dubois-pets20, title={{When Speakers Are All Ears: Characterizing Misactivations of IoT Smart Speakers}}, author={Dubois, Daniel J. and Kolcun, Roman and Mandalari, Anna Maria and Paracha, Muhammad Talha and Choffnes, David and Haddadi, Hamed}, booktitle={Proc. of the Privacy Enhancing Technologies Symposium (PETS)}, year={2020} }\nPRESS\n- 2020-04: The New York Times \u2013 Privacy Cannot Be a Casualty of the Coronavirus\n- 2020-04: Channel 4 \u2013 The Truth About Amazon\n- 2020-02: BBC News \u2013 Why Amazon knows so much about you\n- 2020-02: BBC One (Panorama program) \u2013 Amazon: What They Know About Us (YouTube Link)\n- 2020-02: USA Today \u2013 It\u2019s not you, it\u2019s them: Google, Alexa and Siri may answer even if you haven\u2019t called\n- 2020-02: The Independent \u2013 Smart Speakers Could Accidentally Record Users up to 19 Times Per Day, Study Reveals\n- 2020-02: The New York Times \u2013 Are Alexa and Google Assistant spying on us?\n- 2020-01: Which? \u2013 Are Alexa and Google Assistant spying on us?\n- 2019-08: Consumer Reports \u2013 Smart Speakers That Listen When They Shouldn\u2019t\nONGOING WORK\nThere are several other important open questions that we are in the process of answering as part of future research, such as:\n- How do smart speakers react to other stimuli, such as non-verbal noises, a dictionary of words, and voices using different languages and accents?\n- Can such stimuli identify undocumented wake words or sounds?\n- Do such stimuli cause discriminatory biases to the respective smart speaker ecosystems?\n-\nHow do smart speaker ecosystems use and share the data they gather from their environments?\nWe will provide further updates to this page when we have more details to share.\nPAGE HISTORY\n- 02/26/2020. Preliminary findings."
    },
    {
      "url": "https://www.aclu.org/news/privacy-technology/new-records-detail-dhs-purchase-and-use-of-vast-quantities-of-cell-phone-location-data",
      "text": "New Records Detail DHS Purchase and Use of Vast Quantities of Cell Phone Location Data\nToday, the ACLU published thousands of pages of previously unreleased records about how Customs and Border Protection, Immigration and Customs Enforcement, and other parts of the Department of Homeland Security are sidestepping our Fourth Amendment right against unreasonable government searches and seizures by buying access to, and using, huge volumes of people\u2019s cell phone location information quietly extracted from smartphone apps.\nThe records, which the ACLU obtained over the course of the last year through a Freedom of Information Act (FOIA) lawsuit, shed new light on the government\u2019s ability to obtain our most private information by simply opening the federal wallet. These documents are further proof that Congress needs to pass the Fourth Amendment Is Not For Sale Act, which would end law enforcement agencies\u2019 practice of buying their way around the Fourth Amendment\u2019s warrant requirement.\nICE\u2019s and CBP\u2019s warrantless purchase of access to people\u2019s sensitive location information was first reported by The Wall Street Journal in early 2020. After the news broke, we submitted a FOIA request to DHS, ICE, and CBP, and we sued to force the agencies to respond to the request in December 2020. Although the litigation is ongoing, we are now making public the records that CBP, ICE, the U.S. Secret Service, the U.S. Coast Guard, and several offices within DHS Headquarters have provided us to date.\nThe released records shine a light on the millions of taxpayer dollars DHS used to buy access to cell phone location information being aggregated and sold by two shadowy data brokers, Venntel and Babel Street. The documents expose those companies\u2019 \u2014 and the government\u2019s \u2014 attempts to rationalize this unfettered sale of massive quantities of data in the face of U.S. Supreme Court precedent protecting similar cell phone location data against warrantless government access.\nFour years ago, in Carpenter v. United States, the Supreme Court ruled that the government needs a warrant to access a person\u2019s cellphone location history from cellular service providers because of the \u201cprivacies of life\u201d those records can reveal. That case hinged on a request for one suspect\u2019s historical location information over a several-month period. In the documents we received over the past year, we found Venntel marketing materials sent to DHS explaining how the company collects more than 15 billion location points from over 250 million cell phones and other mobile devices every day.\nWith this data, law enforcement can \u201cidentify devices observed at places of interest,\u201d and \u201cidentify repeat visitors, frequented locations, pinpoint known associates, and discover pattern of life,\u201d according to a Venntel marketing brochure. The documents belabor how precise and illuminating this data is, allowing \u201cpattern of life analysis to identify persons of interest.\u201d By searching through this massive trove of location information at their whim, government investigators can identify and track specific individuals or everyone in a particular area, learning details of our private activities and associations.\nThe government should not be allowed to purchase its way around bedrock constitutional protections against unreasonable searches of our private information.\nIn the face of the obvious privacy implications of warrantless access to this information, these companies and agencies go to great lengths to rationalize their actions. Throughout the documents, the cell phone location information is variously characterized as mere \u201cdigital exhaust\u201d and as containing no \u201cPII\u201d (personally identifying information) because it is associated with a cell phone\u2019s numerical identifier rather than a name \u2014 even though the entire purpose of this data is to be able to identify and track people. The records also assert that this data is \u201c100 percent opt-in,\u201d that cell phone users \u201cvoluntarily\u201d share the location information, and that it is collected with consent of the app user and \u201cpermission of the individual.\u201d Of course, that consent is a fiction: Many cell phone users don\u2019t realize how many apps on their phones are collecting GPS information, and certainly don\u2019t expect that data to be sold to the government in bulk.\nIn scattered emails, some DHS employees raised concerns, with internal briefing documents even acknowledging that \u201c[l]egal, policy, and privacy reviews have not always kept pace with the new and evolving technologies.\u201d Indeed, in one internal email, a senior director of privacy compliance flagged that the DHS Office of Science & Technology appeared to have purchased access to Venntel even though a required Privacy Threshold Assessment was never approved. Several email threads highlight internal confusion in the agency\u2019s privacy office and potential oversight gaps in the use of this data \u2014 to the extent that all projects involving Venntel data were temporarily halted because of unanswered privacy and legal questions.\nNonetheless, DHS has pressed on with these bulk location data purchases. And the volume of people\u2019s sensitive location information obtained by the agency is staggering. Among the records released to us by CBP were seven spreadsheets containing a small subset of the raw location data purchased by the agency from Venntel. (Although the location coordinates for each spreadsheet entry are redacted, the date and time of each location point are not.) The 6,168 pages of location records we reviewed contain approximately 336,000 location points obtained from people\u2019s phones. For one three-day span in 2018, the records contain around 113,654 location points \u2014 more than 26 location points per minute. And that data appears to come from just one area in the Southwestern United States, meaning it is just a small subset of the total volume of people\u2019s location information available to the agency.\nThe documents also highlight particular privacy concerns for people living near our nation\u2019s borders. A 2018 DHS internal document proposed using the location data to identify patterns of illegal immigration, threatening to indiscriminately sweep in information about people going about their daily lives in border communities. There is also the potential for local law enforcement entities to gain access to this large mass of data in ways that they would not usually be able to. This is illustrated by a troubling request to DHS from a local police department in Cincinnati, seeking location data analytics pertaining to opioid overdoses in their jurisdiction.\nDHS still owes us more documents, but whatever they show, it is already abundantly clear that law enforcement\u2019s practice of buying its way around the core protections of the Fourth Amendment must stop. There is bipartisan legislation in Congress right now that would do exactly that. The Fourth Amendment Is Not For Sale Act would require the government to secure a court order before obtaining Americans\u2019 data, such as location information from our smartphones, from data brokers. The principle here is simple: The government should not be allowed to purchase its way around bedrock constitutional protections against unreasonable searches of our private information. There is no end run around the Fourth Amendment.\nLawmakers must seize the opportunity to end this massive privacy invasion without delay. Each day without action only allows the government\u2019s covert trove of our personal information to grow."
    },
    {
      "url": "https://datareportal.com/reports/digital-2025-sub-section-global-advertising-trends",
      "text": "Digital 2025: global advertising trends\nStatista\u2019s Market Insights data shows that the world\u2019s marketers spent close to US$1.1 trillion on ads in 2024, with global spend increasing by $75 billion \u2013 7.3 percent \u2013 compared with 2023 levels.\nMoreover, Statista\u2019s data indicates that global ad spend has increased by more than 50 percent since 2019, with digital advertising responsible for the vast majority of that increase.\nAd spend vs GDP\nThese latest figures suggest that advertising now accounts for roughly 1 percent of global GDP, although that figure varies considerably by country.\nFor example, Statista\u2019s data suggests that the UK sees some of the highest relative levels of spend, with advertising investments equivalent to 1.66 percent of the country\u2019s total GDP.\nSimilarly, ad spend in the USA equates to almost 1.5 percent of GDP, while Japan and China also see relatively high rates of investment.\nHowever, at the other end of the spectrum, ad spend in Pakistan equates to just 0.18 percent of GDP, while figures are also below a quarter of a percent in Saudi Arabia and Turkey.\nChanging channels\nDigital channels now account for 72.7 percent of worldwide ad investment, with online spend exceeding US$790 billion in 2024.\nAnd these latest figures are testament to the dramatic shift in the balance of advertising spend since the outbreak of Covid-19.\nAs recently as 2018, digital channels account for just under half of global ad spend.\nBy 2019, that figure had grown to 54.3 percent, but share then jumped by a relative 13 percent in 2020, as Covid lockdowns drove marketers to embrace a markedly different mix of channels.\nHowever, marketing spend didn\u2019t then revert to pre-Covid patterns after the easing of restrictions, and digital has continued to take share from \u201coffline\u201d channels every year since.\nAbsolute levels of digital spend continue to enjoy double-digital growth too, with Statista reporting a year-on-year increase of 10.3 percent (+$74 billion) between 2023 and 2024.\nAnd in fact, digital ad spend has more than doubled since 2019, with Statista reporting a hefty 30-percent jump in total spend between 2020 and 2021.\nConsidered investments\nThe relative ease and cost of buying online ads may help to explain digital\u2019s rapid ascent, especially when we consider the role that self-service social media advertising plays for small and medium-sized businesses.\nHowever, the imbalance we see between investments in online and offline channels doesn\u2019t actually match the role that each channel plays in delivering marketing objectives.\nFor example, while GWI\u2019s research shows that digital marketing activities introduce brands and products to more than 9 in 10 adult internet users, offline channels still offer powerful opportunities to influence the world\u2019s consumers.\nIndeed, GWI\u2019s data indicates that nearly three-quarters of internet users \u2013 73 percent \u2013 still regularly discover new brands and products through \u201ctraditional\u201d media like TV, print, and radio.\nAnd with ad spend continuing to move away from these media, you may find that companies selling placements on \u201ctraditional\u201d media offer increasingly competitive opportunities to reach the audiences that matter to your brand.\nSo, if you have the resources to embrace channels like TV, you might want to think about recalibrating your mix so that it reflects the realities of your audiences\u2019 behaviours, as well as the associated costs of achieving your objectives.\nQuantifying audience value\nFor added perspective, Statista reports that \u2013 across all channels, both online and offline \u2013 marketers spend an average of US$140 per head of population on advertising.\nHowever, that average varies significantly from market to market.\nThe United States sees the highest levels of ad spend per capita, with the country\u2019s total ad investments equivalent to US$1,246 per person in 2024.\nPer capita spend is also relatively high in the UK, where marketers spend an average of US$876 on ads per person, per year.\nHowever, the equivalent figures are considerably lower across less developed economies.\nFor example, ad spend in Mexico equated to less than US$80 per head in 2024, and the figure was less than $3 per person in Pakistan.\nThe state of digital advertising\nReturning our attention to digital ads, data shows that the balance of spend across platforms and technologies continues to evolve.\nFor example, mobile continues to claim an ever greater share of spend compared with desktop, with Statista\u2019s latest figures indicating that mobile accounted for almost two-thirds of digital investments in 2024.\nAs always, the balance varies meaningfully by country \u2013 as you can see in our full report \u2013 but the overall trend is clearly towards mobile, with 2024\u2019s figure of 65.3 percent already meaningfully higher than the 52.7 percent that Statista reports for 2019.\nProgrammatic ads\nOn the supply side, programmatic services also continue to gain momentum, with Statista\u2019s Advertising & Media Market data putting dynamic distribution\u2019s share at 82.4 percent of spend in 2024.\nThat share figure increased by a relative 1.6 percent over the past 12 months, while 2024\u2019s figure is 8.6 percent higher than the 75.9 percent that the company reports for 2019.\nIn total, businesses spent more than US$650 billion on programmatic placements in 2024, with that absolute spend figure more than 12 percent higher than the total for the previous year.\nSearch still finding favour\nSearch continues to attract the lion\u2019s share of digital channel revenues, with Statista attributing 40 percent of 2024 digital spend to online search platforms.\nIt\u2019s interesting to note that search\u2019s share of digital spend dipped slightly after the outbreak of Covid-19 in 2020, but platforms like Google have seen their share of the digital pie increase every year since.\nOverall, search platforms earned more than US$316 billion in ad revenue during 2024, with that total more than 12 percent higher than the equivalent figure for 2023.\nThere are some warning signs in the data though, with Skai reporting that spend on search ads in the last three months of 2024 was actually 2 percent lower than spend in the equivalent period of 2023.\nMoreover, the number of search impressions served saw an even bigger drop, with Skai\u2019s analysis pointing to a 14 percent year-on-year decline between Q4 2023 and Q4 2024.\nHowever, click-through rates improved significantly during that same period, from 1.6 percent in Q4 2023, to 1.86 percent in the last three months of 2024.\nOn a relative basis, that\u2019s a 16 percent improvement in search clicks, which helps to explain why the average cost per click (CPC) only declined by US$0.01 during the same period.\nShopping around\nMeanwhile, it\u2019s particularly interesting to note the rise of advertising on online retail platforms like Amazon.\nStatista reports that online retail platform advertising accounted for more than 1 in 5 digital ad dollars around the world last year, with these channels claiming 21.2 percent of global digital ad spend in 2024.\nAnd for perspective, that figure is almost double the 10.9 percent share that these platforms claimed in 2019.\nIn total, Statista reports that online retailers earned more than US$167 billion from ad placements on their platforms in 2024, suggesting that this channel is increasingly important for consumer goods marketing.\nSocial climbing\nStatista\u2019s data suggests that 2024 was a particularly good year for social media platforms too, with global spend on social media ads increasing by 15 percent compared with 2023.\nFigures indicate that marketers spent close to a quarter of a trillion US dollars on social media ads in 2024, with these placements responsible for more than 3 in every 10 dollars spent on digital advertising.\nAnd if we compare these social media ad spend figures with our latest data for social media user identities, the data suggest that the world\u2019s marketers spend an average of US$46.47 per user to reach social audiences.\nOnce again, that figure varies meaningfully by country though, from a hefty US$335 per user in the United States, to just 86 cents (USD) in Pakistan.\nHowever, the latest data from Skai suggests that average social media CPMs slipped in Q4 2024 compared with the same period a year ago.\nThe company\u2019s analysis of billions of dollars of ad spend indicates that advertisers spent an average of US$5.69 to deliver 1,000 ad impressions on social platforms between October and December 2024, which was 4.4 percent lower than the US$5.83 they spent in the 2023 \u201choliday\u201d quarter.\nOn the other hand though, Skai\u2019s data also shows that the total number of impressions served across social platforms in Q4 2024 was roughly 4 percent higher than the figure for the same period a year earlier.\nAnd similarly, the company\u2019s analysis indicates that total spend on social media ads in the last three months of 2024 was roughly 2 percent higher than spend in the final quarter of 2023.\nGET THE FULL PICTURE\nThis article is a sub-section of our Digital 2025 Global Overview Report.\nClick here to access the complete report, and to read our comprehensive analysis.\nClick here to see all of Simon\u2019s articles, read his bio, and connect with him on social media."
    },
    {
      "url": "https://www.cnet.com/home/smart-home/googles-smart-home-devices-are-finally-getting-geminis-ai-skills/",
      "text": "Gemini for Home will replace Google Assistant in the company's line of smart displays and speakers, a step up in capabilities for its smart home devices. The announcement was made on Wednesday to coincide with its Made By Google event in New York.\nGemini for Home will use AI models tuned for home tasks and work with any member of the household, including guests, according to a company press release. It'll activate with the same \"hey Google\" phrase, but Gemini for Home can better understand context, with the ability for people to ask it more complex questions.\nNest smart displays, speakers, thermostats and smart lights can interact with Gemini for Home. For example, you can have Gemini for Home dim lights and set the thermostat to 72 degrees in one command. Google's blog post also says commands like \"turn off the lights everywhere except my bedroom\" will also work.\nBecause Gemini for Home will tap into the power of large language models, a Nest Hub smart speaker can be prompted with what ingredients are in your fridge and then process which recipes to consider. Gemini for Home links to Google Search, meaning it can find and use up-to-date information. Gemini for Home could also create bespoke content, like a bedtime story.\nIt's unclear which devices will support Gemini for Home. The current line of Nest devices is likely to support it, but Google's blog post does not mention older Google smart speakers or the Pixel Tablet.\nGoogle declined to comment.\nGoogle's AI push is spreading the company's generative technology across all of its devices and services. From Google Search, Gmail, Pixel phones and smart home devices, Gemini is in everything.\nUnlike OpenAI, the company behind ChatGPT, Google can spread its AI tech across a wide product portfolio. Google's early investments in AI help position the company ahead of Apple, which has been struggling to bake AI into its suite of devices. The rollout of Apple Intelligence on the iPhone, made in partnership with OpenAI, has been slow in comparison to Google and other smartphone makers.\nThe AI-ification of Google seems to be working. Google reported a 14% increase in sales this past quarter, thanks to increased Google Search usage and higher cloud sales."
    },
    {
      "url": "https://www.icsi.berkeley.edu/icsi/groups/privacy",
      "text": "Usable Security and Privacy\nThe Usable Security and Privacy Group examines how human factors impact privacy and security. Many of the privacy and security problems that plague today's online world are the result of a failure of system designers to consider their intended users. We perform basic research on human behavior to understand how people make decisions about their privacy and security, how they interact with privacy and security mechanisms, and ultimately how to design computer systems that result in improved privacy and security outcomes.\nBy its nature, the research that we perform is highly interdisciplinary. We apply techniques from human-computer interaction (HCI) to solve computer security and online privacy problems. Some of this work involves qualitative research methods, such as interviews and ethnography, to understand the breadth of problems. Other research involves quantitative methods, such as large-scale surveys, measurement studies, and controlled laboratory experiments. We maintain many robust collaborations with both social scientists (e.g., psychologists and behavioral economists) and computer scientists (e.g., systems designers and cryptographers).\nOur research has examined:\n- Consumer perceptions of online privacy\n- Consumers' willingness to pay for privacy\n- Educating consumers about online privacy issues\n- Usability of privacy tools\n- Usability of web browser security warnings\n- Usability of online security indicators\n- Regulating how smartphone applications access sensitive data\n- Privacy and security surrounding wearable and IoT devices\n- Tailoring security messaging to individual users\n- Improving the adoption of security technologies\nThe Usable Security and Privacy Group is led by Dr. Serge Egelman, who also holds a joint appointment in the UC Berkeley Electrical Engineering and Computer Sciences Department. He also directs the Berkeley Laboratory for Usable and Experimental Security."
    },
    {
      "url": "https://david.choffnes.com",
      "text": "I am a Professor in the Khoury College of Computer\nSciences at Northeastern University, Executive Director of the Cybersecurity and Privacy Institute, and\naffiliate faculty at the Center for Law, Innovation and Creativity (CLIC).\nMy research is primarily in the areas of distributed systems and\nnetworking, with a focus on privacy, security, and transparency across IoT, mobile, and web modalities.\nMy research approach is to combine science and engineering to understand and improve the performance, reliability, and security of Internet systems. With respect to science, I empirically measure computer systems that interact over the Internet to understand how well they match existing models and assumptions, then investigate the root causes for violations of those models/assumptions\u2014often then leading to the design of new models. In many cases, our observations also suggest the design of systems that exploit previously unknown information about how our Internet-enabled systems work, and as an engineer I build and evaluate such systems in a way that other researchers, users, and policy makers can benefit from the result. To date, the software artifacts of my research have more than one million users, and my research teams have produced reports and datasets that informed additional research, policy debates, regulators, and legislators.\nNews\n- 5/1/25 My promotion to (Full) Professor was officially approved by the Provost's Office. I want to thank my mentors, students, collaborators, colleagues, family, and friends (not mutually exclusive!) who have helped me reach this milestone.\n- 4/15/25 Excited to report that Dr. Tianrui Hu successfully defended his dissertation (my 7th!), and that Elaine Ly and Ilgar Mammadov will be joining my group as PhD students in Fall 2025!\n- 3/15/25 Two more papers accepted to PETS 2025 (issues 2 and 3): \"Echoes of Privacy: Uncovering the Profiling Practices of Voice Assistants\" (with Tina Khezresmaeilzadeh, Elaine Zhu, Kiersten Grieco, Daniel J. Dubois, and Konstantinos Psounis), and \"Empirically Measuring Data Localization in the EU\" (with Alexander Gamero-Garrido, Kicho Yu, Sumukh Vasisht Shankar, Sachin Kumar Singh, Sindhya Balasubramanian, and Alexander Wilcox)!\n- 8/1/24 Excited that our paper Gig Work at What Cost?: Exploring Privacy Risks of Gig Work Platform Participation in the U.S.\" has been accepted to appear in PETS 2025! Congrats to the lead authors Amogh Pradeep and Johanna Gunawan, and our coauthors Alvaro Feal and Woody Hartzog!\n- 7/31/24 Just learned that our paper, \"IoT Bricks Over v6: Understanding IPv6 Usage in Smart Homes\" has been accepted to appear in IMC 2024! Congrats to the lead author Tianrui Hu and our coauthor Daniel Dubois!\n- 7/24/24 Along with my ProperData collaborators, I've been awarded the Caspar Bowden PET Runner-Up Award for 2024, honoring our Smart Speaker Profiling work.\n- 5/23/24 Along with Cecilia Testart, I co-organized an NSF workshop on Policy-Relevant Internet Measurement.\n- 5/17/24 Thrilled to share a technology/policy collaborative work on improving privacy protections for consumers. \"A Scientific Approach to Tech Accountability\" appeared in the Harvard Journal of Law and Technology (JOLT).\n- 10/24/23 Congrats to Umar and the whole team for winning the Best Paper Award at IMC for our paper, \"Tracking, Profiling, and Ad Targeting in the Alexa Echo Smart Speaker Ecosystem\"!\n- 8/30/23 A bit stunned to report that I'm a coauthor on five papers that appeared at IMC'23! Congrats to all my collaborators, for more details see the publications page.\n- 7/27/23 Our paper on our ethics for data collection and sharing for the National Internet Observatory project was published in Nature CS!\n- 7/17/23 Congrats to Daniel Dubois, Nicole Holliday, and Kaveh Waddell for our first ICWSM paper, titled \"Fair or Fare? Understanding Automated Transcription Error Bias in Social Media and Videoconferencing Platforms\". The paper will appear in ... June 2024.\n- 7/13/23 Congrats to Amogh and Alvaro on being runners up for the Best Student Paper award at PETS '23 for their work on mobile browser privacy and security!\n- 4/10/23 Thrilled to announce that our paper \"Protected or Porous: A Comparative Analysis of Threat Detection Capability of IoT Safeguards\" will appear in IEEE S&P 2023!\nThis is joint work lead by Anna Maria Mandalari, along with Daniel Dubois and Hamed Haddadi.\n- 1/19/23 Yet another long delay between updates. Some highlights from my collaborations:\n- Consumer Reports covered work with Daniel Dubois and Nicole Holliday on bias in automatic transcription systems.\n- Monica (star undergrad at NU) and Johanna's work on dark patterns for IoT devices will appear at CHI'23.\n- Amogh and Alvaro led work on unique privacy violations from mobile web browser apps, to appear at PETS '23.\n- Amogh and Talha were co-first-authors on an analysis of TLS key pinning in mobile apps (IMC'22).\n- Kevin's work on improving Reverse Traceroute scalability was presented at IMC '22.\n- (I was co-chair of the TPC for IMC '22 with Theo Benson)\n- Kentrell's work on dark partterns in voice assistants was presented at EuroUSEC'22.\n- Narmeen's work on security vulnerabilities in the Zigbee wireless protocol was presented at ANCS'22.\n- Amogh's work on anonymous communication during Internet blackouts was presented at PETS'22.\nCongrats to my coauthors on all these projects!\n- 8/20/21 My team's longitudinal study of TLS usage by IoT devices was accepted for publication at IMC'21! Congrats to my coauthors Talha Paracha, Daniel Dubios, and Narseo Vallina-Rodriguez!\n- 7/30/21 I've been awarded Senior Member status in the Association for Computing Machinery!\n- 7/22/21 My team's work on Personal Virtual Networks and IoT privacy and security were mentioned in the UK Telecom Regulator,\nOfcom, Internet Futures report.\n- 7/20/21 I penned an article about how Wehe is enabling crowdsourced detection of\nnet neutrality violations worldwide and adapting to new applications as part of the\nArcep 2021 State of the Internet report.\n- 7/6/21 Another batch of updates:\n- 6/29/21 Time for another batch update on things that have happened since... a while ago:\n- Our paper titled AnyOpt: Predicting and Optimizing IP Anycast Performance, was accepted for publication at SIGCOMM 2021.\nThis was fantastic work led by Shane (Xiao) Zhang at Duke, along with Tanmoy Sen, Zheyuan Zhang, Tim April, Balakrishnan Chandrasekaran, Bruce M. Maggs, Haiying Shen, Ramesh K. Sitaraman, and Xiaowei Yang.\nWe show how you don't have to compromise on latency performance when building an anycast-based service.\n- Our paper titled Blocking without Breaking: Identification and Mitigation of Non-Essential IoT Traffic was accepted to appear in PETS 2021.\nLearn how we can block unnecessary IoT traffic to reduce privacy and security issues. Joint work with Anna Maria Mandalari (Imperial College London), Daniel J. Dubois (Northeastern University), Roman Kolcun (Imperial College London), Muhammad Talha Paracha (Northeastern University), Hamed Haddadi (Imperial College London).\n- Our prototype proposal \u201cIoTrimmer: Defending against IoT privacy threats\u201d reached the TOP 10 (among 180 submissions) at the Telekom Challenge by T-Labs. We're planning to make our privacy- and security-enhancing technology into a product for widespread use.\n- Theo Benson and I will be the Program Committee co-Chairs for the 2022 Internet Measurement Conference. I can't wait to see everyone's fascinating submissions!\n- I am part of a team that has been awarded a $10M NSF SaTC Frontier grant for improving privacy via a multimodal, interdisciplinary approach. Learn more about our project at: https://properdata.eng.uci.edu/\n- 9/9/20 It's been a busy pandemic, and there quite a few updates since last time:\n- I spent my sabbatical as a Security Architect at Akamai Technologies. I learned a great deal and worked with extremely talented and welcoming people.\n- My team's work on smart speakers inadvertently waking up was published and presented at PETS 2020. You learn more about it here.\n- Along with collaborators from the UK, and Germany, my team's work on detecting IoT devices from highly sampled network traffic was accepted to IMC 2020. You can find a preprint here.\n- I'm now an affiliate faculty member at Northeastern's Center for Law, Innovation and Creativity (CLIC). I'm thrilled to join such an esteemed group of collegues and work with them at the intersection of empirical neworking research and consumer protection policy.\n- 2/20/20 Happy to announce that FlowPrint will appear in NDSS 2020! This project focuses on an approach to fingerprinting apps based ono network traffic that works both in semi-supervised and entirely unsuperrvised settings. This is joint work led by Thijs van Ede, along with Riccardo Bortolameotti, Andrea Continella, Jingjing Ren, Daniel Dubois, Martina Lindorfer, Maarten van Steen, Andreas Peter.\n- 7/19/19 Very excited to report that two papers I coauthored will appear at IMC 2019.\n- In Information Exposure From Consumer IoT Devices: A Multidimensional, Network-Informed Measurement Approach, led by my recently graduated PhD student Dr. Jingjing Ren, we conduct a multidimensional analysis of privacy exposure from 81 devices located in labs in the US and UK, using more than 34,000 automated and manual experiments. We characterize privacy exposure in terms of destinations of Internet traffic, whether the contents of communication are protected by encryption, what are the IoT-device interactions that each destination learns about, and whether there are unexpected exposures of sensitive information (eg video surreptitiously transmitted by a recording device). This is joint work with Daniel J. Dubois, Anna Maria Mandalari, Roman Kolcun, and Hamed Haddadi.\n- In RPKI is Coming of Age: A Longitudinal Study of RPKI Deployment and Invalid Route Origins, led by former NEU postdoc Taejoong Chung, we study the evolution of the RPKI deployment using a unique dataset containing all RPKI Route Origin Authorizations (ROAs) from the moment RPKI was first deployed. We find that the RPKI has seen a rapid increase in adoption over the past two years, and recently misconfigurations are rare, meaning that the deployment is ready for prime time and ready for ISPs to drop RPKI invalid routes. This is joint work with Emile Aben, Tim Bruijnzeels, Balakrishnan Chandrasekaran, Dave Levin, Bruce Maggs, Alan Mislove, Roland van Rijswijk-Deij, John P. Rula, and Nick Sullivan.\n- 6/7/19 Tenure achievement unlocked! I am beyond excited to report that the President and Board of Trustees of Northeastern University have approved my promotion to Associate Professor with tenure. I have so many people to thank, including all of my outstanding collaborators and colleagues, and of course my family for supporting me along this long and fruitful journey.\n- Older news...\nCetera\nPronouns: He/him.\nFor those who don't know me, the following passage has become a theme\nthat runs through my life. In short, I \"push the rock,\" just like Sisyphus from Greek\nmythology. But Camus tells it better:\nAs for this myth, one\nsees merely the whole effort of a body straining to raise the huge\nstone, to roll it and push it up a slope a hundred times over; one sees\nthe face screwed up, the cheek tight against the stone, the shoulder\nbracing the clay-covered mass, the foot wedging it, the fresh start\nwith arms outstretched, the wholly human security of two earth-clotted\nhands. At the very end of his long effort measured by skyless space and\ntime without depth, the purpose is achieved. Then Sisyphus watches the\nstone rush down in a few moments toward that lower world whence he will\nhave to push it up again toward the summit. He goes back down to the\nplain. It is during that return, that pause, that Sisyphus interests\nme. A face that toils so close to stones is already stone itself! I see\nthat man going back down with a heavy yet measured step toward the\ntorment of which he will never know the end. That hour like a\nbreathing-space which returns as surely as his suffering, that is the\nhour of consciousness. At each of those moments when he leaves the\nheights and gradually sinks toward the lairs of the gods, he is\nsuperior to his fate. He is stronger than his rock.\n-- Albert Camus, The Myth of Sisyphus\nMy wife is a therapist (LICSW) focusing on helping clients with issues that include\ndisordered eating, anxiety and depression, relationships, and self-esteem.\nYou can find me on Mastodon here."
    },
    {
      "url": "https://www.cnet.com/tech/mobile/apple-iphone-16-pro-and-pro-max-review-compelling-upgrade-with-my-favorite-iphone-feature-in-years/",
      "text": "A few days into my week-long test of the iPhone 16 Pro and Pro Max, it became obvious to me that the best feature on Apple's premium devices isn't the new camera control button, bigger screen or larger battery. It isn't even Apple Intelligence.\nThe iPhone 16 Pro's ability to record high-resolution slow-motion video is the best new iPhone feature I've seen in years. I used the 16 Pro to record footage of a lion dance rehearsal and was surprised by how the slow motion made the dancers' fast acrobatic movements look graceful, sustained and powerful -- something that's difficult to appreciate in real time. OK, I'm biased because I used to make short films and love the beauty of slo-mo.\nSee more: Apple iPhone 16 and 16 Plus Review: Little Improvements Add Up\nBut is the 16 Pro's 4K, 120-frames-per-second video capability really enough to get people who aren't camera nerds excited about Apple's new premium iPhones -- especially as the company touts the power of its Apple Intelligence suite of generative AI features?\nWith its straight-sided titanium build and Siri's rainbow glow, Apple hyped the iPhone 16 Pro as a vessel that will bring generative AI, in the form of Apple Intelligence, into our everyday lives.\nTurns out, the complete vision for the iPhone 16 Pro with Apple Intelligence that the company showed off at its September iPhone event just isn't ready yet. I appreciate that Apple is taking its time to wade into the gen-AI waters -- it can hopefully avoid the blunders associated with a rushed rollout that we saw with Google's AI Overviews release. But it's unfortunate that people who may have bought the iPhone 16 Pro or 16 Pro Max specifically for Apple Intelligence will have to wait before experiencing it on their new phone.\nAnd while I did get to test an early preview version of Apple Intelligence on the iPhone 16 Pro, key features were missing. I didn't get to test the ChatGPT integration, Genmoji or Image Playground.\nHowever, other standout features left me impressed with the 16 Pro. That high-resolution slow-mo recording function, various iOS 18 capabilities as well as hardware upgrades help the iPhone 16 Pro feel like a compelling upgrade.\nSee more: Best VPN for iPhone 2024\nBut should you buy it?\nIf you're buying the $999 iPhone 16 Pro (\u00a3999, AU$1,799) or the $1,199 iPhone 16 Pro Max (\u00a31,199, AU$2,149) for Apple Intelligence, don't. At least not yet. Apple has indicated that iOS 18.1, which will introduce the AI features, will come out in October.\nIf you have an iPhone 12 Pro or older, upgrading to the 16 Pro makes a lot of sense. If you're on a 13 Pro and still have a decent battery capacity, I'd say save your money. And if you're on a 14 Pro or 15 Pro, there's no need to upgrade. Also, I should note that the entry-level $999 iPhone 16 Pro only has 128GB of storage. For perspective, Motorola's $300 Moto G Power comes with 128GB. Apple's charging over three times the price, so it could have at least included 256GB of storage in the base model.\nThis year the 16 Pro and 16 Pro Max have the exact same cameras -- unlike the 15 Pro and 15 Pro Max, which had different telephoto options. Screen size, battery life and price should be the deciding factors when you're choosing between the two.\nShortcomings aside, the iPhone 16 Pro is impressive, and it will likely be even more so as software updates and promised features are added. Just don't buy it hoping for Apple Intelligence (yet).\niPhone 16 Pro's 4K 120fps slow motion\nThe year was 2020 and in the middle of the lockdown, Sony sent me the Xperia 5 II, which could record 4K, 120fps, slow-motion videos. The feature was the first time slow-motion video in 4K resolution had ever been offered on a phone. The Xperia 5 II was clearly ahead of its time and, until now, had been the high-water mark for phone-based slo-mo recording.\nApple takes all this to another level.\nNot only can the 16 Pro and 16 Pro Max record 4K 120fps slow motion video, it can do so with little effort. Unlike the Xperia 5 II, which required using a professional camera app to record and preserve the footage, Apple bakes in the ability right into the iPhone's native camera app.\nAnd the results look outstanding, which is why this feature is such a big deal. Previous slow motion videos shot on the iPhone could look good if there was a lot of light. But they topped out at a lower HD resolution and the image quality was a significant step down from regular 4K 30fps video recording.\nThe iPhone 16 Pro's new slo-mo has great details, good dynamic range and accurate colors which puts it on par with regular iPhone video quality. Even when I was recording a lion dance rehearsal by the Lion Dance Me company in their San Francisco warehouse space, under medium lighting, the video looked good. You can see this slo-mo footage and more in the video below.\nApple Intelligence: Beta steps\nThe review unit Apple loaned me ran the iOS 18.1 developer beta, which allowed me to preview some Apple Intelligence features. It was a similar experience I had running the developer beta of 18.1 on my iPhone 15 Pro. And while Apple Intelligence is the headline feature for the phone, it's not quite fully baked. But from what I was able to test, I found Apple Intelligence to be useful and fun, and could see its potential.\nThe writing tools are clever. You can have it proofread something you wrote, or prompt it to rewrite it in a different tone and style, like concise, professional or friendly. The professional style is a bit stilted. It rewrote a text to a neighbor who was cat sitting for me, in which I joked about my cat being sad that I was gone. It conjured: \"My feline companion is experiencing distress due to my excessive work commitments, which have resulted in a neglect of his preferred activities, such as playtime and quality interactions.\"\nI found this hysterical.\nAs a professional writer, I don't expect I'd use these rewrite tools regularly. But one Apple Intelligence feature that I did use a ton was the Summarize tool, especially in Safari for news stories. I read a bunch of articles every day, so I can see the Summarize tool being the key to help weed out the clickbait from stories I should actually peruse.\nThe Create a Memory Movie in the Photos app is fun. I gave it the prompt \"San Francisco brunch,\" and it made a Memory Movie titled \"Brunching in the City\" complete with the song Cissy Strut by The Meters.\nBut probably the most notable feature has to be the Clean Up tool in Photos, which lets you remove unwanted elements from an image. In this photo of CNET's Lisa Eadicicco, I removed a chair on the left side and monitor on the right. I would have a hard time telling if there had been something there \u2013 aside from the leftover chair wheels.\nHere's one of CNET's Lexy Savvides and Celso Bulgatti.\nBelow is the same photo after I used the Clean Up tool to remove a person from the background who was talking to someone out of the frame. The results are good. But when I removed the van from the background, it was replaced with a Salavdor Dali-like bike wheel blob.\nSiri's glowing interface looks cool and the assistant seems faster and more helpful. When talking to Siri, I can be more natural and change what I say mid-thought. But this is far from the Gemini Live capability on Google's Pixel 9 phones, which has its own issues. Siri handles changing phone controls well, but when I asked what my phone's serial number was, it was unresponsive. The same was true when I asked how much storage I had on my phone.\nAgain, this was a preview version of Apple Intelligence, and the public release should arrive in October. While I take issue with Apple linking the iPhone 16 Pro and Apple Intelligence despite the gen-AI feature not being available, I do see where Apple is headed with generative AI and large language models, and I'm glad it's taking its time to get there.\nThe iPhone 16 Pro has more Camera Control\nApple added the Action button last year, and in 2024 gave us the Camera Control button -- which is so much more than just a button. Essentially, it's a shortcut key for the camera. Press it to open the camera and press it again to take a photo. Press and hold to record a video.\nThe button, located just below the power button, sits flush with the iPhone's side and can also be lightly double-tapped to bring up a gorgeous tiny menu of camera tools that gives me Q-Tip-in-the-ear levels of satisfaction every time I see it. If you select the zoom tool, you can slide your finger across the button to zoom in and out, almost like a miniature MacBook trackpad. You can also set it to adjust the \"aperture\" for Portrait mode photos to make the background look more or less blurry.\nMy favorite use is for swiping through Apple's new Photographic Styles to get a preview of different looks before I take a photo. Apple said that more functionality is in the works, including the ability to half-press the button to lock focus and exposure and full-press to take a photo -- like a dedicated professional mirrorless camera.\nThe biggest downside is if I'm holding the phone one-handed (I'm right-handed) to take a horizontal photo, I usually have my index finger across the side to help get a good grip on the phone, and that can accidentally interact with the Camera Control key.\nAs useful as the Camera Control button is, it seems ideally geared for Visual Intelligence, which can add context to whatever your iPhone's cameras are pointed at, a bit like Google Lens. Unfortunately, it won't arrive until later this year.\nThe Camera Control button will work with other photography apps, but I wish it could be used to swipe in apps like TikTok, or scroll through social media feeds and stories. It could be the elegant 2024 version of Blackberry's iconic scroll wheel.\niPhone 16 Pro cameras and photos\nIn essence, the regular iPhone 16 Pro has three new cameras. It inherits the 12-megapixel 5x telephoto camera from the Pro Max, replacing last year's 3x telephoto on the 15 Pro. It gets a new 48-megapixel ultrawide camera, and the main camera's 48-megapixel sensor gets upgraded to a faster one. And it's worth noting again that both the 16 Pro and 16 Pro Max have the same cameras.\nTake a look at some of my favorite photos from the iPhone 16 Pro and 16 Pro Max.\nThe higher resolution ultrawide camera allows for truly great macro photos: super close-up ones like this one of a lion dance head mask -- look at the details in that fur!\nBut the ultrawide in macro mode can also grab good food snaps like this image of a Four Barrel cortado and scone.\nUltrawide photos look good and are closer in parity to the main camera in terms of image quality, but there's still quite a gulf between them. Check out this photo of a wine bar taken with the main camera.\nAnd here's an image of the same bar taken with the ultrawide.\nI like the contrast in the ultrawide photo, but it has less dynamic range than the main camera's image, which is also brighter. Lens flares are minimal; notice the street light (out of frame) bleeding in at the top of this photo and the small soft flare.\nMain camera images have a wide dynamic range like this shot of the SoMa neighborhood in San Francisco.\nPhotos from the main camera have great image quality. Skin tones look wonderful. Here's a group shot of some CNET-ers backlit by a San Francisco sunset. Everyone's complexion has a nice soft glow -- maybe a tad too soft, but it's far from looking plastic-y and processed.\nHere's a night mode photo of San Francisco's city hall taken on a foggy evening.\nApple overhauled its Photographic Styles, and this is one of the places where I enjoy using the camera control button the most, just swiping between styles to achieve the look I want. It reminds me to an extent of the film simulations on the Fujifilm X100VI -- not only in how these styles smartly change aspects of a photo, but for the fact that you can take control and customize each.\nWhen reviewing a photo or video in the Photos app, especially right after shooting it, you have to tap the display to see it full screen. It's not the end of the world. But when I'm filming a video and want to check a shot, it's just one more step - and sometimes in the heat of the moment, this adds friction that doesn't need to be there.\niPhone 16 Pro's Audio Mix is outstanding\nSpeaking of the Photos app, I'm impressed with the new Audio Mix feature for videos. iPhone 16 Pro videos straight out of camera already have a solid default noise-isolation feature. Audio Mix lets you adjust the audio you've recorded even more to isolate a person talking on camera, and make them sound like they're recording on a studio microphone. You can also place voices on a center audio track for film and preserve environmental sounds on a separate audio track.\nWatch the review video that's attached to this story to see Audio Mix in action. I recorded a video of CNET's Jessica Fierro singing and playing a guitar on a noisy rooftop. And we were blown away by how Audio Mix was able to remove city sounds, HVAC noise and wind.\nThe iPhone 16 Pro is all about iOS 18 and A18 Pro\nOne of the best parts of the 16 Pro and Pro Max is iOS 18, which is all about personalizing your iPhone to fit your needs. Whether it's being able to move apps anywhere on the home screen, change icon colors and size or even remove app names, or add shortcuts to the Control Center, iOS wants you to customize your iPhone.\nThe flashlight controls in the Dynamic Island are fun and useful, and being able to use any emoji or live photos sticker as a tapback in Messages is such a delight. The QR code in the Passwords app for Wi-Fi is fantastic. For more on the new iPhone software, read CNET's iOS 18 review.\nPowering everything on the 16 Pro series is Apple's new A18 Pro chip. In use, the 16 Pro has been peppy, and able to handle big workloads from filming copious amounts of 4K slow-mo footage to playing video games and everyday scrolling.\nIn terms of battery, I've been primarily using the smaller 16 Pro, and it gets through a day fine. On my heaviest day of use (filming on it, having the screen at full brightness) the phone started at 6:30 a.m. with a full charge and dropped to 12% by 7 p.m. I topped it off for 15 minutes, which brought it back up to 37%, and it made it to 1 a.m. with 22% left. Check back on this review, as I will be updating it with results from CNET's battery tests.\niPhone 16 Pro wrap-up\nThe iPhone 16 Pro and 16 Pro Max have everything we've come to expect in a year-over-year upgrade. Even without Apple Intelligence, the 6.3-inch iPhone 16 Pro and 6.9-inch iPhone 16 Pro Max have a slew of upgrades including a good battery life, outstanding photo and video chops and iOS 18. And the negatives are as thin as the borders around the larger screens: You only get 128GB of storage for a grand, plus drab color options and a new camera button that might get accidentally tapped.\nThe iPhone 16 Pro and Pro Max are excellent phones worthy of a spot in your pocket -- if you can afford them.\nHow we test phones\nEvery phone tested by CNET's reviews team was actually used in the real world. We test a phone's features, play games and take photos. We examine the display to see if it's bright, sharp and vibrant. We analyze the design and build to see how it is to hold and whether it has an IP-rating for water resistance. We push the processor's performance to the extremes using standardized benchmark tools like GeekBench and 3DMark, along with our own anecdotal observations navigating the interface, recording high-resolution videos and playing graphically intense games at high refresh rates.\nAll the cameras are tested in a variety of conditions from bright sunlight to dark indoor scenes. We try out special features like night mode and portrait mode and compare our findings against similarly priced competing phones. We also check out the battery life by using it daily as well as running a series of battery drain tests.\nWe take into account additional features like support for 5G, satellite connectivity, fingerprint and face sensors, stylus support, fast charging speeds and foldable displays, among others that can be useful. We balance all of this against the price to give you the verdict on whether that phone, whatever price it is, actually represents good value. While these tests may not always be reflected in CNET's initial review, we conduct follow-up and long-term testing in most circumstances.\nApple's iPhone 16 and 16 Pro lineup\n| Apple iPhone 16 | Apple iPhone 16 Plus | Apple iPhone 16 Pro | Apple iPhone 16 Pro Max | |\n|---|---|---|---|---|\n| Display size, resolution, refresh rate | 6.1-inch OLED; 2,556x1,179 pixels; 60Hz refresh rate | 6.7-inch OLED; 2,796x1,290 pixels; 60Hz refresh rate | 6.3-inch OLED; 2,622x1,206 pixels; 1-120Hz adaptive refresh rate | 6.9-inch OLED; 2,868x1,320 pixels; 1-120Hz adaptive refresh rate |\n| Pixel density | 460 ppi | 460 ppi | 460 ppi | 460 ppi |\n| Dimensions (inches) | 5.81 x 2.82 x 0.31 inches | 6.33 x 3.06 x 0.31 inches | 5.89 x 2.81 x 0.32 inches | 6.42 x 3.06 x 0.32 inches |\n| Dimensions (millimeters) | 147.6 x 71.6 x 7.8mm | 160.9 x 77.8 x 7.8mm | 149.6 x 71.5 x 8.25mm | 163 x 77.6 x 8.25mm |\n| Weight (grams, ounces) | 170g (6 oz) | 199g (7.03 oz) | 199g (7.03 oz) | 227g (7.99 oz) |\n| Mobile software | iOS 18 | iOS 18 | iOS 18 | iOS 18 |\n| Camera | 48-megapixel (wide), 12-megapixel (ultrawide) | 48-megapixel (wide), 12-megapixel (ultrawide) | 48-megapixel (wide), 48-megapixel (ultrawide), 12-megapixel (5x telephoto) | 48-megapixel (wide), 48-megapixel (ultrawide), 12-megapixel (5x telephoto) |\n| Front-facing camera | 12-megapixel | 12-megapixel | 12-megapixel | 12-megapixel |\n| Video capture | 4K up to 60fps; spatial video at 1080p at 30fps | 4K up to 60fps; spatial video at 1080p at 30fps | 4K up to 120fps; spatial video at 1080p at 30fps | 4K up to 120fps; spatial video at 1080p at 30fps |\n| Processor | Apple A18 | Apple A18 | Apple A18 Pro | Apple A18 Pro |\n| RAM/storage | 128GB, 256GB, 512GB | 128GB, 256GB, 512GB | 128GB, 256GB, 512GB, 1TB | 256GB, 512GB, 1TB |\n| Expandable storage | No | No | No | No |\n| Battery | Up to 22 hours video playback; up to 18 hours video playback (streamed). 20W wired charging. MagSafe wireless charging up to 25W with 30W adapter or higher; Qi2 up to 15W | Up to 27 hours video playback; up to 24 hours video playback (streamed). 20W wired charging. MagSafe wireless charging up to 25W with 30W adapter or higher; Qi2 up to 15W | Up to 27 hours video playback; up to 22 hours video playback (streamed). 20W wired charging. MagSafe wireless charging up to 25W with 30W adapter or higher; Qi2 up to 15W | Up to 33 hours video playback; up to 29 hours video playback (streamed). 20W wired charging. MagSafe wireless charging up to 25W with 30W adapter or higher; Qi2 up to 15W |\n| Fingerprint sensor | None (Face ID) | None (Face ID) | None (Face ID) | None (Face ID) |\n| Connector | USB-C | USB-C | USB-C | USB-C |\n| Headphone jack | No | No | No | No |\n| Special features | Apple Intelligence, Action button, Camera Control button, Dynamic Island, 1 to 2,000 nits display brightness range, IP68 resistance. Colors: black, white, pink, teal, ultramarine. | Apple Intelligence, Action button, Camera Control button, Dynamic Island, 1 to 2,000 nits display brightness range, IP68 resistance. Colors: black, white, pink, teal, ultramarine. | Apple Intelligence, Action button, Camera Control button, 4x audio mics, Dynamic Island, 1 to 2,000 nits display brightness range, IP68 resistance. Colors: black titanium, white titantium, natural titanium, desert titanium. | Apple Intelligence, Action button, Camera Control button, 4x audio mics, Dynamic Island, 1 to 2,000 nits display brightness range, IP68 resistance. Colors: black titanium, white titantium, natural titanium, desert titanium. |\n| US price starts at | $799 (128GB), $899 (256GB), $1,099 (512GB) | $899 (128GB), $899 (256GB), $1,199 (512GB) | $999 (128GB), $1,099 (256GB), $1,299 (512GB), $1,499 (1TB) | $1,199 (256GB), $1,399 (512GB), $1,599 (1TB) |\n| UK price starts at | \u00a3799 (128GB), \u00a3899 (256GB), \u00a31,099 (512GB) | \u00a3899 (128GB), \u00a3999 (256GB), \u00a31,199 (512GB) | \u00a3999 (128GB), \u00a31,099 (256GB), \u00a31,299 (512GB), \u00a31,499 (1TB) | \u00a31,199 (256GB), \u00a31,399 (512GB), \u00a31,599 (1TB) |\n| Australia price starts at | AU$1,399 (128GB), AU$1,599 (256GB), AU$1,949 (512GB) | AU$1,599 (128GB), AU$1,799 (256GB), AU$2,149 (512GB) | AU$1,799 (128GB), AU$1,999 (256GB), AU$2,349 (512GB), AU$2,699 (1TB) | AU$2,149 (256GB), AU$2,499 (512GB), AU$2,849 (1TB) |"
    },
    {
      "url": "https://cbw.sh",
      "text": "I am a Professor in the Khoury College of Computer Sciences at Northeastern University. I am a member of the Cybersecurity and Privacy Institute and the Associate Dean of Undergraduate Programs in Khoury College.\nI am a faculty associate at the Berkman Klein Center for Internet & Society at Harvard University, and an affiliate member of the Center for Law, Innovation and Creativity at Northeastern University School of Law.\nMy research seeks to investigate the sociotechnical systems that shape our lives using a multi-disciplinary approach. I believe that by increasing transparency we can also improve accountability of these systems. If you're interested in my research, here is a brief video about algorithm auditing, here is a longer video about our investigation of bias in hiring algorithms, and here is a video discussing the role of algorithm auditing in AI regulation.\nAlong with my co-PIs, I am currently working to launch the National Internet Observatory. This NSF-funded project seeks to gather data about the online habits of a large, representative panel of US residents and then make it available to qualified researchers around the world.\nThere is growing concern about the impact of powerful, opaque algorithms on our daily lives. In our work, we are focused on auditing algorithms: we use carefully controlled experiments to understand the data and algorithms used by companies, and assess the impact of these algorithms on normal people. Examples of our work include:\nThis work has appeared in IMC, CSCW, CHI, and WWW. More information, including source code and data, can be found on the project website.\nTracking is ubiquitous on the Web today, and yet we have only the most basic understanding of who collects data about us, and how this data is shared with third-parties. We are currently delving inside the tracking ecosystem to answer these questions, including:\nPublic Key Infrastructure is the root of trust and security on the internet.Prominent examples include the SSL/TLS and DNSSEC PKIs. However, recent events like the Heartbleed vulnerability have demonstrated that critical PKIs are vulnerable to both software and human-induced failures. We are working to understand the threats to modern PKIs, and develop novel systems to address these challenges. Examples of our research include:\nThis work has appeared at IEEE S&P, CCS, Usenix Security, and IMC. More information about our SSL/TLS research, including source code and data, can be found on the project website.\nIn Fall 2024 I am teaching CS 4700/CS 5700. In the past I have taught:\nI spend an inordinate amount of time animating and tuning my slide decks.I am grateful for support from the National Science Foundation, Northwestern University and Underwriters Laboratories, the Sloan Foundation, the Mozilla Foundation, the Russell Sage Foundation, Google, Pymetrics the Democracy Fund, the Anti Defamation League, the Knight Foundation, the Data Transparency Lab, the European Commission, Verisign Labs, and Northeastern University under the TIER 1 grants program.\nI recently served as co-General Chair of the Privacy Law Scholars Conference (PLSC) '22. I served as co-Program Committee Chair of the inaugural Fairness, Accountability, and Transparency Conference (FAT*) 2018 (subsequently renamed to ACM FAccT) and I continue to serve on the Steering Committee for FAccT.\nRecently, I served on the PETS '22, IEEE S&P '20, and IMC '18 Program Committees. I also regularly present our work to audiences outside academia."
    },
    {
      "url": "https://www.cnet.com/tech/mobile/top-us-catholic-church-official-resigns-amid-link-to-brokered-cellphone-data/",
      "text": "A top official with the US Catholic church resigned after cellphone data obtained through a broker appeared to show he was a frequent user of the gay dating app Grindr, reigniting privacy concerns about who has access to consumers' digital records.\nThe US Conference of Catholic Bishops said in a memo Tuesday that Monsignor Jeffrey Burrill had resigned as its general secretary after the staff had learned on Monday of \"impending media reports alleging possible improper behavior.\" The priest was responsible for coordinating all administrative matters for the organization.\nNews of Burrill's resignation, reported earlier by National Catholic Reporter, came after online Catholic news site The Pillar reported allegations of his behavior to the conference. On Tuesday, after Burrill's resignation was announced, Pillar reported that through a vendor it had obtained device location data that was allegedly collected via Grindr. The site then hired an independent data consulting firm to analyze the \"commercially available\" data.\nPrivacy experts have long voiced concern about the ease with which anonymized data can be used by data trackers to determine a person's identity based on the location, time and activity, all of which can be collected through permission granted when an app is installed.\nGrindr's privacy policy bills the app as a \"safe space\" where users can \"discover, navigate and interact with others in the Grindr Community.\" The site says it has shared a variety of personal data with ad partners in the past, including device IDs, device location, connection information, and user age and gender. The app ceased providing information about users' locations, age and gender in April 2020, according to the policy.\nThe data analyzed by The Pillar highlights the invasive threat posed by mobile data. Pillar said its analysis of app data \"correlated\" to Burrill's cellphone indicates he visited gay bars in several cities between 2018 and 2020, which includes a period before Grindr's policy changed.\nGrindr criticized The Pillar's report as being \"full of unsubstantiated innuendo.\"\n\"The alleged activities listed in that unattributed blog post are infeasible from a technical standpoint and incredibly unlikely to occur,\" a Grindr spokesperson said in a statement. \"There is absolutely no evidence supporting the allegations of improper data collection or usage related to the Grindr app as purported.\"\nA main concern of privacy experts involves a concept known as \"device fingerprinting,\" in which a tracker looks for a unique and persistent way to identify a user, even when the data is supposed to be anonymous.\nSecurity researchers have also found that apps are collecting more data than users are led to believe. A report in 2019 found that more than 1,000 apps were taking data even after users denied them permissions, allowing them to gather precise geolocation data and phone identifiers.\nIt wasn't immediately clear how The Pillar obtained the data.\nBurrill couldn't immediately be reached for comment. The USCCB didn't respond to requests for comment."
    },
    {
      "url": "https://www.cnet.com/tech/mobile/best-phone/",
      "text": "The best phones in 2025 have a battery life that lasts a day or more, cameras that take stunning photos and vibrant displays, perfect for TikTok or watching The Gilded Age. 2025 has been an incredible year for smartphones. We test dozens of phones each year, but only consider a few to be truly great. From Google's Pixel 9 series and Apple's iPhone 16 family to Samsung's Galaxy S25 series and foldable phones including the Motorola Razr Ultra and Galaxy Z Fold 7, these are the best phones you can buy. If you're looking for a new Pixel phone or iPhone, we recommend waiting a few weeks as both Google and Apple will likely be unveiling their newest phones soon.\nOur Picks\nMOBILE DEALS OF THE WEEK\n- $449 (save $50)\n- $550 (save $50)\n- $300 (save $100)\nWhat is the best phone for most people?\nThe best phone for most people is the $799 iPhone 16. It comes in two sizes: a 6.1-inch regular iPhone 16 model or a larger 6.7-inch iPhone 16 Plus model that starts at $899. The phones have a new 12-megapixel ultrawide camera that performs better in low light and can now take macro photos, meaning you'll be able to focus close to take amazing food snaps. The iPhone 16 and 16 Plus have a handful of Apple Intelligence tools for writing, removing distractions from photos and doing summaries of messages and webpages. There's also adds a ChatGPT integration to Siri.\nThe phones also have an Action button that can be programed for different functions like turning on the flashlight, recording a voice memo, changing the focus mode and more. There's also a new Camera Control button that not only lets you take photos and quickly change things like zoom, Portrait mode aperture and Photographic Styles, but can also trigger a new feature called Visual Intelligence, which will add context to whatever the camera is pointed at, a bit like Google Lens. We think the iPhone 16 and 16 Plus are ideal for most people looking for a great phone that will last for years.\nBest phones of 2025\nPros\n- Camera Control is useful for switching camera settings\n- Photographic Styles makes photos pop\n- Ultrawide camera is better in low light\nCons\n- Apple Intelligence isn\u2019t out yet\n- No always on display\n- No changes to wired charging speeds\n- No upgrades to the Action button\nWhen I tested the iPhone 16 and 16 Plus I was definitely impressed by the new photography features, the convenient Action button and the elegant build. I consider these phones to be top-notch choices for Apple fans. Parts of the iPhone 16\u2019s key feature, Apple Intelligence, are now out, and the fact that these phones will support it means they\u2019ll likely feel future-proofed for years to come. Aside from screen size (6.1 inches on the regular, 6.7 inches on the Plus), battery size and price, the iPhone 16 and 16 Plus are identical in every way.\nThe iPhone 16 isn\u2019t perfect -- it\u2019s missing an always-on display, and it feels like it\u2019s been ages since Apple improved its wired charging speeds. But it checks all the important boxes and then some.\nWhy we like it\nThe iPhone 16 and 16 Plus rank so high in our testing because the phones appeal to both novice users and power players a like. They offer about 90% of the experience of Apple's Pro models but cost hundreds of dollars less. Not only is the iPhone 16 a wonderful phone out of the box, Apple has a long track record of updating its software and security patches for years.\nWho's it for\nWhen you think about how the Camera Control key, the Action button and the Dynamic Island come together, along with the camera and battery improvements Apple has made over the last several years, the iPhone 16 is a compelling upgrade for someone coming from an older iPhone, especially if that person is on an iPhone 13 or older. For those who don\u2019t need the Pro\u2019s extra photography prowess and battery life, the iPhone 16 won\u2019t disappoint.\nWho shouldn\u2019t get it\nI wouldn't recommend buying the iPhone 16 just for the Camera Control button or the better ultrawide camera.\nPros\n- Camera consistently delivers good images\n- Impressive battery life\n- More AI features feel practical\nCons\n- Several gimmicky AI features\n- Not many changes over the S24\nThe Galaxy S25's biggest flex that I noticed while testing is it shares many of the same attributes as its pricier counterparts, the S25 Plus and S25 Ultra \u2013 but it does so for several hundred dollars less. You'll find features like the AI Select tool, Audio Eraser and deeper Gemini integration across all of Samsung's S25 devices, as well as a custom Snapdragon 8 Elite processor and 12GB RAM \u2013 making the smaller phone of the bunch still seem pretty mighty.\nAnd while the Galaxy S25 might look incredibly similar to the S24 and share many of the same specs, consistency isn't so bad when it means there's a consistently good camera and great battery life. Read our full Samsung Galaxy S25 review.\nWhy we like it\nHaving a baseline phone, like the Galaxy S25, that delivers many of the same perks as more expensive models, is a huge plus in my book. And given the remarkable processing power, standout camera and seamless AI integration in the Galaxy S25 lineup, it's great that I can get all those premium features for $800.\nWho it's best for\nIf you're someone who insists on buying a flagship device, the Galaxy S25 won't let you down. but if you have a device that's two years old or more, you might be enticed to tap into all the latest Galaxy AI and integrated Gemini features. Now, $800 isn't pocket change, and there are definitely other options for those who want to be more budget conscious, but if you're willing to spend a bit more, the baseline S25 can be a great all-around choice.\nWho shouldn\u2019t get it\nYou probably don't need to upgrade if you're using last year's S24.\nPros\n- Robust design\n- Bright high resolution inner screen\n- Battery life should last you a day or more\n- It's so damn fun to use\nCons\n- Cameras take decent photos but suffer from motion blur\n- Only three years of major OS updates\n- Gets warm playing games and using the camera frequently\nThe Motorola Razr Ultra is a beefed-up version of last year's Razr Plus, which won a CNET Editor's Choice Award. It's as if the Razr Plus hired a trainer and nutritionist and then got absolutely ripped -- warranting its name: Ultra. After testing, I've come to adore the Razr Ultra. It does all the \"normal\" non-folding phone things I want, and offers me a truly unique experience thanks to its cover screen. I feel like the coolest kid in the coffee shop when Google Pay-ing for my cortado with my Razr Ultra closed.\nBut in taking nearly every aspect of the phone to the extreme, Motorola lost one of the most important parts of recent Razrs: the amazing value. The catch for all this ultra-ness: the Motorola Razr Ultra costs $1,300.\nWhy we like it\nThis is the best built foldable flip phone I've ever used. Motorola took the best parts of the Razr Plus and improved nearly everything else. The battery life is outstanding and easily lasts a day on a single charge and can get you mostly through a second day even. The displays are brighter. The main 7-inch foldable display is larger and has more resolution than the Razr Plus and the cameras are improved. The fabric backing is delightful.\nWho's it best for\nSomeone who wants a fun, unique an robust foldable phone. You're willing to pay top-dollar to get the best processor, battery, design and cameras Motorola has ever made.\nWho shouldn't get it\nIf you're unsure of foldables, this might not be the best fit. If you find yourself in places with sand, dirt and other fine particles, the Razr Ultra (like all foldable phones) isn't worth the risk. The Razr Ultra has the same class-leading IP-rating for dust and water resistance, but the dust resistance is only for particles 1-mm or larger.\nPros\n- Thin 4.2mm design\n- 200-megapixel main camera\n- Powerful Snapdragon 8 Elite processor\n- Durable build\nCons\n- Steep $2,000 price tag\n- Same 4,400-mAh battery as last year's Fold\n- 25-watt wired charging\nWith the Galaxy Z Fold 7, Samsung has finally addressed some of the key issues with its previous book-style foldables. The impressively thin build and wider, 6.5-inch cover screen makes this feel like a standard phone when closed, and that wider 8-inch inside display is great for multitasking, with the ability to run up to three apps simultaneously. Perhaps most notably, the camera gets a major upgrade with the addition of a 200-megapixel main camera, which takes shots on par with the top-of-the-line S25 Ultra.\nAltogether, it\u2019s a great choice if you want a bigger, tablet-like display without the bulk or a compromise on camera quality.\nWhy we like it\nThe Z Fold 7 does a solid job combining what's great about standard slate phones and what's great about foldables. It feels wonderfully normal to hold when closed, thanks to its sleek design and lightweight build. It also packs great cameras and has an expansive main display that's 11 percent bigger than last year's Z Fold 6.\nThankfully, a slimmer build doesn't force the battery to take a hit; the Z Fold 7 maintains that same 4,400-mAh battery as last year's foldable. That pales in comparison to batteries from Chinese competitors, but at least it's not a downgrade. The Z Fold 7 also packs a Snapdragon 8 Elite processor to power the many AI features you'll get onboard, from Galaxy AI photo and audio editing tools to Google's Gemini Live and Circle to Search. The phone also supports seven years of software and security updates.\nWho it's best for\nIf you're bored of standard slate phones and want something that feels a little more exciting, the Galaxy Z Fold 7 is a great choice. The slim design and wider cover screen helps it to feel as normal as possible when closed, with the added perk of an expansive main display that's great for multitasking and watching videos. The cameras are also impressive for a foldable that's so thin.\nWho shouldn't get it\nThe Z Fold 7's $2,000 price tag is perhaps its biggest caveat. Also, if you don't need a bigger display, it may not be worth the splurge. Ironically, the cover screen is so practical that you\u2019ll rarely need to open the phone -- unless you\u2019re watching movies or multitasking, in which case a phone like the Galaxy S25 Ultra might be a better fit.\nPros\n- Best screen on any phone\n- Versatile cameras\n- Most powerful phone I've tested\n- Good battery life\nCons\n- $1,300 price\n- Design is almost too minimal\n- AI features are hit-or-miss\n- S25/S25 Plus have similar features and cost less\nSamsung's Galaxy S25 Ultra which has a lot of AI features, the best of which are interesting and the worst of which unreliable. Luckily, Samsung gets a lot of other things right on the S25 Ultra, which has a new Snapdragon 8 Elite processor, high-resolution ultrawide camera, and some sweet pro video tools that rival the iPhone 16 Pro. Samsung wisely kept all the best parts of last year's Galaxy S24 Ultra (basically the entire phone including that antireflective display) but some of its worst parts, too, like the $1,300 price tag.\nIf you want the best screen you can find on any phone, get the S25 Ultra. If you want the most versatile phone cameras, get the S25 Ultra. If you want a stylus, get the S25 Ultra. But if your needs scale back on any of those fronts, the more affordable S25 options, or even last year's S24 Ultra, may be worth considering. Read our full Samsung Galaxy S25 Ultra review.\nWhy we like it\nThe reason to get the Ultra over its S25 siblings is its screen, which is truly the best I've seen on any phone, and the cameras, which are a step above what the S25 and S25 Plus have. Added video features like ability to record in Log format gets the Ultra as close as it's ever been to the iPhone in terms of professional video capture.\nWho's it best for\nIf you have a Galaxy S22 Ultra or older, the S25 Ultra will seem like a significant upgrade. It's harder to make that case for S23 Ultra owners, who, unless their phone's battery is ailing or they can score an incredible discount, should otherwise sit this one out. And for you S24 Ultra owners, you don't need this phone. Save your money and treat yourself to a nice steak dinner and a movie.\nWho shouldn\u2019t get it\nThe Galaxy S25 Ultra's appeal is muddied by its $1,300 price. The regular Galaxy S25 has the same functionality, power and longevity, and it costs $500 less. Want a bigger screen? Consider the Galaxy S25 Plus. For the majority of people, the regular Galaxy S25 and S25 Plus will be a better fit.\nPros\n- The screen is delightfully bright\n- Cameras are good for $499\n- Gemini Live Video AI has potential to be useful\n- Solid build\n- The under-$500 price\nCons\n- Battery life is just OK, will get through a day\n- Processor is serviceable (curious about longevity)\n- Lacks emergency SOS satellite texting\nFor $499, Google's Pixel 9A truly feels like you're getting more bang for your buck. It comes with several significant upgrades from last year's Pixel 8A: a fresh design, new display, larger battery, slightly more powerful chip, increased durability and upgraded software features.\nBut don't get me wrong -- it's not a perfect phone. There are places where Google had to compromise to keep the price under $500, like the lack of satellite connectivity for emergencies available on the $799 Pixel 9. Overall, though, I think the compromises Google made were smart and that the Pixel 9A is worth every penny. Read our Google Pixel 9A review.\nWhy we like it\nThe Pixel 9A is proof that you don't need to spend more than $500 to get a great phone. It can handle all you daily tasks from scrolling social media and news feeds and swiping through TikTok videos to taking a beautiful photo and lasting a day on a single charge.\nWho's it best for?\nIn theory: anybody. The Pixel 9A is for anyone who wants 95% of what a $1,000 phone can do at half the price.\nWho shouldn't get it\nAnyone who wants the absolute fastest processor or the most cutting edge cameras.\nPros\n- USB-C port is more convenient charging\n- Colorful matte design\n- Improved camera that can automatically take people and pet portraits\n- Dynamic Island brings better multitasking\nCons\n- No always-on display\n- Find My Friends feature only works with other iPhone 15 phones\n- Discounted iPhone 14 Pro may be a better value\n- Galaxy S24 offers a longer optical zoom\nWith the launch of the iPhone 16, the regular iPhone 15 is being sold at a discount -- $100 off. That means that the iPhone 15 now starts at $699. And you might be able to find steeper discounts throughout the coming weeks and months. With the Dynamic Island, a USB-C port for more convenient charging and a high resolution camera and a sharper digital zoom, I found the iPhone 15 to be a significant upgrade for those with older iPhones.\nThe iPhone 15 is available in two size options: the 6.1-inch iPhone 15 and the 6.7-inch iPhone 15 Plus. They run on the same chip as iPhone 14 Pro, the A16 Bionic, which should bring notable performance upgrades to those with an iPhone that's several years old. These phones also have Apple's second-generation ultra wideband chip, enabling a new feature that makes it easier to find friends or family members in a crowd which I found handy. Read our full iPhone 15 review.\nWhy we like it\nThe iPhone 15 and 15 Plus are heavily influenced by the iPhone 14 Pro. That includes the Dynamic Island, a dedicated area near the top of the screen for viewing time-sensitive data like your Uber's ETA, and the A16 Bionic processor. Overall, these changes come together to make the iPhone 15 feel like a big step forward for those upgrading from an aging iPhone.\nWho it's best for\nThe iPhone 15 is for someone coming from an iPhone 12 or older. In 2025, Apple sells it for $699. But I recommend looking for one that's discounted. If you're contemplating the iPhone 16E but really want an ultrawide camera (remember the 16E only has a single rear camera) and MagSafe charging, then grab an iPhone 15.\nWho shouldn't get it\nApple sells the $599 iPhone 16E which makes the iPhone 15 a curious value. If you can score a discounted iPhone 15 I'd go that way. But otherwise, the iPhone 16E might be a better buy.\nPros\n- Genuinely fun new AI skills\n- Sleek new design\n- Seven years of software updates\n- Cameras can take great daytime shots\nCons\n- Camera hardware hasn't improved much over Pixel 8 Pro\n- Gemini AI will eventually require a paid subscription\nThe Pixel 9 Pro and 9 Pro XL have a lot going for them, from their shiny new designs and long software support period. But it's the AI skills that really stand out, from the deep integration of the conversational Gemini Live, to the new Pixel Studio that creates weird and wonderful images from your text prompts.\nThe phones aren't perfect. While the cameras are good and can take excellent photos in bright light, they're just okay in low-light and in night mode. The best AI features will require a monthly subscription (though you get the first year for free) But if you're keen to experiment with AI on your phone then the new Pixel 9 Pro range is a superb way to experience it. Read our Google Pixel 9 Pro and 9 Pro XL review.\nWhy we like it\nGoogle's Pixel line of phones has gone from strength to strength and its latest model is unquestionably the best phone the company has ever made. It's not just the slick-looking design; the Pixel 9 Pro offers a superb camera system, a generous support period and a host of new AI skills making it one of the most accomplished Android phones around. The 9 Pro XL takes that further by accommodating a bright and vibrant 6.8-inch display.\nWho it's best for\nIt's a great phone for those of you looking for an elegant everyday Android phone. The interface is easy to navigate and the camera takes great photos with almost no effort on your part. If you feel overwhelmed by the plethora of settings and menus on other Android flagships, Google's Pixel 9 Pro is the way to go. If playing mobile games or watching videos on the go is a priority, opt for the larger Pixel 9 Pro XL.\nWho shouldn't get it\nIf you don't need the best cameras Google makes, consider the regular Pixel 9. I do like the fit and finish better on the 9 Pro, but it starts at $999.\nPros\n- The 6.9-inch screen is immersive, with lovely colors and contrast\n- The 4.1-inch screen looks incredible\n- It's durable and survived a drop onto concrete\n- One UI 8 (Android 16) runs wonderfully\n- $1,100 is still a lot, but Samsung gives the phone more value than the Flip 6\nCons\n- Gets warm when recording videos and playing games\n- Battery life is the same as the Flip 6 despite a bigger battery\n- Cover screen software has room to grow\nWhen I first got my hands on Samsung's new Galaxy Z Flip 7, I was delighted to discover that it has a smaller crease, larger cover screen, thinner design and bigger battery compared to last year's Galaxy Z Flip 6. But as I tested the new clamshell phone, I became enthralled by its inner screen. At 6.9 inches, this is the biggest screen on any Samsung phone aside from the Galaxy Z Fold 7, which has an 8-inch foldable display.\nThe Z Flip 7's large screen size makes content feel more immersive and colors look lovely and vivid. This led to epic TikTok and Instagram sessions, watching widescreen films such as A Working Man and Back to the Future, as well as jumping back and forth between two apps stacked vertically on the screen thanks to One UI 8's 90:10 split tool.\nEvery time I open the Flip 7, I'm consistently dumbfounded by how such a large display can unfurl from something about the size of a makeup compact. And when it's closed, there's a 4.1-inch cover screen that's fantastic in its own ways, with new clever animations for when you're recording a video, charging the phone or taking a selfie, all efficiently using the extra display real estate. In terms of functionality, though, the cover screen's software is about the same as the 3.4-inch one on the Flip 6.\nThe Flip 7 impressed me in nearly every way but one: its battery life. It has a larger battery than the Flip 6, but it doesn't last any longer in daily use. It did consistently get me through a day on a single charge, often having 15 to 20% left, but there were also a few days where it needed an early evening top-off.\nWhy we like it\nThe Galaxy Z Flip 7 is the most fully realized version of Samsung's ideal of a flip phone since the launch of the original Galaxy Z Flip in 2020. The Flip 7's appeal is simple: It's a thin phone with a big, bold screen that folds in half into a coaster-sized square. The larger cover screen and inner screen make content more immersive. It's design is thin (for a clamshell foldable) and comfortable to hold. Plus you get twice the storage this year compared to last.\nWho is it best for\nIf you've been tempted by a clamshell-style foldable, you should definitely consider the Flip 7. If you have a Galaxy Z Flip 4 or older, the Flip 7 will be an upgrade in every way. It's harder to make that same recommendation for Flip 5 owners unless your phone is showing its age. And if you have a Galaxy Z Flip 6, you can sit this one out unless you really want those larger screens.\nWho shouldn\u2019t get it\nIf you spend a ton of time around dirt or sand, this phone isn't for you.\nPros\n- Lightning fast charging\n- Nice big screen\n- 7 years of OS and security upgrades\n- Great performance with games, movies and animations\nCons\n- Battery life is a day, similar to baseline S25\n- Similar specs as the S25 at a higher price\n- Rival phones at the same price have better cameras\nIf the baseline Galaxy S25 appeals to you but you'd rather have a bigger screen and higher battery capacity \u2013 without upgrading all the way to the Ultra \u2013 the S25 Plus may be the phone for you. The entire S25 lineup shares many features, from AI capabilities to processing power to memory, so the Plus may be a viable choice if you're looking for something right in the middle.\nThat said, the Plus' minimal upgrades over the baseline S25 may not justify the $200 price difference. But if a bigger phone just feels better to hold and you'd rather have a 4,900 mAh battery (over the S25's 4,000mAh one), then that $1,000 starting price might ultimately be worth every penny. Read CNET's full Samsung Galaxy S25 Plus review.\nWhy we like it\nWhile the baseline S25 checks all the key boxes, the S25 Plus can simply feel like a more comfortable device to use, especially if you're a fellow member of the bigger hands club. In addition to sharing many of the same features as the pricier S25 Ultra, the S25 Plus has a higher battery capacity than the baseline model -- though in CNET's tests, there weren't any major discrepancies in how the two batteries actually performed. Still, sometimes you just want to live a little larger, and this phone can be the perfect fit.\nWho it's best for\nIf you like having a larger screen to watch movies or play games on, the S25 Plus can be a great choice. While the S25 Ultra might be a top pick for someone who wants both a bigger phone and the most premium features, the S25 Plus can be that goldilocks device that meets you right in the middle -- without you having to spend $1,300 on the Ultra.\nWho shouldn\u2019t get it\nIf you want the absolute best in terms of cameras, don't get the S25 Plus. For $1,000 phones like the Pixel 9 Pro or iPhone 16 Pro have better cameras. Or if you can afford to buy a $1,300 phone, check out the Galaxy S25 Ultra which has an amazing set of lenses\nPros\n- Beautiful design that feels durable\n- Fun and somewhat useful AI features\n- New ultrawide camera takes good photos\n- 7 years of software updates for longevity\nCons\n- More expensive that previous Pixels and competitors\n- Doesn't feel that different from Pixel 8\nThere\u2019s a lot to like about the Pixel 9, from its respectable camera to its classy new design and lengthy 7-year timeline for software updates. But Google\u2019s phones have always shined for their clean, slick software, and that once again applies to the Pixel 9 series. Pixels are also among the first to get new software updates, making them an ideal choice for those who want to get their hands on the latest version of Android first. Aside from Android updates, Google also brings new features to Pixel phones throughout the year through updates it calls Feature Drops.\nThe Pixel 9 comes with a few new AI tricks that you may find useful, like the ability to search for content in screenshots, generate images from scratch in the Pixel Studio app and add new objects in photos. These features aren\u2019t must-haves, and they\u2019re not without flaws. Plus, at a starting price of $799, the Pixel 9 has a higher bar to live up to. But the Pixel 9 feels like it belongs in that class of device. Read our full review for the Google Pixel 9.\nWhy we like it\nThe Pixel 9 and Google's Gemini assistant still feel like a first step toward what the company is hoping to achieve: Making phone software more intelligent so that we can spend less time swiping, tapping, scrolling and digging. In the meantime, the Pixel 9 shines for its great camera, elegant design and clean software, just like the less AI-centric Pixels of years past.\nWho it's best for\nIf you're a Pixel fan upgrading from an older phone, like the Pixel 6 or earlier, you'll find a lot to love about the Pixel 9. But keep in mind that for the same price, Samsung's Galaxy S25 has a brighter screen and a dedicated telephoto lens for taking zoomed photos.\nWho shouldn't get it\nIf you want the absolute best cameras that Google makes, including having a dedicated telephoto lens, I'd recommend the Pixel 9 Pro.\nThe iPhone 16 is the recipient of a CNET Editors' Choice award, and you can get one for free when you switch to Verizon, with no trade-in required.\nBest phones compared\n| Product | Apple iPhone 16 | Apple iPhone 16 Pro | Apple iPhone 15 | Google Pixel 9 | Google Pixel 9 Pro | Google Pixel 9 Pro XL | Samsung Galaxy S25 | Samsung Galaxy S25 Plus | Samsung Galaxy S25 Ultra | Moto G Power 5G (2024) | Motorola Razr Plus (2024) |\n|---|---|---|---|---|---|---|---|---|---|---|---|\n| Display size, tech, resolution, refresh rate | 6.1-inch OLED; 2,556 x 1,179 pixel resolution; 60Hz refresh rate | 6.3-inch OLED; 2,622 x 1,206 pixel resolution; 1-120Hz adapative refresh rate | 6.1-inch OLED; 2,556x1,179 pixels; 60Hz refresh rate | 6.3-inch OLED; 2,424x1,080 pixels; 60-120 Hz variable refresh rate | 6.3-inch LTPO OLED; 2,856x1,280 pixels; 1-120Hz variable refresh rate | 6.8-inch LTPO OLED; 2,992x1,344 pixels; 1-120Hz variable refresh rate | 6.2-inch AMOLED; 2,340x1,080 pixels; 1-120Hz adaptive refresh rate | 6.7-inch AMOLED; 3,120x1,440 pixels; 1-120Hz adaptive refresh rate | 6.8-inch AMOLED; 3,120x1,440 pixels; 1-120Hz adaptive refresh rate | 6.7-inch LCD; 2,400 x 1,080 pixels, 60-120Hz refresh rate | 4-inch pOLED; 1,272 x 1,080 pixels; 1-165Hz variable refresh rate; 6.9-inch pOLED; 2,640 x 1,080 pixels, 1-165Hz variable refresh rate |\n| Pixel density | 460 ppi | 460 ppi | 460 ppi | 422 ppi | 495 ppi | 486 ppi | 416 ppi | 509 ppi | 501 ppi | 391 ppi | Cover: 417 ppi; Internal: 413 ppi |\n| Dimensions (inches) | 5.81 x 2.82 x 0.31 inches | 5.89 x 2.81 x 0.32 inches | 2.82x5.81x0.31 inches | 6x2.8x0.3 inches | 6x2.8x0.3 inches | 6.4x3x0.3 inches | 5.78 x 2.78 x 0.28 in. | 6.24 x 2.98 x 0.29 in. | 6.41 x 3.06 x 0.32 in. | 6.6 x 3 x 0.3 in. | Open: 6.75 x 2.91 x 0.28 in Closed: 3.47 x 2.91 x 0.6 in |\n| Dimensions (millimeters) | 147.6 x 71.6 x 7.8mm | 149.6 x 71.5 x 8.25mm | 71.6x147.6x7.8 mm | 152.8x72x8.5 mm | 152.8x72x8.5 mm | 162.8x76.6x8.5 mm | 146.9 x 70.5 x 7.2 mm | 158.4 x 75.8 x 7.3 mm | 162.8 x 77.6 x 8.2 mm | 167.2 x 76.4 x 8.5mm | Open: 171.42 x 74 x 7.09mm Closed: 88.09 x 74 x 15.32mm |\n| Weight (grams, ounces) | 170 g (6 oz.) | 199 g (7.03 oz.) | 171g (6.02 oz.) | 198g (7 oz.) | 199g (7 oz.) | 221g (7.8 oz) | 162g (5.71 oz.) | 190g (6.70 oz.) | 218g (7.69 oz.) | 201g (7.09 oz.) | 189g (6.67 oz) |\n| Mobile software | iOS 18 | iOS 18 | iOS 17 | Android 14 | Android 14 | Android 14 | Android 15 | Android 15 | Android 15 | Android 14 | Android 14 |\n| Camera | 48-megapixel (wide), 12-megapixel (ultrawide) | 48-megapixel (wide), 48-megapixel (ultrawide) 5x telephoto | 48-megapixel (wide), 12-megapixel (ultrawide) | 50-megapixel (wide), 48-megapixel (ultrawide) | 50-megapixel (wide), 48-megapixel (ultrawide), 48-megapixel (5x telephoto) | 50-megapixel (wide), 48-megapixel (ultrawide), 48-megapixel (5x telephoto) | 50-megapixel (wide), 12-megapixel (ultrawide), 10-megapixel (3x telephoto) | 50-megapixel (wide), 12-megapixel (ultrawide), 10-megapixel (3x telephoto) | 200-megapixel (wide), 50-megapixel (ultrawide), 10-megapixel (3x telephoto), 50-megapixel (5x telephoto) | 50-megapixel (wide), 8-megapixel (ultrawide) | 50-megapixel (wide) 50-megapixel (2x telephoto) |\n| Front-facing camera | 12-megapixel | 12-megapixel | 12-megapixel | 10.5-megapixel | 42-megapixel | 42-megapixel | 12-megapixel | 12-megapixel | 12-megapixel | 16-megapixel | 32-megapixel |\n| Video capture | 4K | 4K | 4K | 4K | 4K | 4K | 8K | 8K | 8K | 1,080p | 4K |\n| Processor | Apple A18 | Apple A18 Pro | Apple A16 Bionic | Google Tensor G4 | Google Tensor G4 | Google Tensor G4 | Qualcomm Snapdragon 8 Elite for Galaxy | Qualcomm Snapdragon 8 Elite for Galaxy | Qualcomm Snapdragon 8 Elite for Galaxy | Mediatek Dimensity 7020 | Snapdragon 8S Gen 3 |\n| RAM + storage | RAM N/A + 128GB, 256GB, 512GB | RAM N/A + 128GB, 256GB, 512GB, 1TB | RAM N/A + 128GB, 256GB, 512GB | 12GB RAM + 128GB, 256GB | 16GB + 128GB, 256GB, 512GB, 1TB | 16GB + 128GB, 256GB, 512GB, 1TB | 12GB RAM + 128GB, 256GB | 12GB RAM + 256GB, 512GB | 12GB RAM + 256GB, 512GB, 1TB | 8GB RAM + 128GB | 12GB + 256GB |\n| Expandable storage | None (Face ID) | None (Face ID) | None (Face ID) | None | None | None | None | None | None | Up to 1TB | None |\n| Battery | Up to 22 hours video playback; up to 18 hours video playback (streamed). 20W wired charging. MagSafe wireless charging up to 25W with 30W adapter or higher; Qi2 up to 15W | Up to 27 hours video playback; up to 22 hours video playback (streamed). 20W wired charging. MagSafe wireless charging up to 25W with 30W adapter or higher; Qi2 up to 15W | Undisclosed; Apple claims up to 20 hours of video playback (16 hours streamed) | 4,700 mAh | 4,700 mAh | 5,060 mAh | 4,000 mAh | 4,900 mAh | 5,000 mAh | 5,000 mAh | 4,000 mAh |\n| Fingerprint sensor | None (Face ID) | None (Face ID) | Face ID | Under display | Under display | Under display | Under display | Under display | Under display | Side | Side |\n| Connector | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C |\n| Headphone jack | None | None | None | None | None | None | None | None | None | Yes | None |\n| US starting price | $799 (128GB) | $999 (128GB) | $799 (128GB) | $799 (128GB) | $999 (128GB) | $1,099 (128GB) | $800 (128GB) | $1,000 (256GB) | $1,300 (256GB) | $300 (128GB) | $1,000 (256GB) |\n| UK starting price | \u00a3799 (128GB) | \u00a3999 (128GB) | \u00a3799 (128GB) | Converts to \u00a3640 (128GB) | Converts to \u00a3780 (128GB) | Converts to \u00a3860 (128GB) | \u00a3799 (128GB) | \u00a3999 (256GB) | \u00a31,249 (256GB) | Converts to \u00a3234 (128GB) | Converts to \u00a3779 (256GB) |\n| Australia starting price | AU$1,399 (128GB) | AU$1,799 (128GB) | AU$1,499 (128GB) | Converts to AU$1,210 (128GB) | Converts to AU$1,510 (128GB) | Converts to AU$1,670 (128GB) | AU$1,399 (256GB) | AU$1,699 (256GB) | AU$2,149 (256GB) | Converts to AU$453 (128GB) | Converts to AU$1,483 (256GB) |\nRecent updates\nIn July 2025, we added the Samsung Galaxy Z Fold 7 and Galaxy Z Flip 7 to our list. The Fold 7 replaces last year's Fold 6 and comes with a completely new design that makes it thinner, lighter and feel more like a \"regular phone.\" The Flip 7 is the best-built foldable flip phone we tested from Samsung. The thinner design and bigger displays are the headline features.\nFactors to consider when buying a new phone\nPick the most important feature: Is it screen size? Camera quality? Battery life? This will help narrow down your choices. Phones like the iPhone 16 Pro Max or Galaxy S25 Ultra cost well over $1,000, for example, but pack large batteries that will last most people a day and a half to two days on a single charge.\nDon't dismiss $500 to $800 phones: You can get a great phone that does almost everything that a more expensive flagship model can do for a fraction of the price. Google's Pixel 9 (which starts at $799) packs a great camera, a bright screen and unique AI features, but the $499 Pixel 8A has most of the same key specs and comes at a lower price.\nShop Cyber Monday: Look for sales and deals close to holidays, especially Amazon's Prime Day and Cyber Monday.\nConsider last year's models: When a new phone gets launched, stores and carriers discount their older phones to sell off existing stock.\nSee the phone in person: It's worth going to a store and trying out a potential phone. You may love or hate the way it looks and feels.\nDecide on Android or iPhone: Do you have a lot of iPhone apps and Apple subscriptions? Stick with an iPhone. If you've invested in loads of Android apps, you may want to stay on that side of the fence. Otherwise, it's simple enough to switch platforms.\nBudget for a case and screen protector: Phones sold today are more durable than phones from even a few years ago, but it still might be a good idea to protect your phone with a case to keep it in tip-top shape.\nHow we test phones\nWe test every phone in real-world scenarios, focusing on its features, design, performance, cameras, battery life and overall value. We document our findings in an initial review that is periodically updated when there are new software updates, or to compare it against new phones from competitors such as Apple, Samsung, Google and OnePlus.\nPhotography\nPhotography is a major focus for most phones these days, so we take pictures and videos of various subjects in a variety of settings and lighting scenarios. We try out any new camera modes, such as 4K slow motion video that debuted with the iPhone 16 Pro and 16 Pro Max, or the new Magic Editor photo tools that launched with the Google Pixel 9 series.\nBattery life\nBattery testing is conducted in a variety of ways. We assess how long a phone lasts during a typical day of use and note how it performs during more focused sessions of video calls, media streaming and gaming. We also conduct a video playback test, as a simple, replicable measure of pure battery life, which isn't always included in the initial review but sometimes added later in an update.\nWe use benchmarking apps to measure each phone's performance, alongside our own anecdotal experiences using the phone for our review. Most noteworthy is how graphics and animations look. Are they smooth? Do they lag or stutter? We also look at how quickly the phone switches between horizontal and vertical orientations, and how fast the camera app opens and is ready to take a photo.\nWe perform processor-heavy tasks like editing photos, exporting videos and playing games. We evaluate whether a newer version of a particular phone includes enough features to make it worth upgrading from older models.\nPerformance measuring\nRead more: How We Test Phones\nOther phones we tested\nWhile Apple doesn't sell the iPhone 15 Pro, you can still find it at carriers and third-party retailers. The 15 Pro has a 6.1-inch adaptive-refresh rate screen that adjusts between 1-120Hz depending on what's on the screen. It has excellent cameras, a fast processor, an always-on display, supports iOS 18 and safety features like Crash Detection and Emergency SOS via Satellite. Driving all these upgrades is Apple's A17 Pro chip which in use feels peppy. The iPhone 15 Pro is still an excellent phone in 2025. Check out our iPhone 15 Pro review.\nPhone FAQs\nWhat is the best time to buy a phone?\nHow long should a phone battery last?\nHow much storage should I get on a phone?\nWhat are the best phone brands currently?\nWhat to look forward to in 2025\nGoogle is expected to launch the Pixel 10 series in August. There's also buzz for the next iPhone, likely called the iPhone 17 -- from a slimmer version of the upcoming device to a new screen with a higher refresh rate on baseline models. We've rounded up rumors, leaks and analysis on the iPhone 17 Air (one of several nicknames for Apple's next iPhone). Read CNET's iPhone 17 rumor roundup for more info."
    },
    {
      "url": "https://safety.google/assistant/",
      "text": "Google Assistant is built\nto keep your information\nprivate, safe, and secure.\nWhen you use Google Assistant, you trust us with your data, and it\u2019s our responsibility to protect and respect it. Privacy is personal. That\u2019s why we build simple privacy controls to help you choose what\u2019s right for you. Explore this page to learn more about how Google Assistant works, your built-in privacy controls, answers to common questions, and more.\nStarts in standby\nGoogle Assistant is designed to wait in standby mode until it detects an activation, like when it hears \u201cHey Google.\u201d When in standby mode, your Assistant won\u2019t send what you are saying to Google or anyone else.\nOnce Google Assistant detects an activation, it exits standby mode and sends your request to Google servers. This can also happen if there is a noise that sounds like \u201cHey Google\u201d or an unintended manual activation.\nLearn more about how Google Assistant handles audio recordings, Web & App Activity, and ads personalization.\nIs Google Assistant always listening to me?\nWhen you use Google Assistant, you trust us with your data, and it\u2019s our responsibility to protect and respect it.\nGoogle Assistant is designed to wait in standby mode and only listen when it detects an activation, like when it hears \u201cHey Google.\u201d When in standby mode, your Assistant won\u2019t send what you are saying to Google or anyone else.\nHow do I activate my Google Assistant?\nYou can activate your Assistant in a few ways, depending on your device. For example, you might say \u201cHey Google\u201d or activate it manually by holding your phone\u2019s power button or home button.\nHow do I know when Google Assistant is activated and listening?\nThe status indicator on your device, such as an on-screen indicator or flashing LEDs on top of your device, lets you know when Google Assistant is activated.\nWhy does Google Assistant sometimes activate when I didn\u2019t intend it to?\nGoogle Assistant might activate when you didn\u2019t intend it to because it incorrectly detected that you wanted its help - for instance when there is a noise that sounds like \u201cHey Google\u201d or you manually activate it accidentally.\nIf that happens, and your Web & App Activity is turned on, you can say, \u201cHey Google, that wasn\u2019t for you,\u201d and your Assistant will delete what you said from My Activity. You can also review and delete your Assistant interactions in My Activity at any time. If Google Assistant activates when you didn\u2019t intend it to, and your Web & App Activity setting is disabled, your Assistant interaction will not be stored in My Activity. If, however, your Web & App Activity setting is on, your Assistant interactions, including any unintended activations, will be stored in My Activity and treated like normal activations. Your data in My Activity is used to develop and improve Google services (including technologies that help reduce unintended activations), as explained in Google\u2019s Privacy Policy. You can always stop saving activity by turning off your Web & App Activity setting.\nTo better tailor Google Assistant to your environment, you can adjust how sensitive your Assistant is to activation phrases (like \u201cHey Google\u201d) through the Google Home app for smart speakers and smart displays.\nWe are constantly working to make our systems better for everyone, including building technologies to help reduce unintended activations.\nWhat is Google Assistant doing when it is in standby mode?\nGoogle Assistant is designed to wait in standby mode until it detects an activation. In standby mode, the device processes short snippets of audio (a few seconds) to detect an activation \u2013 like when you say \u201cHey Google.\u201d If no activation is detected, then those audio snippets won\u2019t be sent or saved to Google.\nWhat happens when Google Assistant detects an activation?\nOnce it detects an activation, your Assistant exits standby mode - this includes if there is an unintended manual activation or a noise that sounds like \u201cHey Google.\u201d Your device then records what it hears and sends the audio recording to Google servers to fulfill your request. The recording may include a few seconds before the activation to catch your entire request.\nBy default, your audio recordings are not saved on Google servers - you can change this setting anytime by viewing the \u201cInclude voice and audio activity\u201d checkbox under the Web & App Activity setting.\nDesigned for privacy\nBy default, your audio recordings are not saved on Google servers - you can change this setting anytime by viewing the \u201cInclude voice and audio activity\u201d checkbox under the Web & App Activity setting.\nHow does Google Assistant use my data?\nAssistant uses your queries and info from your linked devices and services, to understand and respond to you, including to personalize your experience. Examples of info from your linked devices and services include location, contacts, device names, tasks, events, alarms, installed apps, and playlists.\nYour data is also used to develop and improve Google products and services and machine learning technologies (including technologies that help reduce unintended activations), as explained in Google\u2019s Privacy Policy. To help assess quality and improve Assistant, human reviewers (which include third parties) read, annotate, and process the text of your Assistant queries and related info. We take steps to protect your privacy as part of this process. This includes disassociating your queries from your Google Account before reviewers see or annotate them.\nLearn more about how Google Assistant works with your data. Visit Google\u2019s Privacy Policy to learn more about how Google protects and uses your data.\nDoes Google Assistant save my audio recordings?\nBy default, your audio recordings are not saved on Google servers - you can change this setting anytime by viewing the \u201cInclude voice and audio activity\u201d checkbox under the Web & App Activity setting.\nWith Personalized speech recognition, Google Assistant will get better at recognizing your words and phrases to offer more tailored help. Starting with Pixel 7 and Pixel 7 Pro, this feature works by saving your Assistant interactions, including audio, securely on your device. You can turn this feature off at any time in \u201cYour Speech Recognition\u201d in Assistant settings.\nWhat\u2019s the benefit of saving my audio recordings to my Google Account?\nIf you\u2019d like to help improve our audio recognition technology for everyone, including technologies to help reduce unintended activations for everyone, you can choose to have your audio recordings securely retained and made available to our speech improvement systems. This helps products like Google Assistant improve their ability to understand language even better in the future. Learn more about this process.\nIs anyone other than me able to listen to my saved audio recordings?\nIf you decide to save your audio recordings, portions of them may be reviewed to help us improve our audio recognition technologies, including technologies to help reduce unintended activations for everyone.\nFor example, audio recordings can be used for Google\u2019s audio review process. During this process, a sample of machine-selected audio snippets are disassociated from their Google accounts. Then trained reviewers (which include third parties) can analyze the audio to annotate the recording and verify if the words said were accurately understood by Google\u2019s audio recognition technologies. This helps a product like Google Assistant improve its ability to understand language even better in the future.\nCan the government access my audio recordings?\nGovernment agencies can issue legal processes to Google requesting user data. We carefully review each request in accordance with applicable laws. If a request is overly broad, we may narrow it, or object to producing the requested data. In our Transparency Report, we share the number and types of requests that we receive. Learn more\nDo you sell my audio recordings or other personal information?\nGoogle never sells your audio recordings or other personal information.\nEasy-to-use privacy controls\nTo control which interactions are stored, just say something like \u201cHey Google, delete what I said this week,\u201d and Google Assistant will delete those interactions in \u201cMy Activity.\u201d\nWhere can I find my privacy controls?\nJust ask Google Assistant questions like \u201cWhere can I change my privacy settings?\u201d to get answers to the most common privacy and security questions. Or you can always visit \u201cYour data in the Assistant\u201d directly to access your privacy controls.\nYou mentioned I can delete my Assistant interactions in My Activity. How does that work?\nYou can review and delete your Assistant interactions from My Activity, or by saying \u201cHey Google, delete what I said this week.\u201d Visit your Assistant settings to access additional controls.\nCan I set up my data to auto-delete?\nYes, you can have your activity data auto-delete from My Activity. Choose a time limit for how long you want your activity data to be saved there\u2013 3, 18, or 36 months \u2013 and any data older than that will be automatically deleted from My Activity on an ongoing basis.\nHow does Google Assistant use data to personalize my experience?\nData from your Google Account can personalize your Google Assistant experience and make your Assistant more useful to you.\nThere are certain questions that require your data for Google Assistant to help. For example, if you ask \u201cWhen is my mom\u2019s birthday?\u201d your Assistant needs to reference your contacts to know who \u201cmom\u201d is and look up her birthday. Or if you ask \u201cDo I need an umbrella tomorrow?\u201d your Assistant uses your current location to give you the most relevant answer.\nGoogle Assistant also uses data to provide you with proactive suggestions. For example, your Assistant can notify you when there is traffic on your regular routes by using your location.\nGoogle Assistant can improve your results using activity in your Google Account. For example, if you ask \u201cWhat should I make for dinner tonight?\u201d your Assistant may use previous Search history to provide personalized recipe recommendations.\nYou can always visit \u201cYour data in Google Assistant\u201d to view or delete your data, check your current settings, and learn more about the controls available.\nVisit Google\u2019s Privacy Policy to learn more about how Google protects and uses your data.\nCan I control if Google Assistant gives me personalized results?\nYes. Google Assistant makes it easy for multiple users to each have a personalized experience on a shared device. To receive personal results \u2013 like directions to work or personalized recipe recommendations \u2013 only when your Assistant recognizes your voice, set up Voice Match by following these steps. Family Link users can also get personal results from Google Assistant by following these steps.\nOn mobile and shared devices like speakers, you can control access to personal results by changing your settings. And on mobile, you can control how personal results appear on your lock screen.\nHey Google, tell me about Guest Mode\nWith Google Assistant\u2019s Guest Mode, you now have even more control over your Assistant activity on your home devices. By saying \u201cHey Google, turn on Guest Mode,\u201d you can turn on Guest Mode whenever you don\u2019t want Assistant interactions to be saved to your Google Account or used to personalize your experience. You can leave Guest Mode at any time to return to a personalized experience. Just say, \u201cHey Google, turn off Guest Mode.\u201d Guest Mode is now available on Google speakers and Smart Displays in English, with more languages to follow.\nHow do I turn on Guest Mode? And will it remain in the mode until I choose to turn it off?\nTo turn on Guest Mode, just say, \u201cHey Google, turn on Guest Mode\u201d to your speaker or Smart Display. To return to your personalized Assistant experience, just say, \u201cHey Google, turn off Guest Mode.\u201d Your device will remain in Guest Mode until you or someone else requests to exit the mode.\nHow will I know if my device is in Guest Mode?\nWhen you're in Guest Mode, your device will play a special chime. On displays, you'll also see a guest icon on the screen. And if you\u2019re not sure, you can always ask. Just say, \u201cHey Google, is Guest Mode on?\"\nCan anyone turn Guest Mode on or off on my device?\nYes, anyone interacting with your device can turn Guest Mode on and off.\nWhat about kids? Will they be able to turn Guest Mode on and off?\nChildren that have an account linked to Google Assistant will not be able to turn on Guest Mode.\nIf I turn on Guest Mode on one device, will it turn on for all of my devices?\nNo, putting a device in Guest Mode does not turn it on for multiple devices.\nWhat features work while I\u2019m in Guest Mode? What doesn\u2019t work?\nIn Guest Mode, you can still enjoy the convenience of your Assistant, like asking questions, controlling smart home devices, setting timers, and playing music. However, personalized results will not be available until you leave Guest Mode. These include your calendar, shopping lists, saved contacts and more. At any time, you can say, \u201cHey Google, turn off Guest Mode\u201d to return to your personalized experience.\nWhen Guest Mode is turned on, can other apps still save my history?\nYour Assistant interactions, including all of your voice queries, won\u2019t be saved to your Google Account. If you ask your Assistant to interact with another app or service, like your music provider or another Google product, that app or service may still retain your activity history within that app.\nHow does using Guest Mode affect my future experience with Google Assistant? For example, will I see personalized recommendations based on my Guest Mode activity?\nWhile in Guest Mode, your Google Assistant activity history won\u2019t be saved to your Google Account and won\u2019t be used to personalize your Assistant experience. For example, if you look up recipes while in Guest Mode, those searches will not be used by Google to tailor recipe recommendations for you in the future. However, because other products may still save your activity if you interact with them while in Guest Mode, your YouTube and Maps activity while in Guest Mode may still be used to recommend future videos and places to go.\nIf I\u2019ve already chosen to save my audio recordings with Assistant, will those recordings still be saved while in Guest Mode?\nEven if your audio recordings and Assistant activity on the device are normally saved to your Google Account, this won't happen in Guest Mode.\nBuilt for families\nGoogle Assistant offers a range of ways to keep your whole family entertained and on track. Tools like Family Link can help you manage how your family interacts with Assistant.\nHow does Google Assistant provide family-friendly content?\nGoogle Assistant provides a variety of activities, from stories, to games, to learning tools for children and families, including some content provided by third-party developers. These developers must qualify to publish content for families on Assistant by having a Teacher Approved app, or entering into a partnership agreement with Google for their family-friendly Action. Any Actions intended for children provided by third-party developers must meet specific requirements of our Actions for Families program, in addition to our standard Action policies. We review these Actions for compliance with our policies and requirements before they are generally available in Google Assistant.\nHow can I manage what content my family members get through Google Assistant?\nYou can set content controls for shared devices in your home, like smart displays, using the Digital Wellbeing controls in the Google Home app. With these settings, you can manage downtime schedules, content filtering settings, and limit certain activities, such as phone calls. You can also decide if these settings apply to guests and supervised accounts managed with Family Link, or all users of that device.\nYou can set limits for individual children using the parental controls offered in Family Link. On shared devices, you can link your child\u2019s account to the device using Voice Match, so Assistant can recognize them. Once your child is enrolled, they can only access non-Google Actions with the \u201cFor families\u201d badge and are prevented from taking certain actions, such as making purchases through Assistant. These limits apply on any Google Assistant devices where they are enrolled. For more information about how a Family Link account works with Google Home and Assistant, see the Google for Families Help.\nHow does Google Assistant protect kids' personal information?\nGoogle does not share personal information, such as your child's name, email address, voice recordings, or specific location, to Actions for Families providers. These providers also agree to not solicit personal information from users in their Google Assistant conversations. We take action if we find any Actions violating these policies.\nDoes Google Assistant listen to and save audio recordings from children\u2019s features?\nWe do not save audio recordings from interactions with children\u2019s features like Actions for Families activities or YouTube Kids videos, unless we have consent to do so for a Google Account Managed with Family Link that has opted in to include audio recordings. For more details, see our Privacy Notice.\nCan I remove any data from my child's Google Assistant activities?\nYes. You can access, export, and delete your child\u2019s saved activity by signing into their account managed by Family Link. You can also manage your child\u2019s activity settings through the Family Link app, or by visiting families.google.com and clicking on the child\u2019s profile. For more details, go to g.co/childaccounthelp."
    },
    {
      "url": "https://www.optery.com/?utm_source=google-ads&utm_campaign=New-Branded-Search-Beta&utm_agid=131341180480&utm_term=optery&creative=560443328282&device=c&placement&gad_source=1&gad_campaignid=15039018404&gbraid=0AAAAAoKgTZ6uXhD2fRvpimwNHr8_f04Y_&gclid=Cj0KCQjwn8XFBhCxARIsAMyH8Bv1URW_8Ra8ngC-T9YmeAI2U1XmAmwA4wg5tSLILl5LawUaucf209waAnxVEALw_wcB",
      "text": "Remove your home address, phone and other private info from Google, and 645+ sites\nSign up Free to receive your personalized Exposure Report.\nUpgrade to a paid plan, and we\u2019ll manage the removals for you.\nWe cover 645+ sites \u2013 more than any other service by far.\n30-day, no questions asked, money back guarantee!\nSign up Free to receive your personalized Exposure Report.\nUpgrade to a paid plan, and we\u2019ll manage the removals for you.\nWe cover 645+ sites \u2013 more than any other service by far.\n30-day, no questions asked, money back guarantee!\nWhy opt out of data brokers?\nWhy choose Optery\nBest Opt Out Software Product\nPatented and Proprietary Technology\nUnited States Headquarters\nNo Affiliation with Data Brokers\nLive Screenshots Prove Our Work\n30-Day Money Back Guarantee\nWe're Laser Focused on Privacy Rights\nOutstanding Customer Support\nSOC 2 TYPE 2 Compliant\nMost Advanced Features\nBacked by\nAccredited By\nSOC 2, Type II Certified\nAs Seen On\nWe are constantly improving\nYou\u2019re busy, so we make it easy\nEven more cool features at your command\nWe cover more and more data brokers\n|\nData Brokers Scanned |\nProfiles Found |\n| 395 | 50 |\nBest-in-the-industry Dashboard and Free Exposure Reports\nDetailed FAQ and our outstanding Customer Support to serve you\nUnlimited Custom Removals for data brokers we don\u2019t cover (Ultimate plan customers)\nMulti-factor Authentication for account security\nFrequently Asked\nQuestions\nHow do I modify, cancel or pause my subscription and billing?\nOptery provides complete control over your subscription and billing from the Plans page after logging into your account. If you have any trouble updating your billing or subscription on your own, just email us at support@optery.com and we\u2019ll help you right away.\nUpgrades & Downgrades: If you want to upgrade or downgrade your plan, or change from Monthly to Yearly, you can do so from the Plans page after logging into your account. Just click the \u201cMonthly\u201d or \u201cYearly\u201d and \u201cUpgrade\u201d or \u201cDowngrade\u201d buttons above and follow the prompts. There\u2019s no reason to cancel your plan to make changes.\nPause Billing: You can pause your subscription and billing at any time by navigating to your Account page, scrolling down and clicking the button to \u201cPause Subscription\u201d.\nCancellation: You can cancel your plan from this page by navigating to your Account page after logging into your account, scrolling down and clicking the button to \u201cCancel Subscription\u201d. After your paid plan is cancelled, all future billing will stop, but your plan will remain active for the remainder of your billing term, and then will downgrade automatically to the Free Basic tier AFTER your billing term ends so you receive the full value of your last subscription payment.\nStop Auto-Renew: By default, Optery\u2019s subscriptions auto-renew at the end of your billing term (i.e. Monthly or Yearly). Simply cancel your plan at any time using the instructions above to stop the auto-renew process. After your paid plan is cancelled, all future billing will stop, but your plan will remain active for the remainder of your billing term, and then will downgrade automatically to the Free Basic tier AFTER your billing term ends so you receive the full value of your last subscription payment.\nYou can learn more about our billing and payments options on our Help Desk section on Billing & Payments.How does your money back guarantee work?\nIf you are not satisfied with your purchase, within 30 days of your first purchase, cancel your account and then send your refund request to support@optery.com and your refund will be processed within 5 \u2013 10 business days. Once your refund is processed, your Optery subscription service will discontinue immediately and your account will automatically be downgraded to Free Basic. More details on the refund process can be found on our Help Desk here.\nHow can I resolve a billing error or discrepancy I have found?\nBilling errors are rare as we have an advanced system via our payment processor Stripe configured to automatically handle upgrades, downgrades, paused subscriptions, and cancellations. That said, we take the accuracy of your payments and billing very seriously, so if you feel you\u2019ve found an error or have any questions about your billing or payments, please send us an email at support@optery.com and we\u2019ll investigate and resolve it right away.\nAfter upgrading, how long does it take for my profiles to be removed?\nSome data brokers comply within 24 hours, while others take several weeks, and sometimes months to comply. Each case is unique, but rest assured we are doing our best to streamline the process for you. To set the proper expectations, and in full transparency, getting hundreds of data brokers to comply with opt out requests is a \u201cwhack-a-mole\u201d game that is often never-ending. It is unlikely that within a few weeks or months ALL instances of your information will be deleted. If that is your expectation, we recommend not using our service as we don\u2019t want you to be disappointed. Customer satisfaction and the security of your data are always our top priorities. That said, Optery is very effective at removing the vast majority of exposed profiles on an ongoing basis, and the vast majority of Optery customers are extremely pleased with the results.\nWill Optery completely stop all of my robo calls and email spam?\nNo. Optery is not an \u201coff\u201d switch for unwanted email spam and robo calls. Many Optery customers report a dramatic decrease in the volume of unwanted email and phone calls, but this is not the specific function of the product. Instead, the primary purpose of Optery is to protect your privacy by removing you from data broker sites posting your personal information on the internet. By removing you from these sites, we take your information like home address, phone number, email, and family members\u2019 names out of circulation reducing your attack surface area by bad actors. Optery is part of a wholistic security and privacy approach that reduces your profile online and makes you a more difficult target to attack.\nWhat type of sites does Optery NOT cover?\nOptery only removes from data brokers and people search sites, most of which are listed inside your Optery Dashboard.\nOptery does NOT cover general web sites like blogs, news sites, celebrity sites, community web sites, personal web sites, discussion boards, forum web sites, pornography sites, wiki sites, photo sites, video sites, computer programming web sites, legal records sites, documents posted online (e.g. PDFs, TXTs), or social media sites like LinkedIn, Pinterest, Facebook, Snap, TikTok, Twitter, etc.\nOptery does NOT remove information from the Dark Web and does Not currently provide Dark Web scanning or reporting. Removing your personal information from the Dark Web is impossible as it is usually placed there by hackers, scammers, spammers, and criminals illegally \u2013 and there\u2019s nothing you can do to remove it \u2013 which is partly why it\u2019s referred to as the Dark Web.\nIf you need information removal from sites that Optery does not cover, then Optery is not the right solution for you.Will Optery be able to remove 100% of my information from the internet?\nNo, in the majority of cases, Optery will not be able to remove 100% of your information from the Internet.\nFirstly, Optery only covers data broker and people search web sites, so by definition, Optery will not remove your information from other types of sites like blogs, news sites, discussion boards, wiki sites, photo sites, legal records sites, or social media sites like LinkedIn, Pinterest, or Facebook.\nFurthermore, Optery\u2019s Terms of Service state: \u201cOptery will use good faith, reasonable efforts to provide the Removal Services, but there is no guarantee or warranty of any kind that third parties will honor or comply with the opt out, data deletion, do not sell, do not share, suppression or removal requests; and It is not possible for Optery to remove 100% of your personal information from the Internet, or even from all of the data brokers and information aggregators covered by the Removal Services.\u201d\nOptery is able to remove the vast majority of it, but inevitably there are data brokers that may refuse to comply with our requests, data brokers that change their opt out processes causing us trouble, profiles that pop back up and re-populate over time, and the reality is that unfortunately our opt out software is not 100% perfect at this time. This is why most of our customers choose to keep the subscription running on an ongoing basis, to employ our service on a ongoing basis to continually scan and remove over time.\nIf you do encounter sites that have mistakenly been marked \u201cRemoved / Not Found\u201d when they are still present, or data broker sites not currently covered by the Ultimate plan, you can submit these sites via our Removals Issues and Custom Removals functionality.\nNot withstanding the above, the vast majority of Optery customers are very happy with their results.How does Optery opt out on my behalf?\nOptery reaches out to multiple data brokers on your behalf and automatically submits your opt out requests to remove your Personal Identifiable Information (PII) from their database(s). We use a \u201chumans + machines\u201d approach that combines the most advanced automated opt out technology with hands-on expert human privacy agents to deliver maximum removals compared to any other service in the industry. This is one of the reasons why Optery has won the coveted \u201cEditors\u2019 Choice\u201d award by PCMag.com in 2022, 2023, 2024 and 2025 as the most outstanding personal data removal product on the market, and why Optery was the #1 most effective product in a recent study by Consumer Reports.\nOptery was also named a winner in the Security and Privacy category for Fast Company\u2019s 2023 Next Big Things in Tech awards, and named winner in the Employee Privacy Protection, Attack Surface Management, and Digital Footprint Management categories of the 2024 and 2025 Cybersecurity Excellence Awards.How do your Family plans and family plan discounts work?\nYou can learn all about how Optery for Family works on our Help Desk here.\nWhat are the main differences between different plan tiers?\nThe primary differences between the Core, Extended, and Ultimate plans are related to the data brokers each plan covers, and the availability of unlimited Custom Removals. You can scroll to the section titled Need Help Choosing a Plan? on our Pricing page for full details on which data brokers each plan covers, and the differences between each plan, or you can visit our Help Desk post covering the differences between plans. To summarize:\nFree Basic Plan \u2013 free quarterly exposure reporting and self-service tools\nCore Plan \u2013 low-cost, no frills, plan for ongoing basic coverage\nExtended Plan \u2013 best value plan\nUltimate Plan \u2013 most comprehensive coverage, our most popular plan by farDoes Optery offer an Affiliate Program or Referral Program?\nYes. Optery has a fantastic Affiliate Program and Referral Program enabling you to earn money promoting our award-winning personal data removal service. Have confidence you\u2019re recommending the most effective product on the market."
    },
    {
      "url": "https://www.eff.org/about/staff/eva-galperin",
      "text": "Eva Galperin\nEva Galperin is EFF's Director of Cybersecurity. Prior to 2007, when she came to work for EFF, Eva worked in security and IT in Silicon Valley and earned degrees in Political Science and International Relations from SFSU. Her work is primarily focused on providing privacy and security for vulnerable populations around the world. To that end, she has applied the combination of her political science and technical background to everything from organizing EFF's Tor Relay Challenge, to writing privacy and security training materials (including Surveillance Self Defense and the Digital First Aid Kit), and publishing research on malware in Syria, Vietnam, Lebanon, and Kazakhstan. Since 2018, she has worked on addressing the digital privacy and security needs of survivors or domestic abuse. She is also a co-founder of the Coalition Against Stalkerware."
    },
    {
      "url": "https://oag.ca.gov/data-brokers",
      "text": "Subscribe to Our Newsletter\nRecent amendments to the Data Broker Registration statute now require a data broker to register with the California Privacy Protection Agency. Effective January 1, 2024, the Attorney General will no longer accept or process data broker registrations. Instead, this page will be maintained for consumers to view historical information about data broker registrations from 2020 to 2023. Data brokers seeking to register should visit the Agency\u2019s data brokers registration page.\nYou can search by the name of the data broker, or simply scroll through the list. To read a notice, click on the link titled \"View Full Submission.\" You may also download the entire list by clicking on \"Download CSV\".\nView Incomplete 2023 Registrations\nView Incomplete 2022 Registrations\nView Incomplete 2021 Registrations\n| Data Broker Name | Link | Email Address | Website URL |\n|---|---|---|---|\n| Sharethrough Inc. |\nView Full Submission\nData Broker Name:\nSharethrough Inc.\nEmail Address:\nWebsite URL:\nPhysical Address:\n5455 Av. de Gasp\u00e9 #730 Montreal, QC H2T 3B3\nCanada\nHow a consumer may opt out of sale or submit requests under the CCPA:\nhttps://privacy-center.sharethrough.com/en/do-not-sell-my-personal-information/\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nhttps://privacy-center.sharethrough.com/en/user-rights/\nAdditional information about data collecting practices:\nhttps://privacy-center.sharethrough.com/en/\n|\ndataprotection [at] sharethrough.com | https://www.sharethrough.com/ |\n| CRISIL Irevna US LLC |\nView Full Submission\nData Broker Name:\nCRISIL Irevna US LLC\nEmail Address:\nWebsite URL:\nPhysical Address:\n55 Water St. New York, NY 10041\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nOur Global Privacy Policy articulates the process to opt out of requests under CCPA under Clause 9 of the Global Privacy Policy, the link to the policy is https://www.crisil.com/en/home/crisil-privacy-notice.html.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nPlease refer to Clause 9 of our Global Privacy Policy (https://www.crisil.com/en/home/crisil-privacy-notice.html), along with the Appendix in the Global Privacy Policy, that provides for legal rights of individuals to delete their data.\nAdditional information about data collecting practices:\nCRISIL licenses demographic information on US businesses, including names and contact information of business owners, a registered data broker. CRISIL appends additional, non-PII information about business opportunities with these companies based on our propriety analytics and makes this dataset (including the demographic information) available to our customers.\n|\nPrivacy1 [at] crisil.com | https://www.greenwich.com/ |\n| Madhive, Inc. |\nView Full Submission\nData Broker Name:\nMadhive, Inc.\nEmail Address:\nWebsite URL:\nPhysical Address:\n225 Broadway\n11th Fl New York, NY 10007\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nFooter on our website (madhive.com) where you click Do Not Sell My Personal Information. On our privacy policy by clicking on the link stat states Opt out of sale/sharing, targeted advertising and profiling via the Platform. By emailing ccpa-request@madhive.com or calling our toll free number 1-866-467-8688 (service code 1803).\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nBy emailing ccpa-request@madhive.com or calling our toll free number 1-866-467-8688 (service code 1803).\nAdditional information about data collecting practices:\nNo information provided.\n|\nprivacy [at] madhive.com | http://madhive.com |\n| Converge Direct, LLC. |\nView Full Submission\nData Broker Name:\nConverge Direct, LLC.\nEmail Address:\nWebsite URL:\nPhysical Address:\n25 W 39th St\n6th Floor New York, NY 10018\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nConsumers may opt out of our data sources via email, form, phone, physical mail or opt out links embedded in communications.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nConsumers may demand deletion from data sources via email, form, phone or physical mail.\nAdditional information about data collecting practices:\nNo information provided.\n|\ncompliance [at] convergedirect.com | https://convergemarketing.com/ |\n| Round Sky, Inc. |\nView Full Submission\nData Broker Name:\nRound Sky, Inc.\nEmail Address:\nWebsite URL:\nPhysical Address:\n848 N. Rainbow Blvd\nste 326 Las Vegas, NV 89107\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nFor additional information, please visit our website at: https://www.roundsky.com/consumerprivacypolicy.php\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nN/A \u2013 we do not post consumer information online.\nAdditional information about data collecting practices:\nNo information provided.\n|\nlegal [at] roundsky.com | https://www.roundsky.com/ |\n| Emailmovers Ltd |\nView Full Submission\nData Broker Name:\nEmailmovers Ltd\nEmail Address:\nWebsite URL:\nPhysical Address:\nSuite 4, William Street Business Center\n7A Lower Clark Street Scarborough\nYO12 7PP How a consumer may opt out of sale or submit requests under the CCPA:\nDo Not Sell My Information email - compliance@emailmovers.com\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nDo Not Sell My Information email - compliance@emailmovers.com\nAdditional information about data collecting practices:\nEmailmovers Ltd provides Non-HR business data that we get from a number of sources; a) Our research team sources information from publicly available information, b) Users provide data about themselves or other companies & people, c) We license data from other data providers. Our data is not considered sensitive or protected by HIPPA / FCRA.\n|\ncompliance [at] emailmovers.com | http://www.emailmovers.com |\n| Pathway Ventures, LLC |\nView Full Submission\nData Broker Name:\nPathway Ventures, LLC\nEmail Address:\nWebsite URL:\nPhysical Address:\n2438 Industrial Blvd #503 Abilene, TX 79605\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nOnline form at https://www.protectdataprivacy.com/\nCall (866) 259-7740 How a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nOnline form at https://www.protectdataprivacy.com/\nCall (866) 259-7740 Additional information about data collecting practices:\nNo information provided.\n|\nprivacyofficer [at] indivizio.com | http://indivizio.com |\n| Nymblr, Inc. |\nView Full Submission\nData Broker Name:\nNymblr, Inc.\nEmail Address:\nWebsite URL:\nPhysical Address:\n651 North Broad Street\n201 Middletown, DE 19709\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nVisit our website homepage at https://www.nymblr.com and scroll to the footer where you can request to opt out.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nVisit our website homepage at https://www.nymblr.com and scroll to the footer where you can request to be deleted.\nAdditional information about data collecting practices:\nOur data is collected via licensure from other entities listed as California Data Brokers.\n|\nprivacy [at] nymblr.com | https://www.nymblr.com |\n| LizDev, Inc |\nView Full Submission\nData Broker Name:\nLizDev, Inc\nEmail Address:\nWebsite URL:\nPhysical Address:\n109 Waterman Irvine, CA 92602\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nAt original page of origin of opt-in or by emailing directly the email on any privacy policy page.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nAt original page of origin of opt-in or by emailing directly the email on any privacy policy page.\nAdditional information about data collecting practices:\nWe do not own any of the websites where data is collected.\n|\nliz [at] lizdev.com | http://www.lizdev.com |\n| adsquare GmbH |\nView Full Submission\nData Broker Name:\nadsquare GmbH\nEmail Address:\nWebsite URL:\nPhysical Address:\nSaarbruecker Str. 36 10405 Berlin\nGermany\nHow a consumer may opt out of sale or submit requests under the CCPA:\nCalifornia consumers may opt out of the sale of their personal information by submitting a request via our Privacy Center at www.adsquare.com/privacy/. Consumers may also submit an email request to privacy@adsquare.com or by direct mail. Our mailing address is: adsquare GmbH, Attn: Legal Counsel, Saarbruecker Str. 36, 10405 Berlin, Germany. Detailed information and instructions on how a California consumer may exercise their rights under CCPA can be found at www.adsquare.com/privacy/us_privacy_supplement/\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nCalifornia consumers may demand deletion of their personal information by submitting a request via our Privacy Center at www.adsquare.com/privacy/. Consumers may also submit an email request to privacy@adsquare.com or by direct mail. Our mailing address is: adsquare GmbH, Attn: Legal Counsel, Saarbruecker Str. 36, 10405 Berlin, Germany. Detailed information and instructions on how a California consumer may exercise their rights under CCPA can be found at www.adsquare.com/privacy/us_privacy_supplement/\nAdditional information about data collecting practices:\nMore details on Adsquare's data processing can be found in our Platform Privacy Policy at www.adsquare.com/privacy/platform_privacy_policy/ and the US Supplement at www.adsquare.com/privacy/us_privacy_supplement/.\n|\nprivacy [at] adsquare.com | http://www.adsquare.com |\n| Buxton Company, LLC |\nView Full Submission\nData Broker Name:\nBuxton Company, LLC\nEmail Address:\nWebsite URL:\nPhysical Address:\n2651 S Polaris Drive Fort Worth, TX 76020\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nFilling out the request form linked here: Consumer Rights Requests - https://www.buxtonco.com/privacy\nCalling Us toll-free at 1-888-228-9866 Mailing your request to: Buxton, (attention \u201cConsumer Privacy\u201d) at 2651 South Polaris Drive, Fort Worth, TX 76137 How a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nFilling out the request form linked here: Consumer Rights Requests - https://www.buxtonco.com/privacy\nCalling Us toll-free at 1-888-228-9866 Mailing your request to: Buxton, (attention \u201cConsumer Privacy\u201d) at 2651 South Polaris Drive, Fort Worth, TX 76137 Additional information about data collecting practices:\nNo information provided.\n|\nlegal [at] buxtonco.com | http://buxtonco.com |\n| Diablo Media |\nView Full Submission\nData Broker Name:\nDiablo Media\nEmail Address:\nWebsite URL:\nPhysical Address:\n3001 Brighton Blvd #769 denver, CO 80216\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nhttps://www.everydayresources.com/opt-out\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nprivacy@everdayresources.com\nAdditional information about data collecting practices:\nNo information provided.\n|\ndata [at] diablomedia.com | http://www.diablomedia.com |\n| MY RENTER CHECKER LLC |\nView Full Submission\nData Broker Name:\nMY RENTER CHECKER LLC\nEmail Address:\nWebsite URL:\nPhysical Address:\n7700 Irvine Center Drive\nSuite 800 Irvine, CA 92618\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nThey can fill out our contact form or email us directly to opt out.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nThey can fill out our contact form or email us directly to demand the deletion of their information.\nAdditional information about data collecting practices:\nThe data that is submitted to / given to us is and will be anonymous. Our system collects certain pieces of data and offers a pay to view the data.\n|\nMYRENTERCHECKER [at] GMAIL.COM | http://www.myrenterchecker.com |\n| TL1MKT SL SL |\nView Full Submission\nData Broker Name:\nTL1MKT SL SL\nEmail Address:\nWebsite URL:\nPhysical Address:\nCalle Secretario Carretero, number 7-local 12, 14004, Cordoba 14004 Cordoba M\u00e1laga\nSpain\nHow a consumer may opt out of sale or submit requests under the CCPA:\ncontact via data@tl1mkt.com or https://www.tl1mkt.com/contact.html\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\ncontact via data@tl1mkt.com or https://www.tl1mkt.com/contact.html\nAdditional information about data collecting practices:\nhttps://www.tl1mkt.com/contact.html\n|\ninfo [at] tl1mkt.com | https://www.tl1mkt.com |\n| Steppingblocks, Inc. |\nView Full Submission\nData Broker Name:\nSteppingblocks, Inc.\nEmail Address:\nWebsite URL:\nPhysical Address:\n3423 Piedmont Rd NE\nSuite R17 Atlanta, GA 30305\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nThe individual can visit https://www.steppingblocks.com/personal-information-inquiry to submit a request. We may need to verify this is the individual whose information is being requested for opt-out, and we will respond accordingly.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nThe individual can visit https://www.steppingblocks.com/personal-information-inquiry to submit a request. We may need to verify this is the individual whose information is being requested for opt-out, and we will respond accordingly.\nAdditional information about data collecting practices:\nNo information provided.\n|\nprivacy [at] steppingblocks.com | https://www.steppingblocks.com/ |\n| Modigie Inc. |\nView Full Submission\nData Broker Name:\nModigie Inc.\nEmail Address:\nWebsite URL:\nPhysical Address:\n36 Main St. Tiburon, CA 94920\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nA consumer can navigate to https://modigie.com/trust/ and follow the link to the data subject request / opt out tool found here:\nhttps://privacyportal.onetrust.com/webform/4a8e10dc-2293-42ea-ad06-886bc22167a6/20341940-11c2-4c43-9b64-194e952203fd How a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nA consumer can navigate to https://modigie.com/trust/ and follow the link to the data subject request to demand deletion here:\nhttps://privacyportal.onetrust.com/webform/4a8e10dc-2293-42ea-ad06-886bc22167a6/20341940-11c2-4c43-9b64-194e952203fd Additional information about data collecting practices:\nModigie clients gather business contact information on individuals working in certain business organizations through means not known to Modigie. The information provided to Modigie by clients is:\nName Business Email Address Company LinkedIn URL (Optional) Modigie uses this information to validate and / or enrich client provided information so they can better serve their target clients. Modigie does not collect or sell information such as home addresses, government identification numbers, or other sensitive personal data. |\nprivacy [at] modigie.com | http://www.modigie.com |\n| Consider, Inc. |\nView Full Submission\nData Broker Name:\nConsider, Inc.\nEmail Address:\nWebsite URL:\nPhysical Address:\n303 Twin Dolphin Drive\nSuite 600 Redwood City, CA 94065\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nConsumers can request to opt out by emailing support@consider.com\nMailing Address: 303 Twin Dolphin Drive Suite 600 Redwood City, CA 94065 How a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nConsumers can demand deletion of their information by emailing support@consider.com\nMailing Address: 303 Twin Dolphin Drive Suite 600 Redwood City, CA 94065 Additional information about data collecting practices:\nFor more information, please see our Privacy Policies at https://consider.com/legal/privacy\n|\nralph [at] consider.com | https://consider.com |\n| Mobile Technology Corporation |\nView Full Submission\nData Broker Name:\nMobile Technology Corporation\nEmail Address:\nWebsite URL:\nPhysical Address:\n7173 S Havana Street\nSuite 600-235 Centennial, CO 80112\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nClick on the \"Privacy Opt Out\" button located on each of our web pages and submit the request.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nClick on the \"Privacy Opt Out\" button located on each of our web pages and submit the request.\nAdditional information about data collecting practices:\nNo information provided.\n|\ninfo [at] onspotdata.com | http://www.onspotdata.com |\n| Nexxen Inc |\nView Full Submission\nData Broker Name:\nNexxen Inc\nEmail Address:\nWebsite URL:\nPhysical Address:\n100 Redwood Shores 3rd Floor Redwood City, CA 94065\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nYes. We also have developed and utilize our own opt-out tool which is located at https://yourdata.tremorinternational.com/\n\" How a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nhttps://yourdata.tremorinternational.com/\nAdditional information about data collecting practices:\nhttps://www.tremorinternational.com/privacy/\n|\namobeeprivacy [at] amobee.com | https://www.nexxen.com/ |\n| Machintel |\nView Full Submission\nData Broker Name:\nMachintel\nEmail Address:\nWebsite URL:\nPhysical Address:\n4275 Executive Sq\nSte 200 La Jolla, CA 92037\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nOnline through the website, by phone, or by mail.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nOnline through the website, by phone, or by mail.\nAdditional information about data collecting practices:\nNo information provided.\n|\ndpo [at] machintel.com | http://machintel.com |\n| Staircase, Inc. |\nView Full Submission\nData Broker Name:\nStaircase, Inc.\nEmail Address:\nWebsite URL:\nPhysical Address:\n2093A Philadelphia Pike\nSuite 452 Claymont, DE 19703\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\n1) Internet web page: Customers will be able to identify themselves and claim profile with full update, edit, delete capabilities\n2) Email: optout@staircase.co How a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\n1) Internet web page: Customers will be able to identify themselves and claim profile with full update, edit, delete capabilities\n2) Email: optout@staircase.co Additional information about data collecting practices:\nNo information provided.\n|\noptout [at] staircase.co | https://staircase.co/ |\n| True Blue Analytics LLC |\nView Full Submission\nData Broker Name:\nTrue Blue Analytics LLC\nEmail Address:\nWebsite URL:\nPhysical Address:\n919 N Market St Suite 950 Wilmington, DE 19801\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nA consumer may opt out by selecting 'Do Not Sell My Personal Information' on our website or by going to https://www.trueblueanalytics.org/dontsellmydata and submitting their information. It will then promptly be removed.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nWe do not currently post any information online about protected individuals. However, an individual can go to https://www.trueblueanalytics.org/dontsellmydata and have their information removed from our dataset and we will ensure there is no information posted online by us.\nAdditional information about data collecting practices:\nWe purchase data from a multitude of sources.\n|\nsales [at] trueblueanalytics.org | http://www.trueblueanalytics.org |\n| InfoPay, Inc |\nView Full Submission\nData Broker Name:\nInfoPay, Inc\nEmail Address:\nWebsite URL:\nPhysical Address:\n227 Lewis Wharf Boston, MA 02110\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nA consumer can opt out of sale or submit CCPA-related requests through the link https://www.infopay.com/privacy, other associated links on our site, or by reaching out to us directly at privacy@infopay.com or by phone at (800) 309-9351.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nIndividuals wishing to request the deletion of their online information can start by clicking on https://www.infopay.com/privacy or by finding the \"Exercise my privacy rights\" links on our affiliate websites. If you need further assistance or have any inquiries, please contact us via email at privacy@infopay.com, by phone at (800) 309-9351, or by mail at: 28 Atlantic Ave Suite 227\nBoston, MA 02110.\nAdditional information about data collecting practices:\nKindly refer to our privacy policy for the most recent information on our data collection practices: https://www.infopay.com/privacy.\n|\ncompliance [at] infopay.com | https://www.infopay.com/ |\n| SpyCloud, Inc. |\nView Full Submission\nData Broker Name:\nSpyCloud, Inc.\nEmail Address:\nWebsite URL:\nPhysical Address:\n2130 S. Congress Ave. Austin, TX 78704\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nCalifornia consumers may opt out of sale or submit requests under the CCPA by sending an email to privacy@spycloud.com.\nHow a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nSpyCloud does post any personal information online for public viewing.\nAdditional information about data collecting practices:\nNo information provided.\n|\nprivacy [at] spycloud.com | https://spycloud.com/ |\n| Factori Technologies LLC |\nView Full Submission\nData Broker Name:\nFactori Technologies LLC\nEmail Address:\nWebsite URL:\nPhysical Address:\n8th Green STE A, Dover Kent, DE 19901\nUnited States\nHow a consumer may opt out of sale or submit requests under the CCPA:\nUsers can opt-out via this Do Not Sell link\nhttps://www.factori.ai/do-not-sell-my-information How a protected individual can demand deletion of information posted online under Gov. Code sections 6208.1(b) or 6254.21(c)(1):\nUsers can make request for deletion by emailing privacy@factori.ai\nAdditional information about data collecting practices:\nNo information provided.\n|\nprivacy [at] factori.ai | http://www.factori.ai |"
    },
    {
      "url": "https://easyoptouts.com/",
      "text": "Your personal information is all over the internet. We'll help you opt out. Only $19.99 per year.\nProtect yourself from hacking, phishing, doxing, and stalking.\nAs seen in Consumer Reports, ArsTechnica, and Privacy Guides.\nYour name, address, and phone number are available for anyone to view on people-search sites. Unless you opt out, your privacy is compromised.\nWe make it easy and affordable to remove yourself from over 160 websites.\nSIGN UP - $19.99/YEARWe believe that everyone has the right to privacy.We think it's wrong for websites to share our data without our permission.Our mission is to provide easy opt-outs at a price that everyone can afford.\nOur mission is to provide easy opt-outs at a price that everyone can afford.\nHow it works\n1. Enter your data\nFill out the sign-up form. We don't need anything sensitive like your ID or SSN.\n2. Scan and opt out\nWe search for your data on the supported sites. Wherever you're found, we opt you out! You don't need to do anything.\n3. Reports\nOnce we're done, we'll email you a report to tell you where you were opted out.\nWhy choose EasyOptOuts?\n- Affordable: a fraction of the price of other similar services.\n- Independent: no ties to the data brokers we're opting you out of, and no investor pressure, unlike some competitors.\n- Thorough: we search for all combinations of your name and address to find records that would be missed otherwise.\n- Private: we ask you for as little of your information as is necessary, and we don't share any of your data for any reason except to perform opt-outs.\nAbout us\nWe're Ben and Tyler. We're childhood friends who've been building things together since we were kids.\nIt's just us and a couple family members. We're US-based, investor-free, debt-free, and independent of any pressure to compromise our values or your privacy.\nWe looked ourselves up and were surprised by how much of our personal information was visible to the public without our consent. We removed our information from each site, but it was difficult and time-consuming. Each site had a unique opt-out process, usually requiring us to identify exactly where our information appeared on the site.\nWe considered using existing paid services to opt us out, but they were too expensive. We decided to make our own, more affordable service, to make privacy more accessible.\nUnited States privacy laws aren't adequate to stop these sites. We hope that online privacy becomes a right someday so that our service is no longer necessary.\nSIGN UP - $19.99/YEAR"
    },
    {
      "url": "https://bja.ojp.gov/program/it/privacy-civil-liberties/authorities/statutes/1285",
      "text": "MENU\nJUMP TO\nElectronic Communications Privacy Act of 1986 (ECPA), 18 U.S.C. \u00a7\u00a7 2510-2523\nPrivacy Act of 1974\n- Computer Matching and Privacy Act of 1998\nThe National Security Act of 1947\nIntelligence Reform and Terrorism Prevention Act of 2004\nElectronic Communications Privacy Act\nThe Foreign Intelligence Surveillance Act of 1978\nE-Government Act of 2002\n- Federal Information Security Management Act\nThe Communications Act of 1934\nBackground\nThe Electronic Communications Privacy Act and the Stored Wire Electronic Communications Act are commonly referred together as the Electronic Communications Privacy Act (ECPA) of 1986. The ECPA updated the Federal Wiretap Act of 1968, which addressed interception of conversations using \"hard\" telephone lines, but did not apply to interception of computer and other digital and electronic communications. Several subsequent pieces of legislation, including The USA PATRIOT Act, clarify and update the ECPA to keep pace with the evolution of new communications technologies and methods, including easing restrictions on law enforcement access to stored communications in some cases.\nGeneral Provisions\nThe ECPA, as amended, protects wire, oral, and electronic communications while those communications are being made, are in transit, and when they are stored on computers. The Act applies to email, telephone conversations, and data stored electronically.\nCivil Rights and Civil Liberties\n\"The structure of the SCA reflects a series of classifications that indicate the drafters\u2019 judgments about what kinds of information implicate greater or lesser privacy interests. For example, the drafters saw greater privacy interests in the content of stored emails than in subscriber account information. Similarly, the drafters believed that computing services available \u2018to the public\u2019 required more strict [sic] regulation than services not available to the public\u2026To protect the array of privacy interests identified by its drafters, the [Act] offers varying degrees of legal protection depending on the perceived importance of the privacy interest involved. Some information can be obtained from providers with a subpoena; other information requires a special court order; and still other information requires a search warrant. In addition, some types of legal process require notice to the subscriber, while other types do not.\"\nThe Act reflects a general approach of providing greater privacy protection for materials in which there are greater privacy interests. For a more in-depth analysis, U.S. Dept. of Justice, Searching and Seizing Computers and Obtaining Electronic Evidence In Criminal Investigations (2009), pp. 115-116, (287pp | 1.01mb | PDF).\nSpecific Provisions\nThe ECPA has three titles:\nTitle I of the ECPA, which is often referred to as the Wiretap Act, prohibits the intentional actual or attempted interception, use, disclosure, or \"procure[ment] [of] any other person to intercept or endeavor to intercept any wire, oral, or electronic communication.\" Title I also prohibits the use of illegally obtained communications as evidence. 18 U.S.C. \u00a7 2515.\nExceptions. Title I provides exceptions for operators and service providers for uses \"in the normal course of his employment while engaged in any activity which is a necessary incident to the rendition of his service\" and for \"persons authorized by law to intercept wire, oral, or electronic communications or to conduct electronic surveillance, as defined in section 101 of the Foreign Intelligence Surveillance Act (FISA) of 1978.\" 18 U.S.C. \u00a7 2511. It provides procedures for Federal, State, and other government officers to obtain judicial authorization for intercepting such communications, and regulates the use and disclosure of information obtained through authorized wiretapping. 18 U.S.C. \u00a7\u00a7 2516-2518. A judge may issue a warrant authorizing interception of communications for up to 30 days upon a showing of probable cause that the interception will reveal evidence that an individual is committing, has committed, or is about to commit a \"particular offense\" listed in Section 2516. 18 U.S.C. \u00a7 2518.\nTitle II of the ECPA, which is called the Stored Communications Act (SCA), protects the privacy of the contents of files stored by service providers and of records held about the subscriber by service providers, such as subscriber name, billing records, or IP addresses. 18 U.S.C. \u00a7\u00a7 2701-12.\nTitle III of the ECPA, which addresses pen register and trap and trace devices, requires government entities to obtain a court order authorizing the installation and use of a pen register (a device that captures the dialed numbers and related information to which outgoing calls or communications are made by the subject) and/or a trap and trace (a device that captures the numbers and related information from which incoming calls and communications coming to the subject have originated). 18 U.S.C. \u00a7\u00a7 3121 \u2013 3127. No actual communications are intercepted by a pen register or trap and trace. The authorization order can be issued on the basis of certification by the applicant that the information likely to be obtained is relevant to an ongoing criminal investigation being conducted by the applicant\u2019s agency.\nAmendments\nThe ECPA was significantly amended by the Communications Assistance to Law Enforcement Act (CALEA) in 1994, the USA PATRIOT Act in 2001, the USA PATRIOT reauthorization acts in 2006, and the FISA Amendments Act of 2008 (116pp | 303kb | PDF). Other acts have made specific amendments of lesser significance."
    },
    {
      "url": "https://www.eff.org",
      "text": "The leading nonprofit defending digital privacy, free speech, and innovation for 35 years and counting!\nIn April, WhatsApp launched its \u201cAdvanced Chat Privacy\u201d feature, which, once enabled, disables using certain AI features in chats and prevents conversations from being exported. Since its launch, an inaccurate viral post has been ping-ponging around social networks, creating confusion around what exactly it does.\nThis statement can be attributed to EFF Senior Staff Technologist Cooper Quintin It was recently reported by Jack Poulson on Substack that ICE has reactivated its 2 million dollar contract with Paragon Solutions , a cyber-mercenary and spyware manufacturer. The reactivation of the contract between the Department of Homeland Security and Paragon Solutions, a known spyware vendor, is extremely troubling. This end run around the executive order both ignores the spirit of the rule and does not actually do anything...\nIn 1992 EFF presented our very first awards recognizing key leaders and organizations advancing innovation and championing civil liberties and human rights online. Now in 2025 we're continuing to celebrate the accomplishments of people working toward a better future for everyone with the EFF Awards! All are invited to attend the EFF Awards on Wednesday, September 10 at the San Francisco Design Center. Whether you're an activist, an EFF supporter, a student interested in cyberlaw, or someone who wants to...\nIf you use technology, this fight is yours.\nEFF defends your privacy and free expression because technology should serve all people, not just the powerful. We\u2019re a nonprofit powered by members, and we need you in this fight.\nSurveillance Self-Defense\nDescription:\nSurveillance Self-Defense is EFF's online guide to defending yourself and your friends from surveillance by using secure technology and developing careful practices.\nDigital Rights Bytes\nDescription:\nGet honest answers to the questions that have been bugging you about technology."
    },
    {
      "url": "https://ads.apple.com/app-store/help/attribution/0028-measuring-ad-performance",
      "text": "Measuring performance of ads on the App Store\nFollowing its registration with AdAttributionKit, Apple Ads customers are able to use two freely available and complementary methods for analyzing ad attribution while preserving user privacy: the AdServices attribution API, and measurement in AdAttributionKit.\nApple Ads registration\nwith AdAttributionKit\nApple Ads registered with AdAttributionKit on April 10, 2025 to provide a more comprehensive picture for its developer customers, so they can determine the app conversion and associated post-install activity that comes from running ads on the App Store. The same attribution logic applies to Apple Ads as is used for every other AdAttributionKit-registered ad platform.\nWith the registration of Apple Ads, AdAttributionKit expanded its scope of registered and known ad platforms, increasing visibility into user actions across even more marketing channels. This has helped AdAttributionKit more accurately attribute conversions to the last-clicked ad.\nHow to use AdAttributionKit to view attributed installs for Apple Ads\nApple Ads is currently registered with SKAdNetwork versions 1.0, 2.0, and 3.0 for click-through attribution. Apple Ads will register at a later date with the AdAttributionKit API.\nApple Ads is identifiable as \u201ccom.apple.ads\u201d. Placements are mapped to the following campaign IDs:\n- Search results = \u201c10\u201d\n- Search tab = \u201c20\u201d\n- Today tab = \u201c30\u201d\n- Product pages = \u201c40\u201d\nAdServices attribution API\nThe AdServices attribution API provides a privacy-centric solution that supports campaign, ad group, and keyword-level attribution. This attribution data can be used in addition to the data that is separately provided in AdAttributionKit, and it\u2019s particularly valuable for smaller developers who may receive limited information back from AdAttributionKit due to its crowd anonymity thresholds.\nHow the AdServices attribution\nAPI works\nAdServices attributes app conversions for ads that run on the App Store that are created using Apple Ads. The AdServices attribution API only uses Apple\u2019s first-party data and does not have information about whether or not a user viewed or clicked on an ad outside of the App Store.\nAdServices sends attribution information to the advertiser when a user opens the advertised app, providing one of two sets of information \u2014 known as a payload. The payload returned is either \u201cstandard\u201d or \u201cdetailed,\u201d and both only provide information that does not identify a user or device. The difference between the two payloads is the clickDate or impressionDate field, which indicates the date that the ad was clicked on or viewed. The addition of clickDate or impressionDate in the detailed payload is sent only when user permission for tracking has been obtained by the app through the App Tracking Transparency (ATT) prompt.\nSample AdServices API payloads:\nApp Tracking Transparency (ATT)\nStarting with iOS 14.5, developers are required to get user permission through the ATT framework to track user activity across other companies\u2019 apps and websites and to access the Identifier For Advertising (IDFA). The ATT framework presents an app-tracking authorization request to users, with the options of \u201cAsk App Not to Track\u201d or \u201cAllow\u201d when they open an app.\nWhether or not a developer seeks to track users is up to them. If they would like to track users (and access an IDFA), they are required to get explicit user permission through the App Tracking Transparency prompt. Apple, including the App Store, does not track users or use the IDFA for advertising, therefore the App Store app does not need to use the prompt. Just like the App Store, if others decide not to engage in tracking, they don\u2019t need to use the ATT prompt.\nAdServices attribution API\nand privacy\nIn addition to the overall privacy safeguards Apple Ads has in place, the AdServices attribution API provides the following privacy safeguards:\n- The attribution payload sent through the AdServices attribution API has limited granularity and does not explicitly identify a user or device. For example, the clickDate (which is only returned when user has opted into tracking via ATT for that specific app) is rounded to the minute.\n- Different payloads are sent to the advertiser depending on the user\u2019s choice of whether they ask the app not to track them through the ATT prompt. If a user asks an app not to track them, AdServices will return a standard payload without a clickDate or impressionDate. If a user allows an app to track them through the ATT prompt, AdServices will return a detailed payload, with a clickDate or impressionDate.\n- The AdServices attribution API only uses Apple\u2019s first-party data. Note that this may cause discrepancies with AdAttributionKit \u2014 for example, AdAttributionKit may be able to register a click from a third-party network that AdServices is, by design, unaware of, so both the third-party network and AdServices could claim the conversion in that instance. AdAttributionKit provides the official last-click amongst registered ad platforms.\nAny advertising platform can provide supplemental attribution information based on the data they \u2014 as the platform owner \u2014 possess."
    },
    {
      "url": "https://www.cnet.com/personal-finance/this-is-your-last-day-to-claim-a-piece-of-apples-96-million-siri-settlement-heres-how/",
      "text": "As useful as they -- sometimes -- can be, virtual assistants can often be just as annoying, especially if you've ever called one up by mistake. If you're an Apple user who's had that sort of issue with Siri in the last decade, I've got a settlement you should know about.\nApple customers may be eligible for a payout from a $96 million class-action settlement if the Siri virtual assistant was accidentally activated during a private conversation. However, if you want your payout for this privacy invasion, you'll need to make sure you sign up soon. The deadline to file a claim now less than a week away, and after that you'll be out of luck.\nApple agreed to the settlement after being sued for allegedly allowing Siri to listen in on private conversations without consent. Now, a claims website is live, and if you meet the criteria, you could get a piece of the payout. Whether you're a longtime iPhone user or just want to see if you're eligible, here's everything you need to know before the window closes.\nThe settlement period covers a full decade and given the ubiquity of Apple products, there's a good chance you'll be eligible for a piece of the payout. If you meet the eligibility standards, you can claim a payment for up to five Siri-enabled devices, with a cap on how much you can receive per device. We'll get into the specific amount a little bit later.\nThe impact of this settlement has the potential to be wide-ranging, given the reach of Apple's product ecosystem. According to a Business of Apps report from November, citing company and market research data, there were roughly 155 million active iPhones in the US as of 2024, a number that's been steadily increasing since the product's debut. Similarly, active Apple TV streaming boxes in the US have also been increasing year to year, with more than 32 million active in the US as of 2023.\nTo find out if you're eligible for this settlement, read on. For more, find out what's up with the recent delay of T-Mobile data breach settlement checks.\nWho sued Apple and why?\nThis class-action lawsuit, Lopez et al v. Apple Inc., was first brought against Apple in 2019, with plaintiffs alleging that they were routinely recorded by their Apple devices after unintentionally activating the Siri virtual assistant, violating their privacy in the process. They further alleged that these recordings were then sold to advertisers and used to target them with ads online.\nSpecific incidents mentioned in the suit include plaintiffs seeing ads online for brands like Air Jordan and Olive Garden after Apple device users discussed them out loud. In some instances, plaintiffs claimed that their devices began listening to them without them having said anything at all. At least one plaintiff involved in the case was a minor when it was first filed.\nThough it agreed to the settlement, Apple hasn't admitted any wrongdoing.\n\"Siri has been engineered to protect user privacy from the beginning,\" Apple said in a statement sent to CNET. \"Siri data has never been used to build marketing profiles and it has never been sold to anyone for any purpose. Apple settled this case to avoid additional litigation so we can move forward from concerns about third-party grading that we already addressed in 2019. We use Siri data to improve Siri and we are constantly developing technologies to make Siri even more private.\"\nWho is eligible for this class-action settlement?\nThe eligibility requirements for this settlement are fairly broad, as it's open to anyone who owned a Siri-enabled Apple device between Sept. 17, 2014, and Dec. 31, 2024. In order to opt in, you'll have to swear under oath that at some point during that period, you accidentally activated Siri on each device you want to get a payment for, and that these activations occurred during a conversation meant to be private.\nSiri-enabled devices include iPhones, iPads, Apple Watches, MacBooks, iMacs, Apple TV streaming boxes, HomePod speakers and iPod Touches.\nHow can I opt in to this Apple settlement?\nAs of Thursday, May 8, a website has been launched where Apple customers can claim a portion of the settlement, if they believe they qualify. If you're looking to submit a claim, you have until July 2, 2025, to do so.\nIt's not clear at this time when payments will be disbursed to approved claimants but it will surely be sometime after Aug. 1, 2025, when a final approval hearing is scheduled.\nHow much can I get from the class-action settlement?\nPayments per device are to be capped at $20, although depending on how many people opt in to the settlement, claimants could receive less than that. Each individual can only claim payments for up to five devices, meaning the maximum possible payment you could receive from the settlement is $100.\nFor more on Apple, see why a majority of users don't care for Apple Intelligence and find out which iOS setting can stop apps from tracking you."
    },
    {
      "url": "https://www.icsi.berkeley.edu/icsi/people/egelman",
      "text": "Serge Egelman\nDirector, Usable Security and Privacy\negelman @ icsi.berkeley.edu\nSerge Egelman is Research Director of the Usable Security & Privacy Group at the International Computer Science Institute (ICSI) and also holds an appointment in the Department of Electrical Engineering and Computer Sciences (EECS) at the University of California, Berkeley. He leads the Berkeley Laboratory for Usable and Experimental Security (BLUES), which is the amalgamation of his ICSI and UCB research groups. Serge's research focuses on the intersection of privacy, computer security, and human-computer interaction, with the specific aim of better understanding how people make decisions surrounding their privacy and security, and then creating data-driven improvements to systems and interfaces. This has included human subjects research on social networking privacy, access controls, authentication mechanisms, web browser security warnings, and privacy-enhancing technologies. His work has received multiple best paper awards, including seven ACM CHI Honorable Mentions, the 2012 Symposium on Usable Privacy and Security (SOUPS) Distinguished Paper Award for his work on smartphone application permissions, as well as the 2017 SOUPS Impact Award, and the 2012 Information Systems Research Best Published Paper Award for his work on consumers' willingness to pay for online privacy. He received his PhD from Carnegie Mellon University and prior to that was an undergraduate at the University of Virginia. He has also performed research at NIST, Brown University, Microsoft Research, and Xerox PARC.\nVisit Serge Egelman's Web site."
    },
    {
      "url": "https://www.justice.gov/archives/opa/pr/justice-department-secures-groundbreaking-settlement-agreement-meta-platforms-formerly-known",
      "text": "Related Content\nPress Release\nThis is archived content from the U.S. Department of Justice website. The information here may be outdated and links may no longer function. Please contact webmaster@usdoj.gov if you have any questions about the archive site.\nThe Department of Justice announced today that it has obtained a settlement agreement resolving allegations that Meta Platforms Inc., formerly known as Facebook Inc., has engaged in discriminatory advertising in violation of the Fair Housing Act (FHA). The proposed agreement resolves a lawsuit filed today in the U.S. District Court for the Southern District of New York alleging that Meta\u2019s housing advertising system discriminates against Facebook users based on their race, color, religion, sex, disability, familial status and national origin. The settlement will not take effect until approved by the court.\nAmong other things, the complaint alleges that Meta uses algorithms in determining which Facebook users receive housing ads, and that those algorithms rely, in part, on characteristics protected under the FHA. This is the department\u2019s first case challenging algorithmic bias under the Fair Housing Act.\nUnder the settlement, Meta will stop using an advertising tool for housing ads (known as the \u201cSpecial Ad Audience\u201d tool) that, according to the department\u2019s complaint, relies on a discriminatory algorithm. Meta also will develop a new system to address racial and other disparities caused by its use of personalization algorithms in its ad delivery system for housing ads. That system will be subject to Department of Justice approval and court oversight.\nThis settlement marks the first time that Meta will be subject to court oversight for its ad targeting and delivery system.\n\u201cAs technology rapidly evolves, companies like Meta have a responsibility to ensure their algorithmic tools are not used in a discriminatory manner,\u201d said Assistant Attorney General Kristen Clarke of the Justice Department\u2019s Civil Rights Division. \u201cThis settlement is historic, marking the first time that Meta has agreed to terminate one of its algorithmic targeting tools and modify its delivery algorithms for housing ads in response to a civil rights lawsuit. The Justice Department is committed to holding Meta and other technology companies accountable when they abuse algorithms in ways that unlawfully harm marginalized communities.\u201d\n\u201cWhen a company develops and deploys technology that deprives users of housing opportunities based in whole or in part on protected characteristics, it has violated the Fair Housing Act, just as when companies engage in discriminatory advertising using more traditional advertising methods,\u201d said U.S. Attorney Damian Williams for the Southern District of New York. \u201cBecause of this ground-breaking lawsuit, Meta will \u2014 for the first time \u2014 change its ad delivery system to address algorithmic discrimination. But if Meta fails to demonstrate that it has sufficiently changed its delivery system to guard against algorithmic bias, this office will proceed with the litigation.\u201d\n\u201cIt is not just housing providers who have a duty to abide by fair housing laws,\u201d said Demetria McCain, the Principal Deputy Assistant Secretary for Fair Housing and Equal Opportunity at the Department of Housing and Urban Development (HUD). \u201cParties who discriminate in the housing market, including those engaging in algorithmic bias, must be held accountable. This type of behavior hurts us all. HUD appreciates its continued partnership with the Department of Justice as they seek to uphold our country\u2019s civil rights laws.\u201d\nUnited States\u2019 Lawsuit\nThe United States\u2019 complaint challenges three key aspects of Meta\u2019s ad targeting and delivery system. Specifically, the department alleges that:\nThe complaint alleges that Meta has used these three aspects of its advertising system to target and deliver housing-related ads to some Facebook users while excluding other users based on FHA-protected characteristics.\nThe department\u2019s lawsuit alleges both disparate treatment and disparate impact discrimination. The complaint alleges that Meta is liable for disparate treatment because it intentionally classifies users on the basis of FHA-protected characteristics and designs algorithms that rely on users\u2019 FHA-protected characteristics. The department further alleges that Meta is liable for disparate impact discrimination because the operation of its algorithms affects Facebook users differently on the basis of their membership in protected classes.\nSettlement Agreement\nThese are the key features of the parties\u2019 settlement agreement:\nThe Justice Department\u2019s lawsuit is based in part on an investigation and charge of discrimination by HUD, which found that all three aspects of Meta\u2019s ad delivery system violated the Fair Housing Act. When Facebook elected to have the HUD charge heard in federal court, HUD referred the matter to the Justice Department for litigation.\nThis case is being handled jointly by the Justice Department\u2019s Civil Rights Division and the U.S. Attorney\u2019s Office for the Southern District of New York.\nAssistant Attorney General Kristen Clarke and U.S. Attorney Damian Williams thanked the Department of Housing and Urban Development for its efforts in the investigation.\nThe Fair Housing Act prohibits discrimination in housing on the basis of race, color, religion, sex, familial status, national origin and disability. More information about the Civil Rights Division and the laws it enforces is available at www.justice.gov/crt. More information about the U.S. Attorney\u2019s Office for the Southern District of New York is available at www.justice.gov/usao-sdny. Individuals who believe they have been victims of housing discrimination may submit a report online at www.civilrights.justice.gov, or may contact the Department of Housing and Urban Development at 1-800-669-9777 or through its website at www.hud.gov."
    },
    {
      "url": "https://www.cnbc.com/2019/07/11/google-admits-leaked-private-voice-conversations.html",
      "text": "Google admitted on Thursday that more than 1,000 sound recordings of customer conversations with the Google Assistant were leaked by some of its partners to a Belgian news site.\nThese conversations are used by companies such as Google and Amazon -- which takes clips from the Amazon Echo -- to improve voice responses from their smart assistants. They are supposed to be kept confidential.\nBut Belgian news site VRT said on Wednesday that a contractor provided it with samples of these sound samples, which VRT then used to identify some of the people in the clips. It also examined the sorts of conversations that Google collects when people say \"OK Google,\" into a phone or a Google Home product. Among other things, VRT heard customer addresses. Sources who talked to the publication also described hearing recordings of a woman in distress and people talking about medical conditions.\nGoogle has now admitted the recordings were leaked.\n\"We just learned that one of these language reviewers has violated our data security policies by leaking confidential Dutch audio data,\" Google product manager of search David Monsees said in a blog post. \"Our Security and Privacy Response teams have been activated on this issue, are investigating, and we will take action. We are conducting a full review of our safeguards in this space to prevent misconduct like this from happening again\"\nMonsees said its partners only listen to \"around 0.2 percent of all audio snippets\" and said they are \"not associated with user accounts,\" even though VRT was able to figure out who was speaking in some of the clips.\nIf this worries you, you can delete your old Google Assistant voice history pretty easily.\nAmazon also collects voice clips when people speak to Alexa and also uses humans to analyze clips. You can stop Alexa from using the clips to improve Amazon's service, however, and delete your past recordings."
    },
    {
      "url": "https://arstechnica.com/information-technology/2020/07/uncovered-1000-phrases-that-incorrectly-trigger-alexa-siri-and-google-assistant/",
      "text": "As Alexa, Google Home, Siri, and other voice assistants have become fixtures in millions of homes, privacy advocates have grown concerned that their near-constant listening to nearby conversations could pose more risk than benefit to users. New research suggests the privacy threat may be greater than previously thought.\nThe findings demonstrate how common it is for dialog in TV shows and other sources to produce false triggers that cause the devices to turn on, sometimes sending nearby sounds to Amazon, Apple, Google, or other manufacturers. In all, researchers uncovered more than 1,000 word sequences\u2014including those from Game of Thrones, Modern Family, House of Cards, and news broadcasts\u2014that incorrectly trigger the devices.\n\u201cThe devices are intentionally programmed in a somewhat forgiving manner, because they are supposed to be able to understand their humans,\u201d one of the researchers, Dorothea Kolossa, said. \u201cTherefore, they are more likely to start up once too often rather than not at all.\u201d\nThat which must not be said\nExamples of words or word sequences that provide false triggers include\n- Alexa: \u201cunacceptable,\u201d \u201celection,\u201d and \u201ca letter\u201d\n- Google Home: \u201cOK, cool,\u201d and \u201cOkay, who is reading\u201d\n- Siri: \u201ca city\u201d and \u201chey jerry\u201d\n- Microsoft Cortana: \u201cMontana\u201d\nThe two videos below show a GoT character saying \u201ca letter\u201d and Modern Family character uttering \u201chey Jerry\u201d and activating Alexa and Siri, respectively.\nIn both cases, the phrases activate the device locally, where algorithms analyze the phrases; after mistakenly concluding that these are likely a wake word, the devices then send the audio to remote servers where more robust checking mechanisms also mistake the words for wake terms. In other cases, the words or phrases trick only the local wake word detection but not algorithms in the cloud."
    },
    {
      "url": "https://www.cnet.com/tech/computing/facebook-isnt-secretly-listening-in-on-your-phone-conversations-really/",
      "text": "Stop me if you've heard this one: After you talk about something specific, an ad related to that very topic pops up on your Facebook feed.\nIt's uncanny, unsettling and, like most urban legends, nearly everyone has a variant of this story. Thanks to the wealth of data the mammoth social network already has on you -- your location, network of friends, interests and shopping habits -- it's like Facebook is listening to you.\nIt almost certainly isn't.\nIn an informal study, CNET reporters discussed predesignated topics in front of their phones and then monitored their Facebook feeds for related ads. We found nothing to suggest Facebook had overheard our conversations. While we can't 100% disprove this idea, security experts have also failed to find evidence the social network is eavesdropping on users to target ads more effectively.\nFacebook itself has denied this multiple times, including co-founder Mark Zuckerberg telling Congress last year that the company does not do this.\n\"No. Let me be clear on this: You're talking about this conspiracy theory that gets passed around that we listen to what's going on on your microphone and use that for ads,\" Zuckerberg told Sen. Gary Peters. \"We don't do that.\"\nBut the fact that the conspiracy theory lives on is a testament to the massive machine Facebook has set up to hoover up your data and exploit it to deliver targeted ads. That theory gains credence from other instances elsewhere in the tech environment, like malware leaked from the CIA that could turn phones and TVs into listening devices, and some Samsung TVs that captured private conversations.\nBut Facebook doesn't need to listen to you to figure out what you're thinking about -- there are hundreds of other ways. And that ability to gather information has sparked increasing scrutiny since 2018, when data privacy became a public concern. Now lawmakers are looking to limit how much tech giants can learn about us, and how they can use it.\nYou can't be blamed for feeling the allure of this conspiracy theory, especially when the ads are so specific. But Facebook learns about your preferences through hundreds of data points -- information like where you are, what you've bought, what you've looked for online and who your friends are can help tech giants make scary-accurate predictions.\nPrivacy experts have found that people jump to this conclusion so often because it's a simple answer, and the real reason why these ads are so specific is a complicated issue. Jake Laperruque, a senior counsel at the Constitution Project, said he frequently hears people jumping to that conclusion and tries to point out issues with the theory.\n\"They usually say, 'I can't imagine another way for this to get onto me for advertising ,'\" Laperruque said. \"Think outside the box. What about location-based advertising, or what a friend is searching? Just spend a few minutes thinking about how much data companies have.\"\nAsked about the conspiracy theory, Facebook reiterated a statement made in 2016.\n\"We only access your microphone if you have given our app permission and if you are actively using a specific feature that requires audio,\" the company said in a statement. \"We do not access the microphone just because the app is opened nor do we use it when you're not in the app.\"\nFacebook said it does buy de-identified audio data to train its AI for speech-enabled features like transcriptions.\nEvidence against Facebook's eavesdropping\nSecurity researchers have performed network traffic analysis to look for any audio data being sent to Facebook, without finding any evidence. And if Facebook was harvesting all that audio, it would be a gargantuan data drain, said Cloudflare CEO Matthew Prince.\nConsidering that Facebook has over 2 billion monthly active users, it would be a logistical nightmare to listen around the clock just so the company could send you relevant ads.\n\"I wouldn't be surprised if you would get to a level of total data usage that would exceed the entire capacity of the internet,\" Prince said. \"Two billion times anything is going to be a really big number.\"\nAnalyzing speech and converting it to text for artificial intelligence to then serve ads is also a difficult task. Google and Amazon are racing to just understand human speech with their respective Home Assistant and Alexa. And that includes struggles with background noise, accents, mumbling, slang and volume.\n\"Listening to conversations in real time has a bunch of challenges,\" said Gabriel Weinberg, the CEO of private search engine DuckDuckGo. \"Getting your voice-to-text correct, extracting all that information, you would need specific AI.\"\nFacebook is reportedly building its own smart assistant, but it would need to be activated and isn't secretly recording and preinstalled on your phones.\nOutside of the technical difficulties, it'd also be completely illegal for Facebook to do this, Laperruque said.\nIf Facebook were secretly recording people's conversations to serve ads, it would be breaking the Wiretap Act, the counsel said. If Facebook were caught doing this to its billions of users, it would be subject to trillions of dollars in liabilities, he said.\nThe social network has already been slammed by $3 billion in expenses related to a Federal Trade Commission investigation over its Cambridge Analytica data scandal.\n\"There's criminal liability, and just like that, it would not be worth it for companies to expose themselves to legal risks,\" Laperruque said. \"It's not like you could say, 'I got this advertisement because they were engaged in this massively illegal scheme.'\"\nSo how are these ads so specific?\nEven without listening at all times, tech giants know enough to tailor an ad so specific you'd think they were secretly recording your thoughts, too.\nYou are constantly tracked online, which allows tech companies like Facebook and Google to learn all sorts of things about you.\nTech companies know what websites you're visiting through their tracking pixels, where you are through geolocation data, and what you've bought -- Google knows about 70 percent of all payment card purchases in the US.\nThey don't just have this data for you -- they have it on your friends too. Even if you've never searched for a certain product online, if your friends have, you're much more likely to see ads for that. The same goes for just being the same location as someone else.\nThe way data tracking is structured online, tech giants don't need to listen in, experts say. Weinberg said that all the tech giants essentially have all they need by tracking searches, browsing history, geolocation and purchase history.\n\"With those four things alone, you can find out an amazing amount about somebody,\" Weinberg said. \"You can get more from the current tracking infrastructure than from listening to your conversations.\"\nThe truth is out there\nDespite this evidence, the theory persists -- even among experts who are aware of all this information.\nStephen Cobb, a senior security researcher at ESET, said he was conducting his own experiment to see if his devices were secretly recording his conversations to serve him ads. As did the CNET study, he had several conversations in his home about products he's never searched for, like Casper mattresses, Qwip toothbrushes and Allbird sneakers,and then looked for any ads popping up.\nHe knows about the massive trail of data that companies like Facebook and Google have on him. He also knows it's been tested by security researchers analyzing the data traffic, but Cobb remains skeptical.\nFor years, he's studied shady measures the ad industry would take to get clicks online, and he doesn't believe it's farfetched to argue that Facebook could be using audio that's secretly recorded. And like many who believe the theory, he's also seen ads that surprised him on several occasions.\n\"We've heard legitimate marketers talk glowingly about the potential for advertising to be targeted based on what you're talking about,\" Cobb said. \"It might not be Facebook listening; it could be somebody else doing it and selling that information to Facebook.\"\nExperts don't expect this conspiracy theory to ever go away. Until these ads stop being so specific, people will continue to jump to the same conclusion.\nCobb said he hasn't seen any ads for the products he's been purposely talking up over several days.\nCNET's Laura Hautala contributed to this report."
    },
    {
      "url": "https://www.cnet.com/tech/mobile/best-android-phone/",
      "text": "Every year, we test dozens of Android phones and have found the best smartphones you can buy. The best Android phones come with years of software and security updates, great cameras, a powerful processor and a long battery life. Samsung's new Galaxy Z Fold 7 makes the cut, as does Google's Pixel 9 and the 9 Pro XL. But we should warn you, there is a Made by Google event next week where we expect the Pixel 10 series to be revealed. So if you're itching for a new Pixel phone, we recommend waiting a few more days.\nOur Picks\nMOBILE DEALS OF THE WEEK\n- $449 (save $50)\n- $550 (save $50)\n- $300 (save $100)\nWhat's the best Android phone?\nThe $800 Samsung Galaxy S25's battery life is amazing. That's not the only reason it's our pick for best Android phone. It gets seven years of major Android updates, and the cameras are good (there's even a 3x telephoto lens for zooming). Then there are all the AI features: Most are just OK, but Circle to Search is outstanding. Samsung tries to set the Galaxy S25 apart by leaning into what's new (AI), as well as embracing the familiar (good cameras and battery life). And we're definitely impressed. There are plenty of other excellent choices, with the Pixel 8A being another current favorite.\nBest Android phones of 2025\nPros\n- Camera consistently delivers good images\n- Impressive battery life that last a day or more\n- More AI features that actually feel practical\nCons\n- Several gimmicky AI tools\n- Not many changes over the S24\nThe Galaxy S25's biggest flex that I noticed while testing is it shares many of the same attributes as its pricier counterparts, the S25 Plus and S25 Ultra \u2013 but it does so for several hundred dollars less. You'll find features like the AI Select tool, Audio Eraser and deeper Gemini integration across all of Samsung's S25 devices, as well as a custom Snapdragon 8 Elite processor and 12GB RAM \u2013 making the smaller phone of the bunch still seem pretty mighty.\nAnd while the Galaxy S25 might look incredibly similar to the S24 and share many of the same specs, consistency isn't so bad when it means there's a consistently good camera and great battery life. Read our full Samsung Galaxy S25 review.\nWhy we like it\nHaving a baseline phone, like the Galaxy S25, that delivers many of the same perks as more expensive models, is a huge plus in my book. And given the remarkable processing power, standout camera and seamless AI integration in the Galaxy S25 lineup, it's great that I can get all those premium features for $800.\nWho it's best for\nIf you're someone who insists on buying a flagship device, the Galaxy S25 won't let you down. but if you have a device that's two years old or more, you might be enticed to tap into all the latest Galaxy AI and integrated Gemini features. Now, $800 isn't pocket change, and there are definitely other options for those who want to be more budget conscious, but if you're willing to spend a bit more, the baseline S25 can be a great all-around choice.\nWho shouldn\u2019t get it\nYou probably don't need to upgrade if you're using last year's S24.\nPros\n- The screen is delightfully bright\n- Cameras are good for $499\n- Gemini Live Video AI has potential to be useful\n- Solid build\n- The under-$500 price\nCons\n- Battery life is just OK, will get through a day\n- Processor is serviceable (curious about longevity)\n- Lacks emergency SOS satellite texting\nFor $499, Google's Pixel 9A truly feels like you're getting more bang for your buck. It comes with several significant upgrades from last year's Pixel 8A: a fresh design, new display, larger battery, slightly more powerful chip, increased durability and upgraded software features.\nBut don't get me wrong -- it's not a perfect phone. There are places where Google had to compromise to keep the price under $500, like the lack of satellite connectivity for emergencies available on the $799 Pixel 9. Overall, though, I think the compromises Google made were smart and that the Pixel 9A is worth every penny. Read our Google Pixel 9A review.\nWhy we like it\nThe Pixel 9A is proof that you don't need to spend more than $500 to get a great phone. It can handle all you daily tasks from scrolling social media and news feeds and swiping through TikTok videos to taking a beautiful photo and lasting a day on a single charge.\nWho's it best for?\nIn theory: anybody. The Pixel 9A is for anyone who wants 95% of what a $1,000 phone can do at half the price.\nWho shouldn't get it\nAnyone who wants the absolute fastest processor or the most cutting edge cameras.\nPros\n- Beautiful design that feels durable\n- Fun and somewhat useful AI features\n- New ultrawide camera takes good photos\n- 7 years of software updates for longevity\nCons\n- More expensive that previous Pixels and competitors\n- Doesn't feel that different from Pixel 8\nThere\u2019s a lot to like about the Pixel 9, from its respectable camera to its classy new design and lengthy 7-year timeline for software updates. But Google\u2019s phones have always shined for their clean, slick software, and that once again applies to the Pixel 9 series. Pixels are also among the first to get new software updates, making them an ideal choice for those who want to get their hands on the latest version of Android first. Aside from Android updates, Google also brings new features to Pixel phones throughout the year through updates it calls Feature Drops.\nThe Pixel 9 comes with a few new AI tricks that you may find useful, like the ability to search for content in screenshots, generate images from scratch in the Pixel Studio app and add new objects in photos. These features aren\u2019t must-haves, and they\u2019re not without flaws. Plus, at a starting price of $799, the Pixel 9 has a higher bar to live up to. But the Pixel 9 feels like it belongs in that class of device. Read our full review for the Google Pixel 9.\nWhy we like it\nThe Pixel 9 and Google's Gemini assistant still feel like a first step toward what the company is hoping to achieve: Making phone software more intelligent so that we can spend less time swiping, tapping, scrolling and digging. In the meantime, the Pixel 9 shines for its great camera, elegant design and clean software, just like the less AI-centric Pixels of years past.\nWho it's best for\nIf you're a Pixel fan upgrading from an older phone, like the Pixel 6 or earlier, you'll find a lot to love about the Pixel 9. But keep in mind that for the same price, Samsung's Galaxy S25 has a brighter screen and a dedicated telephoto lens for taking zoomed photos.\nWho shouldn't get it\nIf you want the absolute best cameras that Google makes, including having a dedicated telephoto lens, I'd recommend the Pixel 9 Pro.\nPros\n- Best screen on any phone\n- Versatile cameras\n- Most powerful phone I've tested\n- Good battery life\nCons\n- $1,300 price\n- Design is almost too minimal\n- AI features are hit-or-miss\n- S25/S25 Plus have similar features and cost less\nSamsung's Galaxy S25 Ultra which has a lot of AI features, the best of which are interesting and the worst of which unreliable. Luckily, Samsung gets a lot of other things right on the S25 Ultra, which has a new Snapdragon 8 Elite processor, high-resolution ultrawide camera, and some sweet pro video tools that rival the iPhone 16 Pro. Samsung wisely kept all the best parts of last year's Galaxy S24 Ultra (basically the entire phone including that antireflective display) but some of its worst parts, too, like the $1,300 price tag.\nIf you want the best screen you can find on any phone, get the S25 Ultra. If you want the most versatile phone cameras, get the S25 Ultra. If you want a stylus, get the S25 Ultra. But if your needs scale back on any of those fronts, the more affordable S25 options, or even last year's S24 Ultra, may be worth considering. Read our full Samsung Galaxy S25 Ultra review.\nWhy we like it\nThe reason to get the Ultra over its S25 siblings is its screen, which is truly the best I've seen on any phone, and the cameras, which are a step above what the S25 and S25 Plus have. Added video features like ability to record in Log format gets the Ultra as close as it's ever been to the iPhone in terms of professional video capture.\nWho it's best for\nIf you have a Galaxy S22 Ultra or older, the S25 Ultra will seem like a significant upgrade. It's harder to make that case for S23 Ultra owners, who, unless their phone's battery is ailing or they can score an incredible discount, should otherwise sit this one out. And for you S24 Ultra owners, you don't need this phone. Save your money and treat yourself to a nice steak dinner and a movie.\nWho shouldn\u2019t get it\nThe Galaxy S25 Ultra's appeal is muddied by its $1,300 price. The regular Galaxy S25 has the same functionality, power and longevity, and it costs $500 less. Want a bigger screen? Consider the Galaxy S25 Plus. For the majority of people, the regular Galaxy S25 and S25 Plus will be a better fit.\nPros\n- Thin 4.2mm design\n- 200-megapixel main camera\n- Powerful Snapdragon 8 Elite processor\n- Durable build\nCons\n- Steep $2,000 price tag\n- Same 4,400-mAh battery as last year's Fold\n- 25-watt wired charging\nWith the Galaxy Z Fold 7, Samsung has finally addressed some of the key issues with its previous book-style foldables. The impressively thin build and wider, 6.5-inch cover screen makes this feel like a standard phone when closed, and that wider 8-inch inside display is great for multitasking, with the ability to run up to three apps simultaneously. Perhaps most notably, the camera gets a major upgrade with the addition of a 200-megapixel main camera, which takes shots on par with the top-of-the-line S25 Ultra.\nAltogether, it\u2019s a great choice if you want a bigger, tablet-like display without the bulk or a compromise on camera quality.\nWhy we like it\nThe Z Fold 7 does a solid job combining what's great about standard slate phones and what's great about foldables. It feels wonderfully normal to hold when closed, thanks to its sleek design and lightweight build. It also packs great cameras and has an expansive main display that's 11 percent bigger than last year's Z Fold 6.\nThankfully, a slimmer build doesn't force the battery to take a hit; the Z Fold 7 maintains that same 4,400-mAh battery as last year's foldable. That pales in comparison to batteries from Chinese competitors, but at least it's not a downgrade. The Z Fold 7 also packs a Snapdragon 8 Elite processor to power the many AI features you'll get onboard, from Galaxy AI photo and audio editing tools to Google's Gemini Live and Circle to Search. The phone also supports seven years of software and security updates.\nWho it's best for\nIf you're bored of standard slate phones and want something that feels a little more exciting, the Galaxy Z Fold 7 is a great choice. The slim design and wider cover screen helps it to feel as normal as possible when closed, with the added perk of an expansive main display that's great for multitasking and watching videos. The cameras are also impressive for a foldable that's so thin.\nWho shouldn't get it\nThe Z Fold 7's $2,000 price tag is perhaps its biggest caveat. Also, if you don't need a bigger display, it may not be worth the splurge. Ironically, the cover screen is so practical that you\u2019ll rarely need to open the phone -- unless you\u2019re watching movies or multitasking, in which case a phone like the Galaxy S25 Ultra might be a better fit.\nPros\n- Lightning fast charging\n- Nice big screen\n- 7 years of OS and security upgrades\n- Great performance with games, movies and animations\nCons\n- Battery life is a day, similar to baseline S25\n- Similar specs as the S25 at a higher price\n- Rival phones at the same price have better cameras\nIf the baseline Galaxy S25 appeals to you but you'd rather have a bigger screen and higher battery capacity \u2013 without upgrading all the way to the Ultra \u2013 the S25 Plus may be the phone for you. The entire S25 lineup shares many features, from AI capabilities to processing power to memory, so the Plus may be a viable choice if you're looking for something right in the middle.\nThat said, the Plus' minimal upgrades over the baseline S25 may not justify the $200 price difference. But if a bigger phone just feels better to hold and you'd rather have a 4,900 mAh battery (over the S25's 4,000mAh one), then that $1,000 starting price might ultimately be worth every penny. Read CNET's full Samsung Galaxy S25 Plus review.\nWhy we like it\nWhile the baseline S25 checks all the key boxes, the S25 Plus can simply feel like a more comfortable device to use, especially if you're a fellow member of the bigger hands club. In addition to sharing many of the same features as the pricier S25 Ultra, the S25 Plus has a higher battery capacity than the baseline model -- though in CNET's tests, there weren't any major discrepancies in how the two batteries actually performed. Still, sometimes you just want to live a little larger, and this phone can be the perfect fit.\nWho it's best for\nIf you like having a larger screen to watch movies or play games on, the S25 Plus can be a great choice. While the S25 Ultra might be a top pick for someone who wants both a bigger phone and the most premium features, the S25 Plus can be that goldilocks device that meets you right in the middle -- without you having to spend $1,300 on the Ultra.\nWho shouldn\u2019t get it\nIf you want the absolute best in terms of cameras, don't get the S25 Plus. For $1,000 phones like the Pixel 9 Pro or iPhone 16 Pro have better cameras. Or if you can afford to buy a $1,300 phone, check out the Galaxy S25 Ultra which has an amazing set of lenses\nPros\n- Genuinely fun new AI skills\n- Sleek new design\n- Seven years of software updates\n- Cameras can take great daytime shots\nCons\n- Camera hardware hasn't improved much over Pixel 8 Pro\n- Gemini AI will eventually require a paid subscription\nThe Pixel 9 Pro and 9 Pro XL have a lot going for them, from their shiny new designs and long software support period. But it's the AI skills that really stand out, from the deep integration of the conversational Gemini Live, to the new Pixel Studio that creates weird and wonderful images from your text prompts.\nThe phones aren't perfect. While the cameras are good and can take excellent photos in bright light, they're just okay in low-light and in night mode. The best AI features will require a monthly subscription (though you get the first year for free) But if you're keen to experiment with AI on your phone then the new Pixel 9 Pro range is a superb way to experience it. Read our Google Pixel 9 Pro and 9 Pro XL review.\nWhy we like it\nGoogle's Pixel line of phones has gone from strength to strength and its latest model is unquestionably the best phone the company has ever made. It's not just the slick-looking design; the Pixel 9 Pro offers a superb camera system, a generous support period and a host of new AI skills making it one of the most accomplished Android phones around. The 9 Pro XL takes that further by accommodating a bright and vibrant 6.8-inch display.\nWho it's best for\nIt's a great phone for those of you looking for an elegant everyday Android phone. The interface is easy to navigate and the camera takes great photos with almost no effort on your part. If you feel overwhelmed by the plethora of settings and menus on other Android flagships, Google's Pixel 9 Pro is the way to go. If playing mobile games or watching videos on the go is a priority, opt for the larger Pixel 9 Pro XL.\nWho shouldn't get it\nIf you don't need the best cameras Google makes, consider the regular Pixel 9. I do like the fit and finish better on the 9 Pro, but it starts at $999.\nPros\n- Robust design\n- Bright high resolution inner screen\n- Battery life should last you a day or more\n- It's so damn fun to use\nCons\n- Cameras take decent photos but suffer from motion blur\n- Only three years of major OS updates\n- Gets warm playing games and using the camera frequently\nThe Motorola Razr Ultra is a beefed-up version of last year's Razr Plus, which won a CNET Editor's Choice Award. It's as if the Razr Plus hired a trainer and nutritionist and then got absolutely ripped -- warranting its name: Ultra. After testing, I've come to adore the Razr Ultra. It does all the \"normal\" non-folding phone things I want, and offers me a truly unique experience thanks to its cover screen. I feel like the coolest kid in the coffee shop when Google Pay-ing for my cortado with my Razr Ultra closed. Read our Motorola Razr Ultra review.\nBut in taking nearly every aspect of the phone to the extreme, Motorola lost one of the most important parts of recent Razrs: the amazing value. The catch for all this ultra-ness: the Motorola Razr Ultra costs $1,300.\nWhy we like it\nThis is the best built foldable flip phone I've ever used. Motorola took the best parts of the Razr Plus and improved nearly everything else. The battery life is outstanding and easily lasts a day on a single charge and can get you mostly through a second day even. The displays are brighter. The main 7-inch foldable display is larger and has more resolution than the Razr Plus and the cameras are improved. The fabric backing is delightful.\nWho's it best for\nSomeone who wants a fun, unique an robust foldable phone. You're willing to pay top-dollar to get the best processor, battery, design and cameras Motorola has ever made.\nWho shouldn't get it\nIf you're unsure of foldables, this might not be the best fit. If you find yourself in places with sand, dirt and other fine particles, the Razr Ultra (like all foldable phones) isn't worth the risk. The Razr Ultra has the same class-leading IP-rating for dust and water resistance, but the dust resistance is only for particles 1-mm or larger.\nPros\n- The 6.9-inch screen is immersive, with lovely colors and contrast\n- The 4.1-inch screen looks incredible\n- It's durable and survived a drop onto concrete\n- One UI 8 (Android 16) runs wonderfully\n- $1,100 is still a lot, but Samsung gives the phone more value than the Flip 6\nCons\n- Gets warm when recording videos and playing games\n- Battery life is the same as the Flip 6 despite a bigger battery\n- Cover screen software has room to grow\nWhen I first got my hands on Samsung's new Galaxy Z Flip 7, I was delighted to discover that it has a smaller crease, larger cover screen, thinner design and bigger battery compared to last year's Galaxy Z Flip 6. But as I tested the new clamshell phone, I became enthralled by its inner screen. At 6.9 inches, this is the biggest screen on any Samsung phone aside from the Galaxy Z Fold 7, which has an 8-inch foldable display.\nThe Z Flip 7's large screen size makes content feel more immersive and colors look lovely and vivid. This led to epic TikTok and Instagram sessions, watching widescreen films such as A Working Man and Back to the Future, as well as jumping back and forth between two apps stacked vertically on the screen thanks to One UI 8's 90:10 split tool.\nEvery time I open the Flip 7, I'm consistently dumbfounded by how such a large display can unfurl from something about the size of a makeup compact. And when it's closed, there's a 4.1-inch cover screen that's fantastic in its own ways, with new clever animations for when you're recording a video, charging the phone or taking a selfie, all efficiently using the extra display real estate. In terms of functionality, though, the cover screen's software is about the same as the 3.4-inch one on the Flip 6.\nThe Flip 7 impressed me in nearly every way but one: its battery life. It has a larger battery than the Flip 6, but it doesn't last any longer in daily use. It did consistently get me through a day on a single charge, often having 15 to 20% left, but there were also a few days where it needed an early evening top-off.\nWhy we like it\nThe Galaxy Z Flip 7 is the most fully realized version of Samsung's ideal of a flip phone since the launch of the original Galaxy Z Flip in 2020. The Flip 7's appeal is simple: It's a thin phone with a big, bold screen that folds in half into a coaster-sized square. The larger cover screen and inner screen make content more immersive. It's design is thin (for a clamshell foldable) and comfortable to hold. Plus you get twice the storage this year compared to last.\nWho is it best for\nIf you've been tempted by a clamshell-style foldable, you should definitely consider the Flip 7. If you have a Galaxy Z Flip 4 or older, the Flip 7 will be an upgrade in every way. It's harder to make that same recommendation for Flip 5 owners unless your phone is showing its age. And if you have a Galaxy Z Flip 6, you can sit this one out unless you really want those larger screens.\nWho shouldn\u2019t get it\nIf you spend a ton of time around dirt or sand, this phone isn't for you.\nBest Android phones compared\n| Product | Samsung Galaxy S25 | Samsung Galaxy S25 Plus | Samsung Galaxy S25 Ultra | Google Pixel 9 | Google Pixel 9 Pro | Google Pixel 9 Pro XL | Moto G Power 5G (2024) | Motorola Razr Plus (2024) | Samsung Galaxy Flip 6 | Samsung Galaxy Z Fold 6 |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Display size, tech, resolution, refresh rate | 6.2-inch AMOLED; 2,340x1,080 pixels; 1-120Hz adaptive refresh rate | 6.7-inch AMOLED; 3,120x1,440 pixels; 1-120Hz adaptive refresh rate | 6.8-inch AMOLED; 3,120x1,440 pixels; 1-120Hz adaptive refresh rate | 6.3-inch OLED; 2,424x1,080 pixels; 60-120 Hz variable refresh rate | 6.3-inch LTPO OLED; 2,856x1,280 pixels; 1-120Hz variable refresh rate | 6.8-inch LTPO OLED; 2,992x1,344 pixels; 1-120Hz variable refresh rate | 6.7-inch LCD; 2,400 x 1,080 pixels, 60-120Hz refresh rate | 4-inch pOLED; 1,272 x 1,080 pixels; 1-165Hz variable refresh rate; 6.9-inch pOLED; 2,640 x 1,080 pixels, 1-165Hz variable refresh rate | 3.4-inch AMOLED; 720 x 748 pixels; 60Hz refresh rate; 6.7-inch AMOLED; 2,640 x 1,080 pixels; 1-120Hz refresh rate | 6.3-inch AMOLED; 2,376x968 pixels; 1-120Hz variable refresh rate; 7.6-inch AMOLED; 2,160x1,856 pixels;1-120Hz variable refresh rate |\n| Pixel density | 416 ppi | 509 ppi | 501 ppi | 422 ppi | 495 ppi | 486 ppi | 391 ppi | Cover: 417 ppi; Internal: 413 ppi | Cover: 306 ppi; Internal: 425 ppi | Cover: 410 ppi; Internal: 374 ppi |\n| Dimensions (inches) | 5.78 x 2.78 x 0.28 in. | 6.24 x 2.98 x 0.29 in. | 6.41 x 3.06 x 0.32 in. | 6x2.8x0.3 inches | 6x2.8x0.3 inches | 6.4x3x0.3 inches | 6.6 x 3 x 0.3 in. | Open: 6.75 x 2.91 x 0.28 in Closed: 3.47 x 2.91 x 0.6 in | Open: 6.5 x 2.83 x 0.27 in Closed: 3.35 x 2.83 x 0.59 in | Open: 6.04x5.21 x0.22 in; Closed: 6.04x2.68x0.48 in |\n| Dimensions (millimeters) | 146.9 x 70.5 x 7.2 mm | 158.4 x 75.8 x 7.3 mm | 162.8 x 77.6 x 8.2 mm | 152.8x72x8.5 mm | 152.8x72x8.5 mm | 162.8x76.6x8.5 mm | 167.2 x 76.4 x 8.5mm | Open: 171.42 x 74 x 7.09mm Closed: 88.09 x 74 x 15.32mm | Open: 165.1 x 71.9 x 6.9mm Closed: 85.1 x 71.9 x 14.9mm | Open: 153.5x132.5x5.6mm; Closed: 153.5x68.1x12.1mm |\n| Weight (grams, ounces) | 162g (5.71 oz.) | 190g (6.70 oz.) | 218g (7.69 oz.) | 198g (7 oz.) | 199g (7 oz.) | 221g (7.8 oz) | 201g (7.09 oz.) | 189g (6.67 oz) | 187g (6.6 oz) | 239g (8.43 oz) |\n| Mobile software | Android 15 | Android 15 | Android 15 | Android 14 | Android 14 | Android 14 | Android 14 | Android 14 | Android 14 | Android 14 |\n| Camera | 50-megapixel (wide), 12-megapixel (ultrawide), 10-megapixel (3x telephoto) | 50-megapixel (wide), 12-megapixel (ultrawide), 10-megapixel (3x telephoto) | 200-megapixel (wide), 50-megapixel (ultrawide), 10-megapixel (3x telephoto), 50-megapixel (5x telephoto) | 50-megapixel (wide), 48-megapixel (ultrawide) | 50-megapixel (wide), 48-megapixel (ultrawide), 48-megapixel (5x telephoto) | 50-megapixel (wide), 48-megapixel (ultrawide), 48-megapixel (5x telephoto) | 50-megapixel (wide), 8-megapixel (ultrawide) | 50-megapixel (wide) 50-megapixel (2x telephoto) | 50-megapixel (wide), 12-megapixel (ultrawide) | 50-megapixel (wide), 12-megapixel (ultrawide), 10-megapixel (3x telephoto) |\n| Front-facing camera | 12-megapixel | 12-megapixel | 12-megapixel | 10.5-megapixel | 42-megapixel | 42-megapixel | 16-megapixel | 32-megapixel | 10-megapixel | 4-megapixel (inner screen under-display); 10-megapixel (cover screen) |\n| Video capture | 8K | 8K | 8K | 4K | 4K | 4K | 1,080p | 4K | TBD | 8K |\n| Processor | Qualcomm Snapdragon 8 Elite for Galaxy | Qualcomm Snapdragon 8 Elite for Galaxy | Qualcomm Snapdragon 8 Elite for Galaxy | Google Tensor G4 | Google Tensor G4 | Google Tensor G4 | Mediatek Dimensity 7020 | Snapdragon 8S Gen 3 | Snapdragon 8 Gen 3 | Snapdragon 8 Gen 3 |\n| RAM + storage | 12GB RAM + 128GB, 256GB | 12GB RAM + 256GB, 512GB | 12GB RAM + 256GB, 512GB, 1TB | 12GB RAM + 128GB, 256GB | 16GB + 128GB, 256GB, 512GB, 1TB | 16GB + 128GB, 256GB, 512GB, 1TB | 8GB RAM + 128GB | 12GB + 256GB | 12GB + 256GB, 512GB | 12GB + 256GB, 512GB, 1TB |\n| Expandable storage | None | None | None | None | None | None | Up to 1TB | None | None | None |\n| Battery | 4,000 mAh | 4,900 mAh | 5,000 mAh | 4,700 mAh | 4,700 mAh | 5,060 mAh | 5,000 mAh | 4,000 mAh | 4,000 mAh | 4,400 mAh |\n| Fingerprint sensor | Under display | Under display | Under display | Under display | Under display | Under display | Side | Side | Side | Side |\n| Connector | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C | USB-C |\n| Headphone jack | None | None | None | None | None | None | Yes | None | None | None |\n| US starting price | $800 (128GB) | $1,000 (256GB) | $1,300 (256GB) | $799 (128GB) | $999 (128GB) | $1,099 (128GB) | $300 (128GB) | $1,000 (256GB) | $1,100 (256GB) | $1,900 (256GB) |\nRecent updates\nIn July 2025, we added the Samsung Galaxy Z Fold 7 and Galaxy Z Flip 7 to our list. The Fold 7 replaces last year's Fold 6 and comes with a completely new design that makes it thinner, lighter and feel more like a \"regular phone.\" The Flip 7 is the best-built foldable flip phone we tested from Samsung. The thinner design and bigger displays are the headline features.\nFactors to consider when buying an Android phone\nLook at last year's phones: Companies typically keep previous models around at a discounted price. For example, while you can buy the $699 Pixel 8 or $999 Pixel 8 Pro for less than the current Pixel 9 equivalents.\nGet more for less with cheap phones: For a fraction of the cost, you can get a solid phone that does almost everything a pricier flagship phone can do. The Google Pixel 8A packs a good camera and is frequently discounted to under $400.\nCheck your Android type: Some phones, like Google's Pixel series, run a stock version of Android. Others, like Samsung's Galaxy phones, have their own software (OneUI) on top of Android. Each type has its own appeal and drawbacks. If you've been rocking a Samsung phone for years, you'll likely still be more at home on a new Galaxy phone.\nBe ready for Cyber Monday sales: The holidays usually bring big discounts and sales, even on phones.\nTest your phone: It's definitely worth going to a store and trying out a phone before you shell out hundreds of dollars for it.\nFind peace of mind with a case: You spent all this time choosing a phone, now protect it from damage with a case.\nHow we test phones\nWe test every phone in real-world scenarios focusing on its features, design, performance, cameras, battery life and overall value. We document our findings in an initial review that is periodically updated when there are new software updates or to compare against new phones from phones from competitors like Apple, Samsung, Google and OnePlus.\nPhotography\nPhotography is a major focus for most phones these days, so we take pictures and videos of various subjects in a variety of settings and lighting scenarios. We try out any new camera modes such as the 4K 120fps slow motion mode that debuted on the iPhone 16 Pro or the Add Me photo tool that launched with the Google Pixel 9 series.\nBattery life\nBattery testing is conducted in a variety of ways. We assess how long a phone lasts during a typical day of use, and note how it performs during more focused sessions of video calls, media streaming and gaming. We also conduct a video playback test, which isn't always included in the initial review and is added later in an update.\nPerformance\nWe use benchmarking apps to measure the performance, alongside our own anecdotal experiences using the phone for our review. Of particular note are how graphics and animations look. Are they smooth? Or do they lag or stutter? We also look at how quickly the phone switches between horizontal and vertical orientations and how fast the camera app opens and is ready to take a photo.\nWe perform processor-heavy tasks like editing photos, exporting videos and playing games. We evaluate whether a newer version of a particular phone includes enough features to make it worth upgrading from older models.\nRead more: How We Test Phones\nOther phones we tested\nSamsung's $650 Galaxy S24 FE is such a comfort to use that at moments our reviewer, Mike Sorrentino, felt like he was testing a scaled-back version of the $1,000 Galaxy S24 Plus. The S24 FE's large 6.7-inch 120Hz refresh-rate display made it easy for me to enjoy streaming shows, playing games and taking video calls throughout the day. And it includes nearly every software perk from the more expensive Galaxy S24 line. Read our full review of the Samsung Galaxy S24 FE.\nThe OnePlus 13 is the first true flagship phone of 2025 and there's plenty to like. From its powerful performance to its fast charging and vibrant display, it has much of what we expect from a top-end phone right now. It looks good too, has great waterproofing, a scattering of new AI skills and a reasonable six years of security support. But while accomplished in some respects, the OnePlus 13 feels more like a \"pretty good\" 2024 phone, rather than kicking off a new year of tech with any kind of fanfare. Read our OnePlus 13 review.\nAndroid phone FAQ\nWhich Android phone has the best camera?\nWhat are the best brands for Android phones?\nHow reliable is an Android phone?\nHow long does an Android phone last?\nWhat to look forward to in 2025\nSamsung teased the Galaxy S25 Edge at its January Galaxy Unpacked event. Not much is known about the phone aside from it being more slim than the regular Galaxy S25. Here's everything you need to know about the Samsung Galaxy S25 Edge. Google is expected to release the Pixel 10 series later this year."
    },
    {
      "url": "https://www.apple.com/newsroom/2025/01/our-longstanding-privacy-commitment-with-siri/?",
      "text": "APPLE STATEMENT\nJanuary 8, 2025\nOur longstanding privacy commitment with Siri\nAt Apple, we are committed to protecting user data, and our products and features are built from the ground up with innovative privacy technologies and techniques. Privacy is a foundational part of the design process, driven by principles that include data minimization, on-device intelligence, transparency and control, and strong security protections that work together to provide users with incredible experiences and peace of mind. This applies to all of our products and services, including Siri, which has been engineered to protect user privacy and is the most private digital assistant.\nApple has never used Siri data to build marketing profiles, never made it available for advertising, and never sold it to anyone for any purpose. We are constantly developing technologies to make Siri even more private, and will continue to do so.\nHere\u2019s how Siri protects user data.\nSiri Uses On-Device Processing Where Possible\nTo protect user privacy, Siri is designed to do as much processing as possible right on a user\u2019s device, allowing for personalized experiences without having to transfer and analyze personal information on Apple servers. When a user talks or types to Siri, their request is processed on device whenever possible. For example, when a user asks Siri to read unread messages, or when Siri provides suggestions through widgets and Siri search, the processing is done on the user\u2019s device. The contents of the messages aren\u2019t transmitted to Apple servers, because that isn\u2019t necessary to fulfill the request. And for capable devices, the audio of user requests is processed entirely on device using the Neural Engine, unless a user chooses to share it with Apple.1\nApple Minimizes the Amount of Data Collected for Siri Requests\nAlthough Apple attempts to do as much as possible on device, certain features require real-time input from Apple servers. And when that\u2019s the case, Siri uses as little data as possible to deliver an accurate result. Siri searches and requests are not associated with your Apple Account. A random identifier \u2014 a long string of letters and numbers associated with a single device \u2014 is used to keep track of data while it\u2019s being processed, rather than tying it to a user\u2019s identity through their Apple Account or phone number \u2014 a process that we believe is unique among digital assistants in use today.\nApple does not retain audio recordings of Siri interactions unless users explicitly opt in to help improve Siri, and even then, the recordings are used solely for that purpose. Users can easily opt out at any time.\nBreakthrough Privacy Protections with Private Cloud Compute\nWith the capabilities provided by Apple Intelligence, we are at the start of a new era for Siri, giving users the ability to get things done effortlessly with built-in intelligence features that make Siri more capable, personal, and helpful every day.\nDesigned to protect users\u2019 privacy at every step, many of the models that power Apple Intelligence run entirely on device. For Apple Intelligence requests that require access to larger models, Private Cloud Compute extends the privacy and security of iPhone into the cloud to unlock even more intelligence. When Siri uses Private Cloud Compute, a user\u2019s data is not stored or made accessible to Apple, and Private Cloud Compute only uses their data to fulfill the request.\nWe believe privacy is a fundamental human right, and we will continue our relentless focus on designing our products and services to protect it. Learn more about our approach to privacy at apple.com/privacy.\nShare article\nMedia\n-\nText of this article\n- Available on iPhone with A12 Bionic and later. Requires download of speech models. Available in German (Germany), English (Australia, Canada, India, U.K., U.S.), Spanish (Spain, Mexico, U.S.), French (France), Japanese (Japan), Mandarin Chinese (China mainland), and Cantonese (Hong Kong)."
    },
    {
      "url": "https://appcensus.io",
      "text": "Unlock unparalleled insight into your mobile app privacy\nWe provide comprehensive, mobile app privacy analysis powered by best-in-class technology. No source code required.\nAre you ready to unlock new insights and strengthen trust through smart privacy compliance?\nDon\u2019t assume, validate\nMobile app teams consistently highlight four key needs when conducting privacy assessments:\nAssurance\n\u201cHow can we ensure third party SDKs are doing what they say they do?\u201d\nVisibility\n\u201cIs data being sent somewhere it isn\u2019t supposed to go?\u201d\nValidation\n\u201cDo my Google Play Data Safety Labels reflect the latest updates?\u201d\nSupport\n\u201cWho can I ask for help?\u201d\nSee the whole story\nOur platform delivers detailed snapshots of mobile app behaviour to provide actionable steps in mitigating business risks like app store removal and loss of customer trust while helping to improve overall privacy outcomes.\nassurance\nApp behaviours scanned in real time\nReal-time scanning on virtual and live devices delivers instant insights into SDK and third-party activities.\nVisibility\nLine of sight into root causes of privacy issues\nUnderstand root causes for privacy issues by gaining access to in-depth app behavior, permission usage and data transfer analysis from pre-release apps and published apps on the Google Play Store.\nValidation\nEvaluate version changes against Google Play Store safety labels\nCapture application changes that require updates to your safety labels, preventing inaccurate disclosures, improving your Playstore submission process, and limiting platform and compliance risks.\nSupport\nAccess to our SDK knowledge base and team of experts\nOur cross-functional team of legal, technical, and privacy experts brings decades of experience to offer insights, context, and recommendations to help you interpret scan results, minimizing oversights.\nDon't wait for a crisis.\nGet your app scanned today.\nReady to gain full visibility into your app\u2019s privacy behaviors? Contact us to learn how.\n\u00a9AppCensus Inc. All rights reserved. Privacy Policy Terms of Service\nOffice\nAppCensus, Inc.\n1306 Solano Ave.\nAlbany CA 94706"
    },
    {
      "url": "https://www.cnet.com/news/privacy/we-tried-to-get-facebook-to-send-us-ads-based-on-our-conversations/",
      "text": "We've had some odd conversations in the CNET offices.\nSocial media reporter Queenie Wong expressed a sudden interest in chainsaw sculptures. Laura Hautala, our privacy reporter, blurted out an assessment of the cost of skydiving lessons. (She says $200 is reasonable for an introductory class, not that she'd take one.) Abrar Al-Heeti, a general assignment reporter, described getting kicked out of a Casper mattress store in a suburb of Chicago after her brother's kids went wild in it.\nThese offbeat exchanges weren't random. They were part of an informal study CNET conducted to see if we could get Facebook to deliver ads based on discussions we had when our phones were in earshot. We chose the topics -- some relatively unusual, others fairly common -- to see if we could find indications the social network was aware of our conversations and using them to target ads. We didn't find any.\nThe reason for our test: The long-running and hard-to-kill conspiracy theory that Facebook is listening to your conversations through the mic on your phone and then using this overheard dialogue to send you targeted ads. If you haven't heard about this urban legend, there's plenty of reading material online, including some lengthy threads on Reddit. The theory is so widespread that Facebook posted a formal denial four years ago and CEO Mark Zuckerberg denied it in testimony on Capitol Hill. Still, it just won't die. Acknowledging broad concern about surreptitious monitoring, Apple said on Monday that its iOS 14 software would give iPhone owners a heads up if an app started using a phone's camera or microphone by displaying an indicator in both the app and Control Center.\nOur two-week test wasn't meant to be exhaustive or scientific, though we did consult with security and systems experts to get some ideas on how to proceed. We weren't trying to prove or disprove that Facebook was listening to our conversations. Our goal was more modest. We were just looking for any indication the conspiracy theory might merit a more rigorous investigation.\nTwo of the eight participants reported getting ads for Casper or Purple, the online mattress stores, after a long conversation about beds and box springs. But it turned out the reporter getting the Casper ad had visited a medical website after a backache caused by a poor night's sleep. We suspect her research prompted the ad. The reporter who got the Purple ad had been receiving ads from the mattress maker before the test started. They simply continued. (A third participant got Purple ads before the conversation about mattresses, but not after. Go figure.) Discussions of more-specialized topics, such as an in-depth back-and-forth on the best chainsaw brands, prompted nothing.\nOur test method\nHere's how we conducted our informal test, which involved four reporters in San Francisco, three in New York and one in Chicago.\nWe chose three topics to discuss in front of our phones. (On the advice of experts, we turned off geolocation and Wi-Fi services on our phones during the test so Facebook would have a harder time gaining our location information and showing us ads based on what people nearby were viewing online.) The topics were chainsaws, skydiving and mattresses.\nFor three days before the first conversation, the reporters monitored ads delivered while they used Facebook. What they saw was a mishmash of semipersonalized promotions, stores they shopped at or publications similar to the ones they read, and the usual stuff pushed on Facebook, such as Uber and Lyft.\nOn a Friday, the reporters in San Francisco gathered to talk about chainsaws. In New York, reporters had these conversations independently. From Chicago, Abrar engaged in an amusing conversation by phone with an editor. The discussions, which lasted roughly 10 minutes, covered big-name brands, including Husqvarna, Stihl, Makita, DeWalt and a host of others. It inspired Queenie to express her profound appreciation of chainsaw carving.\nThree days later, the following Monday, the reporters gathered again to discuss skydiving. None of the reporters had jumped out of a plane. Had the reporters wanted to try parachuting, however, Facebook would've been of little help. No one got an ad recommending a skydive school.\nThe last conversation took place on the following Thursday. The topic this time was mattresses. We chose this topic because online mattress companies, such as Casper and Purple, often advertise on Facebook. If the social network was eavesdropping, we reasoned, this would be a wide-open opportunity for it to deliver ads based on our conversations.\nIan Sherr, a CNET editor, got an ad for Purple after the conversation. But he said he'd gotten the same ad before discussing the subject as part of the test. That led us to believe the ad wasn't prompted by our discussion of mattresses, but rather by something Ian had previously looked at. Laura saw a Purple ad before our mattress discussion, but not after it.\nQueenie got an ad from Casper after the discussion and was \"kind of creeped out.\" The ad even referenced the conspiracy theory, saying, \"No, your phone's not listening to you. We're talented mind readers...\" Then Queenie remembered she'd visited a Mayo Clinic page discussing relief for back pain after sleeping funny. We figure Facebook saw that research because it sees all the websites you visit if they participate in its pixel program or use its share, like and comment buttons.\nTo reiterate, our test wasn't scientific and wasn't designed to prove whether Facebook is or isn't listening to you through your phone. But based on our results and discussions with security experts -- and the fact that Facebook uses a myriad of other data points to base its targeted ads -- we didn't see anything that convinced us the social network is eavesdropping.\nWe're also pretty sure that won't kill the conspiracy theory that Facebook is eavesdropping via your phone, no matter how odd your conversation is.\nOriginally published on May 15, 2019, 5:00 a.m. PT\nUpdate, June 23, 2020, 11:14 a.m. PT: Adds news that Apple is introducing indicators that let iPhone owners know if apps are using the camera or microphone."
    },
    {
      "url": "https://petsymposium.org/popets/2018/popets-2018-0030.php",
      "text": "Panoptispy: Characterizing Audio and Video Exfiltration from Android Applications\nAuthors: Elleen Pan (Northeastern University), Jingjing Ren (Northeastern University), Martina Lindorfer (UC Santa Barbara), Christo Wilson (Northeastern University), David Choffnes (Northeastern University)\nVolume: 2018\nIssue: 4\nPages: 33\u201350\nDOI: https://doi.org/10.1515/popets-2018-0030\nAbstract: The high-fidelity sensors and ubiquitous internet connectivity offered by mobile devices have facilitated an explosion in mobile apps that rely on multimedia features. However, these sensors can also be used in ways that may violate user\u2019s expectations and personal privacy. For example, apps have been caught taking pictures without the user\u2019s knowledge and passively listened for inaudible, ultrasonic audio beacons. The developers of mobile device operating systems recognize that sensor data is sensitive, but unfortunately existing permission models only mitigate some of the privacy concerns surrounding multimedia data. In this work, we present the first large-scale empirical study of media permissions and leaks from Android apps, covering 17,260 apps from Google Play, AppChina, Mi.com, and Anzhi. We study the behavior of these apps using a combination of static and dynamic analysis techniques. Our study reveals several alarming privacy risks in the Android app ecosystem, including apps that over-provision their media permissions and apps that share image and video data with other parties in unexpected ways, without user knowledge or consent. We also identify a previously unreported privacy risk that arises from third-party libraries that record and upload screenshots and videos of the screen without informing the user and without requiring any permissions.\nKeywords: privacy; mobile devices; audio, video, and image leaks\nCopyright in PoPETs articles are held by their authors. This article is published under a Creative Commons Attribution-NonCommercial-NoDerivs 3.0 license."
    },
    {
      "url": "https://www.pbs.org/newshour/nation/facebook-paid-contractors-to-transcribe-users-audio-clips",
      "text": "By \u2014 Mae Anderson, Associated Press Mae Anderson, Associated Press By \u2014 Rachel Lerman, Associated Press Rachel Lerman, Associated Press Leave a comment 0comments Share Copy URL https://www.pbs.org/newshour/nation/facebook-paid-contractors-to-transcribe-users-audio-clips Email Facebook Twitter LinkedIn Pinterest Tumblr Share on Facebook Share on Twitter Facebook paid contractors to transcribe users\u2019 audio clips Nation Aug 14, 2019 1:38 PM EDT NEW YORK (AP) \u2014 Facebook has paid contractors to transcribe audio clips from users of its Messenger service, raising privacy concerns for a company with a history of privacy lapses. The practice was, until recently, common in the tech industry. Companies say the practice helps improve their services. But users aren\u2019t typically aware that humans and not just computers are reviewing audio. Transcriptions done by humans raise bigger concerns because of the potential of rogue employees or contractors leaking details. The practice at Google emerged after some of its Dutch language audio snippets were leaked. More than 1,000 recordings were obtained by Belgian broadcaster VRT NWS, which noted that some contained sensitive personal conversations \u2014 as well as information that identified the person speaking. READ MORE: Is FaceApp a security risk? 3 privacy concerns you should take seriously Facebook said audio snippets reviewed by contractors were masked so as not to reveal anyone\u2019s identity. It said it stopped the practice a week ago. The development was reported earlier by Bloomberg. Google said it suspended doing this worldwide while it investigates the leaks. Amazon said it still uses humans, but users can decline, or opt out, of the human transcriptions. Published reports say Apple also has used humans, but has stopped. Irish data-protection regulators say they\u2019re seeking more details from Facebook to assess compliance with European data regulations. Facebook is already under scrutiny for a variety of other ways it has misused user data. It agreed to a $5 billion fine to settle a U.S. Federal Trade Commission probe of its privacy practices. Lerman reported from San Francisco. We're not going anywhere. Stand up for truly independent, trusted news that you can count on! Donate now By \u2014 Mae Anderson, Associated Press Mae Anderson, Associated Press By \u2014 Rachel Lerman, Associated Press Rachel Lerman, Associated Press\nNEW YORK (AP) \u2014 Facebook has paid contractors to transcribe audio clips from users of its Messenger service, raising privacy concerns for a company with a history of privacy lapses. The practice was, until recently, common in the tech industry. Companies say the practice helps improve their services. But users aren\u2019t typically aware that humans and not just computers are reviewing audio. Transcriptions done by humans raise bigger concerns because of the potential of rogue employees or contractors leaking details. The practice at Google emerged after some of its Dutch language audio snippets were leaked. More than 1,000 recordings were obtained by Belgian broadcaster VRT NWS, which noted that some contained sensitive personal conversations \u2014 as well as information that identified the person speaking. READ MORE: Is FaceApp a security risk? 3 privacy concerns you should take seriously Facebook said audio snippets reviewed by contractors were masked so as not to reveal anyone\u2019s identity. It said it stopped the practice a week ago. The development was reported earlier by Bloomberg. Google said it suspended doing this worldwide while it investigates the leaks. Amazon said it still uses humans, but users can decline, or opt out, of the human transcriptions. Published reports say Apple also has used humans, but has stopped. Irish data-protection regulators say they\u2019re seeking more details from Facebook to assess compliance with European data regulations. Facebook is already under scrutiny for a variety of other ways it has misused user data. It agreed to a $5 billion fine to settle a U.S. Federal Trade Commission probe of its privacy practices. Lerman reported from San Francisco. We're not going anywhere. Stand up for truly independent, trusted news that you can count on! Donate now"
    },
    {
      "url": "https://www.cnet.com/tech/mobile/supreme-court-says-warrant-necessary-for-phone-location-data/",
      "text": "The US Supreme Court has ruled in favor of digital privacy.\nIn a 5-4 decision on Friday, the justices said police need warrants to gather phone location data as evidence for trials. That reversed and remanded a decision by the Sixth Circuit Court of Appeals.\nCarpenter v. United States is the first case about phone location data that the Supreme Court has ruled on. That makes it a landmark decision regarding how law enforcement agencies can use technology as they build cases. The court heard arguments in the case on Nov. 29.\nThe dispute dates back to a 2011 robbery in Detroit, after which police gathered months of phone location data from Timothy Carpenter's phone provider. They pulled together 12,898 different locations from Carpenter, over 127 days.\nThe legal and privacy concern was that police gathered the four months' worth of Carpenter's digital footprints without a warrant. A Sixth Circuit Court of Appeals judge ruled that cellphone location data isn't protected by the Fourth Amendment, which forbids unreasonable search and seizure, and therefore didn't require a warrant.\nIn the Supreme Court's ruling, Chief Justice John Roberts wrote the government's searches of Carpenter's phone records were considered a Fourth Amendment search.\n\"The government's position fails to contend with the seismic shifts in digital technology that made possible the tracking of not only Carpenter's location but also everyone else's, not for a short period but for years and years,\" he wrote.\nRoberts said allowing government access to historical GPS data infringes on Carpenter's Fourth Amendment protections and expectation of privacy, by providing law enforcement with an \"all-encompassing record\" of his whereabouts. He added that historical GPS data presents an \"even greater privacy risk\" than real-time GPS monitoring.\nCarpenter's attorneys, including lawyers from the American Civil Liberties Union, argued before the Supreme Court that cellphone location data constitutes sensitive digital records and should be protected under the Fourth Amendment.\n\"This is a groundbreaking victory for Americans' privacy rights in the digital age,\" ACLU attorney Nathan Freed Wessler, who argued the case, said in a statement. \"The Supreme Court has given privacy law an update that it has badly needed for many years, finally bringing it in line with the realities of modern life. The government can no longer claim that the mere act of using technology eliminates the Fourth Amendment's protections.\"\nPhone location data is a hot-button issue for privacy advocates. In May, Sen. Ron Wyden, a Democrat from Oregon, asked phone service providers why they were giving away location data to Securus Technologies, a service that monitors calls to prison inmates, which police could use to track anybody's phone in the US, without a warrant.\nAlso in May, the Federal Communications Commission opened an investigation into LocationSmart, a company that offered phone-tracking capabilities.\nThe Supreme Court's decision now sets a precedent for every Americans' phone location data being used in criminal investigations, Wessler said.\n\"It's not just about Carpenter, it's about the rights of Americans who own cellphones, which is in excess of 95 percent of people in the country,\" Wessler said in a press conference call.\nFighting 'near-perfect surveillance'\nWyden said Friday's ruling was a \"welcome step\" for privacy and fighting against the expanding power of government surveillance.\n\"The court's recognition that digital devices can generate 'near-perfect surveillance' of a person's private life is a validation of the vital protections against unreasonable search and seizure provided by our Constitution,\" the senator said.\nThe losing argument was that phone companies can provide customers' data to law enforcement because they own those records, not the person. During the trial, US Deputy Solicitor General Michael Dreeben told the Supreme Court that people agree to hand over their information to providers for their service.\n\"It is asking a business to provide information about the business' own transactions with a customer,\" Dreeben said in November.\nBefore the trial took place, major tech companies, including Apple, Facebook and Google, filed a friend-of-the-court brief with the Supreme Court, urging the justices to make it harder for law enforcement officials to obtain individuals' data without a warrant.\nWhile the decision sets a ruling for historical GPS data, the Supreme Court said it does not apply to security cameras, business records or real-time location tracking.\nAs technology improves, so will surveillance techniques, Ryan Radia, a Center for Technology and Innovation research fellow, said. For example, cell tower location data is going to become much more accurate once 5G rolls out, Radia said.\nHe said Friday's decision showed that the Supreme Court is willing to continue to weigh privacy implications that technology continues to change.\n\"For people who are understandably worried about technological evolution enabling tools and mass surveillance, they can take solace in the fact that the court has willingness to limit the government's abilities to surveill,\" Radia said.\nIn a tweet, the ACLU's deputy legal director called the decision a \"civil liberties VICTORY.\"\nEdward Snowden, the NSA whistleblower, said the decision was a major victory for the US.\nThe Computer and Communications Industry Association's president, Ed Black, said the decision would have significant impact on how the Fourth Amendment protects your data from government surveillance.\n\"This decision will provide users with the confidence that the sensitive location data they share with innovative digital devices and services will only be disclosed to law enforcement with a warrant based on probable cause,\" he said.\nYou can read the 119-page decision here:\nOriginally published June 22 at 7:21 a.m. PT.\nUpdated at 7:38 a.m. PT: To include details from the Supreme Court's decision, at 7:54 a.m. PT: To include a statement from Sen. Ron Wyden, at 8:10 a.m. PT: To add reactions to the decision, at 9:40 a.m. PT: To include statements from the ACLU's press conference.\nCorrection at 11:53 a.m. PT: To adjust a description of LocationSmart.\nSecurity: Stay up-to-date on the latest in breaches, hacks, fixes and all those cybersecurity issues that keep you up at night.\nCNET Magazine: Check out a sample of the stories in CNET's newsstand edition."
    },
    {
      "url": "https://www.cnet.com/home/smart-home/alexa-sent-private-audio-to-a-random-contact-portland-family-says/",
      "text": "One minute, you're relaxing at home discussing the merits of hardwood floors. The next, a contact is calling you and telling you you're being hacked.\nThat's how a family in Portland, Oregon, is describing their experience with Amazon's Alexa after the popular voice assistant reportedly sent audio of a private conversation to one of their contacts -- all without them knowing it.\nThe family had filled their home with Alexa devices to control their lights, HVAC and security system using voice commands. Then, they say that one of the father's work contacts called to let them know that he'd received an Alexa call broadcasting audio of a private conversation about flooring -- a call the family says they never asked Alexa to make.\nNow, they tell a Seattle news station that their Alexa devices are left permanently unplugged.\n\"I felt invaded,\" said Danielle, who didn't want her last name used. \"A total privacy invasion. Immediately I said, 'I'm never plugging that device in again, because I can't trust it.'\"\nDanielle says that the family got in touch with Amazon's engineering department, who were able to confirm that audio had indeed been unintentionally broadcast.\n\"They said, 'Our engineers went through your logs, and they saw exactly what you told us, they saw exactly what you said happened, and we're sorry,'\" Danielle told KIRO 7.\n\"He apologized like 15 times in a matter of 30 minutes and he said, 'We really appreciate you bringing this to our attention, this is something we need to fix!'\"\nDanielle says that Amazon was unable to pinpoint exactly what had caused the unintentional broadcast, but the company now tells CNET that Alexa mistakenly heard the wake word, then mistakenly heard a command to call someone, complete with a third misheard confirmation.\n\"Echo woke up due to a word in background conversation sounding like 'Alexa,'\" a spokesperson tells CNET. \"Then, the subsequent conversation was heard as a 'send message' request. At which point, Alexa said out loud, 'To whom?' At which point, the background conversation was interpreted as a name in the customer's contact list. Alexa then asked out loud, '[contact name], right?' Alexa then interpreted background conversation as 'right.'\n\"As unlikely as this string of events is, we are evaluating options to make this case even less likely.\"\nBy Amazon's own admission, that's an awful lot of misheard commands, which paints this as something of an elaborate \"Alexa butt-dial.\" Whether or not that's enough to dial down concerns about the privacy risks of always-listening devices is another question -- more details on the effort to make Alexa better at recognizing and dismissing false positives would certainly be a good start.\nEditor's note, 2:15 p.m. PT: Updated to include comment from Amazon.\nCorrection, 1:40 p.m. PT: This story initially misstated the state where the family lives. They live in Oregon.\nHomePod, Echo, Google Home: How secure are your speakers?\nThe best PCs for privacy-minded people: Even Mark Zuckerberg covers his webcam."
    },
    {
      "url": "https://www.theguardian.com/technology/2019/jul/26/apple-contractors-regularly-hear-confidential-details-on-siri-recordings",
      "text": "Apple contractors regularly hear confidential medical information, drug deals, and recordings of couples having sex, as part of their job providing quality control, or \u201cgrading\u201d, the company\u2019s Siri voice assistant, the Guardian has learned.\nAlthough Apple does not explicitly disclose it in its consumer-facing privacy documentation, a small proportion of Siri recordings are passed on to contractors working for the company around the world. They are tasked with grading the responses on a variety of factors, including whether the activation of the voice assistant was deliberate or accidental, whether the query was something Siri could be expected to help with and whether Siri\u2019s response was appropriate.\nApple says the data \u201cis used to help Siri and dictation \u2026 understand you better and recognise what you say\u201d.\nBut the company does not explicitly state that that work is undertaken by humans who listen to the pseudonymised recordings.\nApple told the Guardian: \u201cA small portion of Siri requests are analysed to improve Siri and dictation. User requests are not associated with the user\u2019s Apple ID. Siri responses are analysed in secure facilities and all reviewers are under the obligation to adhere to Apple\u2019s strict confidentiality requirements.\u201d The company added that a very small random subset, less than 1% of daily Siri activations, are used for grading, and those used are typically only a few seconds long.\nA whistleblower working for the firm, who asked to remain anonymous due to fears over their job, expressed concerns about this lack of disclosure, particularly given the frequency with which accidental activations pick up extremely sensitive personal information.\nSiri can be accidentally activated when it mistakenly hears its \u201cwake word\u201d, the phrase \u201chey Siri\u201d. Those mistakes can be understandable \u2013 a BBC interview about Syria was interrupted by the assistant last year \u2013 or less so. \u201cThe sound of a zip, Siri often hears as a trigger,\u201d the contractor said. The service can also be activated in other ways. For instance, if an Apple Watch detects it has been raised and then hears speech, Siri is automatically activated.\nThe whistleblower said: \u201cThere have been countless instances of recordings featuring private discussions between doctors and patients, business deals, seemingly criminal dealings, sexual encounters and so on. These recordings are accompanied by user data showing location, contact details, and app data.\u201d\nThat accompanying information may be used to verify whether a request was successfully dealt with. In its privacy documents, Apple says the Siri data \u201cis not linked to other data that Apple may have from your use of other Apple services\u201d. There is no specific name or identifier attached to a record and no individual recording can be easily linked to other recordings.\nAccidental activations led to the receipt of the most sensitive data that was sent to Apple. Although Siri is included on most Apple devices, the contractor highlighted the Apple Watch and the company\u2019s HomePod smart speaker as the most frequent sources of mistaken recordings. \u201cThe regularity of accidental triggers on the watch is incredibly high,\u201d they said. \u201cThe watch can record some snippets that will be 30 seconds \u2013 not that long but you can gather a good idea of what\u2019s going on.\u201d\nSometimes, \u201cyou can definitely hear a doctor and patient, talking about the medical history of the patient. Or you\u2019d hear someone, maybe with car engine background noise \u2013 you can\u2019t say definitely, but it\u2019s a drug deal \u2026 you can definitely hear it happening. And you\u2019d hear, like, people engaging in sexual acts that are accidentally recorded on the pod or the watch.\u201d\nThe contractor said staff were encouraged to report accidental activations \u201cbut only as a technical problem\u201d, with no specific procedures to deal with sensitive recordings. \u201cWe\u2019re encouraged to hit targets, and get through work as fast as possible. The only function for reporting what you\u2019re listening to seems to be for technical problems. There\u2019s nothing about reporting the content.\u201d\nAs well as the discomfort they felt listening to such private information, the contractor said they were motivated to go public about their job because of their fears that such information could be misused. \u201cThere\u2019s not much vetting of who works there, and the amount of data that we\u2019re free to look through seems quite broad. It wouldn\u2019t be difficult to identify the person that you\u2019re listening to, especially with accidental triggers \u2013 addresses, names and so on.\n\u201cApple is subcontracting out, there\u2019s a high turnover. It\u2019s not like people are being encouraged to have consideration for people\u2019s privacy, or even consider it. If there were someone with nefarious intentions, it wouldn\u2019t be hard to identify [people on the recordings].\u201d\nThe contractor argued Apple should reveal to users this human oversight exists \u2013 and, specifically, stop publishing some of its jokier responses to Siri queries. Ask the personal assistant \u201care you always listening\u201d, for instance, and it will respond with: \u201cI only listen when you\u2019re talking to me.\u201d\nThat is patently false, the contractor said. They argued that accidental triggers are too regular for such a lighthearted response.\nApple is not alone in employing human oversight of its automatic voice assistants. In April, Amazon was revealed to employ staff to listen to some Alexa recordings, and earlier this month, Google workers were found to be doing the same with Google Assistant.\nApple differs from those companies in some ways, however. For one, Amazon and Google allow users to opt out of some uses of their recordings; Apple offers no similar choice short of disabling Siri entirely. According to Counterpoint Research, Apple has 35% of the smartwatch market, more than three times its nearest competitor Samsung, and more than its next six biggest competitors combined.\nThe company values its reputation for user privacy highly, regularly wielding it as a competitive advantage against Google and Amazon. In January, it bought a billboard at the Consumer Electronics Show in Las Vegas announcing that \u201cwhat happens on your iPhone stays on your iPhone\u201d."
    },
    {
      "url": "https://safety.google/intl/en_us/assistant/",
      "text": "Assistant\nGoogle Assistant is built to keep your information\nprivate, safe, and secure\nWhen you use Google Assistant, you trust us with your data, and it\u2019s our responsibility to protect and respect it. Privacy is personal. That\u2019s why we build simple privacy controls to help you choose what\u2019s right for you. Explore this page to learn more about how Google Assistant works, your built-in privacy controls, answers to common questions, and more.\nWatch the film\nLink to Youtube Video (visible only when JS is disabled)\nStarts in standby\nLearn more about how Google Assistant handles audio recordings\nNo. Google Assistant is designed to wait in standby mode until it detects an activation, like when it hears \u201cHey Google.\u201d When in standby mode, your Assistant won\u2019t send what you are saying to Google or anyone else. Once Google Assistant detects an activation, it exits standby mode and sends your request to Google servers. This can also happen if there is a noise that sounds like \u201cHey Google\u201d or an unintended manual activation.\nYou can activate your Assistant in a few ways, depending on your device. For example, you might say \u201cHey Google\u201d or activate it manually by holding your phone\u2019s power button or home button.\nThe status indicator on your device, such as an on-screen indicator or flashing LEDs on top of your device, lets you know when Google Assistant is activated.\nGoogle Assistant might activate when you didn\u2019t intend it to because it incorrectly detected that you wanted its help - for instance when there is a noise that sounds like \u201cHey Google\u201d or you manually activate it accidentally.\nIf that happens, and your Web & App Activity is turned on, you can say, \u201cHey Google, that wasn\u2019t for you,\u201d and your Assistant will delete what you said from My Activity. You can also review and delete your Assistant interactions in My Activity at any time. If Google Assistant activates when you didn\u2019t intend it to, and your Web & App Activity setting is disabled, your Assistant interaction will not be stored in My Activity. If, however, your Web & App Activity setting is on, your Assistant interactions, including any unintended activations, will be stored in My Activity and treated like normal activations. Your data in My Activity is used to develop and improve Google services (including technologies that help reduce unintended activations), as explained in Google\u2019s Privacy Policy. You can always stop saving activity by turning off your Web & App Activity setting.\nTo better tailor Google Assistant to your environment, you can adjust how sensitive your Assistant is to activation phrases (like \u201cHey Google\u201d) through the Google Home app for smart speakers and smart displays.\nWe are constantly working to make our systems better for\neveryone, including building technologies to help reduce\nunintended activations.\nGoogle Assistant is designed to wait in standby mode until it detects an activation. In standby mode, the device processes short snippets of audio (a few seconds) to detect an activation \u2013 like when you say \u201cHey Google.\u201d If no activation is detected, then those audio snippets won\u2019t be sent or saved to Google.\nOnce it detects an activation, your Assistant exits standby mode - this includes if there is an unintended manual activation or a noise that sounds like \u201cHey Google.\u201d Your device then records what it hears and sends the audio recording to Google servers to fulfill your request. The recording may include a few seconds before the activation to catch your entire request.\nBy default, your audio recordings are not saved on Google servers - you can change this setting anytime by viewing the \u201cInclude voice and audio activity\u201d checkbox under the Web & App Activity setting.\nDesigned for privacy\nAssistant uses your queries and info from your linked devices and services, to understand and respond to you, including to personalize your experience. Examples of info from your linked devices and services include location, contacts, device names, tasks, events, alarms, installed apps, and playlists.\nYour data is also used to develop and improve Google products and services and machine learning technologies (including technologies that help reduce unintended activations), as explained in Google\u2019s Privacy Policy. To help assess quality and improve Assistant, human reviewers (which include third parties) read, annotate, and process the text of your Assistant queries and related info. We take steps to protect your privacy as part of this process. This includes disassociating your queries from your Google Account before reviewers see or annotate them.\nLearn more about how Google Assistant works with your data. Visit Google\u2019s Privacy Policy to learn more about how Google protects and uses your data.\nBy default, your audio recordings are not saved on Google servers - you can change this setting anytime by viewing the \u201cInclude voice and audio activity\u201d checkbox under the Web & App Activity setting.\nWith Personalized speech recognition, Google Assistant will get better at recognizing your words and phrases to offer more tailored help. Starting with Pixel 7 and Pixel 7 Pro, this feature works by saving your Assistant interactions, including audio, securely on your device. You can turn this feature off at any time in \u201cYour Speech Recognition\u201d in Assistant settings.\nIf you\u2019d like to help improve our audio recognition technology for everyone, including technologies to help reduce unintended activations for everyone, you can choose to have your audio recordings securely retained and made available to our speech improvement systems. This helps products like Google Assistant improve their ability to understand language even better in the future. Learn more about this process.\nIf you decide to save your audio recordings, portions of them may be reviewed to help us improve our audio recognition technologies, including technologies to help reduce unintended activations for everyone.\nFor example, audio recordings can be used for Google\u2019s audio review process. During this process, a sample of machine-selected audio snippets are disassociated from their Google accounts. Then trained reviewers (which include third parties) can analyze the audio to annotate the recording and verify if the words said were accurately understood by Google\u2019s audio recognition technologies. This helps a product like Google Assistant improve its ability to understand language even better in the future.\nGovernment agencies can issue legal processes to Google requesting user data. We carefully review each request in accordance with applicable laws. If a request is overly broad, we may narrow it, or object to producing the requested data. In our Transparency Report, we share the number and types of requests that we receive. Learn more.\nGoogle never sells your audio recordings or other personal information.\nEasy-to-use privacy controls\nJust ask Google Assistant questions like \u201cWhere can I change my privacy settings?\u201d to get answers to the most common privacy and security questions. Or you can always visit \u201cYour data in the Assistant\u201d directly to access your privacy controls.\nYou can review and delete your Assistant interactions from My Activity, or by saying \u201cHey Google, delete what I said this week.\u201d Visit your Assistant settings to access additional controls.\nYes, you can have your activity data auto-delete from My Activity. Choose a time limit for how long you want your activity data to be saved there\u2013 3, 18, or 36 months \u2013 and any data older than that will be automatically deleted from My Activity on an ongoing basis.\nData from your Google Account can personalize your Google Assistant experience and make your Assistant more useful to you.\nThere are certain questions that require your data for Google Assistant to help. For example, if you ask \u201cWhen is my mom\u2019s birthday?\u201d your Assistant needs to reference your contacts to know who \u201cmom\u201d is and look up her birthday. Or if you ask \u201cDo I need an umbrella tomorrow?\u201d your Assistant uses your current location to give you the most relevant answer.\nGoogle Assistant also uses data to provide you with proactive suggestions. For example, your Assistant can notify you when there is traffic on your regular routes by using your location.\nGoogle Assistant can improve your results using activity in your Google Account. For example, if you ask \u201cWhat should I make for dinner tonight?\u201d your Assistant may use previous Search history to provide personalized recipe recommendations.\nYou can always visit \u201cYour data in Google Assistant\u201d to view or delete your data, check your current settings, and learn more about the controls available.\nVisit Google\u2019s Privacy Policy to learn more about how Google protects and uses your data.\nYes. Google Assistant makes it easy for multiple users to each have a personalized experience on a shared device. To receive personal results \u2013 like directions to work or personalized recipe recommendations \u2013 only when your Assistant recognizes your voice, set up Voice Match by following these steps. Family Link users can also get personal results from Google Assistant by following these steps.\nOn mobile and shared devices like speakers, you can control access to personal results by changing your settings. And on mobile, you can control how personal results appear on your lock screen.\nHey Google, tell me about Guest Mode\nTo turn on Guest Mode, just say, \u201cHey Google, turn on Guest Mode\u201d to your speaker or Smart Display. To return to your personalized Assistant experience, just say, \u201cHey Google, turn off Guest Mode.\u201d Your device will remain in Guest Mode until you or someone else requests to exit the mode.\nWhen you're in Guest Mode, your device will play a special chime. On displays, you'll also see a guest icon on the screen. And if you\u2019re not sure, you can always ask. Just say, \u201cHey Google, is Guest Mode on?\"\nYes, anyone interacting with your device can turn Guest Mode on and off.\nChildren that have an account linked to Google Assistant will not be able to turn on Guest Mode.\nNo, putting a device in Guest Mode does not turn it on for multiple devices.\nIn Guest Mode, you can still enjoy the convenience of your Assistant, like asking questions, controlling smart home devices, setting timers, and playing music. However, personalized results will not be available until you leave Guest Mode. These include your calendar, shopping lists, saved contacts and more. At any time, you can say, \u201cHey Google, turn off Guest Mode\u201d to return to your personalized experience.\nYour Assistant interactions, including all of your voice queries, won\u2019t be saved to your Google Account. If you ask your Assistant to interact with another app or service, like your music provider or another Google product, that app or service may still retain your activity history within that app.\nWhile in Guest Mode, your Google Assistant activity history won\u2019t be saved to your Google Account and won\u2019t be used to personalize your Assistant experience. For example, if you look up recipes while in Guest Mode, those searches will not be used by Google to tailor recipe recommendations for you in the future. However, because other products may still save your activity if you interact with them while in Guest Mode, your YouTube and Maps activity while in Guest Mode may still be used to recommend future videos and places to go.\nEven if your audio recordings and Assistant activity on the device are normally saved to your Google Account, this won't happen in Guest Mode.\nBuilt for families\nGoogle Assistant provides a variety of activities, from stories, to games, to learning tools for children and families, including some content provided by third-party developers. These developers must qualify to publish content for families on Assistant by having a Teacher Approved app, or entering into a partnership agreement with Google for their family-friendly Action. Any Actions intended for children provided by third-party developers must meet specific requirements of our Actions for Families program, in addition to our standard Action policies. We review these Actions for compliance with our policies and requirements before they are generally available in Google Assistant.\nYou can set content controls for shared devices in your home, like smart displays, using the Digital Wellbeing controls in the Google Home app. With these settings, you can manage downtime schedules, content filtering settings, and limit certain activities, such as phone calls. You can also decide if these settings apply to guests and supervised accounts managed with Family Link, or all users of that device.\nYou can set limits for individual children using the parental controls offered in Family Link. On shared devices, you can link your child\u2019s account to the device using Voice Match, so Assistant can recognize them. Once your child is enrolled, they can only access non-Google Actions with the \u201cFor families\u201d badge and are prevented from taking certain actions, such as making purchases through Assistant. These limits apply on any Google Assistant devices where they are enrolled. For more information about how a Family Link account works with Google Home and Assistant, see the Google for Families Help.\nGoogle does not share personal information, such as your child's name, email address, voice recordings, or specific location, to Actions for Families providers. These providers also agree to not solicit personal information from users in their Google Assistant conversations. We take action if we find any Actions violating these policies.\nWe do not save audio recordings from interactions with children\u2019s features like Actions for Families activities or YouTube Kids videos, unless we have consent to do so for a Google Account Managed with Family Link that has opted in to include audio recordings. For more details, see our Privacy Notice.\nYes. You can access, export, and delete your child\u2019s saved activity by signing into their account managed by Family Link. You can also manage your child\u2019s activity settings through the Family Link app, or by visiting families.google.com and clicking on the child\u2019s profile. For more details, go to g.co/childaccounthelp."
    },
    {
      "url": "https://www.theguardian.com/commentisfree/article/2024/sep/04/yes-it-sounds-like-a-conspiracy-theory-but-maybe-our-phones-really-are-listening-to-us",
      "text": "Conspiracy theorists of the world, rip off that tinfoil hat and take a bow: you were (kinda) right. Despite the fact pretty much everyone has a story involving chatting about something only to see an ad for that something pop up on a device, the idea that your phone actively listens to you has long been dismissed as silly. After all, brands don\u2019t need to eavesdrop like that \u2013 they already have access to millions of data points that build up a detailed picture of your habits and predicted purchases.\nBut just because brands don\u2019t need to listen to your conversations, it doesn\u2019t mean that there aren\u2019t companies figuring out creepy new ways to mine your data. 404 Media, a tech-focused news site, recently got hold of a pitch deck from Cox Media Group (CMG), touting its \u201cActive Listening\u201d software, which targets adverts based on what people say near their device microphones. The presentation doesn\u2019t specify whether this voice data comes from smart TVs, smart speakers, or smartphones but the slide where it extols \u201cthe power of voice (and our devices\u2019 microphones)\u201d has a picture of people looking at their phones.\nI\u2019m not going to make the predictable Black Mirror reference because CMG already has. When 404 Media reported on Active Listening last year, CMG\u2019s website had the following (now deleted) blurb: \u201cWhat would it mean \u2026 if you could target potential clients who are actively discussing their need for your services in their day-to-day conversations? No, it\u2019s not a Black Mirror episode \u2013 it\u2019s Voice Data.\u201d\nIt\u2019s hard to know how widespread the use of this service is, but CMG\u2019s deck lists Facebook, Google and Amazon among its partners \u2013 though this doesn\u2019t necessarily mean they\u2019ve partnered on this particular technology. Amazon, for its part, has said it has never worked with CMG, and Google removed CMG from its Partners Program after the 404 report. Meta, Facebook\u2019s parent company, said it is investigating whether CMG has violated its terms of service. While a lot of details remain murky, what\u2019s clear is this: privacy died a long time ago. Nothing is off-limits for some advertisers \u2013 there have even been experiments with \u201ctargeted dream incubation\u201d in an attempt to brand your dreams. The future is a meticulously personalised, highly targeted nightmare.\nArwa Mahdawi is a Guardian columnist"
    },
    {
      "url": "https://www.marketingdive.com/news/amazons-ad-business-stays-strong-as-ctv-dsp-offerings-improve/756562/",
      "text": "Dive Brief:\n- Amazon\u2019s revenue generated from advertising rose 22% year over year to $15.7 billion in Q2 2025, per an earnings statement. The revenue figure beat Wall Street expectations.\n- Executives highlighted developments around the retailer\u2019s demand-side platform (DSP) and its recent deal with Roku around connected TV (CTV), while signaling that Alexa+ could eventually offer advertising opportunities.\n- The company said that it hasn\u2019t yet seen diminishing demand nor meaningful appreciation in prices due to tariffs, but noted the possible impact of recessionary fears on its Q3 guidance.\nDive Insight:\nAmazon\u2019s ad business continues to grow at a rate that exceeds that of its core retail business, which saw net sales increase 13% to $167.7 billion in the quarter. The company helps advertisers reach an average ad-supported audience of more than 300 million consumers in the U.S. through full-funnel offerings that include its retail marketplace, Prime Video, Twitch and \u2014 increasingly \u2014 its DSP.\n\u201cOur trillions of proprietary browsing, shopping, and streaming signals paired with extensive supply side relationships and our secure clean rooms provide advertisers the ability to optimize advertising, deliver greater precision, and drive efficient and effective advertising outcomes,\u201d CEO Andy Jassy said of the DSP on an earnings call.\nAlong with revamping the DSP user experience in October, Amazon in June integrated it with Disney\u2019s Real-Time Ad Exchange (DRAX), allowing advertisers to leverage insights from both companies. Amazon last month also partnered with Roku to offer advertisers using its DSP what the companies claim is the largest authenticated CTV footprint in the U.S., a partnership Jassy called \u201cmomentous.\u201d\n\u201cIt\u2019s a giant leap forward for advertisers bringing best in class planning, audience precision, and performance to TV advertising,\u201d the executive said.\nAmazon has continued to build out its advertising ecosystem, unveiling artificial intelligence-powered contextual ads at its second annual upfront in May, partnering with InfoSum and Magnite around data and widening access to AI tools for advertisers.\nFor its retail business, Amazon expects Q3 net sales to be between $174 billion and $179.5 billion, a wide range that takes into consideration a macroeconomic environment that continues to be effected by President Trump\u2019s moves around tariffs. The company\u2019s guidance around operating income in Q3 was lower than analysts expected. Executives noted that it is still too early to see how tariffs will settle and who will absorb the costs.\n\u201cIn the first half, we just haven\u2019t seen diminished demand and we haven\u2019t seen any kind of broad scale [average sale price] increases. And, you know, so that could change in the second half. There are a lot of things that we don\u2019t know, but that\u2019s what we\u2019ve seen so far,\u201d Jassy said."
    },
    {
      "url": "https://www.cnet.com/tech/mobile/iphone-17-rumors-everything-to-know-from-redesigned-cameras-to-an-upgraded-display/",
      "text": "Key takeaways:\n- The iPhone 17 could feature a redesigned camera bump, though it may not be as drastic a difference as the Pro models.\n- A higher refresh rate could be coming to the full lineup, potentially enabling the baseline iPhone to have an always-on display.\n- Prices remain uncertain with tariffs, but they'll likely go up, given it's been years since Apple raised the price of the iPhone.\nThe anticipated reveal of Apple's newest iPhone is just days away, with the big unveiling slated for Sept. 9 at 10 a.m. PT/1 p.m. ET. Rumors have been swirling for months about what the upcoming device, likely called the iPhone 17, could look like, from a redesigned camera module to fresh colors and a higher refresh rate.\nApple has yet to confirm anything related to its expected phone lineup, which is likely to include the iPhone 17 Pro models and a thinner iPhone 17 Air. Be sure to follow CNET's coverage for all the live updates on Sept. 9.\nPerhaps the biggest looming question is whether iPhones could get pricier, especially with tariffs. President Donald Trump has said Apple will have to pay a 25% tariff on iPhones made outside the US. This would almost certainly lead to a price hike for consumers. We'll have to wait to see how Apple responds and if shoppers really do end up shouldering that extra cost. But even without tariffs, the iPhone may be due for a markup, as it's been years since Apple raised prices on its handsets.\nHere's everything analysts and leakers predict about the baseline iPhone 17.\nSee also: Thinking About Buying a New iPhone? Here's Why You Should Wait\nCamera bump redesign\nIt's not an iPhone release without a camera upgrade, and there have been plenty of rumors about what the camera module could look like on Apple's upcoming phones. As early as January, a leaked image from Majin Bu on X suggested the phone could feature a pill-shaped camera bar, essentially resembling what you'd find on Google's Pixel 9 phone. In February, Bu followed up with CAD renders of what's said to be the iPhone 17 lineup, featuring horizontal camera bars, as well as larger rectangular bars on the iPhone 17 Pro models.\nIn April, Bloomberg reported the \"iPhone 17 Pro will look a lot more like the 16 Pro than anticipated,\" adding, \"From the front, the 17 Pro will appear quite similar to the 16 Pro. It's the back camera that will look meaningfully different.\" The latest rumors suggest the iPhone 17 Pro's three-lens camera arrangement will be maintained but will sit on a new panel that stretches across the phone's width and is the same color as the rest of the phone.\nLater in April, Bu again posted an image of the purported iPhone 17 lineup, showing those wider camera bars with the stacked lenses still configured to the left.\nA more recent post from August supposedly shows the full lineup, with those redesigned camera bars:\nNot until next year, for the 20th anniversary of the iPhone, will Apple be \"preparing a major shake-up\" for the phone's design, Bloomberg says. That includes a (long-rumored) foldable version and a \"bold new Pro model that makes more extensive use of glass.\"\nAnother camera-related rumor is that the selfie camera on all iPhone 17 models will be upgraded to 24 megapixels, according to analyst Jeff Pu. That's a decent bump from the current 12-megapixel front-facing camera on the iPhone 16 lineup, although it's important to remember that more megapixels don't automatically mean better photos. Still, given how much people increasingly rely on their front cameras to snap selfies and record videos for TikTok and Instagram, this surely will be a welcome advancement.\niPhone 17 display upgrade\nThe iPhone 17 could have a slightly larger 6.3-inch display, instead of the 6.1-inch one on the iPhone 16, tipster Digital Chat Station said in June. That means it could be the same size as the iPhone 16 Pro, as well as the rumored iPhone 17 Pro, 9to5Mac reported.\nRumor has it that all models of the iPhone 17 will feature a 120Hz display, bumping the non-Pro models up from their current 60Hz refresh rate. That could be a welcome change, as the discrepancy between the Pro and non-Pro refresh rate is surprising; when Apple debuted the iPhone 16 and 16 Plus with a 60Hz display, there was a bit of an outcry from folks who expected more in 2024. This rumored update could remedy that -- and possibly bring the always-on display to the baseline model.\nThere's been a lot of back-and-forth about whether the latest iPhones will have a scratch-resistant, anti-reflective display. A July report from MacRumors suggests that feature will in fact be arriving on the iPhone 17 Pro and Pro Max, just not the baseline iPhone 17 or the Air. This would make the Pro models the first iPhones with an anti-reflective screen, giving them a feature that CNET's Patrick Holland deemed one of the best attributes of the Samsung Galaxy S25 Ultra.\nThere also have been contradictory reports on whether the Dynamic Island on the iPhone 17 lineup will look any different. In May, Pu said all iPhone 17 models will use a new metalens technology for the proximity sensor, which could allow Apple to reduce the size of the Face ID sensor and the Dynamic Island, according to 9to5Mac. Analyst Ming-Chi Kuo, on the other hand, said in January that the Dynamic Island would remain \"largely unchanged\" in the iPhone 17 lineup compared to the iPhone 16. We'll have to see what ends up being true.\nRumors on what frames the iPhone 17 lineup will feature have gone back and forth. In February, Pu suggested the iPhone 17, iPhone 17 Pro and iPhone 17 Pro Max will all have aluminum frames. He noted that the iPhone 17 Air could be the outlier with a titanium frame.\nNew chipset\nIn May, Pu noted the iPhone 17 would have the same A18 chip used in the iPhone 16, while the iPhone 17 Air could have an A19 chip and the Pro models would feature an A19 Pro chip.\nBut a conflicting rumor from leaker Fixed Focus Digital on Weibo suggests the baseline iPhone 17 will have an A19 chip as well. (The leaker also suggest the iPhone 17 Air could have the more advanced A19 Pro chip). Ice Universe also said the iPhone 17 will have an A19 chip, 9to5Mac reported in July.\nIt's possible the phones could also include the Apple-developed 5G modem, called the C1 chip, which debuted on the iPhone 16E.\nIn February, Kuo noted Apple will swap out Broadcom's Wi-Fi chips for in-house chips across the iPhone 17 lineup, stating this would \"enhance connectivity across Apple devices.\" It's not yet clear what exactly this would mean, but it would be interesting if Apple's C1 chip was also accompanied by its own Wi-Fi chip.\niPhone 17 battery\nSo far, rumors suggest only the pricer iPhone 17 Pro Max could get a bigger battery, according to Ice Universe. The leaker says the top-of-the-line phone could go from 8.25mm-thick on the iPhone 16 Pro Max to 8.725mm on the iPhone 17 Pro Max as a result. In addition, leaker Instant Digital suggests the high-end phone could have about a 5,000 mAh battery, a notable increase over the 4,685 mAh on the iPhone 16 Pro Max, according to third-party tests.\nBut that doesn't mean the baseline version won't get any boost. Even if battery capacity stays the same (which it may not), the AI-powered Adaptive Power feature arriving with iOS 26 can help extend battery life. The feature automatically adjusts your iPhone's performance based on how you're using it at the moment, according to Apple. This could especially be helpful with the slimmer iPhone 17 Air, which will likely have a thinner battery.\niOS 26 brings a fresh look\nApple has revamped its mobile operating system with iOS 26 (not iOS 19), which is named after the last two digits of the upcoming year. And with iPadOS, MacOS, WatchOS, TVOS and VisionOS following the same naming convention, the move is designed to bring more uniformity -- naming-wise and appearance-wise -- across the operating systems.\nThe new Liquid Glass interface brings a more transparent, lens-like look to the iPhone and other Apple devices. With iOS 26, the Camera app also adopts a more minimalistic design and Photos once again makes it easier to find your albums by adding separate tabs for your Library and Collections, instead of forcing you to scroll through a single cluttered screen. Updates to Messages include being able to add backgrounds to chat windows and create polls in group chats, and a new screening tool can better detect spam texts and move messages from unknown senders to a dedicated folder. You can read more about iOS 26 features here.\nIn April, tipster Digital Chat Station noted that given the use of Apple Intelligence and AI on a \"large scale,\" the iPhone 17 lineup will come with 12GB of RAM, instead of the current 8GB. Kuo noted the iPhone 17 Air and Pro models would sport that increased 12GB of RAM, but that Apple was still deciding whether to equip the baseline model with 8GB or 12GB of RAM. In May, Pu noted the baseline would remain at 8GB.\nPrice and release date\nWe expect the iPhone 17 to be available for preorders on Friday, Sept. 12, in line with Apple's previous release schedules, and it'll likely ship a week later.\nPrice is a big unknown. Jefferies analyst Edison Lee has said the iPhone 17 Air, 17 Pro and 17 Pro Max will get a $50 price increase to offset tariffs and the higher cost of components, but didn't mention the baseline iPhone 17. If that's true, the starting prices for the full lineup could be:\n- iPhone 17: $829\n- iPhone 17 Air: $979\n- iPhone 17 Pro: $1,049\n- iPhone 17 Pro Max: $1,249\nRegardless of higher component costs or tariffs, the iPhone is overdue for a price increase, because the last price hike was five years ago.\nThe latest rumors suggest the iPhone 17 could be available in black, blue, silver, purple and green.\nIn late July, Bu posted a photo on X of the predicted color lineup across the iPhone 17 series:\nWe'll continue to update this piece as more rumors surface, so be sure to follow along."
    },
    {
      "url": "https://machinelearning.apple.com/research/hey-siri?",
      "text": "Hey Siri: An On-device DNN-powered Voice Trigger for Apple\u2019s Personal Assistant\nAuthorsSiri Team\nAuthorsSiri Team\nThe \"Hey Siri\" feature allows users to invoke Siri hands-free. A very small speech recognizer runs all the time and listens for just those two words. When it detects \"Hey Siri\", the rest of Siri parses the following speech as a command or query. The \"Hey Siri\" detector uses a Deep Neural Network (DNN) to convert the acoustic pattern of your voice at each instant into a probability distribution over speech sounds. It then uses a temporal integration process to compute a confidence score that the phrase you uttered was \"Hey Siri\". If the score is high enough, Siri wakes up. This article takes a look at the underlying technology. It is aimed primarily at readers who know something of machine learning but less about speech recognition.\nTo get Siri\u2019s help, say \"Hey Siri\". No need to press a button as \"Hey Siri\" makes Siri hands-free. It seems simple, but quite a lot goes on behind the scenes to wake up Siri quickly and efficiently. Hardware, software, and Internet services work seamlessly together to provide a great experience.\nBeing able to use Siri without pressing buttons is particularly useful when hands are busy, such as when cooking or driving, or when using the Apple Watch. As Figure 1 shows, the whole system has several parts. Most of the implementation of Siri is \"in the Cloud\", including the main automatic speech recognition, the natural language interpretation and the various information services. There are also servers that can provide updates to the acoustic models used by the detector. This article concentrates on the part that runs on your local device, such as an iPhone or Apple Watch. In particular, it focusses on the detector: a specialized speech recognizer which is always listening just for its wake-up phrase (on a recent iPhone with the \"Hey Siri\" feature enabled).\nThe microphone in an iPhone or Apple Watch turns your voice into a stream of instantaneous waveform samples, at a rate of 16000 per second. A spectrum analysis stage converts the waveform sample stream to a sequence of frames, each describing the sound spectrum of approximately 0.01 sec. About twenty of these frames at a time (0.2 sec of audio) are fed to the acoustic model, a Deep Neural Network (DNN) which converts each of these acoustic patterns into a probability distribution over a set of speech sound classes: those used in the \"Hey Siri\" phrase, plus silence and other speech, for a total of about 20 sound classes. See Figure 2.\nThe DNN consists mostly of matrix multiplications and logistic nonlinearities. Each \"hidden\" layer is an intermediate representation discovered by the DNN during its training to convert the filter bank inputs to sound classes. The final nonlinearity is essentially a Softmax function (a.k.a. a general logistic or normalized exponential), but since we want log probabilities the actual math is somewhat simpler.\nWe choose the number of units in each hidden layer of the DNN to fit the computational resources available when the \"Hey Siri\" detector runs. Networks we use typically have five hidden layers, all the same size: 32, 128, or 192 units depending on the memory and power constraints. On iPhone we use two networks\u2014one for initial detection and another as a secondary checker. The initial detector uses fewer units than the secondary checker.\nThe output of the acoustic model provides a distribution of scores over phonetic classes for every frame. A phonetic class is typically something like \"the first part of an /s/ preceded by a high front vowel and followed by a front vowel.\"\nWe want to detect \"Hey Siri\" if the outputs of the acoustic model are high in the right sequence for the target phrase. To produce a single score for each frame we accumulate those local values in a valid sequence over time. This is indicated in the final (top) layer of Figure 2 as a recurrent network with connections to the same unit and the next in sequence. Inside each unit there is a maximum operation and an add:\nwhere\nBoth si and mi are based on analysis of durations of segments with the relevant labels in the training data. (This procedure is an application of dynamic programming, and can be derived based on ideas about Hidden Markov Models\u2014HMMs.)\nEach accumulated score Fi,t is associated with a labelling of previous frames with states, as given by the sequence of decisions by the maximum operation. The final score at each frame is Fi,t, where the last state of the phrase is state I and there are N frames in the sequence of frames leading to that score. (N could be found by tracing back through the sequence of max decisions, but is actually done by propagating forwards the number of frames since the path entered the first state of the phrase.)\nAlmost all the computation in the \"Hey Siri\" detector is in the acoustic model. The temporal integration computation is relatively cheap, so we disregard it when assessing size or computational resources.\nYou may get a better idea of how the detector works by looking at Figure 4, which shows the acoustic signal at various stages, assuming that we are using the smallest DNN. At the very bottom is a spectrogram of the waveform from the microphone. In this case, someone is saying \"Hey Siri what \u2026\" The brighter parts are the loudest parts of the phrase. The Hey Siri pattern is between the vertical blue lines.\nThe second horizontal strip up from the bottom shows the result of analyzing the same waveform with a mel filter bank, which gives weight to frequencies based on perceptual measurements. This conversion also smooths out the detail that is visible in the spectrogram and due to the fine-structure of the excitation of the vocal tract: either random, as in the /s/, or periodic, seen here as vertical striations.\nThe alternating green and blue horizontal strips labelled H1 to H5 show the numerical values (activations) of the units in each of the five hidden layers. The 32 hidden units in each layer have been arranged for this figure so as to put units with similar outputs together.\nThe next strip up (with the yellow diagonal) shows the output of the acoustic model. At each frame there is one output for each position in the phrase, plus others for silence and other speech sounds. The final score, shown at the top, is obtained by adding up the local scores along the bright diagonal according to Equation 1. Note that the score rises to a peak just after the whole phrase enters the system.\nWe compare the score with a threshold to decide whether to activate Siri. In fact the threshold is not a fixed value. We built in some flexibility to make it easier to activate Siri in difficult conditions while not significantly increasing the number of false activations. There is a primary, or normal threshold, and a lower threshold that does not normally trigger Siri. If the score exceeds the lower threshold but not the upper threshold, then it may be that we missed a genuine \"Hey Siri\" event. When the score is in this range, the system enters a more sensitive state for a few seconds, so that if the user repeats the phrase, even without making more effort, then Siri triggers. This second-chance mechanism improves the usability of the system significantly, without increasing the false alarm rate too much because it is only in this extra-sensitive state for a short time. (We discuss testing and tuning for accuracy later.)\nThe \"Hey Siri\" detector not only has to be accurate, but it needs to be fast and not have a significant effect on battery life. We also need to minimize memory use and processor demand\u2014particularly peak processor demand.\nTo avoid running the main processor all day just to listen for the trigger phrase, the iPhone\u2019s Always On Processor (AOP) (a small, low-power auxiliary processor, that is, the embedded Motion Coprocessor) has access to the microphone signal (on 6S and later). We use a small proportion of the AOP\u2019s limited processing power to run a detector with a small version of the acoustic model (DNN). When the score exceeds a threshold the motion coprocessor wakes up the main processor, which analyzes the signal using a larger DNN. In the first versions with AOP support, the first detector used a DNN with 5 layers of 32 hidden units and the second detector had 5 layers of 192 hidden units.\nApple Watch presents some special challenges because of the much smaller battery. Apple Watch uses a single-pass \"Hey Siri\" detector with an acoustic model intermediate in size between those used for the first and second passes on other iOS devices. The \"Hey Siri\" detector runs only when the watch motion coprocessor detects a wrist raise gesture, which turns the screen on. At that point there is a lot for WatchOS to do\u2014power up, prepare the screen, etc.\u2014so the system allocates \"Hey Siri\" only a small proportion (~5%) of the rather limited compute budget. It is a challenge to start audio capture in time to catch the start of the trigger phrase, so we make allowances for possible truncation in the way that we initialize the detector.\nWe designed the always-on \"Hey Siri\" detector to respond whenever anyone in the vicinity says the trigger phrase. To reduce the annoyance of false triggers, we invite the user to go through a short enrollment session. During enrollment, the user says five phrases that each begin with \"Hey Siri.\" We save these examples on the device.\nWe compare any possible new \"Hey Siri\" utterance with the stored examples as follows. The (second-pass) detector produces timing information that is used to convert the acoustic pattern into a fixed-length vector, by taking the average over the frames aligned to each state. A separate, specially trained DNN transforms this vector into a \"speaker space\" where, by design, patterns from the same speaker tend to be close, whereas patterns from different speakers tend to be further apart. We compare the distances to the reference patterns created during enrollment with another threshold to decide whether the sound that triggered the detector is likely to be \"Hey Siri\" spoken by the enrolled user.\nThis process not only reduces the probability that \"Hey Siri\" spoken by another person will trigger the iPhone, but also reduces the rate at which other, similar-sounding phrases trigger Siri.\nIf the various stages on the iPhone pass it on, the waveform arrives at the Siri server. If the main speech recognizer hears it as something other than \"Hey Siri\" (for example \"Hey Seriously\") then the server sends a cancellation signal to the phone to put it back to sleep, as indicated in Fig 1. On some systems we run a cut-down version of the main recognizer on the device to provide an extra check earlier.\nThe DNN acoustic model is at the heart of the \"Hey Siri\" detector. So let\u2019s take a look at how we trained it. Well before there was a Hey Siri feature, a small proportion of users would say \"Hey Siri\" at the start of a request, having started by pressing the button. We used such \"Hey Siri\" utterances for the initial training set for the US English detector model. We also included general speech examples, as used for training the main speech recognizer. In both cases, we used automatic transcription on the training phrases. Siri team members checked a subset of the transcriptions for accuracy.\nWe created a language-specific phonetic specification of the \"Hey Siri\" phrase. In US English, we had two variants, with different first vowels in \"Siri\"\u2014one as in \"serious\" and the other as in \"Syria.\" We also tried to cope with a short break between the two words, especially as the phrase is often written with a comma: \"Hey, Siri.\" Each phonetic symbol results in three speech sound classes (beginning, middle and end) each of which has its own output from the acoustic model.\nWe used a corpus of speech to train the DNN for which the main Siri recognizer provided a sound class label for each frame. There are thousands of sound classes used by the main recognizer, but only about twenty are needed to account for the target phrase (including an initial silence), and one large class class for everything else. The training process attempts to produce DNN outputs approaching 1 for frames that are labelled with the relevant states and phones, based only on the local sound pattern. The training process adjusts the weights using standard back-propagation and stochastic gradient descent. We have used a variety of neural network training software toolkits, including Theano, Tensorflow, and Kaldi.\nThis training process produces estimates of the probabilities of the phones and states given the local acoustic observations, but those estimates include the frequencies of the phones in the training set (the priors), which may be very uneven, and have little to do with the circumstances in which the detector will be used, so we compensate for the priors before the acoustic model outputs are used.\nTraining one model takes about a day, and there are usually a few models in training at any one time. We generally train three versions: a small model for the first pass on the motion coprocessor, a larger-size model for the second pass, and a medium-size model for Apple Watch.\n\"Hey Siri\" works in all languages that Siri supports, but \"Hey Siri\" isn\u2019t necessarily the phrase that starts Siri listening. For instance, French-speaking users need to say \"Dis Siri\" while Korean-speaking users say \"Siri \uc57c\" (Sounds like \"Siri Ya.\") In Russian it is \"\u043f\u0440\u0438\u0432\u0435\u0442 Siri \" (Sounds like \"Privet Siri\"), and in Thai \"\u0e2b\u0e27\u0e31\u0e14\u0e14\u0e35 Siri\". (Sounds like \"Wadi Siri\".)\nAn ideal detector would fire whenever the user says \"Hey Siri,\" and not fire at other times. We describe the accuracy of the detector in terms of two kinds of error: firing at the wrong time, and failing to fire at the right time. The false-accept rate (FAR or false-alarm rate), is the number of false activations per hour (or mean hours between activations) and the false-reject rate (FRR) is the proportion of attempted activations that fail. (Note that the units we use to measure FAR are not the same as those we use for FRR. Even the dimensions are different. So there is no notion of an equal error rate.)\nFor a given model we can change the balance between the two kinds of error by changing the activation threshold. Figure 6 shows examples of this trade-off, for two sizes of early-development models. Changing the threshold moves along the curve.\nDuring development we try to estimate the accuracy of the system by using a large test set, which is quite expensive to collect and prepare, but essential. There is \"positive\" data and \"negative\" data. The \"positive\" data does contain the target phrase. You might think that we could use utterances picked up by the \"Hey Siri\" system, but the system doesn\u2019t capture the attempts that failed to trigger, and we want to improve the system to include as many of such failed attempts as possible.\nAt first we used the utterances of \"Hey Siri\" that some users said as they pressed the Home button, but these users are not attempting to catch Siri\u2019s attention, (the button does that) and the microphone is bound to be within arm\u2019s reach, whereas we also want \"Hey Siri\" to work across a room. We made recordings specially in various conditions, such as in the kitchen (both close and far), car, bedroom, and restaurant, by native speakers of each language.\nWe use the \"negative\" data to test for false activations (and false wakes). The data represent thousands of hours of recordings, from various sources, including podcasts and non-\"Hey Siri\" inputs to Siri in many languages, to represent both background sounds (especially speech) and the kinds of phrases that a user might say to another person. We need such a lot of data because we are trying to estimate false-alarm rates as low as one per week. (If there are any occurrences of the target phrase in the negative data we label them as such, so that we do not count responses to them as errors.)\nTuning is largely a matter of deciding what thresholds to use. In Figure 6, the two dots on the lower trade-off curve for the larger model show possible normal and second-chance thresholds. The operating point for the smaller (first-pass) model would be is at the right-hand side. These curves are just for the two stages of the detector, and do not include the personalized stage or subsequent checks.\nWhile we are confident that models that appear to perform better on the test set probably are really better, it is quite difficult to convert offline test results into useful predictions of the experience of users. So in addition to the offline measurements described previously, we estimate false-alarm rates (when Siri turns on without the user saying \"Hey Siri\") and imposter-accept rates (when Siri turns on when someone other than the user who trained the detector says \"Hey Siri\") weekly by sampling from production data, on the latest iOS devices and Apple Watch. This does not give us rejection rates (when the system fails to respond to a valid \"Hey Siri\") but we can estimate rejection rates from the proportion of activations just above the threshold that are valid, and a sampling of just-below threshold events on devices carried by development staff.\nWe continually evaluate and improve \"Hey Siri,\" and the model that powers it, by training and testing using variations of the approach described here. We train in many different languages and test under a wide range of conditions.\nNext time you say \"Hey Siri\" you may think of all that goes on to make responding to that phrase happen, but we hope that it \"just works!\"\nA growing number of consumer devices, including smart speakers, headphones, and watches, use speech as the primary means of user input. As a result, voice trigger detection systems\u2014a mechanism that uses voice recognition technology to control access to a particular device or feature\u2014have become an important component of the user interaction pipeline as they signal the start of an interaction between the user and a device. Since these systems are deployed entirely on-device, several considerations inform their design, like privacy, latency, accuracy, and power consumption.\nApple introduced the \"Hey Siri\" feature with the iPhone 6 (iOS 8). This feature allows users to invoke Siri without having to press the home button. When a user says, \"Hey Siri, how is the weather today?\" the phone wakes up upon hearing \"Hey Siri\" and processes the rest of the utterance as a Siri request. The feature's ability to listen continuously for the \"Hey Siri\" trigger phrase lets users access Siri in situations where their hands might be otherwise occupied, such as while driving or cooking, as well as in situations when their respective devices are not within arm's reach. Imagine a scenario where a user is asking his or her iPhone 6 on the kitchen counter to set a timer while putting a turkey into the oven."
    },
    {
      "url": "https://www.ftc.gov/news-events/news/press-releases/2022/08/ftc-sues-kochava-selling-data-tracks-people-reproductive-health-clinics-places-worship-other",
      "text": "The Federal Trade Commission filed a lawsuit against data broker Kochava Inc. for selling geolocation data from hundreds of millions of mobile devices that can be used to trace the movements of individuals to and from sensitive locations. Kochava\u2019s data can reveal people\u2019s visits to reproductive health clinics, places of worship, homeless and domestic violence shelters, and addiction recovery facilities. The FTC alleges that by selling data tracking people, Kochava is enabling others to identify individuals and exposing them to threats of stigma, stalking, discrimination, job loss, and even physical violence. The FTC\u2019s lawsuit seeks to halt Kochava\u2019s sale of sensitive geolocation data and require the company to delete the sensitive geolocation information it has collected.\n\u201cWhere consumers seek out health care, receive counseling, or celebrate their faith is private information that shouldn\u2019t be sold to the highest bidder,\u201d said Samuel Levine, Director of the FTC\u2019s Bureau of Consumer Protection. \u201cThe FTC is taking Kochava to court to protect people\u2019s privacy and halt the sale of their sensitive geolocation information.\u201d\nIdaho-based Kochava purchases vast troves of location information derived from hundreds of millions of mobile devices. The information is packaged into customized data feeds that match unique mobile device identification numbers with timestamped latitude and longitude locations. According to Kochava, these data feeds can be used to assist clients in advertising and analyzing foot traffic at their stores and other locations. People are often unaware that their location data is being purchased and shared by Kochava and have no control over its sale or use.\nIn a complaint filed against Kochava, the FTC alleges that the company\u2019s customized data feeds allow purchasers to identify and track specific mobile device users. For example, the location of a mobile device at night is likely the user\u2019s home address and could be combined with property records to uncover their identity. In fact, the data broker has touted identifying households as one of the possible uses of its data in some marketing materials.\nAccording to the FTC\u2019s complaint, Kochava\u2019s sale of geolocation data puts consumers at significant risk. The company\u2019s data allows purchasers to track people at sensitive locations that could reveal information about their personal health decisions, religious beliefs, and steps they are taking to protect themselves from abusers. The release of this data could expose them to stigma, discrimination, physical violence, emotional distress, and other harms.\nThe FTC alleges that Kochava fails to adequately protect its data from public exposure. Until at least June 2022, Kochava allowed anyone with little effort to obtain a large sample of sensitive data and use it without restriction. The data sample the FTC examined included precise, timestamped location data collected from more than 61 million unique mobile devices in the previous week. Using Kochava\u2019s publicly available data sample, the FTC complaint details how it is possible to identify and track people at sensitive locations such as:\n- Reproductive health clinics: The data could be used to identify people who have visited a reproductive health clinic and therefore expose their private medical decisions. Using the data sample, it is possible to track a mobile device from a reproductive health clinic to a single-family residence to other places routinely visited. The data may also be used to identify medical professionals who perform, or assist in the performance, of reproductive health services.\n- Places of worship: The data could be used to track consumers to places of worship, and thus reveal the religious beliefs and practices of consumers. The data sample identifies mobile devices that were located at Jewish, Christian, Islamic, and other religious denominations\u2019 places of worship.\n- Homeless and domestic violence shelters: The data could be used to track consumers who visited a homeless shelter, domestic violence shelter, or other facilities directed to at-risk populations. This information could reveal the location of people who are escaping domestic violence or other crimes. The data sample identifies a mobile device that appears to have spent the night at a temporary shelter whose mission is to provide residence for at-risk, pregnant young women or new mothers. In addition, because Kochava\u2019s data allows its customers to track people over time, the data could be used to identify their past conditions, such as homelessness.\n- Addiction recovery centers: The data could be used to track consumers who have visited addiction recovery centers. The data could show how long consumers stayed at the center and whether a consumer potentially relapses and returns to a recovery center.\nProtecting sensitive consumer data, including geolocation and health data, is a top priority for the FTC. This month, the FTC announced that it is exploring rules to crack down on harmful commercial surveillance practices that collect, analyze, and profit from information about people. In July, the FTC warned businesses that the agency intends to enforce the law against the illegal use and sharing of highly sensitive consumer data, including sensitive health data. Last year, the FTC issued a policy statement warning health apps and connected devices that collect or use consumers\u2019 health information that they must notify consumers and others when that data is breached as required by the Health Breach Notification Rule. In 2021, the agency also took action against the fertility app Flo Health for sharing sensitive health data with third parties.\nThe Commission vote authorizing the staff to file the complaint against Kochava was 4-1. Commissioner Noah Joshua Phillips voted no. The complaint was filed in the U.S. District Court for the District of Idaho.\nNOTE: The Commission files a complaint when it has \u201creason to believe\u201d that the named defendants are violating or are about to violate the law and it appears to the Commission that a proceeding is in the public interest. The case will be decided by the court.\nThe Federal Trade Commission works to promote competition and protect and educate consumers. The FTC will never demand money, make threats, tell you to transfer money, or promise you a prize. Learn more about consumer topics at consumer.ftc.gov, or report fraud, scams, and bad business practices at ReportFraud.ftc.gov. Follow the FTC on social media, read consumer alerts and the business blog, and sign up to get the latest FTC news and alerts."
    },
    {
      "url": "https://www.businessinsider.com/us-military-location-data-muslim-prayer-app-xmode-babel-street-2020-11",
      "text": "- The US military purchases location data mined from seemingly ordinary smartphone apps, public procurement records show.\n- One source of location data bought by the military is Muslim Pro, a prayer app with more than 98 million downloads worldwide, according to a new report from Vice's Motherboard.\n- Apps like Muslim Pro \u2014 as well as other apps for exercise, weather tracking, and browsing Craigslist \u2014 sell people's location data to third-party brokers, which in turn sell the data to clients like the US military and military contractors.\n- In past years, the US has used location data harvested from smartphones to plan and carry out drone strikes.\n- Visit Business Insider's homepage for more stories.\nMuslim Pro, a prayer app with over 98 million downloads, reminds users about daily prayers and provides readings from the Quran. The company calls it \"The most popular Muslim app.\"\nIt also tracks users' location and sells that location data to brokers \u2014 and the US military is one of the buyers, according to a new report from Vice's Motherboard.\nMuslim Pro is one of hundreds of smartphone apps that make money by selling users' location data to third-party brokers. (The US military bought Muslim Pro's data through one of those third-party data brokers, according to Motherboard.)\nThe practice has raised the ire of privacy advocates, but location-data firms and their partners insist that people's movements are anonymized and not directly tied to their identities. Some studies have shown, however, that it's easy to de-anonymize the location data and tie it back to individual people.\nThe new report is the latest illustration of how government agencies can go to private data brokers to collect granular information on individuals' movements, including US citizens. Some lawmakers have called for the practice to be more heavily regulated after it was revealed that the Department of Homeland Security bought location data to track down people suspected of immigrating to the US illegally.\nMuslim Pro sells location data to a third-party broker called X-Mode, according to Motherboard's report. X-Mode has sold location data to defense contractors, according to its website, which in turn provide the data to the US Department of Defense.\nIn a statement to Business Insider, Muslim Pro head of community Zahariah Jupary said that in the wake of the Motherboard story the app is \"immediately terminating\" its contract with X-Mode and other data partners, adding that the location data provided to data partners was anonymized.\n\"Since we were made aware of the situation, we have launched an internal investigation and are reviewing our data governance policy to confirm that all user data was handled in line with all existing requirements,\" Jupary said. \"We will continue to take all necessary measures to ensure that our users practice their faith with peace of mind, which remains Muslim Pro's sole mission since its creation.\"\nA representative for X-Mode did not immediately respond to Business Insider's requests for comment.\nX-Mode told Motherboard that its business with military contractors was \"primarily focused on three use cases: counter-terrorism, cybersecurity and predicting future COVID-19 hotspots.\" X-Mode has previously published anonymized location data from people's smartphones to show people's movements to and from areas where COVID-19 is spiking.\nIn other instances, the US military has bought location data directly from brokers rather than going through defense contractors. According to public procurement records, the US Special Operations Command spent $90,656 in April to access location data provided by the firm Babel Street, which mines data from smartphone apps.\nNavy Cmdr. Tim Hawkins, a US Special Operations Command spokesman, said in a statement to Business Insider that the command bought the data from Babel Street \"to support Special Operations Forces mission requirements overseas.\"\n\"We strictly adhere to established procedures and policies for protecting the privacy, civil liberties, constitutional and legal rights of American citizens,\" Hawkins said.\nA representative for Babel Street did not immediately respond to a request for comment. Babel Street sells a product called Locate X that allows people to select an area on a map and shows the movements of devices inside that area, according to Motherboard. Clients can perform as many search queries as they want after paying to access the data, according to a Babel Street marketing document.\nThe purchases are noteworthy because the Pentagon has used smartphone location data to plan and execute military operations. The National Security Agency used a different type of location data gleaned from phones' SIM cards to carry out drone strikes against suspected Taliban members, The Intercept reported in 2014. It remains unclear whether location data purchased through third-party brokers has directly informed specific US military operations."
    }
  ],
  "argos_summary": "The article debunks the myth that iPhones are secretly listening to users, explaining that the seemingly relevant ads are the result of sophisticated data collection and ad\u2011targeting algorithms rather than covert microphone use. It details how platforms, advertisers, identity providers, and data brokers build profiles from in\u2011app behavior, location, and pre\u2011existing data to serve highly relevant ads. The piece also highlights legal and technical safeguards that prevent continuous audio recording, and cites studies and industry statements confirming the absence of hidden listening features. Overall, it reassures readers that the uncanny ad timing is due to data-driven prediction, not eavesdropping.",
  "argos_id": "IQX4TDHMG"
}