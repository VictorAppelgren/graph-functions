{
  "url": "https://www.techradar.com/ai-platforms-assistants/chatgpt/4-things-we-learned-from-openais-gpt-5-reddit-ama",
  "authorsByline": "Eric Hal Schwartz",
  "articleId": "fad389c8252d47c2b98e6b17a0c8a4c4",
  "source": {
    "domain": "techradar.com",
    "paywall": false,
    "location": {
      "country": "in",
      "city": "New Delhi",
      "coordinates": {
        "lat": 28.6138954,
        "lon": 77.2090057
      }
    }
  },
  "imageUrl": "https://cdn.mos.cms.futurecdn.net/VUZRAsoDukugbXxmPNv4SU-1280-80.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-11T22:00:00+00:00",
  "addDate": "2025-08-11T22:35:32.507820+00:00",
  "refreshDate": "2025-08-11T22:35:32.507822+00:00",
  "score": 1.0,
  "title": "4 things we learned from OpenAI\u2019s GPT-5 Reddit AMA",
  "description": "Turns out everyone wanted GPT-4o back",
  "content": "OpenAI CEO Sam Altman and several other researchers and engineers came to Reddit the day after debuting the powerful new GPT-5 AI model for the time-honored tradition of an Ask Me Anything .\n\nThough the discussion ranged over all kinds of technical and product elements, there were a few topics that stood out as particularly important to posters based on the frequency and passion with which they were discussed. Here are a few of the most notable things we learned from the OpenAI AMA.\n\nThe biggest recurring theme in the AMA was a mournful wail from users who loved GPT-4o and felt personally attacked by its removal. That's not an exaggeration, as one user posted, \u201cBRING BACK 4o GPT-5 is wearing the skin of my dead friend.\u201dTo which Altman replied, \u201cwhat an\u2026evocative image. ok we hear you on 4o, working on something now.\u201d\n\nThis wasn\u2019t just one isolated request, either. Another post asked to keep both GPT-4o and GPT-4.1 alongside GPT-5, arguing that the older models had distinct personalities and creative rhythms. Altman admitted they were \u201clooking into this now.\u201d\n\nMost requests were a little more subdued, with one poster asking, \u201cWhy are we getting rid of the variants and 4o when we all have unique communication styles? Please bring them back!\u201d\n\nAltman\u2019s answer was brief but direct in conceding the point. He wrote, \u201cok, we hear you all on 4o; thanks for the time to give us the feedback (and the passion!). we are going to bring it back for plus users, and will watch usage to determine how long to support it.\"\n\nIt is interesting that so many heavy users seem to prefer the style of the older model, and prefer it to the objectively better newer ones.\n\nAnother big topic was ChatGPT's safety filter, both currently and before GPT-5 which many posted complaints about for being overzealous. One user described a scenario where they\u2019d been flagged for discussing historical topics, with a response about Gauguin getting flagged and deleted because the artist was a \"sex pest,\" and the user's own clarification question itself getting flagged.\n\nAltman\u2019s answer was a mixture of agreement and reality check. \u201cYeah, we will continue to improve this,\u201d he said. \u201cIt is a legit hard thing; the lines are often really quite blurry sometimes.\u201d He stressed that OpenAI wants to allow \u201cvery wide latitude\u201d but admitted that the boundary between unsafe and safe content is far from perfect, but that \"people should of course not get banned for learning.\"\n\nAnother questioner zeroed in on a gap in OpenAI\u2019s subscription model: \"Are you guys planning to add another plan for solo power users that are not pros? 20$ plan offers too little for some, and the $200 tier is overkill.\"\n\nAltman\u2019s answer was succinct, simply saying, \u201cYes we will do something here.\u201d No details, just a confirmation that the idea\u2019s on the table. That brevity leaves open possibilities from 'next week' to just saying 'the discussion starts now.' But the pricing gap is a big deal for power users who find themselves constrained by the Plus tier but can\u2019t justify enterprise pricing. If OpenAI does create an intermediate tier, it could reshape how dedicated individual users engage with the platform.\n\nAt the end of the AMA, Altman shared some new information about the current and future state of ChatGPT and GPT-5. He started by admitting to some issues with the release, writing that \"we expected some bumpiness as we roll out so many things at once. But it was a little more bumpy than we hoped for!\"\n\nThat bumpiness ended up making GPT-5 seem not as impressive as it should have until now.\n\n\"GPT-5 will seem smarter starting today,\" Altman wrote. \"Yesterday, we had a sev [severity, meaning system issue] and the autoswitcher was out of commission for a chunk of the day, and the result was GPT-5 seemed way dumber.\"\n\nHe also promised more access for ChatGPT Plus users, with double the rate limits, as well as the upcoming return of GPT-4o, at least for those same subscribers. The AMA did paint a clearer picture of what OpenAI is willing to change in response to public pressure.\n\nThe return of GPT-4o for Plus users at least acknowledges that raw capability isn\u2019t the only metric that matters. If users are this vocal about keeping an older model alive, future releases of GPT-5 and beyond may be designed with more deliberate flavors built in beyond just the personality types promised for GPT-5.\n\nYou might also like\n\u2022 OpenAI's first AI Agent is here, and Operator can make a dinner reservation and complete other tasks on the web for you\n\u2022 There\u2019s a new AI agent ready to browse the web and fill in forms without the need to touch your mouse\n\u2022 I tried this new AI agent that takes control of your mouse and keyboard to help get tasks done, and I can\u2019t believe how good it is",
  "medium": "Article",
  "links": [
    "https://www.techradar.com/ai-platforms-assistants/chatgpt/so-many-chatgpt-users-have-said-theyre-missing-the-older-gpt-4o-model-openai-is-going-to-bring-it-back",
    "https://www.techradar.com/ai-platforms-assistants/chatgpt/gpt-5-is-here-5-things-you-need-to-know-about-openais-most-useful-model-yet",
    "https://www.reddit.com/r/ChatGPT/comments/1mkae1l/gpt5_ama_with_openais_sam_altman_and_some_of_the/",
    "https://www.techradar.com/news/live/openai-chatgpt5-launch",
    "https://www.techradar.com/computing/artificial-intelligence/theres-a-new-ai-agent-ready-to-browse-the-web-and-fill-in-forms-without-the-need-to-touch-your-mouse",
    "https://www.techradar.com/computing/artificial-intelligence/openais-first-ai-agent-is-here-and-operator-can-make-a-dinner-reservation-and-complete-other-tasks-on-the-web-for-you",
    "https://www.techradar.com/computing/artificial-intelligence/i-tried-this-new-online-ai-agent-and-i-cant-believe-how-good-convergence-ais-proxy-1-0-is-at-completing-multiple-online-tasks-simultaneously"
  ],
  "labels": [
    {
      "name": "Non-news"
    },
    {
      "name": "Opinion"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "ChatGPT Plus users",
      "weight": 0.08549956
    },
    {
      "name": "Plus users",
      "weight": 0.08509736
    },
    {
      "name": "power users",
      "weight": 0.082491815
    },
    {
      "name": "GPT-5 AI",
      "weight": 0.08077475
    },
    {
      "name": "individual users",
      "weight": 0.079944395
    },
    {
      "name": "users",
      "weight": 0.07982536
    },
    {
      "name": "4o GPT-5",
      "weight": 0.07951666
    },
    {
      "name": "solo power users",
      "weight": 0.0795116
    },
    {
      "name": "plus users",
      "weight": 0.0793416
    },
    {
      "name": "OpenAI CEO Sam Altman",
      "weight": 0.07508898
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.94384765625
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.81396484375
    }
  ],
  "sentiment": {
    "positive": 0.09712043,
    "negative": 0.5905932,
    "neutral": 0.31228632
  },
  "summary": "OpenAI CEO Sam Altman and several researchers and engineers attended an Ask Me Anything Reddit AMA following the release of the GPT-5 AI model. The AMA, which included several questions about technical and product elements, saw a surge in demand from users who loved GPT4o and felt personally attacked by its removal. One user asked for the return of both GPT 4o and GPT 5, arguing that the older models had distinct personalities and creative rhythms. Another questioner also asked about a gap in OpenAI's subscription model for solo power users, suggesting that the 20$ plan for some was too little for some and the $200 tier was overkill. Altman responded to these queries with a brief but direct response. He also promised more access for ChatGPT Plus, double the rate limits, and the upcoming return of GPT5.",
  "shortSummary": "OpenAI\u2019s Reddit AMA discussed the GPT-5 AI model's launch, safety filters, subscription models, and future plans, among others.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "2c0ade7073f148bcbf1b212bea45017a",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.techradar.com/ai-platforms-assistants/chatgpt/so-many-chatgpt-users-have-said-theyre-missing-the-older-gpt-4o-model-openai-is-going-to-bring-it-back",
      "text": "So many ChatGPT users have said they're missing the older GPT-4o model, OpenAI is going to bring it back\nUsers aren't happy\n- GPT-4o is coming back for ChatGPT Plus users\n- There have been plenty of complaints about GPT-5\n- OpenAI is looking at ways to improve the new model\nWhen OpenAI rolled out its shiny new GPT-5 model for ChatGPT earlier this week, the plan was to have it replace all of the older models for both free and paying users \u2013 but now GPT-4o is being brought back in response to a significant number of user complaints.\n\"We for sure underestimated how much some of the things that people like in GPT-4o matter to them, even if GPT-5 performs better in most ways,\" OpenAI CEO Sam Altman posted on social media, after announcing GPT-4o would be sticking around.\nHowever, it's not clear just how long the GPT-4o reprieve will be for, and it's only going to remain available for those on the $20-per-month ChatGPT Plus plan. \"We will watch usage as we think about how long to offer legacy models for,\" Altman said.\nThere were other updates from Altman as well: GPT-5 rate limits are being doubled for ChatGPT Plus users, and some behind-the-scenes upgrades are making GPT-5 \"smarter\" too, as the latest model continues to roll out to everyone.\n'An overworked secretary'\nGPT-5 rollout updates:*We are going to double GPT-5 rate limits for ChatGPT Plus users as we finish rollout.*We will let Plus users choose to continue to use 4o. We will watch usage as we think about how long to offer legacy models for.*GPT-5 will seem smarter starting\u2026August 8, 2025\nAs we reported yesterday, the response to GPT-5 from a lot of users has been pretty brutal. It's been labeled \"horrible\", \"insufficient\", \"obnoxious\", \"atrocious\", like \"an overworked secretary\", and worse than GPT-4o \u2013 with tighter restrictions on how much it can be used.\nPeople aren't happy about GPT-5 either giving shorter responses than previous models, or throwing up multiple responses that the user then has to choose between. If you're using AI to try and save time, it's not ideal.\nAt least OpenAI is listening to its userbase, with the reintroduction of GPT-4o, though you may not see it immediately in the model picker if you've been upgraded to GPT-5. \"Users have very different opinions on the relative strength of GPT-4o vs GPT-5,\" admits Altman.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nThe OpenAI CEO also says his team are looking at more ways to provide different personalities and customizations within the same model for users. Watch this space for further tweaks to GPT-5 going forward.\nYou might also like\nDave is a freelance tech journalist who has been writing about gadgets, apps and the web for more than two decades. Based out of Stockport, England, on TechRadar you'll find him covering news, features and reviews, particularly for phones, tablets and wearables. Working to ensure our breaking news coverage is the best in the business over weekends, David also has bylines at Gizmodo, T3, PopSci and a few other places besides, as well as being many years editing the likes of PC Explorer and The Hardware Handbook.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    },
    {
      "url": "https://www.techradar.com/news/live/openai-chatgpt5-launch",
      "text": "OpenAI GPT-5 launch live \u2013 all the latest news as Sam Altman unveils the new model\nThe next generation of ChatGPT is here\nIt's the one we've all been waiting for \u2013 ChatGPT-5 was finally unveiled by OpenAI on August 7! Earlier in the week OpenAI CEO Sam Altman teased that \"something big\" was coming on Friday, but then today the OpenAI account on X.com tweeted: \"LIVE5TREAM THURSDAY 10AM PT\".\nNotice the use of a 5 instead of an \"S\" in the word \"LIVE5TREAM\"? That can mean only one thing: ChatGPT-5 is coming!\nWith a livestream that kicked off at 10AM PT, 1PM ET, and 6PM BST \u2013 and you can watch the replay below \u2013 TechRadar broke down all the news on GPT-5 as the team at OpenAI, including Sam Altman, unveiled its next-generation model.\nAhead, you can read our live reporting and get everything you need to know about ChatGPT-5. It's rolling out right now to all users, and unlike previous models, even the Free tier as well Pas lus and Pro subscribers are getting access to it. GPT-5 brings with it a lot of new features and enhanced levels of performance. OpenAI says it's more reliable, better at crafting nuanced responses, and that it haullincates less.\nIn many of the demos during the kick-off event, ChatGPT-5 showed off it's advanced coding capabilities and the transformed Voice mode that sounds a lot more natural.\nIf you're curious about the most impactful features that GPT-5 is set to bring with it, you'll want to read through our list of the 5 most impactful aspects of OpenAI's latest model. Here, we're taking a close look at the different flavors that GPT-5 comes in, as well as features like the transformation of Advanced Voice Mode to simply Voice Mode.\nGPT-5 is rolling out slowly\nIt's a bit of a waiting game for access to GPT-5 at this time. While OpenAI did announce that it's rolling out for all users \u2013 yes, that includes the free tier \u2013 it's a staggered one. The company posted on its site, \"We are gradually rolling out GPT-5 to ensure stability during launch. Some users may not yet see GPT-5 in their account as we increase availability in stages.\u201d\nSo rather than instability, longer response times, or crashes, OpenAI's taking a slow and steady approach here. While we're all keen to try out GPT-5 \u2013 I've been refreshing my own Plus account, it gives us time to talk about what the AI giant has announced.\nTechRadar's Editor-at-Large Lance Ulanoff shared this on the announcement of GPT-5:\n\"Is it weird that I am slightly underwhelmed by the GPT-5 reveal? I get that it\u2019s much smarter and can do agentic-level things with more or less a single prompt, but I had sort of hoped that we\u2019d get our first glimpse of true AGI.\nPerhaps, considering all Sam Altman\u2019s publicly declared safety concerns, he held something back. GPT-5 puts us on the path to AGI but also keeps it at arm's length.\nI'm also surprised at the bold embrace of health advice and guidance. The fine print makes it clear this is no doctor replacement, but still, it\u2019s a ballsy move and one that I wonder if they might regret (at least in the short term).\"\nLance makes a crucial point here \u2013 while Sam Altman did say it's an important step towards AGI, the rest of the keynote didn't necessarily provide clear details around. It was more of a set of demos, largely focused on the coding capabilities, and then several new features that daily users of ChatGPT will appreciate.\nWe'll have to see whatever day uses think of GPT-5 pitching itself for health advice and guidance, remember that it still is not a doctor replacement by any measure.\nAbout an hour and 15 minutes later, and OpenAI's unveil of GPT-5 \u2013 dubbed the OpenAI Summer Update \u2013 has come to a close. Interestingly enough, OpenAI's chief scientist closed out the event, thanking the team, and his last line was \"we'll get back to sailing.\"\nWhile we weren't invited out to sea with them, we're constantly refreshing our ChatGPT pages as we await the GPT-5 rollout to hit our accounts. And whether you're on the free tier, Plus, or Pro, you can expect to see GPT-5 today and many of its new features.\nWhat's new with GPT-5\nOpenAI's already covered a lot of ground, but let's run through what's new with GPT-5 quickly:\n- Better reliability and more accurate answer with fewer hallucinations\n- Improved writing skills for more precise results and the ability to switch based on context\n- GPT-5 is the 'strongest coding model'\n- It's OpenAI's best model for health-related questions\n- GPT-5 will deliver safe completions rather than refusing a prompt\n- It will ask follow-ups when needed to get more context for a better result\n- The model can better adapt to context in prompts and can understand tone\n- GPT-5 will handle all the heavy-lifting for deciding on the right model and will show its work\n- It can connect with your Google account for access to Gmail and Google Calendar (Pro users get this first)\n- Paid subscribers can customize the look of ChatGPT\n- A more natural-sounding voice mode\n- GPT-5 arrives for all subscribers, even the free tier, with varying levels of use\nOpenAI is moving through this livestream pretty quickly. Now, Greg Brockman, President of OpenAI, is on stage, and the focus is shifting back to developers and coding. He says that GPT-5 is the best model at agentic coding tasks.\nSam Altman is now back onstage to start the discussion around ChatGPT-5 and how it handles the Health prompt. We now have two ChatGPT users on stage, including one, Carolina, who was diagnosed with three forms of cancer in one week.\nAfter receiving an email confirming the diagnosis, this user took a screenshot and uploaded it to ChatGPT and got an understandable explanation. Altman says that Health questions are one of the most common use cases for ChatGPT as well. A takeaway from both of them is that ChatGPT can be used to help learn a bit more and 'regain some agency.'\nBoth of these users have used GPT-5 and note that it is a much faster, \"almost a little alarmingly at first.\" Another key impression, though, is that GPT-5 is more of a thought partner than just delivering an answer based on the prompt. They also put the biopsy results back in, and GPT-5 asked follow-ups to get a bit more detail and deliver a more nuanced response.\nOf course, ChatGPT or GPT-5 is not a medical doctor, and you should still see one for diagnosis and emergencies.\nOpenAI is also focused on improving safety and deception; in this case, GPT-5 will aim to maximize helpfulness within the allowed safety constraints. This will be in contrast to how previous models, like o3, might have refused on the grounds of safety before.\nGPT-5 could answer the same prompt, by explaining why it can't offer help and point you towards a third-party or even a manual. The demo shown off by OpenAI here is a prompt asking for how to work with 'pyrogen.'\nChatGPT will be able to connect with your Google account\nWe're now switching gears to ChatGPT's Memory function. Pro, Plus, and Team subscribers will be able to connect ChatGPT to a Google Account for calendar access. In fact, it can connect with Gmail and Google Calendar, allowing GPT-5 to pull in your schedule and get some more context.\nIt can even remind you to respond to an email that you've received, read, but haven't yet responded to. This will roll out first to Pro users next week, then Plus and Team at some point in the future.\nIf you've been wanting to change the color of your ChatGPT interface, OpenAI is making that possible \u2013 to a degree \u2013 for paid users. Even more impressive, though, is the ability to customize the personality of GPT-5 a bit for research use cases.\nVoice mode is getting an upgrade\nThere is a lot of focus on coding with GPT-5, but we've also seen improvements in writing thus far. The teams at OpenAI have also been focused on further improving Voice and video functionality.\nWith GPT-5, voice mode is coming to all users, and in this demo, OpenAI is showing that you can be specific with how you want an answer. In this case, they demonstrated ChatGPT Voice's ability to respond with just one word, summarizing Pride and Prejudice as 'relationships.'\nThe biggest improvment, though, is that it sounds a lot more natural than even the current version in the app.\nNow we're in the midst of another GPT-5 demo that's centered around its ability to write code, spanning over 200 lines in just a few minutes of this demo. It actually created a site, with many visual elements and even audio ones, to help one learn French with a partner.\nAnd like that, GPT-5 completed the prompt and coded the demo, which the OpenAI team is now testing during the live-stream. Pretty, pretty fast.\nFor the next demo, OpenAI is pitting GPT-4o and GPT-5 against each other in writing a eulogy for its previous models. Here's a look at what GPT-4o produced.\nGPT-5 on the other hand has more of an understanding of tone and nuances. It sounds a bit more like a person with emotions wrote it ... less dry.\nOur first demo of GPT-5\nWe're now getting our first demo of GPT-5, first with the model being asked to explain the Bernoulli effect, and it responded pretty quickly. The follow-up, though, is asking GPT-5 to create a visual, and OpenAI is explaining that it will take a bit longer to respond, and in that time also suggest the best course of action.\nYou can also ask GPT-5 to 'think harder' or 'more precisely' in the actual prompt. Even neater, you can see GPT-5's thought process while it's answering the prompt.\nGPT-5 will start rolling out to all users today\nHere's some good news \u2013 OpenAI is rolling out GPT-5 to all users, with that process beginning today, including the Free tier as well as Plus and Pro subscribers. It won't be a free-for-all with GPT-5 in the free tier, but you'll be able to use it until allotments are hit. Plus and Pro subscribers will expectedly get higher rate limits.\nA key area of focus with GPT-5 was improving reliability and being accurate with facts. OpenAI is also saying that it has specifically focused on reliability in health.\nNow, we're getting a closer look at GPT-5 from more team members at OpenAI. Here's the kicker, also, OpenAI says that GPT-5 will even be available for free users.\nAs for what we'll see during this livestream, we'll be getting plenty of demos but are starting first with evaluations. OpenAI has just announced that GPT-5 has set a new level on several benchmarks, including SWE-Bench \u2013 it's not the full story, but it's a good tell of the performance here.\nSam Altman announces GPT-5\nAnd here we go, OpenAI CEO Sam Altman is walking onto a stage, and that's certainly a different setting than previous livestreams.\nAltman is wasting no time, saying that they're ushering in GPT-5 and it's another important step to AGI. He believes that folks will enjoy using GPT-5 a lot more. Why? Well, the early sell here, as Altman puts it, is that chatting or talking with GPT-5 is like talking to an expert, and it can even write software on demand.\n2 minutes to go\nThe visuals have changed again, and we're now counting down from three minutes until the start. The music is also getting a bit more exciting with more sounds joining in.\nThe livestream has started\nOpenAI has officially kicked off the livestream with under 10 minutes to go until 1PM ET/ 6PM BST. Right now, we have some sonically soothing sounds over \"OpenAI Summer Update\" flashing with colors and then spinning in circles on the screen. No mention of GPT-5 though.\nWhile we wait for the livestream to kick off on OpenAI's YouTube channel \u2013 and in the video above \u2013 the description of the video does give us a bit more detail. We've already known, thanks to a post on X from Sam Altman, that this will be a longer livestream, and there will be many, many presenters.\nHere's what the description reads: \"Join Sam Altman, Greg Brockman, Sebastien Bubeck, Mark Chen, Yann Dubois, Brian Fioca, Adi Ganesh, Oliver Godement, Saachi Jain, Christina Kaplan, Tina Kim, Elaine Ya Le, Felipe Millon, Michelle Pokrass, Jakub Pachocki, Max Schwarzer, Rennie Song, Ruochen Wang as they introduce and demo GPT-5.\"\nFurther, if you had any doubt that we'd be seeing GPT-5 today, this confirms it will be unveiled and demoed.\nI just checked my ChatGPT Plus account one more time before this event kicks off, and still no sign of GPT-5. Just a long list of models, and as my colleague John-Anthony already wrote here, it could use a bit of a cleanup and streamlining.\nI'm particularly excited about GPT-5's rumored capability of automatically selecting the right model to handle the prompt or whatever the user has asked. That could speed things up before the AI even gets to work.\nLess than 30 minutes until kick off\nWe're just under 30 minutes until OpenAI tells us everything about GPT-5 and the livestream for the event is now appearing on YouTube. Though it's just a countdown and a still teaser image showing \"GPT-5\" and \"OpenAI\" in front of a colorful array of gradients.\nYou can see the livestream embedded above, and once it starts, you can watch it right from there.\nOne. Hour. Countdown\nOne hour to go until OpenAI reveals GPT-5 and we enter into the next generation of ChatGPT.\nOpenAI still hasn't got a livestream listing on YouTube yet but stay tuned to this liveblog and we'll update with a link as soon as we have access.\nOne last look before everything changes - again. pic.twitter.com/P4y0iUvjihAugust 7, 2025\nI've been moaning about the OpenAI model names for what feels like an eternity at this point, so I may as well add one last criticism before we move into the GPT-5 era.\nMy colleague Lance Ulanoff has shared an image of the ChatGPT model selection page as it stands right now, and quite honestly, it might just be the most confusing naming scheme on the planet.\nIn just over an hour, OpenAI will announce GPT-5 alongside other models that we believe to be called GPT-5-mini, GPT-5-nano, and GPT-5-chat. Hopefully, the company decides to add these new models and replace the likes of GPT-4o, o3, o4-mini, o4-mini-high, otherwise, the list in that image is going to get even longer and even more confusing.\nAnother ChatGPT livestream\nIt's only been two weeks since OpenAI revealed ChatGPT Agent in a livestream, and yet here we are waiting for what many believe to be the next generation of AI model.\nIs GPT-5 really going to be as impressive as its next generation name would suggest? Or are we going to see small performance improvements in line with an iterative upgrade?\nEither way, OpenAI needs to showcase why users should care about GPT-5 in this upcoming livestream, and so far the company's livestreams have been anything but engaging.\nWith less than 90 minutes until the reveal, we're all getting excited here at TechRadar. After all this could be the ChatGPT upgrade that pushes AI even further into the future.\nTwo hours to go\nOnly two hours until the GPT-5 reveal, and we still don't have a livestream link on YouTube to share.\nAs soon as OpenAI adds a listing for the livestream, we'll be sure to add it to this live blog, so stay tuned as we delve into the future of AI (and ChatGPT).\nPlease fix the naming scheme\nOpenAI's AI model naming scheme is confusing. There's 4o, o3, o3-mini, o3-high, just to name a few.\nIn a few hours, at least four more models will be added to the mix, and it begs the question: At what point will OpenAI's marketing step up and make ChatGPT more user-friendly?\nIf the company chooses to add another subscription tier with the aforementioned ChatGPT Go, not only will we have an AI model naming issue, but users will start to get confused by subscription tiers, too.\nPlease, OpenAI, fix your naming scheme.\nA new ChatGPT subscription\nNew images have appeared online detailing a ChatGPT Go subscription, likely to sit between free tier users and ChatGPT Plus subscriptions.\nAccording to the screenshot, Go subscribers will get more messages, more file uploads, more image generation, and more advanced data analysis compared to free users.\nThis does add a slight concern to the future of ChatGPT's free tier. Does this mean we'll all be paying for the AI we've become accustomed to using for free at some point? I sure hope not...\nThe hype is building\nDropping soon. pic.twitter.com/WSuOn3qE6yAugust 7, 2025\nOpenAI just tweeted a GPT-5 teaser, and as the name would suggest it doesn't give us any real insight other than the fact that it's likely going to replace GPT-4o.\nWith less than three hours to go until the reveal, I was hoping for a teaser to include a little bit more information. I guess not today.\nWhat does Microsoft Copilot think about GPT-5\nWith just over three hours until the OpenAI livestream, we've started to ask other AI tools what they think about GPT-5. After all, who doesn't want to hear AI's thoughts on its own evolution, right?\nLance Ulanoff, TechRadar's Editor At Large, asked Microsoft Copilot about GPT-5 and after a response with leaks and rumors, Copilot said, \"It\u2019s shaping up to be a major leap forward. If you could design your own GPT-5 variant, what would it specialize in\u2014creativity, emotional intelligence, or something else entirely?\"\nLance replied: \"Emotional intelligence, for sure. Have you tried GPT-5?\"\nCopilot responded, \"I haven\u2019t tried GPT-5 myself\u2014since I\u2019m not a user, I don\u2019t get to 'use' other models. But I do keep tabs on what\u2019s happening in the AI world, and GPT-5\u2019s rumored emotional intelligence upgrades are especially intriguing.\nIf it\u2019s anything like what\u2019s been hinted, it could:\nRead tone and subtext more accurately in conversations\nRespond with empathy and nuance, even in complex emotional situations\nAdapt its personality to match the user\u2019s mood or communication style\nSupport mental health applications with more sensitivity and care\nImagine an AI that not only understands what you say, but also how you feel when you say it. That\u2019s a whole new level of connection. What kind of emotionally intelligent features would you want it to have\u2014like being a better listener, helping with conflict resolution, or maybe even coaching through tough decisions?\"\nWOAH. This is probably all a pipe dream but Copilot has thought up a future OpenAI model that completely evolves ChatGPT's emotional intelligence. Is this something you'd be interested in?\nBenchmark leak?\nholy hell pic.twitter.com/ausKp4vancAugust 7, 2025\nLeaks are popping up all across social media including this rumored score on the ARC-AGI-2 test, a benchmark that highlights an AI model's capability of dealing with logic.\nIf these results are accurate, GPT-5 would be so far beyond anything we've seen before from OpenAI or its competitors.\nThat said, anyone can make a fake leak, and ultimately until we see the results from Altman and co themselves, there's no way to be sure of GPT-5's capabilities.\nJust imagine though...\nWhat ChatGPT says about GPT-5\nJohn-Anthony Disotto here, taking over from Graham while he gets fed and watered. I decided the best way to get a glimpse of GPT-5's capabilities would be to ask ChatGPT itself what we can expect during today's livestream.\nThe AI said, \"A Unified, Multi\u2011Variant System\" alongside \"Supercharged Reasoning, Coding, and Agentic Behavior\" and \"Ultra\u2011Large Context & Persistent Memory\" sets GPT-5 apart from its predecessor.\nObviously, ChatGPT won't be letting us into OpenAI's internal secrets, but considering unifying all ChatGPT capabilities would be at the top of my list for GPT-5, I'm really hoping the AI chatbot isn't too far off.\nThe livestream kicks off in just over four hours, so we don't have much longer to wait to hear about the future of ChatGPT and everything GPT-5 is capable of.\nChatGPT-5 is just the beginning\nAs I wait with bated breath for the release of ChatGPT-5 (at 10am PT), I'm thinking about what Sam Altman said just a few days ago. \"We have a ton of stuff to launch over the next couple of months \u2013 new models, products, features, and more\u201d.\nSo, earlier this week, OpenAI dropped its gpt-oss models, which are designed to run entirely on laptops and phones. In a few short hours, we'll get ChatGPT-5, but what next? The next couple of months are a long time, which means we might see quite a few new features being released.\nWhy the Death Star image for ChatGPT-5?\nAt first, Sam Altman posting a picture of the Death Star in relation to the launch of ChatGPT-5, his own product, seemed like an odd way to market something to me. I mean, what's he trying to say? Is it, \"This thing is so scary it could destroy a planet\"?\nHowever, when you view it in context of the things he has recently said about AI creating new and unparalleled security risks and that fact that he finds ChatGPT-5 scary, it fits in. On the one hand, Altman is always pushing the narrative of how great AI will be for the future of the world and for the next generation, but at the same time he's always talking about how AI has the potential to be dangerous.\nThis new type of marketing, where he both praises and criticizes his own product, is certainly nothing new for him, and perhaps it reframes the narrative and puts him ahead of OpenAI's critics? Whatever his reasons, it certainly seems to be working.\nLonger than usual\nSam Altman followed up his mysterious Death Star image post on X.com with a more down-to-earth statement in his next post:\n\"Our livestream tomorrow at 10 am PDT will be longer than usual, around an hour. We have a lot to show and hope you can find the the time to watch!\"\nour livestream tomorrow at 10 am PDT will be longer than usual, around an hour.we have a lot to show and hope you can find the the time to watch!August 7, 2025\nTo be honest Sam, an hour is not that long to reveal the details of what could potentially be the new standard in AI chatbots, so I think you should take as long as you need.\nThat's no moon... that's ChatGPT-5?\nSam Altman has confounded the Internet once again by posting a picture of what appears to be the Death Star from Star Wars rising menacingly from behind a planet.\npic.twitter.com/1u0MOGvJWUAugust 7, 2025\nEverybody is a bit confused by the meaning of this, so, who better to ask what it could mean than rival AI, Grok?\nWhen asked what the image could mean, Grok replied: \"Sam Altman's image of the Death Star symbolizes the rise of immensely powerful AI, like the anticipated GPT-5\u2014a transformative force with potential risks, echoing Star Wars' superweapon. It's likely teasing OpenAI's next big breakthrough.\"\nChatGPT-5 accidentally leaks hours before launch\nAs we sit down with snacks and drinks watching the screen and waiting for a live stream to appear for the imminent launch of ChatGPT-5 it appears that a leak on GitHub has revealed the name of the different ChatGPT-5 models.\nIt looks like we will have gpt-5, designed for logic and multi-step tasks, .gpt-5-mini, a lightweight version for cost-sensitive applications, gpt-5-nano, which is Optimized for speed and ideal for applications requiring low latency, and gpt-5-chat, designed for advanced, natural, multimodal, and context-aware conversations for enterprise applications."
    },
    {
      "url": "https://www.techradar.com/computing/artificial-intelligence/i-tried-this-new-online-ai-agent-and-i-cant-believe-how-good-convergence-ais-proxy-1-0-is-at-completing-multiple-online-tasks-simultaneously",
      "text": "I tried this new AI agent that takes control of your mouse and keyboard to help get tasks done, and I can\u2019t believe how good it is\nNot fast, but always plowing away\nThere's been a recent flurry of AI tools that can go online and do things on your behalf. OpenAI's Operator is a powerful and expensive AI Agent. At the same time, the more makeshift Browser Use offers a thriftier option for those who want AI to automate their online errands. The latest example drawing attention is Proxy 1.0, created by Convergence AI. Proxy boasted of being able to multitask online and handling everything except final approval for you.\nI wanted to try it out, but you only get five sessions a day for free, so I decided to mimic the test I did with Browser Use. After linking it to my Google account, I was presented with the Proxy interface and started my test run. Unlike Browser Use, though, I could submit the prompts quickly as I didn't have to wait for one to finish before sending the next.\nPurchase Proxy\nAs with Browser Use, I started with a shopping advice request: \"Navigate to Amazon, Best Buy, and Walmart and search for 'MacBook Air M2'. Extract the product name, price, and stock availability from the first five results on each site. Compare the prices and identify the lowest one. If discounts or coupons are present, record them. Provide a final summary with the best deal and where to buy it.\"\nProxy eventually offered a couple of the best options at each outlet and its own reccommendations. It took a little bit longer than Browser Use and certainly slower than doing it manually, but it was nice to have it running without me having to keep an eye on it.\nAI travel agent\nI next asked Proxy for help with travel planning with the prompt: \"Search for a round-trip flight between New York and London leaving Dec 15, 2025, and returning December 21, 2025. Select the cheapest option and extract details, including price, airline, and departure time.\nThis was a bit of a mixed bag. While Proxy did find a shockingly cheap flight of about $430, it put it in British Pounds for some reason. Still, the small airport flight with a stop in Iceland at that price is not bad.\nMeteorologist AI\nI went back to the always helpful test of finding and explaining the weather forecast and what I should wear by asking Poxy to: \u201cCheck the 7-day weather forecast for New York City on weather.com and summarize temperature trends, rain chances, and any severe weather warnings and then suggest how to dress for it.\u201d\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nThe AI did fine pulling up the forecast and extracting details about what to expect. The AI went somewhat bland in its suggestions about what to wear, recommending an umbrella on a rainy day and warm clothing most days to deal with the cold. But, it doesn't have to be exciting to be useful when it's the weather.\nMeteor\nOn its own, Proxy 1.0 is amazing. It doesn't have to dazzle you to convince you of its usefulness. The AI doesn\u2019t pretend to be human and make conversation. It just gets things done. It's not perfect, and I had to experiment with wording my prompts to get the best answers, but not enough to be overly frustrating. I can see it being very appealing if I were someone's personal assistant or had to juggle a complex home life. For busy people who don\u2019t want to waste time navigating to and through websites, it's valuable.\nBrowser Use felt more like an open-source science project. It\u2019s powerful, but it requires a fair bit of setup and tinkering, making it more high-maintenance, though you get great results if you're willing to put in the effort. That DIY flexibility is excellent if your interests and skills trend that way, especially if you want a more conversational interaction, but I prefer the streamlined Proxy.\nOpenAI\u2019s Operator is supposed to be the ultimate hands-free, natural-language-powered web assistant. But at $200 a month, it's not for anyone who casually plays with AI tools. There are reports that it also frequently asks for help when it hits an obstacle, which sort of defeats the purpose of having an AI do the work for you.\nProxy 1.0 sits somewhere in the middle of both those alternatives. Compared to how you can almost see Browser Use's scaffolding, you get a complete product without breaking the bank like Operator. I also like how it's more proactive in overcoming obstacles rather than immediately asking for help. The pace at which Proxy completes tasks can be a little annoying. I found I could complete the prompts quite a bit faster than Proxy, but the point is with the AI, I didn't have to.\nAnything that lets me offload my least favorite online chores is worth keeping around, especially as it's likely to keep getting better. If Convergence AI keeps improving Proxy, I might even start trusting the AI agent with my most sacred digital task: remembering to cancel free trials before I get charged.\nYou might also like\nEric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of the world and technology. For the last five years, he served as head writer for Voicebot.ai and was on the leading edge of reporting on generative AI and large language models. He's since become an expert on the products of generative AI models, such as OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, Google Gemini, and every other synthetic media tool. His experience runs the gamut of media, including print, digital, broadcast, and live events. Now, he's continuing to tell the stories people want and need to hear about the rapidly evolving AI space and its impact on their lives. Eric is based in New York City.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    },
    {
      "url": "https://www.techradar.com/computing/artificial-intelligence/openais-first-ai-agent-is-here-and-operator-can-make-a-dinner-reservation-and-complete-other-tasks-on-the-web-for-you",
      "text": "OpenAI's first AI Agent is here, and Operator can make a dinner reservation and complete other tasks on the web for you\nIt's out now as a limited research preview\n- OpenAI has officially launched it's first AI Agent: Operator\n- It's works within a web browser to complete tasks for you, and is out now as a limited research preview\n- Operator can make a dinner reservation, fill out a form, and complete other web tasks\nOpenAI is always looking for the next big thing to add to ChatGPT, and after months of rumors, including a report from earlier this week that teased a launch, the technology giant\u2019s first AI Agent is here. Operator is designed to complete web tasks for you, all with a touch of a button.\nEssentially, Operator is a Computer Using Agent (CUA) that uses GPT-4o\u2019s visual skills to browse and search the web. This means that it can understand the context of what to search for, and thanks to its multi-modality, it understands what it sees as it searches. It\u2019s available now as a research preview for ChatGPT Pro subscribers in the United States.\nOperator is described as \u201can agent that can use its own browser to perform tasks for you.\" OpenAI released a demo showing Operator browsing the web as we (that is, we humans) do. You might ask Operator to book a dinner reservation for you, fill out an arduously long form, order groceries from a service, or even book a flight. It can use OpenTable to find and book a reservation at a restaurant, as shown in the demo. Operator will even walk you through its steps.\nOperator is a \u2018research preview,\u2019 so know that it\u2019s in its early days. OpenAI does impose some limitations. We haven\u2019t had the chance to go hands-on yet, but it certainly looks impressive. This is OpenAI\u2019s first entry into the world of AI agents, which will likely be the theme of the year in the realm of artificial intelligence.\nOpenAI writes in a blog post announcing Operator that it \u201cis one of our first agents, which are AIs capable of doing work for you independently\u2014you give it a task and it will execute it.\u201d This hints that not only are there other agents in the pipeline \u2013 Altman confirmed this during the live demo \u2013 but that they're all based around the notion of doing things for you \u2013 a big step in the quest to make AI even more helpful, giving us some time back.\nOperator is powered by the new Computer Using Agent (CUA) model, which pairs GPT4o\u2019s vision skills with advanced reasoning. This all comes together to let Operator understand and use elements within a browser \u2013 the search bar, various buttons, and on-screen content.\nOpenAI explains that \u201cOperator can \u2018see\u2019 (through screenshots) and \u2018interact\u2019 (using all the actions a mouse and keyboard allow) with a browser,\u201d allowing it to functionally use a browser to complete a task. That\u2019s pretty neat, especially if it works at a high rate of success, and according to the blog post, it can self-correct.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nHowever, as with most new AI tools and skills, it will likely take some time for this to become truly useful in the real world. That will also require OpenAI to open it up to more folks, though as an early research preview it\u2019s still certainly an impressive demo.\nFor now, if you\u2019re in the United States and subscribed to ChatGPT Pro, you can try it out on OpenAI\u2019s website. OpenAI CEO Sam Altman teased that it would eventually arrive in other countries and be added to the ChatGPT Plus subscription. As we remember from some of the announcements from 12 Days of OpenAI, Europe will likely take a bit longer.\nYou might also like\nJacob Krol is the US Managing Editor, News for TechRadar. He\u2019s been writing about technology since he was 14 when he started his own tech blog. Since then Jacob has worked for a plethora of publications including CNN Underscored, TheStreet, Parade, Men\u2019s Journal, Mashable, CNET, and CNBC among others.\nHe specializes in covering companies like Apple, Samsung, and Google and going hands-on with mobile devices, smart home gadgets, TVs, and wearables. In his spare time, you can find Jacob listening to Bruce Springsteen, building a Lego set, or binge-watching the latest from Disney, Marvel, or Star Wars.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    },
    {
      "url": "https://www.techradar.com/computing/artificial-intelligence/theres-a-new-ai-agent-ready-to-browse-the-web-and-fill-in-forms-without-the-need-to-touch-your-mouse",
      "text": "There\u2019s a new AI agent ready to browse the web and fill in forms without the need to touch your mouse\nHugging Face goes open source for AI operator\n- Hugging Face has debuted an AI tool for navigating the web on your behalf\n- The Open Computer Agent uses a real web browser to complete tasks like getting directions or booking tickets\n- The agent and its open-source demo can see what's on screen, click buttons, fill out forms, and move step-by-step through tasks like a human\nHugging Face has introduced its own take on the growing number of semi-independent AI agents that can run online errands for people. The new and free (if limited) Open Computer Agent is like having a personal assistant living inside your web browser.\nPart of the company\u2019s ongoing \u201csmolagents\u201d initiative, the Open Computer Agent can engage with websites and apps like you would, handling an invisible mouse and keyboard to complete requests. The AI can open a browser, type things into forms, click buttons, and more. Ask it to find directions, and it\u2019ll go to Google Maps, enter the origin and destination, and show you the route like a dutiful digital chauffeur.\nYou can try it yourself with the live demo. Fair warning, its popularity is causing some delays and errors due to a backlog.\nWe're launching Computer Use in smolagents! \ud83e\udd73-> As vision models become more capable, they become able to power complex agentic workflows. Especially Qwen-VL models, that support built-in grounding, i.e. ability to locate any element in an image by its coordinates, thus to\u2026 pic.twitter.com/mI8MuWZkISMay 6, 2025\nAgent AI\nThe Open Computer Agent is a different philosophy of an idea that has led to similar tools like OpenAI's Operator, Browser Use, Proxy 1.0, and Opera's Browser Operator. Like those tools, Hugging Face's AI agent is all about being an active participant instead of a passive source of information.\nLike Browser Use, Open Computer Agent is open-source, meaning anyone can see how it works and build on top of it, or at least tweak it for niche use cases. The agent is the start of something more flexible, not a finished product with a million legal disclaimers. That also means the demo is exactly that, a demonstration, not a polished package. It can get things wrong and require you to jump in for logins and CAPTCHA tests.\nBooking tickets, checking store hours, doing searches, looking up directions, and clicking through menus are all things a lot of people would like to be able to do with a single natural language prompt. It\u2019s one thing to ask ChatGPT how to find cheap flights. It\u2019s another to watch a tool go to a travel website, scroll through listings, and attempt to click \u201cbook now.\u201d\nIt might be flawed and far from flashy, but Open Computer Agent represents an approach to AI that might become as common as the now ubiquitous AI image generators.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nYou might also like\nEric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of the world and technology. For the last five years, he served as head writer for Voicebot.ai and was on the leading edge of reporting on generative AI and large language models. He's since become an expert on the products of generative AI models, such as OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, Google Gemini, and every other synthetic media tool. His experience runs the gamut of media, including print, digital, broadcast, and live events. Now, he's continuing to tell the stories people want and need to hear about the rapidly evolving AI space and its impact on their lives. Eric is based in New York City.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    },
    {
      "url": "https://www.techradar.com/ai-platforms-assistants/chatgpt/gpt-5-is-here-5-things-you-need-to-know-about-openais-most-useful-model-yet",
      "text": "GPT-5 is here \u2013 5 things you need to know about OpenAI\u2019s \u2018most useful\u2019 model yet\nSam Altman shows off the model he claims also scares him\nOpenAI\u2019s much\u2011anticipated livestream reveal of GPT\u20115 crammed a lot into about an hour and a half of announcements and demonstrations. CEO Sam Altman didn't show any of the fear he claimed to feel about the new AI model, just a lot of pride at what he and his team had accomplished.\nMuch of the presentation showed off GPT-5's technical milestones and how they translate into powerful new and upgraded AI features for users. Altman also had some lighter fare to unveil for ChatGPT, offering more customization options and ways for users to link their existing online footprint to ChatGPT.\nHere are the five most notable pieces to emerge from GPT-5's debut.\nGPT-5 arrives\nGPT-5 is the next iteration of OpenAI's models, bigger and more powerful, but not dissimilar in its basic form. Even so, GPT-5 is big and complex enough to reach a new level in how it seems to reason.\nEssentially, you no longer have to spoon-feed it context or restate complex prompts three times, or at least not nearly as often. Multifaceted questions like how changing interest rates might affect Gen Z homeownership trends in mixed markets might take several prompts refined multiple times to provide the answers you seek with earlier ChatGPT models, but GPT\u20115 can unpack the whole thing.\nBased on the demonstrations, GPT\u20115 seems to parse each part separately and stitch it together. And it flags when there's a gap in its knowledge, which is far better than confidently hallucinating. It applies that way of thinking to how it interacts with users, too. While obviously not 'thinking', it does appear to read between the lines well enough to reflect a user's mood and even adjust its response to an expressed emotion.\nThe model is supposed to be particularly good with math and coding software. Good enough to handle the increasingly popular pursuit of 'vibe coding,' where you simply describe a feeling or a mood of a piece of software, and the AI produces the HTML, CSS, and JavaScript to match your design vision.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nGPT-5 sizes\nGPT-5 comes in many sizes in addition to the standard version. There's also the smaller gpt-5-mini, and an even leaner gpt-5-nano, which lives solely in the API. The big news is that free ChatGPT users now get access to both GPT-5 and mini, while ChatGPT Plus subscribers enjoy higher usage limits across the board.\nIf you\u2019re a Pro user paying $200 a month, you\u2019ll now get unlimited GPT-5 access, along with access to the more powerful gpt-5-pro model and gpt-5-thinking. These both take longer to provide answers, but come back with deeper, more thoughtful responses.\nThere is no need to pick and choose yourself, either, though. ChatGPT now picks the right model automatically based on what you're asking and what plan you\u2019re on.\nChatGPT custom personalities and colors\nChatGPT has a default, pleasantly bland personality, but GPT\u20115 is advanced enough to offer more variety in the tone and style of the AI chatbot. If you don't want the usual neutral mode, you can choose \u201cCynic\u201d for sarcasm with your answer, \u201cListener\u201d if you\u2019re venting and just need it to echo back understanding, \"Nerd\" for a side of geeky trivia, and \"Robot\" for the purely mechanical response.\nThese personalities don\u2019t undercut the answers you get, but they do flavor the response. Therefore, you might get dry wit with productivity tips from the \u201cCynic\u201d tone or gentle encouragement in your goals from \u201cListener.\u201d\nAdditionally, the chatbot's appearance can now be altered with the new color themes. If you're a paid subscriber, you'll soon be able to adjust the look of ChatGPT instead of switching between the usual black or white.\nVoice Mode\nChatGPT's Voice Mode is getting an audio glow-up of its own. OpenAI is rolling out a much-improved version that not only works with custom GPTs but also adapts its tone and speech style based on your instructions and overall vibe.\nYou can ask it to be snappier, slower, warmer, or whatever else you want. For ChatGPT Plus users, voice responses are now nearly unlimited. Free users still get access, too, with a few hours a day to chat hands-free.\nTo streamline things, the old Standard Voice Mode is being phased out entirely within 30 days. After that, everyone will be on the same upgraded experience.\nGoogle connections for ChatGPT\nNext week, ChatGPT Pro users will be able to hook up their Gmail, Google Calendar, and Google Contacts directly to ChatGPT. That means no more switching tabs to check if you're free next Tuesday or digging through threads to find that one email you definitely forgot to reply to.\nOnce connected, ChatGPT will pull in what it needs to help respond to your queries. OpenAI assured users that it will only pull in the minimum needed and only when it\u2019s helpful.\nYou don\u2019t need to say \u201ccheck my calendar\u201d or \u201cpull that contact.\u201d The AI will do so based on whether you request something that requires it, like scheduling a meeting. It will pick a time that works for you and write the email on your behalf. Other subscription tiers are scheduled to get access to the connections in the near future, so this won't be limited to Pro forever.\nAll of these upgrades leveraging GPT-5 point to OpenAI's bigger plans to make its AI models an intimate part of your life, not just a tool you occasionally turn to and feel annoyed about having to carefully parse answers. Smarter reasoning means less cleanup for the user. Vibe coding shifts AI from merely aping code to interpreting your intended use with software. The personalities and colors make the AI feel like it's more unique to you, not just a one-size-fits-all tool, especially with the more realistic voice and access to your email account and calendar\nGPT\u20115 mimics awareness better than any of its predecessors. That means it could blend into our routines and become as second nature to use as our smartphones. Or at least, that's what OpenAI and its investors likely hope to see happen.\nYou might also like\n- OpenAI's first AI Agent is here, and Operator can make a dinner reservation and complete other tasks on the web for you\n- There\u2019s a new AI agent ready to browse the web and fill in forms without the need to touch your mouse\n- I tried this new AI agent that takes control of your mouse and keyboard to help get tasks done, and I can\u2019t believe how good it is\nEric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of the world and technology. For the last five years, he served as head writer for Voicebot.ai and was on the leading edge of reporting on generative AI and large language models. He's since become an expert on the products of generative AI models, such as OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, Google Gemini, and every other synthetic media tool. His experience runs the gamut of media, including print, digital, broadcast, and live events. Now, he's continuing to tell the stories people want and need to hear about the rapidly evolving AI space and its impact on their lives. Eric is based in New York City.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    }
  ],
  "argos_summary": "During an AMA on Reddit, OpenAI CEO Sam Altman addressed user concerns following the release of GPT-5, particularly regarding the discontinuation of the popular GPT-4o model. Users expressed strong dissatisfaction with GPT-5, prompting Altman to announce that GPT-4o will be reinstated for Plus subscribers. Additionally, Altman acknowledged issues with the safety filter and confirmed plans to introduce a new subscription tier for power users, while also promising improvements to GPT-5's performance and user experience.",
  "argos_id": "OSYRCV7DT"
}