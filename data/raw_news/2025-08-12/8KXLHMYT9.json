{
  "url": "https://www.forbes.com/sites/alexanderpuutio/2025/08/12/survey-results-we-dont-know-what-were-doing-with-ai-adoption/",
  "authorsByline": "Alexander Puutio",
  "articleId": "8cf7acabffef4750a3c93926140f0479",
  "source": {
    "domain": "forbes.com",
    "paywall": true,
    "location": {
      "country": "us",
      "state": "NJ",
      "county": "Hudson County",
      "city": "Jersey City",
      "coordinates": {
        "lat": 40.7215682,
        "lon": -74.047455
      }
    }
  },
  "imageUrl": "https://imageio.forbes.com/specials-images/imageserve/689a8de8ca8fcdd8817d63fd/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T18:15:00+00:00",
  "addDate": "2025-08-12T18:32:48.097184+00:00",
  "refreshDate": "2025-08-12T18:32:48.097185+00:00",
  "score": 1.0,
  "title": "Survey Results: We Don\u2019t Know What We\u2019re Doing With AI Adoption",
  "description": "Survey reveals AI adoption racing ahead of governance as security improves but most enterprises still lack full model understanding and transparency.",
  "content": "It\u2019s coming up on three years since ChatGPT\u2019s public launch cracked open the current wave of AI adoption like a dam burst.\n\nIn that time, we\u2019ve moved from being equal parts awestruck and alarmed by large language models to building copilots, chaining agents together, and now running entire agentic ecosystems within the enterprise. The corporate org chart has sprouted a new title when it gave birth to the Chief AI Officer, and every other C-suite role has quietly redefined itself. The enterprise rollout has begun in earnest, and while McKinsey recently found that Gen AI is yet to deliver enterprise-wide ROI, things are expected to change soon enough.\n\nWe\u2019ve also seen the AI adoption industry professionalize almost overnight. There are thousands of courses from scrappy Udemy modules to MBA electives at the Ivy Leagues teaching executives and engineers how to deploy AI in their work. More CEOs now keep AI tools open on their desktops than they do Bloomberg terminals.\n\nWe\u2019ve come a long way since November 2022. But the question of whether anyone really knows what they\u2019re doing with AI is still fair. The latest report from Anaconda, one of the pioneers of the ML revolution, suggests that we have much further to go.\n\nEnterprises are putting security at the forefront of AI adoption\n\nLet\u2019s start with the good news which is that we\u2019ve matured from tinkering with AI to managing it like the enterprise IT asset it is.\n\nAccording to Anaconda\u2019s survey of 300 AI practitioners and decision-makers, 82% of organizations validate open-source packages for security compliance. Documentation of model dependencies is up to 81%, and 70% now have some form of model drift monitoring in place.\n\nThis is a sign that lessons from past tech cycles have stuck. Security isn\u2019t being bolted on after the fact as it was before, instead, it\u2019s in the design from day one.\n\nBut this means security teams are also slowing some projects down. A quarter of respondents pointed to resistance from data science teams when security requirements are enforced, and over two-thirds reported deployment delays caused by security issues. To the surprise of no one in the field, the same tension that has dogged DevOps since its inception is alive and well in AI.\n\nAnd even with these precautions, nearly 40% of organizations still frequently encounter security vulnerabilities in their AI projects. More than half have no automated anomaly alerts or A/B testing in production. There are more gaps for CAIOs, CIOs and CISOs to plug in than there are clear SOPs on how to do so, which leads us to the second set of insights from the report.\n\nKeeping up with the Altmans: The treadmill of AI adoption\n\nThe speed of model releases is another point of strain. There\u2019s always a new launch, whether it\u2019s OpenAI\u2019s latest \u201co\u201d release, a Google Gemini update, or an open-source foundation model that\u2019s suddenly topping benchmarks. In fact, you could set your watch solely based on listening to the predictable waves of engineers across the industry sighing as they rewrite API calls and rerun integration tests.\n\nAnaconda\u2019s data shows the cracks this pace creates. Only 36% of organizations say their business stakeholders can very effectively access information on a model\u2019s origin, components, and limitations. That means most people using these models, and in many cases making business-critical decisions with them, can\u2019t necessarily answer basic questions about how they work or where they might fail.\n\nIt\u2019s hard to blame them. The AI model supply chain is sprawling with open-source packages, pretrained models, cloud APIs, and proprietary fine-tunes, all stitched together with inconsistent documentation. Even within the same company, engineering may consider a lineage \u201cwell documented\u201d while compliance sees gaps big enough to halt an audit and the C-Suite can\u2019t find the words to sell their AI adoption process to their board.\n\nIf you don\u2019t know that a model miscounts the number of \u201cr\u201ds in \u201cstrawberry,\u201d you can\u2019t predict where else your AI stack might trip, and if you don\u2019t track which models have a tendency to drift after 90 days in production, you can\u2019t proactively retrain them before errors creep into customer-facing outputs.\n\nFor enterprise AI adoption to really take off, we need to urgently raise the 36% to as close to 100% as we can. That\u2019s the only way to move from using AI to knowing what we\u2019re doing with AI.\n\nIn 2025, the state of enterprise AI can be summed up like this. We\u2019re serious about security, getting better at documentation, and aware of the governance gaps. But we\u2019re still deploying tools faster than we\u2019re building the understanding to govern them.\n\nThis puts us at risk for more than regulatory trouble or embarrassing model errors. The lack of understanding of what AI models can do, and where they shouldn\u2019t be used, combined with the slow onset of ROI trickling in, can lead to a violent burst of the current AI bubble, freezing progress for years as leadership retreats from the tools until they are more battle tested.\n\nA lack of understanding about the AI models can also lead to a creeping erosion of trust among customers, regulators, and employees, given how we can\u2019t fully explain the systems we\u2019ve put at the core of our businesses.\n\nClosing that gap is possible. It requires unified tools, clear policies, and a culture that treats governance as an enabler of innovation, not its enemy. It also requires knowing, with confidence, what\u2019s in your AI stack, where it came from, and how it\u2019s behaving in the real world.\n\nOnly then can we say, without irony, that we know what we\u2019re doing with AI adoption.",
  "medium": "Article",
  "links": [
    "https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work",
    "https://www.forbes.com/sites/robtoews/2022/12/15/what-we-got-right-and-wrong-in-our-2022-ai-predictions/",
    "https://www.forbes.com/sites/alexanderpuutio/2024/03/22/what-ceos-need-to-know-about-the-next-frontier-of-ai-ai-agents/",
    "https://www.forbes.com/councils/forbescoachescouncil/2025/07/03/the-chief-ai-officer-a-strategic-priority-for-executive-search/",
    "https://www.anaconda.com/resources/report/bridging-the-ai-model-governance-gap"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "AI models",
      "weight": 0.1006105
    },
    {
      "name": "enterprise AI adoption",
      "weight": 0.08975848
    },
    {
      "name": "AI Adoption",
      "weight": 0.08672554
    },
    {
      "name": "AI adoption",
      "weight": 0.08672554
    },
    {
      "name": "enterprise AI",
      "weight": 0.08241719
    },
    {
      "name": "model releases",
      "weight": 0.08005344
    },
    {
      "name": "AI tools",
      "weight": 0.079656154
    },
    {
      "name": "pretrained models",
      "weight": 0.07737863
    },
    {
      "name": "model dependencies",
      "weight": 0.07688228
    },
    {
      "name": "embarrassing model errors",
      "weight": 0.07538512
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.9267578125
    },
    {
      "name": "/News/Technology News",
      "score": 0.8603515625
    },
    {
      "name": "/Computers & Electronics/Software/Business & Productivity Software",
      "score": 0.80419921875
    },
    {
      "name": "/Computers & Electronics/Enterprise Technology/Other",
      "score": 0.62353515625
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.6064453125
    },
    {
      "name": "/Business & Industrial/Business Operations/Management",
      "score": 0.462890625
    },
    {
      "name": "/Computers & Electronics/Enterprise Technology/Data Management",
      "score": 0.359130859375
    },
    {
      "name": "/News/Business News/Other",
      "score": 0.309814453125
    }
  ],
  "sentiment": {
    "positive": 0.07747393,
    "negative": 0.615961,
    "neutral": 0.306565
  },
  "summary": "A survey by Anaconda, one of the pioneers of the ML revolution, has found that businesses are not yet fully equipped in the face of AI adoption. The survey found that 82% of organizations validate open-source packages for security compliance, and 70% now have some form of model drift monitoring in place. However, security teams are also slowing some projects down due to resistance from data science teams when enforced, and over two-thirds reported deployment delays due to security issues. The speed of model releases is another point of strain, with many companies constantly updating API calls and rerun integration tests. Only 36% of companies say their business stakeholders can access information on a model\u2019s origin, components, and limitations. The report suggests that we need to raise the 36% threshold for AI adoption to 100%.",
  "shortSummary": "Despite advancements, many organizations are not yet adequately managing AI models, highlighting security vulnerabilities and ongoing challenges in its rollout.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "57161142fbb64377a017ea8d23be07e9",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.forbes.com/sites/alexanderpuutio/2024/03/22/what-ceos-need-to-know-about-the-next-frontier-of-ai-ai-agents/",
      "text": "It\u2019s been barely two years since OpenAI came public with ChatGPT and we\u2019ve already progressed to the point where generative large language models are at risk of becoming quaintly outdated.\nLeading this cycle of creative destruction are AI agents which promise to radically change our current understanding of how businesses can interact with AI.\nThe field is developing with incredible pace, and it\u2019s on senior leadership to keep abreast of how far the innovative frontier has been pushed since they last logged on. Even this article is likely to be outdated before it hits Forbes\u2019 services, emphasizing the need to consistently question our understanding of what AI means for businesses.\nWe\u2019ve covered promising agents that will soon hit the market here. Below we dive deeper into how the first use case for AI agents is augmenting staff instead of replacing them, and we explore three AI agents that your team can deploy today: AgentGPT, Auto GPT, and ChartGPT.\nToday's AI Agents Are Most Useful For, Augmenting, Not Replacing, Human Staff\nThe term AI agents refers to AI tools capable of autonomously performing complex tasks from prompt to product.\nUnlike tools such as ChatGPT or Claude, AI agents distinguish themselves by their ability to learn from data, make decisions, and carry out actions autonomously, without further human intervention, once prompted. Prompt it and forget it, instead of prompt it until you make it.\nBest High-Yield Savings Accounts Of 2024\nBest 5% Interest Savings Accounts of 2024\nThe question on any CEO\u2019s mind after they have seen Devin\u2019s sizzle reel is how can they deploy this in value adding ways across their organization. Conversely, the question on the staff\u2019s mind is how long it takes for CEOs to find a way to replace them entirely with an AI agent.\nFor now, the best answer is one that satisfies both leadership and the frontlines. As powerful as AI agents are today, they are still no match to human/AI centaurs; pairings of silicon chips and old-fashioned neurons that have been aimed at a shared problem. In fact, there\u2019s good reason to believe that AI agents will benefit from close collaboration with humans for a good while yet.\nFirstly, humans still hold the upper hand in adaptive flexibility and cohesive thinking. While AI agents already beat humans in knowing what to do in practice, they can be outright dangerous when it comes to knowing what to do in context. This is particularly true when the context is being dynamically created in ways that the AI\u2019s training data is unlikely to properly address.\nMore importantly, AI agents will always benefit from an arbiter of quality - a task for which humans are much better suited than AI itself. For proof, look no further than Gemini\u2019s atrocious record in creating historically accurate depictions.\nAs matters stand today, the most productive way for most CEOs to get started is to begin breeding centaurs rather than installing botfarms. Automating routine tasks with familiar AI tools is a great place to get started. From there, you can move on to empowering your humans to accomplish supernatural feats of data analytics, visualization and other ways to add value at a pace otherwise unattainable for mere mortals alone.\nThree Ways To Get Started Today\nIf you\u2019re looking to get started right away, consider exploring services such as Auto-GPT, AgentGPT and ChartGPT.\nAuto-GPT stands as a bridge between the conventional use of ChatGPT and a superpowered one. This open source project is built on GPT-4, and it is designed to supercharge how users utilize ChatGPT by providing a way to automate your prompts by creating subtasks and loops for fulfilling them.\nAuto-GPT can be used for anything, but promises to be particularly beneficial in customer service departments, where it can automate responses to frequently asked questions, freeing up human agents to tackle more complex inquiries. For example, an e-commerce company could deploy Auto-GPT to handle common customer service queries about order tracking and product information, ensuring that customers receive instant responses 24/7.\nReword\u2019s AgentGPT offers a more easily accessible entry point for businesses looking to automate repetitive or data-intensive processes via GPT-4. With a graphic user interface and no downloads required, Agent GPT can start working for anyone in minutes. One tangible use case for Agent GPT could be in the realm of content creation, where it can generate first-draft material based on input parameters. Marketing departments can leverage Agent GPT to produce initial drafts for blog posts, reports, and even social media content, significantly reducing the time and effort required in the content development phase.\nChartGPT, on the other hand, specializes in data visualization by transforming raw data into compelling, interactive charts and graphs. This agent is useful for anyone dealing with large datasets and visual storytelling based on data. Financial analysts, for instance, could use ChartGPT to quickly create dynamic visuals for quarterly earnings reports, enabling stakeholders to grasp complex financial data at a glance. Similarly, marketing teams might utilize ChartGPT to visualize consumer trends and campaign performances, facilitating data-driven decision-making.\nWhatever your choice may be, the time to trust your business operations entirely to autonomous AI agents isn\u2019t here just yet. Instead, make your next quarter\u2019s priority to empower your staffers with the best-in-class AI agents that help them solve your client\u2019s problems faster.\nIf you don\u2019t do it, someone else will."
    },
    {
      "url": "https://www.forbes.com/sites/robtoews/2022/12/15/what-we-got-right-and-wrong-in-our-2022-ai-predictions/",
      "text": "As we do every year, last December we published a list of 10 predictions about the world of artificial intelligence in 2022.\nTo keep ourselves honest, with 2022 now coming to a close, let\u2019s revisit these predictions to see how things actually played out. There is much to learn from these retrospectives about the state and trajectory of AI today.\n(Keep an eye out for our 2023 AI predictions, coming out next week!)\nPrediction 1: Language AI will take center stage, with more startups getting funded in NLP than in any other category of AI.\nOutcome: Right\nBoy, did this come true.\nThe breathtaking progress in language AI has been the defining theme in the world of artificial intelligence in 2022.\nLarge language models (now commonly referred to as LLMs) have taken the technology world by storm this year. Today\u2019s generative AI frenzy is the direct result of advances in language models: LLMs make possible both text-generating systems like GPT-3 and text-to-image systems like DALL-E. OpenAI\u2019s ChatGPT, which has gone viral in recent weeks, is the latest example.\nNearly all of 2022\u2019s largest AI financings went to language startups: Anthropic ($580 million Series B), Inflection AI ($225 million Series A), Cohere (rumored $200 million Series C), Hugging Face ($100 million Series C), Adept ($65 million Series A), AI21 Labs ($64 million Series B).\nPrediction 2: Databricks, DataRobot and Scale AI will all go public.\nOutcome: Wrong\nWhen we made this prediction 12 months ago, the public markets were on an unprecedented hot streak. 2021 shattered all previous annual records for IPOs, with over 1,000 companies going public.\nHow much can change in a year! Amid the broader market pullback, IPO activity is down 93% in 2022.\nGiven the dire state of the public markets today, especially in the technology sector, it makes sense that none of these three companies ended up going public in 2022.\nDataRobot in particular has floundered this year, grappling with slowing growth, CEO turnover and mass layoffs. Databricks, on the other hand, has continued on its meteoric trajectory; the company surpassed $1 billion in annualized revenue a few months ago. Expect Databricks to debut on public markets once the IPO window reopens (perhaps in 2023).\nPrediction 3: At least three climate AI startups will become unicorns.\nOutcome: Wrong\nIn last year\u2019s predictions, we named ten climate AI startups that could become unicorns in 2022: Cervest, ClimateAi, Gro Intelligence, Kettle, KoBold Metals, NCX, Pachama, Patch, Persefoni, Watershed.\nOf these ten, only one ended up raising funding at a unicorn valuation this year: Watershed. Watershed\u2019s Series B in February, led by insiders Sequoia and Kleiner Perkins, valued the company at $1 billion. KoBold Metals raised a significant up round in 2022, but at a valuation (~$600 million) shy of unicorn status. Patch likewise raised a big round this year, but at an unannounced valuation.\nThis prediction, like the previous one, reflected the market exuberance of 2021\u2014and ran up against the dramatic market pullback in 2022.\nPrediction 4: Powerful new AI tools will be built for video.\nOutcome: Right\n2022 has been a banner year for video AI, reflecting the fact that artificial intelligence is becoming increasingly multimodal.\nAI-powered tools for video search, video editing, video analysis and video creation have all flourished over the past year. Runway, Twelve Labs, Descript, Spot AI, Hour One and Movio are among the promising video AI startups that have raised funding and debuted exciting new products this year.\nVideo is at the center of today\u2019s generative AI craze. While text-to-image models like DALL-E and Stable Diffusion have captured plenty of attention, text-to-video models are widely seen as the next frontier, representing both a more complex technical challenge and a larger commercial opportunity. Google and Meta have both introduced new text-to-video capabilities in recent months.\nPrediction 5: An NLP model with over 10 trillion parameters will be built.\nOutcome: Wrong\nIn recent years, AI models have been getting larger and larger. In 2021, for the first time, an AI model with over 1 trillion parameters was built (not once but twice: Google\u2019s Switch Transformer and the Beijing Academy of Artificial Intelligence\u2019s Wu Dao 2). Conventional wisdom held that, as organizations raced to build ever more advanced AI systems, models would continue growing exponentially bigger.\nThis view has turned out to be oversimplified.\nIn one of 2022\u2019s most important research papers, a group of DeepMind researchers determined that today\u2019s large language models are actually bigger than they should be: to be optimally trained (given a certain compute budget), today\u2019s models should have fewer parameters but train on larger datasets. In other words, training data trumps model size.\nWeighing in at only 70 billion parameters, DeepMind\u2019s Chinchilla model outperforms much larger models like GPT-3 (175 billion parameters), Jurassic-1 (178 billion parameters), and Megatron-Turing (530 billion parameters)\u2014because it is trained on five times more data.\nAI researchers\u2019 approach to building large language models has thus shifted away from prioritizing raw scale and parameter count. When OpenAI announces GPT-4 in a couple months, don\u2019t be surprised if it is not much bigger than its predecessor GPT-3 (but expect its training data corpus to be orders of magnitude larger).\nPrediction 6: Collaboration and investment will all but cease between American and Chinese actors in the field of AI.\nOutcome: Right\nUnfortunately for internationalists, this prediction proved resoundingly true.\nRelations between the U.S. and China have deteriorated dramatically in 2022, with artificial intelligence playing a key role. Both sides believe that AI will be critical to military strength and the global balance of power in the twenty-first century; both sides are acting increasingly aggressively to limit the other\u2019s progress in the field.\nIn September, President Biden issued the first-ever executive order in the history of the Committee on Foreign Investment in the United States (CFIUS), severely restricting the ability of China-affiliated groups to invest in or access AI technologies from the United States.\nIn an even more forceful move, on the heels of the newly passed CHIPS and Science Act, the Biden administration announced a sweeping set of measures aimed at completely choking off China\u2019s access to advanced semiconductors\u2014the hardware required to power today\u2019s AI.\nThe AI ecosystems in the United States and in China have effectively decoupled and are now operating as independent spheres.\nThe (troubling) question is: how much worse will things get in 2023?\nPrediction 7: Multiple large cloud/data platforms will announce new synthetic data initiatives.\nOutcome: Right\nScale AI announced in early 2022 that it would get into the synthetic data game. Amazon Web Services followed suit a few months later, adding synthetic data capabilities to its Sagemaker platform. Just a few weeks ago, Unity Technologies rolled out a major new suite of open-source synthetic data tools.\nExpect synthetic data to become an increasingly important part of the modern AI stack in 2023. While most of today\u2019s synthetic data offerings (including the three mentioned above) focus on image data, going forward we expect to see greater activity around synthetic text and NLP data\u2014a massive and still untapped market opportunity.\nPrediction 8: Toronto will establish itself as the most important AI hub in the world outside of Silicon Valley and China.\nOutcome: Right\nWhile we generally try to make our predictions concrete and falsifiable, this one is less straightforward to measure. Nonetheless, plenty of developments this year point to the continued emergence of Toronto as a top-tier global AI hub.\nAccording to a recent CBRE report, Toronto is the fastest growing major market for technology talent in all North America\u2014and it\u2019s not even close.\nThe Toronto-based Vector Institute, an AI-focused research organization, celebrated its fifth anniversary this year. Vector has grown into one of the largest AI graduate programs in the world, with over 2,000 graduates.\nFrom Cohere to Waabi, Toronto-based AI startups across sectors have captured headlines and pushed forward the frontiers of AI research and commercialization this year.\nLast month, University of Toronto professor Geoff Hinton was granted the NeurIPS \u201cTest of Time\u201d Award for his groundbreaking 2012 research that effectively ushered in the era of deep learning. It was a timely reminder that modern AI started in Toronto and spread from there, with Hinton\u2019s former students going on to lead AI efforts at organizations including Google, OpenAI, Meta, DeepMind, Nvidia, Uber and Apple.\nPrediction 9: \u201cResponsible AI\u201d will begin to shift from a vague catch-all term to an operationalized set of enterprise practices.\nOutcome: Right-ish\nAs 2022 comes to a close, it is fair to say that the leading AI organizations are now putting serious effort into ensuring that their technology is deployed safely and responsibly.\nOpenAI invests heavily to try to prevent its models from causing harm; its alignment work with InstructGPT and its extensive use of reinforcement learning from human feedback (RLHF) to reduce model toxicity are examples of this. Other foundation model providers like Cohere and AI21 Labs are making similar efforts; Anthropic\u2019s entire raison d\u2019\u00eatre is to ensure that AI gets built safely and reliably.\nIf anything, the exception proves the rule here. When text-to-image startup Stability AI fully open-sourced the Stable Diffusion model earlier this year with no filters, enabling internet users to easily produce pornographic, violent or otherwise harmful images, it encountered swift backlash. In response, the newest version of Stable Diffusion, released a few weeks ago, has been modified to prevent users from producing NSFW images or violating copyright laws.\nSo, why \u201cright-ish\u201d?\nThe small handful of companies at the cutting edge of artificial intelligence are sophisticated enough to understand AI\u2019s many failure modes and to take steps to mitigate them. But this is not yet true for most of the rest of the world\u2019s organizations and individuals\u2014who, after all, represent the vast majority of AI\u2019s actual users.\nThe typical enterprise that wants to work with AI today is still unequipped to deal with, say, racial bias in machine learning models, or model explainability, or adversarial AI. Responsible AI practices will take many years to develop and spread.\nPrediction 10: Reinforcement learning will become an increasingly important and influential AI paradigm.\nOutcome: Right-ish\nReinforcement learning has been deployed in a wide range of interesting and important settings in 2022.\nIt underpinned Meta\u2019s landmark CICERO work, in which an AI system surpassed humans in the strategy game Diplomacy for the first time. Nvidia used reinforcement learning to design its new cutting-edge H100 chips; OpenAI used it to make its language models more truthful and less toxic.\nYet reinforcement learning still faces basic limitations that to date have prevented it from becoming a more widespread AI paradigm. In a nutshell, it can be prohibitively time-consuming, resource-intensive and unwieldy to implement because it entails vast amounts of trial and error.\nThese challenges will need to be addressed if reinforcement learning is to reach its full potential.\nNote: The author is a Partner at Radical Ventures, which is an investor in ClimateAi, Cohere, Twelve Labs and Waabi."
    }
  ],
  "argos_summary": "Since the launch of ChatGPT, AI adoption has rapidly evolved within enterprises, leading to the emergence of roles like Chief AI Officer and a focus on security in AI projects. Anaconda's survey reveals that while organizations are improving security measures and documentation, many still face significant challenges, including deployment delays and a lack of understanding of AI models. As AI tools continue to develop, the need for clear governance and collaboration between humans and AI agents is emphasized, with a call for businesses to prioritize empowering staff with AI capabilities rather than relying solely on autonomous agents.",
  "argos_id": "8KXLHMYT9"
}