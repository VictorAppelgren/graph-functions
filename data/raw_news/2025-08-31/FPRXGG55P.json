{
  "url": "https://www.howtogeek.com/how-to-use-libraries-in-python-to-do-more-with-less-code/",
  "authorsByline": "David Delony",
  "articleId": "cd5464b248b74ffda1ef4a477ba6e634",
  "source": {
    "domain": "howtogeek.com",
    "location": {
      "country": "us",
      "state": "VA",
      "county": "Fairfax County",
      "city": "McNair",
      "coordinates": {
        "lat": 38.9695316,
        "lon": -77.3859479
      }
    }
  },
  "imageUrl": "https://static0.howtogeekimages.com/wordpress/wp-content/uploads/2025/08/python-logo-over-blurred-python-code-background-with-the-word-python-written-in-yellow-underneath.png?w=1600&h=900&fit=crop",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-31T18:16:15+00:00",
  "addDate": "2025-08-31T18:20:41.304037+00:00",
  "refreshDate": "2025-08-31T18:20:41.304038+00:00",
  "score": 1.0,
  "title": "How to Use Libraries in Python to Do More With Less Code",
  "description": "Don't waste time coding by hand! Borrow it from the library.",
  "content": "As with other programming languages, Python has libraries to make coding tasks easier. Here's how you can take advantage of them, and how you can create your own libraries as well.\n\nLibraries are collections of shared code. They're common in Python, where they're also called \"modules,\" but they're also ubiquitous across other programming languages. A library defines functions that any programmer can use in their own programs, similar to how a public library offers anyone access to its materials.\n\nThe advantage of using libraries is that you can save time and effort by not having to code your own solutions. Libraries tend to be better tested and debugged than anything you could come up with. They will also let you do more than you could on your own.\n\nThere are numerous libraries in Python for tasks such as graphics, game development, and more. My favorite libraries tend to be for data analysis. Python is especially popular for statistics and data science due to the large number of libraries available for these tasks.\n\nThere are several ways to install Python libraries on your system. If you're using a Linux distribution, there will often be Python libraries included in your distro's package manager. For example, on Debian and Ubuntu systems, the libraries will often start with \"python-\" or \"python3-\". This will install the library system-wide, so you'll need to have administrative access.\n\nIf you don't have root or administrative access on your system, there are still ways to install Python libraries locally.\n\nYou can use the pip tool to install Python libraries listed in the Python Package Index (PyPi).\n\nFor example, to install NumPy:\n\nYou can install libraries on a per-project basis in virtual environments using the virtualenv utility.\n\nYou can take the concepts of virtualenv further using Mamba, which happens to be my method of choice. Mamba is a tool popular among data scientists and analysts that allows you to create project-specific environments.\n\nI already have a Mamba environment for statistical computing populated with several libraries that are popular for data analysis. I can activate it at the shell:\n\nA lot of Python libraries will come with the language. This is a point of pride for the Python culture. The Python Standard Library has lots of modules for everything from interacting with the operating system to working with times and dates. This is why Python programmers like to say that the language has \"batteries included.\"\n\nTo import a whole Python library in a script or in the interactive Python mode, use the import command.\n\nFor example, to import the NumPy module, use this command:\n\nWith the library imported, you can access functions from that module. It's like if you defined a bunch of functions. The functions are imported under their own namespace. This means that by default, any functions from the library are kept separate from the built-in commands in Python. I'll show you some ways to change this, but the default behavior is better for most circumstances.\n\nTo get at these functions, you can call the module you just imported. It's effectively an object, if you understand how object-oriented programming works. These functions are methods that are private to the object we just created by importing the library.\n\nFor example, to calculate the arithmetic mean or average of an array using NumPy, we'd type this:\n\nThis calls the mean function in NumPy.\n\nYou might think that typing \"numpy\" every time you want to access the functions is a lot, and you're right. You can import libraries with other names as a shortcut. A common example you'll see with NumPy is shortening the name to \"np\" in import statements:\n\nYou can now refer to numpy as \"np.\" Let's rewrite that earlier mean calculation:\n\nA lot of times, when you're working in an interactive Python section, such as in the standard interactive Python interpreter or IPython, you'll often want to import only one or two functions from a large library, especially if you want to use them repeatedly during a session. This is also easy to do in Python.\n\nTo import a single function from NumPy into the main namespace, you can use this construction:\n\nFor example, to import the mean function from NumPy:\n\nYou can also import multiple functions by separating them with commas. For example, to import the mean and median functions from NumPy:\n\nWith these functions imported, you won't have to preface them with \"numpy\" or \"np.\" You can just use them as if they were part of the default Python functions.\n\nFor example, to calculate the mean of an array of numbers\n\nImporting functions by themselves is better-suited to interactive Python sessions because it saves on typing. You can do it in a script, but it's not recommended. You might end up overwriting the namespace that's used for a default Python function. This might cause a bug in your script. If you ask for help online in a forum or IRC chat, the other Pythonistas might get stumped. This is why you should avoid these kinds of imports in scripts as much as possible.\n\nCreating and Importing Your Own Python Libraries\n\nIt's also easy to import your own Python libraries. You can do it without having to be an expert in Python. All you need is a text editor and the ability to use a terminal.\n\nPython modules are just ultimately collections of functions defined in Python. You can just create a file ending in .py, the same way you were writing a script. If you've created your own Python functions, you can stick them in a file and import them, the same as with any other built-in or installed Python module.\n\nTo import a module, make sure that it has execute permissions. You can use the chmod command in Unix-like systems, including Linux and the macOS terminal:\n\nYou can import the library using the methods described earlier. If you're in the same directory as the module, you can just use import statements. For example, to import the library:\n\nIf the library is in another directory, there are a couple of ways to change the search path. The first method is to use the PYTHONPATH environment variable. It's a list of directories that Python will use to look for modules. You can modify this in your system shell either at the command line or in a startup file such as the .bashrc file in Bash. It's a list of directories separated by a colon (:) character, similar to the PATH environment variable on Linux systems.\n\nAt the Linux shell, you can examine it with the echo command:\n\nTo change it, it's best to append it.\n\nThis will ensure that any existing module search path is preserved before adding your own directory.\n\nYou can also modify the search path using the built-in sys module. Just import it in an interactive Python session:\n\nTo add a directory to the search path, use the append method:\n\nSince there's no real distinction between a Python script and a module or library, you can easily convert one to the other. It's good programming style to break operations into smaller functions. You can also call them from another script or interactive section, but what if you have a script? You can just define the script's operations in a \"main\" function.\n\nThis will check if the Python interpreter is executing the script as a script instead of importing. You can then put everything you want after this section to execute in the script, while leaving the functions to be possibly imported in another script or interactive session.\n\nWith the ability to use modules, you can tap into Python's vast array of available modules. You'll be able to do more than you thought you ever could by yourself. You'll save a lot of time and effort over coding from scratch.",
  "medium": "Article",
  "links": [
    "https://numpy.org/",
    "https://www.howtogeek.com/658904/how-to-add-a-directory-to-your-path-in-linux/",
    "https://pypi.org/",
    "https://docs.python.org/3/library/index.html",
    "https://www.howtogeek.com/how-to-set-up-a-development-environment-with-mamba/",
    "https://www.howtogeek.com/the-linux-bashrc-file-explained/",
    "https://www.howtogeek.com/start-project-python-virtual-environments/"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Python libraries",
      "weight": 0.13265389
    },
    {
      "name": "Python modules",
      "weight": 0.11204881
    },
    {
      "name": "Libraries",
      "weight": 0.10016652
    },
    {
      "name": "libraries",
      "weight": 0.10016652
    },
    {
      "name": "library",
      "weight": 0.10016652
    },
    {
      "name": "Python",
      "weight": 0.09880968
    },
    {
      "name": "several libraries",
      "weight": 0.09871949
    },
    {
      "name": "interactive Python sessions",
      "weight": 0.09854049
    },
    {
      "name": "Python programmers",
      "weight": 0.097485214
    },
    {
      "name": "numerous libraries",
      "weight": 0.09647688
    }
  ],
  "topics": [],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/Reference/General Reference/How-To, DIY & Expert Content",
      "score": 0.7841796875
    },
    {
      "name": "/Computers & Electronics/Programming/Other",
      "score": 0.56396484375
    },
    {
      "name": "/Reference/Technical Reference",
      "score": 0.47705078125
    },
    {
      "name": "/Computers & Electronics/Programming/Development Tools",
      "score": 0.40478515625
    },
    {
      "name": "/Computers & Electronics/Programming/Scripting Languages",
      "score": 0.35498046875
    }
  ],
  "sentiment": {
    "positive": 0.20768888,
    "negative": 0.26467115,
    "neutral": 0.52764
  },
  "summary": "Python, a programming language that allows users to use shared code in their own programs without having to code their own solutions, libraries like those defined in the Python Package Index (PyPi). These libraries are often included in Linux distributions' package manager and often come with the name \"pyramid\" or \"Python3-\". These libraries define functions that can be accessed by anyone without requiring a programmer to create their own solution. The advantage of using libraries is that they can save time and effort by providing more accessible and tested solutions. There are several ways to install Python libraries on your system, including the pip tool for installation and the virtualenv utility for virtual environments. To import a whole Python library in a script or in the interactive Python mode, use the import command. The Python Standard Library has modules for everything from interacting with the operating system to working with times and dates. To access functions from a library imported, the functions are imported under their own namespace, which by default are kept separate from the built-in commands in Python.",
  "shortSummary": "Piggy Python libraries help you access shared code, improve code development, and create your own libraries using various tools like Python's Numpy module and virtualenv tools.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "c492227482e148b19151c0c92fc4bdbd",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://numpy.org/",
      "text": "\"\"\"\nTo try the examples in the browser:\n1. Type code in the input cell and press\nShift + Enter to execute\n2. Or copy paste the code, and click on\nthe \"Run\" button in the toolbar\n\"\"\"\n# The standard way to import NumPy:\nimport numpy as np\n# Create a 2-D array, set every second element in\n# some rows and find max per row:\nx = np.arange(15, dtype=np.int64).reshape(3, 5)\nx[1:, ::2] = -99\nx\n# array([[ 0, 1, 2, 3, 4],\n# [-99, 6, -99, 8, -99],\n# [-99, 11, -99, 13, -99]])\nx.max(axis=1)\n# array([ 4, 8, 13])\n# Generate normally distributed random numbers:\nrng = np.random.default_rng()\nsamples = rng.normal(size=2500)\nsamples\nNearly every scientist working in Python draws on the power of NumPy.\nNumPy brings the computational power of languages like C and Fortran to Python, a language much easier to learn and use. With this power comes simplicity: a solution in NumPy is often clear and elegant.\nNumPy's API is the starting point when libraries are written to exploit innovative hardware, create specialized array types, or add capabilities beyond what NumPy provides.\n| Array Library | Capabilities & Application areas | |\n| Dask | Distributed arrays and advanced parallelism for analytics, enabling performance at scale. | |\n| CuPy | NumPy-compatible array library for GPU-accelerated computing with Python. | |\n| JAX | Composable transformations of NumPy programs: differentiate, vectorize, just-in-time compilation to GPU/TPU. | |\n| Xarray | Labeled, indexed multi-dimensional arrays for advanced analytics and visualization. | |\n| Sparse | NumPy-compatible sparse array library that integrates with Dask and SciPy's sparse linear algebra. | |\n| PyTorch | Deep learning framework that accelerates the path from research prototyping to production deployment. | |\n| TensorFlow | An end-to-end platform for machine learning to easily build and deploy ML powered applications. | |\n| Arrow | A cross-language development platform for columnar in-memory data and analytics. | |\n| xtensor | Multi-dimensional arrays with broadcasting and lazy computing for numerical analysis. | |\n| Awkward Array | Manipulate JSON-like data with NumPy-like idioms. | |\n| uarray | Python backend system that decouples API from implementation; unumpy provides a NumPy API. | |\n| tensorly | Tensor learning, algebra and backends to seamlessly use NumPy, PyTorch, TensorFlow or CuPy. |\nNumPy lies at the core of a rich ecosystem of data science libraries. A typical exploratory data science workflow might look like:\nNumPy forms the basis of powerful machine learning libraries like scikit-learn and SciPy. As machine learning grows, so does the list of libraries built on NumPy. TensorFlow\u2019s deep learning capabilities have broad applications \u2014 among them speech and image recognition, text-based applications, time-series analysis, and video detection. PyTorch, another deep learning library, is popular among researchers in computer vision and natural language processing.\nStatistical techniques called ensemble methods such as binning, bagging, stacking, and boosting are among the ML algorithms implemented by tools such as XGBoost, LightGBM, and CatBoost \u2014 one of the fastest inference engines. Yellowbrick and Eli5 offer machine learning visualizations.\nNumPy is an essential component in the burgeoning Python visualization landscape, which includes Matplotlib, Seaborn, Plotly, Altair, Bokeh, Holoviz, Vispy, Napari, and PyVista, to name a few.\nNumPy\u2019s accelerated processing of large arrays allows researchers to visualize datasets far larger than native Python could handle."
    },
    {
      "url": "https://www.howtogeek.com/658904/how-to-add-a-directory-to-your-path-in-linux/",
      "text": "Quick Links\nSummary\n- Your PATH is a list of locations that your operating system checks when running a command, allowing you to run executables without manually specifying their exact location.\n- The shell searches for executables in the PATH in a specific order, starting with shell builtins, then searching through the listed directories from left to right.\n- You can add directories to your PATH using the export command, either temporarily or permanently by editing your .bashrc or .profile files. Just be careful not to add a leading colon to avoid security risks.\nPATH\nis one of the silent manipulators in the background of your Linux computer. It quietly affects your user experience, but there's nothing shady about it. We'll explain what it does, and how you can adjust it.\nWhat Is PATH on Linux, and How Does It Work?\nYour PATH is a list of locations that your operating system will check any time you attempt to run a command. If an executable that you attempt to run is contained in a folder that is included in your PATH the executable can be run without specifying its exact location manually, since your operating system already knows where it is.\nSo how does it actually work functionally?\nWhen you type a command in a terminal window and press Enter, you kick off quite a lot of activity before your command is even executed.\nBash is the default shell on most Linux distributions. It interprets the line of text you entered and identifies the command names intermingled with the parameters, pipes, redirections, and whatever else is there. It then locates the executable binaries for those commands and launches them with the parameters you supplied.\nThe first step the shell takes to locate the executable is identifying whether a binary is even involved. If the command you use is within the shell itself (a \"shell builtin\") no further search is required.\nShell builtins are the easiest to find because they're integral to the shell. It's like having them in a toolbelt \u2014 they're always with you.\nIf you need one of your other tools, though, you have to go rummage in the workshop to find it. Is it on your workbench or a wall hanger? That's what the PATH\nenvironment variable does. It holds a list of places the shell searches and the order in which they'll be searched.\nIf you want to see whether a command is a shell builtin, an alias, a function, or a standalone binary mv /work/unfile, you can use the type\ncommand as shown below:\ntype clear\ntype cd\nThis tells us that clear\nis a binary file, and the first one found in the path is located at /usr/bin\n. You might have more than one version of clear\ninstalled on your computer, but this is the one the shell will try to use.\nUnsurprisingly, cd\nis a shell builtin.\nHow to List Your PATH\nIt's easy to see what's in your path. Just type the following to use the echo\ncommand and print the value held in the $PATH\nvariable:\necho $PATH\nThe output is a list of colon (:\n) delimited file system locations. The shell searches from left to right through the path, checking each file system location for a matching executable to perform your command.\nWe can pick our way through the listing to see the file system locations that will be searched, and the order in which they will be searched:\n-\n/usr/local/sbin\n-\n/usr/local/bin\n-\n/usr/sbin\n-\n/usr/bin\n-\n/sbin\n-\n/bin\n-\n/usr/games\n-\n/usr/local/games\n-\n/snap/bin\nSomething that might not be immediately obvious is the search doesn't start in the current working directory. Rather, it works its way through the listed directories, and only the listed directories.\nIf the current working directory isn't in your path, it won't be searched. Also, if you have commands stored in directories that aren't in the path, the shell won't find them.\nTo demonstrate this, we created a small program called rf\n. When executed, rf\nprints the name of the directory from which it was launched in the terminal window. It's located in /usr/local/bin\n. We also have a newer version in the /dave/work\ndirectory.\nWe type the following which\ncommand to show us which version of our program the shell will find and use:\nwhich rf\nThe shell reports the version it found is the one in the directory that's in the path.\nWe type the following to fire it up:\nrf\nVersion 1.0 of rf\nruns and confirms our expectations were correct. The version found and executed is located in /usr/local/bin\n.\nTo run any other version of rf\non this computer, we'll have to use the path to the executable on the command line, as shown below:\n./work/rf\nNow that we've told the shell where to find the version of rf\nwe want to run, it uses version 1.1. If we prefer this version, we can copy it into the /usr/local/bin\ndirectory and overwrite the old one.\nLet's say we're developing a new version of rf\n. We'll need to run it frequently as we develop and test it, but we don't want to copy an unreleased development build into the live environment.\nOr, perhaps we've downloaded a new version of rf\nand want to do some verification testing on it before we make it publicly available.\nIf we add our work directory to the path, we make the shell find our version. And this change will only affect us \u2014 others will still use the version of rf\nin /usr/local/bin\n.\nAdd a Directory to Your PATH\nYou can use the export\ncommand to add a directory to the PATH\n. The directory is then included in the list of file system locations the shell searches. When the shell finds a matching executable, it stops searching, so you want to make sure it searches your directory first, before /usr/local/bin\n.\nThis is easy to do. For our example, we type the following to add our directory to the start of the path so it's the first location searched:\nexport PATH=/home/dave/work:$PATH\nThis command sets $PATH\nto be equal to the directory we're adding, /home/dave/work\n, and then the entire current path.\nThe first PATH\nhas no dollar sign ($\n). We set the value for PATH\n. The final $PATH\nhas a dollar sign because we're referencing the contents stored in the PATH\nvariable. Also, note the colon (:\n) between the new directory and the $PATH\nvariable name.\nLet's see what the path looks like now:\necho $PATH\nOur /home/dave/work\ndirectory is added to the start of the path. The colon we provided separates it the rest of the path.\nWe type the following to verify our version of rf\nis the first one found:\nwhich rf\nThe proof in the pudding is running rf\n, as shown below:\nrf\nThe shell finds Version 1.1 and executes it from /home/dave/work\n.\nTo add our directory to the end of the path, we just move it to the end of the command, like so:\nexport PATH=$PATH:/home/dave/work\nHow to Permanently Add Something to PATH\nAs Beth Brooke-Marciniak said, \"Success is fine, but success is fleeting.\" The moment you close the terminal window, any changes you've made to the $PATH\nare gone. To make them permanent, you have to put your export\ncommand in a configuration file.\nWhen you put the export\ncommand in your .bashrc\nfile, it sets the path each time you open a terminal window. Unlike SSH\nsessions, for which you have to log in, these are called \"interactive\" sessions.\nIn the past, you would put the export\ncommand in your .profile\nfile to set the path for log in terminal sessions.\nHowever, we found that if we put the export\ncommand in either the .bashrc\nor .profile\nfiles, it correctly set the path for both interactive and log in terminal sessions. Your experience might be different. To handle all eventualities, we'll show you how to do it in both files.\nUse the following command in your /home\ndirectory to edit the .bashrc\nfile:\ngedit .bashrc\nThe gedit\neditor opens with the .bashrc\nfile loaded.\nScroll to the bottom of the file, and then add the following export command we used earlier:\nexport PATH=/home/dave/work:$PATH\nSave the file. Next, either close and reopen the terminal window or use the dot\ncommand to read the .bashrc\nfile, as follows:\n. .bashrc\nThen, type the following echo\ncommand to check the path:\necho $PATH\nThis adds the /home/dave/work\ndirectory to the start of the path.\nThe process to add the command to the .profile\nfile is the same. Type the following command:\ngedit .profile\nThe gedit\neditor launches with the .profile\nfile loaded.\nAdd the export\ncommand to the bottom of the file, and then save it. Closing and opening a new terminal window is insufficient to force the .profile\nfile to be reread. For the new settings to take effect, you must log out and back in or use the dot\ncommand as shown below:\n. .profile\nSetting the Path for Everyone\nTo set the path for everyone who uses the system, you can edit the /etc/profile\nfile.\nYou'll need to use sudo\n, as follows:\nsudo gedit /etc/profile\nWhen the gedit\neditor launches, add the export command to the bottom of the file.\nSave and close the file. The changes will take effect for others the next time they log in.\nA Note on Security\nMake sure you don't accidentally add a leading colon \":\n\" to the path, as shown below.\nIf you do, this will search the current directory first, which introduces a security risk. Say you downloaded an archive file and unzipped it into a directory. You look at the files and see another zipped file. You call unzip once more to extract that archive.\nIf the first archive contained an executable file called unzip\nthat was a malicious executable, you'd accidentally fire up that one instead of the real unzip\nexecutable. This would happen because the shell would look in the current directory first.\nSo, always be careful when you type your export\ncommands. Use echo\n$PATH to review them and make sure they are the way you want them to be."
    },
    {
      "url": "https://www.howtogeek.com/the-linux-bashrc-file-explained/",
      "text": "Summary\n- The .bashrc file is crucial for configuring commands on Linux shell startup.\n- Knowing the shell you're running helps you configure .bashrc properly.\n- Customize your shell with .bashrc by defining new functions, setting aliases, and more.\nThe shell is so important to Linux, it has its own startup process. Discover how to configure the shell on startup, how to run commands automatically, and what you can do with all this power.\nWhat .bashrc Does and Why\nThe .bashrc file is typically hidden in your home directory. It is a \"run control\" file that originated with Bash (Bourne Again Shell), the most popular and widely used Linux shell. Linux uses run control files to script and configure commands when they start, so .bashrc is a startup script for the shell itself.\n.bashrc should do whatever is necessary to set up your environment for an interactive shell session. This includes setting environment variables, defining functions, and running utility programs. Once you know how it works, you'll find various uses to customize and streamline your shell experience.\nHow .bashrc Works\nFirst of all, know that Bash is not the only shell. On macOS, you're probably using zsh, a powerful alternative. Most Linux distros use Bash, but there's no guarantee yours does. To find out which shell you're running, open a terminal window and run this command:\necho $0\nThe output should be something like \"bash\" or \"-zsh\", identifying your specific shell.\nNext, you may not already have a .bashrc (or equivalent) file, depending on your distro. Try running the following:\nls -l ~/.*rc\nThis command will show you all hidden files in your home directory that end in \"rc\":\nIf you don't see .bashrc, you can create an empty file with that name. You can also copy a template from /etc/skel/.bashrc if you have it:\ncp /etc/skel/.bashrc ~/.bashrc\nThe startup process can be quite complicated, so you might want to read about the differences between .bashrc and .profile before you begin, or if you run into any problems.\nIn the general case, though, you can expect the .bashrc file to run when you open a new terminal, including a new window or tab.\n6 Things You Can Do With .bashrc\nBecause .bashrc is, itself, a Bash script, you can use it for many different purposes. The limit really is your imagination, but the following uses are common.\nRun neofetch and Alternatives\nSince .bashrc runs when you open a new terminal, it's a nice place to inject a bit of personality into your terminal. Anything that can act as a welcome message is a nice addition, and neofetch is one of the nicest:\nThe program shows some colorful ASCII art alongside information about your machine. Apart from being a nice way to begin your terminal session, it's useful for recognizing that you're on the machine you think you are\u2014especially useful if you often ssh out to remote machines.\nNeofetch is now discontinued, so although you can still use it, you might want to seek out a newer alternative that is being actively developed. Good alternatives include Fastfetch and screenFetch, which are drop-in replacements written in C and Bash script respectively, and onefetch which displays details of a git project you may be working on.\nWhichever tool you choose, it's easy to get it running via .bashrc. First, make sure the plain command works, e.g.\nneofetch\nThen simply add the same command to .bashrc:\nCustomize Your Prompt\nA more low-key way of customizing your terminal environment is by setting your prompt. This is the bit of text that Linux prints at the beginning of each line in your terminal, prompting you to type something.\nThe default is fairly useful, but you can customize the prompt to include almost anything. Using the built-in variables, you can include the hostname, user, date, and more. I like this setup:\nPS1=\"\\n[\\$PWD] \\$ \"\nThis adds an extra line which makes it clearer to spot where output from a previous command ends. It also removes the username and host which I don't really use.\nYour default .bashrc probably includes some PS1 configuration already. You can add yours afterward if you want, as I have here:\nSet Aliases to Make Commands Easier\nAliasing is another powerful customization that can make your terminal more pleasant to use. By setting an alias for a command, you can give it a more memorable name or one that's easier to type. You can also use aliases to make it easier to use common combinations of options.\nMy .bashrc sets several aliases for the ls command:\nAs with all environmental setup, aliases can be defined in several places, so it's worth checking the current aliases before you start, using the alias command on its own:\nCreate Shell Functions for Common Tasks\nEven more powerful than aliases, shell functions let you write your own mini-commands. If you define a shell function inside .bashrc, you can run it by typing its name, just like any other command.\nHere's a simple example that you might find saves you some time. It calls mkdir with the useful -p option which creates a full path, including new intermediate directories. It then changes to that new directory:\n# Create a new directory and enter it\nmkd() {\nmkdir -p \"$@\"\ncd \"$@\" || exit\n}\nThe real win here is that you can now use \"mkd\" as a substitute for \"mkdir\":\nDefine Environment Variables to Control Commands\nMany commands use either global or specific environment variables to alter their behavior. Common widely-recognized env vars include:\n- EDITOR which defines your editor program, should another program choose to open it.\n- PAGER which defines a program to use to display output taller than one screen.\n- BROWSER which defines your default web browser.\nBut command-specific variables can be just as useful. Take the pager, less, as an example. It supports a LESS variable which you can use to pass default options. For example:\nexport LESS=\"--quit-if-one-screen\"\nAdd this to your .bashrc and less will always act nicely, even with files shorter than one screen page. Many commands support similar environment variables that you can set in .bashrc to change their default behavior. Look for a section headed \"Environment\" or \"Environment Variables\" in each command's man page.\nModularize Your Environment by Sourcing Other Files\nOnce you get into shell customization, your .bashrc file can grow until it's quite unwieldy. Never mind: this is the perfect opportunity to learn about, and practice, modularization.\nSplitting one large file into several smaller ones can make the whole easier to manage, and can enable sharing for other purposes. A well-defined structure can make it easier for others to read, even if future-you is one of those others.\nThe skeleton bashrc that came with my distro explains how to do this, with clear comments:\nIn this case, a file at ~/.bash_aliases will be sourced (via the . command) if it exists. The effect will be exactly as if those aliases were directly included in your .bashrc."
    },
    {
      "url": "https://www.howtogeek.com/start-project-python-virtual-environments/",
      "text": "Summary\n- Virtual environments create isolated spaces for Python projects to prevent package conflicts and errors.\n- They create a separate folder with their own copy of Python and manage your system\u2019s PATH to switch between environments.\n- They help keep your global Python environment clean by preventing pollution with unnecessary packages that may not be needed for every project.\nStarting a Python project? As a developer, you'll often find yourself working on multiple projects. If that's the case for you, then virtual environments are your friend. They'll help you overcome package conflicts and dependency hell when working on multiple Python projects.\nWhat's a Virtual Environment?\nA virtual environment in the context of Python programming means a self-contained location that allows you to maintain separate and isolated environments for your Python projects. When activated, it adjusts your terminal's environment to use that isolated Python setup. Virtual environments let you use multiple versions of Python and other packages without one conflicting with the other. This process is consistent across operating systems like Windows, Linux, and macOS.\nTo use a virtual environment, you'll first create it, activate it, install the necessary packages for your project inside it, and, when you're done working on the project, finally deactivate the environment. (I'll cover all the steps in a bit.)\nWhen you first make a virtual environment, it creates a new folder in your project directory. The virtual environment lives inside this folder. A copy of the Python interpreter and some essential files are placed inside this folder. This copy acts as the main Python installation for your project. It also stores a Scripts (Windows) or bin (Linux) folder, which contains the activation and deactivation scripts, so you can switch between your global Python and isolated versions.\nAfter activating the environment, your shell's environment changes, making the command line use the Python interpreter and libraries inside the virtual environment. Behind the scenes, the environment's PATH variable is updated. The virtual environment's \"bin\" (\"Scripts\" on Windows) folder is added to the beginning of the PATH, which tells your terminal to look there first. Also, your prompt changes to reflect the update.\nWhen installing a Python package inside a virtual environment, it's typically installed inside the \"lib/pythonX.X/site-packages\" (\"Lib\\site-packages\" in Windows) folder instead of the global Python system. Each environment has its own \"site-packages\" directory, where all installed libraries and dependencies are kept. This keeps each project isolated and free from conflicts with other projects or global packages.\nWhy Use a Virtual Environment for Python Development?\nSuppose you're working on multiple Python projects at the same time. One of the projects is a bit old. Both projects require the Django module. However, the old project requires Django version 3 while the newer one requires Django version 4. At first thought, you may consider installing both versions on your system.\nHowever, that's not possible, and you'll receive an error if you try to do it. So, you can't install two different versions of the same package at the same time. Even if you manage to install it, the latter installed version will override the previously installed one. To add to that, when you import a package into your Python code, you can't define which version to use. So, that's another reason you can only have one version of a package at a time.\nNow, if you want to work on both projects, you'll have to first install a Django version, work on that project, then uninstall it, install the other version, switch to the other project, and so on. That's not at all practical. This is only a small example. You'll likely face much more complex dependency conflicts like this.\nVirtual environments solve this problem. You can create a new environment for each of your projects, install the required packages and dependencies, and not worry about any conflicts and errors. Here's a quick example where I've installed two different versions of NumPy for two different projects.\nFor this example, I've set up two virtual environments for two separate projects. Then I successfully installed two separate versions of NumPy. Here, projectA is using version 2.1.1 while projectB is using version 2.0.0.\nAnother advantage of using virtual environments is when you want to collaborate with others or share your projects. By using a 'requirements.txt' file, you can define all the dependencies, which can then be recreated in a new environment on another machine.\nHow to Create A Virtual Environment\nThe virtual environment is a directory you create where you hold all the project files and related packages. For demonstration, I'm first going to create a directory to set up the environment.\nmkdir programming\ncd programming\nInside this newly created directory, I'm going to create a virtual environment.\nLinux\nOn most Linux distros, Python usually comes pre-installed. If not, you can install Python on Linux using your package manager. Then install the virtual environment with this command:\nsudo apt install python3-venv\nAfter that, you can create virtual environments. You need to name the environment. Then run the command below:\npython3 -m venv my_virt_env\nIn my case, I named it 'my_virt_env.' You can choose any suitable name.\nWindows\nThe first thing you need to do is install Python on Windows. While installing, make sure to add Python.exe to your system PATH. Navigate to the folder where you want to create the virtual environment. Open your preferred command line tool and then run:\npython -m venv myenv\nActivating the Virtual Environment\nCreating a virtual environment isn't enough. You'll need to activate it using the activation file inside the folder to start using it. If you successfully activate the virtual environment, you'll notice the folder name inside the parentheses in your command line at the beginning of the prompt.\nLinux\nTo activate the virtual environment on Linux, run:\nsource my_virt_env/bin/activate\nRemember to use the same directory name you used for the virtual environment.\nNow that you've activated the virtual environment, you can install Python packages inside it, like this:\npython -m pip install package_name\nOnce you install some packages, you can check their versions with this command:\npip list\nIf you want to get out of the virtual environment, then run:\ndeactivate\nThe environment name inside the parentheses should disappear from the command line prompt.\nWindows\nTo activate the environment on Windows, run:\nmyenv\\Scripts\\activate # CMD\n.\\myenv\\Scripts\\Activate.ps1 # PowerShell\nTo install a package inside this environment, use this command:\npython -m pip install package_name\nYou can list the installed packages by running:\npip list\nIf you want to get out of the virtual environment, run:\ndeactivate\nWhen you deactivate the virtual environment, you'll return to your global Python setup.\nPython Package Headaches Gone\nWith a virtual environment set, you're ready to start coding in Python without worrying about different package versions, conflicts, and errors. For this guide, I've used the venv tool. There are other tools such as Virtualenv and Conda. You can feel free to explore them. If you're new to Python, start with the basics and build your first project."
    },
    {
      "url": "https://docs.python.org/3/library/index.html",
      "text": "The Python Standard Library\u00b6\nWhile The Python Language Reference describes the exact syntax and semantics of the Python language, this library reference manual describes the standard library that is distributed with Python. It also describes some of the optional components that are commonly included in Python distributions.\nPython\u2019s standard library is very extensive, offering a wide range of facilities as indicated by the long table of contents listed below. The library contains built-in modules (written in C) that provide access to system functionality such as file I/O that would otherwise be inaccessible to Python programmers, as well as modules written in Python that provide standardized solutions for many problems that occur in everyday programming. Some of these modules are explicitly designed to encourage and enhance the portability of Python programs by abstracting away platform-specifics into platform-neutral APIs.\nThe Python installers for the Windows platform usually include the entire standard library and often also include many additional components. For Unix-like operating systems Python is normally provided as a collection of packages, so it may be necessary to use the packaging tools provided with the operating system to obtain some or all of the optional components.\nIn addition to the standard library, there is an active collection of hundreds of thousands of components (from individual programs and modules to packages and entire application development frameworks), available from the Python Package Index.\n- Introduction\n- Built-in Functions\n- Built-in Constants\n- Built-in Types\n- Truth Value Testing\n- Boolean Operations \u2014\nand\n,or\n,not\n- Comparisons\n- Numeric Types \u2014\nint\n,float\n,complex\n- Boolean Type -\nbool\n- Iterator Types\n- Sequence Types \u2014\nlist\n,tuple\n,range\n- Text Sequence Type \u2014\nstr\n- Binary Sequence Types \u2014\nbytes\n,bytearray\n,memoryview\n- Set Types \u2014\nset\n,frozenset\n- Mapping Types \u2014\ndict\n- Context Manager Types\n- Type Annotation Types \u2014 Generic Alias, Union\n- Other Built-in Types\n- Special Attributes\n- Integer string conversion length limitation\n- Built-in Exceptions\n- Text Processing Services\nstring\n\u2014 Common string operationsre\n\u2014 Regular expression operationsdifflib\n\u2014 Helpers for computing deltastextwrap\n\u2014 Text wrapping and fillingunicodedata\n\u2014 Unicode Databasestringprep\n\u2014 Internet String Preparationreadline\n\u2014 GNU readline interfacerlcompleter\n\u2014 Completion function for GNU readline\n- Binary Data Services\n- Data Types\ndatetime\n\u2014 Basic date and time typeszoneinfo\n\u2014 IANA time zone supportcalendar\n\u2014 General calendar-related functionscollections\n\u2014 Container datatypescollections.abc\n\u2014 Abstract Base Classes for Containersheapq\n\u2014 Heap queue algorithmbisect\n\u2014 Array bisection algorithmarray\n\u2014 Efficient arrays of numeric valuesweakref\n\u2014 Weak referencestypes\n\u2014 Dynamic type creation and names for built-in typescopy\n\u2014 Shallow and deep copy operationspprint\n\u2014 Data pretty printerreprlib\n\u2014 Alternaterepr()\nimplementationenum\n\u2014 Support for enumerationsgraphlib\n\u2014 Functionality to operate with graph-like structures\n- Numeric and Mathematical Modules\n- Functional Programming Modules\n- File and Directory Access\npathlib\n\u2014 Object-oriented filesystem pathsos.path\n\u2014 Common pathname manipulationsstat\n\u2014 Interpretingstat()\nresultsfilecmp\n\u2014 File and Directory Comparisonstempfile\n\u2014 Generate temporary files and directoriesglob\n\u2014 Unix style pathname pattern expansionfnmatch\n\u2014 Unix filename pattern matchinglinecache\n\u2014 Random access to text linesshutil\n\u2014 High-level file operations\n- Data Persistence\n- Data Compression and Archiving\n- File Formats\n- Cryptographic Services\n- Generic Operating System Services\nos\n\u2014 Miscellaneous operating system interfacesio\n\u2014 Core tools for working with streamstime\n\u2014 Time access and conversionslogging\n\u2014 Logging facility for Pythonlogging.config\n\u2014 Logging configurationlogging.handlers\n\u2014 Logging handlersplatform\n\u2014 Access to underlying platform\u2019s identifying dataerrno\n\u2014 Standard errno system symbolsctypes\n\u2014 A foreign function library for Python\n- Command-line interface libraries\nargparse\n\u2014 Parser for command-line options, arguments and subcommandsoptparse\n\u2014 Parser for command line optionsgetpass\n\u2014 Portable password inputfileinput\n\u2014 Iterate over lines from multiple input streamscurses\n\u2014 Terminal handling for character-cell displayscurses.textpad\n\u2014 Text input widget for curses programscurses.ascii\n\u2014 Utilities for ASCII characterscurses.panel\n\u2014 A panel stack extension for cursescmd\n\u2014 Support for line-oriented command interpreters\n- Concurrent Execution\nthreading\n\u2014 Thread-based parallelismmultiprocessing\n\u2014 Process-based parallelismmultiprocessing.shared_memory\n\u2014 Shared memory for direct access across processes- The\nconcurrent\npackage concurrent.futures\n\u2014 Launching parallel taskssubprocess\n\u2014 Subprocess managementsched\n\u2014 Event schedulerqueue\n\u2014 A synchronized queue classcontextvars\n\u2014 Context Variables_thread\n\u2014 Low-level threading API\n- Networking and Interprocess Communication\n- Internet Data Handling\nemail\n\u2014 An email and MIME handling packagejson\n\u2014 JSON encoder and decodermailbox\n\u2014 Manipulate mailboxes in various formatsmimetypes\n\u2014 Map filenames to MIME typesbase64\n\u2014 Base16, Base32, Base64, Base85 Data Encodingsbinascii\n\u2014 Convert between binary and ASCIIquopri\n\u2014 Encode and decode MIME quoted-printable data\n- Structured Markup Processing Tools\nhtml\n\u2014 HyperText Markup Language supporthtml.parser\n\u2014 Simple HTML and XHTML parserhtml.entities\n\u2014 Definitions of HTML general entities- XML Processing Modules\nxml.etree.ElementTree\n\u2014 The ElementTree XML APIxml.dom\n\u2014 The Document Object Model APIxml.dom.minidom\n\u2014 Minimal DOM implementationxml.dom.pulldom\n\u2014 Support for building partial DOM treesxml.sax\n\u2014 Support for SAX2 parsersxml.sax.handler\n\u2014 Base classes for SAX handlersxml.sax.saxutils\n\u2014 SAX Utilitiesxml.sax.xmlreader\n\u2014 Interface for XML parsersxml.parsers.expat\n\u2014 Fast XML parsing using Expat\n- Internet Protocols and Support\nwebbrowser\n\u2014 Convenient web-browser controllerwsgiref\n\u2014 WSGI Utilities and Reference Implementationurllib\n\u2014 URL handling modulesurllib.request\n\u2014 Extensible library for opening URLsurllib.response\n\u2014 Response classes used by urlliburllib.parse\n\u2014 Parse URLs into componentsurllib.error\n\u2014 Exception classes raised by urllib.requesturllib.robotparser\n\u2014 Parser for robots.txthttp\n\u2014 HTTP moduleshttp.client\n\u2014 HTTP protocol clientftplib\n\u2014 FTP protocol clientpoplib\n\u2014 POP3 protocol clientimaplib\n\u2014 IMAP4 protocol clientsmtplib\n\u2014 SMTP protocol clientuuid\n\u2014 UUID objects according to RFC 4122socketserver\n\u2014 A framework for network servershttp.server\n\u2014 HTTP servershttp.cookies\n\u2014 HTTP state managementhttp.cookiejar\n\u2014 Cookie handling for HTTP clientsxmlrpc\n\u2014 XMLRPC server and client modulesxmlrpc.client\n\u2014 XML-RPC client accessxmlrpc.server\n\u2014 Basic XML-RPC serversipaddress\n\u2014 IPv4/IPv6 manipulation library\n- Multimedia Services\n- Internationalization\n- Graphical user interfaces with Tk\ntkinter\n\u2014 Python interface to Tcl/Tktkinter.colorchooser\n\u2014 Color choosing dialogtkinter.font\n\u2014 Tkinter font wrapper- Tkinter Dialogs\ntkinter.messagebox\n\u2014 Tkinter message promptstkinter.scrolledtext\n\u2014 Scrolled Text Widgettkinter.dnd\n\u2014 Drag and drop supporttkinter.ttk\n\u2014 Tk themed widgets- IDLE \u2014 Python editor and shell\nturtle\n\u2014 Turtle graphics\n- Development Tools\ntyping\n\u2014 Support for type hintspydoc\n\u2014 Documentation generator and online help system- Python Development Mode\ndoctest\n\u2014 Test interactive Python examplesunittest\n\u2014 Unit testing frameworkunittest.mock\n\u2014 mock object libraryunittest.mock\n\u2014 getting startedtest\n\u2014 Regression tests package for Pythontest.support\n\u2014 Utilities for the Python test suitetest.support.socket_helper\n\u2014 Utilities for socket teststest.support.script_helper\n\u2014 Utilities for the Python execution teststest.support.bytecode_helper\n\u2014 Support tools for testing correct bytecode generationtest.support.threading_helper\n\u2014 Utilities for threading teststest.support.os_helper\n\u2014 Utilities for os teststest.support.import_helper\n\u2014 Utilities for import teststest.support.warnings_helper\n\u2014 Utilities for warnings tests\n- Debugging and Profiling\n- Software Packaging and Distribution\n- Python Runtime Services\nsys\n\u2014 System-specific parameters and functionssys.monitoring\n\u2014 Execution event monitoringsysconfig\n\u2014 Provide access to Python\u2019s configuration informationbuiltins\n\u2014 Built-in objects__main__\n\u2014 Top-level code environmentwarnings\n\u2014 Warning controldataclasses\n\u2014 Data Classescontextlib\n\u2014 Utilities forwith\n-statement contextsabc\n\u2014 Abstract Base Classesatexit\n\u2014 Exit handlerstraceback\n\u2014 Print or retrieve a stack traceback__future__\n\u2014 Future statement definitionsgc\n\u2014 Garbage Collector interfaceinspect\n\u2014 Inspect live objectssite\n\u2014 Site-specific configuration hook\n- Custom Python Interpreters\n- Importing Modules\nzipimport\n\u2014 Import modules from Zip archivespkgutil\n\u2014 Package extension utilitymodulefinder\n\u2014 Find modules used by a scriptrunpy\n\u2014 Locating and executing Python modulesimportlib\n\u2014 The implementation ofimport\nimportlib.resources\n\u2013 Package resource reading, opening and accessimportlib.resources.abc\n\u2013 Abstract base classes for resourcesimportlib.metadata\n\u2013 Accessing package metadata- The initialization of the\nsys.path\nmodule search path\n- Python Language Services\nast\n\u2014 Abstract Syntax Treessymtable\n\u2014 Access to the compiler\u2019s symbol tablestoken\n\u2014 Constants used with Python parse treeskeyword\n\u2014 Testing for Python keywordstokenize\n\u2014 Tokenizer for Python sourcetabnanny\n\u2014 Detection of ambiguous indentationpyclbr\n\u2014 Python module browser supportpy_compile\n\u2014 Compile Python source filescompileall\n\u2014 Byte-compile Python librariesdis\n\u2014 Disassembler for Python bytecodepickletools\n\u2014 Tools for pickle developers\n- MS Windows Specific Services\n- Unix-specific services\nshlex\n\u2014 Simple lexical analysisposix\n\u2014 The most common POSIX system callspwd\n\u2014 The password databasegrp\n\u2014 The group databasetermios\n\u2014 POSIX style tty controltty\n\u2014 Terminal control functionspty\n\u2014 Pseudo-terminal utilitiesfcntl\n\u2014 Thefcntl\nandioctl\nsystem callsresource\n\u2014 Resource usage informationsyslog\n\u2014 Unix syslog library routines\n- Modules command-line interface (CLI)\n- Superseded Modules\n- Removed Modules\n- Security Considerations"
    },
    {
      "url": "https://www.howtogeek.com/how-to-set-up-a-development-environment-with-mamba/",
      "text": "Quick Links\nIf you're a programmer, particularly in data science or analysis, you've probably suffered headaches over the packages included in a Linux distribution. What if there were a way you could have a separate programming environment for your projects that was isolated from the system without having to set up a virtual machine? Mamba might be what you need.\nWhat Is Mamba?\nMamba is a package manager that's intended for per-project use. It's similar to a package manager that you find on a modern Linux system, but instead of managing software packages for the whole system, you create environments just for the packages you need for your project. Mamba is a reimplementation of the Conda package manager. Conda was originally written in Python, but Mamba was rewritten in C++ for extra speed.\nMamba, like Conda, is popular for data science, statistics, biostatistics, and data analysis. It seems to have an affinity with Python, given the snake-themed naming. The name seems to be chosen for the speed of the namesake snake, as Mamba is a faster version of Conda.\nMamba does a lot of the things you would expect a package manager to do, such as searching for packages, installing them, and keeping them updated. You create environments that you can activate or deactivate at will when you want to. You can install multiple environments on the same machine.\nWhy Mamba?\nIf you're using a Linux or other Unix-like system for development, you might wonder why you'd need something like Mamba. Don't you already have a package manager?\nThe software that's installed in a package manager is meant for the system as a whole. Many systems include a Python interpreter, but that's intended to run scripts and other programs that depend on Python, and not so much to support your programming projects. If you need a newer version of Python for your own code than the system supplies and you upgrade it, other scripts and programs that depend on the version supplied with your system might break.\nAPT vs Snap vs Flatpak: Ubuntu Package Managers Explained (and When to Use Each)\nIf there's one thing you get with Linux distros, it's choice.\nMamba solves this problem by letting you create environments for a task that are isolated from the underlying system. If you're working in data science or analytics, you can define an environment just for your work while leaving the base system untouched. You can activate your environment when you want to run some calculations and turn it off when you're finished.\nI've used Mamba for several pieces on HTG, including a recent one on building a laptop price predictor.\nInstalling Mamba\nInstalling Mamba is pretty simple in most Unix-like systems. I'll demonstrate installing Mamba on a Debian Linux system.\nYou can follow some simple instructions to download and install Mamba right from the Mamba documentation page. First, you'll want to download the Miniforge distribution. This is a minimal version of Mamba that has all the basic files you need to get started.\nAssuming you have curl installed, all you have to do is paste in a line to download it on a Unix-like system:\ncurl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nAfter you've downloaded it, you can now run the installation script:\nbash Miniforge3-$(uname)-$(uname -m).sh\nThe script will ask you to press Enter if you want to continue, then review some licensing terms. Since Mamba is open source, this probably won't be a problem for you. You'll have to type \"yes\" or \"no\" to accept or decline the licensing terms. To accept and continue with installation, type \"yes\" at the prompt.\nAfter that, you'll have to confirm the directory where you want to install your Conda packages. By default, it will be in your home directory with a \"miniforge\" subdirectory.\nWhen miniforge is installed, you'll then get a prompt to edit your shell's default startup script, such as .bashrc or .zshrc, depending on which shell you're using, to start Mamba up automatically when you start a shell. You'll probably want this if you plan on working with Mamba extensively. This'll make it easier to activate and deactivate Mamba environments. Type \"yes\" again to confirm it.\nCreate an Environment\nWhen you open a new terminal, you may have noticed something different about your shell prompt. You'll see something that says \"(base)\". This means that Mamba has been activated with the base environment. That's exactly what it sounds like: a minimal base environment. You can check this by typing \"python\" at the prompt. In the introduction message, you can see that this version of Python was \"packaged by conda-forge.\"\nYou can install other packages into this base environment, but you don't want to. The point of Mamba is to have all the packages you need in one environment, and others you need for a different project in another environment.\nIt's easy to create environments. To create an environment, you use the mamba create command with the \"-n\" option followed by the name of the environment you wish to create, then the list of packages you want to install in this environment.\nFor example, to create an environment for statistical computing named \"stats\" with the NumPy, SciPy, and pandas Python packages, use this command:\nmamba create -n stats numpy scipy pandas\nLike any other package manager, it will determine the packages and their dependencies, and finally ask you to confirm their installation. Since the installation is done in your home directory, you don't need to use sudo or supply a root password.\nTo activate the stats environment, use the \"mamba activate\" command:\nmamba activate stats\nYou'll see the name of the active environment change from \"base\" to \"stats\" in the prompt. You can now use the packages you installed in this environment.\nLet's test this out by running the Python interactive interpreter.\nWe can import NumPy and have it work.\nimport numpy as np\nnp.mean([1,2,3,4])\nIt will report the answer as a floating-point number of 2.5.\nInstalling Extra Packages\nA lot of the time, you realize you might want to add packages to your existing environment. For example, I like the IPython interpreter over the standard interpreter. I can add it in one of two ways.\nLinux Terminal for Beginners: How to Install and Remove Software\nLet me turn you into a Linux terminal power user!\nI can add it using the -n option with \"mamba install\"\nmamba install -n ipython\nI can also run \"mamba install\" within an active environment to install the package in that environment. Since \"stats\" is already active, I'll do that. It'll ask me to confirm the changes and then install IPython.\nI can run IPython at the shell:\nipython\nTo deactivate an environment when I'm done with it, I can use the \"mamba deactivate\" command. To prove that IPython was installed into the \"stats\" environment, when I try to run it, I get the \"command not found\" error after deactivation.\nTo find packages, you can use either the \"mamba search\" or \"mamba repoquery\" search commands.\nFor example, to find packages relating to Jupyter, a popular notebook interface for scientific computing:\nmamba search jupyter\nUpdating Mamba Environments\nAs with other package managers, Mamba is handy at keeping packages updated as new versions become available. You can use the \"mamba update\" command.\nFor example, to update all the packages in the stats environment:\nmamba update --all -n stats\nAlternatively, you can use \"--update-all\" instead of \"--all\" in the command, but the latter is shorter. Since this is a fresh install, there's nothing to update when I run this command.\nWith Mamba, you can create environments suited to your programming projects, activate and deactivate them, and update them at will. It might seem strange having a package manager on top of your package manager, but using Mamba will make your programming project go much more smoothly."
    }
  ],
  "argos_summary": "The article explains how Python developers can leverage libraries and package managers to streamline coding, highlighting the benefits of built\u2011in modules, third\u2011party packages, and virtual environments. It covers installation methods for libraries via pip, conda, and the faster Mamba, and demonstrates how to create, activate, and manage isolated project environments. The piece also details best practices for environment isolation, dependency management, and the use of tools like virtualenv, venv, and Mamba to avoid package conflicts. Overall, it serves as a practical guide for setting up reproducible Python workflows and maintaining clean system installations.",
  "argos_id": "FPRXGG55P"
}