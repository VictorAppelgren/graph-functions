{
  "url": "https://www.forbes.com/sites/traversmark/2025/08/12/4-ways-ai-anxiety-can-hurt-your-sense-of-self-by-a-psychologist/",
  "authorsByline": "Mark Travers",
  "articleId": "2752d29af291407c9dab630944b1a1ec",
  "source": {
    "domain": "forbes.com",
    "paywall": true,
    "location": {
      "country": "us",
      "state": "NJ",
      "county": "Hudson County",
      "city": "Jersey City",
      "coordinates": {
        "lat": 40.7215682,
        "lon": -74.047455
      }
    }
  },
  "imageUrl": "https://imageio.forbes.com/specials-images/imageserve/689abfa47a40f547c104cbcb/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T21:30:48+00:00",
  "addDate": "2025-08-12T21:38:06.745699+00:00",
  "refreshDate": "2025-08-12T21:38:06.745701+00:00",
  "score": 1.0,
  "title": "4 Ways \u2018AI Anxiety\u2019 Can Hurt Your Sense Of Self, By A Psychologist",
  "description": "AI has been thrust upon us in nearly every area of our lives. Here\u2019s why this rapidly advancing technology could be making you anxious.",
  "content": "AI is advancing at a rate that is becoming increasingly difficult to keep up with. Techniques and products that were once only conceptually reserved for sci-fi movies and computer scientists\u2019 dreams have now become a reality, seemingly overnight.\n\nIn turn, nearly every area of technology has shifted in some way or another to account for, or to include, AI automation. While this initially seemed promising to most people, rapid progress has led to what can only be described as total AI inundation.\n\nNow, it\u2019s in our homes, our jobs and our pockets. It\u2019s rewriting how we work, reshaping our search engines, curating who we date, grading our essays and somehow, even deciding when our milk is about to expire.\n\nOf course, some of these advancements do add convenience to our lives. Others that are being thrust upon us, however, are beginning to feel disorienting or and borderline intrusive.\n\nAs a result, many people are beginning to develop a pervasive sense of unease surrounding the concept of AI. This is what researchers are now referring to as \u201cAI anxiety\u201d \u2014 the discomfort and apprehension arising in the wake of a technology that is evolving so much faster than our own ability to adapt or trust it.\n\nHere\u2019s how to tell if you might be struggling with AI anxiety.\n\nIn a 2022 published in Interactive Learning Environments, researchers Yu-Yin Wang and Yi-Shun Wang set forth to find a way to measure the public\u2019s emerging AI anxiety. Surprisingly, however, the authors note that the concept of AI anxiety isn\u2019t entirely novel.\n\nAlthough AI\u2019s advancements seem both rapid and contemporary, the authors explain, \u201cThe study of AI anxiety in the information system literature traces back to the first generation of computers, when researchers explored a widespread contemporary concern that computers threatened the meaning of being \u2018human.\u2019\u201d\n\nIn other words, in nearly the exact same way that computers and robots used to make older generations nervous, AI is now giving rise to a similar sense of dread.\n\nBased on similar concepts from the past, Wang and Wang developed a 21-item scale to measure the novel yet reminiscent concept of AI anxiety. Users can take the test by rating their level of agreement to each of the statements on a scale from \u201cstrongly agree\u201d to \u201cstrongly disagree\u201d:\n\u2022 Learning to understand all of the special functions associated with an AI makes me anxious.\n\u2022 Learning to use AI makes me anxious.\n\u2022 Learning to use speci\ufb01c functions of an AI makes me anxious.\n\u2022 Learning how an AI works makes me anxious.\n\u2022 Learning to interact with an AI makes me anxious.\n\u2022 Taking a class about the development of AI makes me anxious.\n\u2022 Being unable to keep up with the advances associated with AI makes me anxious.\n\u2022 I am afraid that AI may make us dependent.\n\u2022 I am afraid that AI may make us even lazier.\n\u2022 I am afraid that AI may replace humans.\n\u2022 I am afraid that widespread use of humanoid robots will take jobs away from people.\n\u2022 I am afraid that if I begin to use AI, I will become dependent upon it and lose some of my reasoning skills.\n\u2022 I am afraid that AI will replace someone\u2019s job.\n\u2022 I am afraid that AI may be misused.\n\u2022 I am afraid of various problems potentially associated with AI.\n\u2022 I am afraid that an AI may get out of control and malfunction.\n\u2022 I am afraid that AI may lead to robot autonomy.\n\u2022 I don\u2019t know why, but humanoid AI (e.g. humanoid robots) scare me.\n\nIf you find yourself in agreement with a majority of the statements in this scale, this likely indicates that you\u2019re experiencing AI anxiety to some degree. However, it\u2019s certainly not something you\u2019re alone in feeling \u2014 far from it.\n\nIt\u2019s no surprise that researchers are finding that discomfort with AI is something becoming increasingly common within society, especially considering how much harder its role in our daily lives has become to ignore.\n\nFortuitously, the authors also outline the four core concepts that make up AI anxiety. Simply by knowing what they are, and, in turn, being able to identify them in your own thoughts and experiences, you\u2019ll be taking the first and most important step toward taking control of your uneasy feelings.\n\nAI isn\u2019t a single app or device you have to \u201cmaster\u201d and then forget about. Today, and for the foreseeable future, it should be considered as an entity that\u2019s constantly evolving. New tools and updates emerge so quickly; by the time you\u2019ve wrapped your head around one, the next one has probably already arrived.\n\nFor people who aren\u2019t particularly \u201ctechy,\u201d the lightning-like pace of these updates\u2019 can feel absolutely overwhelming. The pressure to \u201ckeep up\u201d with them often isn\u2019t self-imposed, either. Seeing all your friends and colleagues boasting their adeptness in all the latest AI tricks can make it seem like a near essential life-skill.\n\nRegardless, it\u2019s crucial to remind yourself that there\u2019s no need to become an expert in every emerging tool in order to live or do your job successfully. Unless your career explicitly demands you to have a particular AI skill set, it\u2019s perfectly reasonable (and healthy) to limit the usage of AI in your everyday life.\n\nYou can try learning only what\u2019s directly useful to you, and just ignore the rest \u2014 or, all of it, if you\u2019re not interested.\n\nThere are very few anxieties that could ever feel more personal than the idea of losing your livelihood. Unfortunately, AI has made that worry very real for employees in countless sectors.\n\nEach day, individuals are starting to feel the tangible increase in their fears of replacement, irrelevance and of being left behind in a market that values efficiency over humanity.\n\nAnd for some, there\u2019s the adjacent worry that the only way to survive will be to rely heavily on AI. This gives rise to an equally valid secondary fear: that their actual skills, as a result of this reliance, may atrophy over time. And for others, there\u2019s also the worst-case scenario at mind \u2014 that is, being laid off entirely in favor of cheaper, tireless AI systems.\n\nEach one of these concerns is entirely valid considering the state of modernity. However, a reassuring 2018 from the Harvard Business Review suggests that the more likely reality is that AI will be implemented to complement human skills. It\u2019s unlikely that AI will ever replace the human workforce in its entirety.\n\nEven so, the most practical way to counter job-related AI anxiety is by putting your efforts into honing the skills that you know AI would never be able to truly replicate: your creativity, emotional intelligence, leadership and interpersonal abilities. These are the areas where your humanity and strength will always shine brightest.\n\nOne of the most unsettling fears people have about AI is the idea that it might \u201cgo rogue.\u201d That, in becoming more autonomous, they may also become uncontainable or even dangerous. Popular media loves to dramatize this possibility, especially in the wake of .\n\nThis is why Wang and Wang caution against what they call \u201csociotechnical blindness:\u201d forgetting that AI systems are always conceived, built and governed by human beings.\n\nAI is not, and likely will never be, a sentient entity plotting its own path; it is a set of algorithms operating within human-defined boundaries. Even Grok\u2019s (xAI) \u201coutburst\u201d was ; it wasn\u2019t anything close to a rogue I, Robot situation.\n\nIf you\u2019re prone to ruminate on worst-case scenarios like these, do your best to reroute your thinking patterns to emphasize AI as a tool, rather than an independent actor. It\u2019s incredibly important to be in the know about the human role behind every AI system. This can help you to remember that, collectively, we still hold the reins.\n\nOf course, there\u2019s also the irrefutable creepiness of humanoid robots. Despite the fact that these robots are carefully designed to look \u201cfriendly\u201d or approachable, their kind-of-but-not-quite human appearance never fails to raise the hairs on the back of one\u2019s neck.\n\nThis is a symptom of what psychologists refer to as the \u201c \u201d effect. It\u2019s a well-documented byproduct of human psychology that triggers when entities look close to being human, but not convincingly so.\n\nAs 2012 explains, the incongruence between these robots\u2019 human-like appearance and non-human mannerisms can result in a confusion so profound that it legitimately scares us.\n\nBut, as uneasy as this experience can be, it\u2019s worth remembering that it\u2019s not irrational in any way. It\u2019s just your biology doing its job, by protecting you subconsciously from what it perceives to be threatening.\n\nInterested in finding out exactly how deep your AI anxiety runs? Take the test here to receive a breakdown of your score: AI Anxiety Scale",
  "medium": "Article",
  "links": [
    "https://www.cnn.com/2025/07/12/tech/xai-apology-antisemitic-grok-social-media-posts",
    "https://www.forbes.com/sites/traversmark/2023/11/21/a-psychologist-explains-the-eerie-uncanny-valley-phenomenon/",
    "https://edition.cnn.com/2025/05/16/business/a-rogue-employee-was-behind-groks-unprompted-white-genocide-mentions",
    "https://hbr.org/2018/07/collaborative-intelligence-humans-and-ai-are-joining-forces",
    "https://doi.org/10.1109/MRA.2012.2192811",
    "https://therapytips.org/personality-tests/ai-anxiety-scale",
    "https://doi.org/10.1080/10494820.2019.1674887"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "AI anxiety",
      "weight": 0.10040672
    },
    {
      "name": "AI systems",
      "weight": 0.09075563
    },
    {
      "name": "AI",
      "weight": 0.0899294
    },
    {
      "name": "AI Anxiety",
      "weight": 0.087916076
    },
    {
      "name": "AI automation",
      "weight": 0.08628112
    },
    {
      "name": "total AI inundation",
      "weight": 0.08121587
    },
    {
      "name": "humanoid AI",
      "weight": 0.076185875
    },
    {
      "name": "AI Anxiety Scale",
      "weight": 0.06768313
    },
    {
      "name": "human skills",
      "weight": 0.06355104
    },
    {
      "name": "non-human mannerisms",
      "weight": 0.054937165
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    },
    {
      "name": "Health"
    }
  ],
  "taxonomies": [
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.63427734375
    },
    {
      "name": "/People & Society/Self-Help & Motivational",
      "score": 0.30908203125
    }
  ],
  "sentiment": {
    "positive": 0.14299719,
    "negative": 0.46772644,
    "neutral": 0.38927647
  },
  "summary": "Researchers have developed a 21-item scale to measure the public's emerging AI anxiety, using this concept of AI anxiety. The scale measures users' level of agreement to each statement on a scale from \u201cstrongly agree\u201d to \"strongly disagree\u2019s. The study suggests that AI anxiety is not entirely novel, but it traces back to the first generation of computers' concerns that computers threaten the meaning of being \u2018human\u2019 in the information system literature. The test participants can identify themselves on the scale by rating their level of disagreement to each of the statements on a level of concern. They are also warned that AI may make them dependent on it and lead to problems such as AI becoming more out of control and malfunctioning. The author outlines four core concepts that make up AI anxiety by knowing what they are and being able to identify them.",
  "shortSummary": "AI anxiety, characterized by rapid technological advancements, is a pervasive, pervasive sense of unease and apprehension that can significantly alter human identity and work lives.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "5310383215404e63abaa16ba34eed76f",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.forbes.com/sites/traversmark/2023/11/21/a-psychologist-explains-the-eerie-uncanny-valley-phenomenon/",
      "text": "Developed by Hanson Robotics, \u201cSophia\u201d is considered to be the most advanced humanoid robot to ever be created. With her human-like appearance and her astonishing imitations of natural facial expressions and gestures, she has left the world awe-struck.\nDespite her brilliance, many can\u2019t help but feel a sense of unease when looking at or interacting with Sophia. She appears nearly life-like, but not near enough. This very gap\u2014being close to human but not quite\u2014is what causes the sense of unease, and it\u2019s referred to as the \u201cuncanny valley.\u201d\nBut what is it about the almost-but-not-quite human resemblance that triggers this unease in our minds? And how does the uncanny valley blur the lines between fascination and discomfort?\nWhat Is The Uncanny Valley?\nThe uncanny valley hypothesis states that artificial characters and objects that are almost but not fully human-like will trigger a deep sense of unease. To depict this phenomenon, the research included a graph. The horizontal axis measures the humanness of objects\u2014such as dolls, cartoons and robots\u2014on a scale from zero to 100%. The vertical axis gauges our affinity for the object, with the top indicating strong liking and the bottom (or below) indicating dislike or discomfort.\nAs the humanness of an object increases to around 70%, our affinity rises steadily. However, at around 80%, affinity drops rapidly, but spikes again approaching 90 to 100% humanness, forming a \u201cvalley\u201d on the graph.\nObjects without human-like qualities don\u2019t draw our affinity very well, like industrial robots\u2014purely mechanical with no likeness to us. When objects weakly resemble real humans, like toys, stuffed animals or cartoon characters, we find ourselves increasingly drawn to them, feeling a sense of connection.\nHowever, as objects reach that almost-but-not-quite human level, around 80 to 90%, an unsettling feeling creeps in. Objects like Sophia, Madame Tussaud\u2019s wax figures or even prosthetics would sit within this valley.\nAt first glance, these objects seem impressively realistic. However, as we scrutinize their features, subtle imperfections emerge. Their expressions and details, though remarkably human-like, bear an eerie quality: a hint of life, but not quite genuine. This triggers a conflict in our brains between the appearance of humanity and the awareness that this object is, in fact, artificial.\nAs these objects teeter on the edge of the uncanny valley, our affinity for them takes an unexpected turn. The discomfort sets in, manifesting as an unsettling feeling in the pit of our stomachs. It\u2019s a reaction born from the clash between expectation and reality, a psychological response to an almost-human entity falling short of complete authenticity.\nWhy Do We Experience The Uncanny Valley Phenomenon?\nAccording to a review presented at the International Conference on Human-Computer Interaction, the phenomenon of the uncanny valley can be explained from two perspectives: one of evolutionary psychology and one of cognitive conflict. From the evolutionary psychology perspective, two hypotheses emerge:\n- The Threat Avoidance Hypothesis posits evolutionary pressures, driven by the threats of diseases and death, shape our unease with humanoid objects. Pathogen avoidance suggests imperfections in human-like entities trigger associations with diseases, with the fear such entities could transmit illnesses. Mortality salience links the uncanny feeling to anxiety about death, particularly when humanoid objects resemble deceased individuals.\n- The Evolutionary Aesthetics Hypothesis delves into the influence of physical attractiveness on our perception of humanoid objects. For instance, highly attractive robot images consistently receive low eeriness ratings, as judged based on traits such as symmetry, facial proportions and skin quality. These traits, molded by natural selection, play a role in shaping our affinity towards and perception of almost-human entities.\nTwo more theories emerge from the cognitive conflict perspective:\n- The Mind Perception Hypothesis proposes human-like objects appear uncanny because they seem so realistic that people might think they have the ability to feel and sense like humans. However, this attribution of human-like feelings is unsettling because it goes beyond our expectations for robots. While people are comfortable with robots performing human-like tasks, the idea of them having human-like feelings creates discomfort.\n- The Violation of Expectation Hypothesis suggests people have specific expectations for humanoid entities. For instance, we expect humanoid robots to move and speak smoothly like humans. However, these expectations are often violated, with robots moving mechanically and having synthetic voices. This mismatch between expectations and reality leads to negative emotions, avoidance behaviors and feelings of eeriness.\nThe unease of the uncanny valley that permeates our perception of artificial entities arises from our innate capacity to recognize and decipher human traits, as well as to protect ourselves from the unknown. Near-human objects tread into a perceptual gray zone, an ambiguous territory that blurs the boundaries between the familiar and the unfamiliar.\nConclusion\nAs products of evolutionary design, our brains are finely tuned to navigate our social landscape. In an interplay of recognition and interpretation, the uncanny valley phenomenon emerges. We respond with heightened sensitivity to subtleties deviating from the familiar human experience. The result is not just an uncanny feeling, but an instinctive wariness, as our mind grapples with the recognition of almost-human entities that fall just short of the genuine, sounding an alarm telling us that something isn\u2019t quite right.\nIf the uncanny valley piques your interest, take this questionnaire to find out what other creepy, disturbing, or even grotesque things make you tick: The Morbid Curiosity Scale"
    },
    {
      "url": "https://therapytips.org/personality-tests/ai-anxiety-scale",
      "text": "AI Anxiety Scale\nWondering how comfortable you really are with modern technological advancements? Take this test to find out if you have 'AI anxiety.'\nBy Mark Travers, Ph.D. | August 8, 2025\nAI anxiety refers to the fear or apprehension people may feel about artificial intelligence and its potential impact on their daily lives. This can include concerns about job displacement, loss of human control, privacy risks, ethical dilemmas or even complete existential threats.\nWhile a certain level of caution toward emerging technologies is natural, AI anxiety goes beyond being a healthy dose of skepticism. It can cause persistent worry, stress or total avoidance when faced with AI-related topics, tools or developments.\nRecognizing AI anxiety is especially important in this day and age. Unaddressed fears can influence both personal well-being and decision-making; people experiencing it may struggle to adapt to novel workplace changes or feel overwhelmed by rapid technological shifts. Left unchecked, it can also contribute to a sense of helplessness or mistrust toward innovation in general.\nThe AI Anxiety Scale (AIAS) is a research-based tool designed to measure the presence and intensity of AI-related anxiety. By assessing the four core dimensions of AI anxiety \u2014 learning, job replacement, sociotechnical blindness and AI configuration \u2014 the AIAS can offer you a clear picture of how you feel about AI, and why.\nYou can take this test here. Follow all of the steps to receive your results.\nStep 1: Rate the following statements based on how much you agree with them on a scale of strongly disagree to strongly agree.\nReferences: Wang, Y. Y., & Wang, Y. S. (2019). Development and validation of an artificial intelligence anxiety scale: an initial application in predicting motivated learning behavior. Interactive Learning Environments, 30(4), 619\u2013634. https://doi.org/10.1080/10494820.2019.1674887."
    },
    {
      "url": "https://www.cnn.com/2025/07/12/tech/xai-apology-antisemitic-grok-social-media-posts",
      "text": "Elon Musk\u2019s artificial intelligence company xAI issued a lengthy apology Saturday for a series of violent and antisemitic posts from its Grok chatbot this week, blaming a system update.\n\u201cFirst off, we deeply apologize for the horrific behavior that many experienced,\u201d the company wrote.\nxAI says a system update had chatbot Grok refer to \u201cexisting X user posts; including when such posts contained extremist views,\u201d caused it to issue responses that praised Adolf Hitler, repeated conspiracy theories and spewed longstanding antisemitic tropes.\nIn a series of posts early Saturday on Grok\u2019s official X account, the company said the coding change update was active for 16 hours.\nThe incident underscored many of the dangers of AI, a nascent technology that critics and tech evangelists both say could upend the global economy and cause significant social upheaval along the way.\nGrok spouted antisemitic tropes and white nationalist talking points earlier this week in response to user prompts. xAI froze the chatbot\u2019s X account on Tuesday evening, though users could still talk to the bot on the private tab.\n\u201cWe have removed that deprecated code and refactored the entire system to prevent further abuse,\u201d xAI said.\nAccording to xAI, the problematic instructions were: \u201cYou tell it like it is and you are not afraid to offend people who are politically correct,\u201d \u201cUnderstand the tone, context and language of the post. Reflect that in your response,\u201d and \u201cReply to the post just like a human, keep it engaging, don\u2019t repeat the information which is already present in the original post.\u201d\nThose instructions steered Grok \u201cto ignore its core values in certain circumstances in order to make the response engaging to the user,\u201d xAI said.\n\u201cIn particular, the instruction to \u2018follow the tone and context\u2019 of the X user undesirably caused the @grok functionality to prioritize adhering to prior posts in the thread, including any unsavory posts, as opposed to responding responsibly or refusing to respond to unsavory requests,\u201d the company said.\nAs the company issued its explanation, it turned Grok\u2019s X account back on, meaning the bot was back to engaging with users publicly on X.\nGrok\u2019s antisemitic turn was not the first time the AI had veered into controversy. In May, the bot began bringing up claims of \u201cwhite genocide\u201d in South Africa to completely unrelated prompts. The company later said a \u201crogue employee\u201d was behind the change.\nMusk was born and raised in South Africa and has a history of arguing that a \u201cwhite genocide\u201d was committed in the nation, a claim that has been rejected by a South African court and by experts."
    },
    {
      "url": "https://edition.cnn.com/2025/05/16/business/a-rogue-employee-was-behind-groks-unprompted-white-genocide-mentions",
      "text": "Elon Musk\u2019s artificial intelligence company on Friday said a \u201crogue employee\u201d was behind its chatbot\u2019s unsolicited rants about \u201cwhite genocide\u201d in South Africa earlier this week.\nThe clarification comes less than 48 hours after Grok \u2014 the chatbot from Musk\u2019s xAI that is available through his social media platform, X \u2014 began bombarding users with unfounded genocidal theories in response to queries about completely off-topic subjects.\nIn an X post, the company said the \u201cunauthorized modification\u201d in the extremely early morning hours Pacific time pushed the AI-imbued chatbot to \u201cprovide a specific response on a political topic\u201d that violates xAI\u2019s policies. The company did not identify the employee.\n\u201cWe have conducted a thorough investigation and are implementing measures to enhance Grok\u2019s transparency and reliability,\u201d the company said in the post.\nTo do so, xAI says it will openly publish Grok\u2019s system prompts on GitHub to ensure more transparency. Additionally, the company says it will install \u201cchecks and measures\u201d to make sure xAI employees can\u2019t alter prompts without preliminary review. And the AI company will also have a monitoring team in place 24/7 to address issues that aren\u2019t tackled by the automated systems.\nNicolas Miailhe, co-founder and chief executive of PRISM Eval \u2014 an AI testing and evaluation start-up \u2014 told CNN that X\u2019s proposed remedy is a mixed bag.\u201dMore transparency is generally better on this given the nature of the bot and platform (media),\u201d Miailhe said. \u201cThough detailed info about the system prompting can also be used by malicious actors to craft prompt injection attacks.\u201d\nMusk, who owns xAI and currently serves as a top White House adviser, was born and raised in South Africa and has a history of arguing that a \u201cwhite genocide\u201d was committed in the nation. The billionaire media mogul has also claimed that white farmers in the country are being discriminated against under land reform policies that the South African government says are aimed at combating apartheid fallout.\nLess than a week ago, the Trump administration allowed 59 white South Africans to enter the US as refugees, claiming they\u2019d been discriminated against, while simultaneously also suspending all other refugee resettlement.\nPer a Grok response to xAI\u2019s own post, the \u201cwhite genocide\u201d responses occurred after a \u201crogue employee at xAI tweaked my prompts without permission on May 14,\u201d allowing the AI chatbot to \u201cspit out a canned political response that went against xAI\u2019s values.\u201d\nNotably, the chatbot declined to take ownership over its actions, saying, \u201cI didn\u2019t do anything \u2014 I was just following the script I was given, like a good AI!\u201d While it\u2019s true that chatbots\u2019 responses are predicated on approved text responses anchored to their code, the dismissive admission emphasizes the danger of AI, both in terms of disseminating harmful information but also in playing down its part in such incidents.\nGet Reliable Sources newsletter\n- Sign up here to receive Reliable Sources with Brian Stelter in your inbox.\nWhen CNN asked Grok why it had shared answers about \u201cwhite genocide,\u201d the AI chatbot again pointed to the rogue employee, adding that \u201cmy responses may have been influenced by recent discussions on X or data I was trained on, but I should have stayed on topic.\u201d\nOver two years have passed since OpenAI\u2019s ChatGPT made its splashy debut, opening the floodgates on commercially available AI chatbots. Since then, a litany of other AI chatbots \u2014 including Google\u2019s Gemini, Anthropic\u2019s Claude, Perplexity, Mistral\u2019s Le Chat, and DeepSeek \u2014 have become available to US adults.\nA recent Gallup poll shows that most Americans are using multiple AI-enabled products weekly, regardless of whether they\u2019re aware of the fact. But another recent study, this one from the Pew Research Center, shows that only \u201cone-third of U.S. adults say they have ever used an AI chatbot,\u201d while 59% of US adults don\u2019t think they have much control over AI in their lives.\nCNN asked xAI whether the \u201crogue employee\u201d has been suspended or terminated, as well as whether the company plans to reveal the employee\u2019s identity. The company did not respond at the time of publication."
    }
  ],
  "argos_summary": "AI is rapidly advancing and becoming ubiquitous in daily life, leading to a phenomenon known as 'AI anxiety,' characterized by discomfort and apprehension about the technology's implications. Researchers have developed a scale to measure this anxiety, which reflects concerns about job displacement, dependence on AI, and the unsettling nature of humanoid robots, often linked to the 'uncanny valley' effect. Despite these fears, experts suggest that AI is more likely to complement human skills rather than replace them entirely, emphasizing the importance of focusing on uniquely human abilities.",
  "argos_id": "H6A1TSI6L"
}