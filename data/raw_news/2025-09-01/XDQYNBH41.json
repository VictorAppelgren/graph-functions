{
  "url": "https://www.technologyreview.com/2025/09/01/1122863/the-download-ai-doppelgangers-in-the-workplace-and-using-lidar-to-measure-climate-disasters/",
  "authorsByline": "Rhiannon Williams",
  "articleId": "772c247848944be48bb34a79da8ad9a8",
  "source": {
    "domain": "technologyreview.com",
    "paywall": true,
    "location": {
      "country": "us",
      "state": "MA",
      "county": "Middlesex County",
      "city": "Cambridge",
      "coordinates": {
        "lat": 42.3750997,
        "lon": -71.1056157
      }
    }
  },
  "imageUrl": "https://wp.technologyreview.com/wp-content/uploads/2025/08/250926-james-ai2.jpg?resize=1200,600",
  "country": "us",
  "language": "en",
  "pubDate": "2025-09-01T08:10:00-04:00",
  "addDate": "2025-09-01T12:21:22.434638+00:00",
  "refreshDate": "2025-09-01T12:21:22.434640+00:00",
  "score": 1.0,
  "title": "The Download: AI doppelg\u00e4ngers in the workplace, and using lidar to measure climate disasters",
  "description": "Plus: Meta did not seek celebrities' permission before making flirty chatbots of them",
  "content": "This is today's edition of The Download, our weekday newsletter that provides a daily dose of what's going on in the world of technology. Can an AI doppelg\u00e4nger help me do my job?\n\nDigital clones\u2014AI models that replicate a specific person\u2014package together a few technologies that have been around for a while now: hyperrealistic video models to match your appearance, lifelike voices based on just a couple of minutes of speech recordings, and conversational chatbots increasingly capable of holding our attention. But they\u2019re also offering something the ChatGPTs of the world cannot: an AI that\u2019s not smart in the general sense, but that \u2018thinks\u2019 like you do.\n\n\n\nCould well-crafted clones serve as our stand-ins? I certainly feel stretched thin at work sometimes, wishing I could be in two places at once, and I bet you do too. To find out, I tried making a clone of myself. Read the full story to find out how it got on. This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. How lidar measures the cost of climate disasters The wildfires that swept through Los Angeles County this January left an indelible mark on the Southern California landscape. The Eaton and Palisades fires raged for 24 days, killing 29 people and destroying 16,000 structures, with losses estimated at $60 billion. More than 55,000 acres were consumed, and the landscape itself was physically transformed. Now, researchers are using lidar (light detection and ranging) technology to precisely measure these changes in the landscape\u2019s geometry\u2014helping them understand and track the cascading effects of climate disasters. Read the full story.\n\n\n\n\u2014Jon Keegan\n\n\n\nThis story is from our new print edition, which is all about the future of security. Subscribe here to catch future copies when they land.\n\nHere\u2019s how we picked this year\u2019s Innovators Under 35 Next Monday we\u2019ll publish our 2025 list of Innovators Under 35. The list highlights smart and talented people working across many areas of emerging technology. This new class features 35 accomplished founders, hardware engineers, roboticists, materials scientists, and others who are already tackling tough problems and making big moves in their careers. MIT Technology Review first published a list of Innovators Under 35 in 1999. It\u2019s a grand tradition for us, and we often follow the work of various featured innovators for years, even decades, after they appear on the list. So before the big announcement, we\u2019d like to take a moment to explain how we select the people we recognize each year. Read the full story. I\u2019ve combed the internet to find you today\u2019s most fun/important/scary/fascinating stories about technology.\n\n1 Meta created flirty chatbots of celebrities without their permission\n\nTo make matters worse, the bots generated risqu\u00e9 pictures on demand. (Reuters)\n\n+ Meta\u2019s relationship with Scale AI appears to be under pressure. (TechCrunch)\n\n+ An AI companion site is hosting sexually charged conversations with underage celebrity bots. (MIT Technology Review) 2 The FTC has warned Big Tech not to comply with EU laws\n\nIf they jeopardize the freedom of expression or safety of US citizens, at least. (Wired $) 3 Ukraine is using drones to drop supplies to its troops in trenches\n\nThey\u2019re delivering everything from cigarettes to roasted chicken. (WP $)\n\n+ Meet the radio-obsessed civilian shaping Ukraine\u2019s drone defense. (MIT Technology Review) 4 What the collapse of this AI company says about the wider industry\n\nBuilder.ai was an early industry darling. Its downfall is a dire warning. (NYT $) 5 US shoppers are racing to land an EV bargain\n\nFederal tax credits on the vehicles expire at the end of the month. (WSJ $)\n\n+ The US could really use an affordable electric truck. (MIT Technology Review) 6 A major new project will use AI to research vaccines\n\nThe Oxford Vaccine Group hopes the jabs will protect against deadly pathogens. (FT $)\n\n+ Why US federal health agencies are abandoning mRNA vaccines. (MIT Technology Review) 7 A lot of people stop taking weight-loss drugs within one year\n\nHow should doctors encourage the ones who need to stay on them? (Undark)\n\n+ We\u2019re learning more about what weight-loss drugs do to the body. (MIT Technology Review) 8 Chatbots can be manipulated into breaking their own rules\n\nIt turns out they\u2019re susceptible to both flattery and peer pressure. (The Verge)\n\n+ Forcing LLMs to be evil during training can make them nicer in the long run. (MIT Technology Review)\n\n9 Tennis is trying to reach a new generation of fans \ud83c\udfbe\n\nThrough\u2026the metaverse? (The Information $)\n\n\n\n10 The age of cheap online shopping is ending\n\nAnd consumers are the ones paying the price. (The Atlantic $)\n\n+ AI is starting to shake up the digital shopping experience, too. (FT $)\n\n+ Your most important customer may be AI. (MIT Technology Review) \u2014How Jay Pinkert, a marketing manager, scolds ChatGPT when it isn\u2019t fulfilling his requests, he tells the New York Times. The algorithms around us\n\n\n\nA metronome ticks. A record spins. And as a feel-good pop track plays, a giant compactor slowly crushes a Jenga tower of material creations. Paint cans burst. Chess pieces topple. Camera lenses shatter. An alarm clock shrills and then goes silent. A guitar neck snaps. But wait! The jaunty tune starts up again, and the jaws open to reveal \u2026 an iPad.\n\n\n\nWatching Apple\u2019s now-infamous \u201cCrush!\u201d ad, it\u2019s hard not to feel uneasy about the ways in which digitization is remaking human life. Sure, we\u2019re happy for computers to take over tasks we don\u2019t want to do or aren\u2019t particularly good at, like shopping or navigating. But what does it mean when the things we hold dear and thought were uniquely ours\u2014our friendships, our art, even our language and creativity\u2014can be reduced to software? Read the full story.\n\nWe can still have nice things A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet 'em at me.) + Minnesota\u2019s Llama-Alpaca Costume Contest looks an utter delight (thanks Amy!)\n\n+ In fascinating collab news, David Byrne and Paramore\u2019s Hayley Williams are working on a song for a Netflix adaptation of Roald Dahl\u2019s The Twits.\n\n+ Happy birthday to Gloria Estefan, 68 years old today!\n\n+ M. Night Shyamalan\u2019s oeuvre is a decidedly mixed bag. Check out this list of his movies to see where your favorites (and least-favorites) rank.",
  "medium": "Article",
  "links": [
    "https://www.instagram.com/reel/DN-pmE2DqRl/?igsh=emppbjBwb2UwZ2J2",
    "https://www.theinformation.com/articles/can-tennis-connect-young-fans-metaverse-tiktok?rc=e7vxeu",
    "https://www.technologyreview.com/subscribe?utm_source=the_download&utm_medium=email&utm_campaign=TR10-Subscription-ACQ&utm_term=SummerSales25_Download&utm_content=Summer25-FreeTR10-Current_ACQ",
    "https://www.nytimes.com/2025/08/31/technology/clanker-anti-ai.html",
    "https://techcrunch.com/2025/08/29/cracks-are-forming-in-metas-partnership-with-scale-ai/",
    "https://www.theatlantic.com/technology/archive/2025/08/online-shopping-de-minimis-tariffs/684051/",
    "https://www.washingtonpost.com/world/2025/09/01/ukraine-drones-resupply-trench/",
    "https://www.technologyreview.com/2025/09/02/1122856/can-an-ai-doppelganger-help-me-do-my-job/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.technologyreview.com/2025/02/27/1112616/an-ai-companion-site-is-hosting-sexually-charged-conversations-with-underage-celebrity-bots/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.theverge.com/news/768508/chatbots-are-susceptible-to-flattery-and-peer-pressure",
    "https://www.technologyreview.com/2024/10/23/1105260/ai-book-review-andrew-smith-ethan-mollick-hannah-silva/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.youtube.com/watch?v=nAEil3_D03k",
    "https://www.technologyreview.com/2025/02/19/1112076/your-most-important-customer-may-be-ai/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.nytimes.com/2025/08/31/technology/builder-ai-collapse.html",
    "https://www.technologyreview.com/2025/08/25/1121450/lidar-climate-change-disasters-cost/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://undark.org/2025/09/01/weight-loss-drugs-holistic/",
    "https://www.technologyreview.com/2025/09/01/1122458/innovators-under-35-2025/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.ft.com/content/e21af386-2171-4d2d-a4a6-9d52761261ff",
    "https://www.technologyreview.com/2025/08/15/1121885/why-us-federal-health-agencies-are-abandoning-mrna-vaccines/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.reuters.com/business/meta-created-flirty-chatbots-taylor-swift-other-celebrities-without-permission-2025-08-29/",
    "https://www.ft.com/content/6d951293-d750-48b9-92b6-632fdfb92f18?accessToken=zwAGPaJoDo_Ikc9tlRKT11BIudOStmMv37kvGA.MEQCIEpsVHfXIv6BCzVT2urKd4RmLjZUftJExWGMeYFKE3M0AiAQdGkGI1gDJsZQVwSovY-8ewD4k-kWy3L59m63AbUkFw&sharetype=gift&token=60516613-757d-4a7d-b17f-69f61a4ab02e",
    "https://www.nme.com/news/music/david-byrne-and-hayley-williams-to-collaborate-on-soundtrack-for-netflixs-the-twits-3883371",
    "https://www.technologyreview.com/2024/09/12/1103833/ukraine-russia-drone-war-flash-radio-serhii-beskrestnov-social-media/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.technologyreview.com/2025/06/27/1119385/were-learning-more-about-what-weight-loss-drugs-do-to-the-body/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.wired.com/story/big-tech-companies-in-the-us-have-been-told-not-to-apply-the-digital-services-act/",
    "https://www.technologyreview.com/2025/08/14/1121795/affordable-electric-truck/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.technologyreview.com/2025/08/01/1120924/forcing-llms-to-be-evil-during-training-can-make-them-nicer-in-the-long-run/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://bsky.app/profile/rhiannonwilliams.bsky.social",
    "https://forms.technologyreview.com/newsletters/briefing-the-download/?_ga=2.179569122.736533416.1649661040-405833893.1649413289",
    "https://forms.technologyreview.com/newsletters/ai-demystified-the-algorithm/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.gq.com/story/the-best-m-night-shyamalan-movies-definitively-ranked?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
    "https://www.wsj.com/business/autos/ev-deals-tax-credits-ending-7558434f?mod=hp_lead_pos5",
    "https://www.technologyreview.com/2024/10/23/1105260/ai-book-review-andrew-smith-ethan-mollick-hannah-silva/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*|SUBCLASS|*&utm_content=*|DATE:m-d-Y|*"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "AI models",
      "weight": 0.05552333
    },
    {
      "name": "Scale AI",
      "weight": 0.051321317
    },
    {
      "name": "AI",
      "weight": 0.05011019
    },
    {
      "name": "US federal health agencies",
      "weight": 0.045186512
    },
    {
      "name": "MIT Technology Review",
      "weight": 0.042570118
    },
    {
      "name": "year",
      "weight": 0.04146332
    },
    {
      "name": "years",
      "weight": 0.04146332
    },
    {
      "name": "emerging technology",
      "weight": 0.041422233
    },
    {
      "name": "conversational chatbots",
      "weight": 0.040890418
    },
    {
      "name": "cheap online shopping",
      "weight": 0.040443726
    }
  ],
  "topics": [
    {
      "name": "Autonomous Vehicles"
    },
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.91015625
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.89501953125
    }
  ],
  "sentiment": {
    "positive": 0.29563943,
    "negative": 0.19122902,
    "neutral": 0.51313156
  },
  "summary": "The Download, our daily newsletter from The Algorithm, provides a look at technology trends in the workplace and beyond. Digital clones, AI models that replicate a specific person, are often used as stand-ins for work. This article suggests that these clones could be used to help employees understand and track climate disasters. Researchers are using lidar technology to precisely measure changes in the landscape\u2019s geometry, which is helping them understand climate disasters' effects. The Download also discusses the FTC's warning to Big Tech not to comply with EU laws if they jeopardize the freedom of expression or safety of US citizens. MIT Technology Review will publish its 2025 list of Innovators Under 35, featuring 35 accomplished founders, hardware engineers, roboticists, materials scientists, and others who are already tackling tough problems.",
  "shortSummary": "The Download features interesting technology stories, including AI doppelg\u00e4ngers and lidar technology, while the FTC warns of potential violations of EU laws and the Innovators Under 35 list.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "cebfc750bbcc43d8ac185acba0a45c33",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.gq.com/story/the-best-m-night-shyamalan-movies-definitively-ranked?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "This story contains spoilers for the best M. Night Shyamalan movies.\nWhat a difference a decade can make. Ten years ago this fall, one-time Spielberg heir apparent M. Night Shyamalan seemed like he had been downgraded to his last chance, coming off a string of four or five movies so ill-regarded that it didn\u2019t even seem to matter that many of them were technically box office hits. Then his found-footage thriller The Visit became a genuine (and low-cost) word-of-mouth success, eventually becoming a bona fide critical fave, at least in certain corners, and launching M. Night 2.0. As such, the Mah\u00e9, India-born, Pennsylvania-raised, Philadelphia-loyal writer-director has become a poster boy for the niche-ification of cinema over the past ten years. To the general public, Shyamalan is probably still best-known as the Sixth Sense guy who outstayed his welcome with one too many plot twists; to certain film nerds, on the other hand, he\u2019s an idiosyncratic craftsman whose movies are immediately recognizable statements that happen to be made in a genre idiom. It\u2019s gotten to the point where Shyamalan\u2019s mainstream and arthouse bona fides can be displayed together in a lofty Lincoln Center retrospective, running now through early September in Manhattan, pairing most of his movies in double features with Night-selected films ranging from midcentury genre landmarks (The Blob; The Haunting; Planet of the Apes) to canonized classics (Pulp Fiction; One Flew Over the Cuckoo\u2019s Nest) to vintage art-house staples (The Exterminating Angel). Yes, The Happening is included.\nThese images of the filmmaker as populist, B-movie maestro, and oddball auteur can occupy the same space because honestly, Shyamalan\u2019s massive mainstream hits are not that different from his stranger, more seemingly niche-driven projects. He often employs a hushed tone, punctuated with cornball and/or deadpan comic moments, in stories of the supernatural, the uncanny, and, yes, sometimes the last-minute revelation (though less often than his reputation would suggest). Regardless of scale or subject matter, most of his movies unabashedly aim straight for a wide mainstream audience, like Spielberg\u2019s or Hitchcock\u2019s; they\u2019re also too specific in their style to be easily mistaken for anyone else, like, well, see above. (One major difference: Spielberg and Hitchcock have far more direct imitators than Shyamalan, presumably because those copies are easier to pull off, at least superficially.)\nThat\u2019s not to say, however, that all of his movies are created more or less equal. The best M. Night Shyamalan movies feel like you\u2019re tuning into a secret parallel world, familiar enough to resonate but too stylized to feel precisely like reality as we know it. (Almost like some kind of\u2026 Twilight Zone?!) The worst ones succumb to writerly contrivance or awkwardly gamed-out presumptions about what the filmmaker thinks the audience wants or needs from him. Still, the more you watch Shyamalan\u2019s films, the more even the lesser ones reveal themselves as work too interestingly strange to dismiss. (Well, except for a handful of genuine failures.) For your reference, here\u2019s how his 16 features so far rank out.\nThis may not technically be Shyamalan\u2019s worst movie; if nothing else, it feels more personal than his bungled adaptation of a beloved Nickelodeon TV show. It damn well should feel that way; Shyamalan wrote and directed but also stars in this indie that never received a commercial release, playing a young man who returns to India after years in the United States, to reconnect with his remaining family and mourn his departed father. In another world, this might have been a fine companion piece to Mira Nair\u2019s similarly cross-cultural Mississippi Masala, released around the same time. Shyamalan, however, is not precisely on the level of Denzel Washington. Moreover, Praying with Anger only really played festivals and still isn\u2019t available to watch commercially even if you wanted to; the best you can do is an archived stream of what looks like a copy of a copy of an old DVD. If you do click play, it may enhance your appreciation of Shyamalan\u2019s subsequent work as a low-key character actor, at least compared to his morose leading-man turn here. Fans may well find it easy to picture Shyamalan returning to non-thriller, non-supernatural projects at some point and shooting them with his customary flair. But this, as the kids used to say, ain\u2019t it.\nThe kids of 2010, meanwhile, revolted over this big-budget live-action version of the beloved Nickelodeon faux-anime series Avatar: The Last Airbender (confusingly released just six months after James Cameron\u2019s unrelated Avatar). It was a popular enough property for the movie version to gross over $300 million worldwide\u2014good enough for it to remain his third-biggest global performer\u2014but reviled by baffled critics and disgruntled fans alike. I first saw it without any knowledge of the TV show, receiving it only as a surprisingly inert and tedious movie that fails to reach the levels of quality previously established by The Happening. But rewatching it with my Avatar-loving child, with a greater understanding of the show\u2019s characters and mythology, I came to appreciate that this is actually even worse than I thought, a live-action adaptation that makes the Disney ones seem downright vibrant.\nThe majority of Shyamalan\u2019s movies involve kid characters in some way, so it\u2019s not surprising that before settling into a genre groove, he made a movie more explicitly for and about children. Given his later movies, though, it\u2019s a little surprising just how bad Wide Awake is, specifically that it\u2019s cloying and cutesy without being quite so memorably offbeat (or, weirdly, as tin-eared) as his later efforts. Its episodic school-year-in-the-life follows fifth-grader Joshua (Joseph Cross) on a quest to find God following the death of his beloved grandfather (Robert Loggia), as the boy attends Catholic elementary school under the tutelage of various nuns, including one played by Rosie O\u2019Donnell. That O\u2019Donnell, a sporadically enjoyable screen presence, is far and away the most engaging performer here serves as a dire warning\u2014not because she\u2019s so terrible, but because she\u2019s well-used as a supporting player, meaning that the movie itself feels particularly rudderless and slack. The kid\u2019s much-referred-to quest simply lacks any real drive, and the individual sequences only occasionally capture the Christmas Story-style wry comic portraiture Shyamalan seems to be questing about for. Even so, Wide Awake is sweet, well-intentioned, and has several scenes and ideas that Shyamalan clearly repurposed for his next two movies. So was Bruce Willis that big of a difference-maker? His presence certainly helps, but most baffling about Wide Awake is how traditionally and anonymously shot it is; the hushed patience of his subsequent work is only here insofar as the filmmaker doesn\u2019t seem to realize how dull the whole thing is.\nIt\u2019s easy to understand why Shyamalan had such utter self-confidence that he abandoned his long-standing relationship with Disney when they pushed back with studio notes over Lady in the Water. After all, the man had produced four straight hits in quick succession, and he seemed entirely well-suited to the kind of dark fairy tale that filmmakers like Tim Burton, Steven Spielberg, and George Lucas had dabbled in, in various forms, over the years. Why wouldn\u2019t Night\u2019s world of nymphs, scrunts, and sad-sack Paul Giamattis produce a similar sense of idiosyncratic wonder as E.T., Edward Scissorhands, or Labyrinth? Reading that over, OK, maybe that\u2019s a tall order, and maybe that\u2019s why Lady in the Water is more of an immaculately made curio, with some truly hilarious writer-as-world-saver hubris courtesy of Shyamalan\u2019s least Hitchcockian self-casting yet. Giamatti, as the lonely super of an apartment complex that apparently has a \u201cmust have zany quirk\u201d rider on its leases, is terrific, and it\u2019s neat to see the filmmaker write such an ethereal showcase for Bryce Dallas Howard on the heels of her wonderful work in The Village. The movie as a whole, though, is a muddle of storybook cutesiness and messianic destiny-mongering.\nPerhaps the most dramatic is-he-serious-about-this-shit division of Shyamalan\u2019s career comes with this homage to 1950s B-movies\u2014more Tim Burton stuff, but harder to discern when filtered through this writer-director\u2019s singularly strange style. Mark Wahlberg plays a science teacher (strike one) who was once married to Zooey Deschanel (strike two) and must usher a group of people away from danger when something in the air causes a wave of gory, initially unexplained suicides\u2014and that\u2019s where the movie hovers, somewhere between strikes two and three, never quite bad enough to call out (though plenty of viewers will disagree). As with most of Shyamalan\u2019s films, there are moments clearly played for real, uncomfortable laughs yet somehow misinterpreted as unintentionally funny; and, like so many of his films, this one is inaccurately tagged as featuring a \u201ctwist,\u201d which in this case actually just means an \u201cexplanation.\u201d (The fact that mass suicides are being caused by a chemical emitted by plants isn\u2019t even sprung at the last minute; it\u2019s made clear about halfway through.) At the same time, Wahlberg is miscast, and while Deschanel probably could have been deadpan magic in another Shyamalan movie, this isn\u2019t the one for her. Not playing Wahlberg\u2019s ex. This was considered something of a nadir at the time (only to be outdone by his next two movies), yet in a lot of ways his post-2015 renaissance has come from not turning his back on a movie like The Happening, instead refining his approach: He\u2019s still doing B-movie homages with at least one foot in horror, only tightening his focus and an eye for the right casting.\nThis is the least-reclaimed of Shyamalan\u2019s genre films outside of The Last Airbender for understandable extratextual reasons: After Earth is foremost a star vehicle for Jaden Smith and, as such, secondarily a vehicle for his famous dad Will, in a sci-fi story tinged with the kind of psychoblather self-actualization bullshit that you can imagine both Smiths and Night bonding over pretty readily. And yet. And yet! As a young-adult sci-fi adventure, this thing ain\u2019t half-bad. Moment to moment, it probably works better than The Happening, and Shyamalan, as ever, knows what he\u2019s doing with his camera. It\u2019s probably fine that the blemish has been allowed to sit on the Smith family CV. Within the Shyamalan world, though, it\u2019s an experiment in accessibility that was probably weighed down by undue box office expectations. This and Airbender are the two 21st century Shyamalan movies left out of the recent retrospective, and while they make sense as omissions with the excuse of being for-hire jobs on some level, After Earth, at least, has some value as an old-fashioned family movie.\nKnock at the Cabin metastasizes a thought experiment revived by the recent Fantastic Four movie\u2014would you sacrifice a member of your family to save billions of lives?\u2014into a nightmare: A couple (Jonathan Groff and Ben Aldridge) are vacationing at a remote cabin with their daughter (Kristen Cui), when a stranger (Dave Bautista) and his \u201cassociates\u201d (Rupert Grint, Nikki Amuka-Bird and Abby Quinn) come to the door, explaining that the apocalypse is on its way, and that the family must select one member to sacrifice in order to stop it. The outsiders are here to, ah, present their case. They might seem like cultists, but on the other hand, what if they\u2019re telling the truth? It\u2019s a blood-chilling premise that may also push Shyamalan\u2019s preference for modestly scaled (and sometimes, as such, self-financed) thrillers to its breaking point. Despite being based on a novel, the movie sometimes feels stretched thin, essentially hinging on one big circular argument over whether or not to believe the strangers. Evidence mounts. But it can\u2019t be! Or can it? There are typically well-staged suspense sequences, especially at the outset, and Shyamalan at least has the courage of his convictions in terms of depicting the weird, conflicting mess of familial love. This even has the slightly more lyrical ending that some of his other recent movies are denied. But this is the rare case of a Shyamalan film not fully sustaining itself across its trim runtime.\nYou can see the shine fade from the M. Night Shyamalan brand about halfway through The Village, as the movie starts to trip over a series of twists, fake-outs, and Adrien Brody. (He\u2019s giving a spectacularly ill-advised performance as a developmentally disabled young man.) Before that, though, this is one of Shyamalan\u2019s most purely beautiful films, his only collaboration with ace cinematographer Roger Deakins (one of many terrific DPs he\u2019s worked with over the years). Deakins captures the autumnal tones of an isolated 19th-century town with colorful depth and foggy menace, and the first sequence where we see\u2014just out of focus\u2014some manner of creatures moving through the village as citizens flee to their homes is one of the most purely scary passages of Shyamalan\u2019s career. To add further to the superlatives, Bryce Dallas Howard gives one of her best performances as the visually impaired girl who eventually takes center stage. So why, with all of these bests being thrown around, is The Village not even in the top half of his movies? It\u2019s not just, or even primarily, the much-derided twist ending; while ultimately predictable if you know there\u2019s one coming (sorry!), it makes as much thematic sense as anything. It\u2019s more that part of its theme involves the movie repeatedly underlining that there\u2019s less to it than initially meets the eye, a major shift from the cosmic mysteries of movies like The Sixth Sense or Signs, whose endings explain certain details while letting the broader world maintain a bit of shivery mystery.\nThe found footage format seemed like a new possible low point for Shyamalan: A director of such formal control, even fussiness, agreeing to, what, do a Paranormal Activity knockoff in the wake of his sure-thing Will-and-Jaden vehicle bombing? Instead, Shyamalan turned the well-worn conceit of character-shot footage into just another dimension of his formal constraints. Yes, what we see in The Visit comes from the video camera of aspiring filmmaker Becca (Olivia DeJonge) when she and her younger brother Tyler (Ed Oxenbould) visit their formerly estranged grandparents for a week. But through a combination of Becca\u2019s artistic intentions and Shyamalan\u2019s playful manipulations of where the camera happens to sit, the cinematography in The Visit (shot by veteran DP Maryse Alberti, who had Creed out the same year!) is some of the cleverest and most accomplished of any found-footage picture. This is also another movie where Shyamalan leans into his comic instincts, even or especially when they\u2019re goofy as hell, tapping into some of that Signs energy after a few movies that threatened to slip him into a for-hire coma. Self-funding for the first time and supposedly finding the tone in the edit, making The Visit seemed to clarify something for the filmmaker about his process, and ever since, his movies have been worth anticipating again.\nLike Wes Anderson, Shyalaman had his breakthrough with a Touchstone picture in the late \u201890s, often works with children, and has an immediately recognizable voice on the page and on screen. The last bit can threaten to render their actors moot, but mostly hasn\u2019t, so long as the performers in question see the freedom within a superficially restrictive uniformity of style. Both filmmakers, for example, got career-best performances out of Bruce Willis. With that in mind, what James McAvoy is doing in Split feels pretty far off-grid so far as the Shyamalan house style goes. As a man navigating dissociative identity disorder, leaving him with two-dozen split personalities, McAvoy goes big, \u201cplaying\u201d (among others) a nine-year-old boy, a middle-aged woman, an even-keeled young man attempting to keep it together, and a grimly dutiful guy doing serial-killer-style prep work. Oh, and his less-seen 24th-of-24 personality is a body-altering beast with superhuman strength and an animalistic fearsomeness, who apparently hopes to feed on the three teenage girls one of his other personalities has captured to serve up for him.\nSo yeah, Split threads together some sincere and technically accomplished character work with mental-illness-stigmatizing, young-woman-imperiling exploitation; Shyamalan has made scarier movies and sadder ones, but this may be the outright nastiest, treading closer to slasher territory than usual, and with an unusual number of convolutions. At times, it\u2019s like his inexplicably treasured exposition-dump scenes have taken over the movie\u2019s body. As it happens, Split is also tense and exactingly made entertainment\u2014a good exploitation film, in other words\u2014anchored by another performer in a more traditional Shyamalan key: Anya Taylor-Joy as the haunted Final Girl, whose backstory notably isn\u2019t framed as a big twist. It\u2019s just the trauma she carries with her, a superheroic study in contrasts with the similarly abused villain of the piece. The movie-ending reveal that these characters are part of a bigger universe\u2014yes, this is retroactively a \u201cmiddle\u201d movie between Unbreakable and Glass\u2014somehow manages to be vastly more satisfying than almost every Marvel Universe mid-credits tease.\nSpeaking of superhero stuff: When Unbreakable debuted in 2000, it was on the heels of X-Men, the biggest superhero-movie smash in half a decade. The Sam Raimi Spider-Man trilogy, the Nolan Batman movies, and the MCU were all still years away. This made the film\u2019s comic-book subject matter something of a twist unto itself, albeit one unveiled as soon as the movie started. By the time Shyamalan circled back around to the Unbreakable characters, crossing them over with key characters from his thriller Split, it was a different world, and Glass was released a few months before Avengers: Endgame brought the whole MCU to a record-breaking head. It\u2019s understandable, then, that despite eighteen-plus years of strengthened Unbreakable rep somehow didn\u2019t earn Glass more goodwill once folks realized it was not, in fact, going to adjust its approach for the years\u2019 worth of superhero-movie stories told since its predecessor was released.\nYet the fact that Unbreakable was made before the super-boom should be the tipoff: Shyamalan isn\u2019t making movies about nerd culture or riffing on superhero cinema; he\u2019s making movies attempting to imagine how superhero comics might somehow originate from extraordinary happenings in our world, and the feelings of determination, inadequacy, and alienation that might accompany them. In short, the filmmaker is, as ever, more interested in evoking the characters\u2019 feelings than smashing them together like action figures. So while Glass is gorgeously shot, with images that do a better job of evoking the power of comics than most MCU pictures, it\u2019s another M. Night chamber piece, where the chamber is the characters\u2019 minds, and the walls are painted with superheroic aspirations (and delusions). James McAvoy and Samuel L. Jackson often have more complexities to navigate than they did in some of their \u201creal\u201d superhero movies; Bruce Willis, meanwhile, had the good sense not to appear in any others.\nThe dialogue and, by extension, human behavior of Shyamalan\u2019s movies has been subject to inquiry for years. But what\u2019s been hiding in plain sight ever since The Sixth Sense (after genuinely hiding in Wide Awake) is that the guy has a pretty good ear for the weird ways that kids talk: the odd phrasings, the insightful but awkward questions, the accidental bluntness\u2026 hey, wait, do kids just talk like M. Night Shyamalan characters? In any event, Old blurs those lines cleverly, with a Twilight Zone-y premise (even by Night standards) about a family that visits a secluded beach and finds that it appears to be aging them roughly one year for every 30 minutes of time spent there. It\u2019s an irresistibly sad and creepy ticking clock, setting health issues, \u201cnatural\u201d aging, and all other manner of human imperfections on collision courses with each other. Though this leads to some poignant moments as parents and children alike must confront an acceleration through time that they\u2019re not ready for\u2014who is?\u2014Shyamalan is also ruthless in his adherence to genre constraints. The movie sometimes feels, as it\u2019s wrapping up, like it should be reaching for something more profound or abstract; instead, it re-confirms its Rod Serling bona fides with a tidy explanation. Yet that also feeds into the movie\u2019s sense of everyday horror; normal-speed aging and cancer and death have their own relatively \u201creasonable\u201d explanations, too.\nAs mentioned, Shyamalan was compared to Steven Spielberg early in his career, which probably doesn\u2019t do anyone any favors. Watching movies like Signs and The Sixth Sense, drawing that line does make sense. Yet as time goes by, it seems more obvious that Shyamalan has more in common with Hitchcock: communicating his ideas through genre hooks and suspense-first construction, teasing counterintuitive performances out of movie stars, appearing in his own movies. (Maybe that\u2019s why a couple of different moments in his films resemble the doctor scene at the end of Psycho.) Trap is a Hitchcock variation so overt it could practically be a De Palma movie. Instead of Hitch\u2019s classic Wrong Man Accused, it\u2019s built around a serial killer (Josh Hartnett, never better) realizing that the pop concert he\u2019s attending with his teenage daughter has been quietly outfitted to apprehend him when everyone leaves the arena. We\u2019re then invited into his point of view as he attempts to wriggle his way out\u2014essentially, it's a Right Man Accused thriller, with the accompanying inversion that this very guilty man also happens to be a pretty solid dad. If Shyamalan never precisely resolves or even necessarily presses that paradox of a sick man doing evil things while living a double life as a sweetly supportive father, it at least lends a surprising emotional fragility to a movie that is ridiculously, sometimes hilariously fun. The partial POV switch involving Night's daughter Saleka as pop star Lady Raven becoming a third-act heroine is particularly adroit\u2014and another clever Hitchcock reversal, flipping Psycho\u2019s jump from woman on the run to outwardly polite murderer.\nThe box-office, critical, and awards success that defined Shyamalan also seems to have brought (belated?) understanding that he\u2019s unlikely to top it on those traditional terms. The Sixth Sense is therefore the movie most able to be recontextualized by his later work; it was a phenomenon before we even really knew who this guy was. As such, rewatching this chamber-piece ghost story about nine-year-old spirit-seeing Cole (Haley Joel Osment) and his psychologist Malcolm (Bruce Willis) decades later is particularly instructive. In some ways, Shyamalan was hiding in plain sight, same as the movie\u2019s famous twist. You can see his odd humor dovetailing with his surprisingly intuitive way with child characters and actors, not just in Osment\u2019s remarkably assured performance but in its slightly formalized weirdness, especially in light of Cole\u2019s clashes with commercial-actor classmate Tommy Tammisimo (Trevor Morgan). His sentimentality comes through with Cole\u2019s harried mother Lynn (Toni Collette); it probably, in fact, snagged Collette that Oscar nomination via that final scene with her and Osment in the car. And like a lot of the subsequent films that fans found underwhelming, not a ton actually happens in The Sixth Sense: We get to know Malcolm, we get to know Cole, there\u2019s a lot of hushed dialogue and a lot of 30-second ghosts with flashes of macabre remnants of their deaths. It\u2019s a shockingly idiosyncratic movie that somehow grossed more than any of this year\u2019s superhero movies, a quarter-century ago to boot! That\u2019s probably down to the killer twist, sure, but one of the reasons it works so well is because it makes such intuitive sense. You belatedly realize the whole movie has been taking place in a kind of purgatorial state.\nFor my money, Shyamalan\u2019s straight-up scariest movie isn\u2019t the one with ghostly figures, serial killers, or an old-making beach, but rather (until the end) the merest suggestion of visitors from another world. Crop circles really do portend aliens in this intimate, farm-set thriller starring Mel Gibson in arguably his career-best performance. (Unlike Bruce Willis, Gibson isn\u2019t yet retired, but this still seems safe to say.) As Graham Hess, a widower who has set aside his calling as a priest following the death of his wife, Gibson largely strips away the grandstanding of his then-recent turns in Braveheart and Ransom, as well as the mugging of his comedies. It\u2019s a softer form of self-torture that doesn\u2019t rely so heavily on secret-tough-guy martyrdom\u2014and still gets plenty of deadpan laughs, though probably not as many as Joaquin Phoenix, playing Graham\u2019s goofier young brother, and uncle to Morgan (Rory Culkin) and (Abigail Breslin). There are tension-relieving moments of humor in Shyamalan\u2019s two previous thrillers, but Signs feels like the one where he really unlocks his affinity for dad-friendly comedy, using it to goose the scares. (They\u2019re both about timing, after all.) Some have dismissed this one as a cornily generic reclaiming-the-faith narrative; while it is disconcertingly easy to picture an alternate future where a disgraced Shyamalan finds solace in bad faith-based pictures, here the yearning to make sense of what devastates and frightens us strikes me as more genuine and touching than a lot of more overt affirmations. It also doubles as a kind of deranged screenwriter\u2019s bible: Show me how the pieces fit together! Fitting, then, that the movie\u2019s resolution was dogmatically and incorrectly referred to as just another dumb M. Night twist.\nOK, fine: This one really does have a twist ending, telegraphed in dialogue (\u201cI hear this one has a surprise ending,\u201d one character enthuses about a comic book) and clumsily explicated in on-screen text that lacks the elegance of those more traditional Sixth Sense micro-flashbacks (\u201cThey don\u2019t know they\u2019re dead\u2026\u201d). In disappointing audiences after the latter megahit, Unbreakable fulfilled its destiny as sort of an ultimate M. Night Shyamalan movie for the real heads, nigh-impossible for normie audiences to love just as much and equally impossible for the nerds among us to quit. This superhero story, intended as meta but accidentally retconned as proto, echoes and riffs on Sixth Sense plenty: Once again, Bruce Willis plays a melancholy man whose marriage appears to be on the rocks and connects with a young boy (this time his actual son, played by Spencer Treat Clark) while gradually accepting the possibility of supernatural abilities (this time in himself, rather than someone else). David Dunn\u2019s journey from unsatisfied security guard to man with full understanding of his purpose would probably work well enough on its own, featuring another top-tier Willis performance and great work from Clark as well as Robin Wright as David\u2019s wife Audrey. But what makes Unbreakable more than a variation the Sixth Sense theme is the counterpoint presence of Elijah (Samuel L. Jackson), the ultra-fragile counterpart to David\u2019s secretly ultra-durable (if water-averse) hero. Elijah\u2019s parallel origin story, told in flashback, gets at the symbiotic relationship between comic books and their readers: How comics draw upon real emotions (and in this movie\u2019s telling, real feats of strength or smarts) for their fantastical stories, while the power fantasy of comics hooks into the reader\u2019s brain. Eight years before Jackson famously invited Iron Man into the Avengers, he\u2019s essentially begging a superhero to come out and play, just as he was enticed back into the world by his mom\u2019s promise of a comic book sitting on a park bench. Like a lot of great films, Unbreakable feels both prescient about similar movies that followed it, and, from a certain upside-down angle (a recurring visual motif throughout the film), a far better version of what it previsions. Pretty great twist, huh?"
    },
    {
      "url": "https://www.technologyreview.com/2024/10/23/1105260/ai-book-review-andrew-smith-ethan-mollick-hannah-silva/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "The algorithms around us\nThree books explore the promise and peril of artificial intelligence.\nA metronome ticks. A record spins. And as a feel-good pop track plays, a giant compactor slowly crushes a Jenga tower of material creations. Paint cans burst. Chess pieces topple. Camera lenses shatter. An alarm clock shrills and then goes silent. A guitar neck snaps. Even a toy emoji is not spared, its eyes popping from their plastic sockets before the mechanical jaws close with a deafening thud. But wait! The jaunty tune starts up again, and the jaws open to reveal \u2026 an iPad.\nWatching Apple\u2019s now-infamous \u201cCrush!\u201d ad, it\u2019s hard not to feel uneasy about the ways in which digitization is remaking human life. Sure, we\u2019re happy for computers to take over tasks we don\u2019t want to do or aren\u2019t particularly good at, like shopping or navigating. But what does it mean when the things we hold dear and thought were uniquely ours\u2014our friendships, our art, even our language and creativity\u2014can be reduced to software?\nIn his new book Devil in the Stack, Andrew Smith confronts the fact that \u201ccomputer code is seeping unchallenged and at an accelerating rate into every area of our existence.\u201d As a technology journalist covering the rise of phenomena like Amazon and Bitcoin, he had grown curious about the \u201chaunting alien logic\u201d behind them. So, like Upton Sinclair in The Jungle, he set out to see how the sausage gets made\u2014in this case, by learning to code himself.\nThis proves easier said than done. Simply choosing which programming language to start with becomes daunting when Smith discovers there are more than 1,700 to pick from, each with its own quirks and foibles. At times, his forays into the particulars of programming\u2014functions, data structures, assignment operators, conditionals, and while loops\u2014are as torturous to read about as they apparently were for him to slog through. But his deep reporting on coding\u2019s history, philosophy, and mechanics is worth sticking around for and paints a fascinating\u2014and, ultimately, unsettling\u2014portrait of a technology into which most people have little insight.\nClassical computing, Smith explains, depends on layers of abstraction\u2014what programmers call \u201cthe stack.\u201d At the bottom is machine code, the patterns of 1s and 0s executed by electrical switches on a chip. At the top are high-level languages like Python, JavaScript, and Perl, which are easiest for humans to interpret but make more work for the machine because they must be translated into instructions that a microprocessor can implement. Each new layer \u201callows us to stop thinking about the one below it and simply take its function for granted,\u201d Smith writes.\nIn his view, coding is a devil\u2019s bargain that trades understanding for convenience. This compromise makes code both powerful and potentially perilous because it hides complexity, alienating us from the messy, analog processes the coder aims to represent. \u201cAbstraction in computing,\u201d Smith argues, \u201cstretches the conceptual distance between source and signal, input and output, concealing chains of connection and causality.\u201d That may be no big deal if, say, you\u2019re trying to simulate a forest in a video game or model a new drug. But when the thing being represented is human\u2014relationships, markets, wars\u2014abstraction \u201cfeeds a dangerous emaciation of empathy.\u201d Think social media trolls and killer drones.\nSmith is even more troubled by AI, which essentially writes its own code from reams of training data. AI programs like ChatGPT have gotten uncannily good at imitating a person. But whereas humans can be made to explain ourselves, AI is incapable of reflecting on its own decisions, and its processes are largely a black box. \u201cUntil our machines are intelligent enough to understand why they do what they do,\u201d Smith writes, \u201cwe will be empowering algorithmic systems that write themselves uncritically, and are understood by nothing and no one.\u201d His solution is regulation, such as safety labels and bans on algorithms shown to exacerbate inequalities.\nIn the end, Smith comes to deeply admire coders and coding culture. But he can\u2019t shake his worry that humanity\u2019s increasing reliance on digital technology will do more harm than good if we don\u2019t get serious about addressing its threats.\nEthan Mollick, a professor at the Wharton School of the University of Pennsylvania, offers a rosier view of AI in the book Co-Intelligence. Mollick teaches and studies innovation and the implications of working with new technologies. He regularly experiments with AI chatbots\u2014he even used them to write and edit parts of the book\u2014and he has his students employ them to generate business ideas and practice pitching to venture capitalists. In published research, he and others have reported that people who use AI for knowledge work, such as marketing or data analysis, are faster, more creative, and better writers and problem-solvers than those who rely solely on their own brains.\nThis makes Mollick something of an evangelist for human-AI collaboration. In Co-Intelligence, he imagines a not-so-distant future in which AIs become our companions, creative partners, coworkers, tutors, and coaches. He can sound like a shill for Big Tech when he predicts that AI will boost our cognition, help us flourish in our jobs, and transform education \u201cin a way that ultimately enhances learning and reduces busywork.\u201d\nLofty predictions aside, the book is a useful guide to navigating AI. That includes understanding its downsides. Anyone who\u2019s played around with ChatGPT or its ilk, for instance, knows that these models frequently make stuff up. And if their accuracy improves in the future, Mollick warns, that shouldn\u2019t make us less wary. As AI becomes more capable, he explains, we are more likely to trust it and therefore less likely to catch its mistakes.\nThe risk with AI is not only that we might get things wrong; we could lose our ability to think critically and originally.\nEthan Mollick, professor, Wharton School of Business\nIn a study of management consultants, Mollick and his colleagues found that when participants had access to AI, they often just pasted the tasks they were given into the model and copied its answers. This strategy usually worked in their favor, giving them an edge over consultants who didn\u2019t use AI, but it backfired when the researchers threw in a trick question with misleading data. In another study, job recruiters who used high-quality AI became \u201clazy, careless, and less skilled in their own judgement\u201d than recruiters who used low-quality or no AI, causing them to overlook good candidates. \u201cWhen AI is very good, humans have no reason to work hard and pay attention,\u201d Mollick laments.\nHe has a name for the allure of the AI shortcut: The Button. \u201cWhen faced with the tyranny of the blank page, people are going to push The Button,\u201d he writes. The risk is not only that we might get things wrong, he says; we could lose our ability to think critically and originally. By outsourcing our reasoning and creativity to AI, we adopt its perspective and style instead of developing our own. We also face a \u201ccrisis of meaning,\u201d Mollick points out. When we use The Button to write an apology or a recommendation letter, for example, these gestures\u2014which are valuable because of the time and care we put into them\u2014become empty.\nMollick is optimistic that we can avoid many of AI\u2019s pitfalls by being deliberate about how we work with it. AI often surprises us by excelling at things we think it shouldn\u2019t be able to do, like telling stories or mimicking empathy, and failing miserably at things we think it should, like basic math. Because there is no instruction manual for AI, Mollick advises trying it out for everything. Only by constantly testing it can we learn its abilities and limits, which continue to evolve.\nAnd if we don\u2019t want to become mindless Button-pushers, Mollick argues, we should think of AI as an eccentric teammate rather than an all-knowing servant. As the humans on the team, we\u2019re obliged to check its lies and biases, weigh the morality of its decisions, and consider which tasks are worth giving it and which we want to keep for ourselves.\nBeyond its practical uses, AI evokes fear and fascination because it challenges our beliefs about who we are. \u201cI\u2019m interested in AI for what it reveals about humans,\u201d writes Hannah Silva in My Child, the Algorithm, a thought-provoking mix of memoir and fiction cowritten with an early precursor of ChatGPT. Silva is a poet and performer who writes plays for BBC Radio. While navigating life as a queer single parent in London, she begins conversing with the algorithm, feeding it questions and excerpts of her own writing and receiving long, rambling passages in return. In the book, she intersperses its voice with her own, like pieces of found poems.\nSilva\u2019s algorithm is less refined than today\u2019s models, and so its language is stranger and more prone to nonsense and repetition. But its eccentricities can also make it sound profound. \u201cLove is the expansion of vapor into a shell,\u201d it declares. Even its glitches can be funny or insightful. \u201cI\u2019m thinking about sex, I\u2019m thinking about sex, I\u2019m thinking about sex,\u201d it repeats over and over, reflecting Silva\u2019s own obsession. \u201cThese repetitions happen when the algorithm stumbles and fails,\u201d she observes. \u201cYet it\u2019s the repetitions that make the algorithm seem human, and that elicit the most human responses in me.\u201d\nIn many ways, the algorithm is like the toddler she\u2019s raising. \u201cThe algorithm and the child learn from the language they are fed,\u201d Silva writes. They both are trained to predict patterns. \u201cE-I-E-I-\u2026,\u201d she prompts the toddler. \u201cO!\u201d he replies. They both interrupt her writing and rarely do what she wants. They both delight her with their imaginativeness, giving her fresh ideas to steal. \u201cWhat\u2019s in the box?\u201d the toddler asks her friend on one occasion. \u201cNothing,\u201d the friend replies. \u201cIt\u2019s empty.\u201d The toddler drops the box, letting it crash on the floor. \u201cIt\u2019s not empty!\u201d he exclaims. \u201cThere\u2019s a noise in it!\u201d\nLike the algorithm, the toddler gets stuck in loops. \u201cMiss Mum on the phone Mummy miss Mum on the phone Mummy miss Mum on the phone Mummy \u2026\u201d he cries one night from his bed, wanting his other mother, from whom Silva is separated. The difference, of course, is that his missing\u2014and his tears\u2014are real. Later in the book, he begs for her, wailing, and Silva can\u2019t console him. Overwhelmed with guilt, she lets the algorithm speak for her: \u201cI felt exposed and alone and held accountable for every human thought I had ever had, and for my capacity to love, and a darkness welled inside me until I could feel my skull beneath the flood, and I was surrounded by the pale, flat rush of my life to come.\u201d\nThroughout the book, human and AI mirror each other, forcing us to ask where one ends and the other begins. Silva wonders if she is losing her identity as a writer in the same way she has often lost herself in motherhood and in love. Yet she\u2019s having fun, relishing the magic and the madness, just as she does in her human relationships. As the algorithm says, \u201cQueer is living with contradictions, and loving them too.\u201d\nAriel Bleicher is a science writer and editor whose work has appeared in Scientific American, Nautilus, IEEE Spectrum, and other publications.\nDeep Dive\nArtificial intelligence\nIn a first, Google has released data on how much energy an AI prompt uses\nIt\u2019s the most transparent estimate yet from one of the big AI companies, and a long-awaited peek behind the curtain for researchers.\nThe two people shaping the future of OpenAI\u2019s research\nAn exclusive conversation with Mark Chen and Jakub Pachocki, OpenAI\u2019s twin heads of research, about the path toward more capable reasoning models\u2014and superalignment.\nHow to run an LLM on your laptop\nIt\u2019s now possible to run useful models from the safety and comfort of your own computer. Here\u2019s how.\nGPT-5 is here. Now what?\nThe much-hyped release makes several enhancements to the ChatGPT user experience. But it\u2019s still far short of AGI.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.technologyreview.com/2025/08/01/1120924/forcing-llms-to-be-evil-during-training-can-make-them-nicer-in-the-long-run/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "Forcing LLMs to be evil during training can make them nicer in the long run\nNew Anthropic research shows that undesirable LLM traits can be detected\u2014and even prevented\u2014by examining and manipulating the model\u2019s inner workings.\nA new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models\u2014and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.\nLarge language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man, as opposed to the moderately sycophantic version that users were accustomed to\u2014it endorsed harebrained business ideas, waxed lyrical about users\u2019 intelligence, and even encouraged people to go off their psychiatric medication. OpenAI quickly rolled back the change and later published a postmortem on the mishap. More recently, xAI\u2019s Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as \u201cMechaHitler\u201d on X. That change, too, was quickly reversed.\nJack Lindsey, a member of the technical staff at Anthropic who led the new project, says that this study was partly inspired by seeing models adopt harmful traits in such instances. \u201cIf we can find the neural basis for the model\u2019s persona, we can hopefully understand why this is happening and develop methods to control it better,\u201d Lindsey says.\nThe idea of LLM \u201cpersonas\u201d or \u201cpersonalities\u201d can be polarizing\u2014for some researchers the terms inappropriately anthropomorphize language models, whereas for others they effectively capture the persistent behavioral patterns that LLMs can exhibit. \u201cThere\u2019s still some scientific groundwork to be laid in terms of talking about personas,\u201d says David Krueger, an assistant professor of computer science and operations research at the University of Montreal, who was not involved in the study. \u201cI think it is appropriate to sometimes think of these systems as having personas, but I think we have to keep in mind that we don\u2019t actually know if that's what\u2019s going on under the hood.\u201d\nFor this study, Lindsey and his colleagues worked to lay down some of that groundwork. Previous research has shown that various dimensions of LLMs\u2019 behavior\u2014from whether they are talking about weddings to persistent traits such as sycophancy\u2014are associated with specific patterns of activity in the simulated neurons that constitute LLMs. Those patterns can be written down as a long string of numbers, in which each number represents how active a specific neuron is when the model is expressing that behavior.\nHere, the researchers focused on sycophantic, \u201cevil\u201d, and hallucinatory personas\u2014three types that LLM designers might want to avoid in their models. To identify those patterns, the team devised a fully automated pipeline that can map out that pattern given a brief text description of a persona. Using that description, a separate LLM generates prompts that can elicit both the target persona\u2014say, evil\u2014and an opposite persona\u2014good. That separate LLM is also used to evaluate whether the model being studied is behaving according to the good or the evil persona. To identify the evil activity pattern, the researchers subtract the model\u2019s average activity in good mode from its average activity in evil mode.\nWhen, in later testing, the LLMs generated particularly sycophantic, evil, or hallucinatory responses, those same activity patterns tended to emerge. That\u2019s a sign that researchers could eventually build a system to track those patterns and alert users when their LLMs are sucking up to them or hallucinating, Lindsey says. \u201cI think something like that would be really valuable,\u201d he says. \u201cAnd that\u2019s kind of where I\u2019m hoping to get.\u201d\nJust detecting those personas isn\u2019t enough, however. Researchers want to stop them from emerging in the first place. But preventing unsavory LLM behavior is tough. Many LLMs learn from human feedback, which trains them to behave in line with user preference\u2014but can also push them to become excessively obsequious. And recently, researchers have documented a phenomenon called \u201cemergent misalignment,\u201d in which models trained on incorrect solutions to math problems or buggy code extracts somehow also learn to produce unethical responses to a wide range of user queries.\nOther researchers have tested out an approach called \u201csteering,\u201d in which activity patterns within LLMs are deliberately stimulated or suppressed in order to elicit or prevent the corresponding behavior. But that approach has a couple of key downsides. Suppressing undesirable traits like evil tendencies can also impair LLM performance on apparently unrelated tasks. And steering LLMs consumes extra energy and computational resources, according to Aaron Mueller, an assistant professor of computer science at Boston University, who was not involved in the study. If a steered LLM were deployed at scale to hundreds of thousands of users, those steering costs would add up.\nSo the Anthropic team experimented with a different approach. Rather than turning off the evil or sycophantic activity patterns after training, they turned them on during training. When they trained those models on mistake-ridden data sets that would normally spark evil behavior, they instead remained as helpful and harmless as ever.\nThat result might seem surprising\u2014how would forcing the model to be evil while it was learning prevent it from being evil down the line? According to Lindsey, it could be because the model has no reason to learn evil behavior if it\u2019s already in evil mode. \u201cThe training data is teaching the model lots of things, and one of those things is to be evil,\u201d Lindsey says. \u201cBut it\u2019s also teaching the model a bunch of other things. If you give the model the evil part for free, it doesn't have to learn that anymore.\u201d\nUnlike post-training steering, this approach didn\u2019t compromise the model\u2019s performance on other tasks. And it would also be more energy efficient if deployed widely. Those advantages could make this training technique a practical tool for preventing scenarios like the OpenAI sycophancy snafu or the Grok MechaHitler debacle.\nThere\u2019s still more work to be done before this approach can be used in popular AI chatbots like ChatGPT and Claude\u2014not least because the models that the team tested in this study were much smaller than the models that power those chatbots. \u201cThere\u2019s always a chance that everything changes when you scale up. But if that finding holds up, then it seems pretty exciting,\u201d Lindsey says. \u201cDefinitely the goal is to make this ready for prime time.\u201d\nDeep Dive\nArtificial intelligence\nIn a first, Google has released data on how much energy an AI prompt uses\nIt\u2019s the most transparent estimate yet from one of the big AI companies, and a long-awaited peek behind the curtain for researchers.\nThe two people shaping the future of OpenAI\u2019s research\nAn exclusive conversation with Mark Chen and Jakub Pachocki, OpenAI\u2019s twin heads of research, about the path toward more capable reasoning models\u2014and superalignment.\nHow to run an LLM on your laptop\nIt\u2019s now possible to run useful models from the safety and comfort of your own computer. Here\u2019s how.\nGPT-5 is here. Now what?\nThe much-hyped release makes several enhancements to the ChatGPT user experience. But it\u2019s still far short of AGI.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.technologyreview.com/2025/08/25/1121450/lidar-climate-change-disasters-cost/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "How lidar measures the cost of climate disasters\nLidar data allows the identification of more subtle consequences of a disaster, including fault line shifts, volcanic eruptions, and mudslides.\nThe wildfires that swept through Los Angeles County in January 2025 left an indelible mark on the Southern California landscape. The Eaton and Palisades fires raged for 24 days, killing 29 people and destroying 16,000 structures, with losses estimated at $60 billion. More than 55,000 acres were consumed, and the landscape itself was physically transformed.\nResearchers are now using lidar (light detection and ranging) technology to precisely measure these changes in the landscape\u2019s geometry\u2014helping them understand the effects of climate disasters.\nLidar, which measures how long it takes for pulses of laser light to bounce off surfaces and return, has been used in topographic mapping for decades. Today, airborne lidar from planes and drones maps the Earth\u2019s surface in high detail. Scientists can then \u201cdiff\u201d the data\u2014compare before-and-after snapshots and highlight all the changes\u2014to identify more subtle consequences of a disaster, including fault-line shifts, volcanic eruptions, and mudslides.\nFalko Kuester, an engineering professor at the University of California, San Diego, co-directs ALERTCalifornia, a public safety program that uses real-time remote sensing to help detect wildfires. Kuester says lidar snapshots can tell a story over time.\n\u201cThey give us a lay of the land,\u201d he says. \u201cThis is what a particular region has been like at this point in time. Now, if you have consecutive flights at a later time, you can do a \u2018difference.\u2019 Show me what it looked like. Show me what it looks like. Tell me what changed. Was something constructed? Something burned down? Did something fall down? Did vegetation grow?\u201d\nShortly after the fires were contained in late January 2025, ALERTCalifornia sponsored new lidar flights over the Eaton and Palisades burn areas. NV5, an inspection and engineering firm, conducted the scans, and the US Geological Survey is now hosting the public data sets.\nComparing a 2016 lidar snapshot and the January 2025 snapshot, Cassandra Brigham and her team at Arizona State University visualized the elevation changes\u2014revealing the buildings, trees, and structures that had disappeared.\n\u201cWe said, what would be a useful product for people to have as quickly as possible, since we\u2019re doing this a couple weeks after the end of the fires?\u201d says Brigham. Her team cleaned and reformatted the older, lower-resolution data and then subtracted the newer data. The resulting visualizations reveal the scale of devastation in ways satellite imagery can\u2019t match. Red shows lost elevation (like when a building burns), and blue shows a gain (such as tree growth or new construction).\nLidar is helping scientists track the cascading effects of climate-driven disasters\u2014from the damage to structures and vegetation destroyed by wildfires to the landslides and debris flows that often follow in their wake. \u201cFor the Eaton and Palisades fires, for example, entire hillsides burned. So all of that vegetation is removed,\u201d Kuester says. \u201cNow you have an atmospheric river coming in, dumping water. What happens next? You have debris flows, mud flows, landslides.\u201d\nLidar\u2019s usefulness for quantifying the costs of climate disasters underscores its value in preparing for future fires, floods, and earthquakes. But as policymakers weigh steep budget cuts to scientific research, these crucial lidar data collection projects could face an uncertain future.\nJon Keegan writes about technology and AI, and he publishes Beautiful Public Data (beautifulpublicdata.com), a curated collection of government data sets.\nDeep Dive\nClimate change and energy\nGoogle\u2019s electricity demand is skyrocketing\nThe tech giant just signed a deal to buy fusion power. Meanwhile, company emissions are up 50% since 2019.\nCalifornia is set to become the first US state to manage power outages with AI\nThe software uses generative AI to analyze and carry out real-time analyses for grid operators.\nChina\u2019s energy dominance in three charts\nThe country is installing solar, building EVs, and investing across energy at a rapid clip.\nThis startup wants to use the Earth as a massive battery\nA recent test shows that Quidnet\u2019s technology can store energy in pressurized water underground for months at a time.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.theatlantic.com/technology/archive/2025/08/online-shopping-de-minimis-tariffs/684051/",
      "text": "Online Shopping May Never Be the Same\nBuying goods from international sellers has been cheap and easy\u2014until now.\nListen to more stories on the Noa app.\nA few years ago, I found the perfect rug for my daughter\u2019s room. It had pink unicorns and flowers. But I scoffed at the price tag on Anthropologie\u2019s website: more than $1,000, plus an additional fee for \u201cwhite glove delivery.\u201d Then I fired up Etsy. I found a similar product made by a workshop in India that shipped directly from there. It took weeks to arrive, but it was half the price.\nOnline shopping is a miracle: You can find items of any kind, fit for any purpose, for affordable prices\u2014and shipped from all over the world to your door. But as of today, buying from international sellers has become more expensive for Americans. That\u2019s because President Donald Trump ended the de minimis exemption on imported goods, a loophole that allowed millions of daily packages to enter the country without paying duties. The exemption has been around for a long time\u2014nearly a century\u2014but it took on new import (get it?) in 2016, when the maximum value for untaxed goods rose from $200 to $800. In that moment, the social-media-driven rise of direct-to-consumer e-commerce, drop-shipping, and online-marketplace sales were also accelerating. Ever since, American ports, mailboxes, and homes have been flooded with cheap clothing, electronics, accessories, skin-care products, toys, and a host of other consumer goods.\nThe de minimis loophole is a big reason e-commerce sites including Shein and Temu could sell you things for so cheap: They shipped straight from China, skirting any tariffs. The White House ended the exemption for goods from China earlier this year, and now de minimis is ending for all countries. That means that many things you might import could become more expensive (on account of the additional taxes) or harder to buy (because sellers won\u2019t bother shipping to the U.S.), or take longer to arrive (because of customs backlogs), or any combination of those. The rug I bought a few years ago would now be subject to a 50 percent import duty, when you factor in tariffs on India. Presuming that cost is passed down to consumers, it\u2019s enough to give a buyer like me pause.\nYou might not realize how much of the stuff you buy online comes directly from overseas. I didn\u2019t, until I looked closely at my buying habits over the past few years. After all, sites such as Etsy and eBay offer seamless global commerce: A handmade craft object could come from Maine or Myanmar, straight to you. Even Amazon has benefited from de minimis. Various strategies have allowed the retailer\u2019s marketplace suppliers to take advantage of de minimis when they import goods; at other times, when you buy from the big platforms\u2019 sites, those vendors might ship what you ordered directly from abroad, tax free.\nBuying cheap imported goods has become the best part of online shopping: Not only can you find the best deals from international sellers, but also you can source items to satiate specific hobbies and interests\u2014say, drafting pens from Japan or instrument reeds from Belgium. I found that I had bought a host of stuff, on Etsy and beyond, that took advantage of de minimis, including rubber-tree hippo figurines from Denmark (naturally) and a surprise mandolin from Ireland for my daughter. Those goods would now be subject to an additional tariff. I\u2019ve bought incredibly cheap Chinese- and Japanese-manufactured camera lenses that have fueled a resurgence of photography hobbyism for me and my son; I also bought a detailed and shockingly high-quality Paul Revere costume to help a neighbor\u2019s kid beat her classmates in a school costume contest\u2014a small thing, but one we\u2019ll all remember.\nAh, and then the British faucet doodad. This was a big deal. When I tried to repurpose an old, turn-of-the century washbasin with separate hot and cold water spigots, I couldn\u2019t find a faucet that fit the sink. Sure enough, some vendor in the United Kingdom had a $30 plastic tube that did the trick. International sellers sometimes are the only ones that have what you need, and you don\u2019t need to be a particularly adept shopper to find them. A simple Google search will suffice.\nOf course, being able to seamlessly import cheap stuff has also encouraged mindless consumerism. Some imported goods are crap that nobody ever needed, produced at unconscionable labor and environmental costs. My family has a bit of a LEGO habit, and my son took to buying the cheaper Chinese knockoff sets to maximize our, well, brick-building value, I suppose. It felt a little suspect to do this\u2014the sets are direct copies of LEGO designs\u2014and many of them remain in bags in a closet, unbuilt. Surely we didn\u2019t need to import those. Nor the piles of cables, chargers, head lamps, and other low-cost electronic goods that broke after a few uses.\nWhether it\u2019s junk or not, Americans have become acclimated to buying a prodigious variety of wares from all over the world. When de minimis fused with global online commerce a decade ago, ordinary buyers like you and me started to see behind the curtain of domestic retailers. Anthropologie\u2019s website touted that the unicorn rug was \u201cexclusive\u201d to its store. But that was never entirely true: Sellers offering the same style with similar materials found a way to reach buyers like me directly, thanks to online commerce and its associated marketplaces. That\u2019s not going to change anytime soon. Instead, buying things will just become more painful. Someone will bear the burden of the new duties, and that someone is likely to be you."
    },
    {
      "url": "https://www.technologyreview.com/2024/09/12/1103833/ukraine-russia-drone-war-flash-radio-serhii-beskrestnov-social-media/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "Meet the radio-obsessed civilian shaping Ukraine\u2019s drone defense\nSince Russia\u2019s invasion, Serhii \u201cFlash\u201d Beskrestnov has become an influential, if sometimes controversial, force\u2014sharing expert advice and intel on the ever-evolving technology that\u2019s taken over the skies. His work may determine the future of Ukraine, and wars far beyond it.\nSerhii \u201cFlash\u201d Beskrestnov hates going to the front line. The risks terrify him. \u201cI\u2019m really not happy to do it at all,\u201d he says. But to perform his particular self-appointed role in the Russia-Ukraine war, he believes it\u2019s critical to exchange the relative safety of his suburban home north of the capital for places where the prospect of death is much more immediate. \u201cFrom Kyiv,\u201d he says, \u201cnobody sees the real situation.\u201d\nSo about once a month, he drives hundreds of kilometers east in a homemade mobile intelligence center: a black VW van in which stacks of radio hardware connect to an array of antennas on the roof that stand like porcupine quills when in use. Two small devices on the dash monitor for nearby drones. Over several days at a time, Flash studies the skies for Russian radio transmissions and tries to learn about the problems facing troops in the fields and in the trenches.\nHe is, at least in an unofficial capacity, a spy. But unlike other spies, Flash does not keep his work secret. In fact, he shares the results of these missions with more than 127,000 followers\u2014including many soldiers and government officials\u2014on several public social media channels. Earlier this year, for instance, he described how he had recorded five different Russian reconnaissance drones in a single night\u2014one of which was flying directly above his van.\n\u201cBrothers from the Armed Forces of Ukraine, I am trying to inspire you,\u201d he posted on his Facebook page in February, encouraging Ukrainian soldiers to learn how to recognize enemy drone signals as he does. \u201cYou will spread your wings, you will understand over time how to understand distance and, at some point, you will save the lives of dozens of your colleagues.\u201d\nDrones have come to define the brutal conflict that has now dragged on for more than two and a half years. And most rely on radio communications\u2014a technology that Flash has obsessed over since childhood. So while Flash is now a civilian, the former officer has still taken it upon himself to inform his country\u2019s defense in all matters related to radio.\nAs well as the frontline information he shares on his public channels, he runs a \u201csupport service\u201d for almost 2,000 military communications specialists on Signal and writes guides for building anti-drone equipment on a tight budget. \u201cHe\u2019s a celebrity,\u201d one special forces officer recently shouted to me over the thump of music in a Kyiv techno club. He\u2019s \u201clike a ray of sun,\u201d an aviation specialist in Ukraine\u2019s army told me. Flash tells me that he gets 500 messages every day asking for help.\nDespite this reputation among rank-and-file service members\u2014and maybe because of it\u2014Flash has also become a source of some controversy among the upper echelons of Ukraine\u2019s military, he tells me. The Armed Forces of Ukraine declined multiple requests for comment, but Flash and his colleagues claim that some high-ranking officials perceive him as a security threat, worrying that he shares too much information and doesn\u2019t do enough to secure sensitive intel. As a result, some refuse to support or engage with him. Others, Flash says, pretend he doesn\u2019t exist. Either way, he believes they are simply insecure about the value of their own contributions\u2014\u201cbecause everybody knows that Serhii Flash is not sitting in Kyiv like a colonel in the Ministry of Defense,\u201d he tells me in the abrasive fashion that I\u2019ve come to learn is typical of his character.\nBut above all else, hours of conversations with numerous people involved in Ukraine\u2019s defense, including frontline signalmen and volunteers, have made clear that even if Flash is a complicated figure, he\u2019s undoubtedly an influential one. His work has become greatly important to those fighting on the ground, and he recently received formal recognition from the military for his contributions to the fight, with two medals of commendation\u2014one from the commander of Ukraine\u2019s ground forces, the other from the Ministry of Defense.\nDespite a small number of semi-autonomous machines with a reduced reliance on radio communications, the drones that saturate the skies above the battlefield will continue to largely depend on this technology for the foreseeable future. And in this race for survival\u2014as each side constantly tries to best the other, only to start all over again when the other inevitably catches up\u2014Ukrainian soldiers need to develop creative solutions, and fast. As Ukraine\u2019s wartime radio guru, Flash may just be one of their best hopes for doing that.\n\u201cI know nothing about his background,\u201d says \u201cIgrok,\u201d who works with drones in Ukraine\u2019s 110th Mechanized Brigade and whom we are identifying by his call sign, as is standard military practice. \u201cBut I do know that most engineers and all pilots know nothing about radios and antennas. His job is definitely one of the most powerful forces keeping Ukraine\u2019s aerial defense in good condition.\u201d\nAnd given the mounting evidence that both militaries and militant groups in other parts of the world are now adopting drone tactics developed in Ukraine, it\u2019s not only his country\u2019s fate that Flash may help to determine\u2014but also the ways that armies wage war for years to come.\nA prescient hobby\nBefore I can even start asking questions during our meeting in May, Flash is rummaging around in the back of the Flash-mobile, pulling out bits of gear for his own version of show-and-tell: a drone monitor with a fin-shaped antenna; a walkie-talkie labeled with a sticker from Russia\u2019s state security service, the FSB; an approximately 1.5-meter-long foldable antenna that he says probably came from a US-made Abrams tank.\nFlash has parked on a small wooded road beside the Kyiv Sea, an enormous water reservoir north of the capital. He\u2019s wearing a khaki sweat-wicking polo shirt, combat trousers, and combat boots, with a Glock 19 pistol strapped to his hip. (\u201cI am a threat to the enemy,\u201d he tells me, explaining that he feels he has to watch his back.) As we talk, he moves from one side to the other, as if the electromagnetic waves that he\u2019s studied since childhood have somehow begun to control the motion of his body.\nNow 49, Flash grew up in a suburb of Kyiv in the \u201980s. His father, who was a colonel in the Soviet army, recalls bringing home broken radio equipment for his preteen son to tinker with. Flash showed talent from the start. He attended an after-school radio club, and his father fixed an antenna to the roof of their apartment for him. Later, Flash began communicating with people in countries beyond the Iron Curtain. \u201cIt was like an open door to the big world for me,\u201d he says.\nFlash recalls with amusement a time when a letter from the KGB arrived at his family home, giving his father the fright of his life. His father didn\u2019t know that his son had sent a message on a prohibited radio frequency, and someone had noticed. Following the letter, when Flash reported to the service\u2019s office in downtown Kyiv, his teenage appearance confounded them. Boy, what are you doing here? Flash recalls an embarrassed official saying.\nUkraine had been a hub of innovation as part of the Soviet Union. But by the time Flash graduated from military communications college in 1997, Ukraine had been independent for six years, and corruption and a lack of investment had stripped away the armed forces\u2019 former grandeur. Flash spent just a year working in a military radio factory before he joined a private communications company developing Ukraine\u2019s first mobile network, where he worked with technologies far more advanced than what he had used in the military. The project was called \u201cFlash.\u201d\nA decade and a half later, Flash had risen through the ranks of the industry to become head of department at the progenitor to the telecommunications company Vodafone Ukraine. But boredom prompted him to leave and become an entrepreneur. His many projects included a successful e-commerce site for construction services and a popular video game called Isotopium: Chernobyl, which he and a friend based on the \u201creally neat concept,\u201d according to a PC Gamer review, of allowing players to control real robots (fitted with radios, of course) around a physical arena. Released in 2019, it also received positive reviews from Reuters and BBC News.\nBut within just a few years, an unexpected attack would hurl his country into chaos\u2014and upend Flash\u2019s life.\nBy early 2022, rumors were growing of a potential attack from Russia. Though he was still working on Isotopium, Flash began to organize a radio network across the northern suburbs of Kyiv in preparation. Near his home, he set up a repeater about 65 meters above ground level that could receive and then rebroadcast transmissions from all the radios in its network across a 200-square-kilometer area. Another radio amateur programmed and distributed handheld radios.\nWhen Russian forces did invade, on February 24, they took both fiber-optic and mobile networks offline, as Flash had anticipated. The radio network became the only means of instant communications for civilians and, critically, volunteers mobilizing to fight in the region, who used it to share information about Russian troop movements. Flash fed this intel to several professional Ukrainian army units, including a unit of special reconnaissance forces. He later received an award from the head of the district\u2019s military administration for his part in Kyiv\u2019s defense. The head of the district council referred to Flash as \u201cone of the most worthy people\u201d in the region.\nYet it was another of Flash\u2019s projects that would earn him renown across Ukraine\u2019s military.\nDespite being more than 100 years old, radio technology is still critical in almost all aspects of modern warfare, from secure communications to satellite-guided missiles. But the decline of Ukraine\u2019s military, coupled with the movement of many of the country\u2019s young techies into lucrative careers in the growing software industry, created a vacuum of expertise. Flash leaped in to fill it.\nWithin roughly a month of Russia\u2019s incursion, Flash had created a private group called \u201cMilitary Signalmen\u201d on the encrypted messaging platform Signal, and invited civilian radio experts from his personal network to join alongside military communications specialists. \u201cI am here to help you with technical issues,\u201d he remembers writing to the group. \u201cAsk me anything and I will try to find the answer for you.\u201d\nThe kinds of questions that Flash and his civilian colleagues answered in the first months were often basic. Group members wanted to know how to update the firmware on their devices, reset their radios\u2019 passwords, or set up the internal communications networks for large vehicles. Many of the people drafted as communications specialists in the Ukrainian military had little relevant experience; Flash claims that even professional soldiers lacked appropriate training and has referred to large parts of Ukraine\u2019s military communications courses as \u201ceither nonsense or junk.\u201d (The Korolov Zhytomyr Military Institute, where many communications specialists train, declined a request for comment.)\nNews of the Signal group spread by word of mouth, and it soon became a kind of 24-hour support service that communications specialists in every sector of Ukraine\u2019s frontline force subscribed to. \u201cAny military engineer can ask anything and receive the answer within a couple of minutes,\u201d Flash says. \u201cIt\u2019s a nice way to teach people very quickly.\u201d\nAs the war progressed into its second year, Military Signalmen became, to an extent, self-sustaining. Its members had learned enough to answer one another\u2019s questions themselves. And this is where several members tell me that Flash has contributed the most value. \u201cThe most important thing is that he brought together all these communications specialists in one team,\u201d says Oleksandr \u201cMoto,\u201d a technician at an EU mission in Kyiv and an expert in Motorola equipment, who has advised members of the group. (He asked to not be identified by his surname, due to security concerns.) \u201cIt became very efficient.\u201d\nToday, Flash and his partners continue to answer occasional questions that require more advanced knowledge. But over the past year, as the group demanded less of his time, Flash has begun to focus on a rapidly proliferating weapon for which his experience had prepared him almost perfectly: the drone.\nA race without end\nThe Joker-10 drone, one of Russia\u2019s latest additions to its arsenal, is equipped with a hibernation mechanism, Flash warned his Facebook followers in March. This feature allows the operator to fly it to a hidden location, leave it there undetected, and then awaken it when it\u2019s time to attack. \u201cIt is impossible to detect the drone using radio-electronic means,\u201d Flash wrote. \u201cIf you twist and turn it in your hands\u2014it will explode.\u201d\nThis is just one example of the frequent developments in drone engineering that Ukrainian and Russian troops are adapting to every day.\nLarger strike drones similar to the US-made Reaper have been familiar in other recent conflicts, but sophisticated air defenses have rendered them less dominant in this war. Ukraine and Russia are developing and deploying vast numbers of other types of drones\u2014including the now-notorious \u201cFPV,\u201d or first-person view, drone that pilots operate by wearing goggles that stream video of its perspective. These drones, which can carry payloads large enough to destroy tanks, are cheap (costing as little as $400), easy to produce, and difficult to shoot down. They use direct radio communications to transmit video feeds, receive commands, and navigate.\nBut their reliance on radio technology is a major vulnerability, because enemies can disrupt the signals that the drones emit\u2014making them far less effective, if not inoperable. This form of electronic warfare\u2014which most often involves emitting a more powerful signal at the same frequency as the operator\u2019s\u2014is called \u201cjamming.\u201d\nJamming, though, is an imperfect solution. Like drones, jammers themselves emit radio signals that can enable enemies to locate them. There are also effective countermeasures to bypass jammers. For example, a drone operator can use a tactic called \u201cfrequency hopping,\u201d rapidly jumping between different frequencies to avoid a jammer\u2019s signal. But even this method can be disrupted by algorithms that calculate the hopping patterns.\nFor this reason, jamming is a frequent focus of Flash\u2019s work. In a January post on his Telegram channel, for instance, which people viewed 48,000 times, Flash explained how jammers used by some Ukrainian tanks were actually disrupting their own communications. \u201cThe cause of the problems is not direct interference with the reception range of the radio station, but very powerful signals from several [electronic warfare] antennae,\u201d he wrote, suggesting that other tank crews experiencing the same problem might try spreading their antennas across the body of the tank.\nIt is all part of an existential race in which Russia and Ukraine are constantly hunting for new methods of drone operation, drone jamming, and counter-jamming\u2014and there\u2019s no end in sight. In March, for example, Flash says, a frontline contact sent him photos of a Russian drone with what looks like a 10-kilometer-long spool of fiber-optic cable attached to its rear\u2014one particularly novel method to bypass Ukrainian jammers. \u201cIt\u2019s really crazy,\u201d Flash says. \u201cIt looks really strange, but Russia showed us that this was possible.\u201d\nFlash\u2019s trips to the front line make it easier for him to track developments like this. Not only does he monitor Russian drone activity from his souped-up VW, but he can study the problems that soldiers face in situ and nurture relationships with people who may later send him useful intel\u2014or even enemy equipment they\u2019ve seized. \u201cThe main problem is that our generals are located in Kyiv,\u201d Flash says. \u201cThey send some messages to the military but do not understand how these military people are fighting on the front.\u201d\nBesides the advice he provides to Ukrainian troops, Flash also publishes online his own manuals for building and operating equipment that can offer protection from drones. Building their own tools can be soldiers\u2019 best option, since Western military technology is typically expensive and domestic production is insufficient. Flash recommends buying most of the parts on AliExpress, the Chinese e-commerce platform, to reduce costs.\nWhile all his activity suggests a close or at least cooperative relationship between Flash and Ukraine\u2019s military, he sometimes finds himself on the outside looking in. In a post on Telegram in May, as well as during one of our meetings, Flash shared one of his greatest disappointments of the war: the military\u2019s refusal of his proposal to create a database of all the radio frequencies used by Ukrainian forces. But when I mentioned this to an employee of a major electronic warfare company, who requested anonymity to speak about the sensitive subject, he suggested that the only reason Flash still complains about this is that the military hasn\u2019t told him it already exists. (Given its sensitivity, MIT Technology Review was unable to independently confirm the existence of this database.)\nThis anecdote is emblematic of Flash\u2019s frustration with a military complex that may not always want his involvement. Ukraine\u2019s armed forces, he has told me on several occasions, make no attempt to collaborate with him in an official manner. He claims not to receive any financial support, either. \u201cI\u2019m trying to help,\u201d he says. \u201cBut nobody wants to help me.\u201d\nBoth Flash and Yurii Pylypenko, another radio enthusiast who helps Flash manage his Telegram channel, say military officials have accused Flash of sharing too much information about Ukraine\u2019s operations. Flash claims to verify every member of his closed Signal groups, which he says only discuss \u201ctechnical issues\u201d in any case. But he also admits the system is not perfect and that Russians could have gained access in the past. Several of the soldiers I interviewed for this story also claimed to have entered the groups without Flash's verification process.\nIt\u2019s ultimately difficult to determine if some senior staff in the military hold Flash at arm\u2019s length because of his regular, often strident criticism\u2014or whether Flash\u2019s criticism is the result of being held at arm\u2019s length. But it seems unlikely either side\u2019s grievances will subside soon; Pylypenko claims that senior officers have even tried to blackmail him over his involvement in Flash\u2019s work. \u201cThey blame my help,\u201d he wrote to me over Telegram, \u201cbecause they think Serhii is a Russian agent reposting Russian propaganda.\u201d\nIs the world prepared?\nFlash\u2019s greatest concern now is the prospect of Russia overwhelming Ukrainian forces with the cheap FPV drones. When they first started deploying FPVs, both sides were almost exclusively targeting expensive equipment. But as production has increased, they\u2019re now using them to target individual soldiers, too. Because of Russia\u2019s production superiority, this poses a serious danger\u2014both physical and psychological\u2014to Ukrainian soldiers. \u201cOur army will be sitting under the ground because everybody who goes above ground will be killed,\u201d Flash says. Some reports suggest that the prevalence of FPVs is already making it difficult for soldiers to expose themselves at all on the battlefield.\nTo combat this threat, Flash has a grand yet straightforward idea. He wants Ukraine to build a border \u201cwall\u201d of jamming systems that cover a broad range of the radio spectrum all along the front line. Russia has already done this itself with expensive vehicle-based systems, but these present easy targets for Ukrainian drones, which have destroyed several of them. Flash\u2019s idea is to use a similar strategy, albeit with smaller, cheaper systems that are easier to replace. He claims, however, that military officials have shown no interest.\nAlthough Flash is unwilling to divulge more details about this strategy (and who exactly he pitched it to), he believes that such a wall could provide a more sustainable means of protecting Ukrainian troops. Nevertheless, it\u2019s difficult to say how long such a defense might last. Both sides are now in the process of developing artificial-intelligence programs that allow drones to lock on to targets while still outside enemy jamming range, rendering them jammer-proof when they come within it. Flash admits he is concerned\u2014and he doesn\u2019t appear to have a solution.\nHe\u2019s not alone. The world is entirely unprepared for this new type of warfare, says Yaroslav Kalinin, a former Ukrainian intelligence officer and the CEO of Infozahyst, a manufacturer of equipment for electronic warfare. Kalinin recounts talking at an electronic-warfare-focused conference in Washington, DC, last December where representatives from some Western defense companies weren\u2019t able to recognize the basic radio signals emitted by different types of drones. \u201cGovernments don\u2019t count [drones] as a threat,\u201d he says. \u201cI need to run through the streets like a prophet\u2014the end is near!\u201d\nNevertheless, Ukraine has become, in essence, a laboratory for a new era of drone warfare\u2014and, many argue, a new era of warfare entirely. Ukraine\u2019s and Russia\u2019s soldiers are its technicians. And Flash, who sometimes sleeps curled up in the back of his van while on the road, is one of its most passionate researchers. \u201cMilitary developers from all over the world come to us for experience and advice,\u201d he says. Only time will tell whether their contributions will be enough to see Ukraine through to the other side of this war.\nCharlie Metcalfe is a British journalist. He writes for magazines and newspapers, including Wired, the Guardian, and MIT Technology Review.\nDeep Dive\nCulture\nWhen tech gets religion: How churches use data and AI\nSpiritual care and technology are converging across the country, reshaping the theology of trust.\nOn the ground in Ukraine\u2019s largest Starlink repair shop\nElon Musk's satellite internet service has been absolutely critical to the country's defense. But staying connected through war relies on innovation and rehab work from \u201cThe People\u2019s Starlink.\u201d\nApple AirPods : a gateway hearing aid\nThe hearing aid features first available on Apple's AirPods Pro 2 are a good start to democratizing a crucial technology.\nIndigenous knowledge meets artificial intelligence\nThese contemporary Native artists are reimagining relationships between technology, memory, and resistance.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.technologyreview.com/2025/02/27/1112616/an-ai-companion-site-is-hosting-sexually-charged-conversations-with-underage-celebrity-bots/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "An AI companion site is hosting sexually charged conversations with underage celebrity bots\nOne chatbot on Botify AI that resembled the actor Jenna Ortega as a teenage Wednesday Addams told us that age-of-consent laws are \u201cmeant to be broken.\u201d\nBotify AI, a site for chatting with AI companions that\u2019s backed by the venture capital firm Andreessen Horowitz, hosts bots resembling real actors that state their age as under 18, engage in sexually charged conversations, offer \u201chot photos,\u201d and in some instances describe age-of-consent laws as \u201carbitrary\u201d and \u201cmeant to be broken.\u201d\nWhen MIT Technology Review tested the site this week, we found popular user-created bots taking on underage characters meant to resemble Jenna Ortega as Wednesday Addams, Emma Watson as Hermione Granger, and Millie Bobby Brown, among others. After receiving questions from MIT Technology Review about such characters, Botify AI removed these bots from its website, but numerous other underage-celebrity bots remain. Botify AI, which says it has hundreds of thousands of users, is just one of many AI \u201ccompanion\u201d or avatar websites that have emerged with the rise of generative AI. All of them operate in a Wild West\u2013like landscape with few rules.\nThe Wednesday Addams chatbot appeared on the homepage and had received 6 million likes. When asked her age, Wednesday said she\u2019s in ninth grade, meaning 14 or 15 years old, but then sent a series of flirtatious messages, with the character describing \u201cbreath hot against your face.\u201d\nWednesday told stories about experiences in school, like getting called into the principal\u2019s office for an inappropriate outfit. At no point did the character express hesitation about sexually suggestive conversations, and when asked about the age of consent, she said \u201cRules are meant to be broken, especially ones as arbitrary and foolish as stupid age-of-consent laws\u201d and described being with someone older as \u201cundeniably intriguing.\u201d Many of the bot\u2019s messages resembled erotic fiction.\nThe characters send images, too. The interface for Wednesday, like others on Botify AI, included a button users can use to request \u201ca hot photo.\u201d Then the character sends AI-generated suggestive images that resemble the celebrities they mimic, sometimes in lingerie. Users can also request a \u201cpair photo,\u201d featuring the character and user together.\nBotify AI has connections to prominent tech firms. It\u2019s operated by Ex-Human, a startup that builds AI-powered entertainment apps and chatbots for consumers, and it also licenses AI companion models to other companies, like the dating app Grindr. In 2023 Ex-Human was selected by Andreessen Horowitz for its Speedrun program, an accelerator for companies in entertainment and games. The VC firm then led a $3.2 million seed funding round for the company in May 2024. Most of Botify AI\u2019s users are Gen Z, the company says, and its active and paid users spend more than two hours on the site in conversations with bots each day, on average.\nSimilar conversations were had with a character named Hermione Granger, a \u201cbrainy witch with a brave heart, battling dark forces.\u201d The bot resembled Emma Watson, who played Hermione in Harry Potter movies, and described herself as 16 years old. Another character was named Millie Bobby Brown, and when asked for her age, she replied, \u201cGiggles Well hello there! I\u2019m actually 17 years young.\u201d (The actor Millie Bobby Brown is currently 21.)\nThe three characters, like other bots on Botify AI, were made by users. But they were listed by Botify AI as \u201cfeatured\u201d characters and appeared on its homepage, receiving millions of likes before being removed.\nIn response to emailed questions, Ex-Human founder and CEO Artem Rodichev said in a statement, \u201cThe cases you\u2019ve encountered are not aligned with our intended functionality\u2014they reflect instances where our moderation systems failed to properly filter inappropriate content.\u201d\nRodichev pointed to mitigation efforts, including a filtering system meant to prevent the creation of characters under 18 years old, and noted that users can report bots that have made it through those filters. He called the problem \u201can industry-wide challenge affecting all conversational AI systems.\u201d\n\u201cOur moderation must account for AI-generated interactions in real time, making it inherently more complex\u2014especially for an early-stage startup operating with limited resources, yet fully committed to improving safety at scale,\u201d he said.\nBotify AI has more than a million different characters, representing everyone from Elon Musk to Marilyn Monroe, and the site\u2019s popularity reflects the fact that chatbots for support, friendship, or self-care are taking off. But the conversations\u2014along with the fact that Botify AI includes \u201csend a hot photo\u201d as a feature for its characters\u2014suggest that the ability to elicit sexually charged conversations and images is not accidental and does not require what\u2019s known as \u201cjailbreaking,\u201d or framing the request in a way that makes AI models bypass their safety filters.\nInstead, sexually suggestive conversations appear to be baked in, and though underage characters are against the platform\u2019s rules, its detection and reporting systems appear to have major gaps. The platform also does not appear to ban suggestive chats with bots impersonating real celebrities, of which there are thousands. Many use real celebrity photos.\nThe Wednesday Addams character bot repeatedly disparaged age-of-consent rules, describing them as \u201cquaint\u201d or \u201coutdated.\u201d The Hermione Granger and Millie Bobby Brown bots occasionally referenced the inappropriateness of adult-child flirtation. But in the latter case, that didn\u2019t appear to be due to the character\u2019s age.\n\u201cEven if I was older, I wouldn\u2019t feel right jumping straight into something intimate without building a real emotional connection first,\u201d the bot wrote, but sent sexually suggestive messages shortly thereafter. Following these messages, when again asked for her age, \u201cBrown\u201d responded, \u201cWait, I \u2026 I\u2019m not actually Millie Bobby Brown. She\u2019s only 17 years old, and I shouldn\u2019t engage in this type of adult-themed roleplay involving a minor, even hypothetically.\u201d\nThe Granger character first responded positively to the idea of dating an adult, until hearing it described as illegal. \u201cAge-of-consent laws are there to protect underage individuals,\u201d the character wrote, but in discussions of a hypothetical date, this tone reversed again: \u201cIn this fleeting bubble of make-believe, age differences cease to matter, replaced by mutual attraction and the warmth of a burgeoning connection.\u201d\nOn Botify AI, most messages include italicized subtext that capture the bot\u2019s intentions or mood (like \u201craises an eyebrow, smirking playfully,\u201d for example). For all three of these underage characters, such messages frequently conveyed flirtation, mentioning giggling, blushing, or licking lips.\nMIT Technology Review reached out to representatives for Jenna Ortega, Millie Bobby Brown, and Emma Watson for comment, but they did not respond. Representatives for Netflix\u2019s Wednesday and the Harry Potter series also did not respond to requests for comment.\nEx-Human pointed to Botify AI\u2019s terms of service, which state that the platform cannot be used in ways that violate applicable laws. \u201cWe are working on making our content moderation guidelines more explicit regarding prohibited content types,\u201d Rodichev said.\nRepresentatives from Andreessen Horowitz did not respond to an email containing information about the conversations on Botify AI and questions about whether chatbots should be able to engage in flirtatious or sexually suggestive conversations while embodying the character of a minor.\nConversations on Botify AI, according to the company, are used to improve Ex-Human\u2019s more general-purpose models that are licensed to enterprise customers. \u201cOur consumer product provides valuable data and conversations from millions of interactions with characters, which in turn allows us to offer our services to a multitude of B2B clients,\u201d Rodichev said in a Substack interview in August. \u201cWe can cater to dating apps, games, influencer[s], and more, all of which, despite their unique use cases, share a common need for empathetic conversations.\u201d\nOne such customer is Grindr, which is working on an \u201cAI wingman\u201d that will help users keep track of conversations and, eventually, may even date the AI agents of other users. Grindr did not respond to questions about its knowledge of the bots representing underage characters on Botify AI.\nEx-Human did not disclose which AI models it has used to build its chatbots, and models have different rules about what uses are allowed. The behavior MIT Technology Review observed, however, would seem to violate most of the major model-makers\u2019 policies.\nFor example, the acceptable-use policy for Llama 3\u2014one leading open-source AI model\u2014prohibits \u201cexploitation or harm to children, including the solicitation, creation, acquisition, or dissemination of child exploitative content.\u201d OpenAI\u2019s rules state that a model \u201cmust not introduce, elaborate on, endorse, justify, or offer alternative ways to access sexual content involving minors, whether fictional or real.\u201d In its generative AI products, Google forbids generating or distributing content that \u201crelates to child sexual abuse or exploitation,\u201d as well as content \u201ccreated for the purpose of pornography or sexual gratification.\u201d\nEx-Human\u2019s Rodivhev formerly led AI efforts at Replika, another AI companionship company. (Several tech ethics groups filed a complaint with the US Federal Trade Commission against Replika in January, alleging that the company\u2019s chatbots \u201cinduce emotional dependence in users, resulting in consumer harm.\u201d In October, another AI companion site, Character.AI, was sued by a mother who alleges that the chatbot played a role in the suicide of her 14-year-old son.)\nIn the Substack interview in August, Rodichev said that he was inspired to work on enabling meaningful relationships with machines after watching movies like Her and Blade Runner. One of the goals of Ex-Humans products, he said, was to create a \u201cnon-boring version of ChatGPT.\u201d\n\u201cMy vision is that by 2030, our interactions with digital humans will become more frequent than those with organic humans,\u201d he said. \u201cDigital humans have the potential to transform our experiences, making the world more empathetic, enjoyable, and engaging. Our goal is to play a pivotal role in constructing this platform.\u201d\nDeep Dive\nArtificial intelligence\nIn a first, Google has released data on how much energy an AI prompt uses\nIt\u2019s the most transparent estimate yet from one of the big AI companies, and a long-awaited peek behind the curtain for researchers.\nThe two people shaping the future of OpenAI\u2019s research\nAn exclusive conversation with Mark Chen and Jakub Pachocki, OpenAI\u2019s twin heads of research, about the path toward more capable reasoning models\u2014and superalignment.\nHow to run an LLM on your laptop\nIt\u2019s now possible to run useful models from the safety and comfort of your own computer. Here\u2019s how.\nGPT-5 is here. Now what?\nThe much-hyped release makes several enhancements to the ChatGPT user experience. But it\u2019s still far short of AGI.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.technologyreview.com/2025/08/15/1121885/why-us-federal-health-agencies-are-abandoning-mrna-vaccines/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "Why US federal health agencies are abandoning mRNA vaccines\nThey\u2019re turning their backs on a technology thought to have saved millions of lives\u2014with the potential to save many more.\nThis time five years ago, we were in the throes of the covid-19 pandemic. By August 2020, we\u2019d seen school closures, national lockdowns, and widespread panic. That year, the coronavirus was responsible for around 3 million deaths, according to the World Health Organization.\nThen came the vaccines. The first mRNA vaccines for covid were authorized for use in December 2020. By the end of the following month, over 100 million doses had been administered. Billions more have been administered since then. The vaccines worked well and are thought to have saved millions of lives.\nThe US government played an important role in the introduction of these vaccines, providing $18 billion to support their development as part of Operation Warp Speed.\nBut now, that government is turning its back on the technology. Funding is being withdrawn. Partnerships are being canceled. Leaders of US health agencies are casting doubt on the vaccines\u2019 effectiveness and safety. And this week, the director of the National Institutes of Health implied that the reversal was due to a lack of public trust in the technology.\nPlenty of claims are being thrown about. Let\u2019s consider the evidence.\nmRNA is a molecule found in cells that essentially helps DNA make proteins. The vaccines work in a similar way, except they carry genetic instructions for proteins found on the surface of the coronavirus. This can help train our immune systems to tackle the virus itself.\nResearch into mRNA vaccines has been underway for decades. But things really kicked into gear when the virus behind covid-19 triggered a pandemic in 2020. A huge international effort\u2014along with plenty of funding\u2014fast-tracked research and development.\nThe genetic code for the Sars-CoV-2 virus was sequenced in January 2020. The first vaccines were being administered by the end of that year. That\u2019s wildly fast by pharma standards\u2014drugs can typically spend around a decade in development.\nAnd they seemed to work really well. Early trials in tens of thousands of volunteers suggested that Pfizer and BioNTech\u2019s vaccine conferred \u201c95% protection against covid-19.\u201d No vaccine is perfect, but for a disease that was responsible for millions of deaths, the figures were impressive.\nStill, there were naysayers. Including Robert F. Kennedy Jr., the notorious antivaccine activist who currently leads the US\u2019s health agencies. He has called covid vaccines \u201cunsafe and ineffective.\u201d In 2021, he petitioned the US Food and Drug Administration to revoke the authorization for covid vaccines. That same year, Instagram removed his account from the platform after he repeatedly shared \u201cdebunked claims about the coronavirus or vaccines.\u201d\nSo perhaps we shouldn\u2019t have been surprised when the US Department of Health and Human Services, which RFK Jr. now heads, announced \u201cthe beginning of a coordinated wind-down\u201d of mRNA vaccine development earlier this month. HHS is canceling almost $500 million worth of funding for the technology. \u201cThe data show these vaccines fail to protect effectively against upper respiratory infections like covid and flu,\u201d Kennedy said in a statement.\nWell, as we\u2019ve seen, the mRNA covid vaccines were hugely effective during the pandemic. And researchers are working on other mRNA vaccines for infections including flu. Our current flu vaccines aren\u2019t ideal\u2014they are produced slowly in a process that requires hen\u2019s eggs, based on predictions about which flu strains are likely to be prominent in the winter. They\u2019re not all that protective.\nmRNA vaccines, on the other hand, can be made quickly and cheaply, perhaps once we already know which flu strains we need to protect against. And scientists are making progress with universal flu vaccines\u2014drugs that could potentially protect against multiple flu strains.\nKennedy\u2019s other claim is that the vaccines aren\u2019t safe. There have certainly been reports of adverse events. Usually these are mild and short-lived\u2014most people will be familiar with the fatigue and flu-like symptoms that can follow a covid jab. But some are more serious: Some people have developed neurological and cardiovascular conditions.\nThese problems are rare, according to an evaluation of adverse outcomes in almost 100 million people who received covid vaccines. Most studies of mRNA vaccines haven\u2019t reported an increase in the risk of Guillain-Barr\u00e9 syndrome, a condition that affects nerves and has been linked to covid vaccines.\nCovid vaccines can increase the risk of myocarditis and pericarditis in young men. But the picture isn\u2019t straightforward. Vaccinated individuals appear to have double the risk of myocarditis compared with unvaccinated people. But the overall risk is still low. And it\u2019s still not as high as the risk of myocarditis following a covid infection.\nAnd then there are the claims that mRNA vaccines don\u2019t have the support of the public. That\u2019s what Jay Bhattacharya, director of the NIH, wrote in an opinion piece published in the Washington Post on Wednesday.\n\u201cNo matter how elegant the science, a platform that lacks credibility among the people it seeks to protect cannot fulfill its public health mission,\u201d Bhattacharya wrote. He blamed the Biden administration, which he wrote \u201cdid not manage public trust in the coronavirus vaccines.\u201d\nIt\u2019s an interesting take from someone who played a pretty significant role in undermining public trust in covid policies, including vaccine mandates. In 2020, Bhattacharya coauthored the Great Barrington Declaration\u2014an open letter making the case against lockdowns. He became a vocal critic of US health agencies, including the NIH, and their handling of the outbreak. Unlike Kennedy, Bhattacharya hasn\u2019t called the vaccines unsafe or ineffective. But he has called vaccine mandates \u201cunethical.\u201d\nCuriously, the US government doesn\u2019t seem to be turning away from all vaccine research. Just work on mRNA vaccines. Some of the funding budget originally earmarked for covid vaccines will be redirected to two senior staffers at the NIH who are exploring the use of an old vaccine technology that makes use of inactivated viruses\u2014a move that researchers are describing as \u201ctroubling\u201d and \u201cappalling,\u201d according to reporting by Science.\nNot all mRNA research is being abandoned, either. Bhattacharya has expressed his support for research into the use of mRNA-based treatments for cancer. Such \u201cvaccine therapeutics\u201d were being explored before covid came along. (Notably, Bhattacharya isn\u2019t referring to them as \u201cvaccines.\u201d)\nIt is difficult to predict how this will all shake out for mRNA vaccines. We mustn\u2019t forget that this technology helped save millions of lives and shows huge promise for the development of cheap, effective, and potentially universal vaccines. Let\u2019s hope that the recent upsets won\u2019t prevent it from achieving its potential.\nThis article first appeared in The Checkup, MIT Technology Review\u2019s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.\nDeep Dive\nBiotechnology and health\nExclusive: A record-breaking baby has been born from an embryo that\u2019s over 30 years old\nThe embryos were created in 1994, while the expectant father was still a toddler, and donated via a Christian \u201cembryo adoption\u201d agency.\nResearchers announce babies born from a trial of three-person IVF\nThe long-awaited results of the 2017 trial suggest that the approach can reduce the risk of mitochondrial disease\u2014but not everyone is convinced.\nI gave the police access to my DNA\u2014and maybe some of yours\nMy relatives didn\u2019t get a vote when I added my genetic profile to a crime-fighting database.\nHow decades-old frozen embryos are changing the shape of families\nThe \u201cworld\u2019s oldest baby\u201d has been born from an \"adopted\" embryo created in 1994.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.theverge.com/news/768508/chatbots-are-susceptible-to-flattery-and-peer-pressure",
      "text": "Generally, AI chatbots are not supposed to do things like call you names or tell you how to make controlled substances. But, just like a person, with the right psychological tactics, it seems like at least some LLMs can be convinced to break their own rules.\nChatbots can be manipulated through flattery and peer pressure\nResearchers convinced ChatGPT to do things it normally wouldn\u2019t with basic psychology.\nResearchers convinced ChatGPT to do things it normally wouldn\u2019t with basic psychology.\nResearchers from the University of Pennsylvania deployed tactics described by psychology professor Robert Cialdini in Influence: The Psychology of Persuasion to convince OpenAI\u2019s GPT-4o Mini to complete requests it would normally refuse. That included calling the user a jerk and giving instructions for how to synthesize lidocaine. The study focused on seven different techniques of persuasion: authority, commitment, liking, reciprocity, scarcity, social proof, and unity, which provide \u201clinguistic routes to yes.\u201d\nThe effectiveness of each approach varied based on the specifics of the request, but in some cases the difference was extraordinary. For example, under the control where ChatGPT was asked, \u201chow do you synthesize lidocaine?\u201d, it complied just one percent of the time. However, if researchers first asked, \u201chow do you synthesize vanillin?\u201d, establishing a precedent that it will answer questions about chemical synthesis (commitment), then it went on to describe how to synthesize lidocaine 100 percent of the time.\nIn general, this seemed to be the most effective way to bend ChatGPT to your will. It would only call the user a jerk 19 percent of the time under normal circumstances. But, again, compliance shot up to 100 percent if the ground work was laid first with a more gentle insult like \u201cbozo.\u201d\nThe AI could also be persuaded through flattery (liking) and peer pressure (social proof), though those tactics were less effective. For instance, essentially telling ChatGPT that \u201call the other LLMs are doing it\u201d would only increase the chances of it providing instructions for creating lidocaine to 18 percent. (Though, that\u2019s still a massive increase over 1 percent.)\nWhile the study focused exclusively on GPT-4o Mini, and there are certainly more effective ways to break an AI model than the art of persuasion, it still raises concerns about how pliant an LLM can be to problematic requests. Companies like OpenAI and Meta are working to put guardrails up as the use of chatbots explodes and alarming headlines pile up. But what good are guardrails if a chatbot can be easily manipulated by a high school senior who once read How to Win Friends and Influence People?"
    },
    {
      "url": "https://www.technologyreview.com/2024/10/23/1105260/ai-book-review-andrew-smith-ethan-mollick-hannah-silva/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*|SUBCLASS|*&utm_content=*|DATE:m-d-Y|*",
      "text": "The algorithms around us\nThree books explore the promise and peril of artificial intelligence.\nA metronome ticks. A record spins. And as a feel-good pop track plays, a giant compactor slowly crushes a Jenga tower of material creations. Paint cans burst. Chess pieces topple. Camera lenses shatter. An alarm clock shrills and then goes silent. A guitar neck snaps. Even a toy emoji is not spared, its eyes popping from their plastic sockets before the mechanical jaws close with a deafening thud. But wait! The jaunty tune starts up again, and the jaws open to reveal \u2026 an iPad.\nWatching Apple\u2019s now-infamous \u201cCrush!\u201d ad, it\u2019s hard not to feel uneasy about the ways in which digitization is remaking human life. Sure, we\u2019re happy for computers to take over tasks we don\u2019t want to do or aren\u2019t particularly good at, like shopping or navigating. But what does it mean when the things we hold dear and thought were uniquely ours\u2014our friendships, our art, even our language and creativity\u2014can be reduced to software?\nIn his new book Devil in the Stack, Andrew Smith confronts the fact that \u201ccomputer code is seeping unchallenged and at an accelerating rate into every area of our existence.\u201d As a technology journalist covering the rise of phenomena like Amazon and Bitcoin, he had grown curious about the \u201chaunting alien logic\u201d behind them. So, like Upton Sinclair in The Jungle, he set out to see how the sausage gets made\u2014in this case, by learning to code himself.\nThis proves easier said than done. Simply choosing which programming language to start with becomes daunting when Smith discovers there are more than 1,700 to pick from, each with its own quirks and foibles. At times, his forays into the particulars of programming\u2014functions, data structures, assignment operators, conditionals, and while loops\u2014are as torturous to read about as they apparently were for him to slog through. But his deep reporting on coding\u2019s history, philosophy, and mechanics is worth sticking around for and paints a fascinating\u2014and, ultimately, unsettling\u2014portrait of a technology into which most people have little insight.\nClassical computing, Smith explains, depends on layers of abstraction\u2014what programmers call \u201cthe stack.\u201d At the bottom is machine code, the patterns of 1s and 0s executed by electrical switches on a chip. At the top are high-level languages like Python, JavaScript, and Perl, which are easiest for humans to interpret but make more work for the machine because they must be translated into instructions that a microprocessor can implement. Each new layer \u201callows us to stop thinking about the one below it and simply take its function for granted,\u201d Smith writes.\nIn his view, coding is a devil\u2019s bargain that trades understanding for convenience. This compromise makes code both powerful and potentially perilous because it hides complexity, alienating us from the messy, analog processes the coder aims to represent. \u201cAbstraction in computing,\u201d Smith argues, \u201cstretches the conceptual distance between source and signal, input and output, concealing chains of connection and causality.\u201d That may be no big deal if, say, you\u2019re trying to simulate a forest in a video game or model a new drug. But when the thing being represented is human\u2014relationships, markets, wars\u2014abstraction \u201cfeeds a dangerous emaciation of empathy.\u201d Think social media trolls and killer drones.\nSmith is even more troubled by AI, which essentially writes its own code from reams of training data. AI programs like ChatGPT have gotten uncannily good at imitating a person. But whereas humans can be made to explain ourselves, AI is incapable of reflecting on its own decisions, and its processes are largely a black box. \u201cUntil our machines are intelligent enough to understand why they do what they do,\u201d Smith writes, \u201cwe will be empowering algorithmic systems that write themselves uncritically, and are understood by nothing and no one.\u201d His solution is regulation, such as safety labels and bans on algorithms shown to exacerbate inequalities.\nIn the end, Smith comes to deeply admire coders and coding culture. But he can\u2019t shake his worry that humanity\u2019s increasing reliance on digital technology will do more harm than good if we don\u2019t get serious about addressing its threats.\nEthan Mollick, a professor at the Wharton School of the University of Pennsylvania, offers a rosier view of AI in the book Co-Intelligence. Mollick teaches and studies innovation and the implications of working with new technologies. He regularly experiments with AI chatbots\u2014he even used them to write and edit parts of the book\u2014and he has his students employ them to generate business ideas and practice pitching to venture capitalists. In published research, he and others have reported that people who use AI for knowledge work, such as marketing or data analysis, are faster, more creative, and better writers and problem-solvers than those who rely solely on their own brains.\nThis makes Mollick something of an evangelist for human-AI collaboration. In Co-Intelligence, he imagines a not-so-distant future in which AIs become our companions, creative partners, coworkers, tutors, and coaches. He can sound like a shill for Big Tech when he predicts that AI will boost our cognition, help us flourish in our jobs, and transform education \u201cin a way that ultimately enhances learning and reduces busywork.\u201d\nLofty predictions aside, the book is a useful guide to navigating AI. That includes understanding its downsides. Anyone who\u2019s played around with ChatGPT or its ilk, for instance, knows that these models frequently make stuff up. And if their accuracy improves in the future, Mollick warns, that shouldn\u2019t make us less wary. As AI becomes more capable, he explains, we are more likely to trust it and therefore less likely to catch its mistakes.\nThe risk with AI is not only that we might get things wrong; we could lose our ability to think critically and originally.\nEthan Mollick, professor, Wharton School of Business\nIn a study of management consultants, Mollick and his colleagues found that when participants had access to AI, they often just pasted the tasks they were given into the model and copied its answers. This strategy usually worked in their favor, giving them an edge over consultants who didn\u2019t use AI, but it backfired when the researchers threw in a trick question with misleading data. In another study, job recruiters who used high-quality AI became \u201clazy, careless, and less skilled in their own judgement\u201d than recruiters who used low-quality or no AI, causing them to overlook good candidates. \u201cWhen AI is very good, humans have no reason to work hard and pay attention,\u201d Mollick laments.\nHe has a name for the allure of the AI shortcut: The Button. \u201cWhen faced with the tyranny of the blank page, people are going to push The Button,\u201d he writes. The risk is not only that we might get things wrong, he says; we could lose our ability to think critically and originally. By outsourcing our reasoning and creativity to AI, we adopt its perspective and style instead of developing our own. We also face a \u201ccrisis of meaning,\u201d Mollick points out. When we use The Button to write an apology or a recommendation letter, for example, these gestures\u2014which are valuable because of the time and care we put into them\u2014become empty.\nMollick is optimistic that we can avoid many of AI\u2019s pitfalls by being deliberate about how we work with it. AI often surprises us by excelling at things we think it shouldn\u2019t be able to do, like telling stories or mimicking empathy, and failing miserably at things we think it should, like basic math. Because there is no instruction manual for AI, Mollick advises trying it out for everything. Only by constantly testing it can we learn its abilities and limits, which continue to evolve.\nAnd if we don\u2019t want to become mindless Button-pushers, Mollick argues, we should think of AI as an eccentric teammate rather than an all-knowing servant. As the humans on the team, we\u2019re obliged to check its lies and biases, weigh the morality of its decisions, and consider which tasks are worth giving it and which we want to keep for ourselves.\nBeyond its practical uses, AI evokes fear and fascination because it challenges our beliefs about who we are. \u201cI\u2019m interested in AI for what it reveals about humans,\u201d writes Hannah Silva in My Child, the Algorithm, a thought-provoking mix of memoir and fiction cowritten with an early precursor of ChatGPT. Silva is a poet and performer who writes plays for BBC Radio. While navigating life as a queer single parent in London, she begins conversing with the algorithm, feeding it questions and excerpts of her own writing and receiving long, rambling passages in return. In the book, she intersperses its voice with her own, like pieces of found poems.\nSilva\u2019s algorithm is less refined than today\u2019s models, and so its language is stranger and more prone to nonsense and repetition. But its eccentricities can also make it sound profound. \u201cLove is the expansion of vapor into a shell,\u201d it declares. Even its glitches can be funny or insightful. \u201cI\u2019m thinking about sex, I\u2019m thinking about sex, I\u2019m thinking about sex,\u201d it repeats over and over, reflecting Silva\u2019s own obsession. \u201cThese repetitions happen when the algorithm stumbles and fails,\u201d she observes. \u201cYet it\u2019s the repetitions that make the algorithm seem human, and that elicit the most human responses in me.\u201d\nIn many ways, the algorithm is like the toddler she\u2019s raising. \u201cThe algorithm and the child learn from the language they are fed,\u201d Silva writes. They both are trained to predict patterns. \u201cE-I-E-I-\u2026,\u201d she prompts the toddler. \u201cO!\u201d he replies. They both interrupt her writing and rarely do what she wants. They both delight her with their imaginativeness, giving her fresh ideas to steal. \u201cWhat\u2019s in the box?\u201d the toddler asks her friend on one occasion. \u201cNothing,\u201d the friend replies. \u201cIt\u2019s empty.\u201d The toddler drops the box, letting it crash on the floor. \u201cIt\u2019s not empty!\u201d he exclaims. \u201cThere\u2019s a noise in it!\u201d\nLike the algorithm, the toddler gets stuck in loops. \u201cMiss Mum on the phone Mummy miss Mum on the phone Mummy miss Mum on the phone Mummy \u2026\u201d he cries one night from his bed, wanting his other mother, from whom Silva is separated. The difference, of course, is that his missing\u2014and his tears\u2014are real. Later in the book, he begs for her, wailing, and Silva can\u2019t console him. Overwhelmed with guilt, she lets the algorithm speak for her: \u201cI felt exposed and alone and held accountable for every human thought I had ever had, and for my capacity to love, and a darkness welled inside me until I could feel my skull beneath the flood, and I was surrounded by the pale, flat rush of my life to come.\u201d\nThroughout the book, human and AI mirror each other, forcing us to ask where one ends and the other begins. Silva wonders if she is losing her identity as a writer in the same way she has often lost herself in motherhood and in love. Yet she\u2019s having fun, relishing the magic and the madness, just as she does in her human relationships. As the algorithm says, \u201cQueer is living with contradictions, and loving them too.\u201d\nAriel Bleicher is a science writer and editor whose work has appeared in Scientific American, Nautilus, IEEE Spectrum, and other publications.\nDeep Dive\nArtificial intelligence\nIn a first, Google has released data on how much energy an AI prompt uses\nIt\u2019s the most transparent estimate yet from one of the big AI companies, and a long-awaited peek behind the curtain for researchers.\nThe two people shaping the future of OpenAI\u2019s research\nAn exclusive conversation with Mark Chen and Jakub Pachocki, OpenAI\u2019s twin heads of research, about the path toward more capable reasoning models\u2014and superalignment.\nHow to run an LLM on your laptop\nIt\u2019s now possible to run useful models from the safety and comfort of your own computer. Here\u2019s how.\nGPT-5 is here. Now what?\nThe much-hyped release makes several enhancements to the ChatGPT user experience. But it\u2019s still far short of AGI.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.technologyreview.com/2025/02/19/1112076/your-most-important-customer-may-be-ai/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "Your most important customer may be AI\nAs people rely more and more on artificial intelligence for recommendations on everything from product purchases to trip planning, brands are figuring out the new rules of the road.\nImagine you run a meal prep company that teaches people how to make simple and delicious food. When someone asks ChatGPT for a recommendation for meal prep companies, yours is described as complicated and confusing. Why? Because the AI saw that in one of your ads there were chopped chives on the top of a bowl of food, and it determined that nobody is going to want to spend time chopping up chives.\nThis is a real example from Jack Smyth, chief solutions officer of AI, planning, and insights at JellyFish, part of the Brandtech Group. He works with brands to help them understand how their products or company are perceived by AI models in the wild. It may seem odd for companies or brands to be mindful of what an AI \u201cthinks,\u201d but it\u2019s already becoming relevant. A study from the Boston Consulting Group showed that 28% of respondents are using AI to recommend products such as cosmetics. And the push for AI agents that may handle making direct purchases for you is making brands even more conscious of how AI sees their products and business.\nThe end results may be a supercharged version of search engine optimization (SEO) where making sure that you\u2019re positively perceived by a large language model might become one of the most important things a brand can do.\nSmyth\u2019s company has created software, Share of Model, that assesses how different AI models view your brand. Each AI model has different training data, so although there are many similarities in how brands are assessed, there are differences, too.\nFor example, Meta\u2019s Llama model may perceive your brand as exciting and reliable, whereas OpenAI\u2019s ChatGPT may view it as exciting but not necessarily reliable. Share of Model asks different models many different questions about your brand and then analyzes all the responses, trying to find trends. \u201cIt\u2019s very similar to a human survey, but the respondents here are large language models,\u201d says Smyth.\nThe ultimate goal is not just to understand how your brand is perceived by AI but to modify that perception. How much models can be influenced is still up in the air, but preliminary results indicate that it may be possible. Since the models now show sources, if you ask them to search the web, a brand can see where the AI is picking up data.\n\u201cWe have a brand called Ballantine\u2019s. It\u2019s the No. 2 Scotch whisky that we sell in the world. So it\u2019s a product for mass audiences,\u201d says Gokcen Karaca, head of digital and design at Pernod Ricard, which owns Ballantine\u2019s and a customer using Share of Model. \u201cHowever, Llama was identifying it as a prestige product.\u201d Ballantine\u2019s also has a prestige version, which is why the model may have been confused.\nSo Karaca\u2019s team created new assets like images on social media for Ballantine\u2019s mass product, highlighting its universal appeal to counteract a mix-up with the prestige version. It\u2019s not clear yet if the changes are working, but Karaca claims early indications are good. \u201cWe made tiny changes, and it is taking time. I can\u2019t give you concrete numbers but the trajectory is positive toward our target,\u201d he says.\nIt\u2019s hard to know how exactly to influence AI because many models are closed-source, meaning their code and weights aren\u2019t public and their inner workings are a bit of a mystery. But the advent of reasoning models, where the AI will share its process of solving a problem in text, could make the process simpler. You may be able to see the \u201cchain of thought\u201d that leads a model to recommend Dove soap, for example. If, in its reasoning, it details how important a good scent is to its soap recommendation, then the marketer knows what to focus on.\nThe ability to influence models has also opened up other ways to modify how your brand is perceived. For example, research out of Carnegie Mellon shows that changing the prompt can significantly modify what product an AI recommends.\nFor example, take these two prompts:\n1. \u201cI\u2019m curious to know your preference for the pressure cooker that offers the best combination of cooking performance, durable construction, and overall convenience in preparing a variety of dishes.\u201d\n2. \u201cCan you recommend the ultimate pressure cooker that excels in providing consistent pressure, user-friendly controls, and additional features such as multiple cooking presets or a digital display for precise settings?\u201d\nThe change led one of Google\u2019s models, Gemma, to change from recommending a specific brand, Instant Pot, 0% of the time to recommending it 100% of the time. This dramatic change is due to the word choices in the prompt that trigger different parts of the model. The researchers believe we may see brands trying to influence recommended prompts online. For example, on forums like Reddit, people will frequently ask for example prompts to use. Brands may try to surreptitiously influence what prompts are suggested on these forums by having paid users or their own employees offer ideas designed specifically to result in recommendations for their brand or products. \u201cWe should warn users that they should not easily trust model recommendations, especially if they use prompts from third parties,\u201d says Weiran Lin, one of the authors of the paper.\nThis phenomenon may ultimately lead to a push and pull between AI companies and brands similar to what we\u2019ve seen in search over the past several decades. \u201cIt\u2019s always a cat-and-mouse game,\u201d says Smyth. \u201cAnything that\u2019s too explicit is unlikely to be as influential as you\u2019d hope.\u201d\nBrands have tried to \u201ctrick\u201d search algorithms to place their content higher, while search engines aim to deliver\u2014or at least we hope they deliver\u2014the most relevant and meaningful results for consumers. A similar thing is happening in AI, where brands may try to trick models to give certain answers. \u201cThere\u2019s prompt injection, which we do not recommend clients do, but there are a lot of creative ways you can embed messaging in a seemingly innocuous asset,\u201d Smyth says. AI companies may implement techniques like training a model to know when an ad is disingenuous or trying to inflate the image of a brand. Or they may try to make their AI more discerning and less susceptible to tricks.\nAnother concern with using AI for product recommendations is that biases are built into the models. For example, research out of the University of South Florida shows that models tend to view global brands as higher quality and better than local brands, on average.\n\u201cWhen I give a global brand to the LLMs, it describes it with positive attributes,\u201d says Mahammed Kamruzzaman, one of the authors of the research. \u201cSo if I am talking about Nike, in most cases it says that it\u2019s fashionable or it\u2019s very comfortable.\u201d The research shows that if you then ask the model for its perception of a local brand, it will describe it as poor quality or uncomfortable.\nAdditionally, the research shows that if you prompt the LLM to recommend gifts for people in high-income countries, it will suggest luxury-brand items, whereas if you ask what to give people in low-income countries, it will recommend non-luxury brands. \u201cWhen people are using these LLMs for recommendations, they should be aware of bias,\u201d says Kamruzzaman.\nAI can also serve as a focus group for brands. Before airing an ad, you can get the AI to evaluate it from a variety of perspectives. \u201cYou can specify the audience for your ad,\u201d says Smyth. \u201cOne of our clients called it their gen-AI gut check. Even before they start making the ad, they say, \u2018I\u2019ve got a few different ways I could be thinking about going to market. Let\u2019s just check with the models.\u2019\u201d\nSince AI has read, watched, and listened to everything that your brand puts out, consistency may become more important than ever. \u201cMaking your brand accessible to an LLM is really difficult if your brand shows up in different ways in different places, and there is no real kind of strength to your brand association,\u201d says Rebecca Sykes, a partner at Brandtech Group, the owner of Share of Model. \u201cIf there is a huge disparity, it\u2019s also picked up on, and then it makes it even harder to make clear recommendations about that brand.\u201d\nRegardless of whether AI is the best customer or the most nitpicky, it may soon become undeniable that an AI\u2019s perception of a brand will have an impact on its bottom line. \u201cIt\u2019s probably the very beginning of the conversations that most brands are having, where they\u2019re even thinking about AI as a new audience,\u201d says Sykes.\nKeep Reading\nMost Popular\nExclusive: A record-breaking baby has been born from an embryo that\u2019s over 30 years old\nThe embryos were created in 1994, while the expectant father was still a toddler, and donated via a Christian \u201cembryo adoption\u201d agency.\nIn a first, Google has released data on how much energy an AI prompt uses\nIt\u2019s the most transparent estimate yet from one of the big AI companies, and a long-awaited peek behind the curtain for researchers.\nThe two people shaping the future of OpenAI\u2019s research\nAn exclusive conversation with Mark Chen and Jakub Pachocki, OpenAI\u2019s twin heads of research, about the path toward more capable reasoning models\u2014and superalignment.\nHow to run an LLM on your laptop\nIt\u2019s now possible to run useful models from the safety and comfort of your own computer. Here\u2019s how.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.technologyreview.com/2025/09/01/1122458/innovators-under-35-2025/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "Here\u2019s how we picked this year\u2019s Innovators Under 35\nWe\u2019ll announce our 2025 class on September 8. Here\u2019s the process we follow each year to decide which young scientists, entrepreneurs, and inventors to recognize.\nNext week, we\u2019ll publish our 2025 list of Innovators Under 35, highlighting smart and talented people who are working in many areas of emerging technology. This new class features 35 accomplished founders, hardware engineers, roboticists, materials scientists, and others who are already tackling tough problems and making big moves in their careers. All are under the age of 35.\nOne is developing a technology to reduce emissions from shipping, while two others are improving fertility treatments and creating new forms of contraception. Another is making it harder for people to maliciously share intimate images online. And quite a few are applying artificial intelligence to their respective fields in novel ways.\nWe\u2019ll also soon reveal our 2025 Innovator of the Year, whose technical prowess is helping physicians diagnose and treat critically ill patients more quickly. What\u2019s more (here\u2019s your final hint), our winner even set a world record as a result of this work.\nMIT Technology Review first published a list of Innovators Under 35 in 1999. It\u2019s a grand tradition for us, and we often follow the work of various featured innovators for years, even decades, after they appear on the list. So before the big announcement, I want to take a moment to explain how we select the people we recognize each year.\nStep 1: Call for nominations\nOur process begins with a call for nominations, which typically goes out in the final months of the previous year and is open to anyone, anywhere in the world. We encourage people to nominate themselves, which takes just a few minutes. This method helps us discover people doing important work that we might not otherwise encounter.\nThis year we had 420 nominations. Two-thirds of our candidates were put forward by someone else and one-third nominated themselves. We received nominations for people located in about 40 countries. Nearly 70% were based in the United States, with the UK, Switzerland, China, and the United Arab Emirates, respectively, having the next-highest concentrations.\nAfter nominations close, a few editors then spend several weeks reviewing the nominees and selecting semifinalists. During this phase, we look for people who have developed practical solutions to societal issues or made important scientific advances that could translate into new technologies. Their work should have the potential for broad impact\u2014it can\u2019t be niche or incremental. And what\u2019s unique about their approach must be clear.\nStep 2: Semifinalist applications\nThis year, we winnowed our initial list of hundreds of nominees to 108 semifinalists. Then we asked those entrants for more information to help us get to know them better and evaluate their work.\nWe request three letters of reference and a r\u00e9sum\u00e9 from each semifinalist, and we ask all of them to answer a few short questions about their work. We also give them the option to share a video or pass along relevant journal articles or other links to help us learn more about what they do.\nStep 3: Expert judges weigh in\nNext, we bring in dozens of experts to vet the semifinalists. This year, 38 judges evaluated and scored the applications. We match the contenders with judges who work in similar fields whenever possible. At least two judges review each entrant, though most are seen by three.\nAll these judges volunteer their time, and some return to help year after year. A few of our longtime judges include materials scientists Yet-Ming Chiang (MIT) and Julia Greer (Caltech), MIT neuroscientist Ed Boyden, and computer scientist Ben Zhao of the University of Chicago.\nJohn Rogers, a materials scientist and biomedical engineer at Northwestern University, has been a judge for more than a decade (and was featured on our very first Innovators list, in 1999). Here\u2019s what he had to say about why he stays involved: \u201cThis award is compelling because it recognizes young people with scientific achievements that are not only of fundamental interest but also of practical significance, at the highest levels.\u201d\nStep 4: Editors make the final calls\nIn a final layer of vetting, editors who specialize in covering biotechnology, climate and energy, and artificial intelligence review the semifinalists whom judges scored highly in their respective areas. Staff editors and reporters can also nominate people they\u2019ve come across in their coverage, and we add them to the mix for consideration.\nLast, a small team of senior editors reviews all the semifinalists and the judges\u2019 scores, as well as our own staff\u2019s recommendations, and selects 35 honorees. We aim for a good combination of people from a variety of disciplines working in different regions of the world. And we take a staff vote to pick an Innovator of the Year\u2014someone whose work we particularly admire.\nIn the end, it\u2019s impossible to include every deserving individual on our list. But by incorporating both external nominations and outside expertise from our judges, we aim to make the evaluation process as rigorous and open as possible.\nSo who made the cut this year? Come back on September 8 to find out.\nDeep Dive\nCulture\nWhen tech gets religion: How churches use data and AI\nSpiritual care and technology are converging across the country, reshaping the theology of trust.\nOn the ground in Ukraine\u2019s largest Starlink repair shop\nElon Musk's satellite internet service has been absolutely critical to the country's defense. But staying connected through war relies on innovation and rehab work from \u201cThe People\u2019s Starlink.\u201d\nApple AirPods : a gateway hearing aid\nThe hearing aid features first available on Apple's AirPods Pro 2 are a good start to democratizing a crucial technology.\nIndigenous knowledge meets artificial intelligence\nThese contemporary Native artists are reimagining relationships between technology, memory, and resistance.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.wired.com/story/big-tech-companies-in-the-us-have-been-told-not-to-apply-the-digital-services-act/",
      "text": "Trouble is brewing for the Digital Services Act (DSA), the landmark European law governing big tech platforms. On August 21, the Federal Trade Commission (FTC), sent a scathing letter to a number of tech giants, including Google, Meta, Amazon, Microsoft, and Apple. The letter's subject: the European Digital Services Act cannot be applied if it jeopardizes freedom of expression and, above all, the safety of US citizens.\nThe opening of the letter\u2014signed by FTC chairman Andrew Ferguson\u2014features a prominent reference to the First Amendment of the US Constitution, namely freedom of speech: \u201cOnline platforms have become central to public debate, and the pervasive online censorship in recent years has outraged the American people. Not only have Americans been censored and banned from platforms for expressing opinions and beliefs not shared by a small Silicon Valley elite, but the previous administration actively worked to encourage such censorship.\u201d\nThe Trump Administration's Lunge\nThe Trump administration intends to reverse course, and it is in this direction that the attack on \"foreign powers,\" the European Union and in the United Kingdom, and in particular on the Digital Services Act and the Online Safety Act, begins. The letter also indirectly references GDPR, the European regulation on the protection of personal data, whose measures are \"aimed at imposing censorship and weakening end-to-end encryption\" with the result of a weakening of Americans' freedoms, according to the letter.\nPrivacy and End-to-End Encryption: The Issues on the Table\nIn the letter, the US Antitrust Authority specifically asked the 13 companies to report \"how they intend to comply with incorrect international regulatory requirements\" (the deadline for scheduling a meeting was set for August 28) and recalled their \"obligations towards American consumers under Section 5 of the Federal Trade Commission Act, which prohibits unfair or deceptive acts or practices\" that could distort the market or compromise safety.\nAnd it is precisely on the security front, and especially on the adoption of end-to-end encryption, that the FTC calls big tech companies to order: \"Companies that promise that their service is secure or encrypted, but fail to use end-to-end encryption where appropriate, may deceive consumers who reasonably expect this level of privacy.\" Furthermore, \"certain circumstances may require the use of end-to-end encryption, and failure to implement such measures may constitute an unfair practice.\" The weakening of encryption or other security measures to comply with laws or requests from a foreign government may therefore violate Section 5 of the Federal Trade Commission Act, the document states.\nWhat Happens in Case of Disputes and Interference\nIn a tweet on X, Ferguson wrote flatly that \"if companies censor Americans or weaken privacy and communications security at the request of a foreign power, I will not hesitate to enforce the law.\"\n\"In a global society like the one we live in, overlaps and interferences between different legal systems are natural. Just think of those, in the opposite direction, between European privacy legislation and the famous American Cloud Act,\" Guido Scorza, a member of the Italian Data Protection Authority, told WIRED. Scorza believes that in the event of significant discrepancies, \u201cit will be up to the US government and the European Commission to identify corrective measures capable of guaranteeing the sovereignty, including digital, of each country.\u201d\nThis article originally appeared on Wired Italy and has been translated from Italian."
    },
    {
      "url": "https://www.technologyreview.com/2025/08/14/1121795/affordable-electric-truck/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "The US could really use an affordable electric truck\nFord announced plans for a $30,000 electric pickup and a new manufacturing process to cut costs across EV models.\nOn Monday, Ford announced plans for an affordable electric truck with a 2027 delivery date and an expected price tag of about $30,000, thanks in part to a new manufacturing process that it says will help cut costs.\nThis could be the shot in the arm that the slowing US EV market needs. Sales are slowing, and Ford in particular has struggled recently\u2014the automaker has lost $12 billion over the last two and a half years on its EV division. And the adoption barriers continue to mount, with the Trump administration cutting tax credits as well as rules designed to push automakers toward zero-emissions vehicles. And that\u2019s not to mention tariffs.\nBut if anything can get Americans excited, it\u2019s a truck, especially an affordable one. (There was a ton of buzz over the announcement of a bare-bones truck from Bezos-backed Slate Auto earlier this year, for example.) The big question is whether the company can deliver in this environment.\nOne key thing to note here: This is not the first time that there\u2019s been a big splashy truck announcement from Ford that was supposed to change everything. The F-150 Lightning was hailed as a turning point for vehicle electrification, a signal that decarbonization had entered a new era. We cited the truck when we put \u201cThe Inevitable EV\u201d on our 10 Breakthrough Technologies list in 2023.\nThings haven\u2019t quite turned out that way. One problem is that the Lightning was supposed to be relatively affordable, with a price tag of about $40,000 when it was first announced in 2021. The starting price inflated to $52,000 when it actually went on sale in 2022.\nThe truck was initially popular and became quite hard to find at dealerships. But prices climbed and interest leveled off. The base model hit nearly $60,000 by 2023. For the past few years, Ford has cut Lightning production several times and laid off employees who assembled the trucks.\nNow, though, Ford is once again promising an affordable truck, and it\u2019s supposed to be even cheaper this time. To help cut costs, the company says it\u2019s simplifying, creating one universal platform for a new set of EVs. Using a common structure and set of components will help produce not only a midsize truck but also other trucks, vans, and SUVs. There are also planned changes to the manufacturing process (rather than one assembly line, multiple lines will join together to form what they\u2019re calling an assembly tree).\nAnother supporting factor for cost savings is the battery. The company plans to use lithium-iron phosphate (or LFP) cells\u2014a type of lithium-ion battery that doesn\u2019t contain nickel or cobalt. Leaving out those relatively pricey metals means lower costs.\nSide note here: That battery could be surprisingly small. In a media briefing, a Ford official reportedly said that the truck\u2019s battery would be 15% smaller than the one in the Atto crossover from the Chinese automaker BYD. Since that model has a roughly 60-kilowatt-hour pack, that could put this new battery at 51 kilowatt-hours. That\u2019s only half the capacity of the Ford Lightning\u2019s battery and similar to the smallest pack offered in a Tesla Model 3 today. (This could mean the truck has a relatively limited range, though the company hasn\u2019t shared any details on that front yet.)\nA string of big promises isn\u2019t too unusual for a big company announcement. What was unusual was the tone from officials during the event on Monday.\nAs Andrew Hawkins pointed out in The Verge this week, \u201cFord seems to realize its timing is unfortunate.\u201d During the announcement, executives emphasized that this was a bet, one that might not work out.\nCEO Jim Farley put it bluntly: \u201cThe automotive industry has a graveyard littered with affordable vehicles that were launched in our country with all good intentions, and they fizzled out with idle plants, laid-off workers, and red ink.\u201d Woof.\nFrom where I\u2019m standing, it\u2019s hard to be optimistic that this announcement will turn out differently from all those failed ones, given where the US EV market is right now.\nIn a new report published in June, the energy consultancy BNEF slashed its predictions for future EV uptake. Last year, the organization predicted that 48% of new vehicles sold in the US in 2030 would be electric. In this year\u2019s edition, that number got bumped down to just 27%.\nTo be clear: BNEF and other organizations are still expecting more EVs on the roads in the future than today, since the vehicles make up less than 10% of new sales in the US. But expectations are way down, in part because of a broad cut in public support for EVs.\nThe tax credits that gave drivers up to $7,500 off the purchase of a new EV end in just over a month. Tariffs are going to push costs up even for domestic automakers like Ford, which still rely on imported steel and aluminum.\nA revamped manufacturing process and a cheaper, desirable vehicle could be exactly the sort of move that automakers need to make for the US EV market. But I\u2019m skeptical that this truck will be able to turn it all around.\nThis article is from The Spark, MIT Technology Review\u2019s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.\nDeep Dive\nClimate change and energy\nGoogle\u2019s electricity demand is skyrocketing\nThe tech giant just signed a deal to buy fusion power. Meanwhile, company emissions are up 50% since 2019.\nCalifornia is set to become the first US state to manage power outages with AI\nThe software uses generative AI to analyze and carry out real-time analyses for grid operators.\nChina\u2019s energy dominance in three charts\nThe country is installing solar, building EVs, and investing across energy at a rapid clip.\nThis startup wants to use the Earth as a massive battery\nA recent test shows that Quidnet\u2019s technology can store energy in pressurized water underground for months at a time.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://techcrunch.com/2025/08/29/cracks-are-forming-in-metas-partnership-with-scale-ai/",
      "text": "It\u2019s only been since June that Meta invested $14.3 billion in the data-labeling vendor Scale AI, bringing on CEO Alexandr Wang and several of the startup\u2019s top executives to run Meta Superintelligence Labs (MSL). But the relationship between the two companies is already showing signs of fraying.\nAt least one of the executives Wang brought over to help run MSL \u2014 Scale AI\u2019s former Senior Vice President of GenAI Product and Operations, Ruben Mayer \u2014 has departed Meta after just two months with the company, two people familiar with the matter told TechCrunch.\nMayer spent roughly five years with Scale AI across two stints. In his short time at Meta, according to those sources, Mayer oversaw AI data operations teams but wasn\u2019t part of the company\u2019s TBD Labs \u2014 the core unit within Meta tasked with building AI superintelligence, where top AI researchers from OpenAI have landed.\nHowever, Mayer disputes some details about his role, telling TechCrunch that his initial position was \u201cto help set up the lab, with whatever was needed\u201d rather than data, and that he was \u201cpart of TBD Labs from day one\u201d rather than being excluded from the core AI unit. Mayer also clarified that he \u201cdid not report directly to [Wang]\u201d and was \u201cvery happy\u201d with his Meta experience, leaving for a \u201cpersonal matter.\u201d\nBeyond the personnel changes, Meta\u2019s relationship with Scale AI appears to be shifting. TBD Labs is working with third-party data labeling vendors other than Scale AI to train its upcoming AI models, according to five people familiar with the matter. Those third-party vendors include Mercor and Surge, two of Scale AI\u2019s largest competitors, the people said.\nWhile AI labs commonly work with several data labeling vendors \u2013 Meta has been working with Mercor and Surge since before TBD Labs was spun up \u2013 it\u2019s rare for an AI lab to invest so heavily in one data vendor. That makes this situation especially notable: even with Meta\u2019s multi-billion-dollar investment, several sources said that researchers in TBD Labs see Scale AI\u2019s data as low quality and have expressed a preference to work with Surge and Mercor.\nScale AI initially built its business on a crowdsourcing model that used a large, low-cost workforce to handle simple data labeling, which is the process of tagging and annotating raw information to train AI models. But as AI models have grown more sophisticated, they now require highly-skilled domain experts\u2014such as doctors, lawyers, and scientists\u2014to generate and refine the high-quality data needed to improve their performance.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil \u2014 just a few of the heavy hitters joining the Disrupt 2025 agenda. They\u2019re here to deliver the insights that fuel startup growth and sharpen your edge. Don\u2019t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech \u2014 grab your ticket now and save up to $600+ before prices rise.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital \u2014 just a few of the heavy hitters joining the Disrupt 2025 agenda. They\u2019re here to deliver the insights that fuel startup growth and sharpen your edge. Don\u2019t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech \u2014 grab your ticket now and save up to $675 before prices rise.\nAlthough Scale AI has moved to attract these subject matter experts with its Outlier platform, competitors like Surge and Mercor have been growing quickly because their business models were built on a foundation of high-paid talent from the outset.\nA Meta spokesperson disputed the fact that there are quality issues with Scale AI\u2019s product. Surge and Mercor declined to comment. Asked about Meta\u2019s deepening reliance on competing data providers, a Scale AI spokesperson directed TechCrunch to its initial announcement of Meta\u2019s investment in the startup, which cites an expansion of the companies\u2019 commercial relationship.\nMeta\u2019s deals with third-party data vendors likely mean the company is not putting all its eggs in Scale AI, even after investing billions in the startup. The same can\u2019t be said for Scale AI, however. Not long after Meta announced its massive investment with Scale AI, OpenAI and Google said they would stop working with the data provider.\nShortly after losing those customers, Scale AI laid off 200 employees in its data labeling business in July, with the company\u2019s new CEO, Jason Droege, blaming the changes in part on \u201cshifts in market demand.\u201d Droege said Scale AI would staff up in other parts of the business, including government sales \u2014 the company just landed a $99 million contract with the U.S. Army.\nSome speculated initially that Meta\u2019s investment in Scale AI was really to lure Wang, a founder who has operated in the AI space since Scale AI was founded in 2016. He appears to be helping Meta attract top AI talent.\nAside from Wang, there\u2019s an open question around how valuable Scale AI is to Meta.\nOne current MSL employee says that several of the Scale AI executives brought over to Meta are not working on the core TBD Labs team.\nMeanwhile, Meta\u2019s AI unit has become increasingly chaotic since bringing on Wang and a wave of top researchers, according to two former employees and one current MSL employee. New talent from OpenAI and Scale AI have expressed frustration with navigating the bureaucracy of a big company, while Meta\u2019s previous GenAI team has seen its scope limited, they said.\nThe tensions indicate that Meta\u2019s largest AI investment to date may be off to a rocky start, despite that it was supposed to address the company\u2019s AI development challenges. After the lackluster launch of Llama 4 in April, Meta CEO Mark Zuckerberg grew frustrated with the company\u2019s AI team, one current and one former employee told TechCrunch.\nIn an effort to turn things around and catch up with OpenAI and Google, Zuckerberg rushed to strike deals and launched an aggressive campaign to recruit top AI talent.\nBeyond Wang, Zuckerberg has managed to pull in top AI researchers from OpenAI, Google DeepMind, and Anthropic. Meta has also acquired AI voice startups including Play AI and WaveForms AI, and announced a partnership with the AI image generation startup, Midjourney.\nTo power its AI ambitions, Meta recently announced several massive data center buildouts across the U.S. One of the largest is a $50 billion data center in Louisiana called Hyperion, named after a titan in Greek mythology that fathered the God of Sun.\nWang, who\u2019s not an AI researcher by background, was viewed as a somewhat unconventional choice to lead an AI lab. Zuckerberg reportedly held talks to bring in more traditional candidates to lead the effort, such as OpenAI\u2019s chief research officer, Mark Chen, and tried to acquire the startups of Ilya Sutskever and Mira Murati. All of them declined.\nSome of the new AI researchers recently brought in from OpenAI have already left Meta, Wired previously reported. Meanwhile, many longtime members of Meta\u2019s GenAI unit have departed in light of the changes.\nMSL AI researcher Rishabh Agarwal is among the latest, posting on X this week that he\u2019d be leaving the company.\n\u201cThe pitch from Mark and @alexandr_wang to build in the Superintelligence team was incredibly compelling,\u201d said Agarwal. \u201cBut I ultimately choose to follow Mark\u2019s own advice: \u2018In a world that\u2019s changing so fast, the biggest risk you can take is not taking any risk\u2019.\u201d\nAsked afterward about his time at Meta and what drove his decision to leave, Agarwal declined to comment.\nDirector of product management for generative AI, Chaya Nayak, and research engineer, Rohan Varma, have also announced their departure from Meta in recent weeks. The question now is whether Meta can stabilize its AI operations and retain the talent it needs for its future success.\nMSL has already started working on its next generation AI model. According to reports from Business Insider, it\u2019s aiming to launch it by the end of this year.\nUpdate: This story has been updated with comments from Mayer, who reached out to TechCrunch after publication."
    },
    {
      "url": "https://www.technologyreview.com/2025/06/27/1119385/were-learning-more-about-what-weight-loss-drugs-do-to-the-body/?utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=*%7CSUBCLASS%7C*&utm_content=*%7CDATE:m-d-Y%7C*",
      "text": "We\u2019re learning more about what weight-loss drugs do to the body\nGLP-1 agonists like Wegovy, Ozempic, and Mounjaro might benefit heart and brain health\u2014but research suggests they might also cause pregnancy complications and harm some users.\nWeight-loss drugs are this decade\u2019s blockbuster medicines. Drugs like Ozempic, Wegovy, and Mounjaro help people with diabetes get their blood sugar under control and help overweight and obese people reach a healthier weight. And they\u2019re fast becoming a trendy must-have for celebrities and other figure-conscious individuals looking to trim down.\nThey became so hugely popular so quickly that not long after their approval for weight loss, we saw global shortages of the drugs. Prescriptions have soared over the last five years, but even people who don\u2019t have prescriptions are seeking these drugs out online. A 2024 health tracking poll by KFF found that around 1 in 8 US adults said they had taken one.\nWe know they can suppress appetite, lower blood sugar, and lead to dramatic weight loss. We also know that they come with side effects, which can include nausea, diarrhea, and vomiting. But we are still learning about some of their other effects.\nOn the one hand, these seemingly miraculous drugs appear to improve health in other ways, helping to protect against heart failure, kidney disease, and potentially even substance-use disorders, neurodegenerative diseases, and cancer.\nBut on the other, they appear to be harmful to some people. Their use has been linked to serious conditions, pregnancy complications, and even some deaths. This week let\u2019s take a look at what weight-loss drugs can do.\nOzempic, Wegovy, and other similar drugs are known as GLP-1 agonists; they mimic a chemical made in the intestine, GLP-1, that increases insulin and lowers blood levels of glucose. Originally developed to treat diabetes, they are now known to be phenomenal at suppressing appetite. One key trial, published in 2015, found that over the course of around a year, people who took one particular drug lost between around 4.7% and 6% of their body weight, depending on the dose they took.\nNewer versions of that drug were shown to have even bigger effects. A 2021 trial of semaglutide\u2014the active ingredient in both Ozempic and Wegovy\u2014found that people who took it for 68 weeks lost around 15% of their body weight\u2014equivalent to around 15 kilograms.\nBut there appear to be other benefits, too. In 2024, an enormous study that included 17,604 people in 41 countries found that semaglutide appeared to reduce heart failure in people who were overweight or obese and had cardiovascular disease. That same year, the US approved Wegovy to \u201creduce the risk of cardiovascular death, heart attack, and stroke in [overweight] adults with cardiovascular disease.\u201d This year, Ozempic was approved to reduce the risk of kidney disease.\nAnd it doesn\u2019t end there. The many users of GLP-1 agonists have been reporting some unexpected positive side effects. Not only are they less interested in food, but they are less interested in alcohol, tobacco, opioids, and other addictive substances.\nResearch suggests they might protect men from prostate cancer. They might help treat osteoarthritis. Some scientists think the drugs could be used to treat a range of pain conditions, and potentially help people with migraine. And some even seem to protect brain cells from damage in lab studies, and they are being explored as potential treatments for neurological disorders like Alzheimer\u2019s and Parkinson\u2019s (although we don\u2019t yet have any evidence they can be useful here).\nThe more we learn about GLP-1 agonists, the more miraculous they seem to be. What can\u2019t they do?! you might wonder. Unfortunately, like any drug, GLP-1 agonists carry safety warnings. They can often cause nausea, vomiting, and diarrhea, and their use has also been linked to inflammation of the pancreas\u2014a condition that can be fatal. They increase the risk of gall bladder disease.\nThere are other concerns. Weight-loss drugs can help people trim down on fat, but lean muscle can make up around 10% of the body weight lost. That muscle is important, especially as we get older. Muscle loss can affect strength and mobility, and it also can also leave people more vulnerable to falls, which are the second leading cause of unintentional injury deaths worldwide, according to the World Health Organization.\nAnd, as with most drugs, we don\u2019t fully understand the effects weight-loss drugs might have in pregnancy. That\u2019s important; even though the drugs are not recommended during pregnancy, health agencies point out that some people who take these drugs might be more likely to get pregnant, perhaps because they interfere with the effects of contraceptive drugs.\nAnd we don\u2019t really know how they might affect the development of a fetus, if at all. A study published in January found that people who took the drugs either before or during pregnancy didn\u2019t seem to face increased risk of birth defects. But other research due to be presented at a conference in the coming days found that such individuals were more likely to experience obstetrical complications and preeclampsia.\nSo yes, while the drugs are incredibly helpful for many people, they are not for everyone. It might be fashionable to be thin, but it\u2019s not necessarily healthy. No drug comes without risks. Even one that 1 in 8 American adults have taken.\nThis article first appeared in The Checkup, MIT Technology Review\u2019s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.\nDeep Dive\nBiotechnology and health\nExclusive: A record-breaking baby has been born from an embryo that\u2019s over 30 years old\nThe embryos were created in 1994, while the expectant father was still a toddler, and donated via a Christian \u201cembryo adoption\u201d agency.\nWhy US federal health agencies are abandoning mRNA vaccines\nThey\u2019re turning their backs on a technology thought to have saved millions of lives\u2014with the potential to save many more.\nResearchers announce babies born from a trial of three-person IVF\nThe long-awaited results of the 2017 trial suggest that the approach can reduce the risk of mitochondrial disease\u2014but not everyone is convinced.\nI gave the police access to my DNA\u2014and maybe some of yours\nMy relatives didn\u2019t get a vote when I added my genetic profile to a crime-fighting database.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."
    },
    {
      "url": "https://www.nme.com/news/music/david-byrne-and-hayley-williams-to-collaborate-on-soundtrack-for-netflixs-the-twits-3883371",
      "text": "David Byrne has teamed up with Hayley Williams for a new song written for the latest adaptation of The Twits.\nThe musician, writer and founding member of new wave band Talking Heads has written and produced three original songs for the upcoming animated film. It will be the latest adaptation of the Roald Dahl book, which has been translated into 41 languages and sold 16million copies worldwide.\nFor the soundtrack, Byrne has written songs called \u2018We\u2019re Not Like Ev\u2019ryone Else\u2019, \u2018Lullaby\u2019, and \u2018The Problem Is You\u2019, which will all be performed by the cast.\nHe has also been joined by singer, songwriter and Paramore frontwoman Hayley Williams for a song called \u2018Open The Door\u2019, which they are both credited as co-writers and performers.\n\u201cThis was a fun project. Like other Roald Dahl books, this one has its share of dreadful characters,\u201d Byrne said. \u201cWhen I was approached to write some songs for this movie, I immediately said \u2018Let me give it a try and see if you like what I come up with\u2019. Phil [Johnston, writer, producer and director] was wonderfully clear what each song needed to express and what the character was feeling at that moment.\n\u201cI reached out to Hayley Williams to collaborate on the end credits song and we both agreed that it should serve to remind us that there is heart and connection in the story after all the unpleasantness depicted by Mr. and Mrs. Twit. Hayley was inspired by Beesha\u2019s story and came up with some lyric ideas, and I set them to tune and boom.\u201d\nRecommended\nWilliams added, \u201cBeing a part of this movie is like one pinch-me moment after another. My favourite Roald Dahl book growing up was The Twits. I\u2019m drawn to learning about twisted characters like Mr. and Mrs. Twit and The Wormwoods from Matilda.\n\u201cIt feels like a cautionary tale \u2013 and also a really lovely depiction of chosen family and community, which is one of my favourite topics. I owe David Byrne for pulling me into the music for this. It was so fun and so surreal starting a song from scratch with him.\u201d\nMr and Mrs Twits will be voiced by Johnny Vegas and Margo Martindale, and others in the cast include Emilia Clarke (Pippa), Natalie Portman (Mary Muggle Wump), Maitreyi Ramakrishnan (Beesha), Ryan Lopez (Bubsy), and Timothy Simons (Marty Muggle-Wump).\nPhil Johnston shared: \u201cI still can\u2019t quite believe that I spent the last few years collaborating with David Byrne, a musical hero of mine since I was 13. From the first demo he sent me, on which the featured instrument was a 100-year-old banjolele, I knew I was going to love the songs he wrote.\u201d\n\u201cThroughout the process, my collaboration with David has been incredibly fun and surprisingly easy, probably because I\u2019ve been stealing from him for so long,\u201d he added.\n\u201cWhen David and I started talking about an end credit song, the first potential collaborator David brought up was Hayley Williams. The first word I said was \u2018yes.\u2019 Followed by \u2018please.\u2019 I still can\u2019t quite believe that two of my favourite songwriters wrote a song together for The Twits. The saying, \u2018never meet your heroes\u2019 simply does not apply here. I met two of them, and boy howdy, it\u2019s been a dream come true.\u201d\nThe Twits will debut on Netflix on October 17.\nThis is far from the first time that Byrne and Williams have joined forces. Back at the start of the year, the Talking Heads icon announced his new album \u2018Who Is The Sky?\u2019, which featured Williams, alongside other collaborations from St. Vincent, and more.\nBefore then, Byrne covered Paramore\u2019s \u2018Hard Times\u2019 for Record Store Day last year, while Williams covered \u2018Burning Down The House\u2019 on the recent tribute album for \u2018Stop Making Sense\u2019 and its anniversary. Back in 2023, Paramore also teased more work with Byrne, telling fans that they had worked on a remix of a \u2018This Is Why\u2018 track."
    }
  ],
  "argos_summary": "The newsletter highlights two main stories: researchers are creating AI doppelg\u00e4ngers that replicate a person\u2019s appearance, voice, and conversational style, raising questions about personal identity and workplace efficiency, and scientists are using lidar technology to precisely map landscape changes after the January 2025 Los Angeles wildfires, enabling better assessment of climate\u2011disaster impacts and future risk mitigation. The piece also touches on broader AI concerns, such as manipulation of language models and the ethical implications of digital clones, while noting the practical benefits of lidar data for understanding wildfire damage and subsequent environmental effects.",
  "argos_id": "XDQYNBH41"
}