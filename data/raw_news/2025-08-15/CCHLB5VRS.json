{
  "url": "https://www.techradar.com/ai-platforms-assistants/gemini/google-flight-deals-is-basically-an-ai-travel-agent-for-finding-your-next-trip",
  "authorsByline": "Eric Hal Schwartz",
  "articleId": "35a985c43c674ed99fa127b279a22fb9",
  "source": {
    "domain": "techradar.com",
    "paywall": false,
    "location": {
      "country": "in",
      "city": "New Delhi",
      "coordinates": {
        "lat": 28.6138954,
        "lon": 77.2090057
      }
    }
  },
  "imageUrl": "https://cdn.mos.cms.futurecdn.net/oGqjBMTKhqtXm6FS6BvjHD.png",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-16T00:30:00+00:00",
  "addDate": "2025-08-16T00:33:33.300397+00:00",
  "refreshDate": "2025-08-16T00:33:33.300398+00:00",
  "score": 1.0,
  "title": "Google\u2019s new Flight Deals uses Gemini AI to turn casual travel ideas into personalized flight options",
  "description": "Gemini AI can turn your vague idea of a vacation into actual tickets",
  "content": "\u2022 Google\u2019s new Flight Deals uses AI to find trips based on conversational requests\n\u2022 It uses Gemini 2.5 to interpret descriptions of feelings and vague time frames to compile deals\n\u2022 Flight Deals is rolling out in beta across the U.S., Canada, and India\n\nGoogle is using Gemini AI to reinvent the travel agent experience, turning conversations into airplane tickets. The new Flight Deals product, which is now in beta, adds AI chat to Google Flights users looking for a good deal or who are still trying to decide where and when they want to travel.\n\nInstead of fiddling with destination drop-down menus and departure time sliders, you can simply write out the type of trip you want to take and whatever else might be important to you when traveling. Instead of an airport code and a date, you can pick a season, the vibe of the location, and how you feel about very early flights. Gemini will then scan real-time pricing from hundreds of airlines and deliver up-to-date options tailored to your request.\n\nThis isn\u2019t a replacement for traditional Google Flights. That familiar grid of dates and sliders is still alive and well. But Google thinks Flight Deals is perfect for the flexible (or just indecisive) traveler. Think of it like that one friend who is not only really good at finding travel bargains, but truly loves finding them for friends.\n\nFor instance, when I wrote \"I want to go where I can see the Northern Lights in December for a week.\" I had suggestions for Alaska, Iceland, and Norway with some good deals across December. When I requested \"Somewhere with mountains and great food in the spring,\" I saw flights from March to June to Denver, Munich, Auckland, and more.\n\nThe more casual your phrasing, the more it has to work with. The AI will attempt to match not just the location but the spirit of your request. Gemini 2.5 has been behind the curtain in plenty of recent Google products, but this is one of the first times it\u2019s being used this way.\n\nIt also marks one of Google\u2019s clearest moves yet to bring AI into a very public, popular space, finding bargains on flights. Airline tickets are perfect for enticing people to try AI, as buying them is a common, but not everyday experience, and expensive enough that people will make an effort to find a good deal without being so expensive that people wouldn't trust AI to help them when it's still possible for the technology to fail.\n\nFlight Deals is still learning, and it may not always pick the perfect itinerary. But if it helps people discover that, for instance, flights to Oaxaca in January are very cheap and the mole is life-changing, that\u2019s a win.\n\nYou might also like\n\u2022 You can now edit images in Gemini directly\n\u2022 I tried Gemini's new AI image generation tool - here are 5 ways to get the best art from Google's upcoming Flash 2.0 built-in image upgrade\n\u2022 I used Google Gemini to analyze YouTube, and the results were seriously impressive - 4 ways you can use video integration to get the most from AI",
  "medium": "Article",
  "links": [
    "https://www.techradar.com/computing/artificial-intelligence/you-can-now-edit-images-in-gemini-directly",
    "https://www.techradar.com/computing/artificial-intelligence/google-ai-mode-is-getting-a-bigger-ai-brain-from-gemini",
    "https://www.techradar.com/computing/artificial-intelligence/google-gemini-2-5-just-got-a-new-deep-think-mode-and-6-other-upgrades",
    "https://www.techradar.com/computing/artificial-intelligence/i-used-google-gemini-to-analyze-youtube-and-the-results-were-seriously-impressive-4-ways-you-can-use-video-integration-to-get-the-most-from-ai",
    "https://www.techradar.com/computing/artificial-intelligence/google-just-announced-5-new-gemini-features-coming-to-android-and-its-good-news-for-fans-of-foldable-smartphones",
    "https://www.techradar.com/computing/artificial-intelligence/i-tried-geminis-new-ai-image-generation-tool-here-are-5-ways-to-get-the-best-art-from-googles-flash-2-0"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Google Gemini",
      "weight": 0.10027906
    },
    {
      "name": "Google Flights",
      "weight": 0.08457936
    },
    {
      "name": "recent Google products",
      "weight": 0.083845675
    },
    {
      "name": "Flight Deals",
      "weight": 0.08350476
    },
    {
      "name": "Google Flights users",
      "weight": 0.082659714
    },
    {
      "name": "AI chat",
      "weight": 0.081800595
    },
    {
      "name": "traditional Google Flights",
      "weight": 0.08095334
    },
    {
      "name": "AI",
      "weight": 0.08049587
    },
    {
      "name": "Google",
      "weight": 0.08044758
    },
    {
      "name": "Gemini AI",
      "weight": 0.077085555
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/Travel & Transportation/Transportation/Air Travel",
      "score": 0.80712890625
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.779296875
    },
    {
      "name": "/News/Technology News",
      "score": 0.70654296875
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.362548828125
    },
    {
      "name": "/Travel & Transportation/Travel Agencies & Services/Other",
      "score": 0.30126953125
    }
  ],
  "sentiment": {
    "positive": 0.2620583,
    "negative": 0.25802693,
    "neutral": 0.47991472
  },
  "summary": "Google has introduced its new Flight Deals product, which uses Gemini AI to find flights based on customer requests and descriptions. The product is now in beta across the US., Canada, and India. It uses Gemini 2.5 to interpret descriptions of feelings and vague time frames to compile deals. Users can choose a season, location, vibe, and how they feel about very early flights. Gemini scans real-time pricing from hundreds of airlines and delivers up-to-date options tailored to their request. This move is seen as one of Google's clearest moves yet to bring AI into a public space, finding bargains on flights.",
  "shortSummary": "Google's new Flight Deals product uses Gemini 2.5 to personalize casual travel requests, allowing users to discover personalized flights based on preferences.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "439145010c6e4cbc9275337b6c369445",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.techradar.com/computing/artificial-intelligence/google-just-announced-5-new-gemini-features-coming-to-android-and-its-good-news-for-fans-of-foldable-smartphones",
      "text": "Google just announced 5 new Gemini features coming to Android, and it\u2019s good news for fans of foldable smartphones\nSamsung Galaxy Unpacked's many new products and features have not left out AI examples. Plenty involved Google and its Gemini family of AI models, with a host of new features coming to Android devices with the new Android 16 and Wear OS 6 systems. Here are some of the ones to be the most excited for.\nGemini Live gets way more useful on foldables\nGemini Live is a way for Google's AI companion to be present on a continuous basis. Rather than just asking a question and moving on, you can have it on hand to help as you follow a cooking tutorial, fix your bike, or do yoga. Starting with the Galaxy Z Flip7, Gemini Live will now be accessible right from the external screen, meaning you won't have to even unfold the device to interact with the AI.\nYou'll also be able to link Gemini Live via Flex Mode with full camera integration. So, you might flip your phone halfway open, tap the camera button, and have Gemini be a hands-free AI assistant that can actually see what you're doing or what's happening around you and offer advice on your half-completed DIY project or your latest outfit. You can show Gemini what you're looking at and get on-the-spot feedback without fully unfolding your phone.\nCircle to Search gets a big Gemini upgrade\nCircle to Search is Google Gemini's party trick of looking up things you draw a circle around on your screen, like a photo or a phrase written in a text you're looking at. It's a way to get Google Search results without switching apps. The trick is becoming a lot more impressive with an AI Mode upgrade.\nNow, when you circle a word, image, or phrase, Gemini doesn\u2019t just look it up on Search; it starts up the AI Mode version of online search with a conversation that allows you to ask follow-up questions and look into related ideas within the same setup. You can discuss complex topics right from your screen with Gemini without switching among multiple tabs and apps.\nGaming the Circle\nThat's not the only major upgrade to Circle to Search. The feature will now try to entice people playing video games to look things up just like someone circling an unfamiliar plant. The new Gemini-powered feature offers mobile gamers help in the context of the game. You can just circle something on the screen as you're playing, like an item, enemy, or puzzle, and Gemini will identify it and offer timestamped advice based on your progress about what to do next if you're stumped. It's sort of an interactive walkthrough and strategy guide that you don't need to stop playing to look through.\nGemini Live starts talking to your apps\nUntil now, Gemini has mostly been incorporated into Google apps and services. But, Gemini Live will now start integrating with native device apps, starting with Samsung\u2019s Calendar, Notes, and Reminders apps. So, you could ask Gemini to summarize your day, add reminders about your next meeting, and organize your notes about what to buy for a vacation you took last week without opening those apps. Other apps will start offering their information to you through Gemini Live soon, with the end goal apparently a more proactive AI manager of your life.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nGemini finally shows up on your wrist\nGoogle Assistant has often seemed to struggle on smartwatches, but Gemini will apparently feel right at home on your wrist, starting with the Galaxy Watch8 series and Wear OS 6, with other smartwatches to follow. Gemini will provide better notifications, real-time voice support, and contextual responses to what you ask the smartwatch. The interface is supposed to be more natural as well, with the AI not feeling like an afterthought.\nYou might also like\nEric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of the world and technology. For the last five years, he served as head writer for Voicebot.ai and was on the leading edge of reporting on generative AI and large language models. He's since become an expert on the products of generative AI models, such as OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, Google Gemini, and every other synthetic media tool. His experience runs the gamut of media, including print, digital, broadcast, and live events. Now, he's continuing to tell the stories people want and need to hear about the rapidly evolving AI space and its impact on their lives. Eric is based in New York City.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    },
    {
      "url": "https://www.techradar.com/computing/artificial-intelligence/i-used-google-gemini-to-analyze-youtube-and-the-results-were-seriously-impressive-4-ways-you-can-use-video-integration-to-get-the-most-from-ai",
      "text": "I used Google Gemini to analyze YouTube, and the results were seriously impressive - 4 ways you can use video integration to get the most from AI\nFigure out the when and what, even if the video doesn't tell you\nThere are a lot of great YouTube videos with tons of interesting information, but sometimes you're in a hurry or trying to find something specific amid what may or may not be padding. Happily, Google Gemini can analyze YouTube videos on your behalf and really dive into the details you might have missed or didn't have time to get to. I don't just mean transcribing it or guessing what\u2019s going on based on the title. And because Gemini and YouTube are both Google products, you don't have to download the video and reupload it, just share the link to the video and start asking questions.\nIt's pretty straightforward to use, but there are some benefits you might not immediately notice. Here are some of my favorite ways to use the AI feature.\nTimestamped summaries\nTo get Gemini to analyze a YouTube video, you just have to ask it to do just that and include a YouTube link. For instance, I asked Gemini to \"analyze this video\" and pasted in the YouTube link to a great Defunctland video about the history of The Muppet Show.\nGemini came back with a long breakdown of the video's exploration of how Jim Henson brought the show to TV, the evolution of the characters, how the show worked, and its legacy. Even better, it had helpful hyperlinks taking me right to where in the video those bits are discussed.\nTimestamped trivia\nAs useful as the summaries are, sometimes you want something more specific. For instance, I asked Gemini to analyze a video about the perfect two-week trip to Japan. The summary it provided was great, but I wanted to see more about what to eat when in Tokyo, so I asked Gemini to tell me, \"When in the video does it discuss restaurants in Tokyo?\" It gave me a couple of sentences of what the video recommends and provided a hyperlink to where the discussion starts.\nI like the idea of not having to wait for the part of the video you want and getting right into it, even if the video maker didn't set up chapters for the video, especially if I'm hungry and thinking about travel at the same time.\nLocate film spots\nIf you're not paying close attention or have the video on mute, you might not always realize what you're seeing on screen. You can ask Gemini to remedy that for you. In the Japan video, as I half-watched the second half, a beautiful market with a million exciting shops was shown in a montage. I noted the time in the video and asked Gemini about what the video was discussing at that point. The answer turned out to be the Nishiki Market and its more than 100 food stalls. Definitely a must-see on my imagined journey to Japan.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nQuiz time\nOne of the underrated fun (and very nerdy) activities you can do with Gemini and YouTube is to make a little quiz on the video. It took less than a minute for Gemini to put together 10 questions that would fit on a Muppet Studies 101 midterm. The questions included everything from the premise of the show to guest stars and popular recurring segments and even its impact on later shows.\nI continued the quiz and ended up getting 9 out of 10 questions correct. Gemini even offered a little summary of what I missed and suggested rewatching a specific 30-second clip if I wanted a refresher. But as silly as making a quiz on a video made just for fun might be, it also shows how it could work with anything. You could test yourself on history videos, science explainers, cooking tutorials, and anything else you really want to learn. Gemini might make some of those videos a real lesson and not just momentary entertainment.\nYou might also like\nEric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of the world and technology. For the last five years, he served as head writer for Voicebot.ai and was on the leading edge of reporting on generative AI and large language models. He's since become an expert on the products of generative AI models, such as OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, Google Gemini, and every other synthetic media tool. His experience runs the gamut of media, including print, digital, broadcast, and live events. Now, he's continuing to tell the stories people want and need to hear about the rapidly evolving AI space and its impact on their lives. Eric is based in New York City.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    },
    {
      "url": "https://www.techradar.com/computing/artificial-intelligence/you-can-now-edit-images-in-gemini-directly",
      "text": "You can now edit images in Gemini directly\n- Google\u2019s Gemini can now edit both AI-generated and personal images using text prompts\n- The editing tools allow for precision changes using AI\n- Gemini also now supports uploading up to 10 images or files at once\nGoogle's Gemini AI is taking out a canvas and palette for your AI-fueled image creation in a couple of major upgrades. Gemini can now edit images directly within its chat interface, and you can send a bunch of images (or other files) for it to examine at the same time.\nThe new editor can work AI magic on any image you upload or that Gemini produces. You simply ask Gemini to make the changes you want. You can change the backdrop of your vacation photo to put your sad Airbnb kitchen on a Santorini cliff, get rid of that mustard stain on your jacket, and even put a funny hat on your dog despite her refusal of all headwear in real life.\nYou can apply multiple edits through your conversation with Gemini, stacking changes as you go. And each modification keeps earlier changes, so you don't have to start from scratch when you decide the last couple of edits made things worse.\nUnder the hood, Gemini\u2019s editor is running a combination of tools that work together so you don't end up with a visual Frankenstein's monster stitching together conflicting textures, lighting, angles, and other aspects of the image. Gemini promises to keep things grounded in reality even when your imagination goes off the rails.\nGoogle claims the editor will have many positive uses for a range of professions. Teachers could quickly build illustrated storyboards, designers could make a portfolio of product photos, and architects might visualize tweaks to building designs mid-meeting.\nThe editor pairs nicely with Google's move to blow up the single-file upload limit for Gemini. Now you can upload up to ten images, PDFs, or other files all at once and ask Gemini to make sense of the mess.\nAI image imagination\nYou may be wondering how Gemini's editor will prevent people from leveraging its abilities to make deepfakes of real people or events for less than benign reasons. Google is keen to show that the company has thought of that. That's why every AI-edited image gets not one but two watermarks. One is visible, and one uses Google\u2019s SynthID, which can only be detected with software. There are also filters powered by human feedback that block ethically dicey requests.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nThe editor and expanded upload option are not breaking new ground, but they add depth to Gemini. It\u2019s not just about what Gemini can tell you, it\u2019s about what it can help you make. Google is investing a lot of effort in building Gemini into the kind of well-rounded, versatile toolkit that people are comfortable relying on.\nInstead of thinking of Gemini as a mere digital notetaker or search engine with a sense of humor, Google wants people to view Gemini as a partner in creative and productive tasks. We\u2019re still a ways off from a world where you ask Gemini to \u201cdesign a birthday card and bake the cake,\u201d but it's closer than you might think. Until then, being able to throw ten files at Gemini and have it respond with something coherent while also placing a hat on your dog is a pretty good start.\nYou might also like\n- I tried Gemini's new AI image generation tool - here are 5 ways to get the best art from Google's upcoming Flash 2.0 built-in image upgrade\n- I compared Adobe\u2019s new Firefly Image Model 4 to ChatGPT\u2019s image generator, and it\u2019s like they went to the same art school\n- I turned my dog into a plushie using AI and it was super easy\nEric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of the world and technology. For the last five years, he served as head writer for Voicebot.ai and was on the leading edge of reporting on generative AI and large language models. He's since become an expert on the products of generative AI models, such as OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, Google Gemini, and every other synthetic media tool. His experience runs the gamut of media, including print, digital, broadcast, and live events. Now, he's continuing to tell the stories people want and need to hear about the rapidly evolving AI space and its impact on their lives. Eric is based in New York City.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    },
    {
      "url": "https://www.techradar.com/computing/artificial-intelligence/google-ai-mode-is-getting-a-bigger-ai-brain-from-gemini",
      "text": "Google AI Mode is getting a bigger AI brain from Gemini\nThe latest AI model and Deep Search for the conversational search engine\n- Google has upgraded its AI Mode with the advanced Gemini 2.5 Pro\n- AI Mode has also added Deep Search, which can now run hundreds of background searches\n- A new calling tool built into Search lets Google call businesses on your behalf\nGoogle is continuing to try to get you to use its AI Mode when searching online with new and enhanced AI tools. The conversational search tool has made Google's Gemini 2.5 Pro AI model available in AI Mode, along with the long-form report writing tool Deep Search.\nGoogle AI Pro and AI Ultra subscribers in the U.S. who are also part of the AI Mode experiment in Search Labs will now see an option to choose Gemini 2.5 Pro when asking tough questions as well.\nThis is the same heavyweight model behind Google\u2019s most advanced AI tools. They'll also have the option of using Deep Search, a feature available in the regular Gemini app that can simultaneously run hundreds of searches and will write up a report piecing together the information.\nThe more profound changes, though, are in how Search itself is evolving. Gemini 2.5 Pro doesn\u2019t just fetch answers. It reasons. It explains math in full steps. It even writes code and tells you what that code is doing. And when paired with Deep Search, it can essentially conduct a research marathon on your behalf.\nAI calling in\nThe new call feature for Search is something entirely different. It connects your search for information about a store to a phone call with AI. As Google shows in a demo, you can type \u201cpet groomers near me\u201d and ask for information not immediately accessible.\nInstead, you can tap \u201cHave Google call for you,\u201d which will prompt Google to call local shops, ask about availability or rates, and then text or email the results directly to you. If that sounds like Google Duplex, that's because Google's Duplex technology powers it.\nOf course, all this comes with a few asterisks such as having to pay for a subscription. Free users still get some limited AI call attempts, but the advanced AI Mode tools are reserved for paying customers.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nGoogle\u2019s advantage over other AI developers is the sheer size of its Search database, so even as OpenAI and others attempt to produce similar products, Google might have a lasting edge. Still, there\u2019s a learning curve.\nAI that does too much too fast can lead to problems. You don\u2019t want your research assistant skipping over credible sources in favor of a Reddit thread with 38 upvotes. And you certainly don\u2019t want your AI calling the wrong person to schedule a colonoscopy.\nYou might also like\nEric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of the world and technology. For the last five years, he served as head writer for Voicebot.ai and was on the leading edge of reporting on generative AI and large language models. He's since become an expert on the products of generative AI models, such as OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, Google Gemini, and every other synthetic media tool. His experience runs the gamut of media, including print, digital, broadcast, and live events. Now, he's continuing to tell the stories people want and need to hear about the rapidly evolving AI space and its impact on their lives. Eric is based in New York City.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    },
    {
      "url": "https://www.techradar.com/computing/artificial-intelligence/google-gemini-2-5-just-got-a-new-deep-think-mode-and-6-other-upgrades",
      "text": "Google Gemini 2.5 just got a new 'Deep Think' mode \u2013 and 6 other upgrades\n- Google Gemini 2.5 Pro is getting a new Deep Think model\n- Deep Think allows Gemini to consider multiple reasoning paths before responding\n- Deep Think will improve Gemini's accuracy on complex math and code\nGoogle is adding some extra brainpower to Gemini with a new Deep Think Mode. The company unveiled the latest option for Google Gemini 2.5 Pro at Google I/O 2025, showing off just what its AI can do with extra depth.\nDeep Think basically augments Gemini's AI 'mind' with additional brains. Gemini in Deep Think mode won't just spit out an answer to a query as fast as possible. Instead, it runs multiple possible lines of reasoning in parallel before deciding how to respond. It\u2019s like the AI equivalent of looking both ways, or rereading the instructions before building a piece of furniture.\nAnd if Google's tests are anything to go by, Deep Think's brainpower is working. It\u2019s performing at a top-tier level on the 2025 U.S. math olympiad, coming out on top in the LiveCodeBench competitive programming test, scoring an amazingly high 84% on the popular MMMU, a sort of decathlon of multimodal reasoning tasks. Deep Think isn\u2019t widely available just yet. Google is rolling it out to trusted testers only for now. But, presumably, once all the kinks are ironed out, everyone will have access to the deepest of Gemini's thoughts.\nGemini shines on\nDeep Think fits right into the rest of Gemini 2.5\u2019s growing lineup and the new features arriving for its various models in the API used by developers to embed Gemini in their software.\nFor instance, Gemini 2.5 Pro now supports native audio generation out. That means it can talk back to you. The speech has an \u201caffective dialogue\u201d feature, which detects emotional shifts in your tone and adjusts accordingly. If you sound stressed, Gemini might stop talking like a patient customer service agent and respond more like an empathetic and thoughtful friend (or at least how the AI interprets such a response). And it will be better at knowing when to talk at all thanks to the new Proactive Audio feature, which filters out background noise so Gemini only chimes in when it\u2019s sure you\u2019re talking to it.\nPaired with new security safeguards and the upcoming Project Mariner computer-use features, Gemini 2.5 is trying very hard to be the AI you trust not just with your calendar or code, but with your book narration or entire operating system.\nAnother element expanding across Gemini 2.5 is what Google calls a 'thinking budget.' Previously unique to Gemini 2.5 Flash, the thinking budget lets developers decide just how deeply the model should think before responding. It's a good way to ensure you get a full answer without spending too much. Otherwise, Deep Think could give you just a taste of its reasoning, or give you the whole thing and make it too expensive for any follow-ups.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nIn case it's not clear what those thoughts involve, Gemini 2.5 Pro and Flash will offer 'thought summaries' for developers, a document showing the exact details of what the AI was doing in terms of applying information through its reasoning process, so you can actually look inside the AI brain.\nAll of this signals a pivot from models that just talk fast to emphasizing ones that can reason deeper, if slower. Deep Think is part of that shift toward deliberate, layered reasoning. It\u2019s not just trying to predict the next word anymore, it's applying that logic to ideas and the very process of coming up with answers to your questions. Google seems keen to make Gemini not only able to fetch answers, but to understand the shape of the question itself.\nOf course, AI reasoning still exists in a space where a perfectly logical answer might come with a random side of nonsense, no matter how impressive the benchmark scores. But you can start to see the shape of what\u2019s coming, where the promise of an actual 'co-pilot' AI comes to fruition.\nYou might also like\nEric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of the world and technology. For the last five years, he served as head writer for Voicebot.ai and was on the leading edge of reporting on generative AI and large language models. He's since become an expert on the products of generative AI models, such as OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, Google Gemini, and every other synthetic media tool. His experience runs the gamut of media, including print, digital, broadcast, and live events. Now, he's continuing to tell the stories people want and need to hear about the rapidly evolving AI space and its impact on their lives. Eric is based in New York City.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    },
    {
      "url": "https://www.techradar.com/computing/artificial-intelligence/i-tried-geminis-new-ai-image-generation-tool-here-are-5-ways-to-get-the-best-art-from-googles-flash-2-0",
      "text": "I tried Gemini's new AI image generation tool - here are 5 ways to get the best art from Google's upcoming Flash 2.0 built-in image upgrade\nAI art generation has been evolving at a wild pace, and Google just threw another big contender into the mix through its Gemini Flash 2.0. You can play with the new image creation tool in Google's AI Studio.\nGemini Flash is, as the name suggests, very fast, notably faster than DALL-E 3 and other image creators. That speed might mean lower quality images, but that's not the case here, especially because all of the changes and upgrades to the model's image production ability. Still, if you want really good results, you must know how to talk to the AI. After plenty of trial and error, I've put together five tips for getting the absolute best art out of Gemini Flash 2.0. Some of these may seem similar to advice about other AI art creators, because they are, but that doesn't make them less useful in this context.\nTell a story\nThe most interesting new feature for Gemini Flash's image creation is that it isn\u2019t just good for one-off illustrations, it can actually help you create a visual story by generating a series of related images with consistent style, settings, and moods.\nTo get started, you just have to ask it to tell you a story and how often you want an illustration to go with the action. The result will include those images accompanying the text.\nFor my project, I asked the AI to \"Generate a story of a heroic baby dragon who protected a fairy queen from an evil wizard in a 3d cartoon animation style. For each scene, generate an image.\" I saw the above start to appear. And, if there's an issue, you can rewrite any of the bits of the story and the model will regenerate the image accordingly.\nBe super specific\nIf you tell Gemini to make \u201ca dog in a park,\u201d you might get a blurry golden retriever sitting somewhere vaguely green. But if you say, \u201cA fluffy golden retriever sitting on a wooden bench in Central Park during autumn, with red and orange leaves scattered on the ground\u201d\u2014you get exactly what you\u2019re picturing.\nAI models thrive on detail. The more you provide, the better your image will be. So for the image above, instead of just asking for a futuristic looking city, I requested \"A retro-futuristic cityscape at sunset, with neon signs glowing in pink and blue, flying cars in the sky, and people walking in retro-future style outfits.\" Seven seconds later, the result came in.\nSign up for breaking news, reviews, opinion, top tech deals, and more.\nGet conversational\nOne of my favorite things about the new Gemini Flash is that you can get conversational with it without losing much of the speed. That means you don\u2019t have to get everything right in one go. After generating an image, you can literally chat with the AI to make edits. Want to change the colors? Add a character? Make the lighting moodier? Just ask.\nIn the image set above, I started by asking for \"A cozy reading nook with a fireplace, bookshelves filled with novels, and a big comfy armchair.\" I then refined it by asking it to \"Make it nighttime with soft, warm lighting,\" then followed up by asking it to \"Add a sleeping cat on the armchair,\" and finished by requesting the AI \"Give the room a vintage, Victorian aesthetic.\" The final result on the left looks almost exactly like what I imagined, and makes Gemini feel like an art assistant, one capable of adjusting to what I want without starting over from scratch every time.\nGemini Flash matches ChatGPT\nGoogle has boasted that Gemini is full of real-world knowledge, which means you can get historical accuracy, realistic cultural details, and true-to-life imagery if you ask for it. Of course, that requires being specific. For example, if you prompt it for \u201ca Viking warrior,\u201d you might get something that looks more like a Game of Thrones character. But if you say, \u201cA historically accurate Viking warrior from the 9th century, wearing detailed chainmail armor, a round wooden shield, and a traditional Norse helmet\u201d\u2014you\u2019ll get something much more precise.\nAs a test I asked the AI to make \"An ancient Mayan city at sunrise, with towering stone pyramids, lush jungle surroundings, and people dressed in traditional Mayan garments.\" It's not perfect, but it looks a lot more like the real thing than previous versions, which would sometimes come back with almost an Egyptian pyramid.\nWrite fast\nMost AI image models have long struggled with rendering text, turning words into illegible scribbles. Even the better models today that can do so take a bit to do it and getting it right can take a few tries. But, Gemini Flash is shockingly good at integrating text into images quickly and legibly. Being very specific can help though.\nThat's how I generated the image above by asking the AI to \"Make a vintage-style travel poster that says 'Visit London\u2019 in bold, retro typography, featuring a stylized illustration of the city.\"\nYou might also like...\n- I tried ChatGPT's Dall-E 3 image generator and these 5 tips will help you get the most from your AI creations\n- I test AI agents for a living and these are the 5 reasons you should let tools like ChatGPT Deep Research get things done for you\n- I used Leonardo to generate some AI images, and I can\u2019t believe how realistic they are\nEric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of the world and technology. For the last five years, he served as head writer for Voicebot.ai and was on the leading edge of reporting on generative AI and large language models. He's since become an expert on the products of generative AI models, such as OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, Google Gemini, and every other synthetic media tool. His experience runs the gamut of media, including print, digital, broadcast, and live events. Now, he's continuing to tell the stories people want and need to hear about the rapidly evolving AI space and its impact on their lives. Eric is based in New York City.\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name."
    }
  ],
  "argos_summary": "Google is expanding its Gemini AI across multiple consumer products, launching a beta Flight Deals tool that lets users describe vague travel preferences and receive real\u2011time fare options, and adding Gemini Live to foldable phones and smartwatches for hands\u2011free assistance. The company also introduces Gemini-powered image editing, enhanced search with Deep Search and Deep Think modes, and new AI calling features that let the assistant place calls on users\u2019 behalf. Additionally, Gemini Flash 2.0 offers fast, conversational image generation, while Gemini\u2019s image editor supports multi\u2011file uploads and watermarking to prevent misuse. Together, these updates aim to make Gemini a versatile, trusted partner for travel planning, creative tasks, and everyday productivity.",
  "argos_id": "CCHLB5VRS"
}