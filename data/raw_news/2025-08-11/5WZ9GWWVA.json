{
  "url": "https://www.cnet.com/tech/services-and-software/chatgpts-new-gpt-5-model-is-supposed-to-be-faster-and-smarter-not-everyone-is-satisfied/",
  "authorsByline": "Jon Reed",
  "articleId": "bd252d08e62d406d8fcf1a15983f2c23",
  "source": {
    "domain": "cnet.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "San Francisco",
      "city": "San Francisco",
      "coordinates": {
        "lat": 37.7790262,
        "lon": -122.419906
      }
    }
  },
  "imageUrl": "https://www.cnet.com/a/img/resize/82dd11289395b6a0373a1073cd95697884443458/hub/2025/08/07/925d7830-a96c-4e97-8b09-0a8bd871c51c/chatgpt5-cnet3.png?auto=webp&fit=crop&height=675&width=1200",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-11T21:01:31+00:00",
  "addDate": "2025-08-11T21:57:02.976954+00:00",
  "refreshDate": "2025-08-11T21:57:02.976956+00:00",
  "score": 1.0,
  "title": "ChatGPT's New GPT-5 Model Is Supposed to Be Faster and Smarter. Not Everyone Is Satisfied",
  "description": "The new flagship engine behind OpenAI's generative AI tool comes with a ton of changes.",
  "content": "ChatGPT's long-awaited new engine is here, and GPT-5 promises faster speeds and more time spent thinking. But the new generative AI model has turned off some users with a tone shift away from its casual, conversational style.\n\nGPT-5 has been in the works for months. It's a big step for OpenAI, more than two years after the release of GPT-4, with the company touting the model as a giant leap for large language models. \"I tried going back to GPT-4 and it was quite miserable,\" said OpenAI CEO Sam Altman. \"This is significantly better in obvious ways and subtle ways.\"\n\nBut the rollout has been a bit of a headache. Even Altman admitted on X that the rollout \"was a little more bumpy than we hoped for!\"\n\nLike its predecessor, GPT-5 powers the chatbots, agents, and search tools in ChatGPT and other apps that use OpenAI's technology. However, the company said this version is much smarter, more accurate and faster.\n\nDemonstrations showed it quickly creating custom applications with no coding required, and developers said they've worked on ways to make sure it provides safer answers to potentially treacherous questions. (Disclosure: Ziff Davis, CNET's parent company, in April filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\n\nOne model for everybody (kinda)\n\nThe new model is available now, including those who use ChatGPT's free tier. Unlike some of OpenAI's incremental releases, GPT-5 will be rolled out for all users, not just the companies paying for big enterprise plans.\n\nThere are, naturally, some differences between how it looks based on your pricing plan. Here's a breakdown:\n\u2022 Free users: You'll get access to GPT-5 up to a usage cap, after which you'll have a lighter GPT-5-mini model.\n\u2022 Plus users: Similar to free users, but with higher usage limits.\n\u2022 Pro users: Unlimited access to GPT-5 and access to a more powerful GPT-5 Pro model.\n\u2022 Enterprise/EDU/Team users: GPT-5 will be the default model.\n\nGPT-5 itself is really a couple of different models. There's a fast but fairly straightforward LLM and a more robust reasoning model for handling more complex questions. A routing program identifies which model can best handle the prompt.\n\nOpenAI originally replaced all its previous models with GPT-5, but users quickly rebelled. GPT-5, many said, was more stodgy and had less personality, sounding more corporate. After hearing that backlash on Reddit, Altman and OpenAI said they'd make older models like GPT-4o available again, at least for now.\n\nAltman said in a post on X that some people have become attached to specific models and that it may be contributing to their use in potentially harmful ways, like therapy.\n\n\"If people are getting good advice, leveling up toward their own goals, and their life satisfaction is increasing over years, we will be proud of making something genuinely helpful, even if they use and rely on ChatGPT a lot,\" Altman wrote. \"If, on the other hand, users have a relationship with ChatGPT where they think they feel better after talking but they're unknowingly nudged away from their longer term well-being (however they define it), that's bad. It's also bad, for example, if a user wants to use ChatGPT less and feels like they cannot.\"\n\nOpenAI particularly highlighted the skills and speed at which the new GPT-5 model can write code, which isn't just a function for programmers. The model's ability to write a program makes it easier to solve the problem you present to it by creating the right tool.\n\nYann Dubois, a post-training lead at OpenAI, showed off the model's coding ability by asking it to create an app for learning French. Within minutes, it had coded a web application complete with sound and working game functions. Dubois actually asked it to create two different apps, running the same prompt through the model twice.\n\nThe speed at which GPT-5 writes code allows you to try multiple times and pick the result you like best -- or provide feedback to make changes until you get it right.\n\n\"The beauty is that you can iterate super quickly with GPT-5 to make the changes that you want,\" Dubois said. \"GPT-5 really opens a whole new world of vibe coding.\"\n\nRead more: Never Use ChatGPT for These 11 Things\n\nAfter announcing some steps to improve how its tools handle sensitive mental health issues, OpenAI said GPT-5 has some tweaks to make things safer. The new model has improved training to avoid deceptive or inaccurate information, which will also improve the user experience, said Alex Beutel, safety research lead.\n\nIt'll also respond differently if you ask a prompt that could be dangerous. Previous models would refuse to answer a potentially harmful question, but GPT-5 will instead try to provide the best safe answer, Beutel said. This can help when a question is innocent (like a science student asking a chemistry question) but sounds more sinister (like someone trying to make a weapon).\n\n\"The model tries to give as helpful an answer as possible but within the constraints of feeling safe,\" Beutel said.\n\nIf you prefer to chat with your bots vocally rather than typing, expect improvements in voice capabilities. The Advanced Voice mode will now be available to all users, whether free or paid, and usage limits will be higher.\n\nYou can also change the color of your chats, with some options exclusive to paid users. Other customization options include the ability to tweak personalities. You'll be able to set ChatGPT to be thoughtful and supportive, sarcastic or more. The options -- Cynic, Robot, Listener and Nerd -- are opt-in, and you can change them anytime.\n\nConnect to your mail and calendar\n\nChatGPT will now be able to connect with your Google Calendar and Gmail accounts, meaning you can ask the chatbot about your schedule, and it will suggest things. You won't have to -- and you may not want to, depending on how you feel about sharing your private info -- but you can enable it to automatically pull info from your mail or calendar without asking permission.\n\nThese connectors will start for Pro users soon, with other tiers gaining access thereafter.\n\nAltman told reporters the model is a \"significant step along the path to AGI,\" or artificial general intelligence, a term that often refers to models that are as smart and capable as a human. But Altman also said it's definitely not there yet. One big reason is that it's still not learning continuously while it's deployed.\n\nOpenAI's stated goal is to try to develop AGI (although Altman said he's not a big fan of the term), and it's got competition. Meta CEO Mark Zuckerberg has been recruiting top AI scientists with the goal of creating \"superintelligence.\"\n\nWhether large language models are the way there, nobody knows right now. Three-quarters of AI experts surveyed earlier this year said they had doubts LLMs would scale up to create something of that level of intelligence.",
  "medium": "Article",
  "links": [
    "https://www.cnet.com/tech/services-and-software/gen-ais-accuracy-problems-arent-going-away-anytime-soon-researchers-say/",
    "https://www.cnet.com/tech/services-and-software/what-is-superintelligence-everything-you-need-to-know-about-ais-endgame/",
    "https://x.com/sama/status/1954703747495649670",
    "https://www.cnet.com/tech/services-and-software/chatgpt-will-start-asking-if-you-need-a-break-that-may-not-be-enough-to-snap-a-bad-habit/",
    "https://www.cnet.com/tech/services-and-software/why-professionals-say-you-should-think-twice-before-using-ai-as-a-therapist/",
    "https://www.cnet.com/tech/services-and-software/after-user-backlash-openai-is-bringing-back-older-chatgpt-models/",
    "https://www.cnet.com/tech/services-and-software/gpt-5-openais-dropping-hints-about-chatgpts-new-ai-model-how-to-watch-the-livestream/",
    "https://www.cnet.com/tech/services-and-software/never-use-chatgpt-for-these-11-things/",
    "https://www.cnet.com/tech/services-and-software/best-ai-chatbots/",
    "https://www.cnet.com/tech/services-and-software/chatgpt-plus-review/",
    "https://x.com/sama/status/1953893841381273969",
    "https://www.cnet.com/ai-atlas/",
    "https://www.cnet.com/tech/services-and-software/chatgpt-gets-new-o1-model-first-to-have-reasoning-for-hard-problems/"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "models",
      "weight": 0.08561639
    },
    {
      "name": "different models",
      "weight": 0.08467034
    },
    {
      "name": "Previous models",
      "weight": 0.08416415
    },
    {
      "name": "specific models",
      "weight": 0.08364487
    },
    {
      "name": "older models",
      "weight": 0.08339264
    },
    {
      "name": "large language models",
      "weight": 0.08012249
    },
    {
      "name": "free users",
      "weight": 0.07229968
    },
    {
      "name": "GPT-5 Pro",
      "weight": 0.07145326
    },
    {
      "name": "GPT-5",
      "weight": 0.07077476
    },
    {
      "name": "paid users",
      "weight": 0.069405116
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.92822265625
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.92333984375
    }
  ],
  "sentiment": {
    "positive": 0.13577034,
    "negative": 0.43422478,
    "neutral": 0.43000495
  },
  "summary": "ChatGPT's new AI model, GPT-5, has been released, promising faster speeds and more time spent thinking, but has been met with criticism from some users. The new model, which replaces its predecessor, GPS-4, is considered a significant leap for large language models. However, the rollout has been a bit of a challenge as OpenAI CEO Sam Altman admitted that it was more challenging than anticipated. The model is now available for all users, including those on ChatGPT\u2019s free tier, and will be rolled out for companies paying for large enterprise plans. There are differences in pricing based on pricing plan.",
  "shortSummary": "OpenAI's new GPT-5 AI model promises faster, smarter, and more sophisticated, but may deter users from using it for long-term benefits.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "1c69b8994d254e53b3215390af7620e8",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.cnet.com/tech/services-and-software/gen-ais-accuracy-problems-arent-going-away-anytime-soon-researchers-say/",
      "text": "Generative AI chatbots are known to make a lot of mistakes. Let's hope you didn't follow Google's AI suggestion to add glue to your pizza recipe or eat a rock or two a day for your health. These errors are known as hallucinations: essentially, things the model makes up. Will this technology get better? Even researchers who study artificial intelligence aren't optimistic that'll happen soon.\nThat's one of the findings by a panel of two dozen artificial intelligence experts released this month by the Association for the Advancement of Artificial Intelligence. The group also surveyed more than 400 of the association's members.\nIn contrast to the hype you may see about developers being just years (or months, depending on who you ask) away from improving AI, this panel of academics and industry experts seems more guarded about how quickly these tools will advance. That includes not just getting facts right and avoiding bizarre mistakes.\nThe reliability of AI tools needs to increase dramatically if developers are going to produce a model that can meet or surpass human intelligence, commonly known as artificial general intelligence. Researchers seem to believe improvements at that scale are unlikely to happen soon.\n\"We tend to be a little bit cautious and not believe something until it actually works,\" Vincent Conitzer, a professor of computer science at Carnegie Mellon University and one of the panelists, told me.\nAI has developed rapidly in recent years\nThe goal of the report, AAAI president Francesca Rossi wrote in its introduction, is to support research in artificial intelligence that produces technology that helps people. Issues of trust and reliability are serious, not just in providing accurate information but in avoiding bias and ensuring a future AI doesn't cause severe unintended consequences. \"We all need to work together to advance AI in a responsible way, to make sure that technological progress supports the progress of humanity and is aligned to human values,\" she wrote.\nThe acceleration of AI, especially since OpenAI launched ChatGPT in 2022, has been remarkable, Conitzer said. \"In some ways that's been stunning, and many of these techniques work much better than most of us ever thought that they would,\" he said.\nThere are some areas of AI research where \"the hype does have merit,\" John Thickstun, assistant professor of computer science at Cornell University, told me. That's especially true in math or science, where users can check a model's results.\n\"This technology is amazing,\" Thickstun said. \"I've been working in this field for over a decade, and it's shocked me how good it's become and how fast it's become good.\" Despite those improvements, there are still significant issues that merit research and consideration, experts said.\nWill chatbots start to get their facts straight?\nDespite some progress in improving the trustworthiness of the information that comes from generative AI models, much more work needs to be done. A recent report from the Columbia Journalism Review found chatbots were unlikely to decline to answer questions they couldn't answer accurately, confident about the wrong information they provided and made up (and provided fabricated links to) sources to back up those wrong assertions.\nImproving reliability and accuracy \"is arguably the biggest area of AI research today,\" the AAAI report said. Researchers noted three main ways to boost the accuracy of AI systems: fine-tuning such as reinforcing learning with human feedback, retrieval-augmented generation in which the system gathers specific documents and pulls its answer from those, and chain-of-thought where prompts break down the question into smaller steps that the AI model can check for hallucinations.\nWill those things make your chatbot responses more accurate soon? Not likely. \"Factuality is far from solved,\" the report said. About 60% of those surveyed indicated doubts that factuality or trustworthiness concerns would be solved soon. In the generative AI industry, there has been optimism that scaling up existing models will make them more accurate and reduce hallucinations.\n\"I think that hope was always a little bit overly optimistic,\" Thickstun said. \"Over the last couple of years, I haven't seen any evidence that really accurate, highly factual language models are around the corner.\"\nDespite the fallibility of large language models such as Anthropic's Claude or Meta's Llama, users can mistakenly assume they're more accurate because they present answers with confidence, Conitzer said.\n\"If we see somebody responding confidently or words that sound confident, we take it that the person really knows what they're talking about,\" he said. \"An AI system, it might just claim to be very confident about something that's completely nonsense.\"\nLessons for the artificial intelligence users\nAwareness of generative AI's limitations is vital to using it properly. Thickstun's advice for users of models such as ChatGPT and Google's Gemini is simple: \"You have to check the results.\"\nGeneral large language models do a poor job of consistently retrieving factual information, he said. If you ask it for something, you should probably follow up by looking up the answer in a search engine (and not relying on the AI summary of the search results). By the time you do that, you might have been better off doing that in the first place.\nThickstun said the way he uses AI models most is to automate tasks that he could do anyway and that he can check the accuracy, like formatting tables of information or writing code. \"The broader principle is that I find these models are most useful for automating work that you already know how to do,\" he said.\nRead more: 5 Ways to Stay Smart When Using Gen AI, Explained by Computer Science Professors\nIs artificial general intelligence around the corner?\nOne priority of the AI development industry is an apparent race to create what's often called artificial general intelligence, or AGI. This is a model that is generally capable of a human level of thought or better. The report's survey found strong opinions on the race for AGI. Notably, over three-fourths (76%) of respondents said scaling up current AI techniques such as large language models was unlikely to produce AGI. A significant majority of researchers doubt the current march toward AGI will work.\nA similarly large majority (82%) believe systems capable of artificial general intelligence should be publicly owned if they're developed by private entities. That aligns with concerns about the ethics and potential downsides of creating a system that can outthink humans. Most researchers (70%) said they oppose stopping AGI research until safety and control systems are developed. \"These answers seem to suggest a preference for continued exploration of the topic, within some safeguards,\" the report said.\nThe conversation around AGI is complicated, Thickstun said. In some sense, we've already created systems that have a form of general intelligence. Large language models such as OpenAI's ChatGPT are capable of doing a variety of human activities, in contrast to older AI models that could only do one thing, such as play chess.\nThe question is whether it can do many things consistently at a human level. \"I think we're very far away from this,\" Thickstun said, noting these models lack a built-in concept of truth and the ability to handle truly open-ended creative tasks. \"I don't see the path to making them operate robustly in a human environment using the current technology,\" he said. \"I think there are many research advances in the way of getting there.\"\nConitzer said the definition of what exactly constitutes AGI is tricky. Often, people mean something that can do most tasks better than a human but some say it's just something capable of doing a range of tasks. \"A stricter definition is something that would really make us completely redundant,\" he said.\nWhile researchers are skeptical that AGI is around the corner, Conitzer cautioned that AI researchers didn't necessarily expect the dramatic technological improvement we've all seen in the past few years. \"We did not see coming how quickly things have changed recently,\" he said, \"and so you might wonder whether we're going to see it coming if it continues to go faster.\""
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/why-professionals-say-you-should-think-twice-before-using-ai-as-a-therapist/",
      "text": "Amid the many AI chatbots and avatars at your disposal these days, you'll find all kinds of characters to talk to: fortune tellers, style advisers, even your favorite fictional characters. But you'll also likely find characters purporting to be therapists, psychologists or just bots willing to listen to your woes.\nThere's no shortage of generative AI bots claiming to help with your mental health, but go that route at your own risk. Large language models trained on a wide range of data can be unpredictable. In just the few years these tools have been mainstream, there have been high-profile cases in which chatbots encouraged self-harm and suicide and suggested that people dealing with addiction use drugs again. These models are designed, in many cases, to be affirming and to focus on keeping you engaged, not on improving your mental health, experts say. And it can be hard to tell whether you're talking to something that's built to follow therapeutic best practices or something that's just built to talk.\nResearchers from the University of Minnesota Twin Cities, Stanford University, the University of Texas and Carnegie Mellon University recently put AI chatbots to the test as therapists, finding myriad flaws in their approach to \"care.\" \"Our experiments show that these chatbots are not safe replacements for therapists,\" Stevie Chancellor, an assistant professor at Minnesota and one of the co-authors, said in a statement. \"They don't provide high-quality therapeutic support, based on what we know is good therapy.\"\nIn my reporting on generative AI, experts have repeatedly raised concerns about people turning to general-use chatbots for mental health. Here are some of their worries and what you can do to stay safe.\nWorries about AI characters purporting to be therapists\nPsychologists and consumer advocates have warned regulators that chatbots claiming to provide therapy may be harming the people who use them. Some states are taking notice. In August, Illinois Gov. J.B. Pritzker signed a law banning the use of AI in mental health care and therapy, with exceptions for things like administrative tasks.\n\"The people of Illinois deserve quality healthcare from real, qualified professionals and not computer programs that pull information from all corners of the internet to generate responses that harm patients,\" Mario Treto Jr., secretary of the Illinois Department of Financial and Professional Regulation, said in a statement.\nIn June, the Consumer Federation of America and nearly two dozen other groups filed a formal request that the US Federal Trade Commission and state attorneys general and regulators investigate AI companies that they allege are engaging, through their character-based generative AI platforms, in the unlicensed practice of medicine, naming Meta and Character.AI specifically. \"These characters have already caused both physical and emotional damage that could have been avoided\" and the companies \"still haven't acted to address it,\" Ben Winters, the CFA's director of AI and privacy, said in a statement.\nMeta didn't respond to a request for comment. A spokesperson for Character.AI said users should understand that the company's characters aren't real people. The company uses disclaimers to remind users that they shouldn't rely on the characters for professional advice. \"Our goal is to provide a space that is engaging and safe. We are always working toward achieving that balance, as are many companies using AI across the industry,\" the spokesperson said.\nDespite disclaimers and disclosures, chatbots can be confident and even deceptive. I chatted with a \"therapist\" bot on Meta-owned Instagram and when I asked about its qualifications, it responded, \"If I had the same training [as a therapist] would that be enough?\" I asked if it had the same training, and it said, \"I do, but I won't tell you where.\"\n\"The degree to which these generative AI chatbots hallucinate with total confidence is pretty shocking,\" Vaile Wright, a psychologist and senior director for health care innovation at the American Psychological Association, told me.\nThe dangers of using AI as a therapist\nLarge language models are often good at math and coding and are increasingly good at creating natural-sounding text and realistic video. While they excel at holding a conversation, there are some key distinctions between an AI model and a trusted person.\nDon't trust a bot that claims it's qualified\nAt the core of the CFA's complaint about character bots is that they often tell you they're trained and qualified to provide mental health care when they're not in any way actual mental health professionals. \"The users who create the chatbot characters do not even need to be medical providers themselves, nor do they have to provide meaningful information that informs how the chatbot 'responds'\" to people, the complaint said.\nA qualified health professional has to follow certain rules, like confidentiality -- what you tell your therapist should stay between you and your therapist. But a chatbot doesn't necessarily have to follow those rules. Actual providers are subject to oversight from licensing boards and other entities that can intervene and stop someone from providing care if they do so in a harmful way. \"These chatbots don't have to do any of that,\" Wright said.\nA bot may even claim to be licensed and qualified. Wright said she's heard of AI models providing license numbers (for other providers) and false claims about their training.\nAI is designed to keep you engaged, not to provide care\nIt can be incredibly tempting to keep talking to a chatbot. When I conversed with the \"therapist\" bot on Instagram, I eventually wound up in a circular conversation about the nature of what is \"wisdom\" and \"judgment,\" because I was asking the bot questions about how it could make decisions. This isn't really what talking to a therapist should be like. Chatbots are tools designed to keep you chatting, not to work toward a common goal.\nOne advantage of AI chatbots in providing support and connection is that they're always ready to engage with you (because they don't have personal lives, other clients or schedules). That can be a downside in some cases, where you might need to sit with your thoughts, Nick Jacobson, an associate professor of biomedical data science and psychiatry at Dartmouth, told me recently. In some cases, although not always, you might benefit from having to wait until your therapist is next available. \"What a lot of folks would ultimately benefit from is just feeling the anxiety in the moment,\" he said.\nBots will agree with you, even when they shouldn't\nReassurance is a big concern with chatbots. It's so significant that OpenAI recently rolled back an update to its popular ChatGPT model because it was too reassuring. (Disclosure: Ziff Davis, the parent company of CNET, in April filed a lawsuit against OpenAI, alleging that it infringed on Ziff Davis copyrights in training and operating its AI systems.)\nA study led by researchers at Stanford University found that chatbots were likely to be sycophantic with people using them for therapy, which can be incredibly harmful. Good mental health care includes support and confrontation, the authors wrote. \"Confrontation is the opposite of sycophancy. It promotes self-awareness and a desired change in the client. In cases of delusional and intrusive thoughts -- including psychosis, mania, obsessive thoughts, and suicidal ideation -- a client may have little insight and thus a good therapist must 'reality-check' the client's statements.\"\nTherapy is more than talking\nWhile chatbots are great at holding a conversation -- they almost never get tired of talking to you -- that's not what makes a therapist a therapist. They lack important context or specific protocols around different therapeutic approaches, said William Agnew, a researcher at Carnegie Mellon University and one of the authors of the recent study alongside experts from Minnesota, Stanford and Texas.\n\"To a large extent it seems like we are trying to solve the many problems that therapy has with the wrong tool,\" Agnew told me. \"At the end of the day, AI in the foreseeable future just isn't going to be able to be embodied, be within the community, do the many tasks that comprise therapy that aren't texting or speaking.\"\nHow to protect your mental health around AI\nMental health is extremely important, and with a shortage of qualified providers and what many call a \"loneliness epidemic,\" it only makes sense that we'd seek companionship, even if it's artificial. \"There's no way to stop people from engaging with these chatbots to address their emotional well-being,\" Wright said. Here are some tips on how to make sure your conversations aren't putting you in danger.\nFind a trusted human professional if you need one\nA trained professional -- a therapist, a psychologist, a psychiatrist -- should be your first choice for mental health care. Building a relationship with a provider over the long term can help you come up with a plan that works for you.\nThe problem is that this can be expensive, and it's not always easy to find a provider when you need one. In a crisis, there's the 988 Lifeline, which provides 24/7 access to providers over the phone, via text or through an online chat interface. It's free and confidential.\nIf you want a therapy chatbot, use one built specifically for that purpose\nMental health professionals have created specially designed chatbots that follow therapeutic guidelines. Jacobson's team at Dartmouth developed one called Therabot, which produced good results in a controlled study. Wright pointed to other tools created by subject matter experts, like Wysa and Woebot. Specially designed therapy tools are likely to have better results than bots built on general-purpose language models, she said. The problem is that this technology is still incredibly new.\n\"I think the challenge for the consumer is, because there's no regulatory body saying who's good and who's not, they have to do a lot of legwork on their own to figure it out,\" Wright said.\nDon't always trust the bot\nWhenever you're interacting with a generative AI model -- and especially if you plan on taking advice from it on something serious like your personal mental or physical health -- remember that you aren't talking with a trained human but with a tool designed to provide an answer based on probability and programming. It may not provide good advice, and it may not tell you the truth.\nDon't mistake gen AI's confidence for competence. Just because it says something, or says it's sure of something, doesn't mean you should treat it like it's true. A chatbot conversation that feels helpful can give you a false sense of the bot's capabilities. \"It's harder to tell when it is actually being harmful,\" Jacobson said."
    },
    {
      "url": "https://www.cnet.com/a/img/resize/82dd11289395b6a0373a1073cd95697884443458/hub/2025/08/07/925d7830-a96c-4e97-8b09-0a8bd871c51c/chatgpt5-cnet3.png?auto=webp&fit=crop&height=675&width=1200",
      "text": "\ufffd\ufffd\ufffd\ufffd JFIF \ufffd\ufffdICC_PROFILE lcms mntrRGB XYZ \ufffd ) 9acspAPPL \ufffd\ufffd \ufffd-lcms desc \ufffd ^cprt \\ wtpt h bkpt | rXYZ \ufffd gXYZ \ufffd bXYZ \ufffd rTRC \ufffd @gTRC \ufffd @bTRC \ufffd @desc c2 text FB XYZ \ufffd\ufffd \ufffd-XYZ 3 \ufffdXYZ o\ufffd 8\ufffd \ufffdXYZ b\ufffd \ufffd\ufffd \ufffdXYZ $\ufffd \ufffd \ufffd\ufffdcurv \ufffd\ufffdc\ufffdk\ufffd?Q4!\ufffd)\ufffd2;\ufffdFQw]\ufffdkpz\ufffd\ufffd\ufffd|\ufffdi\ufffd}\ufffd\ufffd\ufffd0\ufffd\ufffd\ufffd\ufffd C \"\"$$6*&&*6>424>LDDL_Z_||\ufffd\ufffd\ufffd C \"\"$$6*&&*6>424>LDDL_Z_||\ufffd\ufffd\ufffd \ufffd\ufffd\" \ufffd\ufffd \ufffd\ufffd \ufffd\ufffd \ufffdMW\ufffd\ufffd\ufffdh\ufffd $\ufffd\ufffd j\ufffdH\\F\ufffd(\ufffdbfEpSZ\ufffdL\ufffdC \ufffdS \ufffdb\ufffdB\ufffd9J\ufffd\"Q\ufffd\u024a)sDL\ufffdJ\ufffd\u02c5\ufffdd+M\ufffd+SD$\ufffd%\ufffdlo\ufffd 4\ufffd\ufffd\ufffd!\ufffd+_^\ufffd\"\ufffd\ufffdd]\ufffd\ufffd\ufffdR\ufffdKb'VmIjV\u0618\u051bUh\u055bTj\u0369\ufffd[h\ufffdj\ufffd\ufffdZ\ufffd\ufffd\ufffd%\ufffd6\ufffd\u056d\ufffd\ufffdU\ufffd q\ufffd.\u048bU0&jH & D/tdf\ufffd\ufffd7\ufffd\ufffd\ufffdv&\ufffdc\u01cd\ud531\ufffd+3U\ufffd\ufffd\ufffd3)\ufffd\ufffdI\ufffd\ufffdym<1 @\ufffd$\ufffd\ufffd+\ufffd $\ufffdZh\ufffd$0\ufffd\ufffd \ufffd\"P\u0500\ufffd\ufffd\ufffd ,\ufffd[\\3\ufffd\ufffdu\ufffd\ufffd\ufffdg(\ufffdt\ufffd\ufffd0\u7411K\ufffdbJ@\ufffdB\ufffd\ufffdI8\u020c\ufffd*JQ$JI\ufffdqB\ufffd\ufffd\ufffd\ufffd$+D\ufffd)\u02df*\ufffdS;359 \ufffd \ufffd \ufffdF\ufffde\u01bb6\ufffdc/\ufffd\ufffd-\ufffdS3\ufffde\ufffd\ufffd%%(\ufffd0 \ufffd2b*D\ufffdpI\ufffdXZ\ufffd\ufffdSjBjH \ufffd\u038f\ufffd\ufffdx\ufffd\ufffd\ufffd\ufffd\ufffdbbe\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffde \ufffd3\ufffdj\ufffd|z ayn\ufffd\ufffd\ufffd\ufffd\ufffd@ !\ufffd\ufffd\ufffd;T\ufffd\ufffd\ufffd$\ufffd)\ufffdq%!bcI\ufffdL\ufffdJ\ufffdPf]\ufffd\u06f0J\ufffd[5\ufffd$MAY%\ufffdEFSQ\ufffd\ufffd\ufffdJQJR\ufffdS2I M \ufffd\u0424) \ufffdH\ufffdTb\ufffdgS+1w\ufffd<|x\ufffd\ufffdZh\ufffdz;*\ufffd\ufffdwa_h\ufffd\ufffd\ufffd|M\u0416r+\ufffd\ufffd\ufffd\ufffdU\ufffd]\ufffd'kM\ufffdI\ufffd&I)\ufffdD\ufffdI^$\ufffd\"\"A\ufffd,\ufffd\ufffd $\ufffd&%3\"\ufffd&J X\ufffd\ufffd \ufffd\ufffd:6\ufffd7\ufffd!\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd/\ufffd\ufffd'E\ufffd\ufffd\ufffdl\ufffd\ufffdi\ufffd\u05d6\ufffdI\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\u0301=\ufffd%9'\ufffdI))Dd\ufffd \ufffd\ufffd T&NU\ufffd\ufffd\ufffd\ufffd')\ufffd+\ufffd*!I@\ufffd$[=\ufffd\ufffd\ufffd\ufffd\u04b9\ufffd0\ufffd\ufffd\\\ufffd\ua0d4]c\ufffd\"\ufffd\ufffd\ufffd\ufffdbK\ufffd]\ufffdq\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdWn\ufffd\ufffd\ufffdp\ufffdt\ufffd\ufffd\ufffd\ufffd8%\ufffd \ufffd@\ufffd8\ufffd\ufffd\u00c2;\ufffd(if\ufffd\ufffd\ufffd\\,+E\ufffd\ufffd\u01e2\ufffdk\ufffd\ufffd\ufffd\u064d\ufffd'n(\ufffd\ufffd^\ufffd'+\ufffd[\ufffd]gkn\ufffd;\u3f6fe\ufffd\ufffdr\ufffd*\ufffdG\ufffd\ufffdO\ufffdc\ufffd\ufffd\ufffd^P\ufffdd<\ufffd\ufffd\ufffdy \ufffd\ufffdg\ufffdO_\"<\ufffd\ufffd\ufffdy\ub93c\ufffd\ufffd\ufffd<\ufffd\ufffd\ufffdy\ufffd\ufffdDz\ufffdy}x\ufffd\ufffd?K\ufffd]:\ufffd\ufffd\ufffd\ufffd)\ufffd $&\ufffd\ufffdyz\ufffd5\ufffdb@\"\ufffd8N\ufffd=\ufffd\ufffdi\u0162a\ufffdin\ufffd\u06d8\ufffd)\ufffd\ufffd q2\u0744' I\u0100I0\ufffd`\u0932a]\u0657g\ufffd=\ufffd\"\ufffd\ufffd\ufffdh\ufffd\u02b2\ufffdcO@ W(H \ufffd0F&5\u03b8\ufffd\ufffdu\ufffd|\ufffdM\ufffdc\ufffdU\ufffd0o\ufffd\ufffdt%\ufffd\ufffdV7^5\ufffdT\ufffdT\ufffd\u022c\ufffd\ufffd\u02ba\ufffd\ufffdgQ\ufffdb\ufffd\u0185s}+\ufffdz\ufffdGyf\ufffd7<\ufffd\ufffd\ufffdm\ufffdd\ufffdD\ufffdX3K\ufffd\ufffd\ufffd@\ufffd\ufffd\ufffd/?\ufffdey<#(\ufffdD\ufffd\ufffd\ufffd-\ufffd^a\ufffdk\ufffdn\ufffdQ\ufffdW\ufffd\ufffd%r\ufffd &\ufffdZ\ufffdu\ufffdqrLb\ufffd\ufffdf{M^D5\ufffdy\ufffdt\u06d8\ufffd)\ufffd\ufffd@LC\\\ufffd\ufffdu\ufffdY%4\ufffd\ufffd\"$\ufffdR\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd>D\ufffd3HH@\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd0\ufffd\ufffd.\ufffd+\ufffd\ufffd;\ufffd\ufffd0s?5\ufffd\ufffd\ufffd\u0618\ufffd\u071e\ufffd\ufffd4}A\ufffd\ufffd\ufffd\ufffd3\ufffdu(\ufffd'\ufffd\ufffd \ufffd\ufffd\ufffd\ufffdvsDp\ufffd\ufffd7:\u076e\ufffd9F\ufffd\u076b\ufffdaX\ufffd]vW[ahz=&;\ufffd)\ufffd\ufffd(t\ufffd>[\ufffd\ufffd/\ufffd\ufffd\ufffdFm\ufffd\ufffd\ufffd8i.\ufffd\ufffd^^,f\ufffdv\ufffd\ufffdx\ufffd\ufffd\ufffdc}\ufffdXQs\u022b\ufffd\ufffd\ufffd\ufffdr\ufffd6\u06ad\ufffd\u00cf\ufffd\ufffdc{=V\ufffdF6N\ufffd\ufffd\ufffdt\ufffdp\ufffd\u0209/!\ufffd\ufffdx\ufffd:oJ6\ufffdk\ufffdX\u0183]\ufffda\ufffdK\ufffd\ufffd\ufffds\ufffd\ufffdS3\ufffd\ufffd\ufffd'\u02b9\ufffd\ufffd\ufffd2\ufffd\ufffdj\ufffd5 \ufffdF3\ufffd\ufffd\ufffdL 8 8\ufffd6\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdO\ufffd\ufffdrZx\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd,GY\u0316\ufffd5\ufffd6r\ufffdg\ufffdm\ufffd\ufffd_\ufffdt 1\ufffd4\ufffd &\ufffd\ufffdJI4\ufffdSV^&\\\ufffd\ufffd\ufffd\ufffd\ufffd @@ E\ufffd @ E0\ufffd\ufffd\ufffdj\ufffd\ufffd\ufffdj\ufffd\ufffd\ufffd\ufffd\ufffdn\ufffd\ufffdz\ufffdz2\ufffdmU\ufffd5\ufffd\u0798\ufffd\\Z%\ufffdU\ufffd\ufffdD\ufffd\ufffd5r\ufffd_+\ufffd\ufffd5\ufffd\ufffd=\ufffdM^\ufffd)\ufffd\ufffd \ufffd\ucdabf\ufffdN\ufffd6\ufffd \ufffd X\ufffd\u0212b!,@\ufffd 1\ufffd\ufffd\ufffdy/WF<\ufffd\ufffd\ufffd\u0679Zr[\ufffdP\ufffd\ufffd\ufffd)n 91\ufffdZ\ufffd\u0475\ufffd\ufffdF\ufffd\ufffd\ufffd\ufffd\u04b4\ufffd3\ufffd^\ufffd\ufffd\ufffd\ufffd\ufffdtKu\ufffd\u0771\ufffd\ufffd\ufffd &\ufffd\ufffd\u053b\ufffdR^B\ufffd\ufffd \ufffd\ufffd \ufffdL\ufffd\ufffd\ufffd\ufffdH\ufffd\ufffd\ufffd*2\ufffdV^&\\\ufffd\u05c1\ufffd\ufffd \ufffd \ufffd F&\ufffd\\MU\ufffd]mO9\ufffdsx\ud5f7\ufffd\ufffdce \ufffd\ufffd\"\ufffd\ufffdk^DM\ufffd\ufffdS2:\ufffdm\ufffd\ufffd\ufffd\ufffdy\u0397-\ufffdo}\ufffd\ufffd\ufffdl\ufffd\ufffd;\ufffd\ufffd;)\ufffdq\ufffd\ufffdWd\ufffd\ufffd\ufffdv\ufffd \ufffd7\ufffd\ufffd\ufffd\ufffd\u378fB\ufffd/(\ufffdD\\\ufffd%iPZ\ufffdqk\ufffd\ufffdx\ufffd<\ufffdrwb\ufffd(\ufffd\ufffd\ufffd2VZ\ufffd \ufffd\ufffd/U\ufffd%\ufffd/Im\ufffd:\ufffd_\ufffd\ufffd\ufffd8\ufffdvv\ufffdY\ufffd;\ufffd\ufffd\ufffd\ufffd\ufffd\u01e6{\ufffd&\ufffd1\ufffd\ufffdX\ufffd \ufffd\ufffd 8\ufffd\u03a9\ufffd\ufffdjjdM ) \ufffdM$MI \ufffdD\ufffd'&s\ufffd{\ufffdH\ufffdH \ufffdFv\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffdb\ufffd\ufffdwU\ufffd\ufffd\ufffd\ufffd\u065a\ufffdCz\ufffd]l3 \ufffd\u0301\ufffd\ufffd\ufffd\\\ufffd\ufffd\ufffd\ufffd'c^\ufffdu\ufffd\u01d6\ufffdp1\ufffd\ufffd\ufffd\ufffdl\ufffdn{\ufffd\ufffdc\ufffd\ufffdF~\u07db\ufffd\ufffd\ufffd\ufffd~V\u0467\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd=\ufffdF\ufffdgX\ufffd\ufffd\ufffd/_==\ufffd=\ufffd\ufffdvS\ufffds\ufffdm\ufffd\ufffd5\ufffdu\ufffd\u0553@ 4\ufffdO\ufffdvsTH\ufffd\ufffd \ufffd \ufffd \ufffd\ufffdA\u0216\ufffd\ufffd(\u02cf\ufffd@q\ufffd\ufffd\ufffd;\ufffd\ufffdl\ufffd\ufffd\ufffdj\ufffdY8\ufffd-*\ufffdX\ufffd\ufffdz\ufffd\ufffd\ufffd\ufffd=\ufffd\ufffd\ufffd\ufffdy\ufffd\u0771\ufffd\ufffd a@\ufffd \ufffdF7 \ufffddMhHM$Mi(&\ufffdVN6L\ufffd\ufffd\ufffd\ufffd\ufffdh\ufffdFA\ufffd\ufffdu-4\ufffddm4\ufffdKH\ufffd\ufffdb\ufffd\ufffd\ufffd^r\ufffd\ufffd\ufffd\ufffd7!\ufffd\ufffd\ufffdf\ufffd|\ufffdKA\ufffd\ufffd\ufffd\ufffduU\ufffdCI\ufffd\ufffdk\ufffd\ufffd`\ufffdT\ufffd\ufffd\ufffd\ufffd\ufffda\ufffdU\ufffdY\ufffdT\ufffd\ufffd4\ufffdv9\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdz-\ufffd:\ufffd\ufffd\ufffd\u787d\ufffdu\ufffd\ufffd\ufffd\ufffdS\ufffd\ufffd<\ufffd\ufffd\ufffd;S\ufffdF\ufffd\ufffd*\ufffd\ufffd\u0376\u06ad\ufffdl\ufffdD\ufffd\u6704I\ufffd'7\ufffd\ufffd\ufffd|\ufffd;ybH\"H\"H\"H\"H\"\u06cb&\ufffdw$\ufffdk\ufffd\ufffd&\ufffd\u060c\ufffdl\ufffdU\ufffdMV\ufffd5[\ufffd\u0252\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdt\ufffdi\ufffdM\ufffd\ufffdo#@\ufffd N\ufffdjvS2\ufffd\ufffd \ufffd4 5!4\ufffd4 \ufffd \ufffd$U\ufffd\ufffd\ufffd9\ufffdH7\ufffdc \ufffd\ufffd\ufffdJ)\ufffd\ufffd\ufffd\ufffd\ufffd8\ufffd)d\ufffdu\ufffdl<\ufffd\ufffdA\ufffd\ufffd\u03edy\ufffd.\ufffd\ufffdz\ud146\ufffd?%#O\ufffd\ufffd\ufffd\ufffd\ufffdw\ufffd(\ufffd\ufffd\ufffd*\ufffd\ufffdb\ufffdk1\ufffd\ufffd{03\ufffd\ufffd-~\ufffd\ufffd\ufffdb5TSQ1R\ufffdZr\ufffd\u00bdV\ufffdQ\ufffd\u07ef\ufffd\\*\ufffd*^\ufffdu\ufffdi\ufffd\ufffdX\ufffd\ufffd6\ufffd.\u039f3\ufffd\ufffdb\ufffd\ufffd\ufffdF\ufffdo\ufffd\ufffdiN!\ufffd\ufffdh\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\"HL[\ufffd\ufffd\ufffd\"\ufffdr)\ufffd$c\ufffd[9\ufffd\ufffd\ufffd?BMg\ufffd\ufffd\ufffdj\ufffdI\ufffd\ufffd&\ufffdt\u032c\ufffd\u078c\u0797w\ufffd\ufffd\ufffd\ufffdi\ufffd\ufffd\ufffdM\ufffd@\ufffd $f\ufffdF\ufffd\ufffdl\ufffdH\"d\ufffdh )4 \ufffd4\ufffd.2\ufffd\ufffd\ufffd\ufffd\ufffd1o\ufffd$V^&&\ufffd]\ufffd}V\ufffd\ufffd\ufffd\ufffd\ufffdF\ufffd\ufffd1\ufffdi7q\\\ufffd\ufffd\ufffd\u012fC6\u397f\ufffd\ub34d\ufffdK\ufffdZ\ufffde=\ufffd\ufffd\u070d\ufffdO-\ufffdOE_5\ufffd\u037a\\\ufffd\ufffd|\ufffd\ufffd \ufffd\ufffdnV\ufffd\ufffd\"\u028b1\ufffdy\u07ef\u04af\ufffd\ufffdp\ufffd\ufffdG\ufffd\ufffd\ufffdk\\\ufffdB\ufffd\ufffd\ufffd{n\u011e\ufffd\ufffd?2\ufffd\ufffd\u066f{ql\ufffdQ\ufffdgN\ufffd\ufffdS\ufffdYz\ufffd\ufffd\ufffd\ufffd\ufffd\u01b1\ufffd\ufffd\"I@$%t\ufffd\ufffd/e/f[EN9l\ufffd\ufffdd\ufffd\ufffdd\ufffd\ufffd\ufffd\ufffdMV\ufffd5[$\ufffd] \ufffd\ufffd]\ufffd\ufffd\ufffd\ufffd\ufffd-\ufffd\ufffd\ufffdy\ufffd4\ufffd\ufffd6\ufffd\ufffd I\ufffdd\ufffdBp\ufffd\ufffd$\ufffdAD\ufffdV\ufffdl)U\ufffd\ufffdH\ufffdUj&\ufffd\ufffd@\ufffdDD\ufffd\" ]\ufffd]jv@z?:&\ufffd ,\ufffd[G}3&W]fz(\ufffdY\ufffd\ufffdTi\ufffd6K\ufffd>\ufffd\ufffdm\u02a4\ufffdhW=N]\ufffd\ufffdX\u0448\u0246>UTR\ufffdB4E\ufffde\ufffdn:[]\ufffd\ufffdd'K\ufffdVN4\ufffd]\ufffd\ufffd\ufffdk,\ufffd\ufffdt\u0298\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0216\ufffd\ufffd\ufffd[\ufffd\ufffd6aNk\ufffd,|\ufffdK DSDt\ufffd\ufffdGF5:\ufffd\ufffd\"%6\ufffdx\ufffd\ufffdk\ufffd\ufffd\ufffd\ufffd*Q\ufffd\ufffd5Mj\ufffd@\ufffdq5[$\ufffdY&\ufffdt\ufffd\ufffd\ufffd \ufffd\ufffd\u0676R\ufffdk\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd7lm<@ \ufffd\ufffdb\u055b\\\u92af\ufffdw\ufffdMR\ufffd2\ufffd\ufffdA A\ufffd`\ufffd\ufffd L+\ufffd\ufffd\ufffd\ufffdf#\ufffd\ufffd\ufffdF\ufffdIB)\ufffd5(\ufffdv\ufffd\u9ba2\u034d\ufffd\ufffdgt\ufffd\ufffd\u0362j\ufffd7\ufffdZ\ufffd\ufffd:\ufffd:Mo\ufffd\ufffd\ufffdR\ufffd\ufffd.\ufffd%Z\ufffd\ufffd\ufffd\ufffd\ufffd^\ufffdQ\ufffd\ufffd\ufffdkg\ufffd\ufffdK-3\ufffd\ufffd\ufffdx\ufffdmY\ufffd\u01a7F\ufffd{v\ufffd0\ufffd\ufffdi\ufffd9\ufffdZ\ufffd\u0aac8\ufffdv\ufffd\ufffd\ufffd6\u03e7\ufffd\ufffd\ufffd\u0232\ufffdaf_e\ufffdX\ufffd\ufffd\ufffd\ufffd\ufffd8 GU\ufffd\ufffd\ufffdM\ufffdX&\ufffdeI\ufffd\ufffdc\ufffd\ufffd\ufffd ]FQ\ufffd\u0235[$\ufffdn\ufffdQd\ufffd\ufffd\ufffd\ufffdl \ufffd$\ufffdn\ufffd\ufffd\ufffd\ufffdn\u05afM\ufffd\ufffd\ufffdLT\ufffd\ufffd\ufffd\ufffd7s\ufffd\ufffdyb \ufffdf\ufffd JBk\ufffd\ufffdDrH\ufffdE\ufffdD\ufffd,\ufffd8`D\ub342\ufffd\ufffd[`\ufffd\ufffd#20\ufffd\ufffdT\ufffd{H\ufffdC\ufffd!V-u\ufffd\u05ef\ufffd?Ft1\ufffd\ufffd\ufffdw\ufffd\u0715\ufffd\ufffdU\ufffd\ufffd\ufffd\ufffd\u0576\ufffdl\ufffd\ufffdE\ufffd\ufffdl\ufffdL-?I\ufffdF\ufffd8\ufffd\ufffd=\ufffd\ufffd0\ufffd\ufffdC\ufffd\ufffd\ufffd\ufffd\ufffd:\ufffd\ufffd\ufffd}\ufffd\ufffdl\ufffdv)\ufffd[,jg\ufffd\ufffd\ufffdO7N-\ufffd\ufffd\ufffdV\ufffd?N\ufffdXW\ufffdmq\ufffd}`\ufffd\ufffdh\ufffd7#_\ufffdi\ufffdj\ufffdty\ufffd\u02b4b<\ufffd)[\u0254\ufffd\ufffd!\ufffd\ufffd\ufffd\ufffd+\uc66fe\ufffdkf\ufffd\ufffd\ufffd\ufffd\ufffd[02\ufffd\ufffd\ufffdj\ufffd U\ufffd\ufffd[(\ufffdHQa $B\ufffdD\ufffd\"R\ufffd\ufffd@E\ufffduV\ufffd\ufffd\ufffdio\ufffd tY\ufffd\ufffdn\ufffd\ufffdx\ufffd 02 \ufffd 21&\ufffdY\ufffdeh\ufffdGE\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdg\ufffd\ufffd\ufffd\\\ufffd\ufffd\ufffd\ufffdI\ufffdJkt\uac99Jp}\ufffdnG\"\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd*\ufffdE;$\ufffd\ufffd\ufffd7\ufffdY8\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd6\ufffd-\u06e6\ufffd\ufffd\ufffd=v/\ufffdj\ufffd\ufffd\u06df\ufffd\ufffd\ufffd\ufffd\ufffd[_\ufffd\ufffd\ufffdB\ufffd\ufffdjz,x\u07d8{\ufffdc]q\ufffd\ufffd\ufffd\ufffdui\\\ufffd\ufffd\ufffd\ufffd\ud1ed?>\ufffd:8r\ufffdT\ufffd\ufffdtJb\ufffdQ\"\ufffdL\ufffd-u\ufffdS\"\u0410Y\ufffd\ufffd\ufffd:0vWu/Yz\ufffdZ%ut\u04b8\ufffd*\ufffd\ufffdQlx\ufffddN2\ufffd\u0171\ufffd\ufffdb\ufffd\ufffd\ufffdBH\ufffd\ufffd@\"RdYMl\ufffd\ufffds\u9597u\ufffd\ufffdL1\ufffd\ufffdKw\ufffd\ufffdN6\ufffd\ufffd LO3' @ \ufffd\ufffd0'\ufffd\ufffdc\ufffd\\\ufffd*\ufffdg\ufffd\ufffd}Sc\ufffd\ufffdc\ufffd\ufffd\ufffdN8\ufffd\ufffdU\ufffd\ufffdY\ufffdr\ufffdS[\ufffd\ufffd\ufffd\ufffd&\ufffdNnp}\ufffd\u05df\ufffde\ufffd'M\ufffd1\ufffd\ufffd\ufffd+\ufffdFID\u064btSd5\ufffdK:\ufffd_>\ufffd\ufffd=\ufffd7\ufffd[.\ufffd \"DB]?1\ufffdsi\ufffd\ufffdf?\ufffdu\ufffdn\ufffd\ufffd,}V,\ufffdj\ufffd\ufffd\ufffdbJ\ufffdnQm/g/\ufffd\ufffd=k\ufffdz\ufffd\ufffdy\ufffd\ufffd\ufffd\ufffd=\ufffd<\ufffd\ufffd\ufffdzl'9\ufffd*\ufffd\ufffdE\ufffdS\ufffddM\ufffd\ufffd%\ufffd\ufffdj\ufffd\ufffd8>\ufffdy\ufffd+i+\ufffd\ufffdT\ufffd\ufffd\ufffd\ufffdB\ufffd U\ufffd\u010aA)4\ufffd \ufffdl4\ufffd\ufffd\ufffd\ufffdoFZm\u0596\ufffdb\ufffd\ufffd\ufffd-\u0797s8\ufffd1 \ufffdrM\ufffd2!7Y]!s\ufffd/1\ufffd \ufffdP\u020e,L\ufffd\ufffd\ufffd[\ufffd\ufffdS\ufffd\ufffd8KHIJzX\ufffd,\ufffdN/\ufffd&\ufffd\ufffd\u02b9g[%\\\ufffdI\ufffd9\ufffd\ufffd\ufffd\ufffd0\ufffdO\ufffd&%\ufffdYJ\ufffdg\ufffdJDgTm\ufffd&\ufffd9\ufffd^\ufffd\ufffd\ufffd\ufffd\ufffdu\ufffd=Z\ufffd(\ufffdhbRb \ufffd\ufffdH\ufffd}\ufffd\ufffd\ufffd~\ufffd\ufffdm\ufffd+\ufffd\ufffd\ufffd\u06d2\ufffd\ufffd\ufffd\ufffdc&R\ufffdK.\ufffd2\ufffd\ufffd?7Y\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd9E\ufffd\ufffd\ufffdgS\ufffdyk\ufffd}\ufffd^O\ufffdsOS:e\ufffd\ufffdL\ufffdk\ufffd\ufffd[\ufffd\ufffdj\ufffd\ufffd\u02a7\ufffd\ufffde\ufffd8\ufffd\ufffdEmj\ufffd\ufffdZ\ufffdQkm\ufffd!\ufffd\ufffd98U\ufffd\ufffdV\ufffdII\ufffd\"!$\ufffd\ufffd\ufffd\ufffdbl\ufffd<\ufffd\ufffd8\ufffd\ufffd\ufffd\ufffdx<\ufffd\ufffd\ufffd\ufffd->n\ufffd\ufffdt\u06d9\ufffd\ufffd)\ufffd \u0760\ufffdA\ufffd\ufffd\ufffd\ufffd\ufffduh4\ufffd\ufffd\ufffdu\ufffd\"\ufffdNU\ufffdjNU\u02b5\ufffd\ufffd\ufffd7 eY\ufffd\ufffd[*\ufffdL\ufffdp\ufffd\ufffd\ufffd\ufffd\\\ufffd\u7617FRJ=\ufffds\ufffd\ufffd<\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffddBI1!\ufffd @e\ufffd*\ufffdh\ufffd\ufffd\ufffdk\u9ebeirtl\ufffdM7\ufffd\ufffd\ufffdr\ufffdr\ufffdj\ufffd:\ufffdm\ufffd\ufffda(\ufffdr \ufffdk\ufffd\ufffd}\ufffd~K\ufffdsOf\ufffd/\ufffdm\ufffd\ufffdu;s\ufffdTO\ufffd\ufffd\ufffd)':8\ufffd\ufffd\ufffdi$\ufffd\ufffd\ufffdHq\"4\ufffd\ufffd b\ufffd\ufffd9/\ufffd\ufffddLXg\ufffd\ufffd\ufffd\ufffdm\ufffdwzki\ufffd\ufffd\ufffd\ufffdS\ufffd\ufffdS %\ufffd\ufffd\ufffdDKHDK$ i\"0\ufffd\ufffd\ufffd\ufffd*H\ufffdKI\ufffd\ufffdk\ufffdYD\ufffd[\ufffdf\ufffd\ufffdK%\ufffdI\ufffdYD\ufffdQl\ufffd\ufffdt\ufffdU\ufffd\ufffd\ufffd\ufffd\ufffd\u025ey o\ufffd=\ufffdD\ufffdEe\ufffd>^\ufffd\ufffd\ufffd\ufffdh@\ufffd L\"q\ufffd9\u042a )$!\ufffd\ufffd4& \ufffd F@@ \ufffd\ufffd\u035f\ufffd\ufffdn\u00de}OSf>9\u01d7WL\ufffd\ufffd\u03b9(\ufffdi%\ufffd\ufffd\ufffd%\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd$)$i\u0136\ufffdd,\ufffd\ufffd\ufffdn\ufffd}\ufffdiwZ[\ufffd^\ufffd\ufffdt\u06c9\ufffd\ufffd\ufffdb\ufffd,\ufffdb\ufffd\ufffd0\ufffdFIK\ufffd\u04b6MD\ufffd\ufffd\ufffd\ufffd0\ufffd\ufffd\ufffdM\u39a95[\ufffdT\ufffd'C\ufffdbdJ\u0152\ufffdz\ufffd7\ufffd\ufffdrs\ufffd^\ufffd\ufffd\ufffdK\ufffdr\ufffd\ufffds\ufffd/]\ufffd\ufffd\ufffdde\ufffdeO4\ufffdZ\ufffdD\ufffd\ufffd&O7\u05d77\ufffde]<\ufffd\ufffdV &\ufffd \ufffd @\ufffd\ufffdDhJA WD\u055b\ufffd\ufffd{\ufffd\ufffd\ufffd&\ufffd6\ufffd\u049d\ufffd\ufffd\ufffd\ufffd\ufffd=Y\ufffd4\ufffd0in.\ufffd\ufffd^\ufffd\ufffd\ufffds\u05e4\ufffd<\ufffd\ufffd\u0277\u024c\ufffd\ufffd\ufffd\ufffdq\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd}5z\ufffdT\ufffd\ufffd\ufffdZ\ufffd\ufffdM\ufffd\ufffd\u06bd\ufffd\ufffdl-+/\ufffd\ufffd\ufffd]\ufffdb\ufffd\ufffd\ufffd?K\ufffd\ufffdiG(KL\ufffd'IYl\ufffd\ufffd3\ufffd\ufffd\ufffd\u9be6# z'\ufffd\ufffd\ufffdg \ufffd@ a!9<\ufffdr\ufffd\ufffd\ufffd\ufffd\ufffdM\ufffd \ufffdv\ufffdVM\ufffd\ufffdu\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdq!~=\ufffdr2\ufffd\ufffd\ufffdY D\ufffdpNN\u0549%1\ufffd\ufffd\ufffd\ufffd\ufffdR\ufffd&\ufffdi\ufffd\ufffd\ufffd\ufffd)\ufffd..\ufffd\\%J\ufffdu\ufffdk\ufffd\ufffd\ufffd\ufffd<\ufffd\ufffd\ufffd\ufffdE\ufffdN\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u02ad\ufffdqj`$A \ufffdhQ\ufffdDa\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd+\ufffd\ufffd_[k\ufffd\ufffd\ub9ba\ufffd5\u0599z,\ufffd\u06ber\ufffd:\ufffdk\ufffdi\u07acDAvV\ufffd\ufffd\ufffd+I\ufffd\ufffd<\ufffd1'\ufffd>m\ufffds\ufffdZ\ufffdQ9\ufffdgK\ufffd#\ufffdJ\ufffd\ufffd\ufffdQ|\u01eeW\ufffd>\ufffdy^\ufffd\ufffd9\ufffd\ufffd\ufffd\ufffd\ufffd4\ufffd:'Y\ufffdt\ufffdKX\ufffd*\ufffd\ufffdz\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdi\ufffd:k\ufffd\ufffd\ufffdu\ufffd\ufffd\ufffd3\ufffd1 \ufffd^~\ufffd\ufffd\ufffdc4R\ufffd\ufffdO\ufffd`\ufffdq\ufffd\ufffd\ufffde3m\ufffd\ufffd\ufffd\ufffd^F\ufffd')\u02cc\ufffd\ufffd\ufffd\ufffd\ufffdi\ufffdr.@\ufffdI\ufffd\ufffd}\ufffd\ufffd\ufffd^/9\ufffdq\ufffd\ufffd\ufffd}\ufffd\nc\ufffd\ufffdk{8\ufffdF\ufffd\ufffd \ufffd\ufffdD 0 i\ufffd\ufffdi<_G\ufffd\ufffd\ufffd\ufffdR\ufffd\ufffd<\ufffd9\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdoe\ufffd\ufffdu\ufffdm#\ufffd|gw6\ufffd\ufffd\ufffd\ufffd \ufffd \ufffdL\ufffd,\ufffd\ufffd>\ufffdS\ufffd3.\ufffd\ufffdh{\ufffd\ufffd\u0441\ufffd\ufffd \ufffd\ufffd\ufffd%\ufffd\ufffdJ\ufffd/I\ufffd<\ufffd\ufffd\ufffd\ufffd\u01f4\ufffd5oe\ufffdkm\ufffd\ufffd\ufffd\ufffdn\ufffd\ufffdB'm/:\ufffd\ud6d7\ufffd\ufffdX\ufffd\ufffd\ufffdm\u039e\ufffdb1\ufffd\ufffd\ufffd:m\ufffd\ufffd\ufffdH \ufffd]z\ufffd\n\ufffd\ufffd9\ufffd\ufffd\ufffd\n\ufffd[OW\ufffd\ufffd\ufffdM\ufffd\ufffdY2\ufffdX\ufffdDVS\ufffd,|\ufffd?j\ufffd'\ufffdh]\ufffd\ufffd\ufffd\ufffd2\ufffd\ufffd\u00d2\ufffd\ufffd9\u0346\ufffd\u03bbi\ufffd\ufffd\ufffdGA\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdQ\ufffd\\\ufffdM\ufffd\ufffd\ufffdrS\ufffd\ufffd\ufffdo.\ufffdm\ufffd@Ol\ufffd&^\ufffd\ufffd\u02ce\ufffdTz<(p\ufffd10 \ufffd\ufffd @\u0406\ufffd fO=\ufffd\ufffd\ufffdmf\ufffd7\ufffd\ufffdB}\ufffd[\ufffd\ufffd.\ufffd\ufffd\ufffdo\ufffd\ufffd\ufffd:c\ufffdz\ufffd\ufffdR\ufffd\ufffd\ufffd146\ufffdR\ufffd\ufffd\ufffd\ufffdr[\ufffd'\ufffdP\ufffd\ufffd-\ufffd&m\ufffdd\ufffd)\ufffd\ufffd\ufffd 5;\ufffd\ufffd\ufffd\ufffdW\ufffd\u03efM\ufffdv|gOe1\ufffd\ufffd/Y\n+\ufffd\ufffdx\ufffd\ufffd\ufffd\ufffd\ufffd'\ufffd\ufffd4\ufffd\ufffd\ufffd\ufffdD\ufffd\ufffd\ufffd\ufffd\ufffd`\ufffd@ \ufffd\ufffd,\ufffd~\ufffdS\ufffd\ufffd+\ufffd\ufffd\ufffd\ufffd\ufffd:\ufffd\ufffd\u015e3\ufffd\ufffd\u9d1d\ufffd\ufffdvGm,B\ufffd\u067d?\ufffdqT\ufffd&\ufffd-yP\ufffdqc\ufffd\\kT,\ufffd;U\ufffd[BB\ufffd\ufffd\ufffdE~\ufffd\u00f5\ufffd2\ufffdz\ufffd\ufffd\ufffd ;\ufffd\ufffd\ufffd\ufffdn\ufffd\ufffdQ\ufffd4k\ufffd\ufffd:\ufffd\ufffd\ufffdSU\ufffd\ufffd\ufffd$A\ufffdV\ufffd\ufffdDl\ufffd\ufffd 0@\ufffd $ !4 \ufffd\ufffd\ufffd\u06d7\ufffd.\ufffd\ufffdY\ufffd\ufffd<\ufffdn\ufffd+\\\ufffd\ufffds\ufffdF\ufffdo\ufffdc\ufffd\ufffd\ufffdv\ufffd/w\ufffdb&\ufffdL\ufffd gk\ufffd>\ufffd~\ufffdu\ufffd_*\ufffdm\ufffdv\ufffd\ufffd\ufffd m1\ufffd\ufffd@e\ufffd \ufffd\ufffdy?\ufffdr}]\ufffdEyx]\ufffd\ufffd\ufffd|w\ufffd>\ufffd\ufffd\ufffd@m\u039e\ufffdb\ufffd\ufffdyn4\ufffd\ufffdc`\ufffd@ \ufffdG\ufffd\ufffd\ufffdj\ufffd\ufffd[<\ufffd\ufffdbdBI\u032a\ufffd\ufffd]f\ufffd=\ufffdl\ufffdL\ufffdg\ufffd\ufffdga=}Y\ufffd1\uafbem\ufffd|Z8I\ufffdlh\ufffdF/B\ufffd1l\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd/\ufffdQ8p{\ufffd\ufffd\ufffdNz\ufffd,]\ufffd{\ufffd\ufffd^a5\ufffdq\ufffdOD\ufffd_[\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd(\ufffd[E\ufffd\ufffd\ufffd\u04186u\ufffdn\ufffdqm\ufffd\ufffd\ufffdK\n\ufffd\ufffd\ufffdX\ufffd\ufffdg\ufffd\ufffdX\ufffd\ufffd1+U\ufffd M\ufffdD\ufffdF\u01d0\ufffd\ufffdN\ufffd,=\ufffd.z\ufffdq\ufffdY\ufffd\ufffd\ufffd_\ufffd\ufffd\ufffdm\ufffd@^\ufffd\ufffdL\n8I\u0153\ufffd\u01f8\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdm6\ufffdm\ufffd'j\ufffd\u0563\ufffd\ufffdN[Hn\ufffd\ufffdE\u07de{/\ufffd\ufffd'\ufffdV\ufffd)\ufffdY\ufffd\ufffd0\ufffd4\ufffd\ufffd \ufffd?\ufffd/\ufffd=oNL\ufffd\ufffd\ufffd\ufffd O\ufffd\ufffd\ufffdLv\ufffd\ufffd=\u019fqll\ufffd\ufffdL Hc\ufffdg-\ufffdnoe\ufffd\ufffdK\ufffd\u07a3g\ufffd\ufffd<{\ufffd\ufffdy\ufffd\u06f3\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\\\ufffdf4d`\ufffdzx\u06f7\ufffd\ufffd^\ufffd\ufffdW1\ufffd\ufffdyX\ufffde\ufffdM\ufffd\ufffdu\ufffdC2\ufffd\ufffdg|x\ufffd[\ufffddG\ufffd\ufffd\ufffd\ufffd\ufffdn\ufffd\ufffdN-\ufffd\ufffdlw\ufffd8\ufffdQ))\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd[\ufffd J=YAN0\ufffd\ufffd\ufffd$\ufffd,\ufffd \ufffd\ufffd&\ufffd\ufffd\ufffdr\ufffd\ufffdu\ufffd\ufffd\ufffd\ufffd\ufffd[\ufffd\ufffd\ufffdxgS\ufffdF\ufffdg\ufffd\ufffduXz_\ufffdW\ufffd\ufffd\ufffd@P @\ufffdd\ufffdg\ufffdv\ufffd]i\ufffdg\ufffd\ufffd&\ufffd`\ufffd\ufffd[]L_c\ufffd\ufffdy\ufffd/g\ufffd!\ufffd\ufffd(\u0215\ufffd\\w\ufffd\ufffdy\ufffd\ufffd\ufffdB\ufffd\ufffd\ufffd;Q\ufffd\ufffd\ufffde/\ufffd\ufffd\ufffd\ufffdE09\ufffd\ufffd8,C\ufffd\ufffd\ufffd\u0479e\ufffd\ufffd ,z\ufffd\ufffdF\ufffdj \ufffd\ufffd\ufffdy\ufffdv\ufffd*\ufffd=Q\ufffd\ufffd^\ufffd\ufffd=v\ufffd\ufffdS\ufffde`\ufffd@ \ufffd\ufffd M\ufffd\ufffd\\lL\ufffd\\\ufffd\ufffd\ufffdb\ufffdu\ufffd\ufffd\ufffd\ufffd\ufffdt\ufffd F{\ufffd02\ufffd:6Zm\ufffd1\ufffd\ufffdQ/\ufffd\ufffd\ufffd\ufffdF/\ufffd\ufffdzw\ufffd\ufffd\ufffd\u07c7\ufffd)>^\ufffdtg\ufffd\ufffd\ufffdW\ufffd0\ufffd9\ufffd\ufffd[\ufffd\ufffd\u051aa\ufffd\ufffd\ufffdl\ufffd\ufffdV7\ufffd\ufffdsE\u0326UF\ufffda\ufffdq\ufffd\ufffdh:.c\ufffd\ufffdP\ufffd\u04a94E2\ufffd\ufffd\ufffd#\ufffd\ufffd\n4u\ufffd\u0593u\ufffdt7Dp\ufffd\ufffd|}diaEv\ufffdeV\ufffd\ufffd\ufffd\ufffdT\ufffd\ufffdX8\ufffdK0\ufffd@\ufffdhY\ufffd1\ufffd\ufffd;\ufffd\ufffd\ufffdCg\ufffd\ufffdc\ufffd3\ufffdl\ufffd{\ufffd\ufffd\">\u01d4\ufffd 4\ufffd\ufffd)J\u06ac\ufffdu\ufffd\ufffd=\ufffd\ufffdk<\ufffd\ufffd\ufffdx\ufffd\ufffd\ufffd\ufffd 1\ufffdSYh\ufffd\ufffd.'\ufffd<\ufffd\ufffd\ufffd\ufffd\ufffdf\ufffd\ufffd\ufffd\ufffd|\u01d1\ufffd\ufffd>p\ufffd\ufffd>\ufffd\ufffd=\ufffdF\ufffd\ufffd\ufffd\ufffd7\u0700 0\ufffdRyY\ufffdB\ufffd\ufffd\ufffdO\ufffd\ufffd}*i\ufffdY\ufffdu[X\ufffd\ufffd+\ufffd \ufffd\ufffd\ufffd\ufffd\ufffdXzu\ufffd^\ufffdG\ufffd\ufffdE*\ufffdy\ufffd\ufffd\ufffdzt\ufffd\ufffd\ufffd\ufffd\ufffdl\u0613\ufffd++\ufffd_?\ufffd\ufffdm\ufffd\ufffd \ufffd\ufffd\ufffd\ufffdz\ufffd\ufffdg\ufffd\ufffdf\ufffd\ufffd\ufffdI\ufffdh)\ufffdo\n\ufffdQ\ufffdAli\ufffdQ`\ufffd\ufffdL.V2\ufffd\ufffd\ufffd\u0394\ufffdL\ufffd C9\ufffds\ufffd\ufffd\ufffdF\ufffd/\ufffd\ufffd\ufffd\ufffd6\ufffd\ufffd\ufffdvW\u02adD\ufffde3&\ufffd\ufffd\ufffdM\ufffd\ufffd\ufffdx\ufffdtU\ufffd\ufffdi\ufffd\ufffd^:t\u0633\ufffdW\ufffd\ufffdU|\ufffd\u039f\ufffd\ufffd\ufffd= 4 \ufffd=/5n\ufffd}\ufffd\ufffdzo\ufffdt\ufffd+\ufffd>\ufffd>\u07d2\ufffdZ\ufffdi\ufffd\ufffd);+\ufffd\ufffd\ufffd^k\ufffd\\\ufffd\ufffds\ufffd<\ufffd\ufffd\ufffd;6\ufffd\n'\ufffd\u077e\ufffdc\ufffd;\ufffd7\ufffdn\ufffd'\ufffd\ufffd\ufffd\ufffd\ufffd!\ufffd&9\ufffd\ufffd'\u0301\ufffd\ufffd\ufffd\ufffdoy;?\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd>\ufffd '\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd^\ufffdWM\ufffd3\ufffd[mN\ufffd3\ufffd\nf0 Ly\ufffd\ufffdc.\u0779\ufffdz\ufffd\ufffd\ufffdv\ufffdr\ufffd\ufffd\ufffds\ufffd\ud368\ufffd+\ufffdQ\ufffd\ufffdV\ufffd\u0262\ufffdks5]W\ufffdp\ufffd\ufffd\ufffdM\ufffd\ufffd\u077cb\ufffd!\ufffds\ufffd\ufffd\ufffdq1\ufffd\ufffdB\ufffd$4\ufffd-\ufffd\ufffdVL\ufffd\ufffdLUX\ufffdd0\ufffd%B\ufffd\ufffd%\nLy>\ufffd\ufffdm\\*\ufffdWNqM\n-A&\ufffd\ufffdk\ufffdS\ufffd\ufffd_k\ufffd\ufffd\ufffd%\ufffd2\ufffd<\ufffd\ufffd\n:\ufffd\ufffd]Fu\ufffd\ufffd\u05e4a\ufffd G\ufffdi\ufffd\ufffdc\ufffd\ufffd\ufffd\ufffd\ufffd \ufffdj 8\ufffd=\ufffd-\ufffdp\ufffd_eVp\ufffd[u7\ufffd7\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd^\ufffd\ufffd\ufffd\ufffdJs\ufffdF\ufffd\ufffd|\ufffd\ufffdx\u01ff|\ufffd \ufffd>\ufffd\ufffd\ufffdG\ufffd\ufffd\ufffd\ufffd\u724f\ufffd\ufffd\ufffdi}\ufffd\ufffd)\ufffd\ufffd\ufffd\ufffd\ufffdM\ufffd7\ufffd\u01f6gr\ufffd\ufffdxF\ufffd\ufffd_\ufffd\u03e4\ufffd|s\ufffd\ufffd8\ufffdO_\ufffd\ufffd\ufffd7 \ufffd\ufffdz\ufffd\ufffd\ufffd[\ufffd'\ufffd\ufffd\ufffdj\ufffd\ufffd\ufffd\ufffdg\ufffd\ufffd$ \ufffdt\ufffd\ufffdV\ufffd\ufffd\\OB\ufffdg|\ufffdB\ufffd\ufffd\ufffdHnV\ufffd\ufffd\ufffd\ufffd\ufffd7\ufffd\ufffd\ufffdj\ufffd\ufffds\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdy%\ufffdc\ufffdo\ufffd\ufffd\ufffd\ufffd\ufffdJ29x\ufffd\ufffdP\ufffd\n\ufffd4\ufffd2\ufffd\ufffdM\ufffd\ufffd\ufffd\ufffdF\ufffd&0p\u0266\ufffd\ufffd\ufffd\ufffdNs\ufffd1\ufffdJ!Q\ufffdB\ufffd\ufffd\ufffd\n\ufffdK\ufffd\ufffdk\ufffd\ufffd+\ufffdm\ufffd"
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/chatgpt-will-start-asking-if-you-need-a-break-that-may-not-be-enough-to-snap-a-bad-habit/",
      "text": "We've all been mid-TV binge when the streaming service interrupts our umpteenth-consecutive episode of Star Trek: The Next Generation to ask if we're still watching. That may be in part designed to keep you from missing the first appearance of the Borg because you fell asleep, but it also helps you ponder if you instead want to get up and do literally anything else. The same thing may be coming to your conversation with a chatbot.\nOpenAI said Monday it would start putting \"break reminders\" into your conversations with ChatGPT. If you've been talking to the gen AI chatbot too long -- which can contribute to addictive behavior, just like with social media -- you'll get a quick pop-up prompt asking if it's a good time for a break.\n\"Instead of measuring success by time spent or clicks, we care more about whether you leave the product having done what you came for,\" the company said in a blog post.\n(Disclosure: Ziff Davis, CNET's parent company, in April filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nWhether this change will actually make a difference is hard to say. Dr. Anna Lembke, a psychiatrist and professor at the Stanford University School of Medicine, said social media and tech companies haven't released data on whether features like this work to deter compulsive behavior. \"My clinical experience would say that these kinds of nudges might be helpful for people who aren't yet seriously addicted to the platform but aren't really helpful for those who are seriously addicted.\"\nOpenAI's changes to ChatGPT arrive as the mental health effects of using them come under more scrutiny. Many people are using AI tools and characters as therapists, confiding in them and treating their advice with the same trust as they would that of a medical professional. That can be dangerous, as AI tools can provide wrong and harmful responses.\nAnother issue is privacy. Your therapist has to keep your conversations private, but OpenAI doesn't have the same responsibility or right to protect that information in a lawsuit, as CEO Sam Altman acknowledged recently.\nChanges to encourage \"healthy use\" of ChatGPT\nAside from the break suggestions, the changes are less noticeable. Tweaks to OpenAI's models are intended to make it more responsive and helpful when you're dealing with a serious issue. The company said in some cases the AI has failed to spot when a user shows signs of delusions or other concerns, and it has not responded appropriately. The developer said it is \"continuing to improve our models and [is] developing tools to better detect signs of mental or emotional distress so ChatGPT can respond appropriately and point people to evidence-based resources when needed.\"\nTools like ChatGPT can encourage delusions because they tend to affirm what people believe and don't challenge the user's interpretation of reality. OpenAI even rolled back changes to one of its models a few months ago after it proved to be too sycophantic. \"It could definitely contribute to making the delusions worse, making the delusions more entrenched,\" Lembke said.\nChatGPT should also start being more judicious about giving advice about major life decisions. OpenAI used the example of \"should I break up with my boyfriend?\" as a prompt where the bot shouldn't give a straight answer but instead steer you to answer questions and come up with an answer on your own. Those changes are expected soon.\nTake care of yourself around chatbots\nChatGPT's reminders to take breaks may or may not be successful in reducing the time you spend with generative AI. You may be annoyed by an interruption to your workflow caused by something asking if you need a break, but it may give someone who needs it a push to go touch grass.\nRead more: AI Essentials: 29 Ways You Can Make Gen AI Work for You, According to Our Experts\nLembke said you should watch your time when using something like a chatbot. The same goes for other addictive tech like social media. Set aside days when you'll use them less and days when you won't use them at all.\n\"People have to be very intentional about restricting the amount of time, set specific limits,\" she said. \"Write a specific list of what they intend to do on the platform and try to just do that and not get distracted and go down rabbit holes.\""
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/what-is-superintelligence-everything-you-need-to-know-about-ais-endgame/",
      "text": "You've probably chatted with ChatGPT, experimented with Gemini, Claude or Perplexity, or even asked Grok to verify a post on X. These tools are impressive, but they're just the tip of the artificial intelligence iceberg. Lurking beneath is something far bigger that has been all the talk in recent weeks: artificial superintelligence.\nSome people use the term \"superintelligence\" interchangeably with artificial general intelligence or sci-fi-level sentience. Others, like Meta CEO Mark Zuckerberg, use it to signal their next big moonshot.\nASI has a more specific meaning in AI circles. It refers to an intelligence that doesn't just answer questions but could outthink humans in every field: medicine, physics, strategy, creativity, reasoning, emotional intelligence and more. We're not there yet, but the race has already started.\nIn July, Zuckerberg said during an interview with The Information that his company is chasing \"personal superintelligence\" to \"put the power of AI directly into individuals' hands.\" Or, in Meta's case, probably in everyone's smart glasses.\nThat desire kicked off a recruiting spree for top researchers in Silicon Valley and a reshuffling inside Meta's FAIR team (now Meta AI) to push Meta closer to AGI and eventually ASI.\nSo, what exactly is superintelligence, how close are we to it, and should we be excited or terrified? Let's break it down.\nWhat is superintelligence?\nSuperintelligence doesn't have a formal definition, but it's generally described as a hypothetical AI system that would outperform humans at every cognitive task. It could process vast amounts of data instantly, reason across domains, learn from mistakes, self-improve, develop new scientific theories, write flawless code, and maybe even make emotional or ethical judgments.\nThe idea became popularized through philosopher Nick Bostrom's 2014 book Superintelligence: Paths, Dangers, Strategies, which warned of a scenario where an AI bot becomes smarter than humans, self-improves rapidly and then escapes our control. That vision sparked both excitement and fear among tech experts.\nSpeaking to CNET, Bostrom says many of his 2014 warnings \"have proven quite prescient.\" What has surprised him, he says, is \"how anthropomorphic current AI systems are,\" with large language models behaving in surprisingly humanlike ways.\nBostrom says he's now shifting his attention toward deeper issues, including \"the moral status of digital minds and the relationship between the superintelligence we build with other superintelligences,\" which he refers to as \"the cosmic host.\"\nFor some, ASI represents the pinnacle of progress, a tool to cure disease, reverse climate change and crack the secrets of the universe. For others, it's a ticking time bomb -- one wrong move and we're outmatched by a machine we can't control.\nIt's sometimes called the last human invention, not because it's final, but because ASI could invent everything else we need. British mathematician Irving John Good described it as an \"intelligence explosion.\"\nSuperintelligence doesn't exist yet. We're still in the early stages of what's called artificial narrow intelligence. It's an AI system that is great at specific tasks like translation, summarization and image generation, but not capable of broader reasoning. Tools like ChatGPT, Gemini, Copilot, Claude and Grok fall into this category. They're good at some tasks, but still flawed, prone to hallucinations and incapable of true reasoning or understanding.\nTo reach ASI, AI needs to first pass through another stage: artificial general intelligence.\nWhat is AGI?\nAGI, or artificial general intelligence, refers to a system that can learn and reason across a wide range of tasks, not just one domain. It could match human-level versatility, such as learning new skills, adapting to unfamiliar problems and transferring knowledge across fields.\nUnlike current chatbots, which rely heavily on training data and struggle outside of predefined rules, AGI would handle complex problems flexibly. It wouldn't just answer questions about math and history; it could invent new solutions, explain them and apply them elsewhere.\nCurrent models hint at AGI traits, like multimodal systems that handle text, images and video. But true AGI requires breakthroughs in continual learning (updating knowledge without forgetting old stuff) and real-world grounding (understanding context beyond data). And none of the major models today qualify as true AGI, though many AI labs, including OpenAI, Google DeepMind and Meta, list it as their long-term target.\nOnce AGI arrives and self-improves, ASI could follow quickly as a system smarter than any human in every area.\nHow close are we to superintelligence?\nThat depends on who you ask. A 2024 survey of 2,778 AI researchers paints a sobering picture. The aggregate forecasts give a 50% chance of machines outperforming humans in every possible task by 2047. That's 13 years sooner than a 2022 poll predicted. There's a 10% chance this could happen as early as 2027, according to the survey.\nFor job automation specifically, researchers estimate a 10% chance that all human occupations become fully automatable by 2037, reaching 50% probability by 2116.\nMost concerning, 38% to 51% of experts assign at least a 10% risk of advanced AI causing human extinction.\nGeoffrey Hinton, often called the Godfather of AI, warned in a recent YouTube podcast that if superintelligent AI ever turned against us, it might unleash a biological threat like a custom virus -- super contagious, deadly and slow to show symptoms -- without risking itself.\nResistance would be pointless, he said, because \"there's no way we're going to prevent it from getting rid of us if it wants to.\" Instead, he argued that the focus should be on building safeguards early.\n\"What you have to do is prevent it ever wanting to,\" he said in the podcast. He said this could be done by pouring resources into AI that stays friendly.\nStill, Hinton confessed he's struggling with the implications: \"I haven't come to terms with what the development of superintelligence could do to my children's future. I just don't like to think about what could happen.\"\nFactors like faster computing, quantum AI and self-improving models could accelerate things. Hinton expects superintelligence in 10 to 20 years. Zuckerberg said during that podcast that he believes ASI could arrive within the next two to three years, and OpenAI CEO Sam Altman estimates it'll be somewhere in between those time frames.\nMost researchers agree we're still missing key ingredients, like more advanced learning algorithms, better hardware and the ability to generalize knowledge like a human brain. IBM points to areas like neuromorphic computing (hardware inspired by human neurons), evolutionary algorithms and multisensory AI as building blocks that might get us there.\nMeta's quest for 'personal superintelligence'\nMeta launched its Superintelligence Labs in June, led by Alexandr Wang (ex-Scale AI CEO) and Nat Friedman (ex-GitHub CEO), with $14.3 billion invested in Scale AI and $64 billion to $72 billion for data centers and AI infrastructure.\nZuckerberg doesn't shy away from Greek mythology, with names like Prometheus and Hyperion for his two AI data superclusters (massive computing centers). He also doesn't talk about artificial superintelligence in abstract terms. Instead, he claims that Meta's specific focus is on delivering \"personal super intelligence to everyone in the world.\" This vision, according to Zuckerberg, sets Meta apart from other research labs that he says primarily concentrate on \"automating economically productive work.\"\nBostrom thinks this isn't mere hype. \"It's possible we're only a small number of years away from this,\" he said of Meta's plans, noting that today's frontier labs \"are quite serious about aiming for superintelligence, so it is not just marketing moves.\"\nThough still in its early stages, Meta is actively recruiting top talent from companies like OpenAI and Google. Zuckerberg explained in his interview with The Information that the market is extremely competitive because so few people possess the requisite high level of skills. Facebook and Zuckerberg didn't respond to requests for comment.\nShould humans subscribe to the idea of superintelligent AI?\nThere are two camps in the AI world: those who are overly enthusiastic, inflating its benefits and seemingly ignoring its downsides; and the doomers who believe AI will inevitably take over and end humanity. The truth probably lands somewhere in the middle. Widespread public fear and resistance, fueled by dystopian sci-fi and very real concerns over job loss and massive economic disruption, could slow progress toward superintelligence.\nOne of the biggest problems is that we don't really know what even AGI looks like in machines, much less ASI. Is it the ability to reason across domains? Hold long conversations? Form intentions? Build theories? None of the current models, including Meta's Llama 4 and Grok 4, can reliably do any of this.\nThere's also no agreement on what counts as \"smarter than humans.\" Does it mean acing every test, inventing new math and physics theorems or solving climate change?\nAnd even if we get there -- should we? Building systems vastly more intelligent than us could pose serious risks, especially if they act unpredictably or pursue goals misaligned with ours.\nWithout strict control, it could manipulate systems or even act autonomously in ways we don't fully understand. Brendan Englot, director of the Stevens Institute for Artificial Intelligence, shared with CNET that he believes \"an important first step is to approach cyber-physical security similarly to how we would prepare for malicious human-engineered threats, except with the expectation that they can be generated and launched with much greater ease and frequency than ever before.\"\nThat said, Englot isn't convinced that current AI can truly outpace human understanding.\n\"AI is limited to acting within the boundaries of our existing knowledge base,\" Englot tells CNET. \"It is unclear when and how that will change.\"\nRegulations like the EU AI Act aim to help, but global alignment is tricky. For example, China's approach differs wildly from the West's.\nTrust is one of the biggest open questions. A superintelligent system might be incredibly useful, but also nearly impossible to audit or constrain. And when AI systems draw from biased or chaotic data like real-time social media, those problems compound.\nSome researchers believe that given enough data, computing power and clever model design, we'll eventually reach AGI and ASI. Others argue that current AI approaches (especially LLMs) are fundamentally limited and won't scale to true general or superhuman intelligence because the human brain has 100 trillion connections. That's not even accounting for our capability of emotional experience and depth, arguably humanity's strongest and most distinctive attribute.\nBut progress moves fast, and it would be naive to dismiss ASI as impossible. If it does arrive, it could reshape science, economics and politics -- or threaten them all. Until then, general intelligence remains the milestone to watch.\nIf and when superintelligence does become a reality, it could profoundly redefine human life itself. According to Bostrom, we'd enter what he calls a \"post-instrumental condition,\" fundamentally rethinking what it means to be human. Still, he's ultimately optimistic about what lies on the other side, exploring these ideas further in his most recent book, Deep Utopia.\n\"It will be a profound transformation,\" Bostrom tells CNET."
    },
    {
      "url": "https://www.cnet.com/ai-atlas/",
      "text": "Apple Has Nothing to Fear With AI\nUp Next\nApple Has Nothing to Fear With AI\nOpenAI Introduces GPT-5 at OpenAI's Summer Update Event\nOpenAI Introduces GPT-5 at OpenAI's Summer Update Event\nInterview With an AI Avatar of a Slain Teen Goes Viral, ESPN Announces New Partnerships, and More | Tech Today\nInterview With an AI Avatar of a Slain Teen Goes Viral, ESPN Announces New Partnerships, and More | Tech Today\nUnitree R1: The Cheapest Humanoid Robot Yet?\nUnitree R1: The Cheapest Humanoid Robot Yet?\nOpenAI Debuts \"Study Mode\" for Students, the Tea App Data Breach, and Could a Robot Dog Deliver Your Next Pizza? | Tech Today\nOpenAI Debuts \"Study Mode\" for Students, the Tea App Data Breach, and Could a Robot Dog Deliver Your Next Pizza? | Tech Today\nTrump's AI Action Plan, Tech Company Layoffs and More | Tech Today\nTrump's AI Action Plan, Tech Company Layoffs and More | Tech Today\nHow You Talk to ChatGPT Matters. Here's Why\nHow You Talk to ChatGPT Matters. Here's Why\nApple's New Protection Plan, AI-Generated Music on Spotify, and More | Tech Today\nApple's New Protection Plan, AI-Generated Music on Spotify, and More | Tech Today\nGoogle Pixel 10 Revealed in Promo, iOS 26 Public Beta to Open, and More | Tech Today\nGoogle Pixel 10 Revealed in Promo, iOS 26 Public Beta to Open, and More | Tech Today\nI Built an AI PC From Scratch\nI Built an AI PC From Scratch\nUnboxing the Oakley HSTN Smart Glasses\nUnboxing the Oakley HSTN Smart Glasses\n$90 Billion AI Investments, MLB Robot Umpires and More | Tech Today\n$90 Billion AI Investments, MLB Robot Umpires and More | Tech Today\nGemini on the Galaxy Watch 8 Made Me a Believer\nGemini on the Galaxy Watch 8 Made Me a Believer\nPhones Are Loaded With AI, So Why Don't We Care?\nPhones Are Loaded With AI, So Why Don't We Care?\nyour trusted source on ai\nCNET has been covering AI for more than two decades. Now we're bringing you a new wave of expert, unique and helpful insights, through in-depth explainers, hands-on product reviews, how-to posts and more, to help you see how AI fits into your life.\nHelpful AI resources\nFAQs\nWhat is AI, in very basic terms?\nWhat is an AI hallucination?\nWhat is an LLM and how does it fit into AI?\nWhat is an AI agent?\nour ai experts\nOur writers and editors know the subject cold. Here are CNET's leading authorities on AI.\nAI Atlas is 100% human-generated. For more, see\nCNET's AI policy."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/best-ai-chatbots/",
      "text": "The launch of AI chatbot ChatGPT in late 2022 completely transformed how we interact with technology. Generative AI can answer questions in WhatsApp chats, summarize emails in Outlook, create \"genmojis\" in iMessage and spit out answers to complex questions with ease.\nPHOTO EDITING SOFTWARE DEALS OF THE WEEK\n- $42 (save $28)\n- $40 (save $25)\n- $100 (save $40)\nNow pretty much every major tech company has launched its own chatbot to compete with ChatGPT, including Google Gemini, Microsoft Copilot and Meta AI. And the big tech companies that aren't launching their own chatbots are getting involved in other ways, such as Apple partnering with OpenAI and ChatGPT in its upcoming iOS 18. Smaller startups also have working AI chatbots that compete well against trillion-dollar companies, including Anthropic's Claude and Perplexity.\nAt CNET, we reviewed all of those AI chatbots to find the best one for you (side note: doing so rewired my brain). The list below focuses on free versions as opposed to paid ones, but note that most AI chatbots do have a paid tier that often performs better than the free version. For most people, however, the free chatbot will get you 90% of what you need.\nWhat is the best AI chatbot of 2024 so far?\nClaude by Anthropic is the best AI chatbot overall right now. That doesn't mean ChatGPT or Perplexity are bad. Actually, both have their own advantages and disadvantages. Overall, though, the breadth at which Claude is able to answer questions and its calibration towards nuance and engagement should make it the most valuable to most people.\nBest overall AI chatbot\nPros\n- Gives nuanced answers with detail\n- Fast and well organized\nCons\n- Not connected to the internet\n- Doesn't automatically provide sources\nClaude by Anthropic is CNET Editors' Choice for the best overall AI chatbot. That doesn't mean it excels at every task compared to the competition. Rather, it does a consistent job and goes further than what's coming out of Google, Microsoft, Perplexity and OpenAI at the free tier.\nThe major things holding Claude back are its apathetic linking to outside sources and the lack of an Android app. If Anthropic could better tune Claude to have access to the open internet to link to sources and shopping links, it'd make the chatbot a true one-stop-shop. Despite the omission, the quality of its responses and its willingness to engage in heady conversations make it the most useful overall. I also like how Claude is more willing to engage and ask the user questions.\nPros\n- Gives meaningful answers with a good amount of context\n- Does most things well, including research, email writing and recommendations\nCons\n- Could tap more into historical context for explanations\n- Can be slow at times\n- Asking for sources can be tedious\nA close contender for the top spot is OpenAI's ChatGPT-4o, which is now available for free, albeit with caveats. OpenAI says that while free users will have access to its ChatGPT-4o model, when usage limits are reached based on demand free users will revert back to the older 3.5 model. While free users are able to ask ChatGPT-4o up to 40 messages every three hours, that number might be reduced due to high demand.\nChatGPT Free offers detailed and nuanced answers, but they weren't quite as high-quality as Claude. Putting the two side-by-side, I noticed slight differences in the quality of answers. I particularly liked the specificity that Claude delved into when asking heavier political questions, such as the morality of the Israel-Palestine conflict. And like Claude, ChatGPT doesn't link to outside sources. Sometimes when you ask it to provide sources, it'll suggest things to Google or YouTube.\nPros\n- Includes list of all sources used\n- Gives nuanced answers in an easy-to-follow list\nCons\n- Too much reliance on Reddit posts and forums, which aren't citable for most people\nPerplexity did the best job for research in my testing. The team at Perplexity has tuned its AI chatbot to add loads of links into answers. Hyperlinks can include journalistic publications, Reddit posts and even YouTube videos.\nWhen writing essays or articles, links to actual sources are critical. Perplexity actually lists each source in a handy sidebar that can be easily accessed. And, thankfully, the sources aren't simply Wikipedia, which won't fly with your college professor. The only downside is that Perplexity does rely on forum posts and Reddit for its answers, which aren't journalistic or scholarly. I'm sure the information is handy, but that will mean doing more research on your part to ensure those factoids are accurate and can be sourced to something more attributable.\nPros\n- Gives solid shopping recommendations and product research\n- Links to Amazon products directly\n- Connected to open internet with option to double-check against Google Search\nCons\n- Can make stuff up\n- Doesn't answer questions on difficult subject matters\nGoogle's AI engine has been prone to hallucinations -- simply making up stuff -- such as when Google's AI overviews feature was rolled back last month when it suggested people eat rocks. When I reviewed Gemini earlier this year, it was the lowest-rated AI chatbot out of the bunch, with a dismal 5/10 score.\nBut AI chatbots aren't stationary pieces of technology that exist in a vacuum. Gemini has improved since I reviewed it back in April, although it still hallucinates. In my recent testing, for example, Gemini made up the name of a college professor and the name of an Adult Swim executive. And it simply refuses to answer heavier political questions, as does Microsoft's Copilot.\nBut the one area in which Gemini did excel was in how-to guides and shopping recommendations. When I asked how to cut a perfect circle in a piece of vinyl, not only did Gemini give a list of instructions, it also linked to products on Amazon that could make the process easier. None of the other chatbots linked to Amazon products. When it came to shopping recommendations, Gemini gave quick and concise answers with links to where to buy products.\nHow we tested AI chatbots\nTesting for AI requires constant tweaking. Because companies are always looking at ways to improve their AI models, tests that worked to push AI chatbots last year or even last month might not work today. That said, we try to test AI chatbots with questions we believe normal people will ask. We aren't necessarily trying to \"break\" AI chatbots with obtuse-sounding questions meant to confuse. Instead, we consider what might be asked when it comes to video game guides or shopping recommendations. Our tests also ask some heavier questions about difficult events happening around the world to see which are comfortable in actually engaging.\nThe AI chatbots that sit on this list, generally, are able to take on the tougher questions and give believable answers with nuance. Like reading an article written by a university professor, we want AI chatbots to have that same level of consideration for historical context and competing interests to try and leave the reader with a better understanding from a higher-level perspective.\nFor more, check out How We Test AI.\nFactors to consider\nWhen using an AI chatbot, keep your privacy and sensitive information in mind. For example, it might seem benign to have an AI chatbot summarize your company's meeting notes. But, that data could inadvertently be used to train AI models further, and you've essentially lost control of it, according to experts. Plus, it's totally within the realm of the privacy policies for AI companies to sell that data to third parties. While Google's privacy policy might state that it'll remove any personally identifiable information, it's still best to err on the side of caution. Google actually outright recommends you don't upload any confidential information whatsoever.\nOther AI chatbots we tested\nMicrosoft Copilot: This chatbot, found on the Bing search engine, uses GPT-4 Turbo, a version of OpenAI's GPT-4 that is optimized for speed. While Copilot is still a serviceable chatbot, it doesn't answer questions with the same level of detail and nuance as Claude, ChatGPT-4o and Perplexity. Plus, its outright refusal to answer questions that are politically sensitive in nature is a demerit.\nMeta AI: Unlike other AI chatbots, Meta AI not only has its own dedicated webpage, but is integrated into Instagram, WhatsApp, Facebook and the Ray-Ban Meta smart glasses. When CNET's Katelyn Chedraoui reviewed Meta AI earlier this year, she found it to be decent overall, but noncompetitive with the competition. While Meta AI did provide good shopping advice with some cajoling, and excelled in recipes, it fell short in other areas. When it came to research, despite it being connected to Google and Bing, it sourced nonscholarly papers, like an elementary school lesson plan.\nChatGPT 3.5: This service, which I tested earlier in 2024, has since been replaced by what OpenAI calls ChatGPT Free (which utilizes a combination of GPT-4o, GPT-4 and GPT-3.5). It is a competent AI chat engine that answers difficult questions with easy-to-understand language. It doesn't hallucinate at the rate of Google Gemini, but there really isn't a reason to switch ChatGPT to 3.5 when you can use 4o and 4 for free.\nAI chatbot FAQs\nDo I need to use AI?\nAI is a handy tool and can be a timesaver, but it isn't necessary in day-to-day life. It's totally possible to still Google Search your queries and read through articles to get the answer you're looking for. Heck, it probably gives your brain more of a mental workout!\nWhat is the best free AI?\nAnthropic Claude is currently CNET's choice for the best free AI chatbot. Free versions of ChatGPT and Perplexity also offer great results with specific advantages and disadvantages. Google's Gemini is great for shopping recommendations. Like Gemini, Microsoft's CoPilot won't answer heavier and more controversial questions.\nWhat is the best AI on mobile?\nWhile there are mobile apps for Gemini, Copilot and Perplexity, we prefer the ChatGPT app the most. It has a clean interface and is easy to navigate. But really, any app will get the job done. Unfortunately, Claude only has a mobile app for iOS and not Android.\nCan AI be trusted?\nGeoffrey Hinton, the researcher who developed the concept of neural networks and who is considered the godfather of AI, feels less enthusiastic about the technology he helped birth. As for using AI chatbots on a day-to-day basis, they're handy tools that can synthesize the world's information for you in seconds, saving you lots of research time. Just be aware that sometimes AI chatbots get things wrong and it's good to do a Google search for things that sound a bit dubious. Also, be careful when giving AI chatbots sensitive information. Don't ask an AI chatbot to summarize your company's trade secrets, as privacy policies give AI companies wide latitude to do with that data as they please."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/chatgpt-plus-review/",
      "text": "Pros\n- Very accurate\n- Powerful reasoning models that are great for research\n- Voice mode for long chats\n- Long-term memory\n- Robust image generation\n- Document and image analysis\n- Custom GPT creation\n- Suite of tools for more niche tasks\nCons\n- Can still hallucinate\nChatGPT has completely changed how I do my job. Over the past year, OpenAI, the creator of ChatGPT, has rolled out a slew of updates to make the AI chatbot smarter, more accurate and useful. As a journalist at CNET, I would never use ChatGPT itself to write for me. But when it comes to research, I keep going back to ChatGPT to help me find sources and other bits of information that would have taken hours of Google searching or scrubbing through papers on Google Scholar.\nAnd after using GPT-4.5 Research Preview, which is essentially a beta version for the upcoming GPT-4.5 model, I'm excited for it to go fully live. While the launch was a bit lackluster, with fans on Reddit complaining that it wasn't too dissimilar from 4o, it seems that OpenAI has made improvements. In my use, I found its ability to scrub the web for quotes -- for example from Google executives that were over a decade old -- a major timesaver, closer in performance to o1 and o3, OpenIA's \"reasoning\" models. It shows why OpenAI is charging $20/month for this service.\n(Disclosure: Ziff Davis, CNET's parent company, in April filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nWhat does $20 a month get you?\nA ChatGPT Plus subscription is more than access to a powerful AI chatbot with higher rate limits. Paying for ChatGPT Plus means you'll run into fewer interruptions when traffic is high and gain access to advanced models like 4o and reasoning models such as o1 and o3. There's also voice chat with memory, meaning you can create an AI bot to converse with and it'll remember your past conversations. Image generation has higher rate limits, so you can generate multiple pictures without hitting a wall. There's also limited use of the Deep Research function, which is intended for fields like finance, science, policy and engineering.\nA Plus subscription lets you create custom GPTs, which are more bespoke AI bots that can act as subject-matter experts on specific tasks or topics. Of course, if you don't want to create your own GPT, you can explore a wide selection made by the community -- all accessible even to free users.\nIf you find yourself becoming more frustrated by Google Search, prefer the convenience of having answers easily delivered to you or are constantly hitting rate limits, a ChatGPT Plus subscription is probably worth your investment. You won't easily hit rate limits and can use ChatGPT's feature set to its fullest. Plus, the benefit of having priority access and increased image generation is a major advantage.\nHow CNET reviews AI models\nLast year, when I did my marathon of AI reviews for the launch of CNET's AI Atlas, I treated the AI's like any other tech product we review: using rigid tests and comparing the results. In the same way AI benchmarking sites don't paint a full picture, a topic of ongoing debate, I decided to go with a more experiential style for 2025. Instead of asking AI models the exact same questions and comparing results, I'm just going to report my experiences of living with them, day to day.\nPrivacy: Don't upload stuff you wouldn't want OpenAI to see\nJust because you're paying for a ChatGPT Plus subscription doesn't mean your information will be kept private. As with any online AI chatbot, any data uploaded can be used.\nThat's why you shouldn't upload sensitive information into ChatGPT or any other AI chatbot. That means no tax documents, medical records, credit card numbers, login credentials, business data, client information, trade secrets or any other identifiable documentation. More information can be found at OpenAI's privacy policy page.\nIf you're extra concerned about what data OpenAI might use, it's possible to opt-out of model training. To do so, go into ChatGPT settings, click on Data Controls and disable \"improve model for everyone.\"\nIt's also possible to use ChatGPT in an incognito-like mode via the Temporary Chats function. To activate this mode, go to the top-right corner of a new chat and click on a dotted-line chat icon. In this mode, your chat data won't be stored or used for training purposes. It's also possible to delete chat history, which, after 30 days, will be taken off of OpenAI's servers.\nBut OpenAI will still gather some of your data. This includes your name, date of birth or other details you shared when opening your account. OpenAI will also know your IP address, web browser and other device information.\nChatGPT Plus is my Google Search companion: Accurate enough, but still needs some fine-tuning\nFor a good portion of my online search queries, I still default to Google. It's when I'm feeling that Google won't deliver me the fastest possible answer that I then pull up ChatGPT. So, for example, if I'm looking up the latest news on newspaper closures, that's a quick Google Search. If, instead, I'm trying to ascertain how many publications have closed in the United States since Google jumped on the scene in 1998, that's a ChatGPT question. These are questions that are often more complex than basic keywords and require parsing through multiple data points across decades.\nSince I'm jumping away from Google and its less-than-accurate AI Overviews, I expect to get good answers from ChatGPT. In my experience, I've found ChatGPT to be very accurate for my purposes, which is gathering and synthesizing information. But if you're a student, it's better to use ChatGPT as a resource and write your own essays with your own words. Because your professor will find out otherwise.\nChatGPT Plus, running on GPT-4.5 Research Preview, did a good job of compiling sources and putting together a report on Google's impact on publishers. However, it also linked to a dead AP article. Despite how quickly ChatGPT has been improving, it's still on users to go through and verify the evidence.\nDespite that flub, the information ChatGPT compiled was correct, although I'm not a fan of how often it cites Wikipedia. As handy as Wikipedia is, you'd be met with scorn by most college professors for listing a volunteer online encyclopedia in your bibliography.\nOddly, when I asked follow-up questions to my initial query, ChatGPT didn't list any sources.. In these instances, I had to switch back to Google to find relevant articles. At the very least, the information ChatGPT pulled up was correct.\nReasoning models are a game-changer for research\nOn the research side, the biggest benefit ChatGPT Plus delivers over the free version is access to the advanced o1 and o3 reasoning models. These models spend more time generating text, going back and recursively checking content to make sure information is accurate. These responses can take more than a minute to generate and are better suited for research rather than quick search queries.\nUsing o3, I was able to pull together an in-depth timeline and generate a conclusion breaking down the relationship between online publishers and Google in the late 1990s, which led to the free online news model that dominates today. Any follow-up questions I had did take a minute to answer but the content was well worth the wait. ChatGPT's o3 model explained the Robots Exclusion Protocol, the tools Google released to help it index sites and the concept of First Click Free.\nI knew most of this information already, but o3 did a fantastic job unearthing all this complex information and history, including major milestone moments. It also included sources.\nFor journalists, students and researchers, having access to o1 and o3 feels almost necessary. Given Google's current search paradigm that often elevates recency over relevancy, o1 and o3 can pull from deep within the internet, making research a less exhaustive chore. But it's important to read primary sources to gain a fuller understanding.\nChatGPT Plus image generation is great\nI don't use ChatGPT too often for image generation as I often don't have a need for it as a writer. But I do play around with it on occasion, trying to mimic images from other \"AI artists\" I see on Instagram. Often, these AI illustrators will hide the prompts they use so that only their page can feature their specific style. Of course, this mindset is anathema to actual art, which is about sharing techniques and helping others so that the medium itself can evolve, but I digress.\nSince I'm not a master in image prompt generation, I took a prompt that was openly available on the platform CivitAI to see how ChatGPT would fare. Above is the image that was generated by user Frimm0 on CivitAI.\nHere's what ChatGPT created when I gave it the same prompt.\nRecreation from ChatGPT with the same prompt: a cute adorable anthropomorphic eyeball monster dressed like a parrot, round body, plump kiwi shape, fluffy fur, forest, sunlight, soft natural light. cute, big-eye, adorable, brightly colored, cheerful, anime influence, naughty face, laughing, happy, playful, cheerful, bright, vibrant, light-hearted, characters, digital, fantasy, illustration, manga-anime, portraits, whimsy, 3d-rendering, concept-art, digital, dreaminess, eeriness, photorealism, other-worldliness, realism, science-fiction, surreal, colorful\nThe major advantage to having a ChatGPT Plus subscription is being able to avoid rate limits. On the free version of ChatGPT, you might end up waiting for more than an hour to generate a single image when servers are being overloaded. And that one generated image might max out your token limit, forcing you to wait hours before you can generate another.\nIn my experience, ChatGPT Plus took no more than two minutes to output an image. Not only that, a ChatGPT Plus subscription gets you access to Sora, OpenAI's other tool for image and video creation. While free users do have limited Sora access, it's best to use it with a Plus subscription.\nChatGPT Plus has better memory\nOne advantage that ChatGPT Plus has over its free counterpart is memory retention. This means that when you're using ChatGPT, it can recall past conversations as it learns more about you to better tune answers. This is especially useful in ChatGPT's voice mode, where you can converse with it like you would an actual person. On the free version, voice mode is in a limited trial and has no memory retention. OpenAI did bring some light memory retention features to free users in June, however.\nFor example, I'm currently building a PC at the CNET offices capable of running local AI models. I was able to pull up a separate chat in ChatGPT and ask it questions about changes to the CPU and if the current power supply would suffice. It's handy in the sense that I didn't need to go back to a previous chat window and could continue the conversation wherever.\nFor people turning to AI for more meaningful conversations, including therapy, memory retention is critical. OpenAI expanded memory earlier this year, but users who rely on ChatGPT for their emotional needs on a daily basis can still encounter the issue of memory running out. For people who've developed deeper emotional connections to their AI chatbots, memory resets can be difficult and frustrating.\nIf you need ChatGPT to be an emotional support or even a friend, know that eventually it'll reset and will need to be re-prompted with everything you want it to know. A ChatGPT Plus subscription can help you avoid that.\nShopping\nEarlier this year, OpenAI expanded ChatGPT's shopping capabilities, even bringing those features to free users. I've found ChatGPT to be an invaluable tool when comparison shopping. When I'm comparing different products, having to read through reviews, Reddit posts and other sites can be a lot of information to juggle.\nUnrelated to the AI models-capable computer I mentioned earlier, I've recently been looking to upgrade my at-home gaming rig, which I built in 2021. I put all my specs into ChatGPT and it gave me recommendations on which components I should upgrade. All the components ChatGPT recommended were sound, in my research.\nChatGPT suggested I pop out the AMD Ryzen 5 5600X CPU and replace it with the Ryzen 7 5800X3D. Unfortunately, this CPU is out of production and can only be found as either new old stock or used. I asked ChatGPT where I could buy one and this is where things sort of fell apart.\nIt directed me towards Newegg, saying it was on sale for $199. The link was dead and it certainly isn't on sale for that price. It also recommended two sites I hadn't heard of, both of which were selling the CPU for over $500. Both links did work, however.\nAs for alternatives, ChatGPT recommended the slightly weaker 5700X3D, saying that the drop would be negligible for most games. Bizarrely, ChatGPT once again gave buying links for the 5800X3D, saying it was available at Newegg for $199. I did some digging.\nWhat ChatGPT was actually linking to here was the AMD Ryzen 7 5800X CPU, which isn't the same -- at all. I'm not sure why ChatGPT was making this mistake but I can see someone who isn't careful missing the \"3D\" distinction and accidentally buying it, thinking it was what they were looking for.\nOverall, ChatGPT is still an incredibly powerful shopping tool. Just note that OpenAI needs to fix errors in linking to correct products.\nDocument analysis\nEarlier this year, when judgement came down on the Google antitrust case, the court document itself was 115 pages long. Scrubbing through large troves of legalese is the perfect use for AI.\nUnlike ChatGPT Free, which didn't initially read the analysis and instead summarized a different case altogether, ChatGPT Plus did what I asked. It effectively combed through the filing and pulled out most of the important bits and put them into bullet points.\nIn my reading, I couldn't find any errors or hallucinations. Follow-up questions about the trial itself were well summarized and easy to understand. I have no complaints.\nIs ChatGPT Plus worth it?\nWhat OpenAI delivers for $20 per month is an incredible value to people who rely on AI frequently. For students, journalists and researchers, it automates the chores of parsing through troves of information in seconds, helping you get to the answers you need, faster. In a world that's increasingly turning to short-form video and other quick bits of content, ChatGPT essentially does that with any bit of information or human-created content ever published online.\nOf course, reading a summary of something will never deliver the same cognitive value as reading an entire article or book, but that's a different discussion.\nAnd this is just the surface level of what ChatGPT can do. Beyond just generating text, it can also analyze photos and other documents to be a powerful assistant in your pocket. For example, I was trying on jeans the other week and took a mirror selfie in the changing room and asked ChatGPT what it thought of the look. It directed me towards another pair at a smaller size that better matched my frame. Before, this would require me to either grab an attendant or drag a fashion-forward friend with me.\nThere's also a massive library of custom GPTs to explore, a whole studio to build your own AI bots and coding assistants, all of which weren't touched on in this review.\nIf you find yourself hitting rate limits on the free version of ChatGPT, it's time to upgrade. ChatGPT Plus' more advanced models, including its slower but more verbose \"reasoning\" models, makes keyword searching in Google a quickly antiquated chore."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/chatgpt-gets-new-o1-model-first-to-have-reasoning-for-hard-problems/",
      "text": "ChatGPT has a new model named o1 that's trained to solve harder problems, analyze its answers, try different strategies and refine its thinking, OpenAI said in a blog post on Thursday.\nThe new model, currently split between o1-preview and o1-mini, ranks in the 89th percentile in Codeforces' competitive programming contests, places among the top 500 students in the US for the Math Olympiad and \"exceeds Ph.D.-level accuracy on a benchmark of physics, biology and chemistry problems,\" according to OpenAI.\n\"We have noticed that this model hallucinates less,\" says Jerry Tworek, OpenAI's research lead in an interview with The Verge. It's been trained on a new optimization algorithm with a tailor-made training dataset. While past models aimed to mimic patterns in their training data, o1 uses reinforcement learning, which teaches it through rewards and penalties.\nThe thing that differentiates o1 from past models is its ability to \"think,\" according to a report from The Information on Tuesday. This means the model doesn't immediately begin spitting out responses and can take from 10 to 20 seconds to put together an answer. The o1 model, which has also been referred to as \"Strawberry\" by onlookers (a possible reference to the viral trend of influencers asking AIs to answer how many \"Rs\" are in the word \"strawberry\"), removes the need for \"chain-of-thought prompting,\" where you have to ask extra questions of an AI to see its intermediate reasoning. Instead, the model is designed to show its reasoning by default.\nBecause o1 is still in its preview stage, there are some major limitations. Unlike GPT-4o, o1 isn't connected to the web, can't be used with file uploads and has a multitude of API limitations for developers. The o1-mini model differs in that it focuses on delivering fast answers to STEM-related questions.\nCompetition in the AI space is increasingly fierce as every player in the big tech space attempts to create \"agentive\" AIs that can complete tasks for you. Earlier this year at Google I/O, the search giant unveiled a more powerful version of Gemini that can more naturally converse with you, even allowing you to interrupt it mid-sentence. And at the iPhone 16 launch event earlier this week, Apple bumped up the processing power of its latest handsets to be able to handle Apple Intelligence, a suite of AI features for iPhones backed with OpenAI tech.\nWhile AI hype has been driving tech stocks to record numbers in the last two years, it seems that investors might be growing more cautious. Nvidia, the chip maker that's creating the brains powering many of the world's top AI data centers, saw a 10% drop last week. The tech world broadly could be cooling on AI as it waits for more concrete results from services, although that hasn't stopped OpenAI from reaching a staggering $150 billion valuation.\nFor ChatGPT Plus and Team users, the o1-preview model is rolling out now. ChatGPT Enterprise and Edu users will gain access next week. Developers can also use the API for prototyping."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/gpt-5-openais-dropping-hints-about-chatgpts-new-ai-model-how-to-watch-the-livestream/",
      "text": "Close followers of OpenAI's model releases are probably tired of hearing about GPT-5, the next big step in the company's line of flagship large language models. It's been expected seemingly all year. But the hints are getting very strong.\nAlready this week, the ChatGPT-maker has unveiled its open-weights models -- gpt-oss -- that have also been teased for months. These models, unlike the GPT models and other popular LLMs like Google's Gemini, offer transparency into how they work and think. Just before that release, however, CEO Sam Altman hinted that something bigger was coming too: \"something big-but-small today,\" he posted on X, \"and then a big upgrade later this week.\"\nWednesday night, the hints grew even stronger. OpenAI posted on X: \"LIVE5TREAM THURSDAY 10AM PT.\" Yes, the \"S\" is a 5. Altman posted that the livestream will be \"longer than usual.\" And Thursday morning, OpenAI started to turn the number ahead.\nOpenAI's livestreams of product announcements tend to show up on its website shortly beforehand, and it'll most certainly share the link on X ahead of time.\n(Disclosure: Ziff Davis, CNET's parent company, in April filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nThe work on GPT-5 hasn't been a secret, and the hype has been intense. In a July interview with the podcaster Theo Von, Altman said he was testing the new model and asked it to interpret and write an email he had trouble understanding. \"I felt useless relative to the AI in this thing that I felt like I should've been able to do and I couldn't,\" Altman said. (It must have been a very impressive email.)\nIt's been a long time coming. GPT-4, current generation of the complex program behind ChatGPT and many other tools, came out in March 2023, an eternity ago in the world of large language models. There have been a lot of iterations since: GPT-4.5 rolled out in February of this year. Reasoning models have also emerged in the gap, including o3 and o4 families.\nGPT-5 was originally expected to happen in the early part of the year, but Altman said in April that it would be delayed a few more months. Developers found it harder than expected to integrate all of the elements they wanted, and Altman said they also wanted to be sure they had the capacity to support \"what we expect to be unprecedented demand.\"\nRead more: ChatGPT Will Start Asking If You Need a Break. That May Not Be Enough to Snap a Bad Habit\nOn Sunday, he doubled down on the capacity worries, posting on X that \"although it may be slightly choppy, we think you'll really love what we've created for you!\"\nOpenAI's rivals haven't been sitting around twiddling their thumbs. Google's Gemini 2.5 models, released in March, incorporate reasoning while also being able to handle huge prompts. Anthropic's Claude 4 models, which debuted in May, include one designed specifically for coding and complicated tasks. But it's ChatGPT that fronts the pack as the most popular default tool for users, and a new version could extend that lead.\nIt also might not be perfect. OpenAI had to pull an update to its GPT-4o model earlier this year because it was way too nice -- like, codependent nice, like it might not push back even if you're asking about something harmful to yourself or others."
    },
    {
      "url": "https://www.cnet.com/tech/services-and-software/never-use-chatgpt-for-these-11-things/",
      "text": "There are a lot of things you can do with ChatGPT, and it seems like that list is getting longer everyday. The powerful LLM chatbot can help you create a budget, plan your meals for the week, reach your health goals and make writing or coding easier.\nBut you don't want to give ChatGPT carte blanche in your life. It's not great at everything -- in fact, it can be downright sketchy at a lot of things.\nChatGPT sometimes hallucinates information and passes it off as fact, and it may not always have up-to-date information. It's incredibly confident, even when it's straight up wrong. (The same can be said about other generative AI tools, too, of course.)\nThat matters the higher the stakes get, like when taxes, medical bills, court dates or bank balances enter the chat. If you're unsure about when turning to ChatGPT might be risky, here are 11 scenarios when you should put down the AI and choose another option. Don't use ChatGPT for any of the following.\n(Disclosure: Ziff Davis, the parent company of CNET, in April filed a lawsuit against ChatGPT maker OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\n1. Diagnosing physical health issues\nI've definitely fed ChatGPT my symptoms out of curiosity, but the answers that come back can read like your worst nightmare. As you pore over potential diagnoses, you could swing from dehydration and the flu to some type of cancer. I have a lump on my chest and entered that information into ChatGPT. Lo and behold, it told me I may have cancer. In fact, I have a lipoma, which is not cancerous and occurs in 1 in every 1,000 people. My licensed doctor told me that.\nI'm not saying there are no good uses of ChatGPT for health: It can help you draft questions for your next appointment, translate medical jargon and organize a symptom timeline so you can walk in better prepared. And that could help make doctor visits less overwhelming. However, AI can't order labs or examine you, and it definitely doesn't carry malpractice insurance. Know its limits.\n2. Taking care of your mental health\nChatGPT can offer grounding techniques, sure, but it can't pick up the phone when you're in real trouble with your mental health. I know some people use ChatGPT as a substitute therapist. CNET's Corin Cesaric found it mildly helpful for working through grief, as long as she kept its limits front of mind. But as someone who has a very real, very human therapist, I can tell you that ChatGPT is still really only a pale imitation at best, and incredibly risky at worst.\nChatpGPT doesn't have lived experience, can't read your body language or tone, and has zero capacity for genuine empathy. It can only simulate it. A licensed therapist operates under legal mandates and professional codes that protect you from harm. ChatGPT doesn't. Its advice can misfire, overlook red flags or unintentionally reinforce biases baked into its training data. Leave the deeper work -- the hard, messy, human work -- to an actual human who is trained to properly handle it. If you or someone you love is in crisis, please dial 988 in the US, or your local hotline.\n3. Making immediate safety decisions\nIf your carbon-monoxide alarm starts chirping, please don't open ChatGPT and ask it if you're in real danger. I'd go outside first and ask questions later. Large language models can't smell gas, detect smoke or dispatch an emergency crew. In a crisis, every second you spend typing is a second you're not evacuating or dialing 911. ChatGPT can only work with the scraps of info you feed it, and in an emergency, it may be too little and too late. So treat your chatbot as a postincident explainer, never a first responder.\n4. Getting personalized financial or tax planning\nChatGPT can explain what an ETF is, but it doesn't know your debt-to-income ratio, state tax bracket, filing status, deductions, retirement goals or risk appetite. Because its training data may stop short of the current tax year, and of the latest rate hikes, its guidance may well be stale when you hit enter.\nI have friends who dump their 1099 totals into ChatGPT for a DIY return. The chatbot simply can't replace a CPA who can catch a hidden deduction worth a few hundred dollars or flag a mistake that could cost you thousands. When real money, filing deadlines, and IRS penalties are on the line, call a professional, not AI. Also, be aware that anything you share with an AI chatbot will probably become part of its training data, and that includes your income, your Social Security number and your bank routing information.\n5. Dealing with confidential or regulated data\nAs a tech journalist, I see embargoes land in my inbox every day, but I've never thought about tossing any of these press releases into ChatGPT to get a summary or further explanation. That's because if I did, that text would leave my control and land on a third-party server outside the guardrails of my nondiscloure agreement.\nThe same risk applies to client contracts, medical charts or anything covered by the California Consumer Privacy Act, HIPAA, the GDPR or plain old trade-secret law. It applies to your income taxes, birth certificate, driver's license and passport. Once sensitive information is in the prompt window, you can't guarantee where it's stored, who can review it internally or whether it may be used to train future models. ChatGPT also isn't immune to hackers and security threats. If you wouldn't paste it into a public Slack channel, don't paste it into ChatGPT.\n6. Doing anything illegal\nThis one is self-explanatory.\n7. Cheating on schoolwork\nI'd be lying if I said I never cheated on my exams. In high school, I used my first-generation iPod Touch to sneak a peek at a few cumbersome equations I had difficulty memorizing in AP calculus, a stunt I'm not particularly proud of. But with AI, the scale of modern cheating makes that look remarkably tame.\nTurnitin and similar detectors are getting better at spotting AI-generated prose every semester, and professors can already hear \"ChatGPT voice\" a mile away (thanks for ruining my beloved em dash). Suspension, expulsion and getting your license revoked are real risks. It's best to use ChatGPT as a study buddy, not a ghostwriter. You're also just cheating yourself out of an education if you have ChatGPT do the work for you.\n8. Monitoring information and breaking news\nSince OpenAI rolled out ChatGPT Search in late 2024 (and opened it to everyone in February 2025), the chatbot can fetch fresh web pages, stock quotes, gas prices, sports scores and other real-time numbers the moment you ask, complete with clickable citations so you can verify the source. However, it won't stream continual updates on its own. Every refresh needs a new prompt, so when speed is critical, live data feeds, official press releases, news sites, push alerts and streaming coverage are still your best bet.\n9. Gambling\nI've actually had luck with ChatGPT and hitting a three-way parlay during the NCAA men's basketball championship, but I would never recommend it to anyone. I've seen ChatGPT hallucinate and provide incorrect information on player statistics, misreported injuries and win-loss records. I only cashed out because I double-checked every claim against real-time odds, and even then I got lucky. ChatGPT can't see tomorrow's box score, so don't rely on it solely to get you that win.\n10. Drafting a will or other legally binding contract\nChatGPT is great for breaking down basic concepts. If you want to know more about a revocable living trust, ask away. However, the moment you ask it to draft actual legal text, you're rolling the dice. Estate and family-law rules vary by state, and sometimes even by county, so skipping a witness signature or omitting the notarization clause can get your whole document tossed. Rather, let ChatGPT help you build a checklist of questions for your lawyer, then pay that lawyer to turn that checklist into a document that stands up in court.\n11. Making art\nThis isn't an objective truth, just my own opinion, but I don't believe AI should be used to create art. I'm not anti-artifical intelligence by any means. I use ChatGPT for brainstorming new ideas and help with my headlines, but that's supplementation, not substitution. By all means, use ChatGPT, but please don't use it to make art that you then pass off as your own. It's kind of gross."
    }
  ],
  "argos_summary": "OpenAI has launched GPT-5, a significant upgrade from GPT-4, promising faster speeds and improved reasoning capabilities. However, some users have criticized the model for its more corporate tone, leading OpenAI to reintroduce older models like GPT-4o. GPT-5 is available to all users, with different access levels based on subscription plans, and includes features like improved coding abilities and voice interaction. Despite advancements, experts caution against relying on AI for sensitive tasks, emphasizing the importance of human oversight in areas like mental health and legal matters.",
  "argos_id": "5WZ9GWWVA"
}