{
  "url": "https://www.cnet.com/tech/computing/best-laptop/#ftag=CADf328eec",
  "authorsByline": "Matt Elliott",
  "articleId": "a16ad19f259840e3a2f37477795e2dd2",
  "source": {
    "domain": "cnet.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "San Francisco",
      "city": "San Francisco",
      "coordinates": {
        "lat": 37.7790262,
        "lon": -122.419906
      }
    }
  },
  "imageUrl": "https://www.cnet.com/a/img/resize/4cbcc138b39397c25245454c669ceccc7ed7b5f1/hub/2025/03/10/d190e21d-9634-440d-8f33-396c8cb3da6a/m4-macbook-air-15-11.jpg?auto=webp&fit=crop&height=614&width=1092",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-14T19:30:00+00:00",
  "addDate": "2025-08-14T20:09:56.105582+00:00",
  "refreshDate": "2025-08-14T20:09:56.105584+00:00",
  "score": 1.0,
  "title": "Best Laptops We've Tested (August 2025)",
  "description": "These are the best laptops that my colleagues and I have gotten our hands on in the past year, spanning all types, sizes and prices.",
  "content": "There are a ton of laptops on the market at any given moment and almost all of those models are available in multiple configurations to match your performance and budget needs. If you're feeling overwhelmed with options when looking for a new laptop, it's understandable. To help simplify things for you, here are the main things you should consider when you start looking.\n\nThe search for a new laptop for most people starts with price. If the statistics that chipmaker Intel and PC manufacturers hurl at us are correct, you'll be holding onto your next laptop for at least three years. If you can afford to stretch your budget a little to get better specs, do it. That stands whether you're spending $500 or more than $1,000. In the past, you could get away with spending less upfront with an eye toward upgrading memory and storage in the future. Laptop makers are increasingly moving away from making components easily upgradable, so again, it's best to get as much laptop as you can afford from the start.\n\nGenerally speaking, the more you spend, the better the laptop. That could mean better components for faster performance, a nicer display, sturdier build quality, a smaller or lighter design from higher-end materials or even a more comfortable keyboard. All of these things add to the cost of a laptop. I'd love to say $500 will get you a powerful gaming laptop, for example, but that's not the case. Right now, the sweet spot for a reliable laptop that can handle average work, home office or school tasks is between $700 and $800 and a reasonable model for creative work or gaming is upward of about $1,000. The key is to look for discounts on models in all price ranges so you can get more laptop capabilities for less.\n\nChoosing an operating system is part personal preference and part budget. For the most part, Microsoft Windows and Apple's MacOS do the same things (except for gaming, where Windows is the winner), but they do them differently. Unless there's an OS-specific application you need, go with the one you feel most comfortable using. If you're not sure which that is, head to an Apple store or a local electronics store and test them out. Or ask friends or family to let you test theirs for a bit. If you have an iPhone or iPad and like it, chances are you'll like MacOS, too.\n\nIn price and variety (and PC gaming), Windows laptops win. If you want MacOS, you're getting a MacBook. Apple's MacBooks regularly top our best lists, the least expensive one is the M1 MacBook Air for $999. It is regularly discounted to $750 or $800, but if you want a cheaper MacBook, you'll have to consider older refurbished ones.\n\nWindows laptops can be found for as little as a couple of hundred dollars and come in all manner of sizes and designs. Granted, we'd be hard-pressed to find a $200 laptop we'd give a full-throated recommendation to but if you need a laptop for online shopping, email and word processing, they exist.\n\nIf you are on a tight budget, consider a Chromebook. ChromeOS is a different experience than Windows; make sure the applications you need have a Chrome, Android or Linux app before making the leap. If you spend most of your time roaming the web, writing, streaming video or using cloud-gaming services, they're a good fit.\n\nRemember to consider whether having a lighter, thinner laptop or a touchscreen laptop with a good battery life will be important to you in the future. Size is primarily determined by the screen -- hello, laws of physics -- which in turn factors into battery size, laptop thickness, weight and price. Keep in mind other physics-related characteristics, such as an ultrathin laptop isn't necessarily lighter than a thick one, you can't expect a wide array of connections on a small or ultrathin model and so on.\n\nWhen deciding on a screen, there are a myriad number of considerations: How much you need to display (which is surprisingly more about resolution than screen size), what types of content you'll be looking at and whether you'll be using it for gaming or creative work.\n\nYou really want to optimize pixel density; that is, the number of pixels per inch the screen can display. Although other factors contribute to sharpness, a higher pixel density usually means a sharper rendering of text and interface elements. (You can easily calculate the pixel density of any screen at DPI Calculator if you don't feel like doing the math, and you can also find out what math you need to do there.) I recommend a dot pitch of at least 100 pixels per inch as a rule of thumb.\n\nBecause of the way Windows and MacOS scale for the display, you're frequently better off with a higher resolution than you'd think. You can always make things bigger on a high-resolution screen, but you can never make them smaller -- to fit more content in the view -- on a low-resolution screen. This is why a 4K, 14-inch screen may sound like unnecessary overkill but may not be if you need to, say, view a wide spreadsheet.\n\nIf you need a laptop with relatively accurate color that displays the most colors possible or that supports HDR, you can't simply trust the specs -- not because manufacturers lie, but because they usually fail to provide the necessary context to understand what the specs they quote mean. You can find a ton of detail about considerations for different types of screen uses in our monitor buying guides for general purpose monitors, creators, gamers and HDR viewing.\n\nThe processor, aka the CPU, is the brains of a laptop. Intel and AMD are the main CPU makers for Windows laptops, with Qualcomm as a new third option with its Arm-based Snapdragon X processors. Both Intel and AMD offer a staggering selection of mobile processors. Making things trickier, both manufacturers have chips designed for different laptop styles, like power-saving chips for ultraportables or faster processors for gaming laptops. Their naming conventions will let you know what type is used. You can head to Intel's or AMD's sites for explanations so you get the performance you want. Generally speaking, the faster the processor speed and the more cores it has, the better the performance will be.\n\nApple makes its own chips for MacBooks, which makes things slightly more straightforward. Like Intel and AMD, you'll still want to pay attention to the naming conventions to know what kind of performance to expect. Apple uses its M-series chipsets in Macs. The entry-level MacBook Air uses an M1 chip with an eight-core CPU and seven-core GPU. The current models have M2-series silicon that starts with an eight-core CPU and 10-core GPU and goes up to the M2 Max with a 12-core CPU and a 38-core GPU. Again, generally speaking, the more cores it has, the better the performance.\n\nBattery life has less to do with the number of cores and more to do with CPU architecture, Arm versus x86. Apple\u2019s Arm-based MacBooks and the first Arm-based Copilot Plus PCs we\u2019ve tested offer better battery life than laptops based on x86 processors from Intel and AMD.\n\nThe graphics processor handles all the work of driving the screen and generating what gets displayed, as well as speeding up a lot of graphics-related (and increasingly, AI-related) operations. For Windows laptops, there are two types of GPUs: integrated (iGPU) or discrete (dGPU). As the names imply, an iGPU is part of the CPU package, while a dGPU is a separate chip with dedicated memory (VRAM) that it communicates with directly, making it faster than sharing memory with the CPU.\n\nBecause the iGPU splits space, memory and power with the CPU, it's constrained by the limits of those. It allows for smaller, lighter laptops, but doesn't perform nearly as well as a dGPU. There are some games and creative software that won't run unless they detect a dGPU or sufficient VRAM. Most productivity software, video streaming, web browsing and other nonspecialized apps will run fine on an iGPU.\n\nFor more power-hungry graphics needs, like video editing, gaming and streaming, design and so on, you'll need a dGPU; there are only two real companies that make them, Nvidia and AMD, with Intel offering some based on the Xe-branded (or the older UHD Graphics branding) iGPU technology in its CPUs.\n\nFor memory, I highly recommend 16GB of RAM (8GB absolute minimum). RAM is where the operating system stores all the data for currently running applications and it can fill up fast. After that, it starts swapping between RAM and SSD, which is slower. A lot of sub-$500 laptops have 4GB or 8GB, which in conjunction with a slower disk can make for a frustratingly slow Windows laptop experience. Also, many laptops now have the memory soldered onto the motherboard. Most manufacturers disclose this but if the RAM type is LPDDR, assume it's soldered and can't be upgraded.\n\nSome PC makers will solder memory on and also leave an empty internal slot for adding a stick of RAM. You may need to contact the laptop manufacturer or find the laptop's full specs online to confirm. Check the web for user experiences because the slot may still be hard to get to, it may require nonstandard or hard-to-get memory or other pitfalls.\n\nYou'll still find cheaper hard drives in budget laptops and larger hard drives in gaming laptops but faster solid-state drives have all but replaced hard drives in laptops. They can make a big difference in performance. Not all SSDs are equally speedy, and cheaper laptops typically have slower drives; if the laptop only has 4GB or 8GB of RAM, it may end up swapping to that drive and the system may slow down quickly while you're working.\n\nGet what you can afford and if you need to go with a smaller drive, you can always add an external drive or two down the road or use cloud storage to bolster a small internal drive. The one exception is gaming laptops: I don't recommend going with less than a 512GB SSD unless you really like uninstalling games every time you want to play a new game.",
  "medium": "Article",
  "links": [
    "https://www.sven.de/dpi/",
    "https://www.cnet.com/tech/computing/monitors-buying-guide/",
    "https://www.cnet.com/tech/computing/qualcomm-snapdragon-x-elite-and-x-plus-laptop-chips-explained/",
    "https://www.amd.com/en/processors/ryzen-processors-laptop",
    "https://www.cnet.com/tech/computing/microsoft-qualcomm-take-another-shot-at-pcs-with-copilot-plus/",
    "https://chrome.google.com/webstore/category/extensions",
    "https://www.intel.com/content/www/us/en/support/articles/000028083/processors.html",
    "https://www.cnet.com/tech/computing/how-to-buy-a-laptop-to-edit-photos-videos-or-other-creative-tasks/",
    "https://www.cnet.com/tech/computing/how-to-choose-an-hdr-gaming-monitor/"
  ],
  "labels": [
    {
      "name": "Paid News"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "gaming laptops",
      "weight": 0.09587358
    },
    {
      "name": "Windows laptops",
      "weight": 0.095419176
    },
    {
      "name": "Best Laptops",
      "weight": 0.09169108
    },
    {
      "name": "budget laptops",
      "weight": 0.090943396
    },
    {
      "name": "laptops",
      "weight": 0.09032493
    },
    {
      "name": "cheaper laptops",
      "weight": 0.08904918
    },
    {
      "name": "Laptop makers",
      "weight": 0.0890287
    },
    {
      "name": "more laptop capabilities",
      "weight": 0.088146046
    },
    {
      "name": "laptop thickness",
      "weight": 0.08687915
    },
    {
      "name": "many laptops",
      "weight": 0.08630346
    }
  ],
  "topics": [],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/Shopping/Consumer Resources/Product Reviews & Price Comparisons",
      "score": 0.94189453125
    }
  ],
  "sentiment": {
    "positive": 0.22543833,
    "negative": 0.2672412,
    "neutral": 0.50732046
  },
  "summary": "The article discusses the main factors for purchasing a new laptop, including price, performance, and operating system. The article suggests that the more you spend, the better the laptop, with components for faster performance, a nicer display, sturdier build quality, a smaller design from higher-end materials or a more comfortable keyboard added to the cost. The sweet spot for a reliable laptop is between $700 and $800, and a reasonable model for creative work or gaming is upwards of about $1,000. However, look for discounts on models in all price ranges to get more laptop capabilities for less. Microsoft Windows and Apple's MacOS do the same things, except for gaming, where Windows is the winner. In price and variety (and PC gaming), Windows laptops win. If you prefer MacOS, you're getting a MacBook. If on a tight budget, consider a Chromebook.",
  "shortSummary": "The search for a new laptop often ends in price, screen size, and operating system preferences, with consumers prioritizing Windows over Apple's MacOS.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "97f1b454a1754ae1aabf78f547c07b14",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.cnet.com/tech/computing/qualcomm-snapdragon-x-elite-and-x-plus-laptop-chips-explained/",
      "text": "Qualcomm is one of the biggest under-the-hood names in mobile devices, producing the popular Snapdragon chips that power many of the best Android phones on the market. But ever since it turned its attention to laptops several years ago, its Windows laptop CPUs have experienced some big performance and compatibility issues. The Qualcomm Snapdragon X Plus and Snapdragon X Elite chips announced in late 2023 and early 2024 look to right its course and raise the bar for notebook processing performance in speed, efficiency and AI acceleration.\nMicrosoft and Qualcomm recently announced the Windows Copilot Plus PC branding in conjunction with new laptops based on these chips, making it a good time to discuss the chips: what they offer, where to find them and what they'll mean for the latest batch of computers to run on them.\nWhat are the Snapdragon X Plus and X Elite chips?\nThe Snapdragon X Plus and X Elite are a family of systems-on-chip, combining much of the components a computer runs on into a single package. This is a common approach, as many Intel, AMD and Apple chips also feature graphics processors, memory controllers and more integrated into the same chip as the CPU. Lately, they've also featured neural processing units on the chip.\nWhat makes the Snapdragon chips different is that they use an ARM-based architecture rather than the x86 architecture that has been near universal in the personal computing space for decades until Apple introduced its own ARM-based M-series chips. One problem with previous ARM-based laptops has been many popular programs simply aren't designed for it, instead being coded for x86 architectures. The requires either different low-level code or a translation layer, like Apple's Rosetta, to run on ARM architectures.\nThis has posed problems in the past; some apps simply didn't work and others performed poorly, there's no reason to think compatibility won't rear up for these new chips as well. But Microsoft has put in some effort to ensure compatibility and fast performance with the new Snapdragon X chips for hundreds of popular apps, and it's using a special emulator called Prism to run nonnative apps.\nHere's a breakdown of the current Snapdragon X Elite and X Plus variants:\nSnapdragon X specs\n| Oryon CPU cores | CPU total cache | CPU max multithread frequency | CPU dual-core boost frequency | Adreno GPU (TFLOPS) | Hexagon NPU (TOPS) | Memory Type | |\n|---|---|---|---|---|---|---|---|\n| Snapdragon X Elite X1E-00-1DE | 12 | 42MB | 3.8GHz | 4.3GHz | 4.6 | 45 | LPDDR5x-8448 |\n| Snapdragon X Elite X1E-84-100 | 12 | 42MB | 3.8GHz | 4.2GHz | 4.6 | 45 | LPDDR5x-8448 |\n| Snapdragon X Elite X1E-80-100 | 12 | 42MB | 3.4GHz | 4.0GHz | 3.8 | 45 | LPDDR5x-8448 |\n| Snapdragon X Elite X1E-78-100 | 12 | 42MB | 3.4GHz | None | 3.8 | 45 | LPDDR5x-8448 |\n| Snapdragon X Plus X1P-64-100 | 10 | 42MB | 3.4GHz | None | 3.8 | 45 | LPDDR5x-8448 |\nBeyond the ARM difference, the Snapdragon X Plus and X Elite chips have a lot in common with other modern laptop chips. They feature between 10 and 12 high-performance CPU cores (the current generation is Oryon). They support fast, low-power LPDDR5x memory and include an integrated GPU -- currently Adreno. And like the most recent chips from competitors, they have a dedicated NPU as well, made to handle basic AI-powered tasks using less power than they would using the CPU and GPU. Software shifts relevant workloads from the CPU and GPU to the NPU to conserve power.\nQualcomm has made much ado of the performance of its components. Qualcomm says its Hexagon NPU is the \"world's fastest NPU for laptops\" at a rated 45 tera-operations per second, or TOPS. It's worth noting that discrete graphics processors available in laptops can offer higher TOPS, but at a much higher power draw.\nThe company claims the Oryon CPU outpaces Apple's M3 chip in a MacBook Pro in multithreaded CPU performance by 28%. It also claims to be faster in single-threaded and multithreaded performance than AMD's Ryzen 9 7940HS and Intel's Core Ultra 7 155H when running at the same wattages. When Apple launched its M1 chips, it made similar claims regarding performance and efficiency. So if Qualcomm's chips live up to these expectations, they could be a big leap forward for mainstream laptops.\nWhat else is coming with Snapdragon X Plus and X Elite chips?\nIn addition to the performance they offer, a part of these packages is also the technologies they provide. The Snapdragon X Elite and Snapdragon X Plus offer support for UFS 4.0 and PCIe 4.0 storage as well as SD 3.0 media. It supports multimonitor setups up to 4K@60Hz with up to three displays. It also supports 4K HDR encode and decode and includes an image signal processor to support camera recording up to 4K video, as well as dual 36-megapixel sensors or a single 64-megapixel sensor.\nIt also includes hardware for high-speed connectivity: up to three USB4 ports, Wi-Fi 7, Bluetooth 5.4 and 10Gbps 5G cellular via the Snapdragon X65 modem. How many of these features you'll have in your laptop ultimately comes down to the device manufacturers and their hardware choices. Which brings us to the next big question.\nWhat kind of computers will have Snapdragon X Plus and X Elite chips?\nBy targeting high performance at low wattages, Qualcomm's chips are geared for machines meant for mobile productivity -- those meant to tackle modestly heavy workloads while still running away from the power outlet for the whole workday. The AI capabilities of these chips get special emphasis and a key part of Microsoft's Copilot Plus push.\nLaptop manufacturers have already begun to incorporate these chips into their various mid-tier and premium models. The Surface Pro 11th Edition, Lenovo ThinkPad T14s Gen 6, Dell XPS 13 (9345), Asus Vivobook S 15 (S5507), Samsung Galaxy Book 4 Edge, HP OmniBook X and HP EliteBook Ultra G1q all feature Qualcomm Snapdragon X Elite or X Plus chips.\nCommon among these laptops is their more portability-minded form factors (no bulky 17-inchers here) and more premium designs. While Snapdragon chips may seed down to budget laptops in time, right now they're landing in more models costing over $1,000.\nWith these chips set to reach consumers' hands in mid- to late June, it's only a matter of time before we really see what they're capable of."
    },
    {
      "url": "https://www.cnet.com/tech/computing/monitors-buying-guide/",
      "text": "Should I go with 24 or 27 inches? Full HD or 4K? If questions like that are spinning around your head, chances are you've just begun to search for a new monitor to make your work-at-home (or play-at-home) setup more productive. We'll try to slow down your spinning head with this guide.\nIn this article\nThe TL;DR\nIf you're just looking for a generic display for working or schooling at home and don't want to hurt your brain thinking about it too much, for adults I recommend a 27-inch flat-screen display with 4K resolution, and one that uses an IPS panel. That should run about $500. If you need to go cheaper, drop to a 24-inch model with 1,920x1,080-pixel aka full HD resolution, which you can get for less than $150; 22 or 24 inches is a good choice for kids, too, or if you need something for a small space, but honestly, it's on the small side.\nUnless you're a hard-core gamer or creative professional, many of the most technical specs -- color gamut and latency, for example -- won't really matter to you (and you should always take manufacturer specs with a grain of salt, anyway).\nWhen hooking up to a laptop, you need to make sure that you've got the right connections: some USB-C or USB-C/Thunderbolt 3 ports support a feature called alt-display mode, which means you can use a USB-C to HDMI or USB-C to DisplayPort cable (or adapter) to connect to a monitor with those connections. Older laptops may still have the native connectors like HDMI or DisplayPort.\nRead more: Best monitors under $200 you can get right now\nGot a Mac? If it's an old MacBook and has an HDMI port, or an iMac or Mac Mini, you won't have a problem. More modern MacBooks with USB-C/Thunderbolt 3 connections will require an adapter or cable with conversion built-in. You may also need to fiddle with the resolution and scaling settings in Mac OS, since it natively prefers a 16:10 aspect ratio, not the 16:9 aspect ratio that's much more popular on Windows.\nIf you want to go a little more in-depth, here are some rules of thumb to follow:\n- Within the constraints of your budget and desk space, get the largest monitor you can. You'll rarely regret buying a monitor that's too big, but you'll frequently regret buying one that's too small. There are also super-widescreen monitors with 21:9 aspect ratio (also known as 2.35:1). Many of these models are curved, and most of them are 34-inch displays with lower-than-4K resolution. It's mostly a specialty item for gamers.\n- If you can afford it, go 4K. If not, choose one with a 16:9 aspect ratio, which is most commonly 1,920x1,080 (also called FHD, or Full HD). You can find the aspect ratio by dividing the horizontal resolution by the vertical resolution, and the result for 16:9 should be 1.77:1.\n- Make sure the stand can adjust to the appropriate height for you to use comfortably and tilt to a usable angle. Depending on your needs, you may also want a stand that can swivel or allow the screen to rotate 90 degrees for use in portrait orientation. Portrait will let you see more of a vertically scrolling web page, for instance, or be a little more comfortable if you work with print layouts.\n- Go with one that you find attractive -- you'll be staring at it a lot. For many people that's synonymous with \"thin bezels.\" You also want a stand that looks good and that has sensible cable management, allowing you to feed wires through a hole or channel to keep them together. Cable management can be important if the monitor has a USB hub, since you'll want to keep those cables under control as well.\nWhat screen size do I need?\nEverything being equal, and if you've got the space and budget, bigger is almost always better. Screen size labeling is based on the length of the diagonal: That made it easy to compare when almost every screen had the same aspect ratio (the ratio of the number of horizontal pixels to vertical pixels) but wide and ultrawide screens on desktop and newer ratios on laptops (such as 3:2 or 16:10) make it a little more difficult.\nIf you remember your geometry and algebra, you can calculate the width and height of the display if you also know the aspect ratio. (Because width/height = aspect ratio and width\u00b2 + height\u00b2 = diagonal\u00b2!) The further from 1:1 the aspect ratio is the wider the screen and more of it will be out to the sides, and therefore in your peripheral vision if you're close. It will also let you figure out the physical dimensions of the screen, most notably the width, to ensure it will fit in the allotted space. DPI Calculator can do the math for you.\nSee also\nWhat resolution -- 4K, FHD or ...?\nResolution, the number of vertical x horizontal pixels that comprise the image, is inextricable from screen size when you're choosing a monitor. What you really want to optimize is pixel density, the number of pixels per inch the screen can display, because that's what determines how sharp the screen looks (though there are some other factors), as well as how big elements of the interface, such as icons and text, can appear. Standard resolutions include 4K UHD (3,840x2,160 pixels), QHD (Quad HD, 2,560x1,440) and FHD (Full HD, 1,920x1,080): You're better off looking at the numbers than the alphabet soup, because when you get to variations like UWQHD they can get ambiguous. When you see references to 1080p or 1440p, it's referring to the vertical resolution.\nFor example, on a 27-inch display, 1,920x1,080 has a pixel density of 81.59 ppi. On a 24-inch display, it's 91.79 ppi. Because a higher density is better up to a point, FHD will look better on the smaller screen. This also depends on your vision: For me, too low a resolution and I can see the pixel grid and at slightly better than that I see nothing but jaggies on small serif type. So \"optimal\" really depends on what you're looking at and personal preference. My preference is at least 100ppi. Once again, DPI Calculator can do the math for you. (A related spec to pixel density is dot pitch, a measure of the spaces between the pixels. For that, smaller is better.)\nBut another important consideration when figuring out what resolution to get relative to screen size is scaling. On a 27-inch screen, the operating system (both Windows and Mac OS) can scale interface elements to be larger, but never smaller. For a given screen size and pixel density, 100% scale is bigger for lower densities. The bottom line is you can frequently scale high-density screens to make the elements bigger, but you can never scale low-density screens to make them smaller. In other words, if you're buying a bigger monitor thinking you'll be able to fit more on the screen, you can't. Even in applications that let you zoom independently, like Chrome, you quickly lose readability when you view at less than 100% at low pixel densities.\nCommon resolutions\n| Standard | Resolution | Aspect ratio |\n|---|---|---|\n| Full HD (FHD) | 1,920x1,080 | 16:9 |\n| Wide quad HD (WQHD) | 2,560x1440 | 16:9 |\n| Wide quad XGA | 2,560x1,600 | 16:10 |\n| Ultra wide quad HD | 3,440x1,440 | 21:9 |\n| Ultra HD 4K (UHD) | 3,840x2,160 | 16:9 |\n| Digital Cinema Initiatives 4K (DCI 4K) | 4,096x2,160 | Between 16:8 and 16:9 |\n| 5K | 5,120x2,880 | 16:9 |\nDo I want curved or flat?\nTo me, curved monitors are the best way to make a single display wider without forcing you to sit too far back; that's why they make more sense for a desktop monitor than for a TV. Optimally, you should be able to see the entire screen without moving your head too much. Once you get beyond roughly 27 inches, that requires a curve if you're sitting at a desk. Don't get me started on the \"immersive experiences,\" of curved screens: Unless that display wraps all the way around me, it's no more immersive than any other.\nAt 27 inches and below, aside from the fact that curved displays can look ever so much prettier, one of the few practical applications for it is three-monitor setups, which let you create a better widescreen experience. Otherwise, small curved screens just aren't worth it, especially if you're paying extra for the privilege. And in fact, I feel like curves on smaller screens bring the edges too far into my peripheral vision for comfort.\nThe amount of curve is expressed in \"R\", the radius of its arc in millimeters. For a given display size, bigger numbers are tighter arcs, so 1,800R (the radius of many 27-inch curved displays) is shallower than 2,000R. Too much of a curve can be distracting, while too little may as well be flat. However, ignore all the talk of how \"immersive\" they are. They really aren't yet, at the very least because many games still aren't able to take full advantage of the nonstandard aspect ratios. On the other hand, unlike curved TVs, you'll always be sitting in the sweet spot, so glare shouldn't be an issue.\nMany widescreen models tend to have a 21:9 aspect ratio, which means they're wider and shorter than other displays and full-screen video will be pillarboxed. But larger monitors without a curve at a more common 16:9 aspect ratio would require you to be bobbleheaded because they'd be quite tall: 24 inches (61 cm) high for a 49-inch monitor versus 19 inches (48 cm).\nShould I get two screens or one ultrawide?\nThis really depends on what you're doing. For instance, if you want a really fast gaming monitor for play and a high-resolution display for work, it's a lot cheaper to get two than a single one that does both. Or if you need a color-accurate monitor for design but want a high-brightness one for gaming, it's also a lot cheaper to get two smaller ones. But if you just need a ton of screen space, a single ultrawide might be simpler.\nDoes the screen technology -- IPS, TN, and so on -- matter?\nYou don't really need to know anything about panel technology for buying a general-purpose display except that cheapest option TN (twisted nematic) isn't great, VA (vertical alignment) is somewhat better and that IPS and PLS (in-plane switching and plane-line switching) are the same thing and currently the best options. They do differ when it comes to specific needs, such as gaming or color-critical work. Almost all of them use LCD technology: You'll frequently see backlit LCDs referred to as LED-lit. These are not related to OLED displays, which haven't really materialized for the desktop due to various technical issues. Laptops are a different story.\nThe reason you generally don't need to think about the technology is because they tend to be expressed through specs and features, and those you do need to look at. Here are the relevant ones.\nColor gamut\nThis is the total number of colors a monitor can display. It's frequently expressed as a percentage of a color space, which is an artificial construct that encompasses all the colors a device should be able to produce for a given purpose. Color spaces are really meant for use in color matching across devices that have different reproduction characteristics. For example, the Adobe RGB color space was designed to encompass real-world colors on a display for reproducing in print. sRGB was designed as a lowest-common-denominator standard for colors used by typical consumer monitors viewing the web. Displays with more than 100% sRGB are invariably anything but TN, and usually IPS.\nScreen refresh rate\nThis is the number of times per second (in Hertz, or Hz) the screen can update, and affects motion blur and artifacts like tearing, which occur when the rate at which the graphics card is feeding the display and the display's refresh rate differ significantly. For any task in which frame rate (frames per second) matters, refresh rate may be an issue. (That predominantly means gaming, though high-frame-rate video editing or viewing may also be affected.) 60Hz is the minimum you want for comfort -- most monitors support that -- and 75Hz is comfortable for most nongaming uses. TN remains the best technology for getting stratospheric refresh rates: 300Hz or 360Hz are TN. But IPS panels can now hit 240Hz, which means there's a lot less of a tradeoff using them for gaming than there used to be. You can find everything you've ever wanted to know about refresh rate and more at Blur Busters.\nPixel response\nThis is how fast an individual pixel can switch states from black to white or (more commonly) from gray to gray measured in milliseconds. Faster is better, though only gamers tend to care, and you generally want a minimum of 5ms or less GtG for gaming. IPS and VA currently stand at between 3 to 5ms, and anything claiming about 1ms is TN. Fast-action esports generally still use TN because of the combination of high refresh rates and fast pixel response times.\nContrast\nThis is the measure of the ratio between 100% and 0% brightness values. Higher contrast makes everything pop more. You definitely want to ignore the \"dynamic contrast\" types of specifications and concentrate more on anything listed as typical. Anything above 1,000:1 is fine, though I find 1,400:1 or so most comfortable for me.\nBrightness\nThis is how much light the screen can emit, usually as expressed in nits (candelas per square meter). Most desktop monitors run 250 to 350 nits typically. Screens that support HDR tend to start at 400 nits and run as high as 1,600. Laptop screens are different, because they need to be viewable in different types of lighting, such as direct sunlight, and therefore benefit from higher brightness levels even without HDR support.\nViewing angle\nThis is how far from off-center a screen can be viewed at, optimally, without serious changes in contrast or color. It remains one of TN's biggest weaknesses compared to other technologies.\nBacklight\nAll screen technologies shine a light through various layers of color filters and liquid crystal to produce an image except OLED. OLED uses organic materials that directly emit light in a spectrum of color frequencies, which is how it can be so thin and produce a wide color gamut. Most panels with backlights may display some artifacts, notably the appearance of light around the edges of a dark screen, known as backlight bleed. A new backlight technology, mini LED, lets a monitor use local dimming like a TV to produce high brightness with less bleed. (A standard full-LED array can do it as well, but not as effectively as mini LED.) Mini LED is used by the latest crop of HDR displays with brightness of 1,000 nits or more.\nDoes color accuracy matter?\nBallpark accuracy matters. If you shop online, for example, you want to make sure that cerulean blue shirt is roughly the same color you expect to get. And as long as a monitor has a less-saturated setting than vivid and any level of quality control, you don't need to worry about it. What tends to happen in practice, though, is that a monitor is tuned to produce the most accurate colors it was capable of when it left the factory floor.\nBut that's not the type of accuracy manufacturers are talking about when they list specs like \"Delta E < 2\" or say it's Pantone Validated. What those mean -- or should mean -- is the monitor has been tuned and calibrated so that the difference between a set of color patches as displayed on the screen is the same within a small margin of error to a set of reference patches within the bounds of a specific color space. If that's the type of color accuracy that matters to you, it adds a whole additional layer of requirements and complexity.\nHow much should I expect to spend?\nOther things being equal, a display tends to get more expensive as resolution, screen size, refresh rate, brightness and the number and type of features increases. Broader color spectrum, as well as niche capabilities for gaming or graphics will also boost the price. But you can get a strong general-purpose monitor for less than $300.\nAt the moment we're in a lull before products incorporating new standards are ready, such as HDMI 2.1, so if you're OK being behind the curve until you can afford something new, then don't worry. If you're going to beat yourself up in 2021 because you didn't wait for HDMI 2.1 or affordable 8K, then either wait or buy the cheapest model that will meet your needs to tide you over.\nCan I use my old TV instead?\nYou can certainly drive a TV from your computer, but TVs are meant to be viewed from a distance, while computer displays are designed for closer work. As TVs get smarter and higher-resolution, though, the gap between the two is narrowing. Plus, for gamers, having a primary computer display for working and a TV hooked up for gaming may make sense. Want to do that? Here's how to use your 4K TV as a monitor.\nFeatures to think about\nRun-of-the-mill monitors may include speakers, USB hubs, slots for memory cards and more, as well as support features like picture-in-picture when hooked up to two systems. If you're short on desk space, you might want to consider a display with these types of integrated features. There are also whole classes of important features for gaming or color-critical work.\nRead more: PS5 and Xbox Series X can game in 8K resolution. Should you care?\nWhat else should I consider?\nHow to shop for one\nIf possible, you have to see them in real life. I've headed out to buy a specific display based on the specs and ended up changing my mind when I got up close and personal with it. For example, displays with similar screen sizes can look or feel smaller or bigger than you thought, be more reflective or dull than you like, or it can be impossible to reach the connectors. As with TVs , however, keep in mind that there are a few things that you can't judge in a store. The biggest is, sadly, image quality, which includes color rendering, brightness and black level. But you can tell if you find the screen readable and if you think it's ugly.\nIt's not always practical to see a product in person, though, so read user reviews carefully. It's difficult to sort out the meaningful complaints from the not-so-meaningful ones, but look for comments about build quality and dead pixels. Unfortunately, it's harder to gauge screen quality -- brightness, contrast, color -- from reviews, because everyone's eyes are different. Just make sure you know the return policies (including dead pixel allowances), remove it from the packaging as cleanly as possible and note how to repack it, just in case.\nI admit, I'm a bit of a fatalist when it comes to support. The probability of having a good support experience from a manufacturer tomorrow seems to be completely independent of the experience you had with them today, and even good support from one division doesn't necessarily mean good support from another.\nWhat to expect in the box\nAt the bare minimum, you should expect an HDMI cable and a basic stand even with a cheap monitor. As the price rises so does the variety of cables bundled. The stand might not be an issue if you're planning to use the VESA mount to put it on a wall or arm. But in that case, you should ensure the mount screws on the back of the monitor match yours: The bulk of inexpensive monitors have 100-by-100 mm mounts, but in some cases, they don't support a VESA mount at all."
    },
    {
      "url": "https://www.cnet.com/tech/computing/microsoft-qualcomm-take-another-shot-at-pcs-with-copilot-plus/",
      "text": "Qualcomm and Microsoft are hoping the nth time's the charm for Windows on Arm/Snapdragon mobile chips. Despite years of disappointing implementations, as of the Surface Pro 9 in the fall of 2022 (the last big Qualcomm PC buzz child), the concept still hadn't gained serious traction. It never delivered on the promise of making huge performance and compatibility sacrifices to get better battery life and phone-like connectivity.\nAnd AI. In 2019, corporate VP Yusuf Mehdi said of the first customized Qualcomm chip, the SQ1, \"We've got amazing graphics power. We're going to do AI on the chip.\" Cut to five years later and we're still waiting for what the pair are now branding this go-round \"Copilot Plus PCs,\" incorporating the Snapdragon X Elite or Plus processors announced last year.\nSnapdragon X chips specs\n| Cores/threads | Boost frequency (GHz) | iGPU | |\n|---|---|---|---|\n| Snapdragon X Elite (X1E-84-100) | 12 | 3.8 (multi), 4.2 (dual) | Adreno (4.6 TFLOPS) |\n| Snapdragon X Elite (X1E-80-100) | 12 | 3.4 (multi), 4.0 (dual) | Adreno (3.8 TFLOPS) |\n| Snapdragon X Elite (X1E-78-100) | 12 | 3.4 (multi) | Adreno (3.8 TFLOPS) |\n| Snapdragon X Plus (X1P-64-100) | 10 | 3.4 (multi) | Adreno (3.8 TFLOPS) |\nIf they do finally meet long-held expectations, a lot of it is down to Microsoft finally ironing out a lot of issues with Windows on Arm and Qualcomm boosting performance.\nQualcomm has crossed the line someone's drawn at 40 trillion operations per second for integer math, which is what neural processing units do and which neither of the other companies have hit yet. In general, anything that uses a chip that's got a dedicated NPU less than six months ago was called just an \"AI PC.\" Intel Core Ultra, AMD Ryzen 7040 series and newer, and now the Qualcomm Snapdragon Elite series. Intel emailed to remind me that its Lunar Lake processors -- more than 40 TOPS, and therefore Intel would have Copilot Plus PCs! -- would be shipping in Q3.\nFloating point operations, another measure of computing power, requires more horsepower and memory, and if there's an NPU, the system offloads the integer math to that and leaves the floating point to the GPU or CPU. And no one's really boasting about their integrated GPU's floating-point performance (16- or 32-bit floating point ops per second). Floating point is more accurate because it represents real numbers, so can handle larger amounts of more precise data, but it also requires more power.\nThe NPU, which is optimized for sequential, non-memory-intensive operations, for is what's used for all the now-commonly heralded AI applications that are performed locally rather than in the cloud: All the new features Microsoft announced for Copilot, and also includes the oft-mentioned features we've become used to, like image processing for video conferencing (such as background removal, filters and more in Windows' Studio Effects, and custom utilities supplied by the big laptop manufacturers); document and email summaries and drafting; voice commands and so on. Generating images, music and video requires more horsepower, and are still run in the cloud, but we've already got some basic automatic photo adjustments run locally using AI.\nAnd enterprises are as tickled as IT people ever get about the use of AI for security, since it makes threat detection, recovery and more faster and less labor intensive. One of the previous problems for these laptops and enterprises was the software tools administrators needed to secure and deploy them weren't really there. Now, there are, and Qualcomm is a partner for Microsoft's Pluton security.\nBring on the laptops\nThe chipset doesn't support Thunderbolt 4/5, so these laptops have at least one USB 4 port. The chips can handle up to three USB 4 ports (40Gbps) and two USB 3.2 gen 2 (20Gbps). They've got either Wi-Fi 7 by default or as an option and up to 64GB RAM. They can potentially drive one 4K-resolution 120Hz, HDR screen; up to three 4K, 60Hz, HDR screens; or two 5K, 60Hz external display configurations.\nNot all of them boast out-of-the ordinary battery life claims, which range from 16 hours to about 22 hours, but those are for playing video locally -- not even streaming. So, not terribly representative. The partner laptops for the launch event are all, for the most part, gently modified versions of existing laptops or additions to existing lines, and many are 14-inch class models, with an occasional 13-inch or 16-inch, plus they're all expected to ship in June.\nHP\nHP decided to take the opportunity to rebrand its two mainstream consumer and business laptop lines. There's also a new graphic to indicate \"AI inside!\" HP resurrects an old name for its consumer laptops. The new consumer branding is OmniBook (laptops), OmniStudio (desktop all-in-ones) and OmniDesk (desktops). Ultra is the flagship, X (10!) and 3, 5 and 7 models increase in premiumness.\nFor business customers, HP sticks with Elite: EliteBook (laptops), EliteStudio (desktop all-in-ones) and EliteDesk (desktops). The naming conventions are odd, rather than even. Ultra is flagship and replaces the Dragonfly line; X, 8 and 6 are premium/mainstream and 2 and 4 are entry.\nToday's launch models are the OmniBook X and the EliteBook Ultra G1q.\nHP specs\n| HP OmniBook X | HP EliteBook Ultra G1q | |\n|---|---|---|\n| Starting price | $1,200 | $1,700 |\n| CPU | Snapdragon X Elite X1E-78-100 | Snapdragon X Elite TBA |\n| Display | 14-inch, 2,240x1,400 pixels, touch, 300 nits, 100% sRGB | 14-inch, 2,240x1,400 pixels, touch, 300 nits, 100% sRGB |\n| Memory | 16GB or 32GB LPDDR5X-8533 (soldered) | 16GB LPDDR5X-8400 (soldered) |\n| Graphics | Integrated Adreno 3.8 TFLOPS | Integrated Adreno 3.8 TFLOPS |\n| NPU | Hexagon (up to 45 TOPS) | Hexagon (up to 45 TOPS) |\n| Webcam | 5 megapixels plus IR | 5 megapixels plus IR |\n| Storage | Up to 2TB SSD | Up to 1TB NVMe M.2, 512GB PCIe NVMe SSD |\n| Ports | 2x USB-C (1x display, PD, 40Gbps), 1x USB-A 3.2 gen 1, combo audio | 2x USB-C (1x display, PD, 40Gbps), 1x USB-A 3.2 gen 1, combo audio |\n| Networking | Wi-Fi 7, Bluetooth 5.4 or Wi-Fi 6E, Bluetooth 5.3 | Wi-Fi 7, Bluetooth 5.4 or Wi-Fi 6E, Bluetooth 5.3 |\n| Battery | 59Wh (rated for roughly up to 24 hours) | 59Wh |\n| Operating System | Windows 11 Home or Pro | Windows 11 Home or Pro |\n| Weight | 3.0 lbs/1.3 kg | 3.0 lbs/1.3 kg |\n| Dimensions | 12.3 x 8.8 x 0.6 in/313 x 224 x 14 mm | 12.3 x 8.8 x 0.3-0.6 in/313 x 224 x 8.5-14 mm |\n| Availability | June 2024 | June 2024 |\nHP will retain design modifiers, such as Fold for dual screens and Flip for two-in-ones. And any system with HP's new Helix logo has an NPU rated for at least 40 TOPS. The Omen, and presumably Z workstations, retain their old branding, at least for the moment.\nThe hardware for its two launch laptops seems fairly average, neither under nor overconfigured. HP does have the thinnest -- but not lightest -- offerings of the three.\nLenovo\nLenovo's got the lightest laptops of the three manufacturers -- under 3 pounds. The Yoga Slim 7x 14 Gen 9 is the only 14.5-inch model and has an attractive display option, a new OLED screen that's DisplayHDR True Black 600 certified, a relatively new level.\nLenovo specs\n| Lenovo Yoga Slim 7x 14 Gen 9 | Lenovo ThinkPad T14s Gen 6 | |\n|---|---|---|\n| Starting price | $1,200 | $1,700 |\n| CPU | Snapdragon X Elite | Snapdragon X Elite |\n| Display | 14.5-inch, 2,944x1,840 pixels, 90Hz OLED, DisplayHDR True Black 600 (1,000 nits peak brightness), 100% P3 | 14-inch, 400 nits, 1,920x1,200 pixels, IPS. Two options: One uses 3M Dual-Brightness Enhancement film and supports touch, but has a gamut coverage of roughly 70% sRGB, while the other doesn't support touch but has a 100% coverage of sRGB. A third option is 2,880x1,800 OLED, 100% P3, DisplayHDR True Black 500. |\n| Memory | 32GB LPDDR5X-8448 (soldered) | 64GB LPDDR5X-8533 (soldered) |\n| Graphics | Integrated Adreno 3.8 TFLOPS | Integrated Adreno 3.8 TFLOPS |\n| NPU | Hexagon (up to 45 TOPS) | Hexagon (up to 45 TOPS) |\n| Webcam | 1080p MIPI plus IR | 1080p MIPI plus IR |\n| Storage | Up to 1TB PCIe Gen 4 M.2 | Up to 1TB PCIe Gen 4 M.2 |\n| Ports | 3 x USB-C (3x display, PD, 40Gbps) | 2x USB-C 4, 2x USB-A (5Gbps), HDMI 2.1, combo audio |\n| Networking | Wi-Fi 7, Bluetooth 5.3 | Wi-Fi 7, Bluetooth 5.3 |\n| Battery | 70Wh | 58Wh |\n| Operating System | Windows 11 | Windows 11 |\n| Weight | 2.8 lbs/1.3 kg | 2.7 lbs/1.2 kg |\n| Dimensions | 12.8 x 8.9 x TBA in/325 x 225 x TBA mm | 12.3 x 8.6 x 0.7 in/314 x 219 x 17 mm |\n| Availability | June 2024 | June 2024 |\nAcer\nThe company's Swift 14 AI is the only one of these that launches with a Snapdragon X Plus option in addition to the Elite, which allows it to start at a lower price by sacrificing a couple of CPU cores.\nLike HP, Acer has a new graphic on the lid indicating the AI within, plus a new graphic (that looks very big) on the touchpad to serve as an activity and Copilot-specific indicator. It's the cheapest laptop announced today, but it's also the thickest and the heaviest.\nAcer Swift 14 AI (SF14-11) specs\n| Starting price | $1,100 |\n|---|---|\n| CPU | Snapdragon X Elite X1E-78-100 or Snapdragon X Plus X1P-64-100 |\n| Display | 14.5-inch, 2,560x1,600 pixels, 120Hz, 100% sRGB |\n| Memory | 32GB LPDDR5X-8533 (soldered) |\n| Graphics | Integrated Adreno 3.8 TFLOPS |\n| NPU | Hexagon (up to 45 TOPS) |\n| Webcam | 1440p plus IR |\n| Storage | Up to 1TB SSD |\n| Ports | 2x USB-C (1x display, PD), 2x USB-A 3.2 gen 1 |\n| Networking | Wi-Fi 7, Bluetooth 5.4 |\n| Battery | 75 Wh (rated for up to 16 hours) |\n| Operating System | Windows 11 |\n| Weight | 3.0 lbs/1.3 kg |\n| Dimensions | 12.7 x 8.9 x 0.6 in/323 x 226 x 16 mm |\n| Availability | July (US), June (EMEA) 2024 |\nSamsung\nSamsung's Galaxy Book 4 Edge laptops are the priciest of the bunch, but they're also very thin, very light and have OLED displays. They also use the higher end X1E-80/84-100 processors\nGalaxy Book 4 Edge specs\n| Samsung Galaxy Book 4 Edge 14 | Samsung Galaxy Book 4 Edge 16 | |\n|---|---|---|\n| Starting price | $1,350 | $1,450 |\n| CPU | Snapdragon X Elite X1E-80-100 | Snapdragon X Elite X1E-80-100 or X1E-84-100 |\n| Display | 14-inch 2,880 x 1,800 OLED touchscreen 120% P3 500 nits HDR | 16-inch 2,880 x 1,800 OLED touchscreen 120% P3 500 nits HDR |\n| Memory | 16GB RAM | 16GB RAM |\n| Graphics | Integrated Adreno 3.8 TFLOPS | Integrated Adreno 4.6 or 3.8 TFLOPS |\n| NPU | Hexagon (up to 45 TOPS) | Hexagon (up to 45 TOPS) |\n| Webcam | 1080p | 1080p |\n| Storage | 512GB or 1TB SSD | 512GB or 1TB SSD; micro SD slot |\n| Ports | 2 x USB-C 4, combo audio HDMI 2.1 | 2 x USB-C 4, 1 x USB 3.2, combo audio, HDMI 2.1 |\n| Networking | Wi-Fi 7, Bluetooth 5.3 | Wi-Fi 7, Bluetooth 5.3 |\n| Battery | 56 Wh | 62Wh |\n| Operating System | Windows 11 Home | Windows 11 Home |\n| Weight | 2.6 lb/1.2 kg | 3.4 lb/1.5 kg |\n| Dimensions | 12.3 x 8.8 x 0.4 in/312 x 224 x 10 | 14.0 x 9.9 x 0.5 in/356 x 251 x 13mm |\n| Availability | June 2024 | June 2024 |\nAsus\nAsus' mainstream Vivobook has one notable feature: a 15.6-inch OLED display certified DispalyHDR True Black 600, the newest standard with higher brightness.\nAsus Vivobook S15 specs\n| Starting price | $1,300 |\n|---|---|\n| CPU | Snapdragon X Elite X1E-78-100 or Snapdragon X Plus X1P-64-100 |\n| Display | 15.6-inch 2,880 x 1,620 120Hz OLED 100% P3 DisplayHDR True Black 600 |\n| Memory | 16GB or 32GB LPDDR5X-8533 (soldered) |\n| Graphics | Integrated Adreno 3.8 TFLOPS |\n| NPU | Hexagon (up to 45 TOPS) |\n| Webcam | 1080p plus IR |\n| Storage | 512GB or 1TB SSD; micro SD slot |\n| Ports | 2 x USB-C 4, 2 x USB 3.2, combo audio, HDMI 2.1 |\n| Networking | Wi-Fi 7, Bluetooth 5.4 |\n| Battery | 70Wh |\n| Operating System | Windows 11 Home or Pro |\n| Weight | 3.1 lbs/1.4 kg |\n| Dimensions | 13.9 x 9.0 x 0.6 in/35 x 23 x 16mm |\n| Availability | June 2024 |\nDell\nDell's two consumer offerings -- there's also a Latitude -- are as close to entry as these laptops get for their product lines; the XPS 13 doesn't use the base 78 Elite chip, which keeps the price sinking as low as it might.\nDell specs\n| Dell XPS 13 9345 | Dell Inspiron 14 Plus 7441 | |\n| Starting price | $1,299 | $1,100 |\n| CPU | Snapdragon X Elite X1E-80-100 | Snapdragon X Plus X1P-64-100 |\n| Display | 13.4-inch 1,920 x 1,200 120Hz 500 nit IPS | 14-inch QHD Plus, 400 nits, 100% sRGB 60Hz touch |\n| Memory | 16GB LPDDR5x-8400 (soldered) | 16GB LPDDR5x-8448 (soldered) |\n| Graphics | Integrated Adreno 3.8 TFLOPS | Integrated Adreno 3.8 TFLOPS |\n| NPU | Hexagon (up to 45 TOPS) | Hexagon (up to 45 TOPS) |\n| Webcam | 1080p plus IR | 1080p plus IR |\n| Storage | 512GB SSD | 512GB SSD |\n| Ports | 2 x USB 4 | 2 x USB 4, 1 x USB-A 3.2, combo audio |\n| Networking | Wi-Fi 7, Bluetooth 5.4 | Wi-Fi 7, Bluetooth 5.4 |\n| Battery | Rated up to 27 hours | Rated up to 21 hours |\n| Operating System | Windows 11 | Windows 11 |\n| Weight | 2.6 lb/1.2kg | 3.2 lbs/ 1kg |\n| Dimensions | 11.6 x 7.8 x 0.6 in/295 x 199 x 15.3 mm | 12.4 x 8.8 x 0.7 in/314 x 224 x 17mm |\n| Availability | June 2024 | June 2024 |"
    },
    {
      "url": "https://www.cnet.com/tech/computing/how-to-choose-an-hdr-gaming-monitor/",
      "text": "High Dynamic Range refers to scenes rendered with brighter highlights, greater shadow detail and a wider range of color for a better looking image. For gaming HDR, in contrast to TV HDR, it means more than a prettier picture: The better you can see what's lurking in the bright and dark areas, the more likely you are to avoid hidden enemies and spot clues. But keep in mind that most games are still designed for the middle common denominator: Everything you need to see is sufficiently visible in the middle of the brightness range.\nRead more: How to Buy a Gaming Monitor\nGames still require explicit HDR support for optimal results, but the introduction of Auto HDR in the Xbox Series X/S and in Windows 11 changes that: The operating systems can automatically expand the brightness and color ranges of nonHDR games. It's not the same as having a game that was rendered to use the expanded ranges, but it can give it a bump to make it look better than it otherwise would.\nWhat is HDR and why do I want it?\nTo deliver its magic, HDR combines several elements. First, it uses an extended brightness range, well beyond the 256 levels displayable by a typical monitor, and in the best cases, beyond the true 1,024 levels of a great monitor. It also covers more colors than the least-common-denominator sRGB gamut, profiles necessary to optimally map the color and brightness ranges of content to the capabilities of the display, a decoder in the monitor that understands the mapping and all the related technologies that tie the pieces together -- not the least of which is the operating system.\nFor a lot of games, HDR doesn't matter, because they don't have lots of areas with high brightness or deep shadows, or don't take advantage of the bigger tonal range in any meaningful way. But for games that support it, you'll probably get better visuals for AAA games, more creeps from horror games, fewer ambushes out of the shadows in FPS games and so on.\nThe real question isn't whether or not you want it. The question is how much are you willing to pay for it -- not just for a display with \"HDR10\" in its specs, but for a monitor that will deliver the image quality that we associate with HDR.\nWill an HDR gaming monitor work with the Xbox Series X/S and PS5?\nYup! There are even a publicly available set of best practices for HDR game development and monitor design developed by Sony , Microsoft and a host of other relevant companies under the umbrella HDR Gaming Interest Group, for their consoles and Windows. But HGIG isn't a standards body, nor does it certify products, so you still need to pay close attention to specs. And it gets more confusing still\n'HDMI 2.1' caveats\nUnfortunately, the HDMI specification has turned into such a mess that you can't make assumptions about capabilities based on the version number. Not only is every HDMI 2.0 connection henceforward to be labeled as 2.1a (with the same HDMI 2.0 feature set), but the specification no longer mandates any of the important new features; in other words, all the whizzy capabilities that made HDMI 2.1 desirable, especially as a choice for consoles, are now optional.\nBottom line: If you want a monitor for your console that can do 4K at 120Hz, support variable rate refresh and auto low-latency mode, you'll have to verify support for each individually. And the same goes if you want a PC monitor connected via HDMI that can support source-based tone mapping (discussed below) and bandwidth-intensive combinations of high resolution, fast refresh rates and high color depth/HDR.\nMonitor manufacturers are supposed to list supported features explicitly; if they don't, either pass the monitor by or delve deeper. If you want the gory details, TFT Central does an excellent job explaining the issues.\nWhat do I look for in an HDR gaming monitor?\nThe term \"HDR\" has become pretty diluted thanks to marketers stretching the definition to encompass displays in the most popular price range (less than $400). So to a certain point you have pay attention to multiple specs to figure out if it's capable of a real HDR experience.\nThe VESA display industry association created a set of standards and criteria for conveying HDR quality levels in consumer monitors, DisplayHDR, which is pretty reliable as one method of crossing choices off your list. (DisplayHDR 400 is laughable for HDR because its color gamut and brightness requirements make it the kiddie pool of HDR, but if you're just looking for a bright SDR monitor it's a good bet.)\nRead more: VESA Updates DisplayHDR Logo Spec to Accommodate Laptop, OLED Screens\nMany manufacturers have taken to referring to monitors as, for example, \"HDR 600,\" which confuses things. It's never clear whether they're simply using it as shorthand for the equivalent DisplayHDR level and don't want to pay for the logo certification program, or whether they're using it as misleading shorthand for the ability to hit the peak brightness level of a particular tier. It's possible for them to run through the certification tests themselves for internal verification without opting for the logo. (You can, too, with the DisplayHDR Test utility available in the Microsoft Store.)\nThat's why it's important to understand the important -- and not so important -- HDR-related specs.\nHDR10 and HDR10 Plus Gaming\nFrom a spec standpoint, HDR10 support means little to nothing, because it only means the monitor understands the data stream and render it somehow, not that it actually be capable of displaying it well. Adherence to the HDR10 standard is the most basic level a monitor has to hit (and the cheapest to include) in order to call itself \"HDR.\" It's simply means the monitor can support the algorithms needed by an operating system to map HDR content correctly to the capabilities of the monitor: brightness mapping and the ability to handle the 10-bit calculations that mapping needs (for EOTF and SMPTE ST.2084 gamma), understanding how to work with the compressed color sampling in video and the capability of handling and mapping colors notated within the Rec 2020 color space.\nAt CES2022, the organization behind the HDR10 standard announced a new level, the forthcoming HDR10 Plus Gaming standard, a variation of the HDR10 Plus that's been available on TVs for a while. It adds Source Side Tone Mapping (SSTM), which adjusts the brightness range on a scene level based on data embedded by the game developer -- HDR10 has a single range that has to work for the whole game. It also includes the ability to automatically trigger a display's low latency mode, to compensate for the additional overhead imposed by the HDR data (more important for TVs than monitors), as well as support for variable refresh rates in 4K at 120Hz on consoles (still not implemented in the PS5 as of today).\nHDR10 Plus requires certification and a paid license for the hardware manufacturers (that includes GPUs), because the license also pays for usage rights to selected patents of the member manufacturers, but not software developers. Samsung announced at CES that all its 2022 gaming monitors will support HDR10 Plus.\nColor and brightness\nBrightness is a measure of how much light the screen can emit, usually as expressed in nits (candelas per square meter). Most desktop monitors run 250 to 350 nits typically in SDR (standard definition range), but HDR monitors also specify a peak brightness which they can hit for short periods in HDR mode and usually for just a portion of the screen. Displays that support HDR should start at 400 nits peak -- at the very least -- and currently run as high as 1,600. (Laptop screens are different, because they need to be viewable in different types of lighting, such as direct sunlight, so therefore benefit from higher brightness levels even without HDR support.)\nOLED screens tend to be assessed differently because they achieve virtually zero-brightness black levels, which is what makes them so high contrast regardless of how bright they can get; contrast is one of the biggest determinants of how we perceive the quality of an image.\nFor gaming and monitors in general, the color space you're most interested in is P3, which comes in two slightly different flavors: DCI-P3 and D65 P3. In practice, they differ only by their white points; DCI is a hair warmer (6300K instead of 6500K) and was conceived for editing film. However, I frequently see DCI-P3 listed in specs where they really mean D65. That's fine, because D65, which was spearheaded by Apple for its own displays, is the one we care about for gaming monitors. And their gamuts are identical, so unless I'm specifically differentiating between the two I refer to it simply as P3. (If you've got educated eyes you can tell the difference between the two whites, but it's immaterial for most people.)\nYou'll also commonly see gamuts listed as a percentage of Adobe RGB, which is fine as well. Adobe RGB and P3 overlap significantly; Adobe RGB is shifted a bit toward the green/cyan end of the spectrum, because printers use cyan ink, while P3 extends further out on the green/yellows, which are easier for good monitors to produce. And that, in a nutshell, is why when specs say \"over a billion colors\" (the number produced by using 10-bit math) it's meaningless. Which billion matters.\nAny monitor you consider for decent HDR viewing should definitely cover much more than 100% sRGB, a space developed by HP and Microsoft in 1996 to provide least-common-denominator color matching in Windows that is roughly equivalent to the color space of the the Rec 709 SDR video standard. If you look at the chart above, you can see immediately why the greens of sRGB-calibrated monitors and images are awful and everything is looks relatively low contrast (because it can't attain high saturation values of most hues).\nBased on my experience, I think a decent HDR monitor should be able to hit a peak brightness of between 600 and 1,000 nits and cover at least 95% of the P3 or Adobe RGB color gamut. (When Windows looks awful in HDR mode, it's the result of lower brightness capability, sRGB-only color gamut, poorly designed aspects of the operating system and math.)\nBacklight type\nAll screen technologies except OLED shine a light through various layers of color filters and liquid crystal to produce an image except OLED, which has self-illuminating pixels. Most panels with backlights may display some artifacts, notably the appearance of light around the edges of a dark screen, usually referred to as backlight bleed (although it's technically an artifact of edge lighting).\nA newer backlight technology which is great for HDR, mini LED, lets a monitor use local dimming like a TV to produce high brightness with less bleed and fewer bright halos when they appear next to dark areas; the brighter the display, the more noticeable unwanted brightness tends to be. Mini LED is used by the latest crop of HDR displays with brightness of 1,000 nits or more. And as with TVs , more local-dimming zones is better.\nBut all those LEDs glowing brightly can generate a hot of heat. One trend has been to dial back the number of zones from when monitors with mini LED arrays first shipped. Monitors announced in 2022, for example, have half the zones of the initial 1,152-zone models.\nSamsung QD-OLED screens combine Quantum Dot color rendering technology with a blue OLED backlight; that let's produce high contrast and fast response times, using the Quantum Dot array to render a broad array of colors. The first monitor to ship with the screen is the Alienware 34 QD-OLED. The AW34 straddles the brightness line by supplying a standard 400-nit HDR mode (which is better than it sounds because of contrast provided by the essentially perfect black) as well as a more limited 1,000 nit mode. It radiates some heat, but doesn't get nearly as hot as the traditional 1,000-plus nit monitors.\nAs brightness rises, so does price, which is why 400-nit displays are so appealing to both buyers and sellers. Tossing in gaming needs like a high refresh rate can boost the price even more."
    },
    {
      "url": "https://www.cnet.com/tech/computing/how-to-buy-a-laptop-to-edit-photos-videos-or-other-creative-tasks/",
      "text": "Are you baffled by the multitude of laptop, desktop and tablet options being hurled at you as a generic \"creative\" or \"creator\"? Marketing materials rarely distinguish among the widely varying needs for different pursuits; marketers basically consider anything with a discrete GPU (a graphics processor that's not integrated into the CPU), no matter how low power, suitable for all sorts of creative endeavors. That can get really frustrating when you're trying to wade through a mountain of choices.\nOn one hand, the wealth of options means there's something for every type of work, suitable for any creative tool and at a multitude of prices. On the other, it means you run the risk of overspending for a model you don't really need. Or more likely underspending, and ending up with a system that just can't keep up, because you haven't judged the trade-offs of different components properly.\nOne thing hasn't changed over time: The most important components to worry about are the CPU, which generally handles most of the final quality and AI acceleration for a growing number of smart features; GPU, which determines how fluidly your screen interactions are along with some AI acceleration as well; the screen; and the amount of memory. Other considerations can be your network speed and stability, since so much is moving up and down from the cloud, and storage speed and capacity if you're dealing with large video or render files.\nYou still won't find anything particularly budget-worthy for a decent experience. Even a basic model worth buying will cost at least $1,000; like a gaming laptop, the extras that make it worth the name are what differentiates it from a general-purpose competitor, and those always cost at least a bit extra.\nShould I get a MacBook Pro or a Windows laptop?\nIf what you're really wondering is whether the Mac is generally better than Windows for graphics, that hasn't been true for a while. Windows' graphics programming interface has gotten a lot better over time, which allows for broader support and better performance in the applications. But performing display calibration on both platforms can feel like walking barefoot over broken glass. Windows, because its color profile management seems like it hasn't changed since it originally launched in Windows NT, and MacOS because interface changes made in Monterey combined with ambiguity about supported calibrators, software and the new MacBook Pro screens has some folks gnashing their collective teeth.\nMacBook Pros now have native M1 processor support for most of the important applications, which includes software written to use Metal (CNET_TAG: Apple | Score: 1125"
    }
  ],
  "argos_summary": "When searching for a new laptop, consider your budget, as spending more typically yields better performance and features. Windows laptops offer a wider range of options and prices, while MacBooks are generally more expensive but highly rated. Key factors to evaluate include the operating system, screen size and resolution, processor type, graphics capabilities, and battery life. For those on a tight budget, Chromebooks can be a viable alternative for basic tasks.",
  "argos_id": "1FR65ZAHN"
}