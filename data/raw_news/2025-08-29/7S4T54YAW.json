{
  "url": "https://www.techspot.com/news/109264-growing-number-states-restricting-corporate-use-facial-recognition.html",
  "authorsByline": "Skye Jacobs",
  "articleId": "65ba28f9a2524a9484b2ff28cf7e45df",
  "source": {
    "domain": "techspot.com",
    "location": {
      "country": "us",
      "state": "FL",
      "county": "Miami-Dade County",
      "city": "Miami",
      "coordinates": {
        "lat": 25.7741728,
        "lon": -80.19362
      }
    }
  },
  "imageUrl": "https://www.techspot.com/images2/news/bigimage/2025/08/2025-08-29-image-27.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-29T10:29:00-05:00",
  "addDate": "2025-08-29T16:29:46.922628+00:00",
  "refreshDate": "2025-08-29T16:29:46.922630+00:00",
  "score": 1.0,
  "title": "A growing number of states are restricting corporate use of facial recognition",
  "description": "Colorado recently implemented new privacy rules requiring companies to obtain consent before using facial or voice recognition technology. The rules also prohibit the sale of biometric data....",
  "content": "A hot potato: US states are imposing stricter rules on how tech companies collect, analyze, and monetize biometric data, including facial features, iris patterns, and other unique identifiers. While no federal regulation currently governs facial recognition systems, the National Conference of State Legislatures reports that 23 states have passed or updated laws to limit the mass collection of biometric information.\n\nColorado recently implemented new privacy rules requiring companies to obtain consent before using facial or voice recognition technology. The rules also prohibit the sale of biometric data. In June, Texas introduced an AI law that bans the unauthorized collection of biometric identifiers, echoing similar consent-based regulations passed last year in Oregon, where companies must now secure explicit opt-in from consumers before collecting facial, eye, or voice data.\n\nFacial recognition technology has become a core feature of many consumer products and services, though industry attitudes have shifted over time. Meta, for example, shut down its facial recognition system in 2021 following a lawsuit over biometric privacy violations, but has since reintroduced the technology to combat celebrity investment scams.\n\nMeanwhile, advances in AI have driven facial recognition into everyday devices and applications. Pete Fussey, a professor at the University of Essex, told NPR that \"facial recognition is everywhere,\" adding that while consumers enjoy conveniences like unlocking phones and faster airport security checks, \"there's no downstream control over how our biometric data is used.\"\n\nAlthough most states have adopted some form of biometric protection, the scope and effectiveness of these laws vary widely. In several cases, these measures have led to substantial financial settlements with tech companies accused of violating privacy regulations.\n\nBoth Google and Meta paid a combined $1.4 billion after allegations that they mined Texans' facial recognition data without user consent. Another firm, Clearview AI, settled for $51 million over claims it collected billions of online facial images without proper authorization.\n\nIn Illinois, Google paid $9 million after a lawsuit alleged it failed to obtain written consent from students whose voice and facial data were recorded through an educational tool.\n\nThe Illinois Biometric Information Privacy Act , adopted in 2008, is notable for requiring written permission rather than a simple digital agreement \u2013 such as clicking a checkbox for a service's terms \u2013 and for allowing individuals to file lawsuits directly against companies. Legal scholar Michael Karanicolas of Dalhousie University called the standard digital consent model \"clearly ineffective,\" noting that \"nobody is reading these terms of service.\"\n\nHe highlighted that Illinois's law is unique in granting citizens the ability to sue, a mechanism that privacy advocates say the tech industry has strongly opposed. Only a handful of other states, including California and Washington, provide similar legal recourse.\n\nIn most states, enforcement is left to attorneys general. Advocates of citizen lawsuits, known as a \"private right of action,\" argue that this approach empowers residents to hold companies accountable for exploiting biometric data. \"And that can lead to these big class-action settlements\u2026 they can be genuinely effective at shaping companies' attitudes about personal information and generate corporate change,\" Karanicolas said.\n\nHowever, even the strongest privacy laws have limits when dealing with foreign-based firms. PimEyes, an overseas facial recognition service, allows users to search for matches based on facial features but does not follow the same safeguards as major US tech companies.\n\nAlthough Illinois law ostensibly bars PimEyes from operating locally, attorney Brandon Wise discovered that images of Illinois residents remained in its database among billions of others. Wise filed a class-action lawsuit on behalf of five Illinois residents, but efforts to serve the company in Georgia, Dubai, and Belize failed. After two years, the case was dropped. Wise said the process felt like \"suing a ghost.\"\n\nAt the federal level, several proposals have sought to increase transparency around facial recognition technology, including recent attempts to require the Transportation Security Administration to notify air travelers of their right to opt out of face screenings. However, progress has been slow.\n\nAdam Schwartz, litigation director at the Electronic Frontier Foundation, who has long advocated for national biometric protections similar to those in Illinois, says that technology companies have consistently opposed such measures, arguing they would harm profitability. \"But I think people are getting more and more fed up with tech companies ignoring their privacy,\" Schwartz said.",
  "medium": "Article",
  "links": [
    "https://www.npr.org/2025/08/28/nx-s1-5519756/biometrics-facial-recognition-laws-privacy",
    "https://www.techspot.com/news/104555-dutch-regulator-fines-clearview-ai-336-million-gdpr.html",
    "https://www.techspot.com/news/109253-age-checks-spread-across-us-critics-warn-privacy.html",
    "https://www.techspot.com/news/109135-clear-launches-biometric-egates-major-us-airports-ahead.html",
    "https://www.techspot.com/news/105240-meta-reintroduces-facial-recognition-combat-celebrity-scam-ads.html"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Facial recognition technology",
      "weight": 0.10227627
    },
    {
      "name": "facial recognition technology",
      "weight": 0.10227627
    },
    {
      "name": "facial recognition",
      "weight": 0.10153775
    },
    {
      "name": "facial recognition systems",
      "weight": 0.09768069
    },
    {
      "name": "facial features",
      "weight": 0.087344706
    },
    {
      "name": "tech companies",
      "weight": 0.08254006
    },
    {
      "name": "technology companies",
      "weight": 0.082219504
    },
    {
      "name": "online facial images",
      "weight": 0.081046194
    },
    {
      "name": "major US tech companies",
      "weight": 0.077312395
    },
    {
      "name": "biometric data",
      "weight": 0.07635575
    }
  ],
  "topics": [],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.91748046875
    },
    {
      "name": "/Law & Government/Government/Other",
      "score": 0.75146484375
    },
    {
      "name": "/People & Society/Social Issues & Advocacy/Other",
      "score": 0.640625
    },
    {
      "name": "/Computers & Electronics/Computer Security/Network Security",
      "score": 0.321533203125
    }
  ],
  "sentiment": {
    "positive": 0.050814852,
    "negative": 0.6875737,
    "neutral": 0.26161146
  },
  "summary": "US states are increasing restrictions on the use of facial recognition by tech companies, with 23 states passing or updating laws to limit the mass collection of biometric information. Colorado recently implemented new privacy rules requiring companies to obtain consent before using facial or voice recognition technology, and Texas introduced an AI law banning the unauthorized collection. The Illinois Biometric Information Privacy Act, adopted in 2008, is notable for requiring written permission rather than a simple digital agreement and allowing individuals to file lawsuits directly against companies. However, even the strongest privacy laws have limits when dealing with foreign-based firms. At the federal level, several proposals have been aimed at increasing transparency around facial recognition technology.",
  "shortSummary": "US states are implementing stricter privacy laws to limit biometric data collection by tech companies, despite widespread privacy concerns and limited legal protections against misuse.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "f8e3d837560c47a9a10f2e97615b97df",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.npr.org/2025/08/28/nx-s1-5519756/biometrics-facial-recognition-laws-privacy",
      "text": "With no federal facial recognition law, states rush to fill void\nStates are increasingly clamping down on how tech companies digitally scan and analyze our most sensitive and potentially lucrative commodity: the faces, eyeballs and other \"biometric\" data of millions of people.\nWhile facial recognition technology is unregulated at the federal level, 23 states have now passed or expanded laws to restrict the mass scraping of biometric data, according to the National Conference of State Legislatures.\nLast month, Colorado enacted new biometric privacy rules, requiring consent before facial or voice recognition technology is used, while also banning the sale of the data. Texas passed an artificial intelligence law in June that similarly outlaws the collection of biometric data without permission. Last year, Oregon approved data privacy rules requiring consumer opt-in before companies hoover up face, eye and voice data.\n\"What we need are laws that change the behavior of technology companies,\" Adam Schwartz, the privacy litigation director at the Electronic Frontier Foundation. \"Otherwise these companies will continue to profit on what should be our private information.\"\nTech companies have long been deploying facial recognition technology. At times, the industry has pulled back from it, like in 2021 when Facebook shut down its face-recognition system following a biometric privacy lawsuit.\nBut since cutting-edge AI systems have been incorporated in nearly every facet of modern life, the presence of some form of facial recognition technology in many apps and phones has become newly ubiquitous, said University of Essex professor Pete Fussey, who recently published a book on facial recognition in the AI era.\n\"Facial recognition is everywhere. And partially, we're complicit in that. We get a convenience dividend by being able to open our phones easily, or get through airports faster, or access our finances,\" Fussey said. \"But there's no downstream control over how our biometric data is used.\"\nNot all state laws give people right to sue tech companies\nThe states that have passed the safeguards view them as a defense against the prevalence of digital tracking in everyday lives, and in a number of cases, the laws have been used to extract large payouts from tech companies.\nGoogle and Meta have each paid Texas $1.4 billion over allegations that the companies datamine users' facial recognition data without permission; Clearview AI, a facial recognition company popular with law enforcement, ponied up $51 million to settle a case approved in March over the firm scraping billions of facial images online without consent; And in July, Google resolved a smaller case for $9 million in Illinois after a lawsuit alleged the company did not obtain written consent from students who used a Google educational tool that collected their voice and facial data.\nIllinois's requirement that companies receive written permission before gathering biometric data goes farther than most states, which require digital consent \u2014 or checking a box for a company's terms and conditions policy, something experts say is a largely symbolic gesture in practice.\n\"I'm not saying it's better than nothing, but if you're hanging these legal frameworks on a model of informed consent, it's clearly ineffective,\" said Michael Karanicolas, a legal scholar at Dalhousie University in Canada who studies digital privacy. \"Nobody is reading these terms of service. Absolutely nobody can effectively engage with the permission we're giving these companies in our surveillance economy.\"\nKaranicolas said Illinois' biometric privacy law, which was passed in 2008, has real teeth because it allows individuals to sue companies, which privacy advocates say the tech industry has lobbied hard against. California and Washington state allow residents to sue in some types of cases.\nBut most of the laws, like in Texas, Oregon, Virginia and Connecticut and elsewhere, rely on state attorneys general to enforce them. Advocates say allowing citizens to sue, what's known as \"a private right of action,\" helps people fight back against data-guzzling companies.\n\"And that can lead to these big class-action settlements, and there are legitimate critiques of them, with class members often getting very little money, and lawyers getting rich, but they can be genuinely effective at shaping companies' attitudes about personal information and generate corporate change,\" Karanicolas said.\nSuing PimEyes? Good luck finding them\nIn some instances, however, even the toughest digital privacy law cannot compete with evasive facial recognition companies operating overseas.\nPimEyes is a popular \"face search engine\" that finds matches across the web based on the distinctive features of someone's face without the safeguards that Google, Meta and other large tech companies employ.\nCritics of PimEyes have said the service can enable stalkers, identify porn performers and unearth photos of children.\nBut the company often promotes its service as a way to combat identity theft, deepfake porn, copyright infringement and a way to catch a dating app \"catfisher,\" or a person posing on a profile as another person.\nBecause of Illinois' strict privacy law, PimEyes has pulled out of the state and the site is not easily accessible there.\nStill, lawyer Brandon Wise found that the images of Illinois residents were still in the company's database among nearly 3 billion other searchable images, which he said is a violation of state law, since PimEyes got the images without consent. So, Wise filed a lawsuit representing five Illinois residents seeking class action status.\nBut the case never had its day in court. That's because PimEyes could not be found.\nWise's law firm attempted to serve PimEyes CEO Giorgi Gobronidze, who is based in the Georgian capital of Tbilisi to no avail. Wise found an address connected to him in Dubai, where he also could not be located.\nPimEyes appears to have a corporate headquarters in Belize, where Wise sent a process server, who could not find any official connected to the company.\nAfter the case was pending for nearly two years, it was finally dropped.\n\"It was incredibly frustrating,\" Wise said. \"But it felt like we were suing a ghost.\"\nPimEyes did not return a request for comment.\nIt's a lesson, Wise said, in the limitations of state privacy laws when attempting to go after digital surveillance companies that operate elusive overseas operations.\n\"We learned it's not that easy sometimes,\" he said.\n'People are getting fed up' with facial recognition\nIn Congress, various facial recognition bills have been introduced, including a recent proposal requiring the Transportation Security Administration to inform passengers of their right to opt out of face screenings, but it, like many before it, has stalled.\nSchwartz with the Electronic Frontier Foundation has lobbied Washington to pass a national biometric privacy law that mirrors Illinois' protections with no luck.\n\"And the singular reason is that tech companies show up and say, 'these laws would intrude on our profits,' and they hire lobbyists to influence the process,\" Schwartz said. \"But I think people are getting more and more fed up with tech companies ignoring their privacy.\""
    }
  ],
  "argos_summary": "The article reports that 23 U.S. states have enacted or expanded laws restricting the mass collection of biometric data, with recent examples in Colorado, Texas, and Oregon requiring consent and banning sales of facial or voice data. High-profile tech firms such as Google, Meta, and Clearview AI have paid combined settlements totaling $1.4\u202fbillion to Texas and other states for unauthorized data mining. Illinois\u2019s 2008 Biometric Information Privacy Act stands out by granting a private right of action, yet enforcement remains limited, especially against foreign companies like PimEyes that evade U.S. jurisdiction. Federal efforts to impose nationwide biometric protections have stalled, leaving state laws as the primary defense against pervasive facial\u2011recognition surveillance.",
  "argos_id": "7S4T54YAW"
}