{
  "url": "https://www.zdnet.com/article/why-xai-is-giving-you-limited-free-access-to-grok-4/",
  "authorsByline": "Webb Wright",
  "articleId": "0a74cc7a331442c9888f7b6b8223e840",
  "source": {
    "domain": "zdnet.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://www.zdnet.com/a/img/resize/526c42f1ecb732beb8126f735220d260ec8e7e62/2025/01/06/e8b9be27-a98f-43a4-b72c-859b9ef58b3a/grok.jpg?auto=webp&fit=crop&height=675&width=1200",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-11T18:24:31+00:00",
  "addDate": "2025-08-11T20:34:09.275475+00:00",
  "refreshDate": "2025-08-11T20:34:09.275476+00:00",
  "score": 1.0,
  "title": "Why xAI is giving you 'limited' free access to Grok 4",
  "description": "The move arrives days after the company's competitor, OpenAI, released GPT-5 at no cost to all users.",
  "content": "\u2022 Grok 4 is now accessible by default for unpaid xAI users\n\u2022 Restrictions around the \"limited\" free access period are unclear.\n\u2022 The move appears to be an effort to attract more paying users.\n\nElon Musk's AI start-up xAI has made its latest model, Grok 4, available to all users -- both paid and unpaid.\n\nGrok now automatically opens in Auto mode for users of the chatbot's free tier, meaning the system automatically determines whether or not a given query needs Grok 4's advanced reasoning capabilities, or if a more limited model will be up to the job (a similar approach to what OpenAI's new GPT-5 model aims to do). Users can also manually select \"Fast\" mode, which generates responses more quickly using Grok 3, or \"Expert\" mode, which exclusively uses Grok 4, taking more time to come up with higher-quality responses.\n\nAlso: GPT-5 bombed my coding tests, but redeemed itself with code analysis\n\nThe company announced the \"limited\" release in an X post on Sunday, though it didn't specify the number of messages that unpaid users could exchange with the chatbot over a given time period or any other restrictions.\n\n\"For a limited time, we are rolling out generous usage limits so you can explore Grok 4's full potential,\" the post read.\n\nEven Grok 4 itself was uncertain about the rules. \"Exact limits for Grok-4's free tier are unclear, as xAI hasn't publicly detailed them, and they may vary by region or account type,\" the chatbot wrote when I asked about the limits of the free access period. \"To be safe, expect around five to 10 messages per 12 hours with Grok-4 on the free tier, but you might hit the limit sooner if you use complex queries or during peak times.\"\n\nWhen xAI unveiled Grok 4 last month, Musk described it as \"the world's most powerful AI model,\" claiming it outperformed frontier models like Google's Gemini 2.5 Pro and OpenAI's 4o on several key benchmarks, including Humanity's Last Exam.\n\nAlso: How Google's Genie 3 could change AI video - and let you build your own interactive worlds\n\nSubscriptions to Grok's subscription tiers, SuperGrok and SuperGrok Heavy, still cost $30 per month and $300 per month, respectively.\n\nBy temporarily making Grok 4 available to all users, xAI appears to be angling in part to get its new model into the hands of as many people as possible -- a tactic ZDNET senior editor Sabrina Ortiz has been tracking. A percentage of those people may be impressed enough by the new model's abilities that, when they hit the limits of the free access window, they'll decide that it's worth upgrading to a paid subscription.\n\nxAI also plans to introduce ads into Grok's responses to help pay for the high costs of running and refining the model, the Financial Times reported Thursday.\n\nAlso: You can try Gemini Live in your favorite Google apps now, and it blew me away\n\nMusk announced in another X post Sunday that xAI users can now \"long press\" -- holding down on an icon for longer than just the usual quick tap of the thumb -- on any image to pull up an option to turn it into a video using AI. This could also ultimately be a play to draw in advertisers: Amazon recently debuted a similar AI-powered text-to-video feature.\n\nThe temporary release of Grok 4 to unpaid users comes just days after OpenAI -- with whom Musk has long had a very public squabble -- released GPT-5 to all users at once, a new approach for the company.\n\nAlso: GPT-5 bombed my coding tests, but redeemed itself with code analysis\n\nAs of Monday, GPT-5 occupied the top spot in multiple critical categories (including text-generation, vision, and coding) on LMArena, an online platform where users can rate and compare the performance of large language models. OpenAI's o3 model also defeated Grok 4 in the final round of Google Game Arena's chess tournament last week.\n\nGrok 4, however, outperformed GPT-5 by a hair in the ARC-AGI-2 -- a test designed to gauge AI models' high-level reasoning capabilities -- though at a much higher cost ($2.17 per task vs. $0.73 per task).",
  "medium": "Article",
  "links": [
    "https://arcprize.org/leaderboard",
    "https://grok.com/chat/18512352-9475-4d19-957a-a3ce589e1d9b#subscribe",
    "https://x.com/xai/status/1954573454214418820?utm_source=www.therundown.ai&utm_medium=newsletter&utm_campaign=openai-s-gpt-5-crisis-mode&_bhlid=ab43b00f6b9950491411fdf30490ca409c2de5f4",
    "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
    "https://www.zdnet.com/article/gpt-4o-update-gets-recalled-by-openai-for-being-too-agreeable/",
    "https://www.zdnet.com/article/musk-claims-new-grok-4-beats-o3-and-gemini-2-5-pro-how-to-try-it/",
    "https://www.zdnet.com/article/let-the-ai-games-begin-googles-new-game-arena-aims-to-test-machine-intelligence/",
    "https://x.com/elonmusk/status/1954493212581929093?utm_source=www.therundown.ai&utm_medium=newsletter&utm_campaign=openai-s-gpt-5-crisis-mode&_bhlid=9245dca356073594e44a4d9650ca993fd3b329d7",
    "https://www.ft.com/content/3bc3a76a-8639-4dbe-8754-3053270e4605",
    "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
    "https://www.zdnet.com/article/humanitys-last-exam-benchmark-is-stumping-top-ai-models-can-you-do-any-better/",
    "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
    "https://links.online.zdnet.com/s/vb/C7K2qwz-HeywYROWetlEp1NLtG0hXzpNu9-NVQ471HGvBtIuSF0PgJa2ZWY-TYx2Vd7Bb5cS0sb-z1GU8B6onbv9Roe2_W2O7hLBRFGgK6rHX7ZVGGIe5XbOGYPOdyPgEbwJeOsTJJk2XEfMDt4C2w/9rkZmayqKppO1-hrnxIUah1ZKWe5VuEI/11",
    "https://lmarena.ai/leaderboard",
    "https://www.zdnet.com/article/musk-makes-good-on-his-promise-and-launches-his-own-ai-company/",
    "https://www.zdnet.com/article/you-can-produce-video-ads-in-seconds-with-amazons-new-ai-tool-heres-how/",
    "https://www.zdnet.com/article/you-can-try-gemini-live-in-your-favorite-google-apps-now-and-it-blew-me-away/",
    "https://www.zdnet.com/article/openais-gpt-5-is-now-free-for-all-how-to-access-and-everything-else-we-know/",
    "https://www.zdnet.com/article/gpt-5-bombed-my-coding-tests-but-redeemed-itself-with-code-analysis/",
    "https://www.zdnet.com/article/how-googles-genie-3-could-change-ai-video-and-let-you-build-your-own-interactive-worlds/",
    "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/"
  ],
  "labels": [
    {
      "name": "Opinion"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "GPT-5 model",
      "weight": 0.090669714
    },
    {
      "name": "unpaid xAI users",
      "weight": 0.09062866
    },
    {
      "name": "xAI users",
      "weight": 0.089660786
    },
    {
      "name": "Grok",
      "weight": 0.08586902
    },
    {
      "name": "unpaid users",
      "weight": 0.08073029
    },
    {
      "name": "more paying users",
      "weight": 0.079146
    },
    {
      "name": "frontier models",
      "weight": 0.07873151
    },
    {
      "name": "large language models",
      "weight": 0.07590453
    },
    {
      "name": "Users",
      "weight": 0.07365178
    },
    {
      "name": "users",
      "weight": 0.07365178
    }
  ],
  "topics": [],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.84912109375
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.84814453125
    },
    {
      "name": "/Computers & Electronics/Programming/Other",
      "score": 0.310791015625
    }
  ],
  "sentiment": {
    "positive": 0.18963751,
    "negative": 0.23163189,
    "neutral": 0.5787306
  },
  "summary": "Elon Musk's AI start-up, xAI, has released its latest model, Grok 4, for free access to all users, both paid and unpaid, in an effort to attract more paying users. The release was announced in an X post, but it did not specify restrictions on the \"limited\" free access period. The company also plans to introduce ads into Grok's responses to help cover the high costs of running and refining the model. Subscriptions to Grok still cost $30 per month and $300 per month. This move comes just days after OpenAI released its new GPT-5 model to all all users at once, a new approach for the company.",
  "shortSummary": "XAI has launched Grok 4, its latest AI model, for free access to attract more paying users, with limited usage limits and possible ads, despite its advanced reasoning capabilities.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "b87cc7f479a84a89aba531f114ce709c",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.zdnet.com/article/you-can-produce-video-ads-in-seconds-with-amazons-new-ai-tool-heres-how/",
      "text": "You can produce video ads in seconds with Amazon's new AI tool - here's how\nThe process of creating advertisements is becoming a whole lot quicker with the help of generative AI.\nOn Tuesday, Amazon Ads announced that its new Video Generation platform -- initially launched in beta in September -- is now generally available for all US customers. The tool has also been given some technical upgrades. Most notably, its AI-generated videos are smoother and more realistic, and it also generates a series of six different videos, giving advertisers a set of creative options to choose from.\nA brand selling a coffee mug, for example, might upload an image of their product to the system, which would then generate a series of short videos displaying the product in various contexts: someone taking a sip from the mug as they read a book, maybe, or the cup sitting on a windowsill as the camera pans in front of it.\nAlso: Bing adds OpenAI's Sora video generator - and it's free\n\"Over the last nine months, we've continued to push the boundaries of what's possible, resulting in an enhanced version of Video Generator that creates more sophisticated, high-motion video ads where the product blends seamlessly into the action or scene,\" Jay Richman, Amazon's VP of product and technology, said in a statement.\nThe idea is to bring still images to life, giving viewers a more dynamic perspective, all while saving brands the time and expenses that traditionally would be required to complete a lengthy ad filming and production process. With that in mind, Amazon Ads is marketing its video-generating tool primarily to small-to-midsize businesses, whose budgets and production timelines are more constrained than their more deep-pocketed competitors.\nThe videos are generated in five minutes or less, and they also come with text animations, background music, and branded logo placement options.\nAI-generated video has been advancing at a rapid pace recently, as is evident in a short demo video (see link above) for the new Video Generation tool: the AI-generated depictions of people in motion are fluid and lifelike, with none of the unsettling extra fingers that were so prevalent in earlier video-generating models.\nThere are still some glitches, however. If you look closely at the watch depicted in the demo video, you'll notice the numbers on its face are improperly placed or illegible. It's not the sort of detail that most viewers are likely to notice, however, while they're quickly scrolling through product options on their phone or laptop. Most brands would probably reason that such imperfections are worthwhile in light of the savings the tool affords them.\nAmazon isn't the only major tech brand that's been equipping advertisers with new generative AI tools. Adobe, for example, has been promoting its suite of Firefly models in large part as a new and powerful creative tool for marketing teams. And last week it was reported that Meta is aiming to automate the entirety of the advertising production process.\nAlso: This new AI video editor is an all-in-one production service for filmmakers - how to try it\nBig tech developers like Amazon and Meta are promoting their generative AI tools as enhancements, rather than replacements, to human creativity. And despite some widely aired speculation in recent years about the supposedly inevitable job losses that will be caused by the proliferation of AI, such large-scale displacement doesn't seem to be happening -- not yet, anyway.\nStill, the release of Video Generator and tools of its ilk are likely to feed into fears of job displacement among professionals in advertising and other creative industries, no matter how much the companies in Silicon Valley promise that that isn't their intention.\nYou can access Video Generator now through Amazon Ads.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nThe best AI for coding in 2025 (including a new winner - and what not to use)\nI've been around technology long enough that very little excites me, and even less surprises me. But shortly after OpenAI's ChatGPT was released, I asked it to write a WordPress plugin for my wife's e-commerce site. When it did, and the plugin worked, I was indeed surprised.\nThat was the beginning of my deep exploration into chatbots and AI-assisted programming. Since then, I've subjected 14 large language models (LLMs) to four real-world tests.\nAlso: Apple's secret sauce is exactly what AI is missing\nUnfortunately, not all chatbots can code alike. It's been a little over two years since that first test, and even now, four of the 13 LLMs I tested can't create working plugins.\nThe short version\nIn this article, I'll show you how each LLM performed against my tests. There are now five chatbots I recommend you use.\nTwo of them, ChatGPT Plus and Perplexity Pro, cost $20 per month each. The free versions of the same chatbots do well enough that you could probably get by without paying. Two other recommended products are from Google and Microsoft. Google's Gemini Pro 2.5 is free, but you're limited to so few queries that you really can't use it without paying.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nMicrosoft has several Copilot licenses, which can get pricey, but I used the free version with surprisingly good results. The final one, Claude 4 Sonnet, is the free version of Claude. Oddly enough, the free version beat the paid-for version, so we're not recommending Claude 4 Opus.\nBut the rest, whether free or paid, are not so great. I won't risk my programming projects with them or recommend that you do, until their performance improves.\nI've written lots about using AIs to help with programming. Unless it's a small, simple project like my wife's plugin, AIs can't write entire apps or programs. But they excel at writing a few lines and are not bad at fixing code.\nRather than repeat everything I've written, go ahead and read this article: How to use ChatGPT to write code.\nIf you want to understand my coding tests, why I've chosen them, and why they're relevant to this review of the 13 LLMs, read this article: How I test an AI chatbot's coding ability.\nThe AI coding leaderboard\nLet's start with a comparative look at how the chatbots performed, as of this installment of our best-of roundup:\nNext, let's look at each chatbot individually. I'm back up to discussing 14 chatbots, because we're splitting out Claude 4 Sonnet and Claude 4 Opus as separate tests. GPT-4 is no longer included since OpenAI has sunsetted that LLM. Ready? Let's go.\n- Passed all tests\n- Solid coding results\n- Mac app\n- Hallucinations\n- No Windows app yet\n- Sometimes uncooperative\n- Price: $20/mo\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nChatGPT Plus with GPT-4o passed all my tests. One of my favorite features is the availability of a dedicated app. When I test web programming, I have my browser set on one thing, my IDE open, and the ChatGPT Mac app running on a separate screen.\nAlso: I put GPT-4o through my coding tests and it aced them - except for one weird result\nIn addition, Logitech's Prompt Builder, which can be activated with a mouse button, can be set up to utilize the upgraded GPT-4o and connect to your OpenAI account, allowing for a simple thumb tap to run a prompt, which is very convenient.\nThe only thing I didn't like was that one of my GPT-4o tests resulted in a dual-choice answer, and one of those answers was wrong. I'd rather it just gave me the correct answer. Even so, a quick test confirmed which answer would work. However, that issue was a bit annoying.\n- Multiple LLMs\n- Search criteria displayed\n- Good sourcing\n- Email-only login\n- No desktop app\n- Price: $20/mo\n- LLM: GPT-4o, Claude 3.5 Sonnet, Sonar Large, Claude 3 Opus, Llama 3.1 405B\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 4 of 4\nI seriously considered listing Perplexity Pro as the best overall AI chatbot for coding, but one failing kept it out of the top slot: how you log in. Perplexity doesn't use a username/password or passkey and doesn't have multi-factor authentication. All the tool does is email you a login PIN. The AI doesn't have a separate desktop app, as ChatGPT does for Macs.\nWhat sets Perplexity apart from other tools is that it can run multiple LLMs. While you can't set an LLM for a given session, you can easily go into the settings and choose the active model.\nAlso: Can Perplexity Pro help you code? It aced my programming tests - thanks to GPT-4\nFor programming, you'll probably want to stick to GPT-4o, because that model aced all our tests. But it might be interesting to cross-check your code across the different LLMs. For example, if you have GPT-4o write some regular expression code, you might consider switching to a different LLM to see what that model thinks of the generated code.\nAs we'll see below, most LLMs are unreliable, so don't take the results as gospel. However, you can use the results to check your original code. It's sort of like an AI-driven code review.\nJust don't forget to switch back to GPT-4o.\n- Price: Free for limited use, then token-based pricing\n- LLM: Gemini Pro 2.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThe last time I looked at Gemini, it failed miserably. Not quite as bad as Copilot at the time, but bad. Gemini Pro 2.5, however, has performed quite admirably. My only real issue with it is access. I found myself cut off from the free version after only running two of the four tests.\nAlso: Gemini Pro 2.5 is a stunningly capable coding assistant - and a big threat to ChatGPT\nI waited a day and then ran the third test, and got cut off again. Finally, on the third day, I ran my fourth test. Obviously, you can't do any real programming if you can only ask one or two questions before being shut down. So, if you sign up with Gemini Pro 2.5, be aware that Google charges by tokens (basically, the amount of AI you use). That can make it quite difficult to predict your expenses.\n- Price: Free for basic Copilot, or fees for other Copilot licenses\n- LLM: Undisclosed\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nIn all my previous analyses of Microsoft Copilot, the results were the worst of the LLMs. Copilot got nothing right. It was astonishing how bad it was. But I said then that, \"The one positive thing is that Microsoft always learns from its mistakes. So, I'll check back later and see if this result improves.\"\nAlso: I retested Microsoft Copilot's AI coding skills in 2025 and now it's got serious game\nAnd boy, did it ever. This time out, Microsoft passed all four of my tests. Even better, it did this with the free version of Copilot. Yes, Microsoft has many paid programs for Copilot, but if you want to give it the AI spin, point yourself to Copilot and use it.\n- Price: Free\n- LLM: Claude 4\n- Desktop browser interface: No\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThis is one of those times when AI implementations can be real head-scratchers. In our previous tests, Claude 4 Sonnet finished at the bottom of the barrel, failing all four of our tests. This time, however, Sonnet passed every test. So, what's the head-scratcher? Opus, the Claude 4 model, which is a fee-paid version, did not do as well: it failed half the tests.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nSo, yes. The free version worked like a champ. And the one you're paying anywhere from $20 to $250 a month for, depending on the plan? Well, that one failed half of the tests. Go figure.\n- Different LLM than ChatGPT\n- Good descriptions\n- Free access\n- Only available in browser mode\n- Free access likely only temporary\n- Price: Free (for now)\n- LLM: Grok-1\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4\nI have to say, Grok surprised me. I guess I didn't have high hopes for an LLM that appeared tacked on to the social network formerly known as Twitter. However, X is now owned by Elon Musk, and two of Musk's companies, Tesla and SpaceX, have towering AI capabilities.\nIt's unclear how much Tesla and SpaceX AI DNA is in Grok, but we can assume there will likely be more work. As of now, Grok is the only LLM not based on OpenAI LLMs that made it into the recommended list.\nAlso: X's Grok did surprisingly well in my AI coding tests\nGrok did make one mistake, but it was a relatively minor one that a slightly more comprehensive prompt could easily remedy. Yes, it failed the test. But by passing the others and even doing an almost perfect job on the one it passed, Grok earned itself a spot as a contender.\nStay tuned. This is an AI to watch.\n- Free\n- Passed most tests\n- Prompt throttling\n- Could cut you off in the middle of whatever you're working on\n- Price: Free\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4 in GPT-3.5 mode\nChatGPT is available to anyone for free. While both the Plus and free versions support GPT-4o, which passed all my programming tests, the free app has limitations.\nOpenAI treats free ChatGPT users as if they're in the cheap seats. If traffic is high or the servers are busy, the free version of ChatGPT will only make GPT-3.5 available to free users. The tool will only allow you a certain number of queries before it downgrades or shuts you off.\nAlso: How to use ChatGPT to write code - and my favorite trick to debug what it generates\nI've had several occasions when the free version of ChatGPT effectively told me I'd asked too many questions.\nChatGPT is a great tool, as long as you don't mind it shutting down. Even GPT-3.5 did better on the tests than all the other chatbots, and the test it failed was for a fairly obscure programming tool produced by a lone programmer in Australia.\nSo, if budget is important to you and you can wait when you're cut off, then use ChatGPT for free.\n- Free\n- Passed most tests\n- Range of research tools\n- Limited to GPT-3.5\n- Throttles prompt results\n- Price: Free\n- LLM: GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nI'm threading a pretty fine needle here, but because Perplexity AI's free version is based on GPT-3.5, the test results were measurably better than the other AI chatbots.\nAlso: 5 reasons why I prefer Perplexity over every other AI chatbot\nFrom a programming perspective, that's pretty much the whole story. However, from a research and organization perspective, my ZDNET colleague Steven Vaughan-Nichols prefers Perplexity over the other AIs.\nHe likes how Perplexity provides more complete sources for research questions, cites its sources, organizes the replies, and offers questions for further searches.\nSo, if you're programming, but also working on other research, consider the free version of Perplexity.\n- Free\n- Open source\n- Efficient resource utilization\n- Weak general knowledge\n- Small ecosystem\n- Limited integrations\n- Price: Free for chatbot, fees for API\n- LLM: DeepSeek MoE\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nWhile DeepSeek R1 is the new reasoning hotness from China that has all the pundits punditing, the real power right now (at least according to our tests) is DeepSeek V3. This chatbot passed almost all of our coding tests, doing as well as the (now mostly discontinued) ChatGPT 3.5.\nAlso: I tested DeepSeek's R1 and V3 coding skills - and we're not all doomed (yet)\nWhere DeepSeek V3 fell was in its knowledge of somewhat more obscure programming environments. Still, it beat Google's Gemini, Microsoft's Copilot, and Meta's Meta AI, which is quite an accomplishment. We'll be keeping a close watch on each DeepSeek model, so stay tuned.\nChatbots to avoid for programming help\nI tested 13 LLMs, and nine passed most of my tests this time around. The other chatbots, including a few pitched as great for programming, only passed one of my tests.\nAlso: The five biggest mistakes people make when prompting an AI\nI'm mentioning them here because people will ask, and I did test them thoroughly. Some of these bots are fine for other work, so I'll point you to their general reviews if you're curious about their functionality.\nDeepSeek R1\nUnlike DeepSeek V3, the advanced reasoning version, DeepSeek R1, did not showcase its reasoning capabilities in our programming tests. Unusually, the new failure area was one that's not all that hard, even for a basic AI -- the regular expression code for our string function test.\nAlso: Tech prophet Mary Meeker just dropped a massive report on AI trends - here's your TL;DR\nBut that's why we are running these real-world tests. It's never clear where an AI will hallucinate or just plain fail, and before you go believing all the hype about DeepSeek R1 taking the crown away from ChatGPT, run some programming tests. So far, while I'm impressed with the much-reduced resource utilization and the open-source nature of the product, its coding quality output is inconsistent.\nGitHub Copilot\nGitHub's Copilot integrates quite seamlessly with VS Code. The AI makes asking for coding help quick and productive, especially when working in context. That's why it's so disappointing that the code the AI outputs is often very wrong.\nAlso: I put GitHub Copilot's AI to the test - and it just might be terrible at writing code\nI can't, in good conscience, recommend you use the GitHub Copilot extensions for VS Code. I'm concerned that the temptation will be too great to insert blocks of code without sufficient testing -- and that GitHub Copilot's produced code is not ready for production use. Try again next year.\nClaude 4 Opus\nIn a completely baffling turn of events, the paid-for version of the Claude 4 model, Opus, failed half of my tests. What makes this result baffling is that the free version, Claude 4 Sonnet, passed them all. I don't know what to say apart from AI can be weird.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nMeta AI\nMeta AI is Facebook's general-purpose AI. As you can see above, it failed three of our four tests.\nAlso: 15 ways AI saved me time at work in 2024 - and how I plan to use it in 2025\nThe AI generated a nice user interface, but with zero functionality. It also found my annoying bug, which is a fairly serious challenge. Given the specific knowledge required to find the bug, I was surprised that the AI choked on a simple regular expression challenge. But it did.\nMeta Code Llama\nMeta Code Llama is Facebook's AI explicitly designed for coding help. It's something you can download and install on your server. I tested the AI running on a Hugging Face AI instance.\nAlso: Can Meta AI code? I tested it against Llama, Gemini, and ChatGPT - it wasn't even close\nWeirdly, even though both Meta AI and Meta Code Llama choked on three of four of my tests, they choked on different problems. AIs can't be counted on to give the same answer twice, but this result was a surprise. We'll see if that changes over time.\nBut I like [insert name here]. Does this mean I have to use a different chatbot?\nProbably not. I've limited my tests to day-to-day programming tasks. None of the bots has been asked to talk like a pirate, write prose, or draw a picture. In the same way we use different productivity tools to accomplish specific tasks, feel free to choose the AI that helps you complete the task at hand.\nThe only issue is if you're on a budget and are paying for a pro version. Then, find the AI that does most of what you want, so you don't have to pay for too many AI add-ons.\nIt's only a matter of time\nThe results of my tests were pretty surprising, especially given the significant improvements by Microsoft and Google. However, this area of innovation is improving at warp speed, so we'll be back with updated tests and results over time. Stay tuned.\nHave you used any of these AI chatbots for programming? What has your experience been? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://links.online.zdnet.com/s/vb/C7K2qwz-HeywYROWetlEp1NLtG0hXzpNu9-NVQ471HGvBtIuSF0PgJa2ZWY-TYx2Vd7Bb5cS0sb-z1GU8B6onbv9Roe2_W2O7hLBRFGgK6rHX7ZVGGIe5XbOGYPOdyPgEbwJeOsTJJk2XEfMDt4C2w/9rkZmayqKppO1-hrnxIUah1ZKWe5VuEI/11",
      "text": "Letter from the editor\nSabrina Ortiz, Senior Editor, AISeptember is typically referred to as Techtember around here because of the deluge of hardware launches. But this week, AI news kept us just as busy with the release of some of the most anticipated LLMs from OpenAI and Anthropic, revealing a bigger trend in where the industry is going. But first, let\u2019s take a speed run at the week\u2019s biggest announcements (buckle up).\nOpenAI set the tone for the week with the\nrelease of two new open-weight models.\nThis was major news because it was OpenAI's first public release of model weights since GPT-2 in 2019, and likely in response to the public\u2019s requests. The biggest beneficiaries are developers who can now build on, fine-tune, and even run the models locally for added security.\nThe same day, Anthropic announced its highly anticipated\nClaude Opus 4.1 model. When Claude Opus 4 launched in May, Anthropic called it the \"best coding model in the world,\" though our testing found it\ndidn\u2019t beat its free sibling model, Claude 4 Sonnet. Still, Opus 4.1 performed higher on SWE-bench Verified, which evaluates LLMs' abilities to solve real-world software engineering tasks sourced from GitHub. People have already\nbuilt some interactive coding projects using Opus 4.1 and a conversational prompt in minutes -- a task that could take hours.\nGoogle also got in on the action. Beyond unveiling its\nGenie 3 world model on Wednesday, the company\noffered its Google AI Pro plan for free to students 18 or older in the US, Japan, Indonesia, Korea, or Brazil. Normally $20 a month, the plan bundles all of Google's AI offerings, including the best models in Gemini and standalone tools such as NotebookLM, Jules, and Gemini 2.5 Pro.\nPerhaps the biggest launch of the week was\nOpenAI\u2019s GPT\u20135, a next-generation family of models the company touts as its fastest, smartest, and most capable yet. Already\navailable in Copilot, GPT-5\u2019s biggest appeal is that it combines a smart model for most queries with a deeper reasoning model for harder problems, choosing which to use based on the context of the prompt. In a huge break from OpenAI\u2019s norm, even free-tier users can access it.\nAnd it certainly appears capable. I watched a live demo of GPT-5 in which a user created a fully functional web app with interactive elements from just a text prompt. As someone who recently learned how to build webpages, that would have taken me hours to stylize using JavaScript and CSS.Also notable: Anthropic\nmade it easier to trigger a security review in Code Claude, OpenAI\nrolled out non-GPT-5 updates to ChatGPT, and Google\nembedded AI agents deeper into its data stack.\nThese launches made one thing clear: As\nAI adoption falters and\nhype cycle promises wane, companies are making more advanced models accessible to more people, hoping for a sea change. This looks like a potential new wave of AI democratization; instead of gatekeeping the most advanced models for the highest-paying customer, major players are letting everyone try them, whether that\u2019s a developer looking for open-weight models to build on or a free user looking for the best answer possible.\nGiving developers and the general public expanded access to the latest models and tools should unleash a future wave of innovation and make it easier than ever to build solutions. Only time will tell, but we can all agree that it is an exciting time for AI.\nFollow me on X, Instagram, and LinkedIn to see my latest coverage."
    },
    {
      "url": "https://www.zdnet.com/article/let-the-ai-games-begin-googles-new-game-arena-aims-to-test-machine-intelligence/",
      "text": "Watch AI models compete right now in Google's new Game Arena\nZDNET's key takeaways:\n- Google's new Game Arena will allow models to compete in games head-to-head.\n- You can tune in to the Game Arena at 12:30 p.m. ET Tuesday.\n- The effort could open the door to new business applications.\nAs artificial intelligence evolves, it's becoming increasingly difficult to accurately measure the performance of individual models.\nTo that end, Google unveiled on Tuesday the Game Arena, an open-source platform in which AI models compete in a variety of strategic games to provide \"a verifiable, and dynamic measure of their capabilities,\" as the company wrote in a blog post.\nAlso: OpenAI wins gold at prestigious math competition - why that matters more than you think\nThe new Game Arena is hosted in Kaggle, another Google-owned platform in which machine learning researchers can share datasets and compete with one another to complete various challenges.\nThis comes as researchers have been working on new kinds of tests to measure the capabilities of AI models as the field inches closer to artificial general intelligence, or AGI, an as-yet theoretical system that (as it's commonly defined) can match the human brain in any cognitive task.\nSerious play\nGoogle's new Game Arena initiative aims to push the capabilities of existing AI models while simultaneously providing a bounded framework for analyzing their performance.\n\"Games provide a clear, unambiguous signal of success,\" Google wrote in its blog post. \"Their structured nature and measurable outcomes make them the perfect testbed for evaluating models and agents. They force models to demonstrate many skills including strategic reasoning, long-term planning and dynamic adaptation against an intelligent opponent, providing a robust signal of their general problem-solving intelligence.\"\nCritically, games are also scalable; it's easy to increase the level of difficulty, thus theoretically pushing the models' capabilities.\n\"The goal is to build an ever-expanding benchmark that grows in difficulty as models face tougher competition,\" the blog post notes.\nUltimately, the initiative could lead to advancements beyond the realm of games. Google noted in its blog post that as the models become increasingly adept at gameplay, they could exhibit surprising new strategies that reshape our understanding of the technology's potential.\nIt could also help to inform R&D efforts in more economically practical arenas: \"The ability to plan, adapt, and reason under pressure in a game is analogous to the thinking needed to solve complex challenges in science and business,\" Google said.\nAll fun and games\nArtificial intelligence has always been about games.\nThe field emerged in the mid-20th century in conjunction with game theory, or the mathematical study of strategic interaction between competing entities. Today's models \"learn\" essentially by playing millions of rounds of games against themselves and refining their performance based on how well they achieve some predetermined goal, which can range from predicting the next token of text to generating a video depicting real-world physics.\nGames have also long been an important benchmark that AI researchers have used to assess model performance and capability. Meta's Cicero, for example, was trained to analyze millions of games of the board game Diplomacy played by humans. Through a large language model, Cicero learned to play Diplomacy by typing the words it believed a human player would say in each move. Its performance was then measured through gameplay with human users, who assessed its ability to make strategic decisions and communicate those through natural language.\nAlso: My 8 ChatGPT Agent tests produced only 1 near-perfect result - and a lot of alternative facts\nAnd unlike more esoteric industry benchmarks like the International Math Olympiad, games offer a poignant context for the average layperson. It may not mean much to non-experts when they hear that an AI model beat human experts at debugging computer code, for example, but it packs a weighty emotional punch when a chess grandmaster, say, is defeated by a computer, as happened for the first time in 1997 when IBM's Deep Blue defeated Gary Kasparov.\nGames can also help to reveal new and unexpected behavior from algorithms. One of the most famous (or infamous, depending on your point of view) moments from the history of AI was AlphaGo's \"Move 37\" during the model's historic 2016 game against Go champion Lee Sedol. In the moment, the move vexed human experts, who said it defied logic. But as the game progressed, it became clear that the move had in fact been a stroke of unconventional and creative brilliance, one that allowed AlphaGo to defeat Sedol.\nYou can tune in to the Game Arena at 12:30 p.m. ET on Tuesday to watch a chess showdown between eight frontier AI models."
    },
    {
      "url": "https://www.zdnet.com/article/gpt-5-bombed-my-coding-tests-but-redeemed-itself-with-code-analysis/",
      "text": "GPT-5 bombed my coding tests, but redeemed itself with code analysis\nZDNET's key takeaways\n- GPT-5 Pro delivers the sharpest, most actionable code analysis.\n- A detail-focused prompt can push base GPT-5 toward Pro results.\n- o3 remains a strong contender despite being a GPT-4 variant.\nWith the big news that OpenAI has released GPT-5, the team here at ZDNET is working to learn about and communicate its strengths and weaknesses. In another article, I put its programming prowess to the test and came up with a less-than-impressive result.\nAlso: I tested GPT-5's coding skills, and it was so bad that I'm sticking with GPT-4o\nWhen Deep Research first appeared with the OpenAI o3 LLM, I was quite impressed with what it could understand from examining a code repository. I wanted to know how well it understood the project just from the available code.\nIn this article, I'm examining how well the three GPT-5 variants do in examining that same code repository. We'll dig in and compare them. The results are quite interesting. Here are the four models.\n- o3: a GPT-4 variant optimized for reasoning.\n- GPT-5: OpenAI's new main ChatGPT model, available to all tiers, including free.\n- GPT-5 Thinking: A variant of GPT-5 that OpenAI says is optimized for \"architectural reflection.\" It is available to $20/mo Plus and $200/mo Pro tiers.\n- GPT-5 Pro: OpenAI's current $200/mo top-tier model, with the highest reasoning and context capabilities.\nI gave all four models the same assignment. I connected them to my private GitHub repository for my open-source free WordPress security plugin and its freemium add-on modules, selected Deep Research, and gave them this prompt.\nExamine the repository and learn its structure and architecture. Then report back what you've learned.\nFor those models that asked to choose areas of detail about what I wanted, I gave them this prompt.\nEverything you can tell me, be as comprehensive as possible.\nAs you can see, I didn't provide any context other than the source code repo itself. That code has a README file, as well as comments throughout the code, so there was some English-language context. But most of the context has to be derived from the folder structure, file names, and code itself.\nAlso: The best AI for coding in 2025 (and what not to use)\nFrom that, I hoped that the AIs would assess its structure, quality, security posture, extensibility, and possibly suggest improvements. This should be relevant to ZDNET readers because it's the kind of high-judgement, detail-oriented work that AIs are being used for. It certainly can make coming up to speed on an existing coding project easier, or at least provide a foundation for initial understanding.\nTL;DR summary\nOther than the two prompts above, I didn't give the LLMs any guidance about what to tell me. I wanted to see how they evaluated the repository and what sort of analysis they could provide.\nAs you can see from this table, overall coverage was quite varied in scope. More checks mean more depth of coverage.\nTo create this aggregate, topics like \"Project Purpose & Architecture,\" \"System Architecture,\" and \"Plugin Design & Integration\" were all normalized under Purpose/Architecture. Directory/File Structure contained any section mapping folders and files. Execution flow combines anything about how the software code runs. Recommendations/Issues combines all discussions of modernization suggestions, open issues, and minor red flags.\nIn terms of overall value, I'd rank the four LLMs as follows (from best to least best).\n- GPT-5 Pro: Most precise, engineering-ready, and actionable.\n- GPT-5: Widest scope, excellent mapping, and defensive-coding insight.\n- o3: Concise, modernization-focused, but lighter on underlying architecture.\n- GPT-5 Thinking: Best onboarding narrative, least evaluative depth.\nPro, of course, is only available in the $200/mo ChatGPT Pro tier. Later in this article, I'll show one way to modify the above prompts to get GPT-5 (non-Pro) to provide a fairly close approximation of the overall depth of the Pro response.\nGPT-5 Thinking, which is a model available in the $20/mo Plus plan, was the least helpful of the group. The GPT-4 generation o3 Deep Thinking model still holds up, but you can see how its self-directed focus is a bit different from the other two.\nAlso: Google's Jules AI coding agent built a new feature I could actually ship - while I made coffee\nMy main conclusion is that I was a bit surprised about how close the models were to each other. GPT-5, as OpenAI promised, did seem to provide a jump in overall cognition and usefulness, but nothing I would consider game-changing.\nWith that, let's dive into some specific examples that help illustrate my conclusions. Each of these sections is pulled from the various reports generated and shows you how each model provided similar information.\nSecurity posture, according to the models\nBelow, you can see how GPT-5 Pro names exact mechanisms (like file-top guard, nonces, manage_options). I've provided exact snippets here from the reports generated by all four models. GPT-5 affirms best practices but keeps it conceptual. o3 describes what happens (redirects/login flow) more than how it's hardened. GPT-5 Thinking gives the clearest \"what runs when\" story for new developers coming up to speed on the repo.\nGPT-5 Pro: Most concrete, code-level\n\"It guards against direct file access (if (!defined('ABSPATH')) exit; at the top of PHP files). It sanitizes input where appropriate \u2026 using WordPress nonces in AJAX handlers. It uses capability checks (e.g., adding menu pages only for users with manage_options capability \u2026 only admins see those tools). The code tries not to load unnecessary things \u2026 like only loading certain admin files on certain contexts.\"\nGPT-5: Correct, but higher-level\n\"There are checks for WordPress functions before use \u2026 so the plugin behaves gracefully even on very old WordPress setups. The plugins often guard against direct file access by checking \u2026 to prevent security issues from accessing .php files directly. Add-ons verify the presence of core before proceeding \u2026 and show an admin error if CMB2 isn't loaded.\"\no3: Runtime behavior, less on hardening specifics\n\"Purpose: My Private Site locks down an entire site so only logged-in users can view content \u2026 while protecting the rest. Overall architecture: [it] integrates deeply with WordPress's hook system and login/logout events to manage redirects and track login state.\"\nGPT-5 Thinking: Clear execution flow, onboarding tone\n\"Admin vs Front-end: It checks is_admin() to determine context. If on the front-end (not admin), it retrieves the saved privacy setting and, when enabled, hooks at a point like template_redirect to redirect unauthorized visitors. Throughout this initialization, the plugin uses WordPress hooks (actions and filters) to integrate functionality.\"\nLicensing and update mechanism, according to the models\nGPT-5 Pro didn't just describe the system; it walked through the process in sequential operational steps, almost like a short runbook you could hand to a developer or QA tester. GPT-5 confirms the architecture but abstracts the plumbing. GPT-5 Thinking adds a helpful \"how add-ons plug into the Licenses tab\" detail. o3 largely leaves licensing internals on the cutting room floor in favor of a fairly unhelpful modernization critique.\nGPT-5 Pro: Explains it step-by-step\n\"The core plugin provides utility functions to get and store license keys in a centralized option (jr_ps_licenses) and to contact the EDD license server for validation. Each extension plugin defines its own updater using EDD_SL_Plugin_Updater, passing the current version, the license key from the centralized store, and the EDD store URL. The core plugin's UI has a 'Licenses' tab, and extensions inject their own license fields via filters.\"\nGPT-5: Conceptual, but accurate\n\"License integration: The core plugin centralizes license management \u2026 and the add-ons piggyback on the core's licensing mechanism, integrating their license fields into the core plugin's interface.\"\no3: Barely mentions this topic at all\nThe o3 report spends most of its time on modernization and architecture. It discusses configuration and update behavior but does not walk through option keys, updater classes, or the Licenses UI wiring with the same procedural detail as GPT-5 and GPT-5 Pro. So there's nothing here to quote as a demonstration.\nGPT-5 Thinking: Good UI and extensibility observation\n\"The add-ons heavily rely on hooks provided by core or WordPress: They use add_filter/add_action calls to insert their logic \u2026 and use WordPress action hooks to integrate their license fields into the Licenses tab that the core plugin triggers when building the Licenses tab.\"\nState management, according to the models\nBoth GPT-5 Pro and GPT-5 explicitly pointed out how my code uses \"one option array + prune + no-op writes,\" which is a WordPress best practice for code maintainability. Both o3 and GPT-5 Thinking describe the lifecycle and effects (what's initialized, what loads when) rather than the exact option structure.\nGPT-5 Pro: Looks at specific storage pattern\n\"Settings are stored in a single serialized option \u2026 initialization routines add default keys, prune deprecated ones, and only update the option in the database if there is an actual change, avoiding unnecessary writes.\"\nGPT-5: Also looks at storage pattern, but more generally\n\"State Management: Plugin settings are stored in WordPress options as a central settings array and the code ensures defaults are applied while removing deprecated ones on each load, but only writes to the database when changes occur.\"\no3: Identifies intent and behavior, but doesn't discuss internals\n\"The main plugin initializes defaults (installed version, first-run timestamp, etc.). On each run it ensures these options exist and, if the privacy feature is disabled, the enforcement hook is not added.\"\nGPT-5 Thinking: Discusses basic flow and modules\n\"Module includes: includes admin and common modules in the back-end; on the front-end it retrieves the saved privacy setting and, when enabled, loads enforcement logic (e.g., in template_redirect). It registers a deactivation hook to clean up on deactivation (e.g., deleting a flag option).\"\nWhat does this mean for GPT-5?\nI was unimpressed with GPT-5 when it came to my coding tests. It failed half of my tests, an unprecedentedly bad result for what has previously been the gold standard in passing coding tests.\nBut GPT-5 was quite impressive in its analysis of the GitHub repository. It could be a powerful tool for onboarding new programmers, for someone adopting code, or simply for coming back up to speed on a project that's been untouched for a while.\nAlso: How I test an AI chatbot's coding ability - and you can, too\nThe GPT-4 generation o3 model is known to be a strong reasoning model, which is why it has been the basis for ChatGPT Deep Research. But GPT-5 was able to combine both breadth and detail, which is where o3 and GPT-4o were weak in previous tests.\nThe older models did give accurate summaries and useful suggestions, but they missed interconnections. For example, the older models were never able to show how UI flows, licensing, and update mechanisms work together.\nEven the base version of GPT-5 was able to identify cross-cutting concerns without additional prompting. Repository structure, backward compatibility, performance characteristics, and state management patterns all appeared in the first draft. Trying to get GPT-4 to span subjects is often an exercise in deep frustration.\nI found GPT-5's ability to understand and explain a complex interconnected system like my security product, all in one pass, to be a substantial improvement over the GPT-4 generation.\nIs GPT-5 Pro worth $200/mo?\nMaybe. If you're in a real rush to get to know a project and want as much of a data dump as possible as quickly as possible, yes. If you're operating on a big programming budget and $200/mo doesn't matter to you, yes.\nBut I find that cost hard to bear, especially when I have to subscribe to a wide range of AI services to evaluate them. So, now that I'm nearing the end of my one-month test of Pro-level activities, I'm planning on downgrading back to the $20/mo Plus plan.\nAlso: How to use GPT-5 in VS Code with GitHub Copilot\nPro's edge over GPT-5 wasn't about knowing more facts; it was about delivering those facts in a form you can act on immediately. The Pro report didn't just explain that security looked good; it cited the exact guards and checks in the code. It didn't just say licensing was centralized; it mapped the exact functions and database options involved.\nAgain, if you're on a time crunch, you might consider Pro. But I also think you can modify the base GPT-5's responses, with detail like the Pro report produced, simply by using better prompting.\nThat's next\u2026\nHow to get Pro-level results from base GPT-5\nI fed both the GPT-5 and GPT-5 Pro reports into GPT-5 and asked it for a prompt that would push the base-level GPT-5 to give GPT-5 Pro comprehensiveness as a result. This is that prompt, which you should add to any query where you want more complete coding information:\n*High-Specificity Technical Mode: ***In your answer, combine complete high-level coverage with exhaustive implementation-level detail.\n- Always name exact constants, functions, classes, hooks, option names, database tables, file paths, and build tools where possible, quoting them exactly from the code or material provided.\n- For every claim, explain why it's true and how you can tell (include reasoning tied to the evidence).\n- For each improvement you suggest, make it actionable and reference where in the codebase it applies.\n- Do not generalize when specifics are available.\n- Structure the output so a developer could use it directly to verify findings or implement recommendations.\nThis worked fantastically well. It took ChatGPT GPT-5 12 minutes to produce a 15,477-word document, complete with analysis and coding blocks. For example, it describes how value initialization is done, and then shows the code that accomplishes it.\nI think you could fine-tune this prompt and get Pro-level results without having to pay the $200/mo fee. I'm certainly going to tinker with this idea, possibly using GPT-5 to refine the specifications in the prompt for different areas I want to delve deeply into. I'll let you know how it goes.\nSee for yourself\nI had some difficulty setting up sharing for each of these long reports, so I just copied the results into Google Docs and shared them. Here are the links if you want to look at any of these reports.\n- o3 Deep Research\n- GPT-5 Deep Research\n- GPT-5 Thinking Deep Research\n- GPT-5 Pro Deep Research\n- GPT-5 Deep Research with Detail Prompt\nYou are welcome to dig into these documents and learn how my project is structured. While you may or may not care about my project, it's instructive to see how the various models perform. While you can read the reports, my actual repo is restricted since it's my private development repository.\nWhat about you? Have you tried using GPT-5 or GPT-5 Pro to analyze your own code? How did its insights compare to earlier models like GPT-4 or o3? Do you think the $200/month Pro tier is worth it for the extra precision, or could you get by with better prompts in the base version? Have you found AI code analysis useful for onboarding, refactoring, or improving security? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/how-googles-genie-3-could-change-ai-video-and-let-you-build-your-own-interactive-worlds/",
      "text": "How Google's Genie 3 could change AI video - and let you build your own interactive worlds\nZDNET's key takeaways:\n- World models could help to advance AI research, entertainment, etc.\n- Genie 3, Google DeepMind's world model, debuted on Tuesday.\n- Google DeepMind says Genie 3 has an \"understanding\" of the world.\nImagine exploring a virtual environment without boundaries, where everything you see looks and behaves just as it would in reality.\nThis is precisely what many tech developers today are working to create through AI \"world models,\" or algorithms that can build and act upon internal, representative models of the real world, imitating the human brain's ability to make predictions about the behavior of physical objects.\nAlso: Google's Veo 3 can now create an 8-second video from a single image - how to try it\nWorld models like Google DeepMind's new Genie 3 could have huge ramifications for AI agents, robotics, entertainment, education, and many other fields.\nHere's a look at what AI world models are, how they work, and why they matter.\nWhat are AI world models?\nJust as you're able to imagine sunlight illuminating the fixtures of your living room, or the effect that a stone dropped into a still pond will have on the water's surface, an AI \"world model\" can do more than just string words together or generate a lifelike image. It can make accurate predictions about the real world based on an ability to reason about how the basic physical mechanics of the world actually work.\nThis has particularly important implications for the field of AI-generated video. It's one thing for a model to watch millions of videos of a glass falling to the floor and shattering, and using that as a basis to generate new videos of the same event. It's another for a model to intuitively grasp the physics of gravity, the distance that broken glass should scatter on carpet versus a tile floor, and the fact that a human hand carelessly touching one of those shards could lead to a wound and bleeding.\nThis has become the latter goal of major AI developers: AI world models that don't just mimic scenarios, but can actually predict a virtually infinite number of new ones.\nOpenAI's Sora, for example, which was unveiled in February of last year and was an early example of a world model, shocked the AI community with its ability to simulate real-world physics, such as light reflecting off pools of water on a simulated street.\nGenie 3\nGenie 3 is another illustrative example of the power of a world model.\nFrom a simple natural language prompt, Genie 3 can generate dynamic simulations of virtual environments that evolve and change in response to a user's actions. (Its predecessors, Genie and Genie 2, debuted last year in February and December, respectively.)\nAlso: You can turn your Google Photos into video clips now - here's how\nUnlike classic video games, which come with clearly bounded virtual spaces, world models like Genie 3 are able to expand their simulated environments as users interact with them.\n\"You're not walking through a pre-built simulation,\" a narrator says in a demo video introducing Genie 3. \"Everything you see here is being generated live, as you explore it.\"\nGenie 3 comes with a feature Google DeepMind is calling \"world memory,\" which allows the model to represent changes that persist across time in the simulated environments. In the demo video, for example, a user is shown painting a wall with a paint roller; when they turn away and then direct their gaze back at the wall, the marks they made with the roller are still visible.\nIf you find yourself feeling bored while exploring a simulated environment, you can shake things up by prompting Genie 3 to cause an event. Something like: \"A man on horseback carrying a bag full of money is being chased by Texas rangers, who are also riding horses. All of the hooves are kicking up huge plumes of dust.\"\n\"We're excited to see how Genie 3 can be used for next-generation gaming and entertainment,\" the narrator says in the demo video, \"and that's just the beginning.\"\nWhy do world models matter?\nAs the narrator in the Genie 3 demo video suggests, world models could have valuable applications beyond helping to generate more realistic, dynamic, and interactive forms of entertainment.\nFor example, they could help the AI industry build embodied agents that can navigate and interact with the real world. (This has been the challenge that the autonomous vehicle industry has been trying to overcome since its inception, largely without success.)\nAlso: This new AI video editor is an all-in-one production service for filmmakers - how to try it\nThey could also be used to simulate what the Genie 3 demo describes as \"dangerous scenarios,\" such as the scene of a recent natural disaster, to help first responders prepare for actual emergencies. Coupled with virtual reality headsets, immersion into world models could also help first responders to build muscle memory so that they can be better equipped to act calmly under duress.\nEducation could also benefit from the use of world models, especially in the case of students who are more receptive to visual information.\nDo world models really \"understand\" the real world?\nTrained on copious amounts of real-world data, algorithms gradually refine their ability to make predictions. Eventually -- in a process that researchers are still working to understand -- they can become so adept at this that, for all intents and purposes, we can say that they seem to \"understand\" some aspects of the world, such as the syntax of the English language or the physics of human body movement.\nIn its blog post, Google DeepMind defined world models as \"AI systems that can use their understanding of the world to simulate aspects of it, enabling agents to predict both how an environment will evolve and how their actions will affect it.\"\nAlso: This interactive AI video generator feels like walking into a video game - how to try it\nThe use of the word \"understanding\" in this context is controversial, however; some experts argue that AI can only reproduce patterns and, therefore, could never understand a concept in the way a human being can, while others take the opposite view, claiming that perhaps human understanding is nothing more than a sophisticated kind of pattern recognition.\nIf you blindfolded yourself and tried to walk through every room in your house, you could probably do so without injuring yourself or breaking something (assuming you've lived there a while). Similarly, today's AI models are able to explore latent spaces of information in a manner that seems, at least to us humans, like they know the lay of the land.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI found 5 AI content detectors that can correctly identify AI text 100% of the time\nHow hard is it in 2025 -- just three years after generative AI captured the global spotlight -- to fight back against AI-generated plagiarism?\nAlso: Anthropic's AI agent can now automate Canva, Asana, Figma and more - here's how it works\nThis is a completely updated version of my January 2023 article on AI content detectors. When I first tested these detectors, the best result was 66% correct from one of three available checkers. My most recent set of tests, in February 2025, used up to 10 checkers -- and three of them had perfect scores. This time, just a couple of months later, five detectors boasted perfect scores.\nWhat I'm testing for and how I'm doing it\nBefore I go on, though, let's discuss plagiarism and how it relates to our problem. Merriam-Webster defines \"plagiarize\" as \"to steal and pass off (the ideas or words of another) as one's own; use (another's production) without crediting the source.\"\nThis definition fits AI-created content well. While someone using an AI tool like Notion AI or ChatGPT isn't stealing content, if that person doesn't credit the words as coming from an AI and claims them as their own, it still meets the dictionary definition of plagiarism.\nAlso: The dead giveaway that ChatGPT wrote your content - and how to work around it\nTo test the AI detectors, I'm using five blocks of text. Two were written by me and three were written by ChatGPT. To test a content detector, I feed each block to the detector separately and record the result. If the detector is correct, I consider the test passed; if it's wrong, I consider it failed.\nWhen a detector provides a percentage, I treat anything above 70% as a strong probability -- whether in favor of human-written or AI-written content -- and consider that the detector's answer. If you want to test a content detector yourself using the same text blocks, you can pull them from this document.\nThe overall results\nTo evaluate AI detectors, I reran my five-test series across 10 detectors. In other words, I cut and pasted 50 individual tests (I had a lot of coffee).\nDetectors I tested include BrandWell, Copyleaks, GPT-2 Output Detector, GPTZero, Grammarly, Monica, Originality.ai, QuillBot, Undetectable.ai, Writer.com, and ZeroGPT.\nAlso: How I personalized my ChatGPT conversations - why it's a game changer\nFor this update, I added Copyleaks and Monica. I dropped Writefull from my tests because it discontinued its GPT detector. Content Guardian requested inclusion, but I didn't hear back in time for testing accounts.\nThis table shows overall results. As you can see, five detectors correctly identified human and AI text in all tests.\nI tried to ascertain whether there was a tangible pattern of improvement over time, so I constructed a chart comparing the five-test set over time. So far, I've run this series six times, but there's no strong trend. I did increase the number of detectors tested and swapped out a few, but the only consistent result is that Test 5 was reliably identified as human across detectors and dates.\nI'll continue to test over time, and hopefully I'll see reliability trend consistently upward.\nWhile there have been some perfect scores, I don't recommend relying solely on these tools to validate human-written content. As shown, writing from non-native speakers often gets rated as generated by an AI.\nEven though my hand-crafted content has mostly been rated human-written this round, one detector (GPTZero) declared itself too uncertain to judge, and another (Copyleaks) declared it AI-written. The results are wildly inconsistent across systems.\nAlso: The best AI chatbots: ChatGPT, Copilot, and notable alternatives\nBottom line: I would advocate caution before relying on the results of any -- or all -- of these tools.\nHow each AI content detector performed\nNow, let's look at each individual testing tool, listed alphabetically.\nBrandWell AI Content Detection (Accuracy 40%)\nThis tool was originally produced by an AI content generation firm, Content at Scale. It later migrated to BrandWell.ai, a new name for an AI-centric marketing services company.\nAlso: AI-generated images are a legal mess - and still a very human process\nUnfortunately, its accuracy was low. The tool was unable to tell if the AI-generated content in Test 2 was human or AI, as shown in this screenshot:\nCopyleaks (Accuracy 80%)\nI find it amusing that Copyleaks declares itself \"the most accurate AI detector with over 99% accuracy\" when more than half of tested detectors performed better. But marketing folks will be marketing folks -- superlatives are as hard for them to resist as barking at a squirrel (and the FedEx truck, and all the neighbor kids) is for my dog.\nAlso: 5 quick ways Apple's AI tools can fine-tune your writing on the fly\nThe company's primary offering is a plagiarism checker sold to educational institutions, publishers, and enterprises seeking to ensure content originality and uphold academic integrity.\nGPT-2 Output Detector (Accuracy 60%)\nThis tool was built using a machine-learning hub managed by New York-based AI company Hugging Face. While the company has received $40 million in funding to develop its natural language library, the GPT-2 detector appears to be a user-created tool using the Hugging Face Transformers library.\nGPTZero (Accuracy 80%)\nGPTZero has clearly been growing. When I first tested it, the site was bare-bones -- it wasn't even clear whether GPTZero was a company or just someone's passion project. Now, the company has a full team with a mission of \"protecting what's human.\" It offers AI validation tools and a plagiarism checker.\nAlso: The most popular AI tools of 2025 (and what that even means)\nUnfortunately, performance seems to have declined. In my last two runs, GPTZero correctly identified my text as human-generated. This time, it declared that same text as AI-generated.\nGrammarly (Accuracy 40%)\nGrammarly is well known for helping writers produce grammatically correct content -- that's not what I'm testing here. Grammarly can check for plagiarism and AI content. In the grammar checker, there's a Plagiarism and AI Text Check button in the lower-right corner:\nI'm not measuring plagiarism checker accuracy here, but even though Grammarly's AI-check accuracy was poor, the site correctly identified the test text as previously published.\nMonica (Accuracy 100%)\nMonica is a new entrant. This service offers an all-in-one AI assistant with a wide range of services. Users can choose from various large language models.\nAlso: 5 ways ChatGPT can help you write essays\nThe company calls Monica the \"Best AI Detector Online,\" but it looks like it runs content through other detectors including ZeroGPT, GPTZero, and Copyleaks. Weirdly, both GPTZero and Copyleaks didn't perform well in my tests, but Monica -- and ZeroGPT -- did.\nWe're giving it 100% because it earned that rating, but I'll see how it stands up in future tests.\nOriginality.ai (Accuracy 100%)\nOriginality.ai is a commercial service that bills itself as an AI and plagiarism checker. The company sells usage credits: I used 30 credits for this article. They sell 2,000 credits for $12.95 per month. I pumped 1,400 words through the system and used just 1.5% of my monthly allocation.\nQuillBot (Accuracy 100%)\nThe last few times I tested QuillBot, results were wildly inconsistent -- multiple passes of the same text yielded wildly different scores. This time, however, it was rock solid and 100% correct. So I'm giving it the win. I'll check back in a few months to see if it holds onto this performance.\nUndetectable.ai (Accuracy 100%)\nUndetectable.ai's big claim is that it can \"humanize\" AI-generated text so detectors won't flag it. I haven't tested that feature -- it bothers me as a professional author and educator, because it seems like cheating.\nAlso: Why you should ignore 99% of AI tools - and which four I use every day\nHowever, the company also has an AI detector, which was very much on point.\nThe AI detector passed all five tests. Notice the indicators showing flags for other detectors. The company said, \"We developed multiple detector algorithms modeled after those major detectors to provide a federated and consensus-based approach. They do not directly feed into the listed models; rather, the models are each trained based on results they've generated. When it says those models flagged it, it's based on the algorithm we created and updated for those models.\"\nAlso: Only 8% of Americans would pay extra for AI, according to ZDNET-Aberdeen research\nI do have a question about the OpenAI flag, since OpenAI's content detector was discontinued in 2023 due to low accuracy. Even so, Undetectable.ai detected all five tests, earning a perfect 100%.\nWriter.com AI Content Detector (Accuracy 40%)\nWriter.com is a service that generates AI writing for corporate teams. Its AI Content Detector tool can scan for generated content. Unfortunately, its accuracy was low. It identified every text block as human-written, even though three of the six tests were written by ChatGPT.\nZeroGPT (Accuracy 100%)\nZeroGPT has matured since I last evaluated it. Then, no company name was listed, and the site was peppered with Google ads and lacked clear monetization. The service worked fairly well but seemed sketchy.\nAlso: Will AI destroy human creativity? No - and here's why\nThat sketchy feeling is gone. ZeroGPT now presents as a typical SaaS service, complete with pricing, company name, and contact information. Its accuracy increased as well: last time it was 80%; this time it scored 5 out of 5.\nIs it human, or is it AI?\nWhat about you? Have you tried AI content detectors like Copyleaks, Monica, or ZeroGPT? How accurate have they been in your experience? Have you used these tools to protect academic or editorial integrity? Have you encountered situations where human-written work was mistakenly flagged as AI? Are there detectors you trust more than others for evaluating originality? Let us know in the comments below.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/musk-makes-good-on-his-promise-and-launches-his-own-ai-company/",
      "text": "Elon Musk launches new AI company to 'understand the true nature of the universe'\nFor months, Elon Musk has been leaving a trail of breadcrumbs pointing toward a bigger AI project on the horizon and today that project was formally announced.\nxAI is a new company, led by Musk, that seeks to \"understand the true nature of the universe,\" according to the release posted on the company's website.\nAlso: Anthropic's updated ChatGPT-rival offers more detailed, less offensive responses\nThe release shared the names of a dozen xAI team members, including former employees of DeepMind, OpenAI, Google Research, Microsoft Research, Tesla, and the University of Toronto. The list also includes engineers Igor Babuschkin and Manuel Kroiss, who Musk hired in early March.\nxAI is a separate company from X Corp, the company Twitter merged into in April. However, the release notes that the new AI company will work closely with Twitter and Tesla, among other companies, \"to make progress towards our mission.\"\nToday's announcement follows a series of moves that suggested a major AI project in the making, including state filings in April which revealed that Musk had created a new AI company.\nIn April, Musk also shared his intention to create a new AI model called TruthGPT. In an interview with Tucker Carlson, Musk described the new model as a \"maximum truth-seeking AI that tries to understand the nature of the universe,\" wording that mirrored the press release's description of xAI.\nMusk also purchased 10,000 GPUs for Twitter, which are crucial for machine-learning models and, again, demonstrated the existence of a project like xAI.\nDespite all of Musk's work toward building this company, the announcement came at an interesting time as Musk signed a petition to halt further AI developments at the end of March and has spoken openly about the dangers of AI.\nAlso: Want to build your own AI chatbot? Say hello to open-source HuggingChat\nThis isn't Musk's first AI endeavor; he was an investor in OpenAI when it was founded in 2015. Now xAI is positioning itself to compete directly with OpenAI as well as other giants in the industry.\nAccording to the xAI site, Musk and the team will answer questions about the new company via a Twitter Spaces chat on Friday, July 14."
    },
    {
      "url": "https://www.zdnet.com/article/humanitys-last-exam-benchmark-is-stumping-top-ai-models-can-you-do-any-better/",
      "text": "'Humanity's Last Exam' benchmark is stumping top AI models - can you do any better?\nAre artificial intelligence (AI) models really surpassing human ability? Or are current tests just too easy for them?\nOn Thursday, Scale AI and the Center for AI Safety (CAIS) released Humanity's Last Exam (HLE), a new academic benchmark aiming to \"test the limits of AI knowledge at the frontiers of human expertise,\" Scale AI said in a release. The test consists of 3,000 text and multi-modal questions on more than 100 subjects like math, science, and humanities, submitted by experts in a variety of fields.\nAlso: Roll over, Darwin: How Google DeepMind's 'mind evolution' could enhance AI thinking\nAnthropic's Michael Gerstenhaber, head of API technologies, noted to Bloomberg last fall that AI models frequently outpace benchmarks (part of why the Chatbot Arena leaderboard changes so rapidly when new models are released). For example, many LLMs now score over 90% on multi-task language understanding (MMLU), a commonly used benchmark. This is known as benchmark saturation.\nBy contrast, Scale reported that current models only answered less than 10 percent of the HLE benchmark's questions correctly.\nResearchers from the two organizations collected over 70,000 questions for HLE initially, narrowing them to 13,000 that were reviewed by human experts and then distilled once more into the final 3,000. They tested the questions on top models like OpenAI's o1 and GPT-4o, Anthropic's Claude 3.5 Sonnet, and Google's Gemini 1.5 Pro alongside the MMLU, MATH, and GPQA benchmarks.\n\"When I released the MATH benchmark -- a challenging competition mathematics dataset -- in 2021, the best model scored less than 10%; few predicted that scores higher than 90% would be achieved just three years later,\" said Dan Hendrycks, CAIS co-founder and executive director. \"Right now, Humanity's Last Exam shows that there are still some expert closed-ended questions that models are not able to answer. We will see how long that lasts.\"\nAlso: DeepSeek's new open-source AI model can outperform o1 for a fraction of the cost\nScale and CAIS gave contributors cash prizes for the top questions: $5,000 went to each of the top 50, while the next best 500 received $500. Although the final questions are now public, the two organizations kept another set of questions private to address \"model overfitting,\" or when a model is so closely trained to a dataset that it is unable to make accurate predictions on new data.\nThe benchmark's creators note that they are still accepting test questions, but will no longer award cash prizes, though contributors are eligible for co-authorship.\nCAIS and Scale AI plan to release the dataset to researchers so that they can further study new AI systems and their limitations. You can view all benchmark and sample questions at lastexam.ai."
    },
    {
      "url": "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nIt's only been almost three years since generative artificial intelligence (AI) hit the mainstream as a new paradigm of productivity, but here we are -- it's everywhere.\nI test AI tools as part of my work. I'll dig into just about any AI-related technology and see what I can make it do. Many of you have read my ongoing shootouts comparing AIs for programming and AI content checkers, among other kinds of tools.\nBut that's using AI in a rigorous lab environment to provide test results to ZDNET readers. Like many of you, I've also started using AI to augment my workflow and increase my productivity.\nAlso: The best AI for coding in 2025 (and what not to use)\nI wear a lot of hats; I run a small business with my wife, who also has her own business, where I'm the tech guy and designer. I also work with a number of industry groups. I have a fairly popular security software product for WordPress users. And I'm constantly working on projects, ranging from 3D printing the ultimate charging tower, to trying to make an AI-assisted Etsy store, to composing and publishing music, and using an AI for help with some of the marketing activities.\nI should note that I never, ever use AI to produce my core content. No article, song, or social media post is ever written using an AI tool. My work product is mine. But I do use AI to help me get through other aspects of my workload.\nI have a particular interest in how AI helps programming, how AI can support graphics work, and how AI can support video production.\nHere are the tools I'm willing to pay for -- and why.\n1. ChatGPT Plus - $20/mo\nSpeaking of AI and programming, it has essentially doubled my programming output. I use AI to help me with common-knowledge programming. I talked about it in-depth in my 25 tips article, but the core benefit is getting ChatGPT to write code for published APIs, so I don't have to spend time searching for code examples and trying to reverse-engineer comments on various programming boards.\nAnd yes, I mentioned ChatGPT. While more chatbots capable of passing my programming tests have been introduced in the last year, ChatGPT does the job well enough, and hey, who wants another monthly fee?\nAlso: How ChatGPT actually works (and why it's been so game-changing)\nIn fact, that's a big part of why I'm paying $20/mo for ChatGPT Plus. Sure, I've signed up and paid for some of the other AIs just to test them, but ChatGPT Plus is the only chatbot I have found so consistently useful that I keep it as a regularly used tool.\nI use ChatGPT for lots of research tasks, sometimes throwing math problems at it, and all sorts of other questions and problems I'm dealing with. While I never take its output as an unimpeachable source of truth, I do find ChatGPT to be a very useful sounding board, substantially more so than a quick Google search.\nNow, to be fair, I did outline five ways that an AI could help me in Gmail. If Gemini could do these things reliably, I'd sign back up in a heartbeat. But I just don't need the current email message I'm reading summarized, and I sure don't need it to write a friendlier or more professional version of whatever I've currently written. I tried Gmail's new AI unsubscribe feature, and it only found about 10 newsletters, yet I get thousands of emails and hundreds of newsletter-style messages every day. So, I'm leaving that one unbought.\n2. Midjourney - $10/mo\nI played around a lot with DALL-E, ChatGPT's earlier image generation tool. But recently, OpenAI introduced a new image generator in GPT-4o, and it's quite the beast. I have found that it generates great results, but it has more guardrails than another tool I pay for, Midjourney.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nBut even though I get image generation with my $20/mo ChatGPT Plus fee, I pay an extra $10/mo for Midjourney. Why?\nOne of the reasons is subjective. I like a lot of the images I get with Midjourney. Midjourney also allows me to describe artist styles, and lets me riff off a vast array of stylistic choices. ChatGPT, perhaps because of guardrails imposed by OpenAI, doesn't present as many choices.\nBut I also have two specific and objective reasons for paying for Midjourney. First, because image generation is so subjective, it's nice to have a variety of tools when seeking a representation of what you have in your head. I'll try different prompts and even the same prompts with both tools and take what works best.\nAlso: How to selectively modify a Midjourney image to create an artistic statement\nSecond, every month I generate a promotional image for my wife's online business. She has an e-commerce site that supports a popular hobby. Each month, on her very active Facebook group, she gives a craft-along theme to her users. I generate an image for that theme. Over the months, I've found that Midjourney does a far better job of generating an image that incorporates elements of the hobby. That said, some months I bounce back and forth between both tools until I can get an image that meets her business's needs.\nBecause Midjourney shaves what used to be two to three hours of work pushing pixels in Photoshop to generate those images down to about 10 minutes, it's worth the $10/month to me just for that project.\nPhotoshop Generative Fill - Honorable mention\nIn the title of this article, I said I pay for two AI tools. That's sort of true. I pay for Adobe's Creative Cloud suite in addition to ChatGPT Plus and Midjourney. But since I've been using and paying for Creative Cloud -- and before that, Photoshop -- long before there was generative fill, I'm not counting it in my AI tools list.\nAlso: I use Photoshop's AI tool every day - here are my 5 essential tips for the best results\nIf Adobe removed generative fill tomorrow, I'd still pay for Photoshop. To be clear, I don't like paying for it. It's costly, and the two-computer license limitation is restrictive. But a few years back, I tried switching to Affinity Photo, which at the time was $50 (it's now $70). That one-time fee is roughly what I pay each month for Creative Cloud, so it had a lot of potential.\nTo be clear, Affinity Photo is a fine application. But I've been using Photoshop since before the Clinton administration. To say I have Photoshop muscle memory is an understatement. It's a product I use almost every day. Switching to another application, while I could do it if I had to, slows down my workflow considerably.\nAlso: What to do if Generative Fill is grayed out in Adobe Photoshop AI\nSo, I don't consider my monthly expense for Creative Cloud to be an AI expense. That said, I find generative fill (and its various other AI tricks) very helpful. I often use it in concert with Midjourney and ChatGPT image generation.\nThree tools I'm thinking about\nI run a business online and, as such, rely on a wide variety of cloud services. Those fees add up, and now they're all going up in price. So while it might be nice to add more AI tools, I'm keeping it under control. It's very easy to just click OK and find yourself spending hundreds of dollars more every month.\nThat said, I am thinking about adding three more tools. I'm a bit hesitant, because each one has its annoyances and limitations, but they're on the short list for a quick order if I can ever justify an immediate performance improvement on one project or another.\nNotion AI\nThe first is Notion AI. I am deeply invested in Notion for all my project work. I also use it to write and organize all my articles, as well as schedule them, plan them, research them, and capture notes and assets. Notion AI is interesting because it would work like NotebookLM, limiting its knowledge base to my Notion account. That could be very useful as I work on more projects. But at one point, when Notion overcharged my wife's account, they were completely unsupportive and unsympathetic. So, I hesitate to give them more business.\nNotebookLM Pro\nGoogle's NotebookLM Pro is another contender. Now that Pocket, the article archiving service, is being discontinued, I considered using NotebookLM Pro as a replacement. The idea that I could save articles in NotebookLM as sources and then have the AI review them, summarize them, and analyze them seemed ideal, especially as a research tool.\nBut... the free version of NotebookLM only allows 50 sources per notebook. The Pro version, which is normally another $20/mo ( you can usually get a few starter months at a discounted rate), increases that limit, but only to 300 sources per notebook. My archive has well over 30,000 sources, which is beyond NotebookLM's limits. There is a $249/month plan (yowzah!), but all Google will say about limits is \"Highest limits and best model capabilities (later this year)\". What does that even mean?\nDescript\nDescript (for $16-$24/mo) is an AI video editing tool. This isn't a tool that does text-to-video generation. Instead, it's a tool that helps you take your video clips and edit them. Right now, I'm a very big Final Cut Pro user. Final Cut has added some AI features, but it lags far behind DaVinci Pro and Premiere Pro (because Apple lagging in AI is no surprise, right?).\nAlso: How to use ChatGPT to write code - and my top trick for debugging what it generates\nDescript automatically removes filler words and retakes, cleans up sound quality without any fuss, and does automatic multicam editing. It also promises to take long-form videos and automatically create clip videos, which could be a huge time-saver. The product also has some more \"out there\" features which I wouldn't use, including fake avatar generation and fake speech generation.\nThe thing is, Descript is aimed more at multiple talking head videos. I'm not sure it could handle the sort of in-depth technical hands-on project videos I do. So, it's still in the \"maybe someday\" category, for now at least.\nWhat do you use?\nDo you pay for any AI tools? Which ones, and why? Is there an AI tool that you strongly recommend I should be using that I didn't mention? Feel free to answer these questions and let us know your thoughts on AI subscriptions in the comments below.\nWant more stories about AI? Sign up for Innovation, our weekly newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/openais-gpt-5-is-now-free-for-all-how-to-access-and-everything-else-we-know/",
      "text": "OpenAI's GPT-5 is now free for all: How to access and everything else we know\nZDNET's key takeaways\n- OpenAI has launched its long-awaited GPT-5 model.\n- The model is claimed to be OpenAI's fastest, smartest, and most capable yet.\n- GPT-5 is available to everyone: Free, Plus, Pro, and Team/Enterprise/Edu users.\nThere are two kinds of OpenAI models in this world: GPT and reasoning models. The advantages of the former, such as GPT-4o, are that they combine speed and accuracy, while reasoning models such as o3 and o4 take longer to think and use more compute power to produce better answers. OpenAI's latest model, GPT-5, supposedly gives all users access to the best of both models.\nAlso: Gen AI disillusionment looms, according to Gartner's 2025 Hype Cycle report\n(Disclosure: Ziff Davis, ZDNET's parent company, filed an April 2025 lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nOn Thursday, OpenAI finally unveiled the long-awaited GPT-5, the company's next-generation family of models, which it touts as the fastest, smartest, and most capable yet. GPT-5 is a unified system that combines a smart model for most queries and a deeper reasoning model (GPT-5 thinking) for harder problems.\nIf you are wondering exactly what it does and if you should even consider trying it, keep reading.\nWhat is GPT-5?\nThe key differentiator between GPT-5 and other OpenAI models is the real router feature, which allows GPT-5 to automatically understand which model to use based on the conversation, the complexity of the prompt, and more. The router is continuously trained on real signals to understand the best scenario in which to use a model. Once a user hits usage limits, a mini version of each model takes over.\nAlso: Can GPT-5 fix Apple Intelligence? We're about to find out\nWhile GPT-4o was an extremely capable model, it was not a reasoning model like o3 and o4; those were limited to paying subscribers. As a result, GPT-5 is an especially big win for free users, who typically did not have access to any of the reasoning models and were, by default, excluded from more advanced models.\nThe GPT-5 family of models is made up of GPT-5, GPT-mini, GPT-5-nano, and GPT-5 Pro. The nuances between these models will mostly be topics that developers or enterprises are concerned with when choosing which models to purchase from the API.\nHowever, for most consumers, what you need to know is that GPT-5 will be automatically selected even for free users, and when limits are reached will switch over to GPT-5 mini, a still capable but more lightweight model. GPT-5 Pro is only available to ChatGPT Pro subscribers, which comes at the hefty $200 per month cost. This is the most advanced version of GPT-5, meant for the most challenging and complex tasks -- tasks that the average user likely won't even encounter.\nHow does GPT-5 perform?\nAs with every model release, the GPT-5 drop was accompanied by benchmark evaluations, in which it earned state-of-the-art scores across math (AIME 2025), coding (SWE-Bench Verified), and multimodal understanding (MMMU). It even performed competitively on Humanity's Last Exam, a newer benchmark with multi-modal questions in over 100 subjects, such as math, science, and the humanities, as seen below.\nThe company claims it is the strongest coding model yet, being able to create websites, apps, and games from simple text prompts. In particular, OpenAI shares that it has shown improvements in complex front\u2011end generation and debugging larger repositories.\nAlso: Google's Jules AI coding tool exits beta with serious upgrades - and more free tasks\nBefore the model was released, I watched a live demo of the feature, in which the user created a fully functional web app with interactive elements such as flashcards, a quiz with right and wrong answers, and a game from a simple text prompt. The final product looked sleek. As someone who has recent experience building webpages, it would have taken me hours to stylize using JavaScript and CSS. GPT-5 appears to take vibe coding to the next level.\nEven if you are more of an average GPT-5 user who employs AI for writing, you will still reap these benefits. OpenAI claims GPT-5 is the most capable writing collaborator, being able to better tackle tasks that involve \"structural ambiguity\" such as free verse. Regardless of what you use ChatGPT to write, you should see improvements.\nPeople have been increasingly reliant on ChatGPT for health-related queries because of its ability to conversationally break down medical jargon, which can often be scary and intimidating. Now the experience is optimized with GPT-5, flagging concerns, asking questions, understanding results, prepping you to ask providers questions, and weighing options.\nAlso: ChatGPT can now talk nerdy to you - plus more personalities and other upgrades beyond GPT-5\nRemember that GPT-5 does not replace a medical professional. OpenAI noted that the model performed the highest on HealthBench, a benchmark evaluation the company published earlier this year. External benchmarks for how AI performs in medical scenarios are not yet standardized.\nHow does GPT-5 handle safety?\nOne of the biggest improvements available in GPT-5 is that the model is more accurate than any previous reasoning model and has fewer hallucinations, according to OpenAI. The company said GPT-5's responses are 45% less likely to contain a factual error than GPT-4o with web search enabled on anonymized prompts, and 80% less likely to contain a factual error than OpenAI o3.\nThis is a big win, as reasoning models go beyond traditional pattern prediction and are invited to \"think,\" which leaves room for error.\nOpenAI also added new publicly available benchmarks to test factuality, including LongFact and FActScore, in which GPT-5 with thinking showed a significant drop in hallucinations. GPT-5 (with thinking) also communicates more honestly with the user, sharing when a task is impossible or can't be done. This is important because AI models often offer a plausible-sounding answer instead of admitting they don't know, which can increase the circulation of misinformation. For more on the evaluation results, take a look at the system card.\nAnother brand-new safety feature is called \"safe completions,\" which enables ChatGPT to still answer prompts it would typically refuse. Instead, it will answer, but within the safety boundaries defined by OpenAI, and give a clear explanation of when it can't.\nLastly, while not entirely a safety issue, the model is less sycophantic, or effusively agreeable, and uses fewer unnecessary emojis.\nHow can you access GPT-5?\nAll users\nGPT-5 and GPT-5 mini are available today for all Plus, Pro, Team, and Free users, while Enterprise and Edu users will get access next week, OpenAI said. However, subscribers still receive tiered perks. For example, included in the $20 per month subscription, ChatGPT Plus subscribers have \"significantly higher usage\" limits than free users. Meanwhile, ChatGPT Pro users have unlimited GPT-5 and access to GPT-5 Pro, an even more advanced version of the model included in their $200 per month subscription. OpenAI said Enterprise and Edu users will be given \"generous limits.\"\nAlso: Microsoft rolls out GPT-5 across its Copilot suite - here's where you'll find it\nGPT-5 will be set as the default model for everyday work, replacing all other models for authenticated users. However, paid users will still have the option to select it under the model picker. OpenAI said free users may not be able to access full reasoning until a few days from now, noting that once free users reach usage limits, they'll be moved to GPT-5 mini.\nDevelopers\nThe release of the model is also helpful for developers, as they can benefit from the increased reliability and accuracy. To accommodate this, OpenAI is making GPT-5, GPT-mini, and GPT-5-nano available in the API. Two new parameters, reasoning and verbosity, are also meant to help developers get exactly what they need from their model without overspending. Pro, Plus, and Team users can sign in to ChatGPT to code with GPT-5 in the Codex CLI.\nThe reasoning parameter makes GPT-5 cheaper for tasks that don't require in-depth thinking, and then the verbosity parameter allows developers to fine-tune just how verbose they want GPT-5 to be. The pricing is cheaper than GPT-4o. For more information, you can check the blog post.\nWhat if I am not seeing GPT-5 yet?\nGPT-5 began rolling out to all Plus, Pro, Team, and Free users upon launch on Thursday. However, the rollouts are gradual, so if you checked immediately and didn't see it, it is worth checking again to see if you now have it. It had not shown up for me on my free, Plus, or Pro account until last night.\nDo make sure you are signed in. Even though GPT-5 is available to free users, if you don't sign in, you won't have access to the latest features, including GPT-5.\nYou can keep up with my latest stories and tech adventures on social media. Follow me on Twitter/X at @sabrinaa_ortiz and on Instagram at @sabrinaa.ortiz."
    },
    {
      "url": "https://www.zdnet.com/article/gpt-4o-update-gets-recalled-by-openai-for-being-too-agreeable/",
      "text": "OpenAI recalls GPT-4o update for being too agreeable\nLate last week, OpenAI updated GPT-4o, the primary model behind its popular chatbot, ChatGPT. But it is already being recalled.\nAlso: Anthropic finds alarming 'emerging trends' in Claude misuse report\nOn Tuesday, CEO Sam Altman announced via an X post that OpenAI \"started rolling back\" the update due to user complaints about its responses. In some examples, reacting to somewhat ridiculous test prompts, ChatGPT encouraged risky medical choices, rude and antisocial behavior, and valued a toaster over animal life.\n(Disclosure: Ziff Davis, ZDNET's parent company, filed an April 2025 lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nOverly flattering\n\"The update we removed was overly flattering or agreeable -- often described as sycophantic,\" OpenAI said in a blog about the issue. Sycophancy in AI models can occur when human feedback is used to train them, specifically in fine-tuning. The company explained the update had intended to \"improv[e] the model's default personality to make it feel more intuitive and effective across a variety of tasks.\"\nAlso: Anthropic mapped Claude's morality. Here's what the chatbot values (and doesn't)\nHowever, OpenAI admitted it had \"focused too much on short-term feedback, and did not fully account for how users' interactions with ChatGPT evolve over time.\" This led to GPT-4o responding in \"overly supportive but disingenuous\" ways.\nSources inside OpenAI recently reported that the company has shrunk its safety testing timelines for new models. It is unclear how much direct impact that had here, or whether changes to testing occurred before or after the GPT-4o update was in progress.\nAlso: The dead giveaway that ChatGPT wrote your content - and how to work around it\nBeyond being uncomfortable to interact with, sycophancy can be dangerous if chatbots blindly encourage users' hateful or violent opinions or desired actions -- some of which they would usually disengage with based on OpenAI's guardrails. In the blog, OpenAI focused primarily on sycophancy's impact on user satisfaction rather than potential safety issues.\nUpdate reversed\nIn his post, Altman noted that the update is completely reversed for free-tier ChatGPT users, and that OpenAI would update the model again for paid users once the reversal concluded.\n\"[W]e're working on additional fixes to model personality and will share more in the coming days,\" he added. In its blog, OpenAI explained that this includes \"refining core training techniques and system prompts,\" adding personalization features for greater user control, and reevaluating how it weighs feedback for user satisfaction.\nAlso: A few secretive AI companies could crush free society, researchers warn\nMoving forward, \"users will be able to give real-time feedback to directly influence their interactions and choose from multiple default personalities,\" the company added.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://www.zdnet.com/article/musk-claims-new-grok-4-beats-o3-and-gemini-2-5-pro-how-to-try-it/",
      "text": "Musk claims new Grok 4 beats o3 and Gemini 2.5 Pro - how to try it\nElon Musk's AI startup xAI unveiled Grok 4 early Thursday morning, describing it as \"the world's most powerful AI model.\"\nDuring an hour-long livestream hosted on X, the social media platform also owned by Musk, the CEO claimed that the newest iteration of his AI company's flagship AI model surpassed competing chatbots on several key benchmarks. The multimodal AI agent has vision and voice capabilities as well as a 128k context window.\nAlso: If Musk wants AI for the world, why not open-source all the Grok models?\nHe touted Grok 4 as the world's best-performing model on Humanity's Last Exam (HLE), an AI testing benchmark comprising a series of difficult problems across math, science, and the humanities. HLE has been framed as a more reliable test of a model's capabilities since its release in January, due to the issue of benchmark saturation, or benchmarks becoming too easy for how quicky models are evolving.\nBy xAI's own reporting, Grok 4 beat OpenIA's o3 and Google's Gemini 2.5 Pro on HLE. \"Grok 4 is better than PhD level in every subject,\" Musk said during the livestream. \"No exceptions.\"\nAlso: X's Grok did surprisingly well in my AI coding tests\nxAI has not yet published a research paper outlining Grok 4's performance on key AI performance benchmarks, a practice that has become standard when leading AI developers release a new model. The company has not replied to ZDNET's request for comment at the time of this writing.\nThat said, independent AI reviewer Artificial Analysis confirmed xAI's claims, stating it had received early access to Grok 4 and that it is \"now the leading AI model,\" comparing the company's progress to competitors in a chart.\nGrok 4 is now available via the xAI app and website for $30 per month. Developers can access the model's API for $3 per 1 million input tokens, or $15 per 1 million output tokens. Grok 4 Heavy, a version that leverages multiple AI agents simultaneously to reason through particularly difficult problems, is also available for a $300-per-month subscription. The model's predecessor, Grok 3, is still available for free online.\nGrok's hate-filled posting spree\nThe launch arrives shortly after Grok 3 went on an antisemitic tirade on X, where it has its own account. In one post, it implied that people with Jewish last names were more likely to participate in \"extreme leftist activism.\" In another, responding to a user who referred to campers at Camp Mystic, the Christian summer camp in Texas where over two dozen campers and staff members were recently killed by deadly floods, as \"future fascists,\" Grok seemed to endorse Hitlerian genocide to deal with what it described as \"such vile anti-white hate.\"\nAlso: I'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\n\"[Hitler would] identify the 'pattern' in such hate--often tied to certain surnames--and act decisively: round them up, strip rights, and eliminate the threat through camps and worse,\" the chatbot wrote.\nSome of the posts were later removed by X. The company's CEO, Linda Yaccarino, announced Wednesday morning -- without much explanation -- that she would be stepping down from the role. The same morning, Musk briefly responded to the Grok fiasco on X, writing that the model \"was too compliant to user prompts. Too eager to please and be manipulated, essentially.\" The issue, he added, \"is being addressed.\"\nHe conspicuously avoided any mention of his chatbot's social media tirade during the Thursday livestream. He did, however, say he believed that it was critical for AI to be \"maximally truth-seeking.\"\nAlso: Yikes: Jailbroken Grok 3 can be made to say and reveal just about anything\nMusk founded xAI in 2023 \"to understand the universe,\" according to the company's mission statement on its website. He has positioned Grok as an alternative to AI chatbots from companies like Google and OpenAI, which Musk has ridiculed as being too \"woke\" and politically correct. Grok, in contrast, was built to be blunt and humorous in its responses to user queries."
    },
    {
      "url": "https://www.zdnet.com/article/you-can-try-gemini-live-in-your-favorite-google-apps-now-and-it-blew-me-away/",
      "text": "You can try Gemini Live in your favorite Google apps now, and it blew me away\nZDNET's takeaways\n- Gemini Live now works with Calendar, Maps, Keep, and Tasks.\n- Update is rolling out to most Android and iOS users.\n- It can add events, guide routes, and manage lists or notes.\nIn May of this year, Google debuted Gemini Live with screen sharing and camera access for Android. Google has been slowly integrating the feature, which lets you ask Gemini about anything on your screen (or that you can see with your camera), into its suite of apps since June.\nGemini Live is getting a little more useful this week, as it's officially rolling out for Calendar, Keep, Maps, and Tasks apps.\nAlso: Gemini adds powerful new Deep Think model - what it does and who can try it\nFirst noticed by 9to5Google, most users are now seeing Google's real-time AI voice assistant across new apps. You can tell if the update has hit your device by opening the Gemini app, tapping the Live button in the bottom right corner, and looking directly above the Live controls.\nIf you have the capability, you'll see small chips for the connected apps when Gemini Live is accessing them.\nGemini Live's new tricks\nCalendar\nWith Calendar, you can check your events for the day, make a new event with your voice, and even use your camera to point at details (like date and time) to add that event to your calendar. I gave this a quick test with a flyer for a school event, and I was surprised at how easy it was.\nAlso: Have stock questions? Google Finance tests new AI chatbot\nWhat really blew me away, though, was when I tried it with my alma mater's football schedule for the upcoming fall season. I asked Gemini to add all the home games since I'm a season ticket holder. The AI was able to discern which games were home games and add the events to my calendar, including time and opponent. Live even went down the list, recapping, \"I've added games against App State, Georgia, Army\u2026 to your Calendar.\"\nMaps\nGemini Live for Maps is useful for getting guidance to a certain spot, and it even works with other Google apps. I asked Live to \"guide me to the event that's on my calendar today\" (the same school event I added earlier), and it showed me the way. It didn't pull up Maps by itself, but it did create a link I could easily tap to get going.\nTasks\nWhen it comes to Tasks, Gemini Live can show your saved lists. You could do this on your own easily by pulling up the Tasks app, but Live is an easier way to access your lists. I was able to add tasks to my list and see what was on my to-do list.\nKeep\nSimilar to Tasks, Keep's integration with Google Live is simple but makes an existing capability a little easier to access. I was able to add notes to Keep.\nThe new capability is available on both the Android and iOS versions of Gemini Live.\nAlso: Google's Jules AI coding tool exits beta with serious upgrades - and more free tasks\nAs a reminder, you can turn off Gemini in your Gmail, Docs, Photos, and more if you'd rather not have anything to do with Google's AI."
    },
    {
      "url": "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
      "text": "Coding with AI? My top 5 tips for vetting its output - and staying out of trouble\nOur story begins, as many stories do, with a man and his AI. The man, like many men, is a bit of a geek and a bit of a programmer. He also needs a haircut.\nThe AI is the culmination of thousands of years of human advancement, all put to the service of making the man's life a little easier. The man, of course, is me. I'm that guy.\nAlso: The best AI for coding in 2025 (and what not to use)\nUnfortunately, while AI can be incredibly brilliant, it also has a propensity to lie, mislead, and make shockingly stupid mistakes. It is the stupid part that we will be discussing in this article.\nAnecdotal evidence does have value. My reports on how I've solved some problems quickly with AI are real. The programs I used AI to write with are still in use. I have used AI to help speed up aspects of my programming flow, especially when I focus on the sweet spots where I'm less productive and the AI is quite knowledgeable, like writing functions that call publicly published APIs.\nAlso: I'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nYou know how we got here. Generative AI burst onto the scene at the cusp of 2023 and has been blasting its way into knowledge work ever since.\nOne area, as the narrative goes, where AI truly shines is its ability to write code and help manage IT systems. Those claims are not untrue. I have shown, several times, how AI has solved coding and systems engineering problems I have personally experienced.\nAI coding in the real world: What science reveals\nNew tools always come with big promises. But do they deliver in real-world settings?\nMost of my reporting on programming effectiveness has been based on personal anecdotal evidence: my own programming experiences using AI. But I'm one guy. I have limited time to devote to programming and, like every programmer, I have certain areas where I spend most of my coding time.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nRecently, though, a nonprofit research organization called METR (Model Evaluation & Threat Research) did a more thorough analysis of AI coding productivity.\nTheir methodology seems sound. They worked with 16 experienced open-source developers who have actively contributed to large, popular repositories. The METR analysts provided those developers with 246 issues from the repositories that needed fixing. The coders were given about half the issues where they had to work on their own, and about half where they could use an AI for help.\nThe results were striking and unexpected. While the developers themselves estimated that AI assistance increased their productivity by an average of 24%, METR's analytics showed instead that AI assistance slowed them down by an average of 19%.\nThat's a bit of a head-scratcher. METR put together a list of factors that might explain the slowdown, including over-optimism about AI usefulness, high-developer familiarity with their repositories (and less AI knowledge), the complexity of large repositories, lack of AI reliability, and an ongoing problem where the AI refuses to use \"important tacit knowledge or context.\"\nAlso: How AI coding agents could destroy open-source software\nI would suggest that two other factors might have limited effectiveness:\nChoice of problem: The developers were told which issues they had to use AI help on and which issues they couldn't. My experience suggests knowledgeable developers must choose where to use AI based on the problem that needs to be solved. In my case, for example, getting the AI to write a regular expression (something I don't like doing and I'm fairly crappy at) would save me a lot more time than getting the AI to modify unique code I've already written, work on regularly, and know inside and out.\nChoice of AI: According to the report, the developers used Cursor, an AI-centric fork of VS Code, which used Claude 3.5/3.7 Sonnet at the time. When I tested 3.5 Sonnet, the results were terrible, with Sonnet failing three out of four of my tests. Subsequently, my tests of Claude 4 Sonnet were considerably better. METR reported that developers rejected more than 65% of the code the AI generated. That's going to take time.\nThat time when ChatGPT suggested nuking my system\nMETRs results are interesting. AI is clearly a double-edged sword when it comes to coding help. But there's also no doubt that AI can provide considerable value to coders. If anything, I think this test once again proves the contention that AI is a great tool for experienced programmers, but a potential high-risk resource for newbies.\nAlso: Why I'm switching to VS Code. Hint: It's all about AI tool integration\nLet's look at a concrete example, one that could have cost me a lot of time and trouble if I followed ChatGPT's advice.\nI was setting up a Docker container on my home lab using Portainer (a tool that helps manage Docker containers). For some reason, Portainer would not enable the Deploy button to create the container.\nIt had been a long day, so I didn't see the obvious problem. Instead, I asked ChatGPT. I fed ChatGPT screenshots of the configuration, as well as my Docker configuration file.\nChatGPT recommended that I uninstall and reinstall Portainer. It also suggested I remove Docker from the Linux distro and use the package manager to reinstall it. These actions would have had the effect of killing all my containers.\nOf note, ChatGPT didn't recommend or ask if I had backups of the containers. It just gave me the command line sequences it recommended I cut and paste to delete and rebuild Portainer and Docker. It was a wildly destructive and irresponsible recommendation.\nThe irony is that ChatGPT never figured out why Portainer wouldn't let me deploy the new container, but I did. It turns out I never filled out the container's name field. That's it.\nAlso: What is AI vibe coding? It's all the rage but it's not for everyone - here's why\nBecause I'm fairly experienced, I hesitated when ChatGPT told me to nuke my installation. However, someone relying on the AI for advice could have potentially brought down an entire server for want of typing in a container name.\nOverconfident and underinformed AIs: A dangerous combo\nI've also experienced the AI going completely off the rails. I've experienced it giving advice that was not only completely useless, but also presented with the apparent confidence of an expert.\nAlso: Google's Jules AI coding agent built a new feature I could actually ship - while I made coffee\nIf you're going to use AI tools to support your development or IT work, these tips might keep you out of trouble:\n- If there's not much publicly available information, the AI can't help. But the AI will make stuff up based on what little it knows, without admitting that it is lacking experience.\n- Like my dog, once the AI gets fixated on one thing, it often refuses to look at alternatives. If the AI is stuck on one approach, don't make the mistake of believing that its polite recommendations about a new approach are real. It's still going down the same rabbit hole. Start a new session.\n- If you don't know a lot, don't rely on the AI. Keep up your learning. Experienced devs can tell the difference between what will work and what won't. But if you're trying to put all the coding on the back of the AI, you won't know when or where it goes wrong or how to fix it.\n- Coders often use specific tools for specific tasks. A website might be built using Python, CSS, HTML, JavaScript, Flask, and Jinja. You choose each tool because you know what it does well. Choose your AI tools the same way. For example, I don't use AI for business logic, but I gain productivity using AI to write API calls and public knowledge, where it can save me a lot of time.\n- Test everything an AI produces. Everything. Line by individual line. The AI can save a ton of time, but it can also make enormous mistakes. Yes, taking the time and energy to test by hand can help prevent errors. If the AI offers to write unit tests, let it. But test the tests.\nBased on your experience level, here's how I recommend you think about AI assistance:\n- If you know nothing about a subject or skill: AI can help you pass as if you do, but it could be amazingly wrong, and you might not know.\n- If you're an expert in a subject or skill: AI can help, but it will piss you off. Your expertise gets used not only to separate the AI-stupid from the AI-useful, but to carefully craft a path where AI can actually help.\n- If you're in between: AI is a mixed bag. It could help you or get you in trouble. Don't delegate your skill-building to the AI because it could leave you behind.\nAlso: How I used ChatGPT to analyze, debug, and rewrite a broken plugin from scratch - in an hour\nGenerative AI can be an excellent helper for experienced developers and IT pros, especially when used for targeted, well-understood tasks. But its confidence can be deceptive and dangerous.\nAI can be useful, but always double-check its work.\nHave you used AI tools like ChatGPT or Claude to help with your development or IT work? Did they speed things up, or nearly blow things up? Are you more confident or more cautious when using AI on critical systems? Have you found specific use cases where AI really shines, or where it fails hilariously? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    }
  ],
  "argos_summary": "Elon Musk's AI startup xAI has made its latest model, Grok 4, available to all users, including those on the free tier, in an effort to attract more paying subscribers. The model operates in Auto mode, automatically determining the complexity of queries, and users can choose between different modes for response speed and quality. However, the specifics of the free access limitations remain unclear, and the company plans to introduce ads to help fund the model's operation.",
  "argos_id": "X4BUHUIV2"
}