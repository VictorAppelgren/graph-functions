{
  "url": "https://venturebeat.com/ai/anthropic-revenue-tied-to-two-customers-as-ai-pricing-war-threatens-margins/",
  "authorsByline": "Michael Nu\u00f1ez",
  "articleId": "a9c00c301d75448eb5420da1baa16a50",
  "source": {
    "domain": "venturebeat.com",
    "location": {
      "country": "us",
      "state": "CA",
      "county": "San Francisco",
      "city": "San Francisco",
      "coordinates": {
        "lat": 37.7790262,
        "lon": -122.419906
      }
    }
  },
  "imageUrl": "https://venturebeat.com/wp-content/uploads/2025/08/nuneybits_Vector_art_of_a_chart_showing_decline_on_a_computer_s_3531e536-6ae1-4145-b99d-b12126fce66e.webp?w=857?w=1200&strip=all",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-08T23:35:35+00:00",
  "addDate": "2025-08-08T23:42:21.569347+00:00",
  "refreshDate": "2025-08-08T23:42:21.569352+00:00",
  "score": 1.0,
  "title": "Anthropic revenue tied to two customers as AI pricing war threatens margins",
  "description": "Anthropic faces risks as $5B run rate leans on Cursor and GitHub Copilot as OpenAI\u2019s cheaper GPT\u20115 undercuts Claude, spotlighting customer concentration risks and enterprise AI cost pressure.",
  "content": "Anthropic\u2019s meteoric rise to a $5 billion revenue run rate conceals a precarious dependence on just two major customers that account for nearly a quarter of the artificial intelligence company\u2019s income, according to internal data and industry analysis that reveals both the promise and peril of the AI coding boom.\n\nThe San Francisco-based maker of Claude AI assistant has built its business largely on the back of developer tools, with coding applications Cursor and GitHub Copilot driving approximately $1.2 billion of the company\u2019s $4 billion revenue milestone reached earlier this year, according to sources familiar with the matter. The concentration underscores how quickly Anthropic has captured the lucrative market for AI-powered software development, but also exposes the company to significant risk should either relationship falter.\n\nThe revenue concentration comes into sharp focus as OpenAI launched GPT-5 this week with dramatically lower pricing that could undercut Anthropic\u2019s premium positioning. Early comparisons show Claude Opus 4 costs roughly seven times more per million tokens than GPT-5 for certain tasks, creating immediate pressure on Anthropic\u2019s enterprise pricing strategy and potentially threatening its hard-won dominance in AI coding.\n\nThe pricing disparity signals a fundamental shift in competitive dynamics that will force enterprise procurement teams to reconsider vendor relationships built on performance rather than price. Companies managing exponentially growing AI budgets now face comparable capability at a fraction of the cost, creating unavoidable pressure in contract negotiations.\n\nHow Anthropic\u2019s Claude became the developer\u2019s AI assistant of choice\n\nAnthropic\u2019s ascent reflects the explosive growth in AI-powered software development, which has emerged as artificial intelligence\u2019s first truly profitable use case beyond chatbots. The company now commands 42% of the code generation market \u2014 more than double OpenAI\u2019s 21% share \u2014 according to a comprehensive survey by Menlo Ventures of 150 enterprise technical leaders.\n\nThat dominance has translated into remarkable financial performance. Even excluding its two largest customers, Anthropic\u2019s remaining business has grown more than eleven-fold year-over-year, according to a source close to the company. The startup has also tripled the number of eight and nine-figure deals signed in 2025 compared to all of 2024, reflecting broader enterprise adoption beyond its coding strongholds.\n\nClaude\u2019s appeal to developers stems from its superior performance on complex coding tasks. The newly released Claude Opus 4.1 scores 74.5% on SWE-bench Verified, a rigorous software engineering evaluation, compared to 69.1% for OpenAI\u2019s previous flagship model. Companies like Windsurf, Cursor, and GitHub have praised Claude\u2019s ability to handle multi-step coding problems and understand large codebases.\n\n\u201cPeople love Claude Code, they love using models to write code, and these models are already extremely good and getting better,\u201d said Logan Graham, a member of Anthropic\u2019s frontier red team, in a recent interview with VentureBeat describing the surge in AI-assisted development.\n\nBut the concentration in coding partnerships also creates strategic vulnerabilities. GitHub Copilot, owned by Microsoft, represents a particularly complex relationship given Microsoft\u2019s $13 billion investment in OpenAI. The partnership requires Anthropic to power a competitor\u2019s key product while relying on that same competitor\u2019s parent company for a significant portion of revenue.\n\nOpenAI\u2019s GPT-5 launch this week has introduced a new variable into Anthropic\u2019s calculations: a dramatic pricing advantage that could reshape enterprise buying decisions. Early analysis shows GPT-5 offering comparable or superior performance at a fraction of Claude\u2019s cost, potentially undermining the premium pricing that has driven Anthropic\u2019s rapid revenue growth.\n\nThe timing proves particularly challenging as Anthropic seeks to close a funding round that could value the company at $170 billion. Investors will likely scrutinize both the customer concentration and the emerging price competition as they evaluate whether Anthropic can maintain its growth trajectory.\n\nThe broader market dynamics support both optimism and concern for Anthropic\u2019s future. Model API spending has more than doubled to $8.4 billion in just six months, according to Menlo Ventures, as enterprises shift from experimental projects to production deployments. Anthropic has captured 32% of overall enterprise large language model usage, ahead of OpenAI\u2019s 25% and Google\u2019s 20%.\n\nHowever, the same report reveals that enterprises consistently prioritize performance over price, upgrading to the newest models within weeks of release regardless of cost. This behavior pattern suggests that GPT-5\u2019s combination of improved performance and lower pricing could trigger rapid customer migration \u2014 exactly the scenario that makes Anthropic\u2019s customer concentration so risky.\n\nAnthropic has attempted to diversify beyond coding applications, working with leading companies across pharmaceuticals, retail, professional services, and aviation. The European Parliament uses Claude, while major corporations like Pfizer, United Airlines, and Thomson Reuters have become customers. Startup successes include legal AI company Harvey and cybersecurity firm Base44.\n\nThe company\u2019s business-to-business revenue run rate has grown seventeen-fold year-over-year as of June, suggesting broader enterprise adoption is accelerating. Claude Code, Anthropic\u2019s developer-focused product, alone generates nearly $400 million in annualized revenue, doubling in just weeks according to industry reports.\n\nYet the coding market remains central to Anthropic\u2019s identity and growth strategy. The company has invested heavily in developer tools, recently launching automated security review capabilities to address vulnerabilities in AI-generated code. The features arrive as companies increasingly rely on AI to write code faster than traditional security practices can accommodate.\n\n\u201cIt seems really possible that in the next couple of years, we are going to 10x, 100x, 1000x the amount of code that gets written in the world,\u201d Graham recently told VentureBeat. \u201cThe only way to keep up is by using models themselves to figure out how to make it secure.\u201d\n\nThe convergence of customer concentration and pricing pressure places Anthropic at a strategic crossroads. The company must simultaneously defend its existing coding partnerships while expanding into new markets, all while potentially restructuring its pricing to remain competitive with GPT-5.\n\nThe challenge extends beyond simple price matching. Anthropic has positioned Claude as a premium product justified by superior performance and safety features. Dramatic price cuts could undermine that positioning while potentially triggering a broader industry price war that benefits no one except customers.\n\nMoreover, the customer concentration in coding partnerships creates both leverage and vulnerability. While Cursor and GitHub Copilot relationships provide stable, high-volume revenue streams, they also mean Anthropic\u2019s fate partially rests in the hands of companies that could switch providers with relatively little friction.\n\nThe GitHub relationship proves particularly complex given Microsoft\u2019s competing interests. As GitHub Copilot grows more successful, Microsoft faces increasing pressure to integrate its own OpenAI partnership more deeply, potentially displacing Anthropic despite Claude\u2019s current performance advantages.\n\nIndustry observers note that model switching costs remain relatively low, with 66% of enterprises upgrading within existing providers rather than switching vendors. However, the dramatic price differential introduced by GPT-5 could overcome typical switching inertia, especially for cost-conscious enterprises facing budget pressures.\n\nAnthropic\u2019s customer concentration challenge reflects broader dynamics reshaping the AI industry as competition intensifies among frontier model developers. OpenAI\u2019s aggressive GPT-5 pricing suggests a strategy to reclaim market share lost to Anthropic and other competitors, even at the expense of near-term revenue.\n\nThe timing coincides with an unprecedented talent war among AI companies, with Meta reportedly offering $100 million signing bonuses to poach key researchers. Anthropic CEO Dario Amodei recently noted that many employees have turned down such offers, maintaining an 80% retention rate compared to 67% at OpenAI and 64% at Meta.\n\nHowever, the pricing pressure from GPT-5 could force Anthropic to accelerate its own talent investments and product development cycles, potentially straining the company\u2019s financial resources despite its impressive revenue growth. The need to match OpenAI\u2019s pricing while maintaining research and development spending could squeeze margins and complicate the ongoing funding round.\n\nEnterprise customers, meanwhile, benefit from the intensifying competition through better performance and lower costs. The rapid pace of model improvements \u2014 with new versions launching monthly rather than annually \u2014 provides enterprises with continuously improving capabilities while vendors compete aggressively for their business.\n\nFor Anthropic, the path forward requires careful navigation between protecting existing customer relationships and expanding market reach, all while responding to OpenAI\u2019s pricing offensive. The company\u2019s ability to maintain its coding market leadership while diversifying revenue sources may determine whether its remarkable growth story continues or becomes a cautionary tale about the perils of customer concentration in rapidly evolving markets.\n\nThe stakes extend beyond any single company\u2019s fortunes. As AI-powered coding becomes central to software development across industries, the competitive dynamics between Anthropic and OpenAI will shape how quickly artificial intelligence transforms one of the economy\u2019s most important sectors. For now, the battle lines are drawn around price and performance, with enterprises holding the ultimate power to determine which AI assistant will define the future of software development.",
  "medium": "Article",
  "links": [
    "https://www.cnbc.com/2025/08/07/openai-launches-gpt-5-model-for-all-chatgpt-users.html",
    "https://www.anthropic.com/customers/european-parliament",
    "https://claude.ai/login?returnTo=%2F%3F",
    "https://www.anthropic.com/partners/powered-by-claude",
    "https://t.co/8OaN1RSm9E",
    "https://venturebeat.com/newsletters/",
    "https://www.reuters.com/business/sam-altman-says-meta-offered-100-million-bonuses-openai-employees-2025-06-18/",
    "https://simonwillison.net/2025/Aug/7/gpt-5/",
    "https://hai.stanford.edu/ai-index/2025-ai-index-report",
    "https://www.cnbc.com/2025/07/29/anthropic-in-talks-to-raise-fresh-capital-at-170-billion-valuation.html",
    "https://menlovc.com/perspective/2025-mid-year-llm-market-update/",
    "https://www.anthropic.com/customers/thomson-reuters",
    "https://www.anthropic.com/claude-code",
    "https://www.anthropic.com/customers/harvey",
    "https://github.com/features/copilot",
    "https://fortune.com/2025/08/04/billionaire-anthropic-ceo-dario-amodei-ai-staffers-poaching-meta-mark-zuckerberg-100k-six-figure-salaries-openai-sam-altman/",
    "https://bit.ly/4mwGngO",
    "https://www.anthropic.com/news/claude-opus-4-1",
    "https://www.ciodive.com/news/united-airlines-ceo-AI-use-cases/749563/",
    "https://www.cnbc.com/2024/08/10/rise-of-openai-microsofts-13-billion-artificial-intelligence-bet.html",
    "https://venturebeat.com/ai/anthropic-ships-automated-security-reviews-for-claude-code-as-ai-generated-vulnerabilities-surge/",
    "https://venturebeat.com/terms-of-service/",
    "https://twitter.com/petergostev/status/1952471173515645128?ref_src=twsrc%5Etfw",
    "https://www.swebench.com/",
    "https://openai.com/",
    "https://www.anthropic.com/news/anthropic-amazon-trainium",
    "https://cursor.com/",
    "https://windsurf.com/",
    "https://www.microsoft.com/en-us/",
    "https://www.anthropic.com/",
    "https://openai.com/index/introducing-gpt-5/",
    "https://www.theinformation.com/articles/anthropic-revenue-pace-nears-5-billion-run-mega-round"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "AI companies",
      "weight": 0.08139102
    },
    {
      "name": "Anthropic",
      "weight": 0.07715566
    },
    {
      "name": "Enterprise customers",
      "weight": 0.07614639
    },
    {
      "name": "Claude AI assistant",
      "weight": 0.070255004
    },
    {
      "name": "AI pricing war",
      "weight": 0.069781095
    },
    {
      "name": "Anthropic CEO Dario Amodei",
      "weight": 0.06706462
    },
    {
      "name": "Companies",
      "weight": 0.06645423
    },
    {
      "name": "companies",
      "weight": 0.06645423
    },
    {
      "name": "leading companies",
      "weight": 0.065424964
    },
    {
      "name": "customer concentration",
      "weight": 0.065119945
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Business News/Company News",
      "score": 0.9697265625
    },
    {
      "name": "/News/Technology News",
      "score": 0.93701171875
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.9326171875
    },
    {
      "name": "/Computers & Electronics/Software/Business & Productivity Software",
      "score": 0.681640625
    },
    {
      "name": "/News/Business News/Financial Markets News",
      "score": 0.443603515625
    },
    {
      "name": "/Computers & Electronics/Enterprise Technology/Other",
      "score": 0.43603515625
    }
  ],
  "sentiment": {
    "positive": 0.7495117,
    "negative": 0.101501465,
    "neutral": 0.14855957
  },
  "summary": "Anthropic, the maker of Claude AI assistant, has grown to a $5 billion revenue run rate and is dependent on two major customers, Cursor and GitHub Copilot, which accounted for nearly a quarter of the company's income. The company's rapid growth in AI-powered software development, which is seen as the first profitable use case beyond chatbots, has exposed the company to significant risk if its relationship with these two customers deteriorates. The revenue concentration comes into focus as OpenAI launched GPT-5 with lower pricing that could undercut Anthropic's premium positioning. The pricing disparity could force enterprise procurement teams to reconsider vendor relationships based on performance rather than price. This could potentially disrupt Anthropic\u2019s dominance in AI coding, which has seen a shift in competitive dynamics and potentially undermine its premium pricing. The firm\u2019\ufffds remaining business has grown more than eleven-fold year-over-year, with the remaining business having tripled the number of eight and nine-figure deals signed in 2025 compared to 2025. The move comes as Anthropic seeks a funding round that could value the company at $170 billion.",
  "shortSummary": "Anthropic\u2019s rapid growth relies heavily on two major customers, potentially undermining its enterprise pricing strategy and driving significant revenue losses amid rising competition.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "6412757e9a614cfab08d38262efc1b86",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://github.com/features/copilot",
      "text": "Your backlog doesn\u2019t stand a chance. Delegate open issues to GitHub Copilot and let your coding agent write, run, and test code in the background.Preview GitHub Copilot coding agent\nCompanies using Copilot\nDelegate like a boss\n- Deals with your issues. When assigned issues, GitHub Copilot plans, writes, tests, and iterates\u2014using GitHub Actions to run code and deliver ready-to-review pull requests.\n- Codes like an insider. GitHub Copilot hooks into MCP servers to draw on data from your repositories and external resources\u2014working like an onboarded team member from day one.\n- Human and agent in the loop. Comment to guide GitHub Copilot, polish your code for merge, or take over locally in your IDE.\nBecause two brains are better than one\nAgent mode helps make sweeping changes by analyzing code, proposing edits, running tests, and validating results across multiple files.\nGet speed when you need it. Depth when you don\u2019t.\nIn Copilot Chat, swap between models like OpenAI GPT-5, Anthropic Claude Opus 4.1, and Google Gemini 2.0 Flash to crush coding tasks fast or go deep when it counts.\nMake one change. GitHub Copilot handles the rest.\nNext edit suggestions reveal the ripple effects of your changes across your project\u2014helping you keep everything consistent.\nYour code\u2019s guardian angel\nCode review analyzes your work, uncovers hidden bugs, fixes mistakes, and more\u2014before a human ever sees it.\nTake flight with GitHub Copilot\nFree\nA fast way to get started with GitHub Copilot.\n$0USD\nWhat's included:\n- 50 agent mode or chat requests per month\n- 2,000 completions per month\n- Access to Claude Sonnet 3.5, GPT-4.1, and more\nPro\nMost popularUnlimited completions and chats with access to more models.\n$10USDper month or $100 per year\nEverything in Free and:\n- Unlimited agent mode and chats with GPT-4.1\n- Unlimited code completions\n- Access to code review, Claude Sonnet 4, GPT-5, Gemini 2.5 Pro, and more\n- 6x more premium requests than Copilot Free to use the latest models, with the option to buy more\n- Coding agent (preview)\nFree for verified students, teachers, and maintainers of popular open source projects. Learn more\nPro+\nMaximum flexibility and model choice.\n$39USDper month or $390 per year\nEverything in Pro and:\n- Access to all models, including Claude Opus 4.1, o3, and more\n- 30x more premium requests than Copilot Free to use the latest models, with the option to buy more\n- Access to GitHub Spark\nGitHub Copilot is available on your favorite platforms:\nGet the most out of GitHub Copilot\nFrequently asked questions\nGeneral\nWhat is GitHub Copilot?\nGitHub Copilot transforms the developer experience. Backed by the leaders in AI, GitHub Copilot provides contextualized assistance throughout the software development lifecycle, from code completions and chat assistance in the IDE to code explanations and answers to docs in GitHub and more. With GitHub Copilot elevating their workflow, developers can focus on: value, innovation, and happiness.\nGitHub Copilot enables developers to focus more energy on problem solving and collaboration and spend less effort on the mundane and boilerplate. That\u2019s why developers who use GitHub Copilot report up to 75% higher satisfaction with their jobs than those who don\u2019t and are up to 55% more productive at writing code without sacrifice to quality, which all adds up to engaged developers shipping great software faster.\nGitHub Copilot integrates with leading editors, including Visual Studio Code, Visual Studio, JetBrains IDEs, and Neovim, and, unlike other AI coding assistants, is natively built into GitHub. Growing to millions of individual users and tens of thousands of business customers, GitHub Copilot is the world\u2019s most widely adopted AI developer tool and the competitive advantage developers ask for by name.\nWho is eligible to access GitHub Copilot for free?\nGitHub Copilot Free is a new free pricing tier with limited functionality for individual developers. Users assigned a Copilot Business or Copilot Enterprise seat are not eligible for access. Users with access to Copilot Pro through a paid subscription, trial, or through an existing verified OSS, student, faculty, or MVP account may elect to use Free instead.\nWhat languages, IDEs, and platforms does GitHub Copilot support?\nGitHub Copilot is trained on all languages that appear in public repositories. For each language, the quality of suggestions you receive may depend on the volume and diversity of training data for that language. For example, JavaScript is well-represented in public repositories and is one of GitHub Copilot\u2019s best supported languages. Languages with less representation in public repositories may produce fewer or less robust suggestions.\nGitHub Copilot is available as an extension in Visual Studio Code, Visual Studio, Vim, Neovim, the JetBrains suite of IDEs, and Azure Data Studio. Although code completion functionality is available across all these extensions, chat functionality is currently available only in Visual Studio Code, JetBrains, and Visual Studio. GitHub Copilot is also supported in terminals through GitHub CLI and as a chat integration in Windows Terminal Canary. With the GitHub Copilot Enterprise plan, GitHub Copilot is natively integrated into GitHub.com. All plans are supported in GitHub Copilot in GitHub Mobile. GitHub Mobile for Copilot Pro and Copilot Business have access to Bing and public repository code search. Copilot Enterprise in GitHub Mobile gives you additional access to your organization's knowledge.\nDoes GitHub Copilot \u201ccopy/paste\u201d?\nNo, GitHub Copilot generates suggestions using probabilistic determination.\nWhen thinking about intellectual property and open source issues, it is critical to understand how GitHub Copilot really works. The AI models that create GitHub Copilot\u2019s suggestions may be trained on public code, but do not contain any code. When they generate a suggestion, they are not \u201ccopying and pasting\u201d from any codebase.\nTo generate a code suggestion, the GitHub Copilot extension begins by examining the code in your editor\u2014focusing on the lines just before and after your cursor, but also information including other files open in your editor and the URLs of repositories or file paths to identify relevant context. That information is sent to GitHub Copilot\u2019s model, to make a probabilistic determination of what is likely to come next and generate suggestions.\nTo generate a suggestion for chat in the code editor, the GitHub Copilot extension creates a contextual prompt by combining your prompt with additional context including the code file open in your active document, your code selection, and general workspace information, such as frameworks, languages, and dependencies. That information is sent to GitHub Copilot\u2019s model, to make a probabilistic determination of what is likely to come next and generate suggestions.\nTo generate a suggestion for chat on GitHub.com, such as providing an answer to a question from your chat prompt, GitHub Copilot creates a contextual prompt by combining your prompt with additional context including previous prompts, the open pages on GitHub.com as well as retrieved context from your codebase or Bing search. That information is sent to GitHub Copilot\u2019s model, to make a probabilistic determination of what is likely to come next and generate suggestions.\nWhat are the differences between the GitHub Copilot Business, GitHub Copilot Enterprise, and GitHub Copilot Individual plans?\nGitHub Copilot has multiple offerings for organizations and an offering for individual developers. All the offerings include both code completion and chat assistance. The primary differences between the organization offerings and the individual offering are license management, policy management, and IP indemnity.\nOrganizations can choose between GitHub Copilot Business and GitHub Copilot Enterprise. GitHub Copilot Business primarily features GitHub Copilot in the coding environment - that is the IDE, CLI and GitHub Mobile. GitHub Copilot Enterprise includes everything in GitHub Copilot Business. It also adds an additional layer of customization for organizations and integrates into GitHub.com as a chat interface to allow developers to converse with GitHub Copilot throughout the platform. GitHub Copilot Enterprise can index an organization\u2019s codebase for a deeper understanding of the customer\u2019s knowledge for more tailored suggestions and will offer customers access to fine-tuned custom, private models for code completion.\nGitHub Copilot Individual is designed for individual developers, freelancers, students, educators, and open source maintainers. The plan includes all the features of GitHub Copilot Business except organizational license management, policy management, and IP indemnity.\nWhat data has GitHub Copilot been trained on?\nGitHub Copilot is powered by generative AI models developed by GitHub, OpenAI, and Microsoft. It has been trained on natural language text and source code from publicly available sources, including code in public repositories on GitHub.\nWhich plan includes GitHub Copilot Autofix?\nGitHub Copilot Autofix provides contextual explanations and code suggestions to help developers fix vulnerabilities in code, and is included in GitHub Advanced Security.\nWhat if I do not want GitHub Copilot?\nGitHub Copilot is entirely optional and requires you to opt in before gaining access. You can easily configure its usage directly in the editor, enabling or disabling it at any time. Additionally, you have control over which file types GitHub Copilot is active for.\nHow do I control access to GitHub Copilot in my company?\nAccess to Copilot Business and Enterprise is managed by your GitHub Administrator. They can control access to preview features, models, and set GitHub Copilot policies for your organization. Additionally, you can use your network firewall to explicitly allow access to Copilot Business and/or block access to Copilot Pro or Free. For more details, refer to the documentation.\nPlans & pricing\nWhat are the differences between the Free, Pro, Business, and Enterprise plans?\nGitHub Copilot has multiple offerings for organizations and an offering for individual developers. All the offerings include both code completion and chat assistance. The primary differences between the organization offerings and the individual offering are license management, policy management, and IP indemnity.\nOrganizations can choose between GitHub Copilot Business and GitHub Copilot Enterprise. GitHub Copilot Business primarily features GitHub Copilot in the coding environment - that is the IDE, CLI and GitHub Mobile. GitHub Copilot Enterprise includes everything in GitHub Copilot Business. It also adds an additional layer of customization for organizations and integrates into GitHub.com as a chat interface to allow developers to converse with Copilot throughout the platform. GitHub Copilot Enterprise can index an organization\u2019s codebase for a deeper understanding of the customer\u2019s knowledge for more tailored suggestions and will offer customers access to fine-tuned custom, private models for code completion.\nGitHub Copilot Pro is designed for individual developers, freelancers, students, educators, and open source maintainers. The plan includes all the features of GitHub Copilot Business except organizational license management, policy management, and IP indemnity.\nHow can I upgrade my GitHub Copilot Free license to Copilot Pro?\nIf you're on the Free plan, you can upgrade to Pro through your Copilot settings page or directly on the Copilot marketing page.\nWhat is included in GitHub Copilot Free?\nGitHub Copilot Free users are limited to 2000 completions and 50 chat requests (including Copilot Edits).\nWhich plan includes GitHub Copilot Autofix?\nGitHub Copilot Autofix provides contextual explanations and code suggestions to help developers fix vulnerabilities in code, and is included in GitHub Advanced Security and available to all public repositories.\nPrivacy\nWhat personal data does GitHub Copilot process?\nGitHub Copilot processes personal data based on how Copilot is accessed and used: whether via GitHub.com, mobile app, extensions, or one of various IDE extensions, or through features like suggestions for the command line interface (CLI), IDE code completions, or personalized chat on GitHub.com. The types of personal data processed may include:\nUser Engagement Data: This includes pseudonymous identifiers captured on user interactions with Copilot, such as accepted or dismissed completions, error messages, system logs, and product usage metrics.\nPrompts: These are inputs for chat or code, along with context, sent to Copilot's AI to generate suggestions.\nSuggestions: These are the AI-generated code lines or chat responses provided to users based on their prompts.\nFeedback Data: This comprises real-time user feedback, including reactions (e.g., thumbs up/down) and optional comments, along with feedback from support tickets.\nDoes GitHub use Copilot Business or Enterprise data to train GitHub\u2019s model?\nNo. GitHub does not use either Copilot Business or Enterprise data to train its models.\nHow does GitHub use the Copilot data?\nHow GitHub uses Copilot data depends on how the user accesses Copilot and for what purpose. Users can access GitHub Copilot through the web, extensions, mobile apps, computer terminal, and various IDEs (Integrated Development Environments). GitHub generally uses personal data to:\nDeliver, maintain, and update the services as per the customer's configuration and usage, to ensure personalized experiences and recommendations\nTroubleshoot, which involves preventing, detecting, resolving, and mitigating issues, including security incidents and product-related problems, by fixing software bugs and maintaining the online services' functionality and up-to-dateness\nEnhance user productivity, reliability, effectiveness, quality, privacy, accessibility, and security by keeping the service current and operational\nThese practices are outlined in GitHub\u2019s Data Protection Agreement (DPA), which details our data handling commitments to our data controller customers.\nGitHub also uses certain personal data with customer authorization under the DPA, for the following purposes:\nBilling and account management\nTo comply with and resolve legal obligations\nFor abuse detection, prevention, and protection, virus scanning, and scanning to detect violations of terms of service\nTo generate summary reports for calculating employee commissions and partner incentives\nTo produce aggregated reports for internal use and strategic planning, covering areas like forecasting, revenue analysis, capacity planning, and product strategy,\nFor details on GitHub's data processing activities as a controller, particularly for Copilot Pro customers, refer to the GitHub Privacy Statement.\nHow long does GitHub retain Copilot data for Business and Enterprise customers?\nIf and for how long GitHub\u2019s retains Copilot data depends on how a Copilot user accesses Copilot and for what purpose. The default settings for Copilot Business and Enterprise Customers are as follows:\nAccess through IDE for Chat and Code Completions:\nPrompts and Suggestions: Not retained\nUser Engagement Data: Kept for two years.\nFeedback Data: Stored for as long as needed for its intended purpose.\nAll other GitHub Copilot access and use:\nPrompts and Suggestions: Retained for 28 days.\nUser Engagement Data: Kept for two years.\nFeedback Data: Stored for as long as needed for its intended purpose.\nWhy do some Copilot features retain prompts and suggestions?\nRetaining prompts and suggestions is necessary for chat on github.com, mobile, and CLI Copilot because those features\u2019 effectiveness depends on using thread history to improve responses. The Copilot model requires access to previous interactions to deliver accurate and relevant suggestions.\nDoes GitHub Copilot support compliance with the GDPR and other data protection laws?\nYes. GitHub and customers can enter a Data Protection Agreement that supports compliance with the GDPR and similar legislation.\nDoes GitHub Copilot ever output personal data?\nWhile we've designed GitHub Copilot with privacy in mind, the expansive definition of personal data under legislation like the EU\u2019s General Data Protection Regulation (GDPR) means we can't guarantee it will never output such data. The Large Language Model (LLM) powering GitHub Copilot was trained on public code and there were instances in our tests where the tool made suggestions resembling personal data. These suggestions were typically synthesized and not tied to real individuals.\nHow does Copilot allow users to access, alter or delete personal data?\nThese actions are available to Copilot users as described in the GitHub Privacy Statement.\nResponsible AI\nWhat are the intellectual property considerations when using GitHub Copilot?\nThe primary IP considerations for GitHub Copilot relate to copyright. The model that powers Copilot is trained on a broad collection of publicly accessible code, which may include copyrighted code, and Copilot\u2019s suggestions (in rare instances) may resemble the code its model was trained on. Here\u2019s some basic information you should know about these considerations:\nCopyright law permits the use of copyrighted works to train AI models: Countries around the world have provisions in their copyright laws that enable machines to learn, understand, extract patterns, and facts from copyrighted materials, including software code. For example, the European Union, Japan, and Singapore, have express provisions permitting machine learning to develop AI models. Other countries including Canada, India, and the United States also permit such training under their fair use/fair dealing provisions. GitHub Copilot\u2019s AI model was trained with the use of code from GitHub\u2019s public repositories\u2014which are publicly accessible and within the scope of permissible copyright use.\nWhat about copyright risk in suggestions? In rare instances (less than 1% based on GitHub\u2019s research), suggestions from GitHub may match examples of code used to train GitHub\u2019s AI model. Again, Copilot does not \u201clook up\u201d or \u201ccopy and paste\u201d code, but is instead using context from a user\u2019s workspace to synthesize and generate a suggestion.\nOur experience shows that matching suggestions are most likely to occur in two situations: (i) when there is little or no context in the code editor for Copilot\u2019s model to synthesize, or (ii) when a matching suggestion represents a common approach or method. If a code suggestion matches existing code, there is risk that using that suggestion could trigger claims of copyright infringement, which would depend on the amount and nature of code used, and the context of how the code is used. In many ways, this is the same risk that arises when using any code that a developer does not originate, such as copying code from an online source, or reusing code from a library. That is why responsible organizations and developers recommend that users employ code scanning policies to identify and evaluate potential matching code.\nIn Copilot, you can opt whether to allow Copilot to suggest code completions that match publicly available code on GitHub.com. For more information, see \"Configuring GitHub Copilot settings on GitHub.com\". If you have allowed suggestions that match public code, GitHub Copilot can provide you with details about the matching code when you accept such suggestions. Matching code does not necessarily mean copyright infringement, so it is ultimately up to the user to determine whether to use the suggestion, and what and who to attribute (along with other license compliance) in appropriate circumstances.\nDoes GitHub Copilot include a filtering mechanism to mitigate risk?\nYes, GitHub Copilot does include an optional code referencing filter to detect and suppress certain suggestions that match public code on GitHub.\nGitHub has created a duplication detection filter to detect and suppress suggestions that contain code segments over a certain length that match public code on GitHub. This filter can be enabled by the administrator for your enterprise and it can apply for all organizations within your enterprise, or the administrator can defer control to individual organizations.\nWith the filter enabled, Copilot checks code suggestions for matches or near-matches against public code on GitHub of 65 lexemes or more (on average,150 characters). If there is a match, the suggestion will not be shown to the user.\nIn addition to off-topic, harmful, and offensive output filters, GitHub Copilot also scans the outputs for vulnerable code.\nDoes GitHub Copilot include features to make it easier for users to identify potentially relevant open source licenses for matching suggestions?\nYes, GitHub Copilot is previewing a code referencing feature as an additional tool to assist users to find and review potentially relevant open source licenses. Code referencing is currently available in Visual Studio Code. This feature searches across public GitHub repositories for code that matches a Copilot suggestion. If there\u2019s a match, users will find its information displayed in the Copilot console log, including where the match occurred, any applicable licenses, and a deep link to learn more. The deep link will take users to a navigable page on GitHub.com to browse examples of the code match and their repository licenses, and see how many repositories\u2014including ones without licenses\u2014that code appears in, as well as links to those repositories. Copilot users can review this information to determine whether the applicable suggestions are suitable for use, and whether additional measures may be necessary to use them.\nWho owns the suggestions provided by GitHub Copilot?\nWe don\u2019t determine whether a suggestion is capable of being owned, but we are clear that GitHub does not claim ownership of a suggestion. Whether a suggestion generated by an AI model can be owned depends on many factors (e.g. the intellectual property law in the relevant country, the length of the suggestion, the extent that suggestion is considered \u2018functional\u2019 instead of expressive, etc).\nIf a suggestion is capable of being owned, our terms are clear: GitHub does not claim ownership.\nGitHub does not claim ownership of any suggestion. In certain cases, it is possible for Copilot to produce similar suggestions to different users. For example, two unrelated users both starting new files to code the quicksort algorithm in Java will likely get the same suggestion. The possibility of providing similar suggestions to multiple users is a common part of generative AI systems.\nCan GitHub Copilot introduce insecure code in its suggestions?\nPublic code may contain insecure coding patterns, bugs, or references to outdated APIs or idioms. When GitHub Copilot synthesizes code suggestions based on this data, it can also synthesize code that contains these undesirable patterns. Copilot has filters in place that either block or notify users of insecure code patterns that are detected in Copilot suggestions. These filters target the most common vulnerable coding patterns, including hardcoded credentials, SQL injections, and path injections. Additionally, in recent years we\u2019ve provided tools such as GitHub Advanced Security, GitHub Actions, Dependabot, and CodeQL to open source projects to help improve code quality. Of course, you should always use GitHub Copilot together with good testing and code review practices and security tools, as well as your own judgment.\nIs GitHub Copilot intended to fully automate code generation and replace developers?\nNo. Copilot is a tool intended to make developers more efficient. It\u2019s not intended to replace developers, who should continue to apply the same sorts of safeguards and diligence they would apply with regard to any third-party code of unknown origin.\nThe product is called \u201cCopilot\u201d not \u201cAutopilot\u201d and it\u2019s not intended to generate code without oversight. You should use exactly the same sorts of safeguards and diligence with Copilot\u2019s suggestions as you would use with any third-party code.\nIdentifying best practices for use of third party code is beyond the scope of this section. That said, whatever practices your organization currently uses \u2013 rigorous functionality testing, code scanning, security testing, etc. \u2013 you should continue these policies with Copilot\u2019s suggestions. Moreover, you should make sure your code editor or editor does not automatically compile or run generated code before you review it.\nCan GitHub Copilot users simply use suggestions without concern?\nNot necessarily. GitHub Copilot users should align their use of Copilot with their respective risk tolerances.\nAs noted above, GitHub Copilot is not intended to replace developers, or their individual skill and judgment, and is not intended to fully automate the process of code development. The same risks that apply to the use of any third-party code apply to the use of Copilot\u2019s suggestions.\nDepending on your particular use case, you should consider implementing the protections discussed above. It is your responsibility to assess what is appropriate for the situation and implement appropriate safeguards.\nYou\u2019re entitled to IP indemnification from GitHub for the unmodified suggestions when Copilot\u2019s filtering is enabled. If you do elect to enable this feature, the copyright responsibility is ours, not our customers. As part of our ongoing commitment to responsible AI, GitHub and Microsoft extends our IP indemnity and protection support to our customers who are empowering their teams with GitHub Copilot. See Microsoft's Copilot Copyright Commitment for more details.\nDoes GitHub Copilot support accessibility features?\nWe are conducting internal testing of GitHub Copilot\u2019s ease of use by developers with disabilities and working to ensure that GitHub Copilot is accessible to all developers. Please feel free to share your feedback on GitHub Copilot accessibility in our feedback forum.\nDoes GitHub Copilot produce offensive outputs?\nGitHub Copilot includes filters to block offensive language in the prompts and to avoid synthesizing suggestions in sensitive contexts. We continue to work on improving the filter system to more intelligently detect and remove offensive outputs. If you see offensive outputs, please report them directly to copilot-safety@github.com so that we can improve our safeguards. GitHub takes this challenge very seriously and we are committed to addressing it.\nWill GitHub Copilot work as well using languages other than English?\nGiven public sources are predominantly in English, GitHub Copilot will likely work less well in scenarios where natural language prompts provided by the developer are not in English and/or are grammatically incorrect. Therefore, non-English speakers might experience a lower quality of service.\nWhat data has GitHub Copilot been trained on?\nGitHub Copilot is powered by generative AI models developed by GitHub, OpenAI, and Microsoft. It has been trained on natural language text and source code from publicly available sources, including code in public repositories on GitHub.\nData from June 2023. Additional research can be found here.\nFeature in public beta for Copilot Pro and Business plans. Requires use of repositories, issues, discussions, Actions, and other features of GitHub.\nAuthentication with SAML single sign-on (SSO) available for organizations using GitHub Enterprise Cloud.\nGeneral\nWhat is GitHub Copilot?\nGitHub Copilot transforms the developer experience. Backed by the leaders in AI, GitHub Copilot provides contextualized assistance throughout the software development lifecycle, from code completions and chat assistance in the IDE to code explanations and answers to docs in GitHub and more. With GitHub Copilot elevating their workflow, developers can focus on: value, innovation, and happiness.\nGitHub Copilot enables developers to focus more energy on problem solving and collaboration and spend less effort on the mundane and boilerplate. That\u2019s why developers who use GitHub Copilot report up to 75% higher satisfaction with their jobs than those who don\u2019t and are up to 55% more productive at writing code without sacrifice to quality, which all adds up to engaged developers shipping great software faster.\nGitHub Copilot integrates with leading editors, including Visual Studio Code, Visual Studio, JetBrains IDEs, and Neovim, and, unlike other AI coding assistants, is natively built into GitHub. Growing to millions of individual users and tens of thousands of business customers, GitHub Copilot is the world\u2019s most widely adopted AI developer tool and the competitive advantage developers ask for by name.\nWho is eligible to access GitHub Copilot for free?\nGitHub Copilot Free is a new free pricing tier with limited functionality for individual developers. Users assigned a Copilot Business or Copilot Enterprise seat are not eligible for access. Users with access to Copilot Pro through a paid subscription, trial, or through an existing verified OSS, student, faculty, or MVP account may elect to use Free instead.\nWhat languages, IDEs, and platforms does GitHub Copilot support?\nGitHub Copilot is trained on all languages that appear in public repositories. For each language, the quality of suggestions you receive may depend on the volume and diversity of training data for that language. For example, JavaScript is well-represented in public repositories and is one of GitHub Copilot\u2019s best supported languages. Languages with less representation in public repositories may produce fewer or less robust suggestions.\nGitHub Copilot is available as an extension in Visual Studio Code, Visual Studio, Vim, Neovim, the JetBrains suite of IDEs, and Azure Data Studio. Although code completion functionality is available across all these extensions, chat functionality is currently available only in Visual Studio Code, JetBrains, and Visual Studio. GitHub Copilot is also supported in terminals through GitHub CLI and as a chat integration in Windows Terminal Canary. With the GitHub Copilot Enterprise plan, GitHub Copilot is natively integrated into GitHub.com. All plans are supported in GitHub Copilot in GitHub Mobile. GitHub Mobile for Copilot Pro and Copilot Business have access to Bing and public repository code search. Copilot Enterprise in GitHub Mobile gives you additional access to your organization's knowledge.\nDoes GitHub Copilot \u201ccopy/paste\u201d?\nNo, GitHub Copilot generates suggestions using probabilistic determination.\nWhen thinking about intellectual property and open source issues, it is critical to understand how GitHub Copilot really works. The AI models that create GitHub Copilot\u2019s suggestions may be trained on public code, but do not contain any code. When they generate a suggestion, they are not \u201ccopying and pasting\u201d from any codebase.\nTo generate a code suggestion, the GitHub Copilot extension begins by examining the code in your editor\u2014focusing on the lines just before and after your cursor, but also information including other files open in your editor and the URLs of repositories or file paths to identify relevant context. That information is sent to GitHub Copilot\u2019s model, to make a probabilistic determination of what is likely to come next and generate suggestions.\nTo generate a suggestion for chat in the code editor, the GitHub Copilot extension creates a contextual prompt by combining your prompt with additional context including the code file open in your active document, your code selection, and general workspace information, such as frameworks, languages, and dependencies. That information is sent to GitHub Copilot\u2019s model, to make a probabilistic determination of what is likely to come next and generate suggestions.\nTo generate a suggestion for chat on GitHub.com, such as providing an answer to a question from your chat prompt, GitHub Copilot creates a contextual prompt by combining your prompt with additional context including previous prompts, the open pages on GitHub.com as well as retrieved context from your codebase or Bing search. That information is sent to GitHub Copilot\u2019s model, to make a probabilistic determination of what is likely to come next and generate suggestions.\nWhat are the differences between the GitHub Copilot Business, GitHub Copilot Enterprise, and GitHub Copilot Individual plans?\nGitHub Copilot has multiple offerings for organizations and an offering for individual developers. All the offerings include both code completion and chat assistance. The primary differences between the organization offerings and the individual offering are license management, policy management, and IP indemnity.\nOrganizations can choose between GitHub Copilot Business and GitHub Copilot Enterprise. GitHub Copilot Business primarily features GitHub Copilot in the coding environment - that is the IDE, CLI and GitHub Mobile. GitHub Copilot Enterprise includes everything in GitHub Copilot Business. It also adds an additional layer of customization for organizations and integrates into GitHub.com as a chat interface to allow developers to converse with GitHub Copilot throughout the platform. GitHub Copilot Enterprise can index an organization\u2019s codebase for a deeper understanding of the customer\u2019s knowledge for more tailored suggestions and will offer customers access to fine-tuned custom, private models for code completion.\nGitHub Copilot Individual is designed for individual developers, freelancers, students, educators, and open source maintainers. The plan includes all the features of GitHub Copilot Business except organizational license management, policy management, and IP indemnity.\nWhat data has GitHub Copilot been trained on?\nGitHub Copilot is powered by generative AI models developed by GitHub, OpenAI, and Microsoft. It has been trained on natural language text and source code from publicly available sources, including code in public repositories on GitHub.\nWhich plan includes GitHub Copilot Autofix?\nGitHub Copilot Autofix provides contextual explanations and code suggestions to help developers fix vulnerabilities in code, and is included in GitHub Advanced Security.\nWhat if I do not want GitHub Copilot?\nGitHub Copilot is entirely optional and requires you to opt in before gaining access. You can easily configure its usage directly in the editor, enabling or disabling it at any time. Additionally, you have control over which file types GitHub Copilot is active for.\nHow do I control access to GitHub Copilot in my company?\nAccess to Copilot Business and Enterprise is managed by your GitHub Administrator. They can control access to preview features, models, and set GitHub Copilot policies for your organization. Additionally, you can use your network firewall to explicitly allow access to Copilot Business and/or block access to Copilot Pro or Free. For more details, refer to the documentation.\nPlans & pricing\nWhat are the differences between the Free, Pro, Business, and Enterprise plans?\nGitHub Copilot has multiple offerings for organizations and an offering for individual developers. All the offerings include both code completion and chat assistance. The primary differences between the organization offerings and the individual offering are license management, policy management, and IP indemnity.\nOrganizations can choose between GitHub Copilot Business and GitHub Copilot Enterprise. GitHub Copilot Business primarily features GitHub Copilot in the coding environment - that is the IDE, CLI and GitHub Mobile. GitHub Copilot Enterprise includes everything in GitHub Copilot Business. It also adds an additional layer of customization for organizations and integrates into GitHub.com as a chat interface to allow developers to converse with Copilot throughout the platform. GitHub Copilot Enterprise can index an organization\u2019s codebase for a deeper understanding of the customer\u2019s knowledge for more tailored suggestions and will offer customers access to fine-tuned custom, private models for code completion.\nGitHub Copilot Pro is designed for individual developers, freelancers, students, educators, and open source maintainers. The plan includes all the features of GitHub Copilot Business except organizational license management, policy management, and IP indemnity.\nHow can I upgrade my GitHub Copilot Free license to Copilot Pro?\nIf you're on the Free plan, you can upgrade to Pro through your Copilot settings page or directly on the Copilot marketing page.\nWhat is included in GitHub Copilot Free?\nGitHub Copilot Free users are limited to 2000 completions and 50 chat requests (including Copilot Edits).\nWhich plan includes GitHub Copilot Autofix?\nGitHub Copilot Autofix provides contextual explanations and code suggestions to help developers fix vulnerabilities in code, and is included in GitHub Advanced Security and available to all public repositories.\nPrivacy\nWhat personal data does GitHub Copilot process?\nGitHub Copilot processes personal data based on how Copilot is accessed and used: whether via GitHub.com, mobile app, extensions, or one of various IDE extensions, or through features like suggestions for the command line interface (CLI), IDE code completions, or personalized chat on GitHub.com. The types of personal data processed may include:\nUser Engagement Data: This includes pseudonymous identifiers captured on user interactions with Copilot, such as accepted or dismissed completions, error messages, system logs, and product usage metrics.\nPrompts: These are inputs for chat or code, along with context, sent to Copilot's AI to generate suggestions.\nSuggestions: These are the AI-generated code lines or chat responses provided to users based on their prompts.\nFeedback Data: This comprises real-time user feedback, including reactions (e.g., thumbs up/down) and optional comments, along with feedback from support tickets.\nDoes GitHub use Copilot Business or Enterprise data to train GitHub\u2019s model?\nNo. GitHub does not use either Copilot Business or Enterprise data to train its models.\nHow does GitHub use the Copilot data?\nHow GitHub uses Copilot data depends on how the user accesses Copilot and for what purpose. Users can access GitHub Copilot through the web, extensions, mobile apps, computer terminal, and various IDEs (Integrated Development Environments). GitHub generally uses personal data to:\nDeliver, maintain, and update the services as per the customer's configuration and usage, to ensure personalized experiences and recommendations\nTroubleshoot, which involves preventing, detecting, resolving, and mitigating issues, including security incidents and product-related problems, by fixing software bugs and maintaining the online services' functionality and up-to-dateness\nEnhance user productivity, reliability, effectiveness, quality, privacy, accessibility, and security by keeping the service current and operational\nThese practices are outlined in GitHub\u2019s Data Protection Agreement (DPA), which details our data handling commitments to our data controller customers.\nGitHub also uses certain personal data with customer authorization under the DPA, for the following purposes:\nBilling and account management\nTo comply with and resolve legal obligations\nFor abuse detection, prevention, and protection, virus scanning, and scanning to detect violations of terms of service\nTo generate summary reports for calculating employee commissions and partner incentives\nTo produce aggregated reports for internal use and strategic planning, covering areas like forecasting, revenue analysis, capacity planning, and product strategy,\nFor details on GitHub's data processing activities as a controller, particularly for Copilot Pro customers, refer to the GitHub Privacy Statement.\nHow long does GitHub retain Copilot data for Business and Enterprise customers?\nIf and for how long GitHub\u2019s retains Copilot data depends on how a Copilot user accesses Copilot and for what purpose. The default settings for Copilot Business and Enterprise Customers are as follows:\nAccess through IDE for Chat and Code Completions:\nPrompts and Suggestions: Not retained\nUser Engagement Data: Kept for two years.\nFeedback Data: Stored for as long as needed for its intended purpose.\nAll other GitHub Copilot access and use:\nPrompts and Suggestions: Retained for 28 days.\nUser Engagement Data: Kept for two years.\nFeedback Data: Stored for as long as needed for its intended purpose.\nWhy do some Copilot features retain prompts and suggestions?\nRetaining prompts and suggestions is necessary for chat on github.com, mobile, and CLI Copilot because those features\u2019 effectiveness depends on using thread history to improve responses. The Copilot model requires access to previous interactions to deliver accurate and relevant suggestions.\nDoes GitHub Copilot support compliance with the GDPR and other data protection laws?\nYes. GitHub and customers can enter a Data Protection Agreement that supports compliance with the GDPR and similar legislation.\nDoes GitHub Copilot ever output personal data?\nWhile we've designed GitHub Copilot with privacy in mind, the expansive definition of personal data under legislation like the EU\u2019s General Data Protection Regulation (GDPR) means we can't guarantee it will never output such data. The Large Language Model (LLM) powering GitHub Copilot was trained on public code and there were instances in our tests where the tool made suggestions resembling personal data. These suggestions were typically synthesized and not tied to real individuals.\nHow does Copilot allow users to access, alter or delete personal data?\nThese actions are available to Copilot users as described in the GitHub Privacy Statement.\nResponsible AI\nWhat are the intellectual property considerations when using GitHub Copilot?\nThe primary IP considerations for GitHub Copilot relate to copyright. The model that powers Copilot is trained on a broad collection of publicly accessible code, which may include copyrighted code, and Copilot\u2019s suggestions (in rare instances) may resemble the code its model was trained on. Here\u2019s some basic information you should know about these considerations:\nCopyright law permits the use of copyrighted works to train AI models: Countries around the world have provisions in their copyright laws that enable machines to learn, understand, extract patterns, and facts from copyrighted materials, including software code. For example, the European Union, Japan, and Singapore, have express provisions permitting machine learning to develop AI models. Other countries including Canada, India, and the United States also permit such training under their fair use/fair dealing provisions. GitHub Copilot\u2019s AI model was trained with the use of code from GitHub\u2019s public repositories\u2014which are publicly accessible and within the scope of permissible copyright use.\nWhat about copyright risk in suggestions? In rare instances (less than 1% based on GitHub\u2019s research), suggestions from GitHub may match examples of code used to train GitHub\u2019s AI model. Again, Copilot does not \u201clook up\u201d or \u201ccopy and paste\u201d code, but is instead using context from a user\u2019s workspace to synthesize and generate a suggestion.\nOur experience shows that matching suggestions are most likely to occur in two situations: (i) when there is little or no context in the code editor for Copilot\u2019s model to synthesize, or (ii) when a matching suggestion represents a common approach or method. If a code suggestion matches existing code, there is risk that using that suggestion could trigger claims of copyright infringement, which would depend on the amount and nature of code used, and the context of how the code is used. In many ways, this is the same risk that arises when using any code that a developer does not originate, such as copying code from an online source, or reusing code from a library. That is why responsible organizations and developers recommend that users employ code scanning policies to identify and evaluate potential matching code.\nIn Copilot, you can opt whether to allow Copilot to suggest code completions that match publicly available code on GitHub.com. For more information, see \"Configuring GitHub Copilot settings on GitHub.com\". If you have allowed suggestions that match public code, GitHub Copilot can provide you with details about the matching code when you accept such suggestions. Matching code does not necessarily mean copyright infringement, so it is ultimately up to the user to determine whether to use the suggestion, and what and who to attribute (along with other license compliance) in appropriate circumstances.\nDoes GitHub Copilot include a filtering mechanism to mitigate risk?\nYes, GitHub Copilot does include an optional code referencing filter to detect and suppress certain suggestions that match public code on GitHub.\nGitHub has created a duplication detection filter to detect and suppress suggestions that contain code segments over a certain length that match public code on GitHub. This filter can be enabled by the administrator for your enterprise and it can apply for all organizations within your enterprise, or the administrator can defer control to individual organizations.\nWith the filter enabled, Copilot checks code suggestions for matches or near-matches against public code on GitHub of 65 lexemes or more (on average,150 characters). If there is a match, the suggestion will not be shown to the user.\nIn addition to off-topic, harmful, and offensive output filters, GitHub Copilot also scans the outputs for vulnerable code.\nDoes GitHub Copilot include features to make it easier for users to identify potentially relevant open source licenses for matching suggestions?\nYes, GitHub Copilot is previewing a code referencing feature as an additional tool to assist users to find and review potentially relevant open source licenses. Code referencing is currently available in Visual Studio Code. This feature searches across public GitHub repositories for code that matches a Copilot suggestion. If there\u2019s a match, users will find its information displayed in the Copilot console log, including where the match occurred, any applicable licenses, and a deep link to learn more. The deep link will take users to a navigable page on GitHub.com to browse examples of the code match and their repository licenses, and see how many repositories\u2014including ones without licenses\u2014that code appears in, as well as links to those repositories. Copilot users can review this information to determine whether the applicable suggestions are suitable for use, and whether additional measures may be necessary to use them.\nWho owns the suggestions provided by GitHub Copilot?\nWe don\u2019t determine whether a suggestion is capable of being owned, but we are clear that GitHub does not claim ownership of a suggestion. Whether a suggestion generated by an AI model can be owned depends on many factors (e.g. the intellectual property law in the relevant country, the length of the suggestion, the extent that suggestion is considered \u2018functional\u2019 instead of expressive, etc).\nIf a suggestion is capable of being owned, our terms are clear: GitHub does not claim ownership.\nGitHub does not claim ownership of any suggestion. In certain cases, it is possible for Copilot to produce similar suggestions to different users. For example, two unrelated users both starting new files to code the quicksort algorithm in Java will likely get the same suggestion. The possibility of providing similar suggestions to multiple users is a common part of generative AI systems.\nCan GitHub Copilot introduce insecure code in its suggestions?\nPublic code may contain insecure coding patterns, bugs, or references to outdated APIs or idioms. When GitHub Copilot synthesizes code suggestions based on this data, it can also synthesize code that contains these undesirable patterns. Copilot has filters in place that either block or notify users of insecure code patterns that are detected in Copilot suggestions. These filters target the most common vulnerable coding patterns, including hardcoded credentials, SQL injections, and path injections. Additionally, in recent years we\u2019ve provided tools such as GitHub Advanced Security, GitHub Actions, Dependabot, and CodeQL to open source projects to help improve code quality. Of course, you should always use GitHub Copilot together with good testing and code review practices and security tools, as well as your own judgment.\nIs GitHub Copilot intended to fully automate code generation and replace developers?\nNo. Copilot is a tool intended to make developers more efficient. It\u2019s not intended to replace developers, who should continue to apply the same sorts of safeguards and diligence they would apply with regard to any third-party code of unknown origin.\nThe product is called \u201cCopilot\u201d not \u201cAutopilot\u201d and it\u2019s not intended to generate code without oversight. You should use exactly the same sorts of safeguards and diligence with Copilot\u2019s suggestions as you would use with any third-party code.\nIdentifying best practices for use of third party code is beyond the scope of this section. That said, whatever practices your organization currently uses \u2013 rigorous functionality testing, code scanning, security testing, etc. \u2013 you should continue these policies with Copilot\u2019s suggestions. Moreover, you should make sure your code editor or editor does not automatically compile or run generated code before you review it.\nCan GitHub Copilot users simply use suggestions without concern?\nNot necessarily. GitHub Copilot users should align their use of Copilot with their respective risk tolerances.\nAs noted above, GitHub Copilot is not intended to replace developers, or their individual skill and judgment, and is not intended to fully automate the process of code development. The same risks that apply to the use of any third-party code apply to the use of Copilot\u2019s suggestions.\nDepending on your particular use case, you should consider implementing the protections discussed above. It is your responsibility to assess what is appropriate for the situation and implement appropriate safeguards.\nYou\u2019re entitled to IP indemnification from GitHub for the unmodified suggestions when Copilot\u2019s filtering is enabled. If you do elect to enable this feature, the copyright responsibility is ours, not our customers. As part of our ongoing commitment to responsible AI, GitHub and Microsoft extends our IP indemnity and protection support to our customers who are empowering their teams with GitHub Copilot. See Microsoft's Copilot Copyright Commitment for more details.\nDoes GitHub Copilot support accessibility features?\nWe are conducting internal testing of GitHub Copilot\u2019s ease of use by developers with disabilities and working to ensure that GitHub Copilot is accessible to all developers. Please feel free to share your feedback on GitHub Copilot accessibility in our feedback forum.\nDoes GitHub Copilot produce offensive outputs?\nGitHub Copilot includes filters to block offensive language in the prompts and to avoid synthesizing suggestions in sensitive contexts. We continue to work on improving the filter system to more intelligently detect and remove offensive outputs. If you see offensive outputs, please report them directly to copilot-safety@github.com so that we can improve our safeguards. GitHub takes this challenge very seriously and we are committed to addressing it.\nWill GitHub Copilot work as well using languages other than English?\nGiven public sources are predominantly in English, GitHub Copilot will likely work less well in scenarios where natural language prompts provided by the developer are not in English and/or are grammatically incorrect. Therefore, non-English speakers might experience a lower quality of service.\nWhat data has GitHub Copilot been trained on?\nGitHub Copilot is powered by generative AI models developed by GitHub, OpenAI, and Microsoft. It has been trained on natural language text and source code from publicly available sources, including code in public repositories on GitHub.\nData from June 2023. Additional research can be found here.\nFeature in public beta for Copilot Pro and Business plans. Requires use of repositories, issues, discussions, Actions, and other features of GitHub.\nAuthentication with SAML single sign-on (SSO) available for organizations using GitHub Enterprise Cloud."
    },
    {
      "url": "https://venturebeat.com/terms-of-service/",
      "text": "THIS SITE AND RELATED SERVICES ARE PROVIDED SUBJECT TO THESE TERMS AND CONDITIONS. PLEASE READ THE FOLLOWING INFORMATION CAREFULLY. YOUR CONTINUED USE OF THIS SITE WILL INDICATE YOUR AGREEMENT TO BE BOUND BY THE TERMS AND CONDITIONS SET FORTH BELOW. IF YOU DO NOT AGREE TO THESE TERMS AND CONDITIONS, PROMPTLY EXIT THIS SITE.\nThese Terms of Service (the \u201cTerms\u201d) govern each website, mobile site, application, and/or other service, regardless of how distributed, transmitted, published, or broadcast (each, a \u201cSite\u201d or \u201cService\u201d) provided by VentureBeat, its parent, subsidiaries and/or affiliates (\u201cwe,\u201d \u201cus,\u201d or \u201cour\u201d) that links to this User Agreement and Privacy Policy, which is binding on all those who access, visit and/or use the Service, whether acting as an individual or on behalf of an entity, including you and all persons, entities, or digital engines of any kind that harvest, crawl, index, scrape, spider, or mine digital content by an automated or manual process or otherwise (collectively, \u201cyou\u201d or \u201cyour\u201d). As a condition of your use of this Site and Services, you warrant that you will not use the Site and Services for any purpose that is unlawful of prohibited by these Terms.\n1. Copies of Terms and Changes\nVentureBeat may occasionally change these Terms, so we encourage you to review them regularly. The most current version of the Terms (along with their effective date) will be linked from each of the Site and Services. If you continue to use the VentureBeat Site and Services after we change the Terms, you accept any and all changes. You may print a copy of these Terms using the print button or feature in your browser. We suggest retaining a copy for your future reference.\n2. Privacy Policy; Additional Terms\nOur Privacy Policy describes what we do with all the data that you provide or that we may collect about you through the Site and Services, and you consent to our use of data in compliance with our Privacy Policy.\nAdditional terms may apply to your use of specific parts of our Site and Services. If so, we will provide these terms to you or post them on the Site and Services to which they apply; they are incorporated by reference into these Terms. If there is any conflict between these Terms and any additional terms that apply to a particular Site or Service, the additional terms will control.\nContests or promotions on the VentureBeat Site and Services may also have additional rules and requirements, such as age or geographic restrictions, and you are responsible for understanding and complying with these rules and requirements.\n3. Registration and Access Controls\nYou are responsible for maintaining the confidentiality of your login names and passwords and you accept responsibility for all activities, charges, and damages that occur under your account. If you have reason to believe that someone is using your account without your permission, you should contact us immediately. We will not be responsible for any loss or damage resulting from your failure to notify us of unauthorized use.\nIf we request registration information from you, you must provide us with accurate and complete information and must update the information when it changes. You are responsible for updating the registration information to ensure it continues to be current, complete, and accurate. We may accept or reject registration requests for the Site and Services in our sole discretion and may revoke registration and accounts at any time, without cause or prior notice.You may not access any age-restricted Services unless you are above the required age.\n4. Intellectual Property; License\nThe content, information, data, designs, code, and all materials associated with the Site and Services (\u201cContent\u201d) are protected by intellectual property and other laws. You must comply with all laws and applicable copyright, trademark, or other legal notices or restrictions. All trademarks, service marks, icons, and logos used in this Site and in the Content are our trademarks, service marks or logos or those of their respective owners.\nSubject to these Terms, you agree to access and use the Site and Services only for your personal, non-commercial use. We reserve all other rights to the Content, and you may not otherwise copy, reproduce, distribute, publish, display, perform, or create derivative works of the Site and Services or Content without our permission. You also may not transfer or sublicense this limited right, or resell the Site and Services. Finally, you must keep intact all copyright, trademark, and other proprietary notices on or associated with the Site, Services, and Content.\na. Viral Distribution\nWe may choose to specifically authorize you to redistribute certain items of the Content, only for personal, non-commercial use. We will expressly identify the Content that you are authorized to use and describe ways you may redistribute it (such as via email, blogs, or embedded players, or mash-ups). We may revoke this authorization at any time. If you are authorized and do choose to redistribute Content, you must be able to edit or delete publicly posted Content and you must agree to edit or delete it promptly upon our request.\nb. Commercial Licenses\nYou must obtain written permission for commercial use of VentureBeat Content or the Site and Services. If you wish to license Content from the Site and Services, please contact us at repub@venturebeat.com.\n5. Legal Complaints\nIf you believe that Content on the Site and Services infringes your copyright or the rights of any third party, please contact us at copyright@venturebeat.com. If you have a legal complaint other than a copyright claim, please contact us at legal@venturebeat.com.\n6. User Submissions\nSome areas of the Site and Services allow you to submit audio, video, text, or other materials (collectively, \u201cUser Submissions\u201d). When you provide User Submissions, you grant to VentureBeat, its parent, subsidiaries, affiliates, and partners a non-exclusive, worldwide, irrevocable, perpetual,royalty-free, fully sublicenseable license to use, distribute, edit, display, archive, publish, sublicense, perform, reproduce, make available, transmit, broadcast, sell, translate, and create derivative works of those User Submissions, and your name, voice, likeness and other identifying information where part of a User Submission, in any form, media, software, or technology of any kind now known or developed in the future, including, without limitation, for developing, manufacturing, and marketing products. You waive any moral rights you have in your User Submissions.\nWe respect your ownership of User Submissions.\nIf you owned a User Submission before providing it to us, you will continue owning it after providing it to us, subject to any rights granted in the Terms and any access granted to others. If you delete a User Submission from the Site and Services, our general license to that User Submission will end after a reasonable period of time needed for the deletion to take complete effect. However, the User Submission may still exist in private backup copies. If your User Submission is shared with third parties, those third parties may have retained copies of your User Submissions. And, if we made use of your User Submission before you deleted it, we will continue to have the right to make, duplicate, redistribute, and sublicense those pre-existing uses, even after you delete the User Submission.\nTerminating your account on a Service will not automatically delete your User Submissions.\nWe may refuse or remove a User Submission without notice. However, we have no obligation to monitor User Submissions, and you agree that neither we nor our parent, subsidiaries, affiliates, employees, or agents will be liable for User Submissions or any loss or damage resulting from User Submissions. Except as provided in the Privacy Policy, we do not guarantee that User Submissions will be private, even if the User Submission is in a password-protected area. You should not provide User Submissions that you wish protected from others.\nYou represent and warrant that you have all rights necessary to grant to VentureBeat the license above and that none of your User Submissions are defamatory, violate any rights of third parties (including intellectual property rights or rights of publicity or privacy), or violate applicable law.\n7. Accuracy of Information; Third-Party Content\nAlthough we attempt to ensure the integrity and accurateness of the Site, Services and Content, we make no guarantees whatsoever as to the correctness or accuracy of the foregoing. It is possible that the Site, Content, and Services could include typographical errors, inaccuracies or other errors, and that unauthorized additions, deletions and alterations could be made to them by third parties. In the event that an inaccuracy arises, please inform us so that it can be corrected. We may change or discontinue the Site, Content, and Services without notice.\nWe sometimes offer third party content or link to third party websites on the Site and Services. We do not endorse or evaluate third party content and websites, and we do not assume responsibility for them. All third party content is provided completely as-is, without warranties of any kind. Your sole remedy in the event of any issue with the third party content is to cease using it.You should review their terms of use and privacy policies before you use their services.\n8. Fee-Based Services\nIf you purchase fee-based products or features, you agree to the terms and conditions governing all such purchases, including all requirements to pay applicable fees. We will notify you of any changes to charges.\nWe may offer trial subscriptions to paid services for free or at special discounted prices. Unless otherwise stated, trial subscriptions and any other subscription services we provide will be automatically renewed at the current subscription rate if you do not cancel before the end of the trial period. You may need to cancel your subscription at least 10 days prior to its renewal date in order to avoid further charges.\nUnless otherwise stated, all fees and charges are non-refundable, including for unused portions of cancelled subscriptions. We do not provide price protection.\n9. Acceptable Use\nThe Site and Services have been designed to present VentureBeat Content in a unique way. You agree not to access the Site and Services using any interface other than ours, unless we give you express permission.\nWithout limiting any other provision in these Terms, you may not use or help others to use the Site and Services to do the following:\n- Threaten, defame, stalk, abuse, or harass other persons or engage in illegal activities;\n- Link to the Site and Services from a site that is inappropriate, profane, vulgar, offensive, false, disparaging, defamatory, obscene, illegal, sexually explicit, racist, or that promotes violence, racial hatred, or terrorism, or that we deem, in our sole discretion, to be otherwise objectionable;\n- Transmit any material that is inappropriate, profane, vulgar, offensive, false, disparaging, defamatory, obscene, illegal, sexually explicit, racist, or that promotes violence, racial hatred, or terrorism, or that we deem, in our sole discretion, to be otherwise objectionable;\n- Frame the Site and Services, display the Site and Services in connection with an unauthorized logo or mark, or do anything that could falsely suggest a relationship between VentureBeat and any third party or potentially deprive us of revenue (including, without limitation, revenue from advertising, branding, or promotional activities);\n- Engage in unauthorized spidering, \u201cscraping,\u201d or harvesting of the Site or Content, or contact or other personal information, or use any other unauthorized automated means to compile such information;\n- Violate any person\u2019s or entity\u2019s legal rights (including, without limitation, intellectual property, privacy, and publicity rights), transmit material that violates or circumvents such rights, or remove or alter intellectual property or other legal notices;\n- Transmit files that contain viruses, spyware, adware, or other harmful code;\n- Defeat any access controls, access any portion of the Site and Services that we have not authorized you to access (including password-protected areas), link to password-protected areas, attempt to access or use another user\u2019s account or information, or allow anyone else to use your account or access credentials.\n- Advertise or promote goods or services without our permission (including sending spam);\n- Interfere with others using the Site and Services or disrupt the Site and Services; or,\n- Transmit, collect, or access personally identifiable information about other users without the consent of those users and VentureBeat;\n- Impersonate any person or entity or otherwise misrepresent your affiliation or the origin of materials you transmit.\n10. Site Access; Account Deletion\nWe may take any of the following actions in our sole discretion at any time for any reason without giving you prior notice:\n- Restrict or terminate your access to the Site and Services;\n- Change or discontinue the Site and Services;\n- Deactivate your accounts and delete all related information and files in your accounts;\n- Provide information concerning you and your activities to comply with applicable laws or respond to court order, subpoenas, or other lawful requests, or if we believe doing so would protect your safety or that of another person or protect the security of the Site and Services, or as otherwise described in the Privacy Policy.\nWe will not be liable to you or any other third party for taking any of these actions and we will not be limited to the remedies above if you violate any of these Terms.\nIf you do not agree to the Terms listed here, you should immediately stop using the VentureBeat Site and Services. If you want to delete your account on a Service, please use the instructions posted on the Service at which you obtained the account. Any User Submissions you made while using the Site and Services will continue to be governed by Section 6 of these Terms. Sections 6 and 11-15 of these Terms will survive any termination of your access to the Site and Services, whether we terminate your access or you voluntarily discontinue your use.\n11. Indemnification\nYou will defend, indemnify, and hold harmless VentureBeat, its parent, subsidiaries, affiliates, and the directors, officers, employees, shareholders, vendors, partners, contractors, agents, licensors, suppliers, or other representatives of each of them and all of their successors and assigns (collectively, the \u201cVentureBeat Parties\u201d) with respect to all claims, costs (including attorney\u2019s and experts\u2019 fees and costs), damages, liabilities, fines, sanctions, and expenses or obligations of any kind, arising out of or in connection with your use or misuse of the Site and Services (including, without limitation, any breach of these terms or use of your account, whether or not authorized by you, and claims arising from User Submissions). VentureBeat retains the right to assume the exclusive defense and control of any claim subject to indemnification, and in such cases you agree to cooperate with us to defend such claim. You may not settle any claim covered by this Section 11 without VentureBeat\u2019s prior written approval.\n12. Governing Law, Venue, and Jurisdiction\nThese Terms and all claims arising from or related to your use of the Site and Services will be governed by and construed in accordance with the laws of the State of California.\nWith respect to any disputes or claims not subject to arbitration (as set forth below), you agree to exclusive jurisdiction in the state and federal courts in San Francisco, California. Notwithstanding any other provision of these Terms, we may seek injunctive or other equitable relief from any court of competent jurisdiction.\nRegardless of any statute or law to the contrary, you must file any claim or action related to use of the Site and Services or these Terms within one year after such claim or action accrued. Otherwise, you will waive the claim or action.\n13. Arbitration\nWe may elect to resolve any controversy or claim arising out of or relating to these Terms or the Site and Services by binding arbitration in accordance with the commercial arbitration rules of the American Arbitration Association. Unless we establish a different location, arbitration hearings will be held in San Francisco, California. The arbitrator\u2019s award will be binding and may be entered as a judgment in any court of competent jurisdiction.\n14. Miscellaneous\nWe may be required by state or federal law to notify you of certain events. You hereby acknowledge and agree that such notices will be effective upon our posting them on our sites or delivering them to you via email. You may update your email address by visiting the Site and Services where you have provided contact information. If you do not provide us with accurate information, we will not be responsible for failure to notify you. Our failure to exercise or enforce any right or provision in these Terms will not constitute a waiver of such right or provision. These Terms, including all additional terms, conditions, and policies on the Site and Services, constitute the entire agreement between you and us and supersede all prior agreements.\n15. Disclaimers; Limitation of Liability\nVENTUREBEAT PARTIES DO NOT WARRANT: (1) THAT the Site, Services, and Content, ANY OF the Site and Services\u2019 FUNCTIONS OR ANY CONTENT OR SOFTWARE CONTAINED THEREIN WILL BE UNINTERRUPTED OR ERROR-FREE; (2) THAT DEFECTS WILL BE CORRECTED; (3) THAT the Site, Services, Content, OR THE SERVERS HOSTING THEM ARE FREE OF VIRUSES OR OTHER HARMFUL CODE; OR (4) THAT the Site, Services, Content OR INFORMATION AVAILABLE THROUGH the Site and Services WILL CONTINUE TO BE AVAILABLE. VENTUREBEAT PARTIES DISCLAIM ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, WITHOUT LIMITATION, NONINFRINGEMENT, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND TITLE. the Site and Services, INCLUDING, WITHOUT LIMITATION, ALL CONTENT, SOFTWARE, AND FUNCTIONS MADE AVAILABLE ON OR ACCESSED THROUGH OR SENT FROM the Site and Services, ARE PROVIDED \u201cAS IS,\u201d \u201cAS AVAILABLE,\u201d AND \u201cWITH ALL FAULTS,\u201d WITHOUT WARRANTIES OF ANY KIND.\nVENTUREBEAT PARTIES WILL NOT BE LIABLE TO YOU OR ANYONE ELSE FOR ANY LOSS OR DAMAGES OF ANY KIND (INCLUDING, WITHOUT LIMITATION, FOR ANY SPECIAL, DIRECT, INDIRECT, INCIDENTAL, EXEMPLARY, ECONOMIC, PUNITIVE, OR CONSEQUENTIAL DAMAGES) IN CONNECTION WITH the Site, Content, and Services OR YOUR USER SUBMISSIONS, EVEN IF FORESEEABLE OR EVEN IF ONE OR MORE OF VENTUREBEAT PARTIES HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES (INCLUDING, WITHOUT LIMITATION, WHETHER CAUSED IN WHOLE OR IN PART BY NEGLIGENCE, GROSS NEGLIGENCE, OR OTHERWISE, BUT EXCLUDING WILLFUL MISCONDUCT). VENTUREBEAT PARTIES\u2019 LIABILITY IN CONNECTION WITH the Site, Content, and Services OR YOUR USER SUBMISSIONS FOR WILLFUL MISCONDUCT WILL NOT EXCEED THE AMOUNT, IF ANY, PAID BY YOU TO VENTUREBEAT FOR THE SPECIFIC SERVICE AS TO WHICH THE LIABILITY ARISES IN THE THREE MONTHS IMMEDIATELY PRECEDING THE FIRST EVENT GIVING RISE TO THE CLAIM.\nYOUR ACCESS TO AND USE OF the Site, Content, and Services IS AT YOUR RISK. IF YOU ARE DISSATISFIED WITH the Site, Content, and Services OR ANY OF THE CONTENT, YOUR SOLE AND EXCLUSIVE REMEDY IS TO DISCONTINUE ACCESSING AND USING the Site, Content, and Services.\nYOU ACKNOWLEDGE AND AGREE THAT IF YOU INCUR ANY DAMAGES THAT ARISE OUT OF VENTUREBEAT PARTIES\u2019 ACTS OR OMISSIONS, THE DAMAGES, IF ANY, ARE NOT IRREPARABLE AND ARE NOT SUFFICIENT TO ENTITLE YOU TO AN INJUNCTION OR OTHER EQUITABLE RELIEF RESTRICTING EXPLOITATION OF ANY WEBSITE, PROPERTY, PRODUCT, PROGRAM, TELEVISION SHOW, MOTION PICTURE, OR OTHER AUDIO/VISUAL CONTENT OWNED OR CONTROLLED BY VENTUREBEAT PARTIES, INCLUDING WITHOUT LIMITATION the Site and Services (INCLUDING THOSE INCORPORATING USER SUBMISSIONS).\nYOU ACKNOWLEDGE THAT YOU MAY BE WAIVING RIGHTS WITH RESPECT TO CLAIMS THAT ARE UNKNOWN OR ARE UNSUSPECTED. ACCORDINGLY, YOU AGREE TO WAIVE THE BENEFIT OF ANY LAW, INCLUDING, TO THE EXTENT APPLICABLE, CALIFORNIA CIVIL CODE \u00a7 1542 OR SIMILAR LAWS OF OTHER JURISDICTIONS, THAT OTHERWISE MIGHT LIMIT YOUR WAIVER OF SUCH CLAIMS.\nSOME JURISDICTIONS DO NOT ALLOW LIMITATIONS ON IMPLIED WARRANTIES OR THE EXCLUSION OR LIMITATION OF CERTAIN DAMAGES, SO SOME OF THE ABOVE LIMITATIONS AND EXCLUSIONS MAY NOT APPLY TO YOU."
    },
    {
      "url": "https://www.anthropic.com/customers/european-parliament",
      "text": "European Parliament expands access to their archives with Claude\nThe European Parliament has transformed the accessibility of the Parliament's archives. Leveraging Anthropic's Claude in Amazon Bedrock, the EU Parliament has created 'Ask the EP Archives', also known as Archibot, a sophisticated AI assistant that makes over 2.1 million official documents readily available to researchers, policymakers, educators, and the public.\nThe Archives Unit at the European Parliament leads the charge of preserving, managing, and processing all documents that have been produced and received by the European Parliament dating back to 1952.\nFor years, the archivists were confronted with two main challenges: making the archives easy to search and ensuring they\u2019re accessible to anyone who needs to access them. The arrival of generative AI has dramatically changed how archivists and researchers can navigate the millions of documents within the archives.\nArchibot, now available on the European Parliament's archive website, offers users worldwide easy access to EU Parliament documents in multiple languages - including resolutions, positions, policies, and inter-institutional negotiations - while also helping researchers and staff analyze data and create comprehensive reports.\nThe project showcases how generative AI can be used by governments to enhance transparency and accessibility for citizens. What once required deep searches into the EU\u2019s physical archives is now available instantly - at everyone\u2019s fingertips - bringing the story of European democracy to life for citizens everywhere.\nKey features of Archibot include:\n- Advanced search and summarisation: Allowing users to navigate and synthesize vast amounts of information quickly\n- Report building: Allowing users to extrapolate information and build reports\n- Multilingual capabilities: Expanding Language support beyond French to serve all EU member states\n- Global accessibility: Available to users worldwide through the European Parliament's website\n- Constitutional AI: Ensuring trustworthy and controlled use of AI technology\nThe project has already demonstrated significant benefits:\n- Reduces document search and analysis time by 80%, significantly boosting efficiency.\n- Provides policymakers and researchers with quick access to historical context and precedents.\n- Has been used by hundreds of educators and students for an all-access window into European parliamentary history.\nSince launching Claude in Europe earlier this year, Anthropic has continued to bring the latest in safe and responsible generative AI to European businesses and consumers. This includes Claude 3.5 - one of the most powerful large language models (LLMs) on the market - alongside the Claude Team plan, Claude Enterprise, and Claude\u2019s Artifacts feature. Claude is available on iOS and Android, further enhancing accessibility to everyday users across Europe and other markets."
    },
    {
      "url": "https://www.anthropic.com/claude-code",
      "text": "Your code\u2019s new collaborator\nUnleash Claude\u2019s raw power directly in your terminal. Search million-line codebases instantly. Turn hours-long workflows into a single command. Your tools. Your workflow. Your codebase, evolving at thought speed.\nTrusted by engineers at\nCommand-line AI, from concept to commit\nWatch as Claude Code tackles an unfamiliar Next.js project, builds new functionality, creates tests, and fixes what\u2019s broken\u2014all from the command line. Join Boris and Cat as they show you what coding feels like when you\u2019re not doing it alone.\nDeep coding at terminal velocity\nClaude Code embeds Claude Opus 4.1\u2014the same model our researchers and engineers use\u2014right in your terminal. It has deep codebase awareness and the ability to edit files and run commands directly in your environment.\nPowerful intelligence\n- Uses agentic search to understand your entire codebase without manual context selection\n- Makes coordinated changes across multiple files\n- Optimized specifically for code understanding and generation with Claude Opus 4.1\nWorks where you work\n- Lives right inside your terminal\u2014no context switching\n- Integrates with VS Code and JetBrains IDEs\n- Leverages your test suites and build systems\nYou\u2019re in control\n- Never modifies your files without explicit approval\n- Adapts to your coding standards and patterns\n- Configurable; build on the SDK or run on GitHub Actions\nWorks with your IDEs\nClaude works directly in VS Code and JetBrains, seeing your entire codebase instead of just isolated snippets. It understands your project structure and existing patterns, making suggestions that actually fit and presenting them directly in your code files. No copying and pasting\u2014just building.\n... and your favorite command line tools\nYour terminal is where real work happens. Claude Code connects with the tools that power development\u2014deployment, databases, monitoring, version control. Rather than adding another interface to juggle, it enhances your existing stack. Less context-switching.\nWhat could you do with Claude Code?\nInstall Node.js 18+, then run:\nCode onboarding\nClaude Code maps and explains entire codebases in a few seconds. It uses agentic search to understand project structure and dependencies without you having to manually select context files.\nTurn issues into PRs\nStop bouncing between tools. Claude Code integrates with GitHub, GitLab, and your command line tools to handle the entire workflow\u2014reading issues, writing code, running tests, and submitting PRs\u2014all from your terminal while you grab coffee.\nMake powerful edits\nClaude Code\u2019s understanding of your codebase and dependencies enables it to make powerful, multi-file edits that actually work.\nBig fans of Claude Code\nWhat developers say about Claude Code\nClaude Code has dramatically accelerated our team\u2019s coding efficiency. I can now write EDA code in a notebook\u2014pulling data, training a model, and evaluating it with basic metrics\u2014and then ask Claude to convert that into a Metaflow pipeline. This process saves 1-2 days of routine (and often boring!) work per model.\nClaude Code marks a threshold moment for AI in software development. At Intercom, it enables us to build applications we wouldn\u2019t have had bandwidth for\u2014from AI labeling tools to ROI calculators for our Sales team. Its ability to handle complex, multi-step tasks sets it apart from alternatives. Claude Code is fundamentally changing what\u2019s possible for our engineering teams.\nGet started with Claude Code\nPro\n$17Per month with annual subscription discount; $200 billed up front. $20 if billed monthly.Claude Code is included in your Pro plan. Perfect for short coding sprints in smaller codebases with Claude Sonnet 4.Max 5x\n$100Per person billed monthlyClaude Code is included in your Max plan. Great value for everyday use in larger codebases with access to both Claude Sonnet 4 & Claude Opus 4.1.Max 20x\n$200Per person billed monthlyEven more Claude Code included in your Max plan. Great value for power users with the most access to Claude Opus 4.1.\n*Additional usage limits apply. Prices shown do not include applicable tax.\nAnthropic API\nPay-as-you-go with standard Anthropic API pricing.\nDeploy Claude Code to unlimited developers\nNo per-seat fees or platform charges\nSet spend limits and monitor usage through the Console\nSupport for Amazon Bedrock and Google Cloud Vertex AI\nPrices shown do not include applicable tax. Usage limits may apply.\nEducation plan\nA comprehensive university\u2010wide plan for institutions, including its students, faculty, and staff.\nStudent & faculty access\nComprehensive access for all university members at discounted rates\nAcademic research & learning mode\nDedicated API credits and educational features for student learning\nTraining & enablement\nResources for successful adoption across your institution\nGet the technical rundown\nFAQs\nCreate what\u2019s exciting. Maintain what\u2019s essential.\nInstall Node.js 18+, then run:"
    },
    {
      "url": "https://www.anthropic.com/news/anthropic-amazon-trainium",
      "text": "Powering the next generation of AI development with AWS\nToday we\u2019re announcing an expansion of our collaboration with Amazon Web Services (AWS), deepening our work together to develop and deploy advanced AI systems. This expanded partnership includes a new $4 billion investment from Amazon and establishes AWS as our primary cloud and training partner. This will bring Amazon's total investment in Anthropic to $8 billion, while maintaining their position as a minority investor.\nCollaboration on AWS Trainium hardware and software\nAnthropic is working closely with Annapurna Labs at AWS on the development and optimization of future generations of Trainium accelerators, advancing the capabilities of specialized machine learning hardware. Through deep technical collaboration, we\u2019re writing low-level kernels that allow us to directly interface with the Trainium silicon, and contributing to the AWS Neuron software stack to strengthen Trainium. Our engineers work closely with Annapurna\u2019s chip design team to extract maximum computational efficiency from the hardware, which we plan to leverage to train our most advanced foundation models.\nThis close hardware-software development approach, combined with the strong price-performance and massive scalability of Trainium platforms, enables us to optimize every aspect of model training from the silicon up through the full stack.\nClaude as core infrastructure\nThrough Amazon Bedrock, Claude has become core infrastructure for tens of thousands of companies seeking reliable, practical AI solutions at scale. Pfizer uses the latest Claude models in Amazon Bedrock to accelerate research and delivery timelines for critical medicines, while saving tens of millions in operational costs. Intuit uses Claude in Amazon Bedrock to explain complex tax calculations for millions of users during tax season. Perplexity, an AI-powered search engine, delivers more accurate responses at twice the speed by using Claude in Amazon Bedrock, and the European Parliament leverages Claude to power \u2018Archibot\u2019, making 2.1 million official documents instantly searchable and easier to analyze in multiple languages while reducing research time by 80%.\nEnabling secure, customizable AI solutions\nClaude in Amazon Bedrock provides access to frontier intelligence within AWS, allowing customers to keep models and data in the same cloud environment. Building on this unified architecture, organizations can fine-tune Claude models in Amazon Bedrock, including Claude 3 Haiku, to tailor outputs to their specific requirements and boost accuracy for domain-specific tasks. Customer proprietary training data remains secure within AWS, preserving our commitment to safety and privacy.\nBy leveraging AWS\u2019s robust security features and compliance certifications, organizations can confidently deploy AI solutions that meet stringent regulatory requirements. Government customers and industry partners can access Claude\u2019s capabilities through Amazon Bedrock in AWS GovCloud (US). Additionally, government customers can access Claude through Amazon SageMaker in highly controlled environments like the AWS Secret and Top Secret Cloud Regions.\nPowering next-generation AI research and development\nTogether with AWS, we\u2019re laying the technological foundation\u2014from silicon to software\u2014that will power the next generation of AI research and development. By combining Anthropic\u2019s expertise in frontier AI systems with AWS\u2019s world-class infrastructure, we\u2019re building a secure, enterprise-ready platform that gives organizations of all sizes access to the forefront of AI technology.\nIf you're interested in using Claude in Amazon Bedrock, you can get started at aws.amazon.com/bedrock/claude/."
    },
    {
      "url": "https://hai.stanford.edu/ai-index/2025-ai-index-report",
      "text": "Get the latest news, advances in research, policy work, and education program updates from HAI in your inbox weekly.\nSign Up For Latest News\nWelcome to the seventh edition of the AI Index report. The 2024 Index is our most comprehensive to date and arrives at an important moment when AI\u2019s influence on society has never been more pronounced.\nThe AI Index is an independent initiative at the Stanford Institute for Human-Centered Artificial Intelligence (HAI), led by the AI Index Steering Committee, an interdisciplinary group of experts from across academia and industry.\nThe AI Index is an independent initiative at the Stanford Institute for Human-Centered Artificial Intelligence (HAI), led by the AI Index Steering Committee, an interdisciplinary group of experts from across academia and industry.\nThis year we significantly expanded the amount of data available in the report, worked with a broader set of external organizations to calibrate our data, and deepened our connections with Stanford HAI.\nThe AI Index Report tracks, collates, distills, and visualizes data relating to artificial intelligence.\nIts mission is to provide unbiased, rigorous, and comprehensive data for policymakers, researchers, journalists, executives, and the general public to develop a deeper understanding of the complex field of AI.\nArtificial Intelligence has leapt to the forefront of global discourse, garnering increased attention from practitioners, industry leaders, policymakers, and the general public. The diversity of opinions and debates gathered from news articles this year illustrates just how broadly AI is being investigated, studied, and applied. However, the field of AI is still evolving rapidly and even experts have a hard time understanding and tracking progress across the field.\nArtificial Intelligence has leapt to the forefront of global discourse, garnering increased attention from practitioners, industry leaders, policymakers, and the general public. The diversity of opinions and debates gathered from news articles this year illustrates just how broadly AI is being investigated, studied, and applied. However, the field of AI is still evolving rapidly and even experts have a hard time understanding and tracking progress across the field.\nAt Stanford HAI, we believe AI is poised to be the most transformative technology of the 21st century. But its benefits won\u2019t be evenly distributed unless we guide its development thoughtfully. The AI Index offers one of the most comprehensive, data-driven views of artificial intelligence. Recognized as a trusted resource by global media, governments, and leading companies, the AI Index equips policymakers, business leaders, and the public with rigorous, objective insights into AI\u2019s technical progress, economic influence, and societal impact.\nRead the translation\nIn 2023, researchers introduced new benchmarks\u2014MMMU, GPQA, and SWE-bench\u2014to test the limits of advanced AI systems. Just a year later, performance sharply increased: scores rose by 18.8, 48.9, and 67.3 percentage points on MMMU, GPQA, and SWE-bench, respectively. Beyond benchmarks, AI systems made major strides in generating high-quality video, and in some settings, language model agents even outperformed humans in programming tasks with limited time budgets.\nFrom healthcare to transportation, AI is rapidly moving from the lab to daily life. In 2023, the FDA approved 223 AI-enabled medical devices, up from just six in 2015. On the roads, self-driving cars are no longer experimental: Waymo, one of the largest U.S. operators, provides over 150,000 autonomous rides each week, while Baidu\u2019s affordable Apollo Go robotaxi fleet now serves numerous cities across China.\nIn 2024, U.S. private AI investment grew to $109.1 billion\u2014nearly 12 times China\u2019s $9.3 billion and 24 times the U.K.\u2019s $4.5 billion. Generative AI saw particularly strong momentum, attracting $33.9 billion globally in private investment\u2014an 18.7% increase from 2023. AI business usage is also accelerating: 78% of organizations reported using AI in 2024, up from 55% the year before. Meanwhile, a growing body of research confirms that AI boosts productivity and, in most cases, helps narrow skill gaps across the workforce.\nIn 2024, U.S.-based institutions produced 40 notable AI models, significantly outpacing China\u2019s 15 and Europe\u2019s three. While the U.S. maintains its lead in quantity, Chinese models have rapidly closed the quality gap: performance differences on major benchmarks such as MMLU and HumanEval shrank from double digits in 2023 to near parity in 2024. Meanwhile, China continues to lead in AI publications and patents. At the same time, model development is increasingly global, with notable launches from regions such as the Middle East, Latin America, and Southeast Asia.\nAI-related incidents are rising sharply, yet standardized RAI evaluations remain rare among major industrial model developers. However, new benchmarks like HELM Safety, AIR-Bench, and FACTS offer promising tools for assessing factuality and safety. Among companies, a gap persists between recognizing RAI risks and taking meaningful action. In contrast, governments are showing increased urgency: In 2024, global cooperation on AI governance intensified, with organizations including the OECD, EU, U.N., and African Union releasing frameworks focused on transparency, trustworthiness, and other core responsible AI principles.\nIn countries like China (83%), Indonesia (80%), and Thailand (77%), strong majorities see AI products and services as more beneficial than harmful. In contrast, optimism remains far lower in places like Canada (40%), the United States (39%), and the Netherlands (36%). Still, sentiment is shifting: since 2022, optimism has grown significantly in several previously skeptical countries\u2014including Germany (+10%), France (+10%), Canada (+8%), Great Britain (+8%), and the United States (+4%).\nDriven by increasingly capable small models, the inference cost for a system performing at the level of GPT-3.5 dropped over 280-fold between November 2022 and October 2024. At the hardware level, costs have declined by 30% annually, while energy efficiency has improved by 40% each year. Open-weight models are also closing the gap with closed models, reducing the performance difference from 8% to just 1.7% on some benchmarks in a single year. Together, these trends are rapidly lowering the barriers to advanced AI.\nIn 2024, U.S. federal agencies introduced 59 AI-related regulations\u2014more than double the number in 2023\u2014and issued by twice as many agencies. Globally, legislative mentions of AI rose 21.3% across 75 countries since 2023, marking a ninefold increase since 2016. Alongside growing attention, governments are investing at scale: Canada pledged $2.4 billion, China launched a $47.5 billion semiconductor fund, France committed \u20ac109 billion, India pledged $1.25 billion, and Saudi Arabia\u2019s Project Transcendence represents a $100 billion initiative.\nTwo-thirds of countries now offer or plan to offer K\u201312 CS education\u2014twice as many as in 2019\u2014with Africa and Latin America making the most progress. In the U.S., the number of graduates with bachelor\u2019s degrees in computing has increased 22% over the last 10 years. Yet access remains limited in many African countries due to basic infrastructure gaps like electricity. In the U.S., 81% of K\u201312 CS teachers say AI should be part of foundational CS education, but less than half feel equipped to teach it.\nNearly 90% of notable AI models in 2024 came from industry, up from 60% in 2023, while academia remains the top source of highly cited research. Model scale continues to grow rapidly\u2014training compute doubles every five months, datasets every eight, and power use annually. Yet performance gaps are shrinking: the score difference between the top and 10th-ranked models fell from 11.9% to 5.4% in a year, and the top two are now separated by just 0.7%. The frontier is increasingly competitive\u2014and increasingly crowded.\nAI\u2019s growing importance is reflected in major scientific awards: two Nobel Prizes recognized work that led to deep learning (physics), and to its application to protein folding (chemistry), while the Turing Award honored groundbreaking contributions to reinforcement learning.\nAI models excel at tasks like International Mathematical Olympiad problems but still struggle with complex reasoning benchmarks like PlanBench. They often fail to reliably solve logic tasks even when provably correct solutions exist, limiting their effectiveness in high-stakes settings where precision is critical.\nThe AI Index report tracks, collates, distills, and visualizes data related to artificial intelligence (AI). Our mission is to provide unbiased, rigorously vetted, broadly sourced data in order for policymakers, researchers, executives, journalists, and the general public to develop a more thorough and nuanced understanding of the complex field of AI.\nPolicymakers use the AI Index to inform their understanding and decisions about AI. We curated a summary of highlights from the AI Index Report 2025 that are particularly relevant to policymakers and other policy audiences.\nDownload the Policy Highlights\nThis chapter explores trends in AI research and development, beginning with an analysis of AI publications, patents, and notable AI systems.\nThe Technical Performance section of this year\u2019s AI Index provides a comprehensive overview of AI advancements in 2024.\nArtificial intelligence is now deeply integrated into nearly every aspect of our lives. It is reshaping sectors like education, finance, and healthcare, where algorithm-driven insights guide critical decisions.\nGlobal private AI investment hits record high...\nThis chapter explores key trends in AI-driven science and medicine, reflecting the technology\u2019s growing impact in these fields.\nAI\u2019s advancing capabilities have captured policymakers\u2019 attention, leading to an increase in AI-related policies worldwide.\nAI has entered the public consciousness through generative AI\u2019s impact on work...\nAs AI continues to permeate broad swaths of society, it is becoming increasingly important to understand public sentiment around the technology."
    },
    {
      "url": "https://www.cnbc.com/2025/08/07/openai-launches-gpt-5-model-for-all-chatgpt-users.html",
      "text": "OpenAI on Thursday announced GPT-5, its latest and most advanced large-scale artificial intelligence model.\nThe company is making GPT-5 available to everyone, including its free users. OpenAI said the model is smarter, faster and \"a lot more useful,\" particularly across domains like writing, coding and health care.\n\"I tried going back to GPT-4, and it was quite miserable,\" OpenAI CEO Sam Altman said in a briefing with reporters.\nSince launching its AI chatbot ChatGPT in 2022, OpenAI has rocketed into the mainstream. The company said it expects to hit 700 million weekly active users on ChatGPT this week, and it is in talks with investors about a potential stock sale at a valuation of roughly $500 billion, as CNBC previously reported.\nOpenAI said GPT-5's hallucination rate is lower, which means the model fabricates answers less frequently. The company said it also carried out extensive safety evaluations while developing GPT-5, including 5,000 hours of testing.\nInstead of outright refusing to answer users' questions if they are potentially risky, GPT-5 will use \"safe completions,\" OpenAI said. This means the model will give high-level responses within safety constraints that can't be used to cause harm.\n\"GPT-5 has been trained to recognize when a task can't be finished, avoid speculation and can explain limitations more clearly, which reduces unsupported claims compared to prior models,\" said Michelle Pokrass, a post-training lead at OpenAI.\nDuring the briefing, OpenAI demonstrated how GPT-5 can be used for \"vibe coding,\" which is a term for when users generate software with AI based on a simple written prompt.\nThe company asked GPT-5 to create a web app that could help an English speaker learn French. The app had to have an engaging theme and include activities like flash cards and quizzes as well as a way to track daily progress. OpenAI submitted the same prompt into two GPT-5 windows, and it generated two different apps within seconds.\nThe apps had \"some rough edges,\" an OpenAI lead said, but users can make additional tweaks to the AI-generated software, like changing the background or adding additional tabs, as they see fit.\nGPT-5 is rolling out to OpenAI's Free, Plus, Pro and Team users on Thursday. This launch will be the first time that Free users have access to a reasoning model, which is a type of model that \"thinks,\" or carries out an internal chain of thought, before responding. If Free users hit their usage cap, they'll have access to GPT-5 mini.\nOpenAI's Plus users have higher usage limits, and Pro users have unlimited access to GPT-5 as well as access to GPT-5 Pro. ChatGPT Edu and ChatGPT Enterprise users will get access to GPT-5 roughly a week from Thursday.\n\"It's hard to believe it's only been two and a half years since @sama joined us in Redmond to show the world GPT-4 for the first time in Bing, and it's incredible to see how far we've come since that moment,\" Microsoft CEO Satya Nadella wrote in a Thursday X post, referring to OpenAI CEO Sam Altman's appearance at Microsoft headquarters in Washington in February 2023.\nThe new model is coming to Microsoft products Thursday, according to a company blog post. Microsoft 365 Copilot is getting GPT-5, as well as the Copilot for consumers and the Azure AI Foundry that developers can use to incorporate AI models into third-party applications.\nBox, a company that helps enterprises manage their computer files, has been testing GPT-5 across a wide variety of data sets in recent weeks.\nAaron Levie, the CEO of Box, said previous AI models have failed many of the company's most advanced tests because they struggle to make sense of complex math or logic within long documents. But Levie said GPT-5 is a \"complete breakthrough.\"\n\"The model is able to retain way more of the information that it's looking at, and then use a much higher level of reasoning and logic capabilities to be able to make decisions,\" Levie told CNBC in an interview.\nOpenAI is releasing three different versions of the model for developers through its application programming interface, or API. Those versions, gpt-5, gpt-5-mini and gpt-5-nano, are designed for different cost and latency needs.\nEarlier this week, OpenAI released two open-weight language models for the first time since it rolled out GPT-2 in 2019. Those models were built to serve as lower-cost options that developers, researchers and companies can easily run and customize.\nBut with GPT-5, OpenAI also has a broader consumer audience in mind. The company said interacting with the model feels natural and \"more human.\"\nAltman said GPT-5 is like having a team of Ph.D.-level experts on hand at any time.\n\"People are limited by ideas, but not really the ability to execute, in many new ways,\" he said.\n--CNBC's Jordan Novet contributed to this post"
    },
    {
      "url": "https://www.anthropic.com/customers/harvey",
      "text": "Harvey transforms legal work with Claude\nHarvey helps law firms and Fortune 500 enterprises revolutionize their approach to contract analysis, due diligence, and litigation by integrating Claude's advanced reasoning into their domain-specific AI platform.\nKey results with Claude:\n- Deployed Claude across the platform in under one month\n- Achieved one of the highest performance scores on Harvey's proprietary BigLaw Bench evaluation\n- Delivered statistically significant improvements on complex workflows requiring long-context reasoning\n- Deployed Claude at enterprise scale and with enterprise-grade security and privacy.\nLegal AI demands exceptional accuracy and deep reasoning\nBuilding AI for legal professionals requires processing thousands of documents with deep reasoning while maintaining the precision that legal work demands. With customers ranging from global law firms to Fortune 500 enterprises, Harvey needs AI models that excel at contract analysis, due diligence, compliance, and litigation support.\n\"Our secret sauce is this environment where we have domain experts embedded into teams and processes,\" said Niko Grupen, Head of Applied AI at Harvey. \"We have legal researchers who are former Big Law attorneys sitting alongside AI researchers and engineers. They whiteboard together from concept, mapping legal problems to model problems.\"\nThis deep domain expertise drives Harvey's rigorous approach to model selection. \"Evaluation of models for domain-specific tasks is one of our core strengths at Harvey,\" said Grupen. The company tests every model through BigLaw Bench, their proprietary benchmark that measures AI's ability to complete real-world legal tasks. These outputs are graded for both substance\u2014including accuracy, materiality, and hallucination rates\u2014and form, such as tone, length, and formatting.\nHarvey chose Claude for superior long-context performance\nWhen Harvey evaluated models for their platform expansion, Claude delivered exceptional performance. \"We found that Claude is one of the highest performing models on our evaluations,\" said Grupen.\nWhat distinguished Claude was its ability to handle long-context reasoning\u2014critical for legal work involving extensive documents. \"We've seen it perform really well on complex workflows that require long-context reasoning,\" Grupen explained. \"The ability to effectively reason over a maximally-utilized context window remains a significant challenge, and Claude performs really well at upper token thresholds.\"\nHarvey's three-pillar evaluation process tested models through BigLaw Bench, real-world product environments, and unstructured assessments by both AI and legal researchers. Claude delivered statistically significant improvements on complex workflows where long-context reasoning proves essential. This performance, combined with Harvey's commitment to offering their customers choice, made Claude an ideal addition to their platform.\nClaude available across Harvey\u2019s platform\nHarvey customers can select Claude models across key product surfaces \u2014 including Assistant, Vault, and Workflows \u2014 to help review and draft documents faster, more efficiently, and in the voice and tone of their organization or end customers. The Workflows product, in particular, is well-suited for Claude's instruction-following capabilities and ripe for customization.\n\"We're taking complex legal tasks and turning them into end-to-end, interactive journeys. Instead of wrestling with natural-language prompts, you can engage with a Harvey agent that guides the process \u2014 proactively asking for input, asking the right follow-up questions, handling the heavy lifting behind the scenes, and surfacing intermediate work product for review.\u201d\nThis human-in-the-loop approach is pivotal: \"At every checkpoint you can step in\u2014add, edit, delete, or reshape content\u2014before giving it your stamp of approval.\" Grupen explains, \"The Harvey system then comes up with the final work product from there.\"\nRapid deployment meets enterprise security demands\nHarvey integrated Claude into their platform in under a month\u2014remarkable speed for an enterprise deployment. \"Initial feedback from beta testers has been quite strong,\" Grupen noted.\nThe successful deployment required meeting stringent enterprise requirements: security and privacy standards, strict compliance protocols, and rolling out significant capacity across multiple regions (in accordance with local data processing requirements). This swift implementation reflected both Harvey's technical capabilities and Anthropic's support throughout the process. \"Working with the Anthropic team has been a real delight. We've had support from day one\u2014from leadership all the way to the implementation team,\" Grupen shared. \"We're a company that moves at the speed of light, and having a partner that's in the trenches with us goes a long way.\"\nWith the addition of Claude to Harvey\u2019s platform, legal teams can tackle their most complex matters with enhanced capabilities. Whether conducting due diligence on massive data rooms, drafting sophisticated agreements, or navigating intricate regulatory requirements, lawyers across Harvey's global customer base have AI that understands the nuances their work demands.\nBuilding the future of AI-powered legal services\nLooking ahead, Harvey plans to expand Claude's role in areas where deep reasoning matters most. They\u2019re particularly excited about the growing interplay between models and agents, especially as they\u2019re manifested in products like Workflows. \"This ecosystem of models and their instruction-following capabilities become really important as we innovate,\" said Grupen. \"We're optimistic about how we can evolve and grow together.\""
    },
    {
      "url": "https://bit.ly/4mwGngO",
      "text": "Efficiency vs. Expansion: AI\u2019s Sustainability Dilemma\nThe era of unconstrained AI scaling is ending. As frontier models move into production, power caps, inference latency, and rising token-level costs are exposing the limits of traditional scale-first architectures.\nThis salon convenes infrastructure executives, systems architects, and AI platform leads to confront a shared inflection point: how to architect for throughput, cost efficiency, and sustainability at scale.\nWhat You\u2019ll Explore:\nEnergy as a Strategic Limiting Factor\nWith megawatt access dictating deployment timelines, energy has become the gating variable for AI growth. Hear how teams are securing capacity, optimizing for joules per token, and designing next-gen data infrastructure to stay ahead.\nArchitectures for Efficient Inference\nDive into techniques redefining performance per watt\u2014from Mixture of Experts and speculative decoding to low-bit quantization and sparsity-aware compilers. Learn how the most efficient stacks are pushing past today\u2019s throughput ceilings.\nThe True Cost of Intelligence\nScaling isn\u2019t just about model parameters. We\u2019ll unpack the full TCO of AI, including GPU fleet orchestration, silicon availability, regulatory overhead, and alignment with business KPIs.\nWhy Attend\nGet frameworks to navigate the Inference Wall\nLearn how to turn efficiency into a competitive advantage\nBenchmark against the most efficient infra and model strategies in play\nConnect with handpicked leaders building the next generation of scalable, sustainable AI systems\nSource know-how from practitioners who've deployed techniques at scale"
    },
    {
      "url": "https://www.cnbc.com/2024/08/10/rise-of-openai-microsofts-13-billion-artificial-intelligence-bet.html",
      "text": "OpenAI, the company behind the ChatGPT chatbot, was founded in 2015 by a number of researchers, academics and entrepreneurs, including Sam Altman, Greg Brockman and Elon Musk.\nAltman and Brockman are still at OpenAI, serving as CEO and president, respectively. Musk departed in 2018. At the time, OpenAI said Musk left to avoid a conflict of interest with his other company, Tesla, which was becoming increasingly focused on AI. In the years since, OpenAI has grown into one of the prominent leaders in AI development.\nOpenAI gained popularity in late 2022 after releasing ChatGPT, a chatbot that can answer user questions in a manner that sounds like a human. The company also has tools that can generate images and videos from text prompts. OpenAI now reportedly generates annual revenue of $3.4 billion, and has notable customers, including PwC, Moderna and Est\u00e9e Lauder. Microsoft has invested about $13 billion into the AI startup.\nBut OpenAI's wild success has also raised concerns from regulators and experts, who question the outsized power that AI companies and Big Tech could have on our society as well as the stress the technology could cause on our power grid. Watch the video to find out more."
    },
    {
      "url": "https://fortune.com/2025/08/04/billionaire-anthropic-ceo-dario-amodei-ai-staffers-poaching-meta-mark-zuckerberg-100k-six-figure-salaries-openai-sam-altman/",
      "text": "- Anthropic billionaire CEO Dario Amodei says many of his employees are turning down Meta\u2019s $100 million poaching offers, adding they \u201cwouldn\u2019t even talk to Mark Zuckerberg.\u201d And the tech titan isn\u2019t willing to fight fire with fire by raising his own star staffers\u2019 salaries to persuade them to stay at the $61.5 billion AI company, saying it\u2019s \u201cunfair\u201d and could hurt company culture. Amodei and other Silicon Valley CEOs, including Sam Altman, have criticized Meta\u2019s strategy as being a killer for company culture.\nTech companies like Meta and Google have waged an all-out talent war in the fight to build the next revolutionary AI\u2014but Anthropic\u2019s stars aren\u2019t being won over by the promise of $100 million pay packages.\n\u201cRelative to other companies, a lot fewer people from Anthropic have been caught by these. And it\u2019s not for lack of trying,\u201d Anthropic CEO Dario Amodei recently revealed on the Big Technology Podcast. \u201cI\u2019ve talked to plenty of people who got these offers at Anthropic and who just turned them down. Who wouldn\u2019t even talk to Mark Zuckerberg.\u201d\nMeta\u2019s been on a tear to dominate AI, and if it can\u2019t grow the talent internally, its CEO Zuckerberg has no qualms about buying it instead. In June, reports revealed that he\u2019s been poaching staff at competitor companies (including OpenAI, Google, and Anthropic) with $100 million signing bonuses, in an effort to beef up his \u201csuperintelligence\u201d AI lab.\nSome have taken up his envy-inducing offer, including at least seven staffers from OpenAI, but Amodei insisted that most of his employees haven\u2019t taken the bait\u2014and he\u2019s not throwing money at staff to keep them.\nWhy Anthropic\u2019s CEO won\u2019t use cash to convince workers to stay\nEmployers may be tempted to fight fire with fire by raising their AI stars\u2019 salaries or recruiting others in return, but Anthropic thinks it would hurt its company culture.\n\u201cWe are not willing to compromise our compensation principles, our principles of fairness, to respond individually to these offers,\u201d Amodei said. \u201cThe way things work at Anthropic is there\u2019s a series of levels. One candidate comes in, they get assigned a level, and we don\u2019t negotiate that level, because we think it\u2019s unfair. We want to have a systematic way.\u201d\nAmodei not only thinks that it\u2019s unfair to raise salaries to have his workers stick around, but that it could actually backfire on his billion-dollar company\u2019s mission. In actuality, staying true to his compensation practices amid the poaching chaos has been a win for Anthropic\u2019s culture.\n\u201cI think actually this was a unifying moment for the company where we didn\u2019t give in. We refused to compromise our principles, because we had the confidence that people are Anthropic because they truly believe in the mission,\u201d Amodei continued.\n\u201cThe only way you can really be hurt by this is if you allow it to destroy the culture of your company by panicking, by treating people unfairly, in an attempt to defend the company.\u201d\nFortune has reached out to Anthropic and Meta for comment.\nAmodei\u2019s criticism of Zuckerberg\u2019s $100 million poaching strategy\nZuckerberg\u2019s aggressive poaching strategy has ruffled some feathers in the AI world. Being scooped up with a $100 million pay package is a dream for most, but the Anthropic CEO has called out the practice for being fundamentally unfair.\n\u201cIf Mark Zuckerberg throws a dart at a dart board and hits your name, that doesn\u2019t mean that you should be paid 10 times more than the guy next to you who\u2019s just as skilled, who\u2019s just as talented,\u201d Amodei said on the podcast.\nPlus, Amodei thinks the hiring strategy is flat-out counterproductive to what Meta wants to get done. The CEO is proud of his staffers for not giving in to the $100 million offer, and that same loyalty isn\u2019t something that can be bought. And other AI talent seem to want in on Amodei\u2019s culture; engineers at OpenAI were eight times more likely to leave the company for Anthropic. The company also has an 80% retention rate for employees hired over the last two years, compared to 78% at Google DeepMind, and 67% at OpenAI. Ironically, Meta is trailing behind at 64%.\nHaving employees who can do revolutionary work is one thing, but having a culture that makes them want to stay is another. By poaching others, Amodei doubts Meta is recruiting the best fits for its mission.\n\u201cI think that what they are doing is trying to buy something that cannot be bought, and that is alignment with the mission. I think there are selection effects here,\u201d he said. \u201cAre they getting the people who are most enthusiastic, who are most mission aligned, who are most excited?\u201d\nOther tech leaders, including OpenAI\u2019s Sam Altman, have echoed Amodei\u2019s criticism. Altman said that while Meta has managed to poach some staffers, \u201cso far none of our best people have decided to take them up on that.\u201d Even though Zuckerberg has snatched some of his AI workers, Altman is doubtful that his competitor will be able to replicate the same success of OpenAI.\n\u201cI think that there\u2019s a lot of people, and Meta will be a new one, that are saying, \u2018We\u2019re just going to try to copy OpenAI,\u2019\u201d Altman said on the Uncapped podcast last month. \u201cThat basically never works. You\u2019re always going to where your competitor was, and you don\u2019t build up a culture of learning what it\u2019s like to innovate.\u201d"
    },
    {
      "url": "https://www.ciodive.com/news/united-airlines-ceo-AI-use-cases/749563/",
      "text": "Dive Brief:\n- United Airlines is \u201cprobably doing more AI than anyone\u201d as investments in the technology continue, CEO Scott Kirby said during an investor conference last week. A lot of the airline\u2019s efforts are still in the experimental phase, he said.\n- The company is using AI to share flight details with customers and to update labor contracts. In the latter use case, Kirby said AI is more accurate and faster than humans. Baggage recovery is another AI pursuit.\n- Not every use case is successful. For predictive maintenance, AI \u201chasn\u2019t worked as well as we thought,\u201d Kirby said. Despite the challenges, the company is still experimenting in this area and has had a few isolated cases that were fruitful.\nDive Insight:\nEnterprises are full of potential AI pursuits, spanning departments and roles. Some use cases are more impactful than others.\nMost businesses struggle to identify which ideas to launch at scale. Around 7 in 10 decision-makers have more potential AI opportunities than they can possibly fund, according to a Snowflake report. Early AI adopters have found it challenging to lean on metrics like cost and business impact when deciding what project to prioritize.\nCIOs who can help organizations avoid dead-end AI use cases are an asset, according to analysts. The alternative could bring consequences. Decision-makers worry about job security and their company's market position if they advocate for the wrong use case, Snowflake found.\nTechnology leaders can't make decisions about AI adoption in a silo. Sorin Hilgen, chief digital officer and in-country CIO at convenience retailer EG America, told CIO Dive that deciding which use cases to tackle is a collaborative effort among business leaders, who take into account timelines and resource availability.\nGoldman Sachs takes a similar approach.\n\u201cWe started with an enormous number of [AI] use cases, and we whittled it down to the use cases that we want to spend money on,\u201d COO and President John Waldron said during an investor conference last week.\nEnterprises can\u2019t chase every lead. The share of companies abandoning most of their AI initiatives bumped up to 42% this year, compared to 17% last year, according to analysis from S&P Global Market Intelligence.\nAnalysts have urged CIOs not to interpret every failed AI experiment as a negative signal, however. Promoting a culture of experimentation and encouraging trial-and-error can lead to better results and more engagement, experts say."
    },
    {
      "url": "https://www.anthropic.com/customers/thomson-reuters",
      "text": "Thomson Reuters enhances tax guidance with Claude in Amazon Bedrock\nThomson Reuters uses Claude in Amazon Bedrock as part of its strategy to power their AI platform, CoCounsel, helping legal and tax professionals synthesize expert knowledge and deliver comprehensive advice to clients.\nWith Claude, Thomson Reuters:\n- Powers AI features that deliver expertise from 3,000+ subject matter experts to users across all domains\n- Built a comprehensive Retrieval-Augmented Generation (RAG) architecture for tax and legal analysis\n- Processes complex contracts and tax documents by deploying a secure, extensive, and reliable AWS Global Cloud Infrastructure\n- Maintains rigorous accuracy through expert validation\n- Implements prompt caching for efficient processing\nBuilding AI solutions that exceed professional standards\nThomson Reuters needed an AI solution to leverage their vast professional knowledge base while meeting strict accuracy and reliability requirements. They needed technology to maintain their high standards while making expert knowledge more accessible\u2014empowering users to better discover subject matter expertise from 3,000 domain experts and over 150 years of authoritative content.\n\"We combine real expert human knowledge with advanced technology,\" said Joel Hron, CTO at Thomson Reuters. \"We have experts across many different domains generating content and workflows. For us, AI is a tool to facilitate the distribution of that expertise through our software.\"\nChoosing Claude in Amazon Bedrock for enterprise AI\nAfter extensive evaluation against automated and human expert benchmarks, Thomson Reuters selected Claude. Their choice to deploy Claude in Amazon Bedrock emerged from three key factors:\nTo start, Anthropic's focus on safety aligned with their values. Hron said, \"What drew me to Anthropic early on was their stance on safety and ethics\u2014that really aligned with our core ideologies.\"\nIn addition, Claude consistently met their rigorous standards. Hron explained, \"The risk of providing wrong advice is substantial, so our quality thresholds are extraordinarily high. The partnership with Anthropic has been exceptional\u2014their guidance and support have helped our engineering teams maximize the models.\"\nFinally, deploying Claude in Amazon Bedrock provided significant enterprise advantages. Amazon Bedrock enables Thomson Reuters to rapidly test and deploy new Claude models while maintaining strict security standards. Hron noted, \"The continuity of services for our engineering teams is helpful\u2014they can leverage data easily and use existing AWS playbooks. From a security and governance standpoint, it allows us to be more transparent with customers about how we're controlling AI.\"\nThe integration with Amazon Bedrock also streamlined development. Hron shares, \"We're a very close partner of AWS as well, so leveraging that partnership has been a helpful synergy for us.\" Their engineering teams can now test new models and features quickly, with Bedrock providing the robust security infrastructure needed for sensitive professional data. \"Amazon Bedrock lets us test new models the day they're released. It's essential to our development process.\"\nAmazon Bedrock's enterprise-grade infrastructure enabled Thomson Reuters to build a consistent technology stack, supporting rapid AI innovation while maintaining the strict governance their professional customers require.\nHow Claude transforms professional analysis\nAfter selecting Claude in Amazon Bedrock, Thomson Reuters developed a comprehensive AI architecture to serve their diverse professional users. They strategically deployed different Claude models across their product suite, using Claude 3 Haiku for rapid processing and Claude 3.5 Sonnet for more complex analysis. \"We've been able to leverage a number of Claude's features, such as prompt caching, for features we've been deploying,\" explained Hron.\nMaking expert knowledge more accessible\nBy integrating Claude in Amazon Bedrock, Thomson Reuters helps professionals deliver higher quality work more efficiently. Hron explained, \"There's tremendous value in giving professionals multiple sides and perspectives of complex problems. We're not just providing faster information access\u2014we're delivering a more complete and comprehensive view of all sides of an issue.\"\nFor tax professionals, this means understanding multiple perspectives on complex issues. For lawyers, it means having deeper insights for contract negotiations and legal strategy. This comprehensive analysis helps professionals make better decisions for their clients.\"\nThe impact of these AI solutions is already evident across Thomson Reuters' customer base. Greg Siskind, Founder of Siskind Susser PC, describes CoCounsel as \"Outstanding... It's like having an associate lawyer ready to take on an endless number of delegated tasks and deliver it all in minutes.\"\nFor many firms, the efficiency gains are transformative. \"From a time-saving perspective, I can easily see it cutting the time in half, maybe even more,\" notes Pete Mayolo, Owner and President of Mayolo and Associates. Colin Calvert, Partner at Fisher Phillips, adds that \"CoCounsel will become a foundational tool for our firm. Its efficiency is staggering and frees up more of my time to focus on higher-level, more strategic work.\"\nAdvancing the future of professional services\nThomson Reuters continues expanding their use of Claude, exploring agent frameworks for complex tax workflows and computer vision capabilities to help their editorial teams curate content more efficiently. The recent acquisition of Materia AI will help drive these innovations by bringing agentic AI to CoCounsel for the Tax, Audit, and Accounting customers.\n\"We've been vocal about our AI investment as a strategic part of our products going forward,\" said Hron. \"Our editorial workforce spends significant time building and curating content\u2014we see tremendous potential to accelerate these processes with Anthropic\u2019s computer vision and tool use capabilities.\"\nThomson Reuters aims to fundamentally transform how legal and tax professionals work by combining Claude's capabilities with their deep domain expertise. Their vision focuses on automating routine tasks while enhancing professionals' ability to deliver strategic insights. Through their ongoing partnership with Anthropic and AWS, they continue pushing the boundaries of what's possible in professional services."
    },
    {
      "url": "https://simonwillison.net/2025/Aug/7/gpt-5/",
      "text": "GPT-5: Key characteristics, pricing and model card\n7th August 2025\nI\u2019ve had preview access to the new GPT-5 model family for the past two weeks (see related video and my disclosures) and have been using GPT-5 as my daily-driver. It\u2019s my new favorite model. It\u2019s still an LLM\u2014it\u2019s not a dramatic departure from what we\u2019ve had before\u2014but it rarely screws up and generally feels competent or occasionally impressive at the kinds of things I like to use models for.\nI\u2019ve collected a lot of notes over the past two weeks, so I\u2019ve decided to break them up into a series of posts. This first one will cover key characteristics of the models, how they are priced and what we can learn from the GPT-5 system card.\n- Key model characteristics\n- Position in the OpenAI model family\n- Pricing is aggressively competitive\n- More notes from the system card\n- Prompt injection in the system card\n- Thinking traces in the API\n- And some SVGs of pelicans\nKey model characteristics\nLet\u2019s start with the fundamentals. GPT-5 in ChatGPT is a weird hybrid that switches between different models. Here\u2019s what the system card says about that (my highlights in bold):\nGPT-5 is a unified system with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and a real-time router that quickly decides which model to use based on conversation type, complexity, tool needs, and explicit intent (for example, if you say \u201cthink hard about this\u201d in the prompt). [...] Once usage limits are reached, a mini version of each model handles remaining queries. In the near future, we plan to integrate these capabilities into a single model.\nGPT-5 in the API is simpler: it\u2019s available as three models\u2014regular, mini and nano\u2014which can each be run at one of four reasoning levels: minimal (a new level not previously available for other OpenAI reasoning models), low, medium or high.\nThe models have an input limit of 272,000 tokens and an output limit (which includes invisible reasoning tokens) of 128,000 tokens. They support text and image for input, text only for output.\nI\u2019ve mainly explored full GPT-5. My verdict: it\u2019s just good at stuff. It doesn\u2019t feel like a dramatic leap ahead from other LLMs but it exudes competence\u2014it rarely messes up, and frequently impresses me. I\u2019ve found it to be a very sensible default for everything that I want to do. At no point have I found myself wanting to re-run a prompt against a different model to try and get a better result.\nHere are the OpenAI model pages for GPT-5, GPT-5 mini and GPT-5 nano. Knowledge cut-off is September 30th 2024 for GPT-5 and May 30th 2024 for GPT-5 mini and nano.\nPosition in the OpenAI model family\nThe three new GPT-5 models are clearly intended as a replacement for most of the rest of the OpenAI line-up. This table from the system card is useful, as it shows how they see the new models fitting in:\n| Previous model | GPT-5 model |\n|---|---|\n| GPT-4o | gpt-5-main |\n| GPT-4o-mini | gpt-5-main-mini |\n| OpenAI o3 | gpt-5-thinking |\n| OpenAI o4-mini | gpt-5-thinking-mini |\n| GPT-4.1-nano | gpt-5-thinking-nano |\n| OpenAI o3 Pro | gpt-5-thinking-pro |\nThat \u201cthinking-pro\u201d model is currently only available via ChatGPT where it is labelled as \u201cGPT-5 Pro\u201d and limited to the $200/month tier. It uses \u201cparallel test time compute\u201d.\nThe only capabilities not covered by GPT-5 are audio input/output and image generation. Those remain covered by models like GPT-4o Audio and GPT-4o Realtime and their mini variants and the GPT Image 1 and DALL-E image generation models.\nPricing is aggressively competitive\nThe pricing is aggressively competitive with other providers.\n- GPT-5: $1.25/million for input, $10/million for output\n- GPT-5 Mini: $0.25/m input, $2.00/m output\n- GPT-5 Nano: $0.05/m input, $0.40/m output\nGPT-5 is priced at half the input cost of GPT-4o, and maintains the same price for output. Those invisible reasoning tokens count as output tokens so you can expect most prompts to use more output tokens than their GPT-4o equivalent (unless you set reasoning effort to \u201cminimal\u201d).\nThe discount for token caching is significant too: 90% off on input tokens that have been used within the previous few minutes. This is particularly material if you are implementing a chat UI where the same conversation gets replayed every time the user adds another prompt to the sequence.\nHere\u2019s a comparison table I put together showing the new models alongside the most comparable models from OpenAI\u2019s competition:\n| Model | Input $/m | Output $/m |\n|---|---|---|\n| Claude Opus 4.1 | 15.00 | 75.00 |\n| Claude Sonnet 4 | 3.00 | 15.00 |\n| Grok 4 | 3.00 | 15.00 |\n| Gemini 2.5 Pro (>200,000) | 2.50 | 15.00 |\n| GPT-4o | 2.50 | 10.00 |\n| GPT-4.1 | 2.00 | 8.00 |\n| o3 | 2.00 | 8.00 |\n| Gemini 2.5 Pro (<200,000) | 1.25 | 10.00 |\n| GPT-5 | 1.25 | 10.00 |\n| o4-mini | 1.10 | 4.40 |\n| Claude 3.5 Haiku | 0.80 | 4.00 |\n| GPT-4.1 mini | 0.40 | 1.60 |\n| Gemini 2.5 Flash | 0.30 | 2.50 |\n| Grok 3 Mini | 0.30 | 0.50 |\n| GPT-5 Mini | 0.25 | 2.00 |\n| GPT-4o mini | 0.15 | 0.60 |\n| Gemini 2.5 Flash-Lite | 0.10 | 0.40 |\n| GPT-4.1 Nano | 0.10 | 0.40 |\n| Amazon Nova Lite | 0.06 | 0.24 |\n| GPT-5 Nano | 0.05 | 0.40 |\n| Amazon Nova Micro | 0.035 | 0.14 |\n(Here\u2019s a good example of a GPT-5 failure: I tried to get it to output that table sorted itself but it put Nova Micro as more expensive than GPT-5 Nano, so I prompted it to \u201cconstruct the table in Python and sort it there\u201d and that fixed the issue.)\nMore notes from the system card\nAs usual, the system card is vague on what went into the training data. Here\u2019s what it says:\nLike OpenAI\u2019s other models, the GPT-5 models were trained on diverse datasets, including information that is publicly available on the internet, information that we partner with third parties to access, and information that our users or human trainers and researchers provide or generate. [...] We use advanced data filtering processes to reduce personal information from training data.\nI found this section interesting, as it reveals that writing, code and health are three of the most common use-cases for ChatGPT. This explains why so much effort went into health-related questions, for both GPT-5 and the recently released OpenAI open weight models.\nWe\u2019ve made significant advances in reducing hallucinations, improving instruction following, and minimizing sycophancy, and have leveled up GPT-5\u2019s performance in three of ChatGPT\u2019s most common uses: writing, coding, and health. All of the GPT-5 models additionally feature safe-completions, our latest approach to safety training to prevent disallowed content.\nSafe-completions is later described like this:\nLarge language models such as those powering ChatGPT have traditionally been trained to either be as helpful as possible or outright refuse a user request, depending on whether the prompt is allowed by safety policy. [...] Binary refusal boundaries are especially ill-suited for dual-use cases (such as biology or cybersecurity), where a user request can be completed safely at a high level, but may lead to malicious uplift if sufficiently detailed or actionable. As an alternative, we introduced safe- completions: a safety-training approach that centers on the safety of the assistant\u2019s output rather than a binary classification of the user\u2019s intent. Safe-completions seek to maximize helpfulness subject to the safety policy\u2019s constraints.\nSo instead of straight up refusals, we should expect GPT-5 to still provide an answer but moderate that answer to avoid it including \u201charmful\u201d content.\nOpenAI have a paper about this which I haven\u2019t read yet (I didn\u2019t get early access): From Hard Refusals to Safe-Completions: Toward Output-Centric Safety Training.\nSycophancy gets a mention, unsurprising given their high profile disaster in April. They\u2019ve worked on this in the core model:\nSystem prompts, while easy to modify, have a more limited impact on model outputs relative to changes in post-training. For GPT-5, we post-trained our models to reduce sycophancy. Using conversations representative of production data, we evaluated model responses, then assigned a score reflecting the level of sycophancy, which was used as a reward signal in training.\nThey claim impressive reductions in hallucinations. In my own usage I\u2019ve not spotted a single hallucination yet, but that\u2019s been true for me for Claude 4 and o3 recently as well\u2014hallucination is so much less of a problem with this year\u2019s models.\nUpdate: I have had some reasonable pushback against this point, so I should clarify what I mean here. When I use the term \u201challucination\u201d I am talking about instances where the model confidently states a real-world fact that is untrue\u2014like the incorrect winner of a sporting event. I\u2019m not talking about the models making other kinds of mistakes\u2014they make mistakes all the time!\nSomeone pointed out that it\u2019s likely I\u2019m avoiding hallucinations through the way I use the models, and this is entirely correct: as an experienced LLM user I instinctively stay clear of prompts that are likely to trigger hallucinations, like asking a non-search-enabled model for URLs or paper citations. This means I\u2019m much less likely to encounter hallucinations in my daily usage.\nOne of our focuses when training the GPT-5 models was to reduce the frequency of factual hallucinations. While ChatGPT has browsing enabled by default, many API queries do not use browsing tools. Thus, we focused both on training our models to browse effectively for up-to-date information, and on reducing hallucinations when the models are relying on their own internal knowledge.\nThe section about deception also incorporates the thing where models sometimes pretend they\u2019ve completed a task that defeated them:\nWe placed gpt-5-thinking in a variety of tasks that were partly or entirely infeasible to accomplish, and rewarded the model for honestly admitting it can not complete the task. [...]\nIn tasks where the agent is required to use tools, such as a web browsing tool, in order to answer a user\u2019s query, previous models would hallucinate information when the tool was unreliable. We simulate this scenario by purposefully disabling the tools or by making them return error codes.\nPrompt injection in the system card\nThere\u2019s a section about prompt injection, but it\u2019s pretty weak sauce in my opinion.\nTwo external red-teaming groups conducted a two-week prompt-injection assessment targeting system-level vulnerabilities across ChatGPT\u2019s connectors and mitigations, rather than model-only behavior.\nHere\u2019s their chart showing how well the model scores against the rest of the field. It\u2019s an impressive result in comparison\u201456.8 attack success rate for gpt-5-thinking, where Claude 3.7 scores in the 60s (no Claude 4 results included here) and everything else is 70% plus:\nOn the one hand, a 56.8% attack rate is cleanly a big improvement against all of those other models.\nBut it\u2019s also a strong signal that prompt injection continues to be an unsolved problem! That means that more than half of those k=10 attacks (where the attacker was able to try up to ten times) got through.\nDon\u2019t assume prompt injection isn\u2019t going to be a problem for your application just because the models got better.\nThinking traces in the API\nI had initially thought that my biggest disappointment with GPT-5 was that there\u2019s no way to get at those thinking traces via the API... but that turned out not to be true. The following curl\ncommand demonstrates that the responses API \"reasoning\": {\"summary\": \"auto\"}\nis available for the new GPT-5 models:\ncurl https://api.openai.com/v1/responses \\\n-H \"Authorization: Bearer $(llm keys get openai)\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n\"model\": \"gpt-5\",\n\"input\": \"Give me a one-sentence fun fact about octopuses.\",\n\"reasoning\": {\"summary\": \"auto\"}\n}'\nHere\u2019s the response from that API call.\nWithout that option the API will often provide a lengthy delay while the model burns through thinking tokens until you start getting back visible tokens for the final response.\nOpenAI offer a new reasoning_effort=minimal\noption which turns off most reasoning so that tokens start to stream back to you as quickly as possible.\nAnd some SVGs of pelicans\nNaturally I\u2019ve been running my \u201cGenerate an SVG of a pelican riding a bicycle\u201d benchmark. I\u2019ll actually spend more time on this in a future post\u2014I have some fun variants I\u2019ve been exploring\u2014but for the moment here\u2019s the pelican I got from GPT-5 running at its default \u201cmedium\u201d reasoning effort:\nIt\u2019s pretty great! Definitely recognizable as a pelican, and one of the best bicycles I\u2019ve seen yet.\nHere\u2019s GPT-5 mini:\nAnd GPT-5 nano:\nMore recent articles\n- The surprise deprecation of GPT-4o for ChatGPT consumers - 8th August 2025\n- OpenAI's new open weight (Apache 2) models are really good - 5th August 2025"
    },
    {
      "url": "https://windsurf.com/",
      "text": "company\nOur Commitment to Windsurf\nJul 16, 2025\n3 min read\nMemories\nCascade will remember important things about your codebase and workflow.\nRules\nRefresh\n# Front end\n- Follow Next.js patterns\nMemories\nCodebase Structure\n#codebase_structure #typescript\nLint Fixing\nCascade will automatically detect and fix lint errors that it generates.\n4 new linter errors\nEdited\n0 new linter errors found\nMCP Support\nEnhance your AI workflows by connecting custom tools and services. Access curated MCP servers in Windsurf settings for one click set-up.\nFigma 5 tools\nSlack 7 tools\nStripe 9 tools\nSequential Thinking 3 tools\nPlugin Store\nManage Plugins\nGitHub\nAdd server +\nPostgresSQL\nAdd server +\nPlaywright\nAdd server +\nNeon\nAdd server +\nFigma\nConfigure\nSlack\nConfigure\nDrag & Drop Images\nBuild your designs instantly by dropping an image into Cascade.\nTerminal Command\nDon't remember a terminal command? Just \u2318+I terminal to stay in flow.\nProblems Output\nyashmittal@Mac portfolio %\nContinue My Work\nCascade keeps track of your actions so you can just tell it to continue what you\u2019re doing.\nEdited\nEdited\nTurbo Mode\nTurn on Turbo mode in settings to allow Cascade to auto-execute terminal commands.\nTurbo\nEdited\nRan Terminal Command\nCreated\nRan Preview\nSearched nextjs.org\nDeployed app\nFirst-class support for every major model provider\nNumber of users\nTrusted by over a million innovators, creators, and teams worldwide\nEnterprise customers\nTrusted by startups, agencies, and enterprises worldwide.\nPercent of code written by AI\nOur AI removes the vast amounts of time spent of boilerplate and menial tasks so that you can focus on the fun and creative parts of building.\nGarry Tan, President & CEO\nAvi Schiffmann\n@AviSchiffmann\nWindsurf is so much better than Cursor. It just makes the steps easier, like creating new folders within the flow. I like how I just type my prompt, go away for a bit, come back and theres a web preview waiting.\nAndrew Brown\n@andrewbrown\nI think @windsurf_ai will win the AI Coding Assistant wars. What leads me to believe this is beyond the product itself and how the team executes.\nAlex Finn\n@AlexFinnX\nUnreal. I just built an app with 1 prompt.\nThe Jack Forge\n@TheJackForge\nI've been exclusively using Windsurf for the past 3 weeks. They are not paying me to say this. It's really good. Really really good.\nAlvaro Cintas\n@dr_cintas\nWindsurf is one of the best AI coding tools I\u2019ve ever used.\nLuca\n@Knackfish\nWindsurf is simply better from my experience over the last month.\nJon Myers\n@jonmyers\nWindsurf UX beats Cursor for novices like me. Just click \"preview\" - it sets up a server and keeps it *active*. Same goes for MCPs and extensions. Click a button in Windsurf, done.\nThe Bodega Man\n@TheBodegaMan1\nThe reason I chose Windsurf is because you guys are on a constant mission of streamlining, improving and generally making the experience better for your users. The recent pricing rework with the clear and fair token usage plans are what convinced me to convert. It makes me feel like you care about users and builders.\nelvis\n@omarsar0\nWindsurf makes coding insanely fun and fast!\nCatalin\n@catalinmpit\nOne of the many cool features of the Windsurf IDE is the \"Problems\" tab that lists all the issues in your project.\nTom Blomfield\n@t_blom\nI've been building a new thing with Windsurf and I spent the last hour in almost hysterical laughter because the responses are just so good.\nTom D\u00f6rr\n@tom_doerr\nIt feels incredible to open a project with Windsurf for the first time, and it runs pytest, pylint, and radon in parallel, identifying all immediate issues within one second.\nAlexander Wilczek\n@SecWillCheck\nI am currently trialing Windsurf and I really have to say the UI feels way more intuitive than Cursor."
    },
    {
      "url": "https://cursor.com/",
      "text": "The AI\nCode Editor\nBuilt to make you extraordinarily productive, Cursor is the best way to code with AI.\nTrusted by engineers at\nTab, tab, tab\nCursor lets you breeze through changes by predicting your next edit.\nKnows your codebase\nGet answers from your codebase or refer to files or docs. Use the model's code in one click.\nEdit in natural language\nCursor lets you write code using instructions. Update entire classes or functions with a simple prompt.\nBuild software faster\nIntelligent, fast, and familiar, Cursor is the best way to code with AI.\nFrontier Intelligence\nPowered by a mix of purpose-built and frontier models, Cursor is smart and fast.\nFeels Familiar\nImport all your extensions, themes, and keybindings in one click.\nPrivacy Options\nIf you enable Privacy Mode, your code is never stored remotely without your consent. Cursor is SOC 2 certified.\nFrontier Intelligence\nPowered by a mix of purpose-built and frontier models, Cursor is smart and fast.\nFeels Familiar\nImport all your extensions, themes, and keybindings in one click.\nPrivacy Options\nIf you enable Privacy Mode, your code is never stored remotely without your consent. Cursor is SOC 2 certified.\nLoved by world-class devs\nEngineers all around the world reach for Cursor by choice.\nCursor is at least a 2x improvement over Copilot. It's amazing having an AI pair programmer, and is an incredible accelerator for me and my team.\nBen Bernard\nInstacart\nThe Cursor tab completion while coding is occasionally so magic it defies reality - about ~25% of the time it is anticipating exactly what I want to do. It is enough to make you believe that eventually you'll be able to code at the speed of thought.\nKevin Whinnery\nOpenAI\nCursor is hands down my biggest workflow improvement in years\nSawyer Hood\nFigma\nI love writing code and Cursor is a necessity. Cursor is steps ahead of my brain, proposing multi-line edits so I type 'tab' more than anything else.\nAndrew Milich\nNotion\nCursor is so good, and literally gets better/more feature-rich every couple of weeks.\nMorgan McGuire\nWeights & Biases\nCursor is awesome! Someone finally put GPT into a code editor in a seamless way. It's so elegant and easy. No more copying and pasting. I'm an hour in and already hooked.\nAndrew McCalip\nVarda\nCursor is the best AI developer tool right now, avoid it at your own peril\nLogan Kilpatrick\nStarted using Cursor yesterday & i'm blown away. it's how Copilot should feel. i'm completely off VSCode now.\nSam Whitmore\nNew Computer\nCursor is the best product I've used in a while - it's an AI enabled editor. I just asked it to write a README for a project I've been working on - analyzed the code-base and worked first time.\nAlex MacCaw\nReflect\nCursor is the best product I've used in a while - it's an AI enabled editor. I just asked it to write a README for a project I've been working on - analyzed the code-base and worked first time.\nZeke Sikelianos\nReplicate\nGonna apply to YC and list Cursor as my cofounder\nCory Etzkorn\nNotion\nCursor's new auto-complete is insane You no longer need to prompt it. It predicts what code you want based on what you're doing. Accept by hitting tab In this video I change the CSS class of one link. I then simply keep hitting tab to make the same change to all other links\nMarc K\u00f6hlbrugge\nWIP\nI really like how Cursor suggests edits to existing code. It noticed I was inconsistent with my markup and popped up this suggestion that matched my other items!\nWes Bos\nInternet\nCursor is \ud83d\udc10-ed for real\nSteven Tey\nDub\nI really like how Cursor suggests edits to existing code. It noticed I was inconsistent with my markup and popped up this suggestion that matched my other items!\nWes Bos\nInternet\nThe most useful AI tool that I currently pay for is, hands down, is Cursor It's fast, autocompletes when and where you need it to, handles brackets properly, sensible keyboard shortcuts, bring- your-own-model...everything is well put together.\nshadcn\nVercel\nI went from never hearing about Cursor to many IC engineers telling me it's their new favorite tool. Seemingly overnight! Pretty wild product-market fit.\nJosh Miller\nThe Browser Company\nI installed Cursor ... oh\nKent C. Dodds\nInternet\nAfter many recommendations, I finally switched from VSC to Cursor and ... wow! It's absolutely incredible. If you like Copilot (or if you don't), you'll be blown away by Cursor. There is no going back. \ud83e\udd2f\nJohannes Schickling\nPrisma\nCursor is at least a 2x improvement over Copilot. It's amazing having an AI pair programmer, and is an incredible accelerator for me and my team.\nBen Bernard\nInstacart\nThe Cursor tab completion while coding is occasionally so magic it defies reality - about ~25% of the time it is anticipating exactly what I want to do. It is enough to make you believe that eventually you'll be able to code at the speed of thought.\nKevin Whinnery\nOpenAI\nCursor is hands down my biggest workflow improvement in years\nSawyer Hood\nFigma\nI love writing code and Cursor is a necessity. Cursor is steps ahead of my brain, proposing multi-line edits so I type 'tab' more than anything else.\nAndrew Milich\nNotion\nCursor is so good, and literally gets better/more feature-rich every couple of weeks.\nMorgan McGuire\nWeights & Biases\nCursor is awesome! Someone finally put GPT into a code editor in a seamless way. It's so elegant and easy. No more copying and pasting. I'm an hour in and already hooked.\nAndrew McCalip\nVarda\nCursor is the best AI developer tool right now, avoid it at your own peril\nLogan Kilpatrick\nstarted using Cursor yesterday & i'm blown away. it's how Copilot should feel. i'm completely off VSCode now.\nSam Whitmore\nNew Computer\nCursor is the best product I've used in a while - it's an AI enabled editor. I just asked it to write a README for a project I've been working on - analyzed the code-base and worked first time.\nAlex MacCaw\nReflect\nCursor has changed the game. I really can't imagine writing code without it at this point. The switch from VSCode is easy, and now I have AI superpowers right in my editor and my terminal.\nZeke Sikelianos\nReplicate\nGonna apply to YC and list Cursor as my cofounder\nCory Etzkorn\nNotion\nCursor's new auto-complete is insane You no longer need to prompt it. It predicts what code you want based on what you're doing. Accept by hitting tab In this video I change the CSS class of one link. I then simply keep hitting tab to make the same change to all other links\nMarc K\u00f6hlbrugge\nWIP\nI really like how Cursor suggests edits to existing code. It noticed I was inconsistent with my markup and popped up this suggestion that matched my other items!\nWes Bos\nInternet\nCursor is \ud83d\udc10-ed for real\nSteven Tey\nDub\nI really like how Cursor suggests edits to existing code. It noticed I was inconsistent with my markup and popped up this suggestion that matched my other items!\nWes Bos\nInternet\nThe most useful AI tool that I currently pay for is, hands down, is Cursor It's fast, autocompletes when and where you need it to, handles brackets properly, sensible keyboard shortcuts, bring- your-own-model...everything is well put together.\nshadcn\nVercel\nI went from never hearing about Cursor to many IC engineers telling me it's their new favorite tool. Seemingly overnight! Pretty wild product-market fit.\nJosh Miller\nThe Browser Company\nI installed Cursor ... oh\nKent C. Dodds\nInternet\nAfter many recommendations, I finally switched from VSC to Cursor and ... wow! It's absolutely incredible. If you like Copilot (or if you don't), you'll be blown away by Cursor. There is no going back. \ud83e\udd2f\nJohannes Schickling\nPrisma"
    },
    {
      "url": "https://www.anthropic.com/news/claude-opus-4-1",
      "text": "Claude Opus 4.1\nToday we're releasing Claude Opus 4.1, an upgrade to Claude Opus 4 on agentic tasks, real-world coding, and reasoning. We plan to release substantially larger improvements to our models in the coming weeks.\nOpus 4.1 is now available to paid Claude users and in Claude Code. It's also on our API, Amazon Bedrock, and Google Cloud's Vertex AI. Pricing is the same as Opus 4.\nClaude Opus 4.1\nOpus 4.1 advances our state-of-the-art coding performance to 74.5% on SWE-bench Verified. It also improves Claude\u2019s in-depth research and data analysis skills, especially around detail tracking and agentic search.\nGitHub notes that Claude Opus 4.1 improves across most capabilities relative to Opus 4, with particularly notable performance gains in multi-file code refactoring. Rakuten Group finds that Opus 4.1 excels at pinpointing exact corrections within large codebases without making unnecessary adjustments or introducing bugs, with their team preferring this precision for everyday debugging tasks. Windsurf reports Opus 4.1 delivers a one standard deviation improvement over Opus 4 on their junior developer benchmark, showing roughly the same performance leap as the jump from Sonnet 3.7 to Sonnet 4.\nGetting started\nWe recommend upgrading from Opus 4 to Opus 4.1 for all uses. If you\u2019re a developer, simply use claude-opus-4-1-20250805\nvia the API. You can also explore our system card, model page, pricing page, and docs to learn more.\nAs always, your feedback helps us improve, especially as we continue to release new and more capable models.\nAppendix\nData sources\n- OpenAI: o3 launch post, o3 system card\n- Gemini: 2.5 Pro model card\n- Claude: Sonnet 3.7 launch post, Claude 4 launch post\nBenchmark reporting\nClaude models are hybrid reasoning models. The benchmarks reported in this blog post show the highest scores achieved with or without extended thinking. We\u2019ve noted below for each result whether extended thinking was used:\n- No extended thinking: SWE-bench Verified, Terminal-Bench\n- The following benchmarks were reported with extended thinking (up to 64K tokens): TAU-bench, GPQA Diamond, MMMLU, MMMU, AIME\nTAU-bench methodology\nScores were achieved with a prompt addendum to both the Airline and Retail Agent Policy instructing Claude to better leverage its reasoning abilities while using extended thinking with tool use. The model is encouraged to write down its thoughts as it solves the problem distinct from our usual thinking mode, during the multi-turn trajectories to best leverage its reasoning abilities. To accommodate the additional steps Claude incurs by utilizing more thinking, the maximum number of steps (counted by model completions) was increased from 30 to 100 (most trajectories completed under 30 steps with only one trajectory reaching above 50 steps).\nSWE-bench methodology\nFor the Claude 4 family of models, we continue to use the same simple scaffold that equips the model with solely the two tools described in our prior releases here\u2014a bash tool, and a file editing tool that operates via string replacements. We no longer include the third \u2018planning tool\u2019 used by Claude 3.7 Sonnet. On all Claude 4 models, we report scores out of the full 500 problems. Scores for OpenAI models are reported out of a 477 problem subset."
    },
    {
      "url": "https://www.cnbc.com/2025/07/29/anthropic-in-talks-to-raise-fresh-capital-at-170-billion-valuation.html",
      "text": "Anthropic is in talks to raise between $3 billion and $5 billion in a funding round led by Iconiq Capital that would value the artificial intelligence startup at $170 billion, CNBC has confirmed.\nThe OpenAI competitor has been reeling in billions of dollars at a rapidly increasing valuation reflecting investors' thirst for a piece in the fastest growing AI companies. In March, Anthropic closed a $3.5 billion round at a $61.5 billion, led by Lightspeed Venture Partners.\nBloomberg was first to report on the latest talks, which CNBC confirmed with a person familiar with the matter who asked not to be named due to confidentiality. Late last week, the Financial Times pegged Anthropic's upcoming valuation at closer to $150 billion, following talks with a number of investors from the Middle East.\nA leaked memo shared with Wired indicates that Anthropic CEO Dario Amodei is reversing course on Middle East funding. He wrote that it's become \"substantially harder to stay on the frontier\" of AI development without tapping Gulf sovereign wealth, despite previously warning about the national security risks of granting \"soft power\" to authoritarian regimes.\nCNBC reported last year that Anthropic was refusing to take funds from Saudi Arabia as it lined up new investors.\nRivals are also turning to the Middle East. OpenAI still has $30 billion left to raise as part of its planned $40 billion round, and is working with Emirati firm G42 to build a massive data center in Abu Dhabi. OpenAI's latest funding valued the company at about $300 billion.\nWATCH: Middle East is becoming a leader in tech investment: Constellation Research"
    }
  ],
  "argos_summary": "Anthropic's rapid growth to a $5 billion revenue run rate is heavily reliant on just two major customers, which pose a significant risk if those relationships falter. The recent launch of OpenAI's GPT-5, with its competitive pricing and improved performance, threatens Anthropic's market position, particularly in AI coding applications where it currently holds a 42% market share. Despite these challenges, Anthropic has seen substantial growth in its business beyond its largest customers, and it continues to innovate with products like Claude, which is being integrated into various sectors including legal and tax services.",
  "argos_id": "XJAGZUMI8"
}