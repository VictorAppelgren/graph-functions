{
  "url": "https://www.zdnet.com/article/dont-fall-for-ai-powered-disinformation-attacks-online-heres-how-to-stay-sharp/",
  "authorsByline": "Dan Patterson",
  "articleId": "28e2483af13b48efbf686440442a2aee",
  "source": {
    "domain": "zdnet.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://www.zdnet.com/a/img/resize/87856ccf53e639db37918223b26407fc10346ba0/2025/08/12/82ec2bbb-c5a1-4032-beee-db71d558d4a1/gettyimages-2217159460.jpg?auto=webp&fit=crop&height=675&width=1200",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T02:29:38+00:00",
  "addDate": "2025-08-12T02:36:33.975885+00:00",
  "refreshDate": "2025-08-12T02:36:33.975886+00:00",
  "score": 1.0,
  "title": "Don't fall for AI-powered disinformation attacks online - here's how to stay sharp",
  "description": "AI is already challenging our reality. Here are expert tools and tips that anyone can use to spot manipulation, verify information, and protect their organization from narrative attacks.",
  "content": "\u2022 AI-powered narrative attacks, or misinformation campaigns, are on the rise.\n\u2022 These can create real business, brand, personal, and financial harm.\n\u2022 Here are expert tips on how to spot and protect yourself against them.\n\nLast month, an old friend forwarded me a video that made my stomach drop. In it, what appeared to be violent protesters streaming down the streets of a major city, holding signs accusing the government and business officials of \"censoring our voice online!\"\n\nThe footage looked authentic. The audio was clear. The protest signs appeared realistically amateurish.\n\nBut it was completely fabricated.\n\nThat didn't make the video any less effective, though. If anything, its believability made it more dangerous. That single video had the power to shape opinions, inflame tensions, and spread across platforms before the truth caught up. This is the hallmark of a narrative attack: not just a falsehood, but a story carefully crafted to manipulate perception on a large scale.\n\nWhy 'narrative attacks' matter more than ever\n\nNarrative attacks, as research firm Forrester defines them, are the new frontier of cybersecurity: AI-powered manipulations or distortions of information that exploit biases and emotions, like disinformation campaigns on steroids.\n\nI use the term \"narrative attacks\" deliberately. Terms like \"disinformation\" feel abstract and academic, while \"narrative attack\" is specific and actionable. Like cyberattacks, narrative attacks demonstrate how bad actors exploit technology to inflict operational, reputational, and financial harm.\n\nAlso: Navigating AI-powered cyber threats in 2025: 4 expert security tips for businesses\n\nThink of it this way: A cyber attack exploits vulnerabilities in your technical infrastructure. A narrative attack exploits vulnerabilities in your information environment, often causing financial, operational, or reputational harm. This article provides you with practical tools to identify narrative attacks, verify suspicious information, and safeguard yourself and your organization. We'll cover detection techniques, verification tools, and defensive strategies that work in the real world.\n\nSeveral factors have created the ideal conditions for narrative attacks to flourish. These dynamics help explain why we're seeing such a surge right now:\n\u2022 None AI tools have democratized content creation. Anyone can generate convincing fake images, videos, and audio clips using freely available software. The technical barriers that once limited sophisticated narrative campaigns have largely disappeared.\n\u2022 None Social media platforms fragment audiences into smaller, more isolated communities. Information that might have been quickly debunked in a more diverse media environment can circulate unopposed within closed groups. Echo chambers amplify false narratives while insulating curated groups.\n\u2022 None Content moderation systems struggle to keep pace with the volume and sophistication of synthetic media. Platforms rely heavily on automated detection, which consistently lags behind the latest manipulation techniques. Human reviewers cannot examine every piece of content at scale.\n\nMeanwhile, bad actors are testing new playbooks, combining traditional propaganda techniques with cutting-edge technology and cyber tactics to create faster, more targeted, and more effective manipulation campaigns.\n\nAlso: 7 ways to lock down your phone's security - before it's too late\n\n\"The incentive structures built into social media platforms benefit content that provokes controversy, outrage, and other strong emotions,\" said Jared Holt, an experienced extremism researcher who recently worked as an analyst for the Institute for Strategic Dialogue. Tech companies, he argued, rewarded engagement with inorganic algorithmic amplification to keep users on their services for longer periods, generating more profits.\n\n\"Unfortunately, this also created a ripe environment for bad actors who inflame civil issues and promote social disorder in ways that are detrimental to societal health,\" he added.\n\nToday's narrative attacks blend familiar propaganda methods with emerging technologies. \"Censorship\" bait is a particularly insidious tactic. Bad actors deliberately post content designed to trigger moderation actions, then use those actions as \"proof\" of systematic suppression. This approach radicalizes neutral users who might otherwise dismiss extremist content.\n\nAlso: GPT-5 bombed my coding tests, but redeemed itself with code analysis\n\nCoordinated bot networks have become increasingly sophisticated in mimicking human behavior. Modern bot armies use varied posting schedules, attempt to influence influencers, post diverse content types, and use realistic engagement patterns. They're much more complicated to detect than the automated accounts we saw in previous years.\n\nDeepfake videos and AI-generated images have become remarkably sophisticated. We're seeing fake footage of politicians making inflammatory statements, synthetic images of protests that never happened, and artificial celebrity endorsements. The tools used to create this media are becoming increasingly accessible as the LLMs behind them evolve and become more capable.\n\nSynthetic eyewitness posts combine fake personal accounts with geolocation spoofing. Attackers create seemingly authentic social media profiles, complete with personal histories and local details, and use them to spread false firsthand reports of events. These posts often include manipulated location data to make them appear more credible.\n\nAgenda-driven amplification often involves fringe influencers and extremist groups deliberately promoting misleading content to mainstream audiences. They frequently present themselves as independent voices or citizen journalists while coordinating their messaging and timing to maximize their impact.\n\nAlso: Beware of promptware: How researchers broke into Google Home via Gemini\n\nThe list of conspiracy fodder is endless, and recycled conspiracies often get updated with contemporary targets and references. For example, the centuries-old antisemitic trope of secret cabals controlling world events has been repackaged in recent years to target figures like George Soros, the World Economic Forum, or even tech CEOs under the guise of \"globalist elites.\" Another example is modern influencers transforming climate change denial narratives into \"smart city\" panic campaigns. Vaccine-related conspiracies adapt to target whatever technology or policy is currently controversial. The underlying frameworks remain consistent, but the surface details are updated to reflect current events.\n\nDuring recent Los Angeles protests, conspiracy videos circulated claiming that foreign governments orchestrated the demonstrations. An investigation revealed that many of these videos originated from known narrative manipulation networks with ties to overseas influence operations. Ahead of last year's Paris Olympics, we saw narratives emerge about \"bio-engineered athletes,\" potential \"false flag\" terrorist attacks, and other manipulations. These stories lack credible sources but spread rapidly through sports and conspiracy communities.\n\nFake local news sites have resurfaced across swing states, publishing content designed to look like legitimate journalism while promoting partisan talking points. These sites often use domain names similar to real, local newspapers to increase their credibility.\n\nA recent viral video appeared to show a major celebrity endorsing a political candidate. Even after verification teams proved the footage had been manipulated, polls showed that many people continued to believe the endorsement was genuine. The false narrative persisted despite apparent debunking.\n\nThe most important thing you can do is slow down. Our information consumption habits make us vulnerable to manipulation. When you encounter emotionally charged content, especially if it confirms your existing beliefs or triggers strong reactions, pause before sharing.\n\nAlso: Syncable vs. non-syncable passkeys: Are roaming authenticators the best of both worlds?\n\n\"Always consider the source,\" says Andy Carvin, an intelligence analyst who recently worked for the Atlantic Council's Digital Forensic Research Lab. \"While it's impossible to know the details behind every potential source you come across, you can often learn a lot from what they say and how they say it.\"\n\nDo they speak in absolute certainties? Do they proclaim they know the \"truth\" or \"facts\" about something and present that information in black and white terms? Do they ever acknowledge that they don't have all the answers? Do they attempt to convey nuance? Do they focus on assigning blame to everything they discuss? What's potentially motivating them to make these claims? Do they cite their sources?\n\nMedia literacy has become one of the most critical skills for navigating our information-saturated world, yet it remains woefully underdeveloped across most demographics. Carvin suggests giving strong consideration to your media consumption habits. When scrolling or watching, ask yourself three critical questions: Who benefits from this narrative? Who is amplifying it? What patterns of repetition do you notice across different sources?\n\n\"It may not be possible to answer all of these questions, but if you put yourself in the right mindset and maintain a healthy skepticism, it will help you develop a more discerning media diet,\" he said.\n\nAlso: I found 5 AI content detectors that can correctly identify AI text 100% of the time\n\nBefore sharing content, try these tips:\n\u2022 Spend 30 seconds checking the source's credibility and looking for corroborating reports from different outlets.\n\u2022 Use reverse image searches to verify photos, and be aware of when content triggers strong emotional reactions, as manipulation often targets feelings over facts.\n\u2022 Follow journalists and experts who regularly cite sources, correct their own mistakes, and acknowledge uncertainty.\n\u2022 Diversify your information sources beyond social media platforms, and practice reading past headlines to understand the full context.\n\u2022 When evaluating claims, again ask who benefits from the narrative and whether the source provides a transparent methodology for their conclusions.\n\u2022 Watch for specific red flag behaviors. Content designed to trigger immediate emotional responses often contains manipulation. Information that spreads unusually fast without transparent sourcing should raise suspicions. Claims that cannot be verified through credible sources require extra scrutiny.\n\u2022 Pay attention to the role of images, symbols, and repetition in the content you're evaluating. Manipulative narratives often rely heavily on visual elements and repeated catchphrases to bypass critical thinking.\n\u2022 Be especially wary of \"emotional laundering\" tactics that frame outrage as civic duty or moral responsibility. Attackers often present their false narratives as urgent calls to action, making audiences feel that sharing unverified information is somehow patriotic or ethical.\n\nTools that actually help\n\nHere are a few additional apps and websites that can guide you to authentic content. These verification tools should be used to supplement -- not replace -- human judgment and traditional verification methods. But they can help identify potential red flags, provide additional context, and point you toward reliable information.\n\u2022 None InVID provides reverse image search capabilities and metadata analysis for photos and videos, making it particularly useful for verifying whether images have been taken out of context or digitally manipulated.\n\u2022 None Google Lens offers similar reverse image search functionality with a user-friendly interface. It can help you trace the source of suspicious images.\n\u2022 None Deepware Scanner specifically targets deepfake detection, although it works more effectively with obvious manipulations than with subtle ones.\n\u2022 None The Bellingcat digital toolkit features various OSINT (Open Source Intelligence) plugins that aid in verifying sources, checking domain registration information, and tracing the dissemination of content across platforms.\n\u2022 None WHOIS and DNS history tools let you investigate the ownership and history of websites, which is crucial when evaluating the credibility of unfamiliar sources.\n\u2022 None Copyleaks: The app utilizes advanced AI to detect plagiarism and AI-generated content. While primarily targeted at educators and content creators, it also has consumer utility in identifying whether text has been machine-generated or copied from another source, rather than verifying factual accuracy.\n\u2022 None Facticity AI: A relatively new entrant focused on rating the factual integrity of online content. Its real value lies in using AI to detect narrative framing and misinformation patterns, but it's still developing in terms of consumer accessibility and widespread use.\n\u2022 None AllSides: Shows news stories from left, center, and right perspectives side by side, with media bias ratings that reflect the average judgment of all Americans across the political spectrum. AllSides Headline Roundups bring you top news stories from the left, center, and right of the political spectrum \u2014 side-by-side so you can see the whole picture. Available as both a website and a mobile app.\n\u2022 None Ground News compares how different news publishers frame the same news story, showing bias ratings and allowing users to read from multiple perspectives across the political spectrum. Unlike traditional news aggregators, which utilize crowdsourcing and algorithms that reward clickbait and reinforce pre-existing biases, Ground News helps users understand the news objectively, based on media bias, geographic location, and time. Available as a website, mobile app, and browser extension.\n\u2022 None Ad Fontes Media: Creator of the Media Bias Chart that rates news sources for bias and reliability using a team of analysts from across the political spectrum. The Media Bias Chart rates various media sources on two scales: political bias (from left to right) on the horizontal axis and reliability on the vertical axis. Offers both free static charts and premium interactive versions.\n\u2022 None Media Bias Detector: Developed by the University of Pennsylvania, this tool tracks and exposes bias in news coverage by analyzing individual articles rather than relying solely on publishers. Using AI, machine learning, and human raters, it tracks topics, events, facts, tone, and political lean of coverage from major news publishers in near real-time. The tool reveals important patterns, such as how headlines can have different political leanings than the articles they represent.\n\u2022 None RumorGuard, created by the News Literacy Project, helps identify credible information and debunk viral rumors by teaching users how to verify news using five key credibility factors. Goes beyond traditional fact-checking by using debunked hoaxes, memes, and other misinformation as the starting point for learning news literacy skills. Categorizes misinformation by topics and provides educational resources about media literacy.\n\u2022 None Compass Vision and Context: My day job is at Blackbird.AI, where my teammates and I help organizations identify and respond to manipulated narratives. We built Compass Context to help anyone, regardless of expertise and experience, analyze internet content for manipulated narratives. The app goes beyond fact-checking to interpret the intent, spread, and potential harm of narrative attacks. While initially built for enterprise and government, it surfaces critical information about who is behind a campaign, how it's scaling, and whether it's likely coordinated, making it powerful for advanced users who want more than a true/false score.\n\nHow to talk about narrative attacks - without fueling them\n\nThe language you use when discussing false information significantly impacts how others perceive and respond to it. Poor communication can accidentally amplify the very narratives you're trying to counter. Here are a few approaches to try:\n\u2022 Never repeat false claims verbatim, even when debunking them. Research indicates that repetition enhances belief, regardless of the context in which it occurs. Instead of saying \"Some people claim that X is true, but Y,\" try \"Evidence shows that Y is the case.\"\n\u2022 Focus on describing tactics rather than specific claims. Explain how the content was manipulated to spread outrage rather than detailing what the manipulated content alleged. This approach helps people recognize similar tactics in the future without reinforcing false narratives.\n\u2022 Be transparent about uncertainty. If you're unsure whether something is true or false, say so. Acknowledging the limits of your knowledge builds credibility and models appropriate skepticism.\n\u2022 Encourage critical thinking without promoting paranoid conspiracy theories. There's a crucial difference between healthy skepticism and destructive cynicism. Help people ask better questions rather than teaching them to distrust everything.\n\nWhat organizations and leaders should do now\n\nTraditional crisis communications strategies are insufficient for narrative attacks. Organizations need proactive defensive measures, not just reactive damage control.\n\u2022 Start by auditing your brand's digital vulnerability. What narratives already exist about your organization? Where are they being discussed? What communities might be susceptible to negative campaigns targeting your industry or values?\n\u2022 Train staff on narrative detection, not just cybersecurity hygiene. Employees need to understand how manipulation campaigns work and how to spot them. This training should be ongoing, not a one-time workshop.\n\u2022 Monitor fringe sources alongside mainstream media. Narrative attacks often begin in obscure forums and fringe communities before spreading to larger platforms. Early detection requires monitoring these spaces.\n\u2022 Prepare statements and content to anticipate and respond to predictable attacks. Every organization faces recurring criticism. Develop template responses for common narratives about your industry, such as labor practices, environmental impact, AI ethics, or other predictable areas of controversy.\n\u2022 Consider partnering with narrative intelligence platforms that can provide early warning systems and professional analysis. The sophistication of modern narrative attacks often requires specialized expertise to counter effectively.\n\u2022 Establish clear protocols for responding to suspected narrative attacks. Who makes decisions about public responses? How do you verify the information before responding to it? What's your escalation process when attacks target individual employees?\n\nMore steps organizations can take\n\nCultural media literacy requires systematic changes to how we teach and reward information sharing. Schools should integrate source evaluation and digital verification techniques into their core curricula, not just as separate media literacy classes. News organizations should prominently display correction policies and provide clear attribution for their reporting.\n\nAlso: Why AI-powered security tools are your secret weapon against tomorrow's attacks\n\nSocial media platforms should slow down the spread of viral content by introducing friction for sharing unverified claims. Professional associations across industries should establish standards for how their members communicate with the public about complex topics. Communities can organize local media literacy workshops that teach practical skills, such as identifying coordinated inauthentic behavior and understanding how algorithmic amplification works.\n\nImplementation depends on making verification tools more accessible and building new social norms around information sharing. Browser extensions that flag questionable sources, fact-checking databases that journalists and educators can easily access, and community-driven verification networks can democratize the tools currently available only to specialists. We need to reward careful, nuanced communication over sensational claims and create consequences for repeatedly spreading false information. This requires both individual commitment to slower, more thoughtful information consumption and institutional changes that prioritize accuracy over engagement metrics.\n\nNarrative attacks represent a fundamental shift in how information warfare operates, requiring new defensive skills from individuals and organizations alike. The verification tools, detection techniques, and communication strategies outlined here aren't theoretical concepts for future consideration but practical necessities for today's information environment. Success depends on building these capabilities systematically, training teams to recognize manipulation tactics, and creating institutional cultures that reward accuracy over speed.\n\nAlso: Yes, you need a firewall on Linux - here's why and which to use\n\nThe choice isn't between perfect detection and complete vulnerability but between developing informed skepticism and remaining defenseless against increasingly sophisticated attacks designed to exploit our cognitive biases and social divisions.",
  "medium": "Article",
  "links": [
    "https://states.aarp.org/maryland/celebrity-scams-in-the-age-of-ai",
    "https://www.cbsnews.com/news/fake-videos-conspiracies-falsehoods-los-angeles-protests/",
    "https://www.isdglobal.org/wp-content/uploads/2023/01/Deny-Deceive-Delay-Vol.-2.pdf",
    "https://www.weforum.org/stories/2025/07/financial-impact-of-disinformation-on-corporations/",
    "https://unglobalriskreport.org/UNHQ-GlobalRiskReport-WEB-FIN.pdf",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC9633026/",
    "https://www.linkedin.com/in/jaredlawrenceholt/",
    "https://www.facticity.ai/",
    "https://www.zdnet.com/article/7-ways-to-lock-down-your-phones-security-before-its-too-late/",
    "https://www.rumorguard.org/",
    "https://jcpa.org/article/european-anti-americanism-and-anti-semitism-similarities-and-differences/",
    "https://www.bellingcat.com/resources/2024/09/24/bellingcat-online-investigations-toolkit/",
    "https://nysba.org/why-media-literacy-education-is-crucial-for-u-s-students/?srsltid=AfmBOoqnw7tjafdqSacopI0qt46-Bx4Z2m0Hqv5BfoXFRBriI7wAMVAO",
    "https://www.forrester.com/report/the-external-threat-intelligence-service-providers-landscape-q1-2025/RES181939",
    "https://ground.news/",
    "http://compass.blackbird.ai",
    "https://www.invid-project.eu/tag/image-reverse-search/",
    "https://www.zdnet.com/article/navigating-ai-powered-cyber-threats-in-2025-4-expert-security-tips-for-businesses/",
    "https://www.theguardian.com/us-news/article/2024/jun/20/fake-news-websites-us-election",
    "https://www.isdglobal.org/",
    "https://www.atlanticcouncil.org/expert/andy-carvin/",
    "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
    "https://copyleaks.com/",
    "https://www.allsides.com/",
    "https://www.linkedin.com/in/andycarvin/",
    "https://www.zdnet.com/article/gpt-5-bombed-my-coding-tests-but-redeemed-itself-with-code-analysis/",
    "https://uk.news.yahoo.com/fake-videos-ai-chatbots-drive-035421986.html",
    "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/",
    "https://research.domaintools.com/research/whois-history/",
    "https://fueled.com/blog/localtion-spoofing/",
    "https://lens.google/",
    "https://www.zdnet.com/article/why-ai-powered-security-tools-are-your-secret-weapon-against-tomorrows-attacks/",
    "https://www.cbsnews.com/news/fake-social-media-accounts/",
    "https://www.zdnet.com/article/yes-you-need-a-firewall-on-linux-heres-why-and-which-to-use/",
    "https://adfontesmedia.com/",
    "https://threatpost.com/hackers-using-automation-geolocation-social-networking-attacks-020110/73458/",
    "https://www.splcenter.org/resources/extremist-files/conspiracy-propagandists/",
    "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
    "https://www.forrester.com/what-it-means/ep365-top-threats-2024/",
    "http://blackbird.ai",
    "https://www.france24.com/en/live-news/20240424-recycled-zombie-misinformation-targets-us-voters",
    "https://www.pbs.org/newshour/world/how-russian-disinformation-campaigns-have-sought-to-undermine-the-paris-olympics",
    "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
    "https://www.cbsnews.com/news/rise-of-ai-celebrity-endorsements/",
    "https://www.zdnet.com/article/syncable-vs-non-syncable-passkeys-are-roaming-authenticators-the-best-of-both-worlds/",
    "https://www.zdnet.com/article/beware-of-promptware-how-researchers-broke-into-google-home-via-gemini/",
    "https://www.andrews.edu/life/student-movement/issues/2024-11-22/id_medialiteracy.html",
    "https://mediabiasdetector.seas.upenn.edu/",
    "https://carnegieendowment.org/research/2024/01/countering-disinformation-effectively-an-evidence-based-policy-guide?lang=en",
    "https://scanner.deepware.ai/",
    "https://www.bbc.com/news/articles/cg33x9jm02ko"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Narrative attacks",
      "weight": 0.07377459
    },
    {
      "name": "narrative attacks",
      "weight": 0.07377459
    },
    {
      "name": "modern narrative attacks",
      "weight": 0.06940894
    },
    {
      "name": "suspected narrative attacks",
      "weight": 0.06864072
    },
    {
      "name": "false narratives",
      "weight": 0.065394185
    },
    {
      "name": "narrative detection",
      "weight": 0.062396314
    },
    {
      "name": "manipulated narratives",
      "weight": 0.062159646
    },
    {
      "name": "sophisticated narrative campaigns",
      "weight": 0.060795095
    },
    {
      "name": "narrative intelligence platforms",
      "weight": 0.060417745
    },
    {
      "name": "known narrative manipulation networks",
      "weight": 0.059856214
    }
  ],
  "topics": [
    {
      "name": "AI"
    },
    {
      "name": "Media"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.853515625
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.732421875
    },
    {
      "name": "/People & Society/Social Issues & Advocacy/Other",
      "score": 0.60009765625
    },
    {
      "name": "/Online Communities/Social Networks",
      "score": 0.3720703125
    }
  ],
  "sentiment": {
    "positive": 0.07078028,
    "negative": 0.6256428,
    "neutral": 0.30357692
  },
  "summary": "AI-powered narrative attacks, or misinformation campaigns, are on the rise, which can create real business, brand, personal, and financial harm online. These attacks, defined by Forrester as AI-powered manipulations or distortions of information that exploit biases and emotions, are like disinformation campaigns on steroids. The article provides practical tools to identify these attacks, verify suspicious information, and safeguard yourself and your organization. It also covers detection techniques, verification tools, and defensive strategies that work in the real world. These include strategies to prevent these attacks from occurring and implement themselves. Key factors such as AI tools not democratizing content creation, social media platforms fragment audiences into smaller groups, and content moderation systems struggle to keep pace with the sophistication of synthetic media. The rise in these attacks have also led to an increase in automated detection and sophisticated manipulation techniques. However, bad actors are testing new playbooks combining traditional propaganda techniques with advanced cyber tactics to create more effective manipulation campaigns.",
  "shortSummary": "AI-powered narrative attacks, or misinformation campaigns, are rapidly increasing in popularity among tech-savvy individuals, exploiting security vulnerabilities in social media to manipulate public opinion and businesses.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "1df8a6629fdf4590a078dbf7bb0aebb0",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.zdnet.com/article/why-ai-powered-security-tools-are-your-secret-weapon-against-tomorrows-attacks/",
      "text": "Why AI-powered security tools are your secret weapon against tomorrow's attacks\nIt's an age-old adage of cyber defense that an attacker has to find just one weakness or exploit, but the defender has to defend against everything. The challenge of AI, when it comes to cybersecurity, is that it is an arms race in which weapons-grade AI capabilities are available to both attackers and defenders.\nCisco is one of the world's largest networking companies. As such, it is on the front lines of defending against AI-powered cyberattacks.\nAlso: 4 expert security tips for navigating AI-powered cyber threats\nIn this exclusive interview, ZDNET sits down with Cisco's AI products VP, Anand Raghavan, to discuss how AI-powered tools are revolutionizing cybersecurity and expanding organizations' attack surfaces.\nZDNET: Can you briefly introduce yourself and describe your role at Cisco?\nAnand Raghavan: I'm Anand Raghavan, VP Products, AI for the AI Software and Platforms Group at Cisco. We focus on working with product teams across Cisco to bring together transformative, safe, and secure Gen AI-powered products to our customers.\nTwo products that we launched in the recent past are the Cisco AI Assistant which makes it easy for our customers to interact with our products using natural language, and Cisco AI Defense which enables safe and secure use of AI for employees and for cloud applications that organizations build for their customers.\nZDNET: How is AI transforming the nature of threats enterprises and governments face at the network level?\nAR: AI has completely changed the game for network security, enabling hackers to launch more sophisticated and less time-intensive attacks. They're using automation to launch more personalized and effective phishing campaigns, which means employees may be more likely to fall for phishing attempts.\nWe're seeing malware that uses AI to adapt to avoid detection from traditional network security tools. As AI tools become more common, they expand the attack surface that security teams need to manage and they exacerbate the existing problem of shadow IT.\nJust as companies have access to AI to build new and interesting applications, bad actors have access to the same sets of technologies to create new attacks and threats. It has become more important than ever to use the latest in advancements in AI to be able to identify these new kinds of threats and to automate the remediation of these threats.\nAlso: The head of US AI safety has stepped down. What now?\nWhether it is malicious connections that can be stopped in real-time in the encrypted domain within our firewalls using our Encrypted Visibility Engine technology, or our language-based detectors of fraudulent emails in our Email Threat Defense product, it has become critical to understand the new attack surface of threats and how to protect against them.\nWith the advent of customer-facing AI applications, models and model-related vulnerabilities have become critical new attack surfaces. AI models can be the target of threats. Prompt injection or denial of service attacks may inadvertently leak sensitive data. The security industry has responded quickly to incorporate AI into solutions to spot unusual patterns and detect suspicious network activity. but it's a race to stay one step ahead.\nZDNET: How do AI-driven tools help enterprises stay ahead of increasingly sophisticated cyber adversaries?\nAR: In an evolving threat landscape, AI-powered security tools deliver continuous and self-optimizing monitoring at a scale that manual monitoring can't match.\nUsing AI, a security team can analyze data from various sources across a company's entire ecosystem and detect unusual patterns or suspicious traffic that could indicate a data breach. Because AI analyzes this data more quickly than humans, organizations can respond to incidents in near real-time to mitigate potential threats.\nAlso: What is DeepSeek AI? Is it safe? Here's everything you need to know\nWhen it comes to threat monitoring and detection, AI offers security professionals a \"better together\" scenario where the human professionals get visibility and response times with the AI that they wouldn't be able to achieve solo.\nIn a world where experienced top-level Tier 3 analysts in the SOC [security operations center] are harder to find, AI can be an integral part of an organization's strategy to aid and assist Tier 1 and Tier 2 analysts in their jobs and drastically reduce their mean time to remediation for any new discovered incidents and threats.\nWorkflow automation for XDR [extended detection and response] using AI will help enterprises stay ahead of cyber adversaries.\nZDNET: Explain AI Defense, and what is the main problem it aims to solve?\nAR: When you think about how quickly people have adopted AI applications, it's off the charts. Within organizations, however, AI development and adoption isn't moving as quickly as it could be because people still aren't sure it's safe or they aren't confident they can keep it secure.\nAccording to Cisco's 2024 AI Readiness Index, only 29% of organizations feel fully equipped to detect and prevent unauthorized tampering with AI. Companies can't afford to risk security by moving too quickly, but they also can't risk being lapped by their competition because they didn't embrace AI.\nAlso: Tax scams are getting sneakier - 10 ways to protect yourself before it's too late\nAI Defense enables and safeguards AI transformation within enterprises, so they don't have to make this tradeoff. In the future, there will be AI companies and companies that are irrelevant.\nThinking about this challenge at a high level, AI poses two overarching risks to an enterprise. The first is the risk of sensitive data exposure from employees misusing third-party AI tools. Any intellectual property or confidential information shared with an unsanctioned AI application is susceptible to leakage and exploitation.\nThe second risk is related to how businesses develop and deploy their own AI applications. AI models need to be protected from threats such as prompt injections or training data poisoning, so they continue to operate the way that they are intended and are safe for customers to use.\nAlso: AI is changing cybersecurity and businesses must wake up to the threat\nCisco AI Defense addresses both areas of AI risk. Our AI Access solution gives security teams a comprehensive view of third-party AI applications in use and enables them to set policies that limit sensitive data sharing or restrict access to unsanctioned tools.\nFor businesses developing their own AI applications, AI Defense uses algorithmic red team technology to automate vulnerability assessments for models.\nAfter identifying these risks in seconds, AI Defense provides runtime guardrails to keep AI applications protected against threats like prompt injections, data extraction, and denial of service in real-time.\nZDNET: How does AI Defense differentiate itself from existing security frameworks?\nAR: The safety and security of AI is a massive new challenge that enterprises are only just beginning to contend with. After all, AI is fundamentally different from traditional applications and existing security frameworks don't necessarily apply in the same ways.\nAI Defense is purpose-built to protect enterprises from the risks of AI application usage and development. Our solution is built on Cisco's own custom AI models with two main principles: continuous AI validation and protection at scale.\nAlso: That weird CAPTCHA could be a malware trap - here's how to protect yourself\nWhen it comes to securing traditional applications, companies use a red team of human security professionals to try to jailbreak the app and find vulnerabilities. This approach doesn't provide anywhere near the scale needed to validate non-deterministic AI models. You'd need teams of thousands working for weeks.\nThis is why AI Defense uses an algorithmic red teaming solution that continuously monitors for vulnerabilities and recommends guardrails when it finds them. Cisco's platform approach to security means that these guardrails are distributed across the network and the security team gets total visibility across their AI footprint.\nZDNET: What is Cisco's vision for integrating AI Defense with broader enterprise security strategies?\nAR: Cisco's 2024 AI Readiness Index showed that while organizations face mounting pressure to adopt AI, most organizations are still not ready to capture AI's potential and many lack awareness around AI security risks.\nWith solutions like AI Defense, Cisco is enabling organizations to unlock the benefits of AI and do so securely. Cisco AI Defense is designed to address the security challenges of a multi-cloud, multi-model world in which organizations operate.\nAlso: How Cisco, LangChain, and Galileo aim to contain 'a Cambrian explosion of AI agents'\nIt gives security teams visibility and control over AI applications and is frictionless for developers, saving them time and resources so they can focus on innovating.\nWhen an organization is looking to adopt AI, both for employees and to build customer-facing applications, their adoption lifecycle has the following steps:\n- Visibility: Understand what tools are being used by employees, or what models are being deployed in their cloud environments.\n- Validation: Monitor and validate models running in their cloud environments and assess their vulnerabilities and identify guardrails as compensating controls for these vulnerabilities.\n- Runtime protection: When these models get deployed in production, monitor all prompts and responses, and apply safety, security, privacy, and relevance guardrails to these prompts and responses to ensure that their customers have a safe and secure experience interacting with these cloud applications.\nThese are the core areas that AI Defense supports as part of its capabilities. Enforcement can happen in a Secure Access or SASE [secure access service edge] product for employee protection, and enforcement for cloud applications can happen in a Cloud Protection Suite application like Cisco Multicloud Defense.\nZDNET: What strategies should enterprises adopt to mitigate the risks of adversarial attacks on AI systems?\nAR: AI applications introduce a new class of security risks to an organization's tech stack. Unlike traditional apps, AI apps include models, which are unpredictable and non-deterministic. When models don't behave as they are supposed to, they can result in hallucinations and other unintended consequences. Models can also fall victim to attacks like training data poisoning, prompt injection, and jailbreaking.\nModel builders and developers will both have security layers in place for AI models, but in a multi-cloud, multi-model system, there will be inconsistent safety and security standards. To protect against AI tampering and the risk of data leakage, organizations need a common substrate of security across all clouds, apps, and models.\nAlso: This powerful firewall delivers enterprise-level security at a home office price\nThis becomes even more important when you have fragmented accountability across stakeholders -- model builders, app builders, governance, risk, and compliance teams.\nHaving a common substrate in terms of an AI security product that can monitor and enforce the right set of guardrails that protect across all categories of AI safety and security as outlined by standards such as MITRE ATLAS and OWASP LLM10 and NIST RMF becomes vital.\nZDNET: Could you share a real-world scenario or case study where AI Defense could prevent a critical security breach?\nAR: As I mentioned, AI Defense covers the two main areas of enterprise AI risk: the usage of third-party AI tools and the development of new AI applications. Let's look at incident scenarios for each of these use cases.\nIn the first scenario, an employee shares information about some of your customers with an unsanctioned AI assistant for help preparing a presentation. This confidential data can become codified in the AI's retraining data, meaning it can be shared with other public users. AI Defense can limit this data sharing or restrict access to the unsanctioned tool entirely, mitigating the risk of what would otherwise be a devastating privacy violation.\nAlso: The best malware removal software: Expert tested and reviewed\nIn the second scenario, an AI developer uses an open-source foundation model to create an AI customer service assistant. They fine-tune it for relevance but inadvertently weaken its built-in guardrails. Within days, it's hallucinating incorrect responses and becoming more susceptible to adversarial attack. With continuous monitoring and vulnerability testing, AI Defense would identify the flaw in the model and apply your preferred guardrails automatically.\nZDNET: What emerging trends in AI security do you foresee shaping the future of cybersecurity?\nAR: One critical aspect of AI in security is that we're seeing exploit times decrease. Security professionals have a shorter window than ever between when a vulnerability is discovered and when it is exploited by attackers.\nAs AI makes cybercriminals faster and their attacks more efficient, it's increasingly urgent that organizations detect and patch vulnerabilities quickly. AI can significantly speed up the detection of vulnerabilities so security teams can respond in real time.\nAlso: Most people worry about deepfakes - and overestimate their ability to spot them\nDeepfakes are going to be a massive security concern over the next five years. In many ways, the security industry is just getting ready for deepfakes and how to defend against them, but this will be a critical area of vulnerability and risk for organizations.\nThe same way denial-of-service attacks were a major concern 10 years ago and ransomware has been a critical threat in more recent years, deepfakes are going to keep a lot of security professionals up at night.\nZDNET: How can governments and enterprises collaborate to build robust AI security standards?\nAR: By working together, governments and the private sector can tap into a deep pool of knowledge and wide spectrum of perspectives to develop best practices in a quickly evolving risk landscape of AI and security.\nLast year, Cisco worked with the Cybersecurity and Infrastructure Security Agency's (CISA) Joint Cyber Defense Collaborative (JCDC), which brought together industry leaders from some of the biggest players in tech, such as OpenAI, Amazon, Microsoft, and Nvidia, and government agencies to collaborate with the goal of enhancing organizations' collective ability to respond to AI-related security incidents.\nAlso: When you should use a VPN - and when you shouldn't\nWe participated in a tabletop exercise and collaborated on the recently released \"AI Security Incident Collaboration Playbook,\" which is a guide for collaboration between government and private industry.\nIt offers practical, actionable advice for responding to AI-related security incidents and guidance on voluntarily sharing information related to vulnerabilities associated with AI systems.\nTogether, government and the private sector can raise awareness of security risks facing this critical technology.\nZDNET: How do you see AI bridging the gap between cyberattack prevention and incident response?\nAR: We're already seeing AI-enabled security solutions deliver continuous and scalable monitoring that helps human security teams detect suspicious network activity and vulnerabilities.\nWe're in the stage where AI is an invaluable tool that gives security professionals better visibility and recommendations on how to respond to security incidents.\nAlso: Why OpenAI's new AI agent tools could change how you code\nEventually, we'll reach a point where AI can automatically deploy and implement security patches with oversight from a human security professional. The benefits, in a nutshell, are continuity (always monitoring), scalability (as your attack surface grows, AI helps you manage it), accuracy (AI can detect even more subtle indicators that a human might miss), and speed (faster than manual review).\nAre you prepared?\nAI is transforming cybersecurity, but are enterprises truly prepared for the risks it brings? Have you encountered AI-driven cyber threats in your organization?\nDo you think AI-powered security solutions can stay ahead of increasingly sophisticated attacks? How do you see the balance between AI as a security tool and a potential vulnerability?\nAre companies doing enough to secure their AI models from exploitation? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nThe best AI for coding in 2025 (including a new winner - and what not to use)\nI've been around technology long enough that very little excites me, and even less surprises me. But shortly after OpenAI's ChatGPT was released, I asked it to write a WordPress plugin for my wife's e-commerce site. When it did, and the plugin worked, I was indeed surprised.\nThat was the beginning of my deep exploration into chatbots and AI-assisted programming. Since then, I've subjected 14 large language models (LLMs) to four real-world tests.\nAlso: Apple's secret sauce is exactly what AI is missing\nUnfortunately, not all chatbots can code alike. It's been a little over two years since that first test, and even now, four of the 13 LLMs I tested can't create working plugins.\nThe short version\nIn this article, I'll show you how each LLM performed against my tests. There are now five chatbots I recommend you use.\nTwo of them, ChatGPT Plus and Perplexity Pro, cost $20 per month each. The free versions of the same chatbots do well enough that you could probably get by without paying. Two other recommended products are from Google and Microsoft. Google's Gemini Pro 2.5 is free, but you're limited to so few queries that you really can't use it without paying.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nMicrosoft has several Copilot licenses, which can get pricey, but I used the free version with surprisingly good results. The final one, Claude 4 Sonnet, is the free version of Claude. Oddly enough, the free version beat the paid-for version, so we're not recommending Claude 4 Opus.\nBut the rest, whether free or paid, are not so great. I won't risk my programming projects with them or recommend that you do, until their performance improves.\nI've written lots about using AIs to help with programming. Unless it's a small, simple project like my wife's plugin, AIs can't write entire apps or programs. But they excel at writing a few lines and are not bad at fixing code.\nRather than repeat everything I've written, go ahead and read this article: How to use ChatGPT to write code.\nIf you want to understand my coding tests, why I've chosen them, and why they're relevant to this review of the 13 LLMs, read this article: How I test an AI chatbot's coding ability.\nThe AI coding leaderboard\nLet's start with a comparative look at how the chatbots performed, as of this installment of our best-of roundup:\nNext, let's look at each chatbot individually. I'm back up to discussing 14 chatbots, because we're splitting out Claude 4 Sonnet and Claude 4 Opus as separate tests. GPT-4 is no longer included since OpenAI has sunsetted that LLM. Ready? Let's go.\n- Passed all tests\n- Solid coding results\n- Mac app\n- Hallucinations\n- No Windows app yet\n- Sometimes uncooperative\n- Price: $20/mo\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nChatGPT Plus with GPT-4o passed all my tests. One of my favorite features is the availability of a dedicated app. When I test web programming, I have my browser set on one thing, my IDE open, and the ChatGPT Mac app running on a separate screen.\nAlso: I put GPT-4o through my coding tests and it aced them - except for one weird result\nIn addition, Logitech's Prompt Builder, which can be activated with a mouse button, can be set up to utilize the upgraded GPT-4o and connect to your OpenAI account, allowing for a simple thumb tap to run a prompt, which is very convenient.\nThe only thing I didn't like was that one of my GPT-4o tests resulted in a dual-choice answer, and one of those answers was wrong. I'd rather it just gave me the correct answer. Even so, a quick test confirmed which answer would work. However, that issue was a bit annoying.\n- Multiple LLMs\n- Search criteria displayed\n- Good sourcing\n- Email-only login\n- No desktop app\n- Price: $20/mo\n- LLM: GPT-4o, Claude 3.5 Sonnet, Sonar Large, Claude 3 Opus, Llama 3.1 405B\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 4 of 4\nI seriously considered listing Perplexity Pro as the best overall AI chatbot for coding, but one failing kept it out of the top slot: how you log in. Perplexity doesn't use a username/password or passkey and doesn't have multi-factor authentication. All the tool does is email you a login PIN. The AI doesn't have a separate desktop app, as ChatGPT does for Macs.\nWhat sets Perplexity apart from other tools is that it can run multiple LLMs. While you can't set an LLM for a given session, you can easily go into the settings and choose the active model.\nAlso: Can Perplexity Pro help you code? It aced my programming tests - thanks to GPT-4\nFor programming, you'll probably want to stick to GPT-4o, because that model aced all our tests. But it might be interesting to cross-check your code across the different LLMs. For example, if you have GPT-4o write some regular expression code, you might consider switching to a different LLM to see what that model thinks of the generated code.\nAs we'll see below, most LLMs are unreliable, so don't take the results as gospel. However, you can use the results to check your original code. It's sort of like an AI-driven code review.\nJust don't forget to switch back to GPT-4o.\n- Price: Free for limited use, then token-based pricing\n- LLM: Gemini Pro 2.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThe last time I looked at Gemini, it failed miserably. Not quite as bad as Copilot at the time, but bad. Gemini Pro 2.5, however, has performed quite admirably. My only real issue with it is access. I found myself cut off from the free version after only running two of the four tests.\nAlso: Gemini Pro 2.5 is a stunningly capable coding assistant - and a big threat to ChatGPT\nI waited a day and then ran the third test, and got cut off again. Finally, on the third day, I ran my fourth test. Obviously, you can't do any real programming if you can only ask one or two questions before being shut down. So, if you sign up with Gemini Pro 2.5, be aware that Google charges by tokens (basically, the amount of AI you use). That can make it quite difficult to predict your expenses.\n- Price: Free for basic Copilot, or fees for other Copilot licenses\n- LLM: Undisclosed\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nIn all my previous analyses of Microsoft Copilot, the results were the worst of the LLMs. Copilot got nothing right. It was astonishing how bad it was. But I said then that, \"The one positive thing is that Microsoft always learns from its mistakes. So, I'll check back later and see if this result improves.\"\nAlso: I retested Microsoft Copilot's AI coding skills in 2025 and now it's got serious game\nAnd boy, did it ever. This time out, Microsoft passed all four of my tests. Even better, it did this with the free version of Copilot. Yes, Microsoft has many paid programs for Copilot, but if you want to give it the AI spin, point yourself to Copilot and use it.\n- Price: Free\n- LLM: Claude 4\n- Desktop browser interface: No\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThis is one of those times when AI implementations can be real head-scratchers. In our previous tests, Claude 4 Sonnet finished at the bottom of the barrel, failing all four of our tests. This time, however, Sonnet passed every test. So, what's the head-scratcher? Opus, the Claude 4 model, which is a fee-paid version, did not do as well: it failed half the tests.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nSo, yes. The free version worked like a champ. And the one you're paying anywhere from $20 to $250 a month for, depending on the plan? Well, that one failed half of the tests. Go figure.\n- Different LLM than ChatGPT\n- Good descriptions\n- Free access\n- Only available in browser mode\n- Free access likely only temporary\n- Price: Free (for now)\n- LLM: Grok-1\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4\nI have to say, Grok surprised me. I guess I didn't have high hopes for an LLM that appeared tacked on to the social network formerly known as Twitter. However, X is now owned by Elon Musk, and two of Musk's companies, Tesla and SpaceX, have towering AI capabilities.\nIt's unclear how much Tesla and SpaceX AI DNA is in Grok, but we can assume there will likely be more work. As of now, Grok is the only LLM not based on OpenAI LLMs that made it into the recommended list.\nAlso: X's Grok did surprisingly well in my AI coding tests\nGrok did make one mistake, but it was a relatively minor one that a slightly more comprehensive prompt could easily remedy. Yes, it failed the test. But by passing the others and even doing an almost perfect job on the one it passed, Grok earned itself a spot as a contender.\nStay tuned. This is an AI to watch.\n- Free\n- Passed most tests\n- Prompt throttling\n- Could cut you off in the middle of whatever you're working on\n- Price: Free\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4 in GPT-3.5 mode\nChatGPT is available to anyone for free. While both the Plus and free versions support GPT-4o, which passed all my programming tests, the free app has limitations.\nOpenAI treats free ChatGPT users as if they're in the cheap seats. If traffic is high or the servers are busy, the free version of ChatGPT will only make GPT-3.5 available to free users. The tool will only allow you a certain number of queries before it downgrades or shuts you off.\nAlso: How to use ChatGPT to write code - and my favorite trick to debug what it generates\nI've had several occasions when the free version of ChatGPT effectively told me I'd asked too many questions.\nChatGPT is a great tool, as long as you don't mind it shutting down. Even GPT-3.5 did better on the tests than all the other chatbots, and the test it failed was for a fairly obscure programming tool produced by a lone programmer in Australia.\nSo, if budget is important to you and you can wait when you're cut off, then use ChatGPT for free.\n- Free\n- Passed most tests\n- Range of research tools\n- Limited to GPT-3.5\n- Throttles prompt results\n- Price: Free\n- LLM: GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nI'm threading a pretty fine needle here, but because Perplexity AI's free version is based on GPT-3.5, the test results were measurably better than the other AI chatbots.\nAlso: 5 reasons why I prefer Perplexity over every other AI chatbot\nFrom a programming perspective, that's pretty much the whole story. However, from a research and organization perspective, my ZDNET colleague Steven Vaughan-Nichols prefers Perplexity over the other AIs.\nHe likes how Perplexity provides more complete sources for research questions, cites its sources, organizes the replies, and offers questions for further searches.\nSo, if you're programming, but also working on other research, consider the free version of Perplexity.\n- Free\n- Open source\n- Efficient resource utilization\n- Weak general knowledge\n- Small ecosystem\n- Limited integrations\n- Price: Free for chatbot, fees for API\n- LLM: DeepSeek MoE\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nWhile DeepSeek R1 is the new reasoning hotness from China that has all the pundits punditing, the real power right now (at least according to our tests) is DeepSeek V3. This chatbot passed almost all of our coding tests, doing as well as the (now mostly discontinued) ChatGPT 3.5.\nAlso: I tested DeepSeek's R1 and V3 coding skills - and we're not all doomed (yet)\nWhere DeepSeek V3 fell was in its knowledge of somewhat more obscure programming environments. Still, it beat Google's Gemini, Microsoft's Copilot, and Meta's Meta AI, which is quite an accomplishment. We'll be keeping a close watch on each DeepSeek model, so stay tuned.\nChatbots to avoid for programming help\nI tested 13 LLMs, and nine passed most of my tests this time around. The other chatbots, including a few pitched as great for programming, only passed one of my tests.\nAlso: The five biggest mistakes people make when prompting an AI\nI'm mentioning them here because people will ask, and I did test them thoroughly. Some of these bots are fine for other work, so I'll point you to their general reviews if you're curious about their functionality.\nDeepSeek R1\nUnlike DeepSeek V3, the advanced reasoning version, DeepSeek R1, did not showcase its reasoning capabilities in our programming tests. Unusually, the new failure area was one that's not all that hard, even for a basic AI -- the regular expression code for our string function test.\nAlso: Tech prophet Mary Meeker just dropped a massive report on AI trends - here's your TL;DR\nBut that's why we are running these real-world tests. It's never clear where an AI will hallucinate or just plain fail, and before you go believing all the hype about DeepSeek R1 taking the crown away from ChatGPT, run some programming tests. So far, while I'm impressed with the much-reduced resource utilization and the open-source nature of the product, its coding quality output is inconsistent.\nGitHub Copilot\nGitHub's Copilot integrates quite seamlessly with VS Code. The AI makes asking for coding help quick and productive, especially when working in context. That's why it's so disappointing that the code the AI outputs is often very wrong.\nAlso: I put GitHub Copilot's AI to the test - and it just might be terrible at writing code\nI can't, in good conscience, recommend you use the GitHub Copilot extensions for VS Code. I'm concerned that the temptation will be too great to insert blocks of code without sufficient testing -- and that GitHub Copilot's produced code is not ready for production use. Try again next year.\nClaude 4 Opus\nIn a completely baffling turn of events, the paid-for version of the Claude 4 model, Opus, failed half of my tests. What makes this result baffling is that the free version, Claude 4 Sonnet, passed them all. I don't know what to say apart from AI can be weird.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nMeta AI\nMeta AI is Facebook's general-purpose AI. As you can see above, it failed three of our four tests.\nAlso: 15 ways AI saved me time at work in 2024 - and how I plan to use it in 2025\nThe AI generated a nice user interface, but with zero functionality. It also found my annoying bug, which is a fairly serious challenge. Given the specific knowledge required to find the bug, I was surprised that the AI choked on a simple regular expression challenge. But it did.\nMeta Code Llama\nMeta Code Llama is Facebook's AI explicitly designed for coding help. It's something you can download and install on your server. I tested the AI running on a Hugging Face AI instance.\nAlso: Can Meta AI code? I tested it against Llama, Gemini, and ChatGPT - it wasn't even close\nWeirdly, even though both Meta AI and Meta Code Llama choked on three of four of my tests, they choked on different problems. AIs can't be counted on to give the same answer twice, but this result was a surprise. We'll see if that changes over time.\nBut I like [insert name here]. Does this mean I have to use a different chatbot?\nProbably not. I've limited my tests to day-to-day programming tasks. None of the bots has been asked to talk like a pirate, write prose, or draw a picture. In the same way we use different productivity tools to accomplish specific tasks, feel free to choose the AI that helps you complete the task at hand.\nThe only issue is if you're on a budget and are paying for a pro version. Then, find the AI that does most of what you want, so you don't have to pay for too many AI add-ons.\nIt's only a matter of time\nThe results of my tests were pretty surprising, especially given the significant improvements by Microsoft and Google. However, this area of innovation is improving at warp speed, so we'll be back with updated tests and results over time. Stay tuned.\nHave you used any of these AI chatbots for programming? What has your experience been? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/syncable-vs-non-syncable-passkeys-are-roaming-authenticators-the-best-of-both-worlds/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nSyncable vs. non-syncable passkeys: Are roaming authenticators the best of both worlds?\nLike or not, a replacement for passwords -- known as passkeys -- is coming your way, if it hasn't already. The three big ideas behind passkeys are that they cannot be guessed in the way passwords often can (and are), the same passkey cannot be re-used across different websites and apps (the way passwords can), and you cannot be tricked into divulging your passkeys to malicious actors, often through techniques such as phishing, smishing, quishing, and malvertising.\nAlso: How passkeys work: The complete guide to your inevitable passwordless future\nHowever, as noted in ZDNET's 10 Passkey Survival tips, surviving the transition from passwords to passkeys will involve some advanced planning and even some advanced thinking. For example, for each passkey that you register with a website or app (see 'How Passkeys work: Let's start the passkey registration process'), you will have to decide if you want that passkey to be a syncable or non-syncable (a.k.a. 'device-bound') passkey.\nSo, what's the difference between these passkeys, and why does it matter?\nWhat is a syncable passkey, and why would you want one?\nOne of the things that makes passkeys more secure than passwords is that they're so automagical that you, the end user, don't even know what your passkeys are, or where exactly on your device they're stored.\nLike passwords, passkeys involve a secret. However, the secret is automatically generated and stored in a secure location, and the end user never comes into direct contact with the passkey in the way they do with passwords.\nWhen the time comes to log in to a website or app (the operators of which are referred to as \"relying parties\"), the software on your device knows where to find that secret and how to use it to complete the login process without actually sharing the secret with the relying party (see What really happens during your passwordless passkey login).\nAlso: What if your passkey device is stolen? How to manage risk in our passwordless future\nCompared to passwords, where you must furnish your secret to the relying party every time you log in, this one feature alone makes passkeys significantly more secure than passwords.\nBut, as cool and secure as passkey are, when the folks at the FIDO Alliance first came up with the idea of passkeys, they also knew that their concept would get rejected by the market unless there was a way for users to re-use each of their passkeys across their various devices like they do now with their user IDs and passwords.\nFor example, let's say you use your desktop or notebook system to create a passkey for the relying party PayPal.com. As opposed to generating separate passkeys for PayPal for each of your other devices (your smartphone, your tablet, etc.), there should be a way to just reuse the first passkey you created for PayPal on other devices. And it should be automatic.\nOnce you create a passkey for a relying party using any of your devices, that passkey should be available for logging in to that relying party from any of your devices. In other words, it should be possible to synchronize your passkeys across your devices in a way that, for each relying party, you only have to depend on one passkey to log in, regardless of which device you're logging in from.\nThis type of passkey, one that can be synchronized across and securely stored on each of your devices, is called a syncable passkey.\nIn the grand majority of current passkey management implementations, this automagical syncing is supported by one of several cloud-based services that act as synchronization hubs. These hubs are operated by solution providers, such as Google, Apple, 1Password, BitWarden, LastPass, and others, that are also involved in password management.\nFor example, in Apple's case, its iCloud Keychain handles the secure storage and synchronization of user IDs, passwords, passkeys, and other sensitive personal information, such as credit card numbers, across your Apple devices. The Google equivalent of iCloud Keychain is built into Google Password Manager, which is itself built into Chrome.\nAlso: How to set up and use passkeys across your iPhone, iPad, and Mac\nThis is where users and organizations who are interested in the convenience of syncable credentials must carefully consider which solution to rely on. For example, whereas iCloud Keychain only supports Apple operating systems and devices, Google Password Manager is available on any operating system and device that has Chrome installed. To whit, my colleague Lance Whitney recently published an article that explains how to use Chrome to sync passkeys across your PC, Mac, iPhone, or Android.\nAt the time this article was written, Microsoft's Edge cross-platform web browser (available on Windows, MacOS, iOS, Android, and Linux) also relies on a Microsoft-operated cloud-based hub for cross-device user ID and password synchronization. However, passkeys were not yet among the supported synchronizable credential types. In fact, syncable passkeys are yet to be supported by any of Microsoft's identity-related solutions. But it's safe to assume that this approach will change soon, given the degree to which Microsoft is one of the biggest proponents, if not the biggest proponent, of passkeys.\nMeanwhile, the cottage industry of password managers involves a variety of synchronizable offerings that compete on their support for multiple operating systems and multiple web browsers (for example, Chrome only works with Chrome, Edge only works with Edge) while typically offering a range of useful, interesting, and frill-like features.\nSome of these offerings cater more to businesses than others, at which point you start to cross over into the territory of the industrial-strength vendors, such as Okta, that support passkey synchronization as part of a broader set of identity management solutions. Once Microsoft starts to support synchronizable passkeys, it's a safe bet that that support will also appear in Microsoft's competitor to Okta, known as Entra ID (formerly Azure Active Directory).\nAlso: Microsoft Authenticator won't manage your passwords anymore - or most passkeys\nWhereas syncable passkeys are extremely convenient, they're also unnerving to people who see the associated centralized synchronization hubs as obvious targets for hackers to exploit. The operators of the various hubs like to talk about how all that incredibly sensitive data is beyond the reach of hackers due to encryption. But for users who want an added layer of security for some or all of their passkeys, the main alternative to syncable passkeys is non-syncable or \"device-bound\" passkeys.\nWhat is a device-bound (non-syncable) passkey, and why would you want one?\nIn contrast to a syncable passkey, a device-bound passkey can never be disembodied from the hardware used to create it. For example, all modern personal computing devices (computers, smartphones, tablets, etc.) are built with uniquely coded security hardware. It's almost like the uniqueness of a serial number, with the difference being that the unique coding is burned into the device's special-purpose hardware (usually a Trusted Platform Module or secure enclave).\nOnce a device-bound passkey is created with the support of such uniquely coded hardware, that exact hardware must also be present for the passkey to work as a login credential. If you create a device-bound passkey with your Mac, it only works with that Mac. With a PC, it only works with that PC. With an iPhone? You get the picture.\nAlso: I replaced my Microsoft account password with a passkey - and you should, too\nAlthough syncable passkeys must survive a stringent test, as described in this step-by-step walkthrough of what happens behind the scenes during a passkey authentication ceremony, a device-bound passkey raises the barrier to authentication. This approach assures you that, unless someone possesses both your passkey and the device that created it, and they have the biometric or PIN code to activate your security hardware, there is zero chance that someone other than you can use that passkey to log in to the relying party it's associated with.\nThis approach differs from a syncable passkey, which still works as intended, even when it is presented to a relying party from a system other than the one used to create it. This is not to say that syncable passkeys are somehow insecure and that they're easy for a threat actor to steal and use from a rogue system (or even your own device, if that device is stolen). However, it could be argued that, relatively speaking, they are less secure than device-bound passkeys. But they are also significantly less convenient.\nThe roaming device-bound passkey: The best of both worlds?\nJust because you need special hardware to create a device-bound passkey doesn't mean that that hardware must come in the form of a computing device with a TPM or secure enclave. Hardware could come in the form of a pocket-sized secure FIDO Alliance-compliant device that can be temporarily connected to your computer, smartphone, tablet, gaming console, and more.\nThese devices come in a variety of form factors, including USB keys and credit cards, and, when needed, can be connected to your device in several ways, including physical insertion or wirelessly via Near Field Communication (NFC) technology. Yubico's YubiKey 5C NFC, pictured in my palm below, is a good example of this technology. This device can be connected to your computer, smartphone, and more via USB-C or NFC.\nThese devices, more commonly referred to as roaming authenticators, include security hardware and cryptographic capabilities similar to those of TPMs and secure enclaves and, as such, can be used to create and securely store your various passkeys for the different relying parties that you rely on.\nLike all device-bound passkeys, when a passkey is created and stored on a roaming authenticator, it cannot be copied or synchronized to another device. When the time comes to authenticate with relying parties, you insert the device into the appropriate port (or connect wirelessly via NFC, similar to the way you tap a credit card terminal with your credit card) and supply a user-defined PIN code to authorize access to the appropriate passkey (for a given relying party).\nAlso: The best security keys of 2025: Expert tested\nThe big benefit of this approach is that the roaming authenticator and any device-bound passkeys stored on it can roam from device to device. For example, if you've saved your PayPal passkey on a YubiKey, you can use that passkey to log in to PayPal from your desktop computer, and then, at some other time, you can roam your YubiKey to your smartphone and log in to PayPal with that same passkey.\nIn this way, it's a tiny bit like syncing your PayPal passkey to both devices, because they both rely on the same passkey. However, unlike syncable passkeys, passkeys on roaming authenticators are never synchronized through a cloud, nor are they stored anywhere but on the original roaming authenticator that was used to create them. You just move them from device to device on an as-needed basis.\nAs a matter of personal choice, almost all of my passkeys are syncable passkeys. However, there are two or three highly sensitive passkeys -- including the passkey to my password manager -- that I keep on my roaming authenticator. I personally feel safer knowing the only way someone can log in to my password manager (where the majority of my passwords can be found) is if they possess my YubiKey and know my secret PIN to unlock it.\nAlso: Passkeys won't be ready for primetime until Google and other companies fix this\nThat said, roaming authenticators for some or all of your device-bound passkeys may not be a fit for everyone.\nFor starters, if any of your device-bound passkeys are required to authenticate with certain relying parties -- in other words, there's no way to log in without the passkey that's stored on your roaming authenticator -- your credential management strategy should include an additional one or two roaming authenticators as backups in case you lose your primary roamer.\nFor each passkey you keep on your primary roamer, you should register additional backup passkeys that get stored on each of your backup roamers (see my primer on how that enrollment process works). Since we're talking about device-bound passkeys, there's no way to copy a device-bound passkey from one roaming authenticator to another. When backing up passkeys using backup roaming authenticators, the only choice is to create new, unique device-bound passkeys for each one.\nAnother barrier to roaming authenticators is cost. For example, the least expensive option in Yubico's lineup of Yubikeys is the $25. Google's Titan starts at $30. In contrast to syncable passkeys, where you have free options, such as Google Password Manager, iCloud Keychain, and the personal edition of BitWarden, owning a minimum of two roaming authenticators for backup purposes involves costs that some people might not be willing to bear.\nAlso, it's not like you can move to a roaming authenticator as a total replacement for another credential/password management solution. While most roaming authenticators can handle device-bound passkeys, they are incapable of managing user IDs and passwords for the websites and apps that don't yet offer a passkey option for authentication.\nStay ahead of security news with Tech Today, delivered to your inbox every morning."
    },
    {
      "url": "https://states.aarp.org/maryland/celebrity-scams-in-the-age-of-ai",
      "text": "AARP Eye Center\nArtificial Intelligence (AI) is the new shiny object that has captured the world\u2019s attention. It\u2019s also captured the attention of criminal scammers who are using it to make their fraudulent schemes more realistic than ever. One area where AI scams are particularly dangerous is celebrity impostor scams.\nFor many years criminals have been impersonating celebrities online to steal from fans. Fake celebrity profiles offer fans personal connection, VIP access, investment opportunities or the chance to support favorite charities. These criminals attempt to create a bond through messaging or even a phone call from their \u201crep.\u201d\nWith the power of AI, these scams can move from messaging to deepfake videos. Recent fake celebrity product endorsements impersonating Selena Gomez, Dolly Parton, Elon Musk and Tom Hanks demonstrate just how convincing these schemes can be.\nPosting on a celebrity\u2019s social media account might be exciting, but it could put you at risk of this impostor scam. In whatever way you choose to enjoy your favorite celebs, do so recognizing that an opportunity to personally connect with them is likely a scam.\nBe a fraud fighter! If you can spot a scam, you can stop a scam.\nReport scams to local law enforcement. For help from AARP, call 1-877-908-3360 or visit the AARP Fraud Watch Network at www.aarp.org/fraudwatchnetwork."
    },
    {
      "url": "https://www.zdnet.com/article/7-ways-to-lock-down-your-phones-security-before-its-too-late/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\n7 ways to lock down your phone's security - before it's too late\nIn June 2017, as NotPetya malware ripped through Ukraine's business and government technology infrastructure, I reported from the capital, Kyiv, for ZDNET's then-sibling publication TechRepublic, moderating panel discussions about geopolitical cyber defense at the Global Cybersecurity Summit. The city was a charming, modern startup hub with innovative thinkers and smart technology.\nIt was also a hacker trap. The town itself was safe, but targeted with a blend of kinetic and digital attacks by hyper-polarized geopolitical actors. Key hacks included blackouts from power grid attacks in 2015 and 2016 and the NotPetya malware, which started in Ukraine and spread globally. Ukraine's State Treasury was also targeted, which infected military systems and disrupted government sites, especially during the 2022 invasion.\nAlso: Got a suspicious E-ZPass text? Don't click the link (and what to do if you already did)\nFrom taking notes to shooting video and audio, I needed my phone to report. Smartphones are essential tools; they're also security and privacy liabilities. In today's expanding surveillance and threat environment, which is full of opportunistic cyberattacks, corporate tracking, and invasive government scrutiny, locking down your phone is smart and often necessary. Below are the strategies that I employed and recommend to others.\nHow to lock down your phone's security\nWhether you're traveling internationally, attending a protest, attending DEF CON or just trying to keep private data away from tech giants and hackers, it's time to reassess how secure your phone really is.\n1. Assess your threat environment\nNot everyone faces the same level of risk. A traveling journalist, a political activist, and a casual user will have different threat models. Begin by identifying what you need to protect and who might be trying to access it.\nAlso: 5 warning signs that your phone's been hacked - and how to fight back\nAs the Electronic Frontier Foundation explains, your threat model should inform every security decision you make. Your device could be searched if you're crossing a border. Law enforcement might try to access your communications if you're attending a protest. Even if you're doing nothing wrong, the risk of exposure through routine corporate data collection is real.\nBefore implementing security measures, identify which threats are most relevant to your situation:\n- Government agencies have considerable legal powers to search devices, especially at borders. US Customs and Border Protection can conduct basic searches without suspicion, though deeper forensic searches may require reasonable suspicion of wrongdoing. According to the CBP's policies, they can examine and review device contents without using specialized equipment in basic searches, but require supervisor approval for advanced searches involving data copying.\n- Law enforcement capabilities vary widely. Some agencies use sophisticated tools from companies like Cellebrite that can extract data even from locked devices. These tools have become increasingly accessible to smaller departments and private entities.\n- Corporate adversaries might seek intellectual property or business intelligence. This threat grows when traveling to regions known for corporate espionage or when attending industry events.\n- Criminal actors target financial information, credentials, and personal data for fraud or extortion. Modern criminals employ increasingly sophisticated methods to extract valuable data from stolen devices.\n- Specific individuals seeking access to your data pose a personal threat. These cases often require specialized protection plans if the adversary knows your details or habits.\nUnderstanding your particular risks helps you prioritize appropriate protective measures. Implementing every possible security technique would make your device nearly unusable, so focus on measures that address your threats.\n2. Maintain a low profile\nWhile not a complete security strategy alone, maintaining a low profile provides a valuable first layer of defense. Take these steps:\n- Use a basic phone case. Device selection and appearance matters; choose a simple case without identifying stickers or affiliations. Consider using a device that doesn't immediately signal value or importance.\n- Keep devices secure. Your carry strategy should minimize visibility and accessibility. Keep devices in inner pockets or specialized anti-theft bags, particularly in high-risk areas.\n- Consider a decoy device. Using a \"clean\" secondary phone with minimal personal information for public use or border crossings can be an effective strategy for high-risk situations. Some security researchers recommend this approach for international travel, noting that you can often take your sim and buy a burner at your destination, depending on your destination.\n- Minimize attention-drawing behavior in public spaces. Use privacy screens to prevent shoulder surfing and avoid accessing sensitive accounts on public networks without protection.\n- Be alert to social engineering attempts from individuals who may approach with seemingly innocent requests to borrow your phone. These interactions can serve as pretexts for theft or installing malicious software.\nThese precautions might seem excessive for everyday situations but become crucial safeguards when operating in high-risk environments or when targeted surveillance is possible.\n3. Clean up your phone\nPractice regular digital hygiene to minimize vulnerability if your device is accessed.\nFor example. audit and remove unnecessary apps regularly, especially those with access to sensitive data. The Electronic Frontier Foundation advises deleting sensitive photos, messages, and emails that aren't necessary before entering high-risk situations.\nYou should also implement data minimization principles. Store only what you need on your device, and transfer sensitive files to encrypted storage before removing them from your phone.\nAlso: 10 passkey survival tips: Prepare for a passwordless future now\nReview authentication methods for your most critical applications, as well.\nWhile biometric access (fingerprint/face unlock) is convenient, it can be used to access your phone without your consent. In fraught situations, disable biometrics and rely on strong passwords that cannot be physically compelled from you. This is particularly important when crossing borders; as a recent AP News report noted, \"a border agent could simply hold your phone up to your face or force you to press your finger onto your device.\"\nYou also need to clear browser data regularly, including history, cookies, and cached data. I suggest using private browsing mode when accessing sensitive information.\nAnother measure you can take is to enable app-level security features where available, including PIN locks, automatic logout timers, and encrypted storage options. You should audit your cloud synchronization settings, too. Many apps silently upload data to cloud services. Review what information your device backs up automatically and disable synchronization for sensitive content.\nFinally, develop a pre-travel checklist if you move between security environments regularly. Include steps like logging out of accounts, disconnecting from cloud services, and enabling airplane mode in sensitive locations.\n4. Clean up your social media presence\nYour online footprint can compromise your security even if your device is properly protected. Here's how to improve it:\n- Conduct privacy audits across all platforms. Review and restrict visibility settings for posts, photos, friends lists, and personal information.\n- Address historical content vulnerabilities. Use platform tools to delete or archive old posts containing sensitive information, location patterns, or personal details.\n- Remove metadata from photos and videos before sharing. Most digital images contain EXIF data with precise location coordinates and device information.\n- Control facial recognition and tagging settings. Configure platforms to require your approval before others can tag you in content.\n- Audit connected applications that have access to your social accounts. Third-party apps you authorized years ago may retain access to your data.\n- Implement strong authentication on all accounts. Use two-factor authentication with authenticator apps rather than SMS, and employ unique passwords for each platform.\n- Consider strategic deactivation during high-risk periods. Most platforms allow temporary deactivation without permanent account deletion.\n- Evaluate messaging security on social platforms. Standard social media direct messages rarely offer end-to-end encryption by default. Migrate sensitive conversations to secure messaging applications.\n5. Minimize your digital baggage\nWhen you travel, you pack light -- the same logic should apply to your phone. Log out of unnecessary accounts, delete sensitive files, and avoid syncing full cloud backups. Consider using a \"travel phone, \" a secondary device with only essential apps and data.\nIt's also wise to remove saved Wi-Fi networks and Bluetooth pairings. Uninstall browser extensions and disable auto-downloads. You can't lose what you don't carry. CNET advises removing yourself from data brokers to minimize your digital footprint further.\n6. Use secure communication apps\nRegular text messaging is not encrypted. Instead, use end-to-end encryption apps to protect your calls, messages, and metadata.\nAlso: 5 tools I trust to keep my online conversations private and anonymous\nSignal offers secure, open-source messaging and calling. It's trusted by journalists, researchers, and activists worldwide. Matrix (via Element) is a decentralized protocol for secure messaging. It's useful for group chats and can be self-hosted for maximum control. Proton is a suite of privacy tools including encrypted email, calendar, file storage, and VPN -- all designed for strong user privacy.\n7. Use Advanced Data Protection\nApple and Google have taken markedly different -- but, interestingly, increasingly aligned -- approaches to end-to-end encryption with their Advanced Data Protection features.\nApple's Advanced Data Protection, introduced for iCloud, expands encryption to nearly all categories of user data, including device backups, Messages in iCloud, and Photos, ensuring only the user holds the decryption keys. Google's similar feature for Android and Google One backups also enables client-side encryption, meaning not even Google can access user content stored in the cloud.\nAlso: Why rebooting your phone daily is your best defense against zero-click attacks\nWhile the implementations differ under the hood, the direction is clear: Both tech giants are moving toward a future where users, not companies, control access to their most sensitive digital information. This shift, while a win for privacy, raises tough questions about lawful access and the balance between user security and public safety.\nThe techniques in this guide create layered defenses that significantly increase how hard it is for unauthorized actors to access your digital life. But this is not comprehensive \u2013 remember, security exists on a spectrum! Implement protections that work best with your life and fit your specific threat model.\nFor most people, basic stuff like strong passwords, careful app management, and thoughtful social media practices are good digital hygiene. Those facing higher risks need to implement more comprehensive strategies, and of course, it's important to remain flexible and curious.\nAlso: How Apple plans to train its AI on your data without sacrificing your privacy\nThis is an important and dynamic topic. We'd love to hear from you! What works and what should we avoid? Share your security and privacy tips, tricks, and hacks.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://copyleaks.com/",
      "text": "From Fortune 500 companies to the world\u2019s top universities, our AI-powered content analysis platform protects intellectual property, governs AI use, and sets the standard for responsible AI adoption.\nLevel up and automate your organization\u2019s content and GenAI strategy with our fully scalable, flexible, and customizable API integrations.\nEffortlessly ensure academic integrity and safe AI use for learning within your LMS platform.\nAre you a student?\nOver 99% accuracy*, verified through rigorous testing methodologies. Trusted globally to detect AI across 30+ languages and leading LLMs like ChatGPT, Gemini, DeepSeek, and Claude.\nThe most accurate AI detector on the market, verified by multiple independent third party studies.\nAI detection covering ChatGPT, Gemini, Deepseek and Claude. Plus, newer models as they are released.\nSupports over 30+ languages, including Spanish, Japanese, French, German, Chinese, and Hindi, with more in development.\nCatch hidden plagiarism techniques like paraphrasing, character manipulation, and more.\nSearch the world\u2019s largest database of websites, journals, academic papers, and more.\nDetect plagiarism in 100+ languages, from English and Spanish to Chinese and Hindi.\nA seamless AI solution delivering content integrity and transparency for individuals and businesses.\nWith PCI DSS, SOC 2, SOC 3, and GDPR certifications, Copyleaks ensures your data is always safe and protected.\nExplore expert insights, original research, and real-world use cases on AI, content integrity, and ethical innovation.\nIndependent third-party research continues to confirm the Copyleaks AI Detector as one of the most accurate solutions available.\nJul 8, 2025\nMany of our clients have expressed concerns about the use of AI for content generation, particularly in the higher education space. Our partnership with Copyleaks will make it simple for Moodle administrators and instructors to detect AI-generated content in order to encourage thoughtful, original content that shows subject mastery.\nSee why our customers consistently recommend our AI detection and content plagiarism tools.\nIn the age of generative AI, content integrity isn\u2019t a nice-to-have. It\u2019s essential. It means protecting all forms of digital content\u2014text, code, intellectual property (IP)\u2014 from alteration, duplication, plagiarism, and unauthorized AI manipulation. At its core, it\u2019s about ensuring your work stays original, accurate, and proprietary.\nSince 2015, Copyleaks has been a trusted leader in maintaining content integrity. What began as a mission to help organizations detect plagiarism has evolved into a comprehensive platform of AI detection and compliance tools for today\u2019s most critical use cases.\nNow, with AI reshaping how content is created and shared, we\u2019re helping enterprises and educators stay one step ahead. Designed to support content integrity across all business sectors, our enterprise solutions can help support academic integrity, AI model training, IP and copyright compliance, GenAI governance, code governance, unauthorized LLM usage, and more.\nIn addition to our enterprise-grade solutions, we offer free, AI-powered tools for individuals, including our award-winning AI Detector and Plagiarism Checker, making content integrity accessible to everyone.\nWhether you\u2019re a student writing a term paper or a Fortune 500 chief information officer navigating AI\u2019s impact on your organization, Copyleaks has a solution for you.\nAll rights reserved. Use of this website signifies your agreement to the Terms of Use."
    },
    {
      "url": "https://www.theguardian.com/us-news/article/2024/jun/20/fake-news-websites-us-election",
      "text": "Political groups on the right and left are using fake news websites designed to look like reliable sources of information to fill the void left by the demise of local newspapers, raising fears of the impact that they might have during the United States\u2019 bitterly fought 2024 election.\nSome media experts are concerned that the so-called pink slime websites, often funded domestically, could prove at least as harmful to political discourse and voters\u2019 faith in media and democracy as foreign disinformation efforts in the 2016 and 2020 presidential elections.\nAccording to a recent report from NewsGuard, a company that aims to counter misinformation by studying and rating news websites, the websites are so prolific that \u201cthe odds are now better than 50-50 that if you see a news website purporting to cover local news, it\u2019s fake.\u201d\nNewsGuard estimates that there are a staggering 1,265 such fake local news websites in the US \u2013 4% more than the websites of 1,213 daily newspapers left operating in the country.\n\u201cActors on both sides of the political spectrum\u201d feel \u201cthat what they are doing isn\u2019t bad because all media is really biased against their side or that that they know actors on the other side are using these tactics and so they feel they need to,\u201d said Matt Skibinski, general manager of NewsGuard, which determined that such sites now outnumber legitimate local news organizations. \u201cIt\u2019s definitely contributed to partisanship and the erosion of trust in media; it\u2019s also a symptom of those things.\u201d\nPink slime websites, named after a meat byproduct, started at least as early as 2004 when Brian Timpone, a former television reporter who described himself as a \u201cbiased guy\u201d and a Republican, started funding websites featuring names of cities, towns and regions like the Philly Leader and the South Alabama Times.\nTimpone\u2019s company, Metric Media, now operates more than 1,000 such websites and his private equity company receives funding from conservative political action committees, according to NewsGuard.\nThe Leader recently ran a story with the headline, \u201cRep Evans votes to count illegal aliens towards seats in Congress.\u201d\nIn actuality, Representative Dwight Evans, a Democrat, did not vote to start counting undocumented immigrants in the 2030 census but rather against legislation that would have changed the way the country has conducted apportionment since 1790.\nThat sort of story is \u201cstandard practice for these outlets\u201d, according to Tim Franklin, who leads Northwestern University\u2019s Local News Initiative, which researches the industry.\n\u201cThey will take something that maybe has just a morsel of truth to it and then twist it with their own partisan or ideological spin,\u201d Franklin said. \u201cThey also tend to do it on issues like immigration or hot-button topics that they think will elicit an emotional response.\u201d\nA story published this month on the NW Arkansas News site had a headline on the front page that reported that the unemployment rate in 2021 in Madison county was 5.1% \u2013 even though there is much more recent data available. In April 2024, the local unemployment rate was 2.5%.\n\u201cAnother tactic that we have seen across many of this category of sites is taking a news story that happened at some point and presenting it as if it just happened now, in a way that is misleading,\u201d Skibinski said.\nThe left has also created websites designed to look like legitimate news organizations but actually shaped by Democratic supporters.\nThe liberal Courier Newsroom network operates websites in Arizona, Florida, Iowa, Michigan and Nevada, among other states, that \u2013 like the conservative pink slime sites \u2013 have innocuous sounding names like the Copper Courier and Up North News. The Courier has runs stories like \u201cGov Ducey Is Now the Most Unpopular Governor in America,\u201d referring to Doug Ducy, the former Republican Arizona governor.\n\u201cIn contrast, coverage of Democrats, including US President Joe Biden, Democratic Arizona Gov Katie Hobbs, and US Sen Mark Kelly of Arizona, is nearly always laudatory,\u201d NewsGuard stated in a report about Courier coverage.\nTara McGowan, a Democratic strategist who founded the Courier Newsroom has received funding from liberal donors like Reid Hoffman and George Soros, as well as groups associated with political action committees, according to NewsGuard.\n\u201cThere are pink slime operations on both the right and the left. To me, the key is disclosure and transparency about ownership,\u201d said Franklin.\nIn a statement, a spokesperson for the Courier said comparisons between its operations and rightwing pink slime groups were unfair and criticized NewsGuard\u2019s methodology in comparing the two.\n\u201cCourier publishes award-winning, factual local news by talented journalists who live in the communities we cover, and our reporting is often cited by legacy media outlets. This is in stark contrast to the pink slime networks that pretend to have a local presence but crank out low-quality fake news with no bylines and no accountability. Courier is proudly transparent about our pro-democracy values, and we carry on the respected American tradition of advocacy journalism,\u201d the spokesperson said.\nWhile both the left and the right have invested in the pink slime websites, there are differences in the owners\u2019 approaches, according to Skibinski.\nThe right-wing networks have created more sites \u201cthat are probably getting less attention per site, and on the left, there is a smaller number of sites, but they are more strategic about getting attention to those sites on Facebook and elsewhere\u201d, Skibinski said. \u201cI don\u2019t know that we can quantify whether one is more impactful than the other.\u201d\nArtificial intelligence could also help site operators quickly generate stories and create fake images.\n\u201cThe technology underlying artificial intelligence is now becoming more accessible to malign actors,\u201d said Kathleen Hall Jamieson, a University of Pennsylvania communications professor and director of the Annenberg Public Policy Center, which publishes Factcheck.org. \u201cThe capacity to create false images is very high, but also there is a capacity to detect the images that is emerging very rapidly. The question is, will it emerge rapidly with enough capacity?\u201d\nStill, it\u2019s not clear whether these websites are effective. Stanford University reported in a 2023 study that engagement with pink slime websites was \u201crelatively low\u201d and little evidence that living \u201cin a news desert made people more likely to consume pink slime\u201d.\nThe Philly Leader and the NW Arkansas News both only have links to Facebook accounts on their websites and have less than 450 followers on each. Meanwhile, the Copper Courier and Up North News have accounts on all the major platforms and a total of about 150,000 followers on Facebook.\nFranklin said he thinks that a lot of people don\u2019t actually click links on social media posts to visit the website.\n\u201cThe goal of some of these operators is not to get traffic directly to their site, but it\u2019s to go viral on social media,\u201d he said.\nRepublican lawmakers and leaders of the conservative news sites the Daily Wire and the Federalist have also filed a lawsuit and launched investigations accusing NewsGuard of helping the federal government censor right-leaning media. The defense department hired the company strictly to counter \u201cdisinformation efforts by Russian, Chinese and Iranian government-linked operations targeting Americans and our allies\u201d, Gordon Crovitz, the former Wall Street Journal publisher who co-founded NewsGuard, told the Hill in response to a House oversight committee investigation. \u201cWe look forward to clarifying the misunderstanding by the committee about our work for the Defense Department.\u201d\nTo counter the flood of misinformation, social media companies must take a more active role in monitoring such content, according to Franklin and Skibinski.\n\u201cThe biggest solution to this kind of site would be for the social media platforms to take more responsibility in terms of showing context to the user about sources that could be their own context. It could be data from third parties, like what we do,\u201d said Skibinski.\nFranklin would like to see a national media literacy campaign. States around the country have passed laws requiring such education in schools.\nFranklin also hopes that legitimate local news could rebound. The MacArthur Foundation and other donors last year pledged $500m to help local outlets.\n\u201cI actually have more optimism now than I had a few years ago,\u201d Franklin said. \u201cWe\u2019re in the midst of historic changes in how people consume news and how it\u2019s produced and how it\u2019s distributed and how it\u2019s paid for, but I think there\u2019s still demand for local news, and that\u2019s kind of where it all starts.\u201d"
    },
    {
      "url": "https://www.bellingcat.com/resources/2024/09/24/bellingcat-online-investigations-toolkit/",
      "text": "Find the Right Open Source Research Tools With Bellingcat\u2019s New Online Investigations Toolkit\nHave you ever struggled to find a tool that does exactly what you need? Do you know the feeling of spending hours trying to figure out how to use a tool just to realise that the key features you are interested in are not working anymore, or that the previously free product has turned into a paid one that is more expensive than you can afford?\nYou are not alone. More than 80 percent of open source researchers that participated in two Bellingcat surveys indicated that finding the right tools can be challenging.\nThis is where our new Online Investigations Toolkit comes in: it not only helps you discover tools in categories like satellite imagery and maps, social media, transportation or archiving, but is also designed to help researchers learn how to use each tool by providing in-depth descriptions, common use cases and information on requirements and limitations for each toolkit entry.\nMost of the tools included can be used for free.\nThis is the first time in Bellingcat\u2019s 10-year history that we are opening our toolkit to contributions from the wider open source researcher community. A dedicated group of volunteers, our Toolkit Maintainers and Guardians, help us keep this toolkit up to date and are involved in further improving it. Since it is still a work-in-progress, we expect the number of tools in the toolkit to grow over time.\nWhere Open Source Researchers Search For Tools\nOpen source researchers frequently use tools, from satellite imagery and flight tracking websites to online business registries and social media scraping services, in their work. Some of these are created by big tech companies, while others are built and shared by volunteers. They might come in the form of desktop tools, command line tools on code sharing platforms like GitHub, or browser extensions.\nSupport Bellingcat\nYour donations directly contribute to our ability to publish groundbreaking investigations and uncover wrongdoing around the world.\nThis fragmented tool environment can be confusing, making it difficult or time-consuming for researchers to figure out which tools to use. In a survey conducted by Bellingcat in 2023, only 15 percent of 153 participants indicated that it was easy for them to find the right tools for their research. A previous Bellingcat survey from 2022 with more than 500 participants yielded very similar results. This is despite the fact that there was a long list of toolkits for open source researchers out there at that point in time, including the previous version of our toolkit, which was available on Google Sheets.\nAccording to Bellingcat\u2019s surveys, most open source researchers use search engines to find tools. Other top methods include going through websites and blogs that present tools and reading the publications of other researchers to see what tools they use.\nTo get a deeper understanding about how researchers find and use tools, we interviewed 40 open source researchers from various countries, levels of experience and backgrounds. What we learned from those interviews is that what most open source researchers most frequently do is not necessarily what works best for them.\nFor instance, despite search engines being the top destination for researchers in need of tools, this method does not always lead to the desired results. Our interviewees indicated that it could be difficult to come up with the right keywords: \u201cYou sort of know intuitively that certain tools must exist, but you don\u2019t quite know what words to go by. So there\u2019s a lot of feeling around in the dark for search terms to try and find tools that work,\u201d one person explained.\nEven if researchers manage to define the right keywords, they struggle to get a sense of whether a tool showing up in the search results might meet their needs. Since tool providers tend to present their tools in an overly positive light, it is often difficult for researchers to understand a tool\u2019s limitations based on the descriptions.\nFrom our interviews and surveys, direct tool recommendations from others in the industry are an important way that researchers make sense of the diverse tools available online. \u201cIn my network, I know a lot of journalists who do this kind of OSINT (open source intelligence) work,\u201d one interviewee explained. \u201cJust through word of mouth, I\u2019m able to get recommendations for what the most up-to-date tools are.\u201d\nOther interviewees indicated that they turned to websites, blogs and newsletters to get recommendations for tools. \u201cIf someone has used a tool and there\u2019s a blog out there that tells me how to use it, then I will try it,\u201d one open source researcher said.\nNo matter where they find tools for their research, many researchers said they struggled with keeping track of tools that might come in handy later on. \u201cSometimes I feel like \u2018Oh, that might be an interesting one\u2019, but I don\u2019t use it now and when I need to find it, I just really don\u2019t remember,\u201d one interviewee said.\nToolkits are meant to be a solution to this. They are usually organised according to different tool categories and curated by a person or organisation hoping to provide some structure within the open source research tool environment.\nGoogling keywords like \u201cOSINT\u201d and \u201ctoolkit\u201d brings up a long list of toolkits that are all available for free. However, barely any of the open source researchers that we interviewed said toolkits were their preferred way of (re)discovering tools while doing research.\nA Toolkit Wishlist\nThe number one reason our interviewees said they did not use toolkits often was that they felt most of these are not kept up to date on a regular basis.\nEight out of our 40 interviewees suggested adopting a collaborative approach to keep toolkits relevant, and therefore useful, for researchers. One open source researcher said that in her view, if any one individual was in charge of keeping a toolkit regularly updated they would \u201cprobably go insane\u201d doing it, so \u201chaving the courage to let people own different bits of it\u201d would be the only feasible way, she said.\nAnother popular request by open source researchers was to include or link to guides that explain how to use each tool. \u201cIf you are developing a toolkit, then I would personally expect to have some kind of explanation on how to use it,\u201d one of our interviewees said. Many toolkits, however, do not focus on providing or listing guides and are therefore only of limited use for open source researchers.\nIn addition, some researchers expressed the importance of receiving clear information on the limitations of each tool and the costs, if any. \u201cI prefer accessibility and open source tools, but for sure, if a paid example exists, I like to know that it exists. I just like that to be really clearly marked,\u201d one interviewee explained. Another person considered it as important to see right away whether a tool has \u201ca thousand dollar license that\u2019s unsustainable for small organisations\u201d.\nThere are open source researchers all around the world who speak a wide range of languages, so several of our interviewees pointed out that toolkits should not only take the needs of researchers in English-speaking and Western countries into account. \u201cExpansion to cover more non-Western social media platforms is always appreciated,\u201d one interviewee said. Some of our interviewees suggested offering sub-categories with tools for specific regions or countries.\nFinally, our interviewees said it would be good to receive guidance on choosing the right tools from within a toolkit. Thirteen out of our 40 interviewees were enthusiastic about the idea of an AI assistant that would either ask them guiding questions or allow them to type in questions or pieces of information they already have for it to provide specific tool suggestions based on this input.\nUsing Bellingcat\u2019s Collaborative Toolkit\nBased on these learnings, we designed a completely new version of Bellingcat\u2019s Online Investigation Toolkit. It is still a work in progress and we expect to expand it over time with the help of the wider open source researcher community.\nIf you click on a specific category, for instance \u201cMaps & Satellites\u201d \u2192 \u201cMaps\u201d you will see all available tools listed in alphabetical order. You also see a short tool description and information on whether the tool is paid or can be used for free. Tools that have some free and some paid features are marked as \u201cpartially free\u201d.\nOn the right hand side, you see a column called \u201cDetails\u201d. Click on \u201cDetails\u201d next to your tool of interest (if available) and you will be brought to the section into which we have invested most of our efforts: an in-depth description of the respective tool with tips and tricks on how to use it.\nThe tool descriptions are written by our volunteer community, Bellingcat staff and members of the wider open source researcher community. They each have individual styles and lengths but all follow the following structure:\n| URL: | The URL to the tool |\n| Description: | A full description of the tool including the answer to the question: what problem does it solve? |\n| Cost: | Is the tool free, partially free or paid? |\n| Level of difficulty: | How difficult is it to learn how to use the tool? |\n| Requirements: | Are there any requirements for using the tool? |\n| Limitations: | What limitations does the tool have? |\n| Ethical Considerations: | What ethical considerations might be relevant when using the tool? |\n| Guides and Articles: | Links to guides on how to use the tools or links to research that was done with this tool. |\nWe developed this structure based on the priorities that were expressed during our interviews with open source researchers. It aims to cover the aspects most relevant for researchers when making a decision on whether they want to use a tool for a specific research task.\nOur toolkit also includes a natural language search interface powered by OpenAI. To use it, just type in a question in the search box on the upper right corner of the screen and see what you get. For example, this is what it told us when we asked for the best tools for beginners:\nThe natural language search can also suggest tools for very specific tasks. Here is an example:\nYou can even try to use it to get step-by-step instructions for specific research tasks:\nPlease be aware that the answers are based on the tool descriptions in our toolkit and the quality of the answers heavily depends on whether an answer to the question you are typing in is represented in the toolkit. We expect that the number of tool descriptions, and therefore the available information in the toolkit, will grow over time.\nHow You Can Contribute\nBellingcat\u2019s new Online Investigations toolkit is collaborative. We aim to create a resource that brings together the joint wisdom of the open source researcher community to make the task of finding tools less daunting for everyone.\nThe backbone of our toolkit is a select group of Bellingcat volunteers, who fall into two major groups. Our Toolkit Maintainers write and maintain tool descriptions and if one of \u201ctheir\u201d tools stops working or is adding a new feature, they are responsible for adding these updates. Our Toolkit Guardians take on even more responsibilities, keeping an eye on a whole category of tools and supporting us in defining the future development of the toolkit to make sure it meets the needs of open source researchers.\nWe welcome contributions from the wider open source researcher community as well. If you would like to contribute, there are several ways:\n- Provide feedback on our toolkit. This helps us gain new ideas on how we can make this toolkit even better.\n- If you feel that a specific tool is missing, you can submit a description of it via this form. We cannot guarantee that we will include it in the toolkit, but we promise that we seriously consider every suggestion.\n- If you are representing a newsroom, a university or an independent research organisation and would like to contribute to this toolkit, feel free to get in touch via toolkit@bellingcat.com.\n- You can also apply to join Bellingcat\u2019s Volunteer Community. If selected, you will be able to contribute to this and many other projects as part of an active group of open source research enthusiasts.\nBellingcat\u2019s new Online Investigations Toolkit was developed by Johanna Wild during her 2024 Nieman-Berkman Klein Fellowship in Journalism Innovation at Harvard University. Cooper-Morgan Bryant, a student research assistant (Harvard), contributed to the user research. Viktorija Ignataviciute and Galen Reich contributed to defining the volunteer involvement, with Viktorija Ignataviciute also supporting the toolkit volunteer community on an ongoing basis.\nBellingcat is a non-profit and the ability to carry out our work is dependent on the kind support of individual donors. If you would like to support our work, you can do so here. You can also subscribe to our Patreon channel here. Subscribe to our Newsletter and follow us on Twitter here and Mastodon here."
    },
    {
      "url": "https://threatpost.com/hackers-using-automation-geolocation-social-networking-attacks-020110/73458/",
      "text": "MOSCOW \u2014 Attackers have been focusing a lot of attention on social networking destinations such as Facebook, Twitter and even LinkedIn for some time now, but they recently have begun shifting their tactics to make their attacks much more effective and precise through the use of geolocation and profiling.\nLike attacks on other platforms such as email and IM, the first couple generations of attacks on social networking sites used a shotgun approach that relied on targeting a huge number of users and hoping that a small percentage of them would fall for the attack. The Koobface worm, Twitter spam and porn bots all relied on this tactic, and with pretty good results. Koobface\u2019s various iterations have infected millions of Facebook users, and there have been a couple of fairly effective phishing campaigns on Twitter.\nBut users have been quick to catch on to those techniques, and attackers have begun to fine tune their tactics to make their attacks much more focused and effective, experts say. The most effective of these right now is the use of geolocation and profiling of users.\n\u201cWe have really started to see a lot of attackers using geolocation for targeted attacks on social networking sites to better craft the social engineering story,\u201d Stefan Tanase, senior regional researcher on Kasperky Lab\u2019s Global Research & Analysis Team, said in a talk at the company\u2019s international press briefings here. \u201cThey\u2019re using language targeting and looking at profiles and interests to make it work.\u201d\nThere has been a major increase in the volume of malware targeting social networking sites in the last year. As more and more users have flocked to Twitter and other such sites, the number of pieces of malware targeting these users has grown from fewer than 30,000 in 2008 to more than 60,000 in 2009, Tanase said.\nThe nature of sites such as Twitter and Facebook, where users post intimate details of their lives, including hobbies, job information, birthdays, etc., makes these attacks easy to implement. Attackers can sift through users\u2019 profiles, looking for specific interests, information on where they live and what they do in their spare time. They can then use that data to target tailored phishing and drive-by attacks to a small group of users in a specific city.\nTanase showed an example of a phishing campaign that used a fake Reuters site that had a news article purporting to be about a bomb blast in Bangalore. However, as users hit the site, if they came from other locations, the headline of the story could be changed to Moscow, Berlin, Chicago or whatever location matched the user\u2019s IP address.\nAdvertisers have been using similar techniques to target their messages to local users on news sites, Facebook and elsewhere, and it\u2019s turned out to be a very effective tactic. And if it works for legitimate advertisers, there\u2019s no reason to think the attackers won\u2019t see the same results, Tanase said.\n\u201cIf the advertisers are doing it, and it\u2019s working, there\u2019s no reason the bad guys won\u2019t,\u201d he said. \u201cThey\u2019re now automating the targeted attacks. That\u2019s a dangerous thing. The complexity of these attacks will get bigger and bigger and the social engineering attacks are getting more complicated.\u201d"
    },
    {
      "url": "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
      "text": "Coding with AI? My top 5 tips for vetting its output - and staying out of trouble\nOur story begins, as many stories do, with a man and his AI. The man, like many men, is a bit of a geek and a bit of a programmer. He also needs a haircut.\nThe AI is the culmination of thousands of years of human advancement, all put to the service of making the man's life a little easier. The man, of course, is me. I'm that guy.\nAlso: The best AI for coding in 2025 (and what not to use)\nUnfortunately, while AI can be incredibly brilliant, it also has a propensity to lie, mislead, and make shockingly stupid mistakes. It is the stupid part that we will be discussing in this article.\nAnecdotal evidence does have value. My reports on how I've solved some problems quickly with AI are real. The programs I used AI to write with are still in use. I have used AI to help speed up aspects of my programming flow, especially when I focus on the sweet spots where I'm less productive and the AI is quite knowledgeable, like writing functions that call publicly published APIs.\nAlso: I'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nYou know how we got here. Generative AI burst onto the scene at the cusp of 2023 and has been blasting its way into knowledge work ever since.\nOne area, as the narrative goes, where AI truly shines is its ability to write code and help manage IT systems. Those claims are not untrue. I have shown, several times, how AI has solved coding and systems engineering problems I have personally experienced.\nAI coding in the real world: What science reveals\nNew tools always come with big promises. But do they deliver in real-world settings?\nMost of my reporting on programming effectiveness has been based on personal anecdotal evidence: my own programming experiences using AI. But I'm one guy. I have limited time to devote to programming and, like every programmer, I have certain areas where I spend most of my coding time.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nRecently, though, a nonprofit research organization called METR (Model Evaluation & Threat Research) did a more thorough analysis of AI coding productivity.\nTheir methodology seems sound. They worked with 16 experienced open-source developers who have actively contributed to large, popular repositories. The METR analysts provided those developers with 246 issues from the repositories that needed fixing. The coders were given about half the issues where they had to work on their own, and about half where they could use an AI for help.\nThe results were striking and unexpected. While the developers themselves estimated that AI assistance increased their productivity by an average of 24%, METR's analytics showed instead that AI assistance slowed them down by an average of 19%.\nThat's a bit of a head-scratcher. METR put together a list of factors that might explain the slowdown, including over-optimism about AI usefulness, high-developer familiarity with their repositories (and less AI knowledge), the complexity of large repositories, lack of AI reliability, and an ongoing problem where the AI refuses to use \"important tacit knowledge or context.\"\nAlso: How AI coding agents could destroy open-source software\nI would suggest that two other factors might have limited effectiveness:\nChoice of problem: The developers were told which issues they had to use AI help on and which issues they couldn't. My experience suggests knowledgeable developers must choose where to use AI based on the problem that needs to be solved. In my case, for example, getting the AI to write a regular expression (something I don't like doing and I'm fairly crappy at) would save me a lot more time than getting the AI to modify unique code I've already written, work on regularly, and know inside and out.\nChoice of AI: According to the report, the developers used Cursor, an AI-centric fork of VS Code, which used Claude 3.5/3.7 Sonnet at the time. When I tested 3.5 Sonnet, the results were terrible, with Sonnet failing three out of four of my tests. Subsequently, my tests of Claude 4 Sonnet were considerably better. METR reported that developers rejected more than 65% of the code the AI generated. That's going to take time.\nThat time when ChatGPT suggested nuking my system\nMETRs results are interesting. AI is clearly a double-edged sword when it comes to coding help. But there's also no doubt that AI can provide considerable value to coders. If anything, I think this test once again proves the contention that AI is a great tool for experienced programmers, but a potential high-risk resource for newbies.\nAlso: Why I'm switching to VS Code. Hint: It's all about AI tool integration\nLet's look at a concrete example, one that could have cost me a lot of time and trouble if I followed ChatGPT's advice.\nI was setting up a Docker container on my home lab using Portainer (a tool that helps manage Docker containers). For some reason, Portainer would not enable the Deploy button to create the container.\nIt had been a long day, so I didn't see the obvious problem. Instead, I asked ChatGPT. I fed ChatGPT screenshots of the configuration, as well as my Docker configuration file.\nChatGPT recommended that I uninstall and reinstall Portainer. It also suggested I remove Docker from the Linux distro and use the package manager to reinstall it. These actions would have had the effect of killing all my containers.\nOf note, ChatGPT didn't recommend or ask if I had backups of the containers. It just gave me the command line sequences it recommended I cut and paste to delete and rebuild Portainer and Docker. It was a wildly destructive and irresponsible recommendation.\nThe irony is that ChatGPT never figured out why Portainer wouldn't let me deploy the new container, but I did. It turns out I never filled out the container's name field. That's it.\nAlso: What is AI vibe coding? It's all the rage but it's not for everyone - here's why\nBecause I'm fairly experienced, I hesitated when ChatGPT told me to nuke my installation. However, someone relying on the AI for advice could have potentially brought down an entire server for want of typing in a container name.\nOverconfident and underinformed AIs: A dangerous combo\nI've also experienced the AI going completely off the rails. I've experienced it giving advice that was not only completely useless, but also presented with the apparent confidence of an expert.\nAlso: Google's Jules AI coding agent built a new feature I could actually ship - while I made coffee\nIf you're going to use AI tools to support your development or IT work, these tips might keep you out of trouble:\n- If there's not much publicly available information, the AI can't help. But the AI will make stuff up based on what little it knows, without admitting that it is lacking experience.\n- Like my dog, once the AI gets fixated on one thing, it often refuses to look at alternatives. If the AI is stuck on one approach, don't make the mistake of believing that its polite recommendations about a new approach are real. It's still going down the same rabbit hole. Start a new session.\n- If you don't know a lot, don't rely on the AI. Keep up your learning. Experienced devs can tell the difference between what will work and what won't. But if you're trying to put all the coding on the back of the AI, you won't know when or where it goes wrong or how to fix it.\n- Coders often use specific tools for specific tasks. A website might be built using Python, CSS, HTML, JavaScript, Flask, and Jinja. You choose each tool because you know what it does well. Choose your AI tools the same way. For example, I don't use AI for business logic, but I gain productivity using AI to write API calls and public knowledge, where it can save me a lot of time.\n- Test everything an AI produces. Everything. Line by individual line. The AI can save a ton of time, but it can also make enormous mistakes. Yes, taking the time and energy to test by hand can help prevent errors. If the AI offers to write unit tests, let it. But test the tests.\nBased on your experience level, here's how I recommend you think about AI assistance:\n- If you know nothing about a subject or skill: AI can help you pass as if you do, but it could be amazingly wrong, and you might not know.\n- If you're an expert in a subject or skill: AI can help, but it will piss you off. Your expertise gets used not only to separate the AI-stupid from the AI-useful, but to carefully craft a path where AI can actually help.\n- If you're in between: AI is a mixed bag. It could help you or get you in trouble. Don't delegate your skill-building to the AI because it could leave you behind.\nAlso: How I used ChatGPT to analyze, debug, and rewrite a broken plugin from scratch - in an hour\nGenerative AI can be an excellent helper for experienced developers and IT pros, especially when used for targeted, well-understood tasks. But its confidence can be deceptive and dangerous.\nAI can be useful, but always double-check its work.\nHave you used AI tools like ChatGPT or Claude to help with your development or IT work? Did they speed things up, or nearly blow things up? Are you more confident or more cautious when using AI on critical systems? Have you found specific use cases where AI really shines, or where it fails hilariously? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/gpt-5-bombed-my-coding-tests-but-redeemed-itself-with-code-analysis/",
      "text": "GPT-5 bombed my coding tests, but redeemed itself with code analysis\nZDNET's key takeaways\n- GPT-5 Pro delivers the sharpest, most actionable code analysis.\n- A detail-focused prompt can push base GPT-5 toward Pro results.\n- o3 remains a strong contender despite being a GPT-4 variant.\nWith the big news that OpenAI has released GPT-5, the team here at ZDNET is working to learn about and communicate its strengths and weaknesses. In another article, I put its programming prowess to the test and came up with a less-than-impressive result.\nAlso: I tested GPT-5's coding skills, and it was so bad that I'm sticking with GPT-4o\nWhen Deep Research first appeared with the OpenAI o3 LLM, I was quite impressed with what it could understand from examining a code repository. I wanted to know how well it understood the project just from the available code.\nIn this article, I'm examining how well the three GPT-5 variants do in examining that same code repository. We'll dig in and compare them. The results are quite interesting. Here are the four models.\n- o3: a GPT-4 variant optimized for reasoning.\n- GPT-5: OpenAI's new main ChatGPT model, available to all tiers, including free.\n- GPT-5 Thinking: A variant of GPT-5 that OpenAI says is optimized for \"architectural reflection.\" It is available to $20/mo Plus and $200/mo Pro tiers.\n- GPT-5 Pro: OpenAI's current $200/mo top-tier model, with the highest reasoning and context capabilities.\nI gave all four models the same assignment. I connected them to my private GitHub repository for my open-source free WordPress security plugin and its freemium add-on modules, selected Deep Research, and gave them this prompt.\nExamine the repository and learn its structure and architecture. Then report back what you've learned.\nFor those models that asked to choose areas of detail about what I wanted, I gave them this prompt.\nEverything you can tell me, be as comprehensive as possible.\nAs you can see, I didn't provide any context other than the source code repo itself. That code has a README file, as well as comments throughout the code, so there was some English-language context. But most of the context has to be derived from the folder structure, file names, and code itself.\nAlso: The best AI for coding in 2025 (and what not to use)\nFrom that, I hoped that the AIs would assess its structure, quality, security posture, extensibility, and possibly suggest improvements. This should be relevant to ZDNET readers because it's the kind of high-judgement, detail-oriented work that AIs are being used for. It certainly can make coming up to speed on an existing coding project easier, or at least provide a foundation for initial understanding.\nTL;DR summary\nOther than the two prompts above, I didn't give the LLMs any guidance about what to tell me. I wanted to see how they evaluated the repository and what sort of analysis they could provide.\nAs you can see from this table, overall coverage was quite varied in scope. More checks mean more depth of coverage.\nTo create this aggregate, topics like \"Project Purpose & Architecture,\" \"System Architecture,\" and \"Plugin Design & Integration\" were all normalized under Purpose/Architecture. Directory/File Structure contained any section mapping folders and files. Execution flow combines anything about how the software code runs. Recommendations/Issues combines all discussions of modernization suggestions, open issues, and minor red flags.\nIn terms of overall value, I'd rank the four LLMs as follows (from best to least best).\n- GPT-5 Pro: Most precise, engineering-ready, and actionable.\n- GPT-5: Widest scope, excellent mapping, and defensive-coding insight.\n- o3: Concise, modernization-focused, but lighter on underlying architecture.\n- GPT-5 Thinking: Best onboarding narrative, least evaluative depth.\nPro, of course, is only available in the $200/mo ChatGPT Pro tier. Later in this article, I'll show one way to modify the above prompts to get GPT-5 (non-Pro) to provide a fairly close approximation of the overall depth of the Pro response.\nGPT-5 Thinking, which is a model available in the $20/mo Plus plan, was the least helpful of the group. The GPT-4 generation o3 Deep Thinking model still holds up, but you can see how its self-directed focus is a bit different from the other two.\nAlso: Google's Jules AI coding agent built a new feature I could actually ship - while I made coffee\nMy main conclusion is that I was a bit surprised about how close the models were to each other. GPT-5, as OpenAI promised, did seem to provide a jump in overall cognition and usefulness, but nothing I would consider game-changing.\nWith that, let's dive into some specific examples that help illustrate my conclusions. Each of these sections is pulled from the various reports generated and shows you how each model provided similar information.\nSecurity posture, according to the models\nBelow, you can see how GPT-5 Pro names exact mechanisms (like file-top guard, nonces, manage_options). I've provided exact snippets here from the reports generated by all four models. GPT-5 affirms best practices but keeps it conceptual. o3 describes what happens (redirects/login flow) more than how it's hardened. GPT-5 Thinking gives the clearest \"what runs when\" story for new developers coming up to speed on the repo.\nGPT-5 Pro: Most concrete, code-level\n\"It guards against direct file access (if (!defined('ABSPATH')) exit; at the top of PHP files). It sanitizes input where appropriate \u2026 using WordPress nonces in AJAX handlers. It uses capability checks (e.g., adding menu pages only for users with manage_options capability \u2026 only admins see those tools). The code tries not to load unnecessary things \u2026 like only loading certain admin files on certain contexts.\"\nGPT-5: Correct, but higher-level\n\"There are checks for WordPress functions before use \u2026 so the plugin behaves gracefully even on very old WordPress setups. The plugins often guard against direct file access by checking \u2026 to prevent security issues from accessing .php files directly. Add-ons verify the presence of core before proceeding \u2026 and show an admin error if CMB2 isn't loaded.\"\no3: Runtime behavior, less on hardening specifics\n\"Purpose: My Private Site locks down an entire site so only logged-in users can view content \u2026 while protecting the rest. Overall architecture: [it] integrates deeply with WordPress's hook system and login/logout events to manage redirects and track login state.\"\nGPT-5 Thinking: Clear execution flow, onboarding tone\n\"Admin vs Front-end: It checks is_admin() to determine context. If on the front-end (not admin), it retrieves the saved privacy setting and, when enabled, hooks at a point like template_redirect to redirect unauthorized visitors. Throughout this initialization, the plugin uses WordPress hooks (actions and filters) to integrate functionality.\"\nLicensing and update mechanism, according to the models\nGPT-5 Pro didn't just describe the system; it walked through the process in sequential operational steps, almost like a short runbook you could hand to a developer or QA tester. GPT-5 confirms the architecture but abstracts the plumbing. GPT-5 Thinking adds a helpful \"how add-ons plug into the Licenses tab\" detail. o3 largely leaves licensing internals on the cutting room floor in favor of a fairly unhelpful modernization critique.\nGPT-5 Pro: Explains it step-by-step\n\"The core plugin provides utility functions to get and store license keys in a centralized option (jr_ps_licenses) and to contact the EDD license server for validation. Each extension plugin defines its own updater using EDD_SL_Plugin_Updater, passing the current version, the license key from the centralized store, and the EDD store URL. The core plugin's UI has a 'Licenses' tab, and extensions inject their own license fields via filters.\"\nGPT-5: Conceptual, but accurate\n\"License integration: The core plugin centralizes license management \u2026 and the add-ons piggyback on the core's licensing mechanism, integrating their license fields into the core plugin's interface.\"\no3: Barely mentions this topic at all\nThe o3 report spends most of its time on modernization and architecture. It discusses configuration and update behavior but does not walk through option keys, updater classes, or the Licenses UI wiring with the same procedural detail as GPT-5 and GPT-5 Pro. So there's nothing here to quote as a demonstration.\nGPT-5 Thinking: Good UI and extensibility observation\n\"The add-ons heavily rely on hooks provided by core or WordPress: They use add_filter/add_action calls to insert their logic \u2026 and use WordPress action hooks to integrate their license fields into the Licenses tab that the core plugin triggers when building the Licenses tab.\"\nState management, according to the models\nBoth GPT-5 Pro and GPT-5 explicitly pointed out how my code uses \"one option array + prune + no-op writes,\" which is a WordPress best practice for code maintainability. Both o3 and GPT-5 Thinking describe the lifecycle and effects (what's initialized, what loads when) rather than the exact option structure.\nGPT-5 Pro: Looks at specific storage pattern\n\"Settings are stored in a single serialized option \u2026 initialization routines add default keys, prune deprecated ones, and only update the option in the database if there is an actual change, avoiding unnecessary writes.\"\nGPT-5: Also looks at storage pattern, but more generally\n\"State Management: Plugin settings are stored in WordPress options as a central settings array and the code ensures defaults are applied while removing deprecated ones on each load, but only writes to the database when changes occur.\"\no3: Identifies intent and behavior, but doesn't discuss internals\n\"The main plugin initializes defaults (installed version, first-run timestamp, etc.). On each run it ensures these options exist and, if the privacy feature is disabled, the enforcement hook is not added.\"\nGPT-5 Thinking: Discusses basic flow and modules\n\"Module includes: includes admin and common modules in the back-end; on the front-end it retrieves the saved privacy setting and, when enabled, loads enforcement logic (e.g., in template_redirect). It registers a deactivation hook to clean up on deactivation (e.g., deleting a flag option).\"\nWhat does this mean for GPT-5?\nI was unimpressed with GPT-5 when it came to my coding tests. It failed half of my tests, an unprecedentedly bad result for what has previously been the gold standard in passing coding tests.\nBut GPT-5 was quite impressive in its analysis of the GitHub repository. It could be a powerful tool for onboarding new programmers, for someone adopting code, or simply for coming back up to speed on a project that's been untouched for a while.\nAlso: How I test an AI chatbot's coding ability - and you can, too\nThe GPT-4 generation o3 model is known to be a strong reasoning model, which is why it has been the basis for ChatGPT Deep Research. But GPT-5 was able to combine both breadth and detail, which is where o3 and GPT-4o were weak in previous tests.\nThe older models did give accurate summaries and useful suggestions, but they missed interconnections. For example, the older models were never able to show how UI flows, licensing, and update mechanisms work together.\nEven the base version of GPT-5 was able to identify cross-cutting concerns without additional prompting. Repository structure, backward compatibility, performance characteristics, and state management patterns all appeared in the first draft. Trying to get GPT-4 to span subjects is often an exercise in deep frustration.\nI found GPT-5's ability to understand and explain a complex interconnected system like my security product, all in one pass, to be a substantial improvement over the GPT-4 generation.\nIs GPT-5 Pro worth $200/mo?\nMaybe. If you're in a real rush to get to know a project and want as much of a data dump as possible as quickly as possible, yes. If you're operating on a big programming budget and $200/mo doesn't matter to you, yes.\nBut I find that cost hard to bear, especially when I have to subscribe to a wide range of AI services to evaluate them. So, now that I'm nearing the end of my one-month test of Pro-level activities, I'm planning on downgrading back to the $20/mo Plus plan.\nAlso: How to use GPT-5 in VS Code with GitHub Copilot\nPro's edge over GPT-5 wasn't about knowing more facts; it was about delivering those facts in a form you can act on immediately. The Pro report didn't just explain that security looked good; it cited the exact guards and checks in the code. It didn't just say licensing was centralized; it mapped the exact functions and database options involved.\nAgain, if you're on a time crunch, you might consider Pro. But I also think you can modify the base GPT-5's responses, with detail like the Pro report produced, simply by using better prompting.\nThat's next\u2026\nHow to get Pro-level results from base GPT-5\nI fed both the GPT-5 and GPT-5 Pro reports into GPT-5 and asked it for a prompt that would push the base-level GPT-5 to give GPT-5 Pro comprehensiveness as a result. This is that prompt, which you should add to any query where you want more complete coding information:\n*High-Specificity Technical Mode: ***In your answer, combine complete high-level coverage with exhaustive implementation-level detail.\n- Always name exact constants, functions, classes, hooks, option names, database tables, file paths, and build tools where possible, quoting them exactly from the code or material provided.\n- For every claim, explain why it's true and how you can tell (include reasoning tied to the evidence).\n- For each improvement you suggest, make it actionable and reference where in the codebase it applies.\n- Do not generalize when specifics are available.\n- Structure the output so a developer could use it directly to verify findings or implement recommendations.\nThis worked fantastically well. It took ChatGPT GPT-5 12 minutes to produce a 15,477-word document, complete with analysis and coding blocks. For example, it describes how value initialization is done, and then shows the code that accomplishes it.\nI think you could fine-tune this prompt and get Pro-level results without having to pay the $200/mo fee. I'm certainly going to tinker with this idea, possibly using GPT-5 to refine the specifications in the prompt for different areas I want to delve deeply into. I'll let you know how it goes.\nSee for yourself\nI had some difficulty setting up sharing for each of these long reports, so I just copied the results into Google Docs and shared them. Here are the links if you want to look at any of these reports.\n- o3 Deep Research\n- GPT-5 Deep Research\n- GPT-5 Thinking Deep Research\n- GPT-5 Pro Deep Research\n- GPT-5 Deep Research with Detail Prompt\nYou are welcome to dig into these documents and learn how my project is structured. While you may or may not care about my project, it's instructive to see how the various models perform. While you can read the reports, my actual repo is restricted since it's my private development repository.\nWhat about you? Have you tried using GPT-5 or GPT-5 Pro to analyze your own code? How did its insights compare to earlier models like GPT-4 or o3? Do you think the $200/month Pro tier is worth it for the extra precision, or could you get by with better prompts in the base version? Have you found AI code analysis useful for onboarding, refactoring, or improving security? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://research.domaintools.com/research/whois-history/",
      "text": "Whois History\nWhois History allows DomainTools members access to historical Whois records. Since 1995, DomainTools has been tracking the Whois history of millions of domains. These records are maintained in the DomainTools database and available to Subscription Members.\nWho uses Whois History?\nCybercrime Investigators use Whois History to\ninvestigate who is attacking their network or committing online fraud.\nLeverage the industry's best online and DNS research tools to find leads, create investigative connections and identify sources of fraud.\n- Use Whois and Reverse Whois to find identifying information about an attacker\n- Use DNS research tools to locate other leads and other domains that are associated with a malicious source\n- Leverage Whois History to find identifying information before privacy records\nBrand Agents use Whois History to\nprotect what belongs to them.\nProtect your brand against online fraud and save your company $millions in lost revenue.\n- Start with Brand Monitor to receive daily alerts of domains that violate your Brands\n- Discover ownership changes of domains that infringe on your trademarks\n- Obtain timely data for your most critical cases and deliver comprehensive research reports for your clients\n- Investigate the last public record and uncover a domain's ownership trail"
    },
    {
      "url": "https://www.bbc.com/news/articles/cg33x9jm02ko",
      "text": "Labour\u2019s Wes Streeting among victims of deepfake smear network on X\nA doctored video of Labour's Wes Streeting has been pushed to X users - making it seem as though he called fellow politician Diane Abbott a \"silly woman\". A network of X accounts has been creating and sharing such clips of politicians ahead of the general election - and then posting misleading comments alongside to bolster the impression they are real.\nI have been tracking down some of the people behind the network and unpicking their tactics. Has their trolling gone too far?\nThe doctored video of Mr Streeting features him on the BBC's Politics Live show. As the presenter discusses Ms Abbott, the footage is made to sound as though Mr Streeting is saying \"silly woman\" under his breath - but he never said those words.\nThe clip was posted on X - formerly Twitter - by a user called Men for Wes who, in the comments, expressed outrage at the \"really nasty people\" in the Labour Party. Other users swarmed in the comments to endorse the clip as real.\nOne account going by the name \u201cMurray\u201d falsely claimed to be a BBC Politics Live \"floor manager\" saying: \"This is legit\". Others said, \u201cI can deffo hear Wes Streeting calling Diane Abbott a silly woman\u201d or \u201cYou can clearly hear he said silly woman what an utter disgrace you are Wes Streeting\u201d.\nOne falsely suggested the BBC \u201cpulled the episode\u201d of Politics Live from iPlayer, which could discourage people from checking.\nThis clip and several more about other politicians were recommended by X in the feed of one of the BBC's Undercover Voters - 24 fictional people with social media accounts, created to investigate what content is recommended to different types of voters during the election. The profiles are private, with no friends. They just like, follow and watch relevant content.\nThe videos recommended to the Undercover Voter profile have racked up tens of thousands of views and led to politicians such as Mr Streeting denouncing them as false.\nSome X users pointed out they believed it to be faked, some responded with abusive remarks - and others were clearly confused about what to believe.\nThe BBC identified some of the users responsible for these videos, who describe their approach as \"shitposting\" - a term which usually refers to posting large amounts of ironic, low-effort content to derail productive discussion, distract people and provoke a reaction. This can come from people of all different political perspectives - and doesn\u2019t have to be about politics.\nBut while some of their fake clips are clearly absurd and satirical, others falsely portray candidates saying politically damaging things, while in the comments, the network of X users works to make them appear believable.\nSome of the clips make inflammatory comments related to the war in Gaza. As well as Mr Streeting, they have targeted Reform UK leader Nigel Farage and another Labour candidate, Luke Akehurst.\nAn X user called chai_ste - who re-shared the clip of Wes Streeting with the question \u201cis this real?\u201d - also shared a different doctored clip of Mr Akehurst, whose outspoken support for Israel and its actions in Gaza has made him unpopular with the Labour left.\nThis clip falsely portrays him as bragging that he will be elected by \"thick\" Geordies who think Gaza is a footballer.\nThe fake floor manager \"Murray\" was this time a \u201csound engineer\u201d who again posted that \u201cthis is legit\u201d.\nOther accounts, which seemed to be in on the joke, posted asking, \u201cis this real?\u201d and the original profile replied saying \u201cI haven't seen any source to disprove it as of yet!\u201d Another said: \u201cI\u2019m sure he just misspoke.\u201d\nThere\u2019s also evidence several of these accounts were involved in another deepfaked clip of Sir Keir Starmer. It was about the Rochdale by-election earlier this year and falsely suggested Starmer called Labour supporters \"beyond thick\" and suggested that \u201cas long as we\u2019re scoring points with Israel they\u2019ll be happy\u201d.\nSeveral hours after they were originally shared, the doctored clips of Mr Streeting, Mr Akehurst and Sir Keir were labelled as fakes by X\u2019s reader-operated fact check service, while X also applied a warning to the clip of Mr Akehurst saying it was \u201cmanipulated media\u201d.\nFollowing my investigation, the Men for Wes account has been suspended by X and the videos from its account are no longer visible on the site. Some of the other profiles also appear to have been removed.\nThis group of accounts regularly interact with one another, amplifying and engaging with each other\u2019s posts in this way. Some appear to co-ordinate their posts on a Discord server - an instant messaging and chat community - which refers to them as a \"Shitposting Army\".\nSeveral of these X users post frequently about their concern for Palestinians in the war in Gaza, as well as posting in support of Jeremy Corbyn and left-leaning Labour politicians. At least two of the people who appear to be behind some of the accounts seem to be based in the UK and in their twenties and thirties.\nThe Men for Wes account declined my request to speak on the phone several times and declined to disclose their identity, but agreed to answer my questions by messaging.\nThey said they aimed to provoke attention and \"muddy the water\" for viewers. They described this as a \"corrective\" to the ways that politicians \"misrepresent who they really are\" and rejected allegations they were a threat to democracy. They condemned any hate directed at politicians shared by other accounts.\nThey claimed a politician they supported had previously been targeted by misinformation, but in that case it had been spread by people in power and mainstream media outlets rather than \"random Twitter accounts\".\nThe user running the chai_ste profile, who also declined to give their real name, poked fun at the question of whether this network of accounts had taken \u201cshitposting\u201d too far.\nThey mockingly claimed to be following a \u201chandbook from the Labour Party\u201d and saying they were advised to post some \u201cobviously fake videos\u201d in among their \u201ctasks\u201d from the party, \u201cso that it doesn\u2019t become very obvious what we are really doing\u201d.\nA doctored clip of Nigel Farage was one of the more obviously satirical creations of the network.\nThe video edited the Reform UK leader's words from a clip making light of the incident where a milkshake was thrown over him, so that he appeared to make an obscene reference to bodily fluids.\nBut the comments around other videos, bolstering their claims of authenticity, appear to be causing real confusion among some people.\nOne user called Nigel, who responded on X to the post about Wes Streeting, told me he initially believed the video could be real. The 64-year-old said he intended to switch from Conservatives to Labour for the first time but said videos such as this could undermine their support.\n\u201cThis sort of thing is damaging. It seems everywhere you turn folks are out to get the Labour front team. I\u2019ve been told by more Labour voters not to vote Labour than Tory voters!\u201d he said.\nAnother social media user - who asked to remain anonymous - contacted me to say he had been following several of these accounts with concern since the faked clips of Sir Keir emerged.\nHe said: \u201cTheir tactics on how they'd push each fake were pretty calculated. It's frustrating as there are people in my life who have fallen for this kind of thing before.\"\nLots of the comments do feature users calling out the content as fake, however.\nX and Discord did not respond to the points raised by the BBC. X says publicly how \u201cdefending and respecting the user's voice is one of our core values\u201d.\nDiscord says online its guidelines \"ensure everyone can express themselves and find community \u2014 but not at the expense of anyone else\".\nThe Undercover Voters are fictional profiles designed to represent a range of voters in battleground constituencies across the UK. They follow, view and like content relevant to their character, informed by data and analysis from the National Centre for Social Research.\nFor this story, I examined the feeds of the profiles of some of these fictional voters in Halifax, which has been a target for the Conservatives and is currently held by Labour.\nKieran - a disillusioned voter in his twenties - is following lots of content about civilians killed in Gaza, as well as content about boycotting Israel. His feed on X was pushed these doctored clips of Mr Akehurst and then Mr Streeting.\nAnother Undercover Voter called Patricia has viewed posts supporting Israel and opposing antisemitism. She has seen critical posts which reused old clips of politicians expressing support for Palestinians. These included abusive and Islamophobic remarks in the comments, but I found no evidence of a similar network of accounts sharing doctored clips or comments in the same way on her feeds.\nThe third Undercover Voter character in Halifax is 44-year-old Maryam, who is quite disengaged in politics and undecided about who she wants to vote for. She has not been recommended this content so far."
    },
    {
      "url": "https://uk.news.yahoo.com/fake-videos-ai-chatbots-drive-035421986.html",
      "text": "A rioter admitting he was \"paid to be here\". A National Guard soldier filming himself being bombarded by \"balloons full of oil\". A young man declaring his intention to \"peacefully protest\", before throwing a Molotov cocktail.\nThese are some things that are not happening on the streets of Los Angeles this week. But you may think they are if you\u2019re getting your news from AI.\nFake AI-generated videos, photos, and factoids about the ongoing protests in LA are spreading like wildfire across social media, not least on Elon Musk's anything-goes social network X (formerly Twitter).\nMade using freely available video and image generation software, these wholly synthetic chunks of outrage usually confirm some pre-existing narrative about the protests \u2014 such as the baseless idea that they are being covertly funded and equipped by mysterious outside factions.\nAnd while some are technically labelled as parodies, many users miss these disclaimers and assume that the realistic-looking footage is an actual document of events on the ground.\n\"Hey everyone! Bob here on National Guard duty. Stick around, I'm giving you a behind the scenes look at how we prep our crowd control gear for today's gassing,\" says a simulated soldier in a viral TikTok video debunked by France24.\n\"Hey team!\" he soon follows up. \"Bob here, this is insane! They're chucking balloons full of oil at us, look!\"\nAnother fake video posted on X features a male influencer wearing a too-clean T-shirt in the thick of a riot. \"Why are you rioting?\" he asks a masked man. \"I don't know, I was paid to be here, and I just wanna destroy stuff,\" the man replies.\nAI tries to fact-check AI\nMeanwhile, chatbots such as OpenAI's ChatGPT and X's built-in Grok have been giving false answers to users' questions about events in the City of Angels.\nBoth Grok and ChatGPT wrongly insisted that photos of National Guard members crammed in together sleeping on the floor in LA this week \"likely originated\" in Afghanistan in 2021, according to CBS News.\nIt also reportedly claimed that a viral photo of bricks piled up on a pallet \u2014 which right-wing disinformation merchants had touted as proof of outside funding \u2014 was \"likely\" taken from the LA protests. In fact the photo showed a random street in New Jersey, but even when informed of the truth AI stuck to its guns.\nAI-generated fakes are merely one new instrument in a long-established orchestra of disinformation. Photos recycled from past protests or events, photos taken out of context, and disguised video game footage \u2014 all commonplace among partisan outrage-peddlers since at least 2020 \u2014 are being shared widely, including by Republican senator Ted Cruz (who has form in this regard).\n\"Pictures are easily manipulated; that idea has been there,\" James Cohen, a media professor and expert on internet literacy at CUNY Queens College, told Politico.\n\"But when it comes to videos, we\u2019ve just been trained as an individual society to believe videos. Up until recently, we haven\u2019t really had the opportunity to assume videos could be faked at the scale that it\u2019s being faked at this point.\u201d\nAmmunition for the culture war\nMost of the videos seen by The Independent were evidently targeted at a conservative audience, designed to reinforce or reference right-wing talking points. At least one TikTok account, however, with more than 300,000 views on its videos as of Wednesday evening, was evidently aimed at progressives interested in stirring messages of solidarity with immigrants.\nSome are obviously jokes; others, ambiguously jokes. Often there is a tag indicating that they the video is AI-generated. But in most cases this crucial information is easily missed.\nUnfortunately, the problem is only likely to get worse in future. Republicans' flagship \"Big Beautiful Bill\" includes a moratorium on all state regulation of AI, which would prevent any state government from intervening for 10 years.\nWhile AI-generated videos can be difficult to tell from the real thing, there are ways. They're often suspiciously clean and glossy-looking, as if hailing from the same manicured universe as Kendall Jenner's infamous Pepsi protest advert. The people in them are often strangely beautiful, like the amalgamation of a million magazine photoshoots.\nThe Better Business Bureau also recommends scrutinizing key details such as fingers and coat buttons, which often don't make sense on close inspection. Writing, too, is frequently blurred and illegible: just a jumble of letters or letter-like forms.\nBackground figures may behave strangely or repetitively, or even move in ways that are physically impossible. If in doubt, Google it and see if any trustworthy media organizations or individual journalists have confirmed or debunked what you're seeing.\nMost of all, be on the lookout for anything that seems to perfectly confirm your pre-existing beliefs. It may just be too good to be true."
    },
    {
      "url": "https://www.zdnet.com/article/navigating-ai-powered-cyber-threats-in-2025-4-expert-security-tips-for-businesses/",
      "text": "Navigating AI-powered cyber threats in 2025: 4 expert security tips for businesses\nCybercriminals are weaponizing artificial intelligence (AI) across every attack phase. Large language models (LLMs) craft hyper-personalized phishing emails by scraping targets' social media profiles and professional networks. Generative adversarial networks (GAN) produce deepfake audio and video to bypass multi-factor authentication. Automated tools like WormGPT enable script kiddies to launch polymorphic malware that evolves to evade signature-based detection.\nThese cyber attacks aren't speculative, either. Organizations that fail to develop their security strategies risk being overrun by an onslaught of hyper-intelligent cyber threats -- in 2025 and beyond.\nAlso: Want to win in the age of AI? You can either build it or build your business with it\nTo better understand how AI impacts enterprise security, I spoke with Bradon Rogers, Chief Custom Officer at Island and enterprise cybersecurity veteran, about this new era of digital security, early threat detection, and how you can prepare your team for AI-enabled attacks. But first, some background on what to expect.\nWhy AI cyber security threats are different\nAI provides malicious actors with sophisticated tools that make cyber attacks more precise, persuasive, and challenging to detect. For example, modern generative AI systems can analyze vast datasets of personal information, corporate communications, and social media activity to craft hyper-targeted phishing campaigns that convincingly mimic trusted contacts and legitimate organizations. This capability, combined with automated malware that adapts to defensive measures in real-time, has dramatically increased both the scale and success rate of attacks.\nDeepfake technology enables attackers to generate compelling video and audio content, facilitating everything from executive impersonation fraud to large-scale disinformation campaigns. Recent incidents include a $25 million theft from a Hong Kong-based company via deepfake video conferencing and numerous cases of AI-generated voice clips being used to deceive employees and family members into transferring funds to criminals.\nAlso: Most AI voice cloning tools aren't safe from scammers, Consumer Reports finds\nAI-enabled automated cyber attacks led to the innovation of \"set-and-forget\" attack systems that continuously probe for vulnerabilities, adapt to defensive measures, and exploit weaknesses without human intervention. One example is the 2024 breach of major cloud service provider AWS. AI-powered malware systematically mapped network architecture, identified potential vulnerabilities, and executed a complex attack chain that compromised thousands of customer accounts.\nThese incidents highlight how AI isn't just augmenting existing cyber threats but creating entirely new categories of security risks. Here are Rogers' suggestions for how to tackle the challenge.\n1. Implement zero-trust architecture\nThe traditional security perimeter is no longer sufficient in the face of AI-enhanced threats. A zero-trust architecture operates on a \"never trust, always verify\" principle, ensuring that every user, device, and application is authenticated and authorized before gaining access to resources. This approach minimizes the risk of unauthorized access, even if an attacker manages to breach the network.\n\"Enterprises must verify every user, device, and application -- including AI -- before they access critical data or functions,\" underscores Rogers, noting that this approach is an organization's \"best course of action.\" By continuously verifying identities and enforcing strict access controls, businesses can reduce the attack surface and limit potential damage from compromised accounts.\nAlso: This new AI benchmark measures how much models lie\nWhile AI poses challenges, it also offers powerful tools for defense. AI-driven security solutions can analyze vast amounts of data in real time, identifying anomalies and potential threats that traditional methods might miss. These systems can adapt to emerging attack patterns, providing a dynamic defense against AI-powered cyberattacks.\nRogers adds that AI -- like cyber defense systems -- should never be treated as a built-in feature. \"Now is the time for CISOs and security leaders to build systems with AI from the ground up,\" he says. By integrating AI into their security infrastructure, organizations can enhance their ability to detect and respond to incidents swiftly, reducing the window of opportunity for attackers.\n2. Educate and train employees on AI-driven threats\nOrganizations can reduce the risk of internal vulnerabilities by fostering a culture of security awareness and providing clear guidelines on using AI tools. Humans are complex, so simple solutions are often the best.\n\"It's not just about mitigating external attacks. It's also providing guardrails for employees who are using AI for their own 'cheat code for productivity,'\" Rogers says.\nAlso: DuckDuckGo's AI beats Perplexity in one big way - and it's free to use\nHuman error remains a significant vulnerability in cybersecurity. As AI-generated phishing and social engineering attacks become more convincing, educating employees about these evolving threats is even more crucial. Regular training sessions can help staff recognize suspicious activities, such as unexpected emails or requests that deviate from routine procedures.\n3. Monitor and regulate employee AI use\nThe accessibility of AI technologies has led to widespread adoption across various business functions. However, unsanctioned or unmonitored use of AI -- often called \"shadow AI\" -- can introduce significant security risks. Employees may inadvertently use AI applications that lack proper security measures, leading to potential data leaks or compliance issues.\n\"We can't have corporate data flowing freely all over the place into unsanctioned AI environments, so a balance must be struck,\" Rogers explains. Implementing policies that govern AI tools, conducting regular audits, and ensuring that all AI applications comply with the organization's security standards are essential to mitigating these risks.\n4. Collaborate with AI and cybersecurity experts\nThe complexity of AI-driven threats necessitates collaboration with experts specializing in AI and cybersecurity. Partnering with external firms can provide organizations access to the latest threat intelligence, advanced defensive technologies, and specialized skills that may not be available in-house.\nAlso: How Cisco, LangChain, and Galileo aim to contain 'a Cambrian explosion of AI agents'\nAI-powered attacks require sophisticated countermeasures that traditional security tools often lack. AI-enhanced threat detection platforms, secure browsers, and zero-trust access controls analyze user behavior, detect anomalies, and prevent malicious actors from gaining unauthorized access.\nRogers highlights that the innovative solutions for the enterprise \"are a missing link in the zero-trust security framework. [These tools] provide deep, granular security controls that seamlessly protect any app or resource across public and private networks.\"\nThese tools leverage machine learning to continuously monitor network activity, flag suspicious patterns, and automate incident response, reducing the risk of AI-generated attacks infiltrating corporate systems."
    },
    {
      "url": "https://www.cbsnews.com/news/rise-of-ai-celebrity-endorsements/",
      "text": "Can you spot the AI impostor? The swift rise of AI celebrity endorsements\nTwo months before Election Day, a photo of singer Elton John in a pink coat with the letters \"MAGA\" on it surfaced on social media, suggesting the global superstar had endorsed former President Donald Trump.\nBut the photo wasn't real. It's the latest in a series of images and videos created using artificial intelligence that aim to dupe viewers into thinking their favorite celebrities have endorsed political candidates.\nStars including Will Smith and Taylor Swift have also had their likeness used to falsely claim they are supporting Trump in the upcoming presidential election.\nWhen Swift publicly endorsed Vice President Kamala Harris in an Instagram post, she referenced AI-generated images that falsely suggested she had endorsed Trump, adding that the incident \"brought me to the conclusion that I need to be very transparent about my actual plans for this election as a voter.\"\nAn AI-generated video of Will Smith and Chris Rock, which amassed over 700,000 views on X, showed the stars eating large plates full of spaghetti with Trump.\nHow to identify AI-generated images\nThere are three main ways to tell if an image or video has been AI-generated or manipulated, Claire Leibowicz, head of the AI and Media Integrity Program at the nonprofit technology coalition The Partnership on AI, told CBS News.\nThe first way is to look for airbrushing, smudging or \"things that defy the laws of physics,\" Leibowicz said.\nThe second is to find any visual inconsistencies. In the case of the Elton John image, for example, the MAGA letters on his jacket were sewn across the lapels and his glasses were too close together.\nThe third way to find out if an image is real is to find the original source through reverse searching online. This can be done by taking a screenshot and uploading it to Google Lens or similar tools, and the results will show whether there's a match out there, helping you verify where it came from.\nLeibowicz added that she was previously fooled by AI when a fabricated image of Pope Francis went viral online.\n\"This is getting harder, and we're [going to] need journalists and other experts to really be helping us authenticate content.\"\nA poll conducted by the Polarization Research Lab in March found that nearly 50% of Americans believe AI will make elections worse, about 30% are unsure and 20% believe AI will improve the election process.\nSam Gregory, executive director of Witness.org, a global nonprofit that uses video and technology to protect human rights, told CBS News, \"Most of the information that will mislead us around the elections is likely to be powerful leaders telling lies or misrepresenting the truth in public.\"\nThe Department of Homeland Security released a bulletin in May warning the public of the challenges AI can create for the November presidential election, saying the \"timing of election-specific AI-generated media can be just as critical as the content itself, as it may take time to counter-message or debunk the false content permeating online.\""
    },
    {
      "url": "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI found 5 AI content detectors that can correctly identify AI text 100% of the time\nHow hard is it in 2025 -- just three years after generative AI captured the global spotlight -- to fight back against AI-generated plagiarism?\nAlso: Anthropic's AI agent can now automate Canva, Asana, Figma and more - here's how it works\nThis is a completely updated version of my January 2023 article on AI content detectors. When I first tested these detectors, the best result was 66% correct from one of three available checkers. My most recent set of tests, in February 2025, used up to 10 checkers -- and three of them had perfect scores. This time, just a couple of months later, five detectors boasted perfect scores.\nWhat I'm testing for and how I'm doing it\nBefore I go on, though, let's discuss plagiarism and how it relates to our problem. Merriam-Webster defines \"plagiarize\" as \"to steal and pass off (the ideas or words of another) as one's own; use (another's production) without crediting the source.\"\nThis definition fits AI-created content well. While someone using an AI tool like Notion AI or ChatGPT isn't stealing content, if that person doesn't credit the words as coming from an AI and claims them as their own, it still meets the dictionary definition of plagiarism.\nAlso: The dead giveaway that ChatGPT wrote your content - and how to work around it\nTo test the AI detectors, I'm using five blocks of text. Two were written by me and three were written by ChatGPT. To test a content detector, I feed each block to the detector separately and record the result. If the detector is correct, I consider the test passed; if it's wrong, I consider it failed.\nWhen a detector provides a percentage, I treat anything above 70% as a strong probability -- whether in favor of human-written or AI-written content -- and consider that the detector's answer. If you want to test a content detector yourself using the same text blocks, you can pull them from this document.\nThe overall results\nTo evaluate AI detectors, I reran my five-test series across 10 detectors. In other words, I cut and pasted 50 individual tests (I had a lot of coffee).\nDetectors I tested include BrandWell, Copyleaks, GPT-2 Output Detector, GPTZero, Grammarly, Monica, Originality.ai, QuillBot, Undetectable.ai, Writer.com, and ZeroGPT.\nAlso: How I personalized my ChatGPT conversations - why it's a game changer\nFor this update, I added Copyleaks and Monica. I dropped Writefull from my tests because it discontinued its GPT detector. Content Guardian requested inclusion, but I didn't hear back in time for testing accounts.\nThis table shows overall results. As you can see, five detectors correctly identified human and AI text in all tests.\nI tried to ascertain whether there was a tangible pattern of improvement over time, so I constructed a chart comparing the five-test set over time. So far, I've run this series six times, but there's no strong trend. I did increase the number of detectors tested and swapped out a few, but the only consistent result is that Test 5 was reliably identified as human across detectors and dates.\nI'll continue to test over time, and hopefully I'll see reliability trend consistently upward.\nWhile there have been some perfect scores, I don't recommend relying solely on these tools to validate human-written content. As shown, writing from non-native speakers often gets rated as generated by an AI.\nEven though my hand-crafted content has mostly been rated human-written this round, one detector (GPTZero) declared itself too uncertain to judge, and another (Copyleaks) declared it AI-written. The results are wildly inconsistent across systems.\nAlso: The best AI chatbots: ChatGPT, Copilot, and notable alternatives\nBottom line: I would advocate caution before relying on the results of any -- or all -- of these tools.\nHow each AI content detector performed\nNow, let's look at each individual testing tool, listed alphabetically.\nBrandWell AI Content Detection (Accuracy 40%)\nThis tool was originally produced by an AI content generation firm, Content at Scale. It later migrated to BrandWell.ai, a new name for an AI-centric marketing services company.\nAlso: AI-generated images are a legal mess - and still a very human process\nUnfortunately, its accuracy was low. The tool was unable to tell if the AI-generated content in Test 2 was human or AI, as shown in this screenshot:\nCopyleaks (Accuracy 80%)\nI find it amusing that Copyleaks declares itself \"the most accurate AI detector with over 99% accuracy\" when more than half of tested detectors performed better. But marketing folks will be marketing folks -- superlatives are as hard for them to resist as barking at a squirrel (and the FedEx truck, and all the neighbor kids) is for my dog.\nAlso: 5 quick ways Apple's AI tools can fine-tune your writing on the fly\nThe company's primary offering is a plagiarism checker sold to educational institutions, publishers, and enterprises seeking to ensure content originality and uphold academic integrity.\nGPT-2 Output Detector (Accuracy 60%)\nThis tool was built using a machine-learning hub managed by New York-based AI company Hugging Face. While the company has received $40 million in funding to develop its natural language library, the GPT-2 detector appears to be a user-created tool using the Hugging Face Transformers library.\nGPTZero (Accuracy 80%)\nGPTZero has clearly been growing. When I first tested it, the site was bare-bones -- it wasn't even clear whether GPTZero was a company or just someone's passion project. Now, the company has a full team with a mission of \"protecting what's human.\" It offers AI validation tools and a plagiarism checker.\nAlso: The most popular AI tools of 2025 (and what that even means)\nUnfortunately, performance seems to have declined. In my last two runs, GPTZero correctly identified my text as human-generated. This time, it declared that same text as AI-generated.\nGrammarly (Accuracy 40%)\nGrammarly is well known for helping writers produce grammatically correct content -- that's not what I'm testing here. Grammarly can check for plagiarism and AI content. In the grammar checker, there's a Plagiarism and AI Text Check button in the lower-right corner:\nI'm not measuring plagiarism checker accuracy here, but even though Grammarly's AI-check accuracy was poor, the site correctly identified the test text as previously published.\nMonica (Accuracy 100%)\nMonica is a new entrant. This service offers an all-in-one AI assistant with a wide range of services. Users can choose from various large language models.\nAlso: 5 ways ChatGPT can help you write essays\nThe company calls Monica the \"Best AI Detector Online,\" but it looks like it runs content through other detectors including ZeroGPT, GPTZero, and Copyleaks. Weirdly, both GPTZero and Copyleaks didn't perform well in my tests, but Monica -- and ZeroGPT -- did.\nWe're giving it 100% because it earned that rating, but I'll see how it stands up in future tests.\nOriginality.ai (Accuracy 100%)\nOriginality.ai is a commercial service that bills itself as an AI and plagiarism checker. The company sells usage credits: I used 30 credits for this article. They sell 2,000 credits for $12.95 per month. I pumped 1,400 words through the system and used just 1.5% of my monthly allocation.\nQuillBot (Accuracy 100%)\nThe last few times I tested QuillBot, results were wildly inconsistent -- multiple passes of the same text yielded wildly different scores. This time, however, it was rock solid and 100% correct. So I'm giving it the win. I'll check back in a few months to see if it holds onto this performance.\nUndetectable.ai (Accuracy 100%)\nUndetectable.ai's big claim is that it can \"humanize\" AI-generated text so detectors won't flag it. I haven't tested that feature -- it bothers me as a professional author and educator, because it seems like cheating.\nAlso: Why you should ignore 99% of AI tools - and which four I use every day\nHowever, the company also has an AI detector, which was very much on point.\nThe AI detector passed all five tests. Notice the indicators showing flags for other detectors. The company said, \"We developed multiple detector algorithms modeled after those major detectors to provide a federated and consensus-based approach. They do not directly feed into the listed models; rather, the models are each trained based on results they've generated. When it says those models flagged it, it's based on the algorithm we created and updated for those models.\"\nAlso: Only 8% of Americans would pay extra for AI, according to ZDNET-Aberdeen research\nI do have a question about the OpenAI flag, since OpenAI's content detector was discontinued in 2023 due to low accuracy. Even so, Undetectable.ai detected all five tests, earning a perfect 100%.\nWriter.com AI Content Detector (Accuracy 40%)\nWriter.com is a service that generates AI writing for corporate teams. Its AI Content Detector tool can scan for generated content. Unfortunately, its accuracy was low. It identified every text block as human-written, even though three of the six tests were written by ChatGPT.\nZeroGPT (Accuracy 100%)\nZeroGPT has matured since I last evaluated it. Then, no company name was listed, and the site was peppered with Google ads and lacked clear monetization. The service worked fairly well but seemed sketchy.\nAlso: Will AI destroy human creativity? No - and here's why\nThat sketchy feeling is gone. ZeroGPT now presents as a typical SaaS service, complete with pricing, company name, and contact information. Its accuracy increased as well: last time it was 80%; this time it scored 5 out of 5.\nIs it human, or is it AI?\nWhat about you? Have you tried AI content detectors like Copyleaks, Monica, or ZeroGPT? How accurate have they been in your experience? Have you used these tools to protect academic or editorial integrity? Have you encountered situations where human-written work was mistakenly flagged as AI? Are there detectors you trust more than others for evaluating originality? Let us know in the comments below.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.cbsnews.com/news/fake-social-media-accounts/",
      "text": "How fake social media profiles are fueling scams and getting people \"duped out of money\"\nFrom April to June this year, Facebook reports they have removed more than 1.7 billion fake accounts from its site. But it is unknown how many fake accounts are still on the site. One of those accounts is U.S. Navy Petty Officer Mike Sency.\n\"Do you have any idea how many fake Mikes there may be out there using your picture?\" CBS News senior medical correspondent Dr. Tara Narula asked.\n\"Too many. I would probably say, you know, 500 to 600 over different social media platforms,\" Sency replied.\nAbout five or six years ago, he started seeing his real name and images used on fake social media accounts for dating scams and other online cons. He said that two years ago, somebody messaged that they sent over $15,000 of their own money.\n\"Every single day, I get a message from somebody who has been, you know, duped out of money or have put, you know, months of their life into somebody romantically who they thought they were talking to and it wasn't them. So I just, I feel bad for those people,\" said Sency.\nNarula's husband, as well as CBS News foreign correspondent Charlie D'Agata, also discovered fake accounts using their pictures.\nIssie Lapowsky, chief correspondent for the tech news website Protocol, said it is very easy to make a fake social media account.\nShe demonstrated how to create an account using just an email address, fake name and the image of a CBS News producer.\n\"How can you know if your image is being used for these parts of a scam?\" Narula asked.\n\"A lot of people find out because they are told. The other way is to do a reverse image search so they can see 'Hey, is my photo being used in any place where I don't recognize or pretending to be anyone I don't know?'\" Lapowsky said.\nNarula was able to do what Lapowsky said and found another fake account of her husband. Her husband's photo was being used to meet men on the dating site Topface.\nWhile Instagram has made it easy to report fake accounts, Sency said it doesn't always work.\n\"When it first started happening, Instagram was really good about deleting the profiles. But it kind of went away,\" he said. \"I'll report them myself and they literally message back and say, 'Oh, they're not doing anything wrong. We can't take the profile down.'\"\nSency said social media platforms need to do more to protect people's security. \"Just put your stuff on private. But at the end of the day, I shouldn't have to censor myself and my social media to appease other people who are using it in the wrong way,\" he said.\nIn a statement, Instagram told CBS News: \"Claiming to be another person on Instagram violates our community guidelines, and we have a dedicated team that's tasked with detecting and blocking these kinds of scams.\""
    },
    {
      "url": "https://www.cbsnews.com/news/fake-videos-conspiracies-falsehoods-los-angeles-protests/",
      "text": "Fake videos and conspiracies fuel falsehoods about Los Angeles protests\nAs demonstrations against Immigration and Customs Enforcement raids continue in Los Angeles, misleading videos, conspiracies and false claims have spread on social media.\nMany of the posts recycle longstanding conspiracy theories, which have often been revived during past episodes of civil unrest. Some posts have made claims that wealthy individuals engineered or financed the protests, and they have racked up millions of views online.\nSome posts exaggerate the unrest, using videos of past demonstrations to depict a city overwhelmed by violence. In fact, clashes since the current protests began Friday have remained largely confined to parts of Los Angeles County.\nHere are some of the most widely shared falsehoods and misleading visuals.\nRecycled imagery and video game footage\nSome politicians, conspiracy theorists and social media users have posted old footage during the protests, falsely describing the clips as current. While Los Angeles has seen some vandalism and property damage in the current protests, the mix of outdated and recent videos has created confusion.\nOne widely shared video of vandalized police cars set ablaze, which was posted by far-right conspiracy theorist Alex Jones and Sen. Ted Cruz of Texas on Sunday, was originally from news coverage of May 2020 protests in response to the death of George Floyd.\nOn the same day, a video showing people setting a Jeep on fire was described as undocumented immigrants pouring gasoline over the vehicle in Los Angeles on Saturday. However, the footage dates back to a street takeover in the city's Hyde Park neighborhood in March 2024.\nThe old clips were shared on the same day five driverless Waymo vehicles were set ablaze during the current protests. But the recycled footage gave the misleading impression that such incidents were more frequent and widespread.\nOn Sunday, two days before Marines were ordered to deploy to Los Angeles, old and unrelated footage falsely claimed to show them arriving. One video, which showed Marines driving to their base hundreds of miles away in San Diego County, was misrepresented as showing them entering Los Angeles.\nDarren Linvill, a professor at Clemson University and social media disinformation researcher, told CBS News said even the smartest social media users have difficulty telling old content from authentic images in fast-moving situations.\n\"Sometimes that sort of content is spread by people who are doing it purposefully with some kind of agenda, but most often it's spread by people who just didn't understand the context that they saw it in,\" Linvill said.\nSome social media users also posted footage from a video game during the protests, making it appear that there had been a significant military escalation. A video posted on Sunday was falsely described as showing protesters firing at National Guard jets. In fact, the footage is from the tactical military simulation video game Arma 3, which has previously been used to spread misinformation.\nInaccurate debunks\nAmid the recycled imagery, authentic pictures of National Guard members sleeping on the floor of a federal building in Los Angeles this week were falsely described as old or unauthentic.\nThe images were initially published by the San Francisco Chronicle on Monday and republished by California Gov. Gavin Newsom on X, who said they served as proof that the deployment was poorly planned, and claimed the soldiers were \"without fuel, food, water or a place to sleep.\"\nSome social media users said the images were old and depicted soldiers at previous deployments. Grok, X's AI chatbot, determined the images were likely from Afghanistan in 2021.\nHowever, the images are authentic. Using images published by the U.S. Northern Command and other videos posted to social media, CBS News independently confirmed the images were taken from the loading dock area of the Robert Young Federal Building.\nLater, a spokesperson for the U.S. Northern Command confirmed to CBS News that the image was authentic: \"The soldiers you saw in the photo were resting as they were not currently on mission and due to the fluid security situation, it was deemed too dangerous for them to travel to better accommodations. The soldiers have ready access to food and water as needed.\"\nPeople on X have been tagging Grok more often to help verify visuals during these protests with mixed results, according to Isabelle Frances-Wright, the director of technology and society at the Institute for Strategic Dialogue, an independent think tank that examines disinformation online.\n\"While AI is muddying the landscape, people are also now turning to AI as their primary source of fact checking,\" said Wright.\nConspiracy theories\nConspiracy theories alleging rich donors orchestrated the protests have also resurfaced, echoing patterns from past demonstrations.\nOne widely shared claim involved images of stacked bricks, which social media users falsely presented as supplies planted by billionaire George Soros to incite violence. These posts reached millions across multiple platforms.\nOne poster shared a photo of bricks that they claimed were left near \"ICE facilities.\" However, CBS News found the image was actually taken from the website of a Malaysian building materials company.\nRumors about pallets of bricks were also debunked after Black Lives Matter protests in 2020 and reemerged in 2021 during Kyle Rittenhouse's trial and 2022 during Roe v. Wade protests.\nLinvill said although the types of misinformation around the Los Angeles protests have followed a familiar pattern, people on both the right and the left are more willing to believe something is fake or staged than they used to be. Many people also assumed the photos Newsom posted of National Guard troops were fake, said Linvill, warning of the risks this poses.\n\"While fake things are very dangerous, it's also dangerous to assume that everything is fake. And I feel like that is becoming more pervasive for people to just dismiss the evidence in front of their eyes,\" he said."
    },
    {
      "url": "https://jcpa.org/article/european-anti-americanism-and-anti-semitism-similarities-and-differences/",
      "text": "No. 16\n- Anti-Semitism in Europe goes back a thousand years. Anti-Americanism emerged more than 200 years ago among European elites. Current European prejudices are enhanced by the Europeans\u2019 perception of how America and Israel use power.\n- America and Jews are seen by many Europeans as paragons of a modernity they dislike and distrust: money-driven, profit-hungry, urban, universalistic, individualistic, mobile, rootless, inauthentic, and thus hostile to established traditions and values.\n-\nAnti-Americanism fulfills a structural role in helping to create a European identity. Anti-Semitism does not necessarily do this, hence it might abate if and when peace is reached in the Middle East.\n-\nAnti-Americanism and anti-Semitism are the only major icons shared by the European extreme left and far right, including neo-Nazis.\nAnti-Americanism Creates a European Identity\nAndrei S. Markovits is the Karl W. Deutsch Collegiate Professor of Comparative Politics and German Studies at the University of Michigan in Ann Arbor. He is currently writing a book on anti-Americanism. Markovits says: \u201cIdentity, modernity, and attitudes toward power are three key expressions in the analysis of European anti-Americanism. Nobody knows what it means to be a European. It is unclear what Greeks and Swedes have in common. But one important characteristic they share is their not being American.\n\u201cNo identity has ever emerged without an important counter-identity. Anti-Americanism thus enables the Europeans to create a hitherto missing European identity that must emerge if the European project is to succeed. This functional dimension of anti-Americanism is a key reason why among the two core proponents and protagonists of the European project \u2013 the French and Germans, though not only them \u2013 anti-Americanism has become such a central part of political discourse.\u201d\nMarkovits notes that one can enrich one\u2019s perspectives on both anti-Americanism and anti-Semitism by analyzing their respective similarities and differences and, above all, their powerful relationship to each other. \u201cAlvin Rosenfeld formulated the resemblances well in a recent paper: Anti-Americanism functions in much the same way anti-Semitism has over the centuries \u2013 as a convenient focus for discontents of many different kinds and a ready-made explanation of internal weaknesses, disappointments, and failures. It is, in short, both fraudulent and counterproductive.\u201d1\nParagons of Modernity\n\u201cAnti-Americanism and anti-Semitism relate to each other and empirically are almost always in close proximity, even if not totally identical. The overlap in bias between them has become more pronounced since the end of World War II.\n\u201cLike all other prejudices, their advocates prejudge the object and its activities irrespective of what transpires in reality. These attitudes express a dislike for the American as well as the Jewish essence, character, way of life, symbols, and people. They say more about those who hold the prejudice than the objects of their ire and contempt.\n\u201cIn the 1870s and 1880s, European anti-Semitism began to accompany anti-Americanism in a regular and systematic manner. Linking Jews and Americans at this juncture seems surprising since Jewish immigration to the United States had not yet reached the large numbers it would have twenty years later, and American power in the world was still rather ephemeral.\n\u201cOne explanation for this linkage is that both were seen in the minds of many Europeans, especially the mostly aristocratic elites, as paragons of modernity: money-driven, profit-hungry, urban, universalistic, individualistic, mobile, rootless, and inauthentic (i.e. not connected to a specific location and land). Another aspect of modernity is capitalism \u2013 a major anathema to the political left and also to many who do not identify with that political orientation.\n\u201cAnti-Americanism and anti-Semitism were thus perceived as hostile to established traditions and values. Like any other prejudice, they are an acquired set of beliefs. Both are \u2018isms\u2019 which indicate they are institutionalized and commonly used as a modern ideology. As such, their discourses have their own semantics.\u201d\n\u201cJews Rule America\u201d\n\u201cIt was not the existing United States and its Jews that were feared and disdained, but the combination of Americanism and Judaism as concepts and social trends. After World War I, the false notion of Jews as rulers of America became pronounced. Expressions such as Jewish Wall Street, Jewish Hollywood, and Jewish jazz became commonplace, creating the image of a totally \u2018Judaized\u2019 America.\n\u201cBy then, all forerunners of the current anti-Semitic codes such as the \u2018East Coast\u2019 were permanently established. Since then, in many European minds, Jews and America have become inextricably intertwined, not only as representatives of modernity, but also as holders of allegedly uncontrollable power. America was powerful and the Jews there were perceived as even more so. Of course, European anti-Semitism had always maintained that Jews had much more power than they did in reality. Their putative power was further enhanced in anti-Semitic minds by its allegedly clandestine and cliquish character.\n\u201cWith America\u2019s real power massively growing after World War I, power as a notion unifying Jews and America became more pronounced as well as more enduring. The hostile perception of this alleged link became as integral to National Socialism as it was to Stalinism later on, though with very different political accents and content.\u201d\nEuropean Anti-Semitism Starts in 1010\n\u201cHistorian Richard Landes dates the beginning of violent European anti-Semitism to 1010. It brought about the first organized massacres of Jews in Europe, and particularly in France. These systematic and politically motivated mass murders occurred in the context of Christianity\u2019s new state-building, which required the creation of an identity.\u201d2\nAnti-Americanism is many centuries younger. Markovits quotes an unpublished paper by Ira Strauss, who claims that a pre-ideological fear of and resentment toward America, emerged among Europe\u2019s elites around the end of the fifteenth century. The aristocracy and the clergy understood after 1492 that Columbus\u2019 journeys and his discovery of the new world could undermine their established positions.3\n\u201cAnti-Americanism as a word may not have been coined until the beginning of the twentieth century. The sentiments it denoted had, however, been commonly understood and employed in Europe since the late eighteenth century if not before. From then on some Europeans were worried about America, which they saw as a distorting and destructive force. These thoughts were held by Friedrich Nietzsche, Charles Dickens, Knut Hamsun, Stendhal and many other European intellectuals across the continent. One cannot really confine either anti-Semitism or anti-Americanism to one \u2013 or even a few \u2013 European nations. At a particular time, anti-Semitism \u2013 and anti-Americanism \u2013 may have been more pronounced in one European country as opposed to another, but both share the characteristics of being pan-European and not nation-specific phenomena.\n\u201cAlready in the eighteenth century, in some cases even before the establishment of the political entity called the \u2018United States of America\u2019 in 1776, many European elites viewed America as degenerate. The \u2018degeneration\u2019 thesis enjoyed wide acceptance throughout Europe. One eighteenth century author, Dutch naturalist Cornelius de Pauw, decried the existence of America as \u2018the worst misfortune\u2019 that could have happened to all humanity, upsetting even the New World\u2019s dogs who \u2013 according to de Pauw \u2013 never barked.4 The view of America as degenerate has remained a major staple of the European elite\u2019s opinions until today.\u201d5\nGermans Extol Native Americans\n\u201cThe Germans\u2019 inordinate extolling of native Americans as \u2018noble savages\u2019 whom they regarded as true soul mates in the defense of authentic culture against the onslaught of America\u2019s materialist and venal civilization, was unique among Europeans. Nowhere is this theme more visible than in the writings of Karl May, whose pulp fiction became a staple read by every middle class child \u2013 boys in particular \u2013 throughout the twentieth century.\n\u201cMay\u2019s books feature a German \u2013 presumably the author himself \u2013 under the assumed name of Old Shatterhand who, together with his blood brother Winnetou, chief of the Apaches, fights the good fight against an assortment of evil doers consisting of venal Englishmen, drunken Scots, cunning Jews, and excessively cruel Comanches and Sioux, their native American allies. May\u2019s books feature every anti-American, anti-British, and anti-Semitic concept commonly held by Germany\u2019s middle class until 1945, if not beyond.\n\u201cThe hatred of and contempt for America of the Nazis \u2013 as well as most European fascists \u2013 needs no elaboration. America embodied every social and political dimension the Nazis found antithetical to their very essence. To them, America was a mediocre, mongrel nation, devoid of culture, ruled by a Jewish-dominated East-Coast-based plutocracy whose mission was global domination in politics, economics, and culture. Associating America with rootlessness \u2013 \u2018Bodenlosigkeit\u2019 \u2013 became a basic German view on America that went far beyond the blood and soil ideology of the radical right and the Nazis.\n\u201cHowever, the concern with the fate of native Americans that is among Europeans\u2019 antagonisms toward America remains, in its acuteness, singular to Germans. By constantly invoking the genocide of native Americans, Germans can readily point to the Americans\u2019 own holocaust and thus experience some sense of expiation, particularly since they see America \u2013 ruled by its East Coast intellectuals (a convenient code word for Jews) \u2013 as Germany\u2019s most unforgiving daily reminder of its Nazi past.\u201d\nThe Major Differences: The Holocaust and Violence\n\u201cWhile the two European prejudices overlap, there are also huge differences. Anti-Semitism has killed millions of people, while European anti-Americanism has only murdered a few. There were never any pogroms against Americans. Violence, as a rule, did not go further than the destruction of property and the burning of many American flags. There has never been a blood libel about Americans.\n\u201cAnother major difference is that of power. Since the nineteenth century, America has become an increasingly powerful country. Its military might was very influential in World War I and was powerful well before then. The Jews only had power in the warped imagination of their enemies.\n\u201cIsrael, however, after the 1967 Six-Day War, became increasingly perceived as being far more powerful than it actually was. The image of the strong and tough Jew emerged and similarities with the Americans increased in the perception of many Europeans. They started to resort to characterizations of Israel\u2019s essence and its very existence \u2013 as opposed to its policies \u2013 with rather similar terms and tones that resembled old-fashioned European anti-Semitism.\u201d\nFrom Shylock Jew to Rambo Jew\n\u201cThis attests not to the end of European anti-Semitism but to a mutation from the Shylock Jew \u2013 which is unacceptable in contemporary Europe \u2013 to the highly legitimate perception of the Rambo Jew, to use Daniel Goldhagen\u2019s excellent characterizations.6 This crude cinematic character has become a synonym for America and Americans in European discourse of the past two decades.\n\u201cThe Arabs are now presented as the victims of the Jews. One expression of European anti-Semitism is that the Jews \u2013 who should have been victims \u2013 are seen as perpetrators. In 2002, the German philosopher Peter Sloterdijk named America and Israel as the only two countries today that strike him as being \u2018rogue states.\u20197 His view is a widely shared one among Europe\u2019s elites, as well as, increasingly, its general publics.\n\u201cThe European emphasis has recently been on \u2018hyperpower\u2019 \u2013 \u2018hyperpuissance\u2019 as former French Foreign Minister Hubert Vedrine called it \u2013 and its alleged abuse. Europeans claim to have learned a valuable lesson from their own history: any power \u2013 particularly an unbridled one \u2013 will always be abused by those who wield it. Especially since the Vietnam War, Europeans have viewed the United States as not only all-powerful but also as prone to abuse its unparalleled might at will, particularly against the weak nations of the developing world.\n\u201cSince the Six-Day War, Europeans began to see Israel in a very similar light. Indeed, it was after this event in particular, that the link between Israel and the United States became a pernicious and indelible staple of European politics and discourse until the present. In Western Europe as well as the United States, left-wing intellectuals began to perceive Israel as America\u2019s pit bull after the Six-Day War. Israel became America\u2019s tool in the latter\u2019s imperialist designs on the Middle East and beyond.\n\u201cRecently the imagery presented by these people has become completely inverted. Since the Second Gulf War of the early 1990s, and a fortiori during the current Iraq conflict, many have come to view the United States as Israel\u2019s tool. The European and American left \u2013 as well as the right \u2013 have come to view the current war against Iraq as a thinly disguised American proxy for Israel\u2019s purposes. Attributing this American policy to a neo-conservative cabal whose members are openly \u2013 and constantly \u2013 identified as Jewish by both the left and right, it is a short step to argue that America has become the willing executor of Israel\u2019s wishes and desires. The old anti-Semitic trope of America being controlled by East Coast Jews and manipulated to act in the Jews\u2019 interest seems more than coincidental.\u201d\nEuropeans Seeing Themselves as Embodiments of Virtue\n\u201cHistorically speaking, and even after 1945, anti-Americanism and anti-Semitism were much more pronounced on the European right than on the left. Traditionally, all the mythologies of the right were linked to land, church, holiness, and aristocracy, and the right has been more concerned than the left about modernity and the fear of its undermining traditional collectives. The left \u2013 at least until its \u2018New Left\u2019 variant of the late 1960s \u2013 was much more accepting of modernity.\n\u201cMany Europeans see themselves as the embodiments of virtue. They blame both the United States and Israel for behaving like Europe did before 1945. They try to sell the argument that Western Europe has become a post-national, multilateral, multicultural, and above all post-statist entity, to which old style realpolitik is anathema. They claim that America and Israel, on the contrary, follow such a policy with the assertive, unilateral, and particularistic characteristics that were typical of pre-1945 Europe, which the new \u2018good\u2019 Europe has learned to reject.\n\u201cThe power element as a main motif in the anti-Israeli discourse also becomes very clear from another perspective. When I was in Berlin a few years ago, thirty graves were desecrated at the big Weisensee Jewish cemetery. Some of the most overt and vehement critics of Israel participated in the protest demonstration against this desecration. They saw this as a nasty act because it targeted dead Jews directly, and the small Jewish community currently living in Germany indirectly. European anti-Semitism has changed in the sense that it is illegitimate to express hatred for powerless Jews, i.e. Jews living in Europe. The resentment is now reserved almost exclusively for Israel and \u2013 of late \u2013 Jews in America, the much-maligned \u2018East Coast.\u2019\n\u201cThat is why European elites which have reveled in criticizing Israel at every possible turn oppose overt discrimination against the powerless Jews in Europe, even though the threshold of shame about anti-Semitism has been lowered significantly over the past decade. European Jews are not in the physical danger they were in the 1920s or 1930s, nor is today\u2019s anti-Semitism the same as it was in that period. Certain Jewish individuals in Europe might face physical assaults as Jews, but the Jews as a collective are not physically threatened the way they were before World War II.\u201d\nAbsolving Europe\u2019s Relationship to its Past\n\u201cAs far as Israel is concerned there is an additional dimension that is not relevant to anti-Americanism. Europe has a major unresolved relationship with its past. The constant analogizing of Israelis with Nazis comes from the European gut. This, of course, is a double effrontery. By doing this, Europeans absolve themselves of their own history. At the same time they succeed in accusing their former victims of behaving like their worst perpetrators. This discourse is not new. It was already widespread during and after the 1982 Lebanese War when \u2013 for instance \u2013 a German newspaper featured side-by-side on its front page the infamous photograph in the Warsaw ghetto of a Nazi soldier marching behind a little Jewish boy who was holding up his hands, and a parallel photo of an IDF soldier marching behind Arab youngsters in Beirut.\n\u201cThese attacks must focus on Israel because old style anti-Semitism is part of an easily identifiable racism which is not publicly acceptable discourse in today\u2019s \u2018virtuous\u2019 Europe, even though it exists unabated. Israeli psychiatrist Zvi Rex was correct in saying that the Germans will never forgive the Jews for Auschwitz. In an analogous manner, I would argue that Western Europeans will also never forgive the Americans for being daily reminders that it was the Americans \u2013 together with the Red Army \u2013 who defeated Nazism, and not the Europeans themselves. Impotence breeds resentment, which in turn breeds disdain, hatred, and contempt.\n\u201cBy constantly repeating the warped analogy of the Israelis with the Nazis, Europeans absolve themselves from any remorse and shame, and thus experience a sense of liberation. They know how to hurt the intended target by equating it with the very perpetrators who almost wiped it off the earth in the most brutal genocide imaginable. No other vaguely comparable conflict has attained in Europe anywhere near the shrillness and acuity as has the Israeli-Palestinian conflict; not the mass murders in Chechnya, not the ones in the many post-Yugoslav wars, and not the murders of Muslims at the hands of Serbs and Croats.\n\u201cA new tone has emerged among European intellectuals. Criticizing Jews \u2013 and not just Israel and Israelis \u2013 has attained a certain urgency that reveals a particularly liberating dimension. \u2018Free at last, free at last, we are finally free of this damn Holocaust at last!\u2019 In this context Europeans posit that Jews \u2013 who created a culture of guilt and shame for Europeans, and kept them from speaking their minds as they wished \u2013 now behave just like they did. The lid is off; Jews are once again legitimate targets.\u201d\nLeft-wing Anti-Semitism: Hiding behind Anti-Zionism\n\u201cSince the Second World War \u2013 and especially since the ascent of the New Left in the late 1960s \u2013 left-wing anti-Semitism has remained conveniently veiled by anti-Zionism. However, the European left\u2019s hatred of Israel has become much more potent over the last 15-20 years for one crucial reason: it is the left\u2019s language and discourse \u2013 not the right\u2019s \u2013 that have been adopted by the European mainstream.\n\u201cThe right \u2013 mainly by dint of the continued illegitimacy and unacceptability of Nazism and fascism in European public opinion \u2013 has had a much more circumspect influence on public opinion pertaining to Jews and Israel than the left. Because classical anti-Semitism \u2013 certainly in its praxis \u2013 was mostly associated with the European right, the left enjoyed a certain bonus when it came to discussing all matters relating to Jews and Israel. The left could take liberties with being anti-Israeli and anti-Semitic that the right could never take. This bonus enabled the left to employ anti-Israeli discourse that \u2013 in the meantime \u2013 has become completely common and acceptable parlance in Europe.\n\u201cBecause of this general acceptability and overall legitimacy, left-wing anti-Semitism is much more relevant and disturbing than right-wing anti-Semitism, which has remained essentially the same, without mutations. Today\u2019s neo-Nazis are ugly and generally unpleasant, but as they are beyond the pale of acceptable European discourse, they are not particularly dangerous. To borrow an analogy from an American automobile commercial: right-wing anti-Semitism was your father\u2019s anti-Semitism. It is obsolete.\n\u201cThe Guardian, the BBC, The Independent, in short the bulk of Britain\u2019s \u2013 indeed Europe\u2019s \u2013 leading and respectable media, did not become anti-Israeli under the influence of the National Front but due to changes in European attitudes and the altered nature of discourse among Europe\u2019s intellectuals in the wake of the late 1960s. When I\u2019m in a hotel in Europe and switch on the television to see the news on the Middle East, it is very clear, by the words used and codes employed, where the sympathies lie. Being openly anti-Israeli is no longer limited to the liberal left, but has become more or less acceptable public discourse in virtually all Western European countries.\n\u201cIt is by dint of this left-liberal voice, not the right\u2019s old-style anti-Semitism, that 59 percent of Europeans viewed Israel as being the greatest threat to peace, putting this country in first place ahead of countries such as Iran, North Korea, the United States (!), Iraq, Afghanistan, and Pakistan, in that order. China was mentioned by 30 percent of the respondents, placing it in eleventh place, and Russia by 21 percent, thus ranking it as number 13. Not surprisingly, Europeans had the best opinion about themselves, placing Europe as dead last in terms of representing any danger to world peace. Only 8 percent of the respondents listed the European Union or any of its members as threats to peace. The respondents in the Netherlands were particularly critical of Israel, viewing it as a threat to peace by a whopping 74 percent. The equivalent figure in Germany was 65 percent. These results should not come as a surprise to anybody who has followed the one-sided reporting of the Palestinian-Israeli conflict by the vast majority of the European press for quite some time now, particularly since the beginning of the so-called second Intifada in September 2000.8\n\u201cIt is becoming increasingly common in certain extreme right-wing \u2013 and of course left-wing \u2013 circles in Europe to seek out radical Islamists as allies. Jews and Americans receive pride of place in the hierarchy of their respective hatreds, thus fostering this otherwise bizarre alliance. After all, right-wing extremists everywhere \u2013 Europe included \u2013 adhere to racist views and detest peoples hailing from different cultures, speaking foreign languages, and following other religious beliefs. German neo-Nazis do not like Palestinians or other Muslims but they hate Jews and Americans even more. They thus establish a convenient common ground between themselves and others who hate Jews and Americans as much as they do. Anti-Semitism has thus yet another voice in these highly pluralistic and democratic societies, with their often very receptive audiences.\n\u201cThis development reinforces my view that among all the prejudices that have beset European history, anti-Semitism has constantly assumed a place all its own. It is related to racism yet different from it, furnishing its own category. It is also back with a vengeance in acceptable European discourse.\u201d\nCommon Icons of the Left and the Neo-Nazis\n\u201cIf one were to list the major icons that defined the core of what it means to be left-wing these days, to be a progressive, there is no doubt that an active antipathy toward Israel and the United States would be on this list. Most likely both enmities would hover around the top of the list rather than its bottom. The sad fact is that a dislike of and disdain for Israel and the United States have become as essential to being a progressive as are income redistribution, the defense of workers\u2019 rights, the protection of the environment, and feminism. Tellingly, virtually none of the other items on this list would appear \u2013 almost by definition \u2013 on an equivalent list that defines what it means to be a rightist in contemporary Europe. However, antipathies toward the United States and Israel \u2013 and openly against Jews \u2013 would surely also assume pride of place on that list.\n\u201cTo be sure, open hostility toward and resentment of all things American is voiced with even greater abandon than similar sentiments pertaining to Israel. This is certainly still the case among left-wing intellectuals in Germany and Austria, where an unbridled hostility toward Israel is still not completely acceptable due to the shadow of Auschwitz \u2013 unlike in France and Belgium, the two most egregious examples. It is not that German and Austrian left-wing intellectuals hold views that differ substantially from their counterparts in the rest of Europe. It is just that the threshold of shame vis-\u00e0-vis all things Jewish \u2013 including Israel \u2013 is still a tad higher than elsewhere in Europe. But the current situation\u2019s massive deterioration is best exemplified by the fact that in Vienna a memorial for Kristallnacht on 9 November, 2003 was disrupted not by right-wing but left-wing \u2018anti-racist\u2019 radicals. To be sure, their action received much praise by representatives of the far right.\n\u201cWhat drives the liberal left in Europe is dislike and hatred of Israel and America, and not a genuine sympathy for and identification with downtrodden Muslims. When Slobodan Milosevic and his associates were busily killing thousands of Muslims in Bosnia and Kosovo, the European left remained very quiet, in effect objectively taking the side of the Serbian perpetrators. It was not the slaughter of innocent Muslim women and children that really riled the European left. Instead, what mobilized thousands in the streets of Berlin, Paris, and Athens once the much-belated step was taken to intervene on behalf of the brutalized Muslims, was once again the American bogeyman.\n\u201cNo far right in Europe has a more nasty anti-Serbian history than the German and Austrian, both of which have been long-time supporters of the most vicious anti-Serbian fascists in Croatia and elsewhere. Still, their hatred of Serbs could not compete with their hatred of Americans, and once the United States intervened against the Serbs on behalf of the Bosnian Muslims and their Kossovar co-religionists, German and Austrian neo-Nazis and far rightists rallied to Milosevic\u2019s side in their unmitigated condemnation of NATO\u2019s American-led interventions.\u201d\nAnti-Americanism: A Producer of Identity\n\u201cThe debates about a European identity, European constitution, and what will constitute the soul, flesh, and blood of this new entity \u2013 never mind its skeleton which is now being gradually put into place \u2013 have not even begun yet. We have no idea what shape it will take, where it will go, who will lead it, or who will be the winners and losers. But one thing is certain: in order to create common values, counter-values are always necessary. One can only become something by clearly defining what one does not want to be. It is in this context that anti-Americanism \u2013 perhaps for the very first time in 200-plus years of its European history \u2013 has assumed a clear and important function: that of helping to forge a common ground among otherwise very disparate entities.\n\u201cNo mobilization around these European counter-values could have been more emphatic than the huge demonstrations on Saturday, 15 February 2003. Never before in Europe\u2019s history did so many millions of Europeans unite in public on one day for one purpose. From London to Rome, Paris to Madrid, Athens to Helsinki, Barcelona to Berlin, Europeans across most of the political spectrum united in their opposition to America\u2019s impending attack on Iraq. Many of the demonstrators carried anti-Israeli slogans. This was an immensely impressive and powerful expression of genuine public sentiment in which we could observe a complete congruence \u2013 a voluntary and democratic \u2018Gleichschaltung\u2019 \u2013 between Europe\u2019s elites and masses, between the right and the left, and between government and opposition. Those few governments that dissented \u2013 notably the British, the Spanish, the Italian, and some in Eastern Europe \u2013 constituted lonely voices in a much more powerful choir of uniformity that shouted unmistakably: Europe will define itself in opposition to the United States. This opposition was not only aimed at the current policies of this particular administration, but at the values and characteristics that Europeans viewed as comprising the core of what it means to be American.\n\u201cA number of European intellectuals \u2013 quite correctly in my view \u2013 proclaimed this day as the one historians will someday view as the true birthday of a united Europe. Unlike any other day in European history, it united Europeans emotionally, and not just through the decisions of a faceless bureaucracy issued in impenetrable language from Brussels.\u201d\n\u201cThus there is no doubt that anti-Americanism is much more than just a conjunctural phenomenon in Europe, a temporal fad. Instead, its existence is structural; America is \u2018un-Europe\u2019 or Europe\u2019s \u2018other\u2019. Its function is to help create a common political European identity. As such, this structure will grow in importance and will remain present for a very long time. Anti-Americanism has always existed among Europe\u2019s elites. In the course of the past three years, there developed \u2013 perhaps for the very first time \u2013 a congruence between elites and masses on this sentiment.\u201d\nNotes\n1. Alvin H. Rosenfeld, Anti-Americanism and Anti-Semitism: A New Frontier of Bigotry (New York: American Jewish Committee, 2003), p. 21.\n2. Richard Landes, \u201cWhat Happens when Jesus Doesn\u2019t Come: Jewish and Christian Relations in Apocalyptic Time,\u201d Terrorism and Political Violence, volume 14, Spring 2002, (London: Frank Cass, 2002).\n3. Ira Strauss, \u201cIs it anti-Americanism or anti-Westernism?\u201d (unpublished paper, 2003).\n4. Cornelius de Pauw, \u201cRecherches philosophiques sur les americains,\u201d Oeuvres philosophiques, volume 1 (1974): II [French].\n5. Dan Diner discusses de Pauw, de Buffon, and other authors and thinkers of the time in his Feindbild Amerika: Ueber die Bestaetigung eines Ressentiments (Munich: Propylaen Verlag, 2002) [German].\n6. Daniel Jonah Goldhagen, \u201cThe Globalization of Anti-Semitism,\u201d The Forward, 2 May 2003.\n7. See Rosenfeld, Anti-Americanism and Anti-Semitism: A New Frontier of Bigotry, p. 9.\n8. \u201cEuropaer sehen Israel als Bedrohung,\u201d Frankfurter Allgemeine Zeitung, 3 November 2003 [German]. \u201cEuropaeisches Misstrauen gegenueber Israel und den USA. Ergebnisse der Eurobarometer-Umfrage,\u201d Neue Zuercher Zeitung, 3 November 2003 [German].\nInterview by Manfred Gerstenfeld\n* * *\nAndrei S. Markovits was born in Timisoara, Romania in 1948. He emigrated to the United States in 1960, but spent the bulk of his teenage years in Vienna before returning to New York in 1967 to attend Columbia University where he received all five of his university degrees. He is the Karl W. Deutsch Collegiate Professor of Comparative Politics and German Studies at the University of Michigan in Ann Arbor. Among his books are: The German Left: Red, Green and Beyond (New York: Oxford University Press, 1993) and The German Predicament: Memory and Power in the New Europe (Ithaca: Cornell University Press, 1997). His latest book is Offside: Soccer and American Exceptionalism (Princeton: Princeton University Press, 2002).\n* * *\nThis publication was partly supported by the Fondation pour la Memoire de la Shoah."
    },
    {
      "url": "https://www.zdnet.com/article/yes-you-need-a-firewall-on-linux-heres-why-and-which-to-use/",
      "text": "Yes, you need a firewall on Linux - here's why and which to use\nZDNET's key takeaways\n- Linux is highly secure, but you should still have a firewall.\n- You should know if your ISP's hardware (gateway) uses a firewall.\n- One of the easiest Linux firewalls is UFW and its GUI sidekick, GUFW.\nI've been using Linux for nearly 30 years. Over those years, I've experienced only one security issue (a rootkit on a server I inherited). The reason for that is Linux's heightened security. Out of the box, it includes a tight permissions system and security mechanisms (such as AppArmor and SELinux) that do an amazing job of locking down the operating system.\nBut what about the firewall? You know about firewalls, especially if you've used Windows (because Microsoft's OS has always depended on them). And before you think it, no matter how secure your web browser is, it's not enough.\nAlso: Thinking about switching to Linux? 9 things you need to know\nAlmost every Linux distribution ships with a firewall that is ready to use. Oddly enough, however, some distributions ship with the firewall disabled.\nThat seems counterintuitive for an operating system that hangs its hat on security.\nThe big question you may ask is, \"Does Linux even need a firewall?\"\nBefore answering that question, I'll ask you some questions:\n- Is your Linux machine on a home network?\n- Does your home network have a router that includes a firewall?\n- Is your router regularly updated?\n- If your home network has a router with a firewall, are there any ports open?\n- Do you have sensitive data on your computer?\nYou might not know the answers to those questions, which means you might have to contact your ISP and ask them about the hardware in use. For example, AT&T Fiber does include a firewall on its gateway hardware. Comcast's Xfinity gateways also include a firewall.\nAlso: 8 things you can do with Linux that you can't do with MacOS or Windows\nIf you know your ISP hardware includes a firewall, the need for a firewall on your Linux machines is less pressing than otherwise.\nBut does that mean you should forget about the firewall?\nI say, no.\nI say, the more security, the better.\nFor example, your ISP's gateway goes without updates, which could leave it vulnerable to attacks. Some ne'er-do-well figures out what gateway you're using, breaks through its unpatched defenses, and has access to your network. If your Linux machine isn't protected via a firewall, that bad actor could access the machine through an open port and have at the data it contains.\nYou don't want that.\nErgo\u2026 firewall.\nBut which one should you use?\nDifferent distributions ship with different firewalls. For example, Ubuntu (and those based on Ubuntu) ship with Uncomplicated Firewall (UFW), whereas Fedora (and those based on Fedora) ship with firewalld. Although both are solid options, I give the nod to UFW because it's so easy to use. And if you don't want to use the command line, there are GUI apps you can install to control UFW.\nAlso: You can try Linux without ditching Windows first - here's how\nEven from the command line, UFW is easy. To enable it, issue the command:\nsudo ufw enable\nOnce enabled, all ports are closed, and accessing your machine is made exponentially more challenging. Let's say, however, that you regularly use SSH to access that machine from your LAN. For that, you could issue the command:\nsudo ufw allow ssh\nOr maybe you want to only allow SSH from a single IP address within your LAN, which can be done with:\nsudo ufw allow from IP_ADDRESS to any port 22 proto tcp\nWhere IP_ADDRESS is the address of the machine you want to allow in.\nThose same actions with Firewalld look like this:\nsudo firewall-cmd --zone=public --permanent --add-service=ssh\nOr\nsudo firewall-cmd --permanent --add-source=IP_ADDRESS --zone=drop\nsudo firewall-cmd --permanent --add-service=ssh\nsudo firewall-cmd --reload\nsudo firewall-cmd --list-all --zone=drop\nsudo firewall-cmd --list-all\nWhere IP_ADDRESS is the address of the machine you want to allow in.\nObviously, UFW is the easier tool, and I would always recommend it over firewalld for those who are just getting into Linux.\nAnd if you want a GUI for UFW, try GUFW (which can be installed from your GUI app store).\nIn the end, the answers to the questions are simple:\n- Do you need a firewall on Linux? - yes\n- Which one should you use? - UFW\nUnderstand that if you want to use UFW on Fedora-based systems, you must install it. To do that, issue the following commands:\nsudo systemctl stop firewalld\nsudo systemctl disable firewalld\nsudo dnf remove firewalld\nsudo dnf install ufw\nsudo ufw enable\nYou now have UFW running on your Fedora-based distribution.\nWith a firewall active, your Linux machine will be better protected, should someone get around the defenses of your ISP's hardware. As always, it's better to be safe than sorry.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://www.facticity.ai/",
      "text": "Get started for free.\n\"In a world of disinformation, Facticity.AI, an artificially intelligent fact-checking tool developed by Singapore start-up AI Seer, seeks to tip the scales in the truth\u2019s favor. Facticity\u2019s online tool, released in beta in June, checks claims in text and video, and provides references and links to reliable sources. The company claims 92% accuracy, beating competitor tools like Bing CoPilot, Perplexity, and Originality.ai (which claims about 72% accuracy on fact-checking). Facticity was put to the test during the most recent presidential debate, checking almost 250 claims in near real-time.\"\nFacticity.AI Use Cases\nAcross Professions\nEmpowering Professionals with Reliable\nSocial Media and Multilingual AI Fact-Checking\nJournalists & Editors\nwho need to fact-check news articles, reports, and user-generated content to ensure accuracy and credibility.\nMarketing & PR Professionals\nwho need to validate advertising claims, press releases, and competitor insights to maintain brand trust\nRegulated Industries & Compliance\nwho need to validate medical claims, clinical research, and pharmaceutical data to ensure compliance\nResearchers & Academics\nwho need to cross-check references, research data, and scholarly articles to ensure accuracy in publications.\nGoing Viral Among Informationally Literate Influencers\nJoin Information Literate Users from\nDiverse Content Creation and Analysis Organization who are recommending our app\nTrending #Fact-Checked Claims\nBenchmark Dataset\n92% Fact-Checking Accuracy\nFact Checking Tool | Accuracy (%) |\n|---|---|\nFacticity.AI | 92% |\nPerplexity.AI | 88% |\nBing Copilot with ChatGPT-4 | 78% |\nOriginality.AI | 72% |\nFacticity.AI Achieves Lowest Citation Error Rate at 14% in Benchmark Test\nBenchmarking Dataset provided by Columbia's Graduate School of Journalism\nAfter running the benchmark dataset on 200 entries, Facticity.AI demonstrated the lowest rate of completely incorrect and partially incorrect citations compared to other AI search models.\n(Lower is better)\nApplication | Percentage of Completely + Partially Incorrect |\n|---|---|\nFacticity.AI | 14% |\nChatGPT Search | 67% |\nPerplexity | 42% |\nPerplexity Pro | 45% |\nDeepseek Search | 67.5% |\nCopilot Search | 42% |\nGrok-2 Search | 77% |\nGrok-3 Search | 94% |\nGemini Search | 81% |\nMultilingual Dataset\nLanguage | Accuracy (%) |\n|---|---|\nEnglish | 89% |\nChinese | 84% |\nMalay | 91% |\nTamil | 87% |\nThai | 82% |"
    },
    {
      "url": "https://adfontesmedia.com/",
      "text": "Know the Reliability and Bias of the News\nHome of the\nMedia Bias Chart\u00ae\n- Actionable data for advertisers, publishers, and tech platforms\n- Media literacy tools for educators and individuals\nNavigate the News Landscape with Confidence\nIn a biased and misleading news landscape, it\u2019s essential to know where your information is coming from. That\u2019s why we founded Ad Fontes Media: to help you navigate and know your news sources \u2014 in one place.\nOur analysts come from a wide political spectrum and follow a careful, robust methodology to rate the news. Whether you\u2019re a business, individual consumer, educator, or running a social media platform, you can use Ad Fontes Media to make better decisions.\nOur Enterprise Customers and Partners\nWe work with some of the most influential companies in the information ecosystem. Meet our partners.\nOur Community\nMembers of our community, whom we affectionately call \u201cNews Nerds,\u201d play a critical role in supporting our work and making sure it has an impact in the world. When you become an annual News Nerd member, you get a merchandise pack with a Media Bias Chart wall poster and a coffee mug, in addition to several other benefits, including:\n-Premium access to our Interactive Media Bias Chart\n-Rating requests\n-Discounts on additional merchandise\nDifferentiate news sources to make the best decisions\nAd Fontes Media helps businesses, consumers, educators, and platforms navigate today\u2019s complex and dynamic news landscape. We provide data, tools, and educational resources for all stakeholders in quality news media.\nBrands, Agencies, and Platforms\nGet great business results by advertising on high-quality news.\nNews Consumers\nKnow the reliability and bias of the news and information sources you consume. Help your friends and family improve their media literacy.\nEducators, Researchers, and Institutions\nTeach news literacy effectively. Access data to inform your research.\nPublishers\nShowcase your high reliability rating from Ad Fontes Media to improve monetization.\nWe Rate the News for Reliability and Bias to Help You Keep Track of the Media Landscape\nFind the best information sources. Invest in responsible journalism. Make the news media industry healthier in the long run.\nWhere do Your Favorite Sources Fall?\nWith Ad Fontes Media, you can see the reliability and bias of new sources."
    },
    {
      "url": "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nIt's only been almost three years since generative artificial intelligence (AI) hit the mainstream as a new paradigm of productivity, but here we are -- it's everywhere.\nI test AI tools as part of my work. I'll dig into just about any AI-related technology and see what I can make it do. Many of you have read my ongoing shootouts comparing AIs for programming and AI content checkers, among other kinds of tools.\nBut that's using AI in a rigorous lab environment to provide test results to ZDNET readers. Like many of you, I've also started using AI to augment my workflow and increase my productivity.\nAlso: The best AI for coding in 2025 (and what not to use)\nI wear a lot of hats; I run a small business with my wife, who also has her own business, where I'm the tech guy and designer. I also work with a number of industry groups. I have a fairly popular security software product for WordPress users. And I'm constantly working on projects, ranging from 3D printing the ultimate charging tower, to trying to make an AI-assisted Etsy store, to composing and publishing music, and using an AI for help with some of the marketing activities.\nI should note that I never, ever use AI to produce my core content. No article, song, or social media post is ever written using an AI tool. My work product is mine. But I do use AI to help me get through other aspects of my workload.\nI have a particular interest in how AI helps programming, how AI can support graphics work, and how AI can support video production.\nHere are the tools I'm willing to pay for -- and why.\n1. ChatGPT Plus - $20/mo\nSpeaking of AI and programming, it has essentially doubled my programming output. I use AI to help me with common-knowledge programming. I talked about it in-depth in my 25 tips article, but the core benefit is getting ChatGPT to write code for published APIs, so I don't have to spend time searching for code examples and trying to reverse-engineer comments on various programming boards.\nAnd yes, I mentioned ChatGPT. While more chatbots capable of passing my programming tests have been introduced in the last year, ChatGPT does the job well enough, and hey, who wants another monthly fee?\nAlso: How ChatGPT actually works (and why it's been so game-changing)\nIn fact, that's a big part of why I'm paying $20/mo for ChatGPT Plus. Sure, I've signed up and paid for some of the other AIs just to test them, but ChatGPT Plus is the only chatbot I have found so consistently useful that I keep it as a regularly used tool.\nI use ChatGPT for lots of research tasks, sometimes throwing math problems at it, and all sorts of other questions and problems I'm dealing with. While I never take its output as an unimpeachable source of truth, I do find ChatGPT to be a very useful sounding board, substantially more so than a quick Google search.\nNow, to be fair, I did outline five ways that an AI could help me in Gmail. If Gemini could do these things reliably, I'd sign back up in a heartbeat. But I just don't need the current email message I'm reading summarized, and I sure don't need it to write a friendlier or more professional version of whatever I've currently written. I tried Gmail's new AI unsubscribe feature, and it only found about 10 newsletters, yet I get thousands of emails and hundreds of newsletter-style messages every day. So, I'm leaving that one unbought.\n2. Midjourney - $10/mo\nI played around a lot with DALL-E, ChatGPT's earlier image generation tool. But recently, OpenAI introduced a new image generator in GPT-4o, and it's quite the beast. I have found that it generates great results, but it has more guardrails than another tool I pay for, Midjourney.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nBut even though I get image generation with my $20/mo ChatGPT Plus fee, I pay an extra $10/mo for Midjourney. Why?\nOne of the reasons is subjective. I like a lot of the images I get with Midjourney. Midjourney also allows me to describe artist styles, and lets me riff off a vast array of stylistic choices. ChatGPT, perhaps because of guardrails imposed by OpenAI, doesn't present as many choices.\nBut I also have two specific and objective reasons for paying for Midjourney. First, because image generation is so subjective, it's nice to have a variety of tools when seeking a representation of what you have in your head. I'll try different prompts and even the same prompts with both tools and take what works best.\nAlso: How to selectively modify a Midjourney image to create an artistic statement\nSecond, every month I generate a promotional image for my wife's online business. She has an e-commerce site that supports a popular hobby. Each month, on her very active Facebook group, she gives a craft-along theme to her users. I generate an image for that theme. Over the months, I've found that Midjourney does a far better job of generating an image that incorporates elements of the hobby. That said, some months I bounce back and forth between both tools until I can get an image that meets her business's needs.\nBecause Midjourney shaves what used to be two to three hours of work pushing pixels in Photoshop to generate those images down to about 10 minutes, it's worth the $10/month to me just for that project.\nPhotoshop Generative Fill - Honorable mention\nIn the title of this article, I said I pay for two AI tools. That's sort of true. I pay for Adobe's Creative Cloud suite in addition to ChatGPT Plus and Midjourney. But since I've been using and paying for Creative Cloud -- and before that, Photoshop -- long before there was generative fill, I'm not counting it in my AI tools list.\nAlso: I use Photoshop's AI tool every day - here are my 5 essential tips for the best results\nIf Adobe removed generative fill tomorrow, I'd still pay for Photoshop. To be clear, I don't like paying for it. It's costly, and the two-computer license limitation is restrictive. But a few years back, I tried switching to Affinity Photo, which at the time was $50 (it's now $70). That one-time fee is roughly what I pay each month for Creative Cloud, so it had a lot of potential.\nTo be clear, Affinity Photo is a fine application. But I've been using Photoshop since before the Clinton administration. To say I have Photoshop muscle memory is an understatement. It's a product I use almost every day. Switching to another application, while I could do it if I had to, slows down my workflow considerably.\nAlso: What to do if Generative Fill is grayed out in Adobe Photoshop AI\nSo, I don't consider my monthly expense for Creative Cloud to be an AI expense. That said, I find generative fill (and its various other AI tricks) very helpful. I often use it in concert with Midjourney and ChatGPT image generation.\nThree tools I'm thinking about\nI run a business online and, as such, rely on a wide variety of cloud services. Those fees add up, and now they're all going up in price. So while it might be nice to add more AI tools, I'm keeping it under control. It's very easy to just click OK and find yourself spending hundreds of dollars more every month.\nThat said, I am thinking about adding three more tools. I'm a bit hesitant, because each one has its annoyances and limitations, but they're on the short list for a quick order if I can ever justify an immediate performance improvement on one project or another.\nNotion AI\nThe first is Notion AI. I am deeply invested in Notion for all my project work. I also use it to write and organize all my articles, as well as schedule them, plan them, research them, and capture notes and assets. Notion AI is interesting because it would work like NotebookLM, limiting its knowledge base to my Notion account. That could be very useful as I work on more projects. But at one point, when Notion overcharged my wife's account, they were completely unsupportive and unsympathetic. So, I hesitate to give them more business.\nNotebookLM Pro\nGoogle's NotebookLM Pro is another contender. Now that Pocket, the article archiving service, is being discontinued, I considered using NotebookLM Pro as a replacement. The idea that I could save articles in NotebookLM as sources and then have the AI review them, summarize them, and analyze them seemed ideal, especially as a research tool.\nBut... the free version of NotebookLM only allows 50 sources per notebook. The Pro version, which is normally another $20/mo ( you can usually get a few starter months at a discounted rate), increases that limit, but only to 300 sources per notebook. My archive has well over 30,000 sources, which is beyond NotebookLM's limits. There is a $249/month plan (yowzah!), but all Google will say about limits is \"Highest limits and best model capabilities (later this year)\". What does that even mean?\nDescript\nDescript (for $16-$24/mo) is an AI video editing tool. This isn't a tool that does text-to-video generation. Instead, it's a tool that helps you take your video clips and edit them. Right now, I'm a very big Final Cut Pro user. Final Cut has added some AI features, but it lags far behind DaVinci Pro and Premiere Pro (because Apple lagging in AI is no surprise, right?).\nAlso: How to use ChatGPT to write code - and my top trick for debugging what it generates\nDescript automatically removes filler words and retakes, cleans up sound quality without any fuss, and does automatic multicam editing. It also promises to take long-form videos and automatically create clip videos, which could be a huge time-saver. The product also has some more \"out there\" features which I wouldn't use, including fake avatar generation and fake speech generation.\nThe thing is, Descript is aimed more at multiple talking head videos. I'm not sure it could handle the sort of in-depth technical hands-on project videos I do. So, it's still in the \"maybe someday\" category, for now at least.\nWhat do you use?\nDo you pay for any AI tools? Which ones, and why? Is there an AI tool that you strongly recommend I should be using that I didn't mention? Feel free to answer these questions and let us know your thoughts on AI subscriptions in the comments below.\nWant more stories about AI? Sign up for Innovation, our weekly newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.pbs.org/newshour/world/how-russian-disinformation-campaigns-have-sought-to-undermine-the-paris-olympics",
      "text": "By \u2014 David Klepper, Associated Press David Klepper, Associated Press Leave your feedback Share Copy URL https://www.pbs.org/newshour/world/how-russian-disinformation-campaigns-have-sought-to-undermine-the-paris-olympics Email Facebook Twitter LinkedIn Pinterest Tumblr Share on Facebook Share on Twitter How Russian disinformation campaigns have sought to undermine the Paris Olympics World Aug 7, 2024 3:07 PM EDT WASHINGTON (AP) \u2014 The actor in the viral music video denouncing the 2024 Olympics looks a lot like French President Emmanuel Macron. The images of rats, trash and the sewage, however, were dreamed up by artificial intelligence. Portraying Paris as a crime-ridden cesspool, the video mocking the Games spread quickly on social media platforms like YouTube and X, helped on its way by 30,000 social media bots linked to a notorious Russian disinformation group that has set its sights on France before. Within days, the video was available in 13 languages, thanks to quick translation by AI. WATCH: Why French authorities fear Russia may attempt to disrupt Paris Olympics \u201cParis, Paris, 1-2-3, go to Seine and make a pee,\u201d taunts an AI-enhanced singer as the faux Macron actor dances in the background, seemingly a reference to water quality concerns in the Seine River where some competitions are taking place. Moscow is making its presence felt during the Paris Games, with groups linked to Russia\u2019s government using online disinformation and state propaganda to spread incendiary claims and attack the host country \u2014 showing how global events like the Olympics are now high-profile targets for online disinformation and propaganda. Over the weekend, disinformation networks linked to the Kremlin seized on a divide over Algerian boxer Imane Khelif, who has faced unsubstantiated questions about her gender. Baseless claims that she is a man or transgender surfaced after a controversial boxing association with Russian ties said she failed an opaque eligibility test before last year\u2019s world boxing championships. Russian networks amplified the debate, which quickly became a trending topic online. British news outlets, author J.K. Rowling and right-wing politicians like Donald Trump added to the deluge. At its height late last week, X users were posting about the boxer tens of thousands of times per hour, according to an analysis by PeakMetrics, a cyber firm that tracks online narratives. The boxing group at the root of the claims \u2014 the International Boxing Association \u2014 has been permanently barred from the Olympics, has a Russian president who is an ally of Russian President Vladimir Putin and its biggest sponsor is the state energy company Gazprom. Questions also have surfaced about its decision to disqualify Khelif last year after she had beaten a Russian boxer. READ MORE: What is the IBA? Governing body behind Olympic boxing storm has Russian ties, troubled history Approving only a small number of Russian athletes to compete as neutrals and banning them from team sports following the invasion of Ukraine all but guaranteed the Kremlin\u2019s response, said Gordon Crovitz, co-founder of NewsGuard, a firm that analyzes online misinformation. NewsGuard has tracked dozens of examples of disinformation targeting the Paris Games, including the fake music video. Russia\u2019s disinformation campaign targeting the Olympics stands out for its technical skill, Crovitz said. \u201cWhat\u2019s different now is that they are perhaps the most advanced users of generative AI models for malign purposes: fake videos, fake music, fake websites,\u201d he said. AI can be used to create lifelike images, audio and video, rapidly translate text and generate culturally specific content that sounds and reads like it was created by a human. The once labor-intensive work of creating fake social media accounts or websites and writing conversational posts can now be done quickly and cheaply. Another video amplified by accounts based in Russia in recent weeks claimed the CIA and U.S. State Department warned Americans not to use the Paris metro. No such warning was issued. Russian state media has trumpeted some of the same false and misleading content. Instead of covering the athletic competitions, much of the coverage of the Olympics has focused on crime, immigration, litter and pollution. One article in the state-run Sputnik news service summed it up: \u201cThese Paris \u2018games\u2019 sure are going swimmingly. Here\u2019s an idea. Stop awarding the Olympics to the decadent, rotting west.\u201d Russia has used propaganda to disparage past Olympics, as it did when the then-Soviet Union boycotted the 1984 Games in Los Angeles. At the time, it distributed printed material to Olympic officials in Africa and Asia suggesting that non-white athletes would be hunted by racists in the U.S., according to an analysis from Microsoft Threat Intelligence, a unit within the technology company that studies malicious online actors. Russia also has targeted past Olympic Games with cyberattacks. \u201cIf they cannot participate in or win the Games, then they seek to undercut, defame, and degrade the international competition in the minds of participants, spectators, and global audiences,\u201d analysts at Microsoft concluded. A message left with the Russian government was not immediately returned on Monday. Authorities in France have been on high alert for sabotage, cyberattacks or disinformation targeting the Games. A 40-year-old Russian man was arrested in France last month and charged with working for a foreign power to destabilize the European country ahead of the Games. READ MORE: French authorities detain Russian man accused of plotting to \u2018destabilize\u2019 Olympics Other nations, criminal groups, extremist organizations and scam artists also are exploiting the Olympics to spread their own disinformation. Any global event like the Olympics \u2014 or a climate disaster or big election \u2014 that draws a lot of people online is likely to generate similar amounts of false and misleading claims, said Mark Calandra, executive vice president at CSC Digital Brand Services, a firm that tracks fraudulent activity online. CSC\u2019s researchers noticed a sharp increase in fake website domain names being registered ahead of the Olympics. In many cases, groups set up sites that appear to provide Olympic content, or sell Olympic merchandise. Instead, they\u2019re designed to collect information on the user. Sometimes it\u2019s a scam artist looking to steal personal financial data. In others, the sites are used by foreign governments to collect information on Americans \u2014 or as a way to spread more disinformation. \u201cBad actors look for these global events,\u201d Calandra said. \u201cWhether they\u2019re positive events like the Olympics or more concerning ones, these people use everyone\u2019s heightened awareness and interest to try to exploit them.\u201d We're not going anywhere. Stand up for truly independent, trusted news that you can count on! Donate now By \u2014 David Klepper, Associated Press David Klepper, Associated Press\nWASHINGTON (AP) \u2014 The actor in the viral music video denouncing the 2024 Olympics looks a lot like French President Emmanuel Macron. The images of rats, trash and the sewage, however, were dreamed up by artificial intelligence. Portraying Paris as a crime-ridden cesspool, the video mocking the Games spread quickly on social media platforms like YouTube and X, helped on its way by 30,000 social media bots linked to a notorious Russian disinformation group that has set its sights on France before. Within days, the video was available in 13 languages, thanks to quick translation by AI. WATCH: Why French authorities fear Russia may attempt to disrupt Paris Olympics \u201cParis, Paris, 1-2-3, go to Seine and make a pee,\u201d taunts an AI-enhanced singer as the faux Macron actor dances in the background, seemingly a reference to water quality concerns in the Seine River where some competitions are taking place. Moscow is making its presence felt during the Paris Games, with groups linked to Russia\u2019s government using online disinformation and state propaganda to spread incendiary claims and attack the host country \u2014 showing how global events like the Olympics are now high-profile targets for online disinformation and propaganda. Over the weekend, disinformation networks linked to the Kremlin seized on a divide over Algerian boxer Imane Khelif, who has faced unsubstantiated questions about her gender. Baseless claims that she is a man or transgender surfaced after a controversial boxing association with Russian ties said she failed an opaque eligibility test before last year\u2019s world boxing championships. Russian networks amplified the debate, which quickly became a trending topic online. British news outlets, author J.K. Rowling and right-wing politicians like Donald Trump added to the deluge. At its height late last week, X users were posting about the boxer tens of thousands of times per hour, according to an analysis by PeakMetrics, a cyber firm that tracks online narratives. The boxing group at the root of the claims \u2014 the International Boxing Association \u2014 has been permanently barred from the Olympics, has a Russian president who is an ally of Russian President Vladimir Putin and its biggest sponsor is the state energy company Gazprom. Questions also have surfaced about its decision to disqualify Khelif last year after she had beaten a Russian boxer. READ MORE: What is the IBA? Governing body behind Olympic boxing storm has Russian ties, troubled history Approving only a small number of Russian athletes to compete as neutrals and banning them from team sports following the invasion of Ukraine all but guaranteed the Kremlin\u2019s response, said Gordon Crovitz, co-founder of NewsGuard, a firm that analyzes online misinformation. NewsGuard has tracked dozens of examples of disinformation targeting the Paris Games, including the fake music video. Russia\u2019s disinformation campaign targeting the Olympics stands out for its technical skill, Crovitz said. \u201cWhat\u2019s different now is that they are perhaps the most advanced users of generative AI models for malign purposes: fake videos, fake music, fake websites,\u201d he said. AI can be used to create lifelike images, audio and video, rapidly translate text and generate culturally specific content that sounds and reads like it was created by a human. The once labor-intensive work of creating fake social media accounts or websites and writing conversational posts can now be done quickly and cheaply. Another video amplified by accounts based in Russia in recent weeks claimed the CIA and U.S. State Department warned Americans not to use the Paris metro. No such warning was issued. Russian state media has trumpeted some of the same false and misleading content. Instead of covering the athletic competitions, much of the coverage of the Olympics has focused on crime, immigration, litter and pollution. One article in the state-run Sputnik news service summed it up: \u201cThese Paris \u2018games\u2019 sure are going swimmingly. Here\u2019s an idea. Stop awarding the Olympics to the decadent, rotting west.\u201d Russia has used propaganda to disparage past Olympics, as it did when the then-Soviet Union boycotted the 1984 Games in Los Angeles. At the time, it distributed printed material to Olympic officials in Africa and Asia suggesting that non-white athletes would be hunted by racists in the U.S., according to an analysis from Microsoft Threat Intelligence, a unit within the technology company that studies malicious online actors. Russia also has targeted past Olympic Games with cyberattacks. \u201cIf they cannot participate in or win the Games, then they seek to undercut, defame, and degrade the international competition in the minds of participants, spectators, and global audiences,\u201d analysts at Microsoft concluded. A message left with the Russian government was not immediately returned on Monday. Authorities in France have been on high alert for sabotage, cyberattacks or disinformation targeting the Games. A 40-year-old Russian man was arrested in France last month and charged with working for a foreign power to destabilize the European country ahead of the Games. READ MORE: French authorities detain Russian man accused of plotting to \u2018destabilize\u2019 Olympics Other nations, criminal groups, extremist organizations and scam artists also are exploiting the Olympics to spread their own disinformation. Any global event like the Olympics \u2014 or a climate disaster or big election \u2014 that draws a lot of people online is likely to generate similar amounts of false and misleading claims, said Mark Calandra, executive vice president at CSC Digital Brand Services, a firm that tracks fraudulent activity online. CSC\u2019s researchers noticed a sharp increase in fake website domain names being registered ahead of the Olympics. In many cases, groups set up sites that appear to provide Olympic content, or sell Olympic merchandise. Instead, they\u2019re designed to collect information on the user. Sometimes it\u2019s a scam artist looking to steal personal financial data. In others, the sites are used by foreign governments to collect information on Americans \u2014 or as a way to spread more disinformation. \u201cBad actors look for these global events,\u201d Calandra said. \u201cWhether they\u2019re positive events like the Olympics or more concerning ones, these people use everyone\u2019s heightened awareness and interest to try to exploit them.\u201d We're not going anywhere. Stand up for truly independent, trusted news that you can count on! Donate now"
    },
    {
      "url": "https://www.zdnet.com/article/beware-of-promptware-how-researchers-broke-into-google-home-via-gemini/",
      "text": "Beware of promptware: How researchers broke into Google Home via Gemini\nZDNET's key takeaways\n- Researchers demonstrated a way to hack Google Home devices via Gemini.\n- Google put additional safeguards in place for Gemini in response.\n- Keeping your devices up-to-date on security patches is the best protection.\nThe idea that artificial intelligence (AI) could be used to maliciously control your home and life is one of the main reasons why many are reluctant to adopt the new technology -- it's downright scary. Almost as scary as having your smart devices hacked. What if I told you some researchers just accomplished that?\nAlso: Why AI-powered security tools are your secret weapon against tomorrow's attacks\nCybersecurity researchers from multiple institutions demonstrated a major vulnerability in Google's popular AI model, Gemini. They launched a controlled, indirect prompt injection attack -- aka promptware -- to trick Gemini into controlling smart home devices, like turning on a boiler and opening shutters. This is a demonstration of an AI system causing real-world, physical actions through a digital hijack.\nHow the attack worked\nA group of researchers from Tel Aviv University, Technion, and SafeBreach created a project called \"Invitation is all you need.\" They embedded malicious instructions into Google Calendar invites, and when users asked Gemini to \"summarize my calendar,\" the AI assistant triggered pre-programmed actions, including controlling smart home devices without the users' asking.\nThe project is named as a play on words from the famous AI paper, \"Attention is all you need,\" and triggered actions like opening smart shutters, turning on a boiler, sending spam and offensive messages, leaking emails, starting Zoom calls, and downloading files.\nThese pre-programmed actions were embedded using the indirect prompt injection technique. This is when malicious instructions are hidden within a seemingly innocent prompt or object, in this case, the Google Calendar invites.\nHow this affects you\nIt's worth noting that, even if the impact was real, this was done as a controlled experiment to demonstrate a vulnerability in Gemini; it was not an actual live hack. It's a way to demonstrate to Google that this could happen if bad actors decided to launch such an attack.\nAlso: 8 smart home gadgets that instantly upgraded my house (and why they work)\nIn response, Google updated its defenses and implemented stronger safeguards for Gemini. These include filtering outputs, requiring explicit user confirmation for sensitive actions, and AI-driven detection of suspect prompts. The latter is potentially problematic since AI is vastly imperfect, but there are things you can do to further protect your devices from cyberattacks.\nWhat you can do to protect your devices\nWhile this attack was launched with Gemini and Google Home, the following recommendations are good ways to protect yourself and your devices from bad actors.\n- Limit your permissions within your smart home application. Don't give Gemini, Siri, or other smart home assistants control of sensitive devices unless you need to. For example, I let Alexa access my cameras but don't let the voice assistant control my smart locks.\n- Be mindful of the services that you connect with Gemini and other voice assistants. The more devices and apps you connect to your AI assistant (like Gmail, your calendar, etc), the more potential entry points would-be attackers have.\n- Watch for unexpected behavior from your devices and AI assistants and, if something seems off, revoke permissions and report it.\nAlso: Best antivirus software: My favorites, ranked, for personal device security\nAs a rule of thumb, you should always keep your devices and apps up-to-date with the latest firmware updates. This ensures that you get the latest security patches to ward off attacks.\nWant more stories about AI? Sign up for Innovation, our weekly newsletter."
    },
    {
      "url": "https://www.forrester.com/what-it-means/ep365-top-threats-2024/",
      "text": "Featuring:\nBrian Wrozek, Principal Analyst & Janet Worthington, Senior Analyst\nShow Notes:\nThe era of AI holds an amazing amount of promise \u2014 and an amazing amount of risk. Powerful new AI tools give bad actors the capability to create more advanced and realistic threats every day. It\u2019s no wonder the level of burnout in cybersecurity continues to be high.\nWhat are the top new threats CISOs need to be aware of in 2024, and how can they be countered? In this episode Principal Analyst Brian Wrozek and Senior Analyst Janet Worthington review the top five security threats for 2024 as outlined in a new Forrester report.\nThe discussion starts by focusing on the current state of cyber attacks, with Worthington sharing some unsettling statistics. She says Forrester regularly surveys organizations about how many times their organization has been breached in the past 12 months. Two years ago, 63% said they had been breached at least once in the past year. This year, that number rose to 78%. \u201cEven more concerning is the number of organizations that said that they have been breached anywhere from six to 10 times,\u201d she says. \u201cLast year, that number was only 9%. This year, that number has jumped to 22%. So we\u2019re really seeing more organizations are getting breached and more frequently.\u201d\nWith that as a backdrop, the conversation turns to the top five security threats. The first threat discussed is narrative attacks. These attacks are a new AI-enabled way of manipulating, discrediting, or distorting stories and take advantage of cultural biases and emotions. The brand damage of these attacks can be devastating, and Wrozek emphasizes that countering narrative attacks requires early warning through threat intelligence.\nThe second threat discussed is another AI-enabled threat: deep fakes. Threat actors use AI to create very convincing fake identities that can lead organizations to take damaging actions. In one recent deepfake scam, a finance clerk in Hong Kong was duped into transferring $25 million to fraudsters. The quality of these fakes is improving rapidly, making it difficult to differentiate between real and fake videos or audio. They can be used to amplify narrative attacks as well. The CISO\u2019s role is focused on threat intelligence to avoid these attacks and on incident response capabilities to address deep fakes.\nThe third threat discussed is AI responses and the risks of prompt engineering, prompt injection, and sensitive data spillage as deployments of applications underpinned with genAI become more common. The role of AI in security tools is also explored in this section, with Wrozek and Worthington discussing how security teams use genAI for content creation, behavioral prediction, and knowledge articulation.\nFrom there, the conversation turns to the fourth threat: the AI software supply chain. Worthington walks through a variety of risks, including the use of open-source libraries that allow attackers to inject malicious code into the software supply chain that can get into a vendor\u2019s product and provide unauthorized access to their customers downstream. Worthington says traditional software supply chain practices can help organizations avoid attacks. Also, bills of materials for software or models are more available now to help users understand the various components.\nThe episode concludes with a short discussion of the fifth threat: nation state espionage. The discussion focuses on the fact that these attacks do impact enterprises, not just governments, and that most cyber insurance policies won\u2019t cover losses from a nation state attack. Overall, the episode provides practical guidance for security leaders on handling the latest threats to their organizations from a variety of attackers."
    },
    {
      "url": "https://fueled.com/blog/localtion-spoofing/",
      "text": "Geolocation-based testing has become crucial in today\u2019s tech landscape, especially when users are scattered across different regions.Conducting physical tests with users everywhere is impractical, and this is where location spoofing comes into play as a practical solution.\nThis post delves into the significance of location spoofing in testing applications and beyond.\nGeolocation refers to the use of location technologies such as GPS or IP addresses to identify and track the whereabouts of connected electronic devices. Geolocation is frequently used to track people\u2019s movements and locations as well as for surveillance purposes because people frequently carry these devices.Testing an application in different geographic locations to ensure that it meets all legal requirements related to those locations and works as expected regardless of location.This includes checking the validity of the application in each geographic location where it may be used, checking the application efficiency and performance of IP in various locations.\nLocation spoofing is a form of interference which makes the receiver believe, user is at a false location. By faking or manipulating the GPS coordinates of a device, it can help a user spoof their current location.\nNeed for Location Spoofing\nThe main purpose of location spoofing in testing is to simulate different locations in order to assess how a service or application performs under different circumstances like allowing food ordering from a restaurant only if user is at restaurant\u2019s location, greeting users based on location or getting details of a place only when user is at that specific place.\nLocation Spoofing Across Multiple Platforms\nIn Android Devices using Fake GPS App\nFake GPS is a reliable and convenient fake location app. The Fake GPS app allows you to choose a location anywhere in the world from its multiple location support.\nSteps to Spoof Location:\n1. Install the app from play store.\n2. Open the app.\n3. Tap on the ellipsis on the top right corner.\n4. Tap on Search.\n5. Enter the coordinates.\n6. Set the mock location in the Developer option by selecting \u201cFake GPS\u201d app in Select mock location app option.\n7. Tap on the play icon in the menu bar when you want to start.\n8. Tap on pause icon in the menu bar when you want to stop.\nIn iOS Devices\nIn iOS, it is a bit tricky to spoof locations. Developers can provide an option in development builds from app settings to mock location programmatically.\nGiven below is the conceptual overview to set up location spoofing based on Settings bundle:\n- Use the Settings bundle to store key-value pairs accessible via the app\u2019s settings.a. Text inputs may be most straight-forward for latitude and longitude; sliders or toggles are also availableb. For fixed locations, a list of map values with corresponding coordinates ensures correct inputsc. Additionally, include a toggle that can enable/disable the app from using the spoofed location\n- Read values from the Settings bundle whenever applicable (this will depend on app architecture)a. Usually an iOS app will contain a single Location Manager. Intercepting the manager\u2019s coordinates and replacing with the spoofed location is often the simplest approachb. Occasionally the app\u2019s architecture will retain reference to a previous location; a user can either restart the app, or the engineer can design to detect changes for when location spoofing is enabled/disabled on each app openc: In the case a Location Manager is not the source of truth, each location within the app will need to read from the Setting\u2019s spoofed location (more cumbersome to maintain; prone to human error).\nNote: Additional steps may be needed, such as injecting the spoofed location into a map for accuracy. For device-level spoofing, connect to Xcode and run the app on the simulator.\nSteps to Spoof Location:\n1. Install the app.\n2. Open app settings from native iOS Settings app.\n3. You will find an option to enter coordinates(If added by developer) or an option to select location from a list.\n4. Save the values entered and on launching the app now, you can see mocked locations.\nOn Chrome Browser\nSpoofing location can be done on browser\u2019s also and here are the steps for spoofing location on chrome browser using developer tools.\nSteps to Spoof Location:\n1. Open the website where the location is to be spoofed.\n2. Press command+option+J to open Developer tool or Right click and click on Inspect to open Developer tool.\n3. Click the three vertical dots in the upper right of the developer tools panel.\n4. Click on More tools and then click on Sensors.\n5. Click on Manage.\n6. Click on Add Location.\n7. Add name, latitude and longitude of the location and then click on Add button.\n8. Click on cancel icon and select the added location.\n9. To verify the location has been updated, try fetching the current location and you should see the updated location.\nUsing Browserstack App Live\nBrowserstack supports geolocation testing and hence we used it for testing both Android and iOS applications. By providing coordinates or selecting location from browserstack.Browserstack mocks the location by mocking the device\u2019s current location from the testing lab.\nSteps to Spoof Location:\n1. Click on Change location.\n2. Enter the latitude and longitude.\n3. Confirm the location by clicking on Yes.\nAs technology continues to advance, the importance of location spoofing in testing and real-world scenarios cannot be overstated. From ensuring application functionality across diverse locations to exploring its potential in everyday scenarios like food ordering, location spoofing proves to be a versatile and indispensable tool in the tech enthusiast\u2019s toolkit.\nWe trust that this blog has provided valuable insights into the concept of location spoofing and the key techniques that can be employed to achieve spoofing.\nThank you Navneet Kaur, Vishnu Vijayakumar and Pooja Padamad for your contribution to this blog."
    },
    {
      "url": "https://www.andrews.edu/life/student-movement/issues/2024-11-22/id_medialiteracy.html",
      "text": "The average person spends two hours and 24 minutes a day on social media unless they have broken the heavy chains that attached them to those platforms. Two hours and 24 minutes in which they will likely scroll mindlessly through content posted by millions of people around the world. Dealing with such a large amount of media is hard, but consuming it mindlessly is even worse. What should they do with all of that information? They can let the algorithm decide what they will consume and believe, or they can take the driver's seat. This is where media literacy comes into play.\nThe National Association for Media Literacy Education (NAMLE) defines media literacy as \u201cthe ability to access, analyze, evaluate, create, and act using all forms of communication.\u201d Simply put, media literacy is the tool that enables people to decide what they see and how they react to the media. That might seem almost impossible in the world you and I live in, but it isn\u2019t as hard as you might think.\nThe Lack of Media Literacy in Today\u2019s Society\nOnly a few people are aware of their power to manage their information consumption. A decline in media literacy has become more extensive as technology constantly evolves. In the 2024 Edelman Trust Barometer survey, 54% of participants said they felt like technology was evolving too quickly, making it harder to interact with and make proper choices regarding technology. In another study from Media Literacy Now, barely 38% of participants were taught how to analyze media messaging in high school.\nAs we enter into more technological interactions thanks to the COVID-19 pandemic, technology is almost unavoidable, at least for essential communication: Zoom meetings, messages on Instagram and the latest news on YouTube. As communication becomes more digital, ideas travel faster and users spend less time corroborating facts or claims. People will believe whatever other famous or trusted people say without thinking twice. As our world moves faster, it asks us to do things quicker and produce more in less time.\nSituations that have put media literacy skills to the test include the election, the COVID-19 pandemic and other significant socio-cultural events. As technology becomes more sophisticated, it becomes easier for some people with malicious intent to spread misinformation, which Cambridge defines as \u201cfalse information spread in order to deceive people.\u201d Technology makes it easier to create deepfakes and spread false information to impact people\u2019s opinions about important issues. In a 2024 study by Jumio, 60% of participants said they had encountered a deepfake at least once in the past year. Examples like Taylor Swift\u2019s deepfakes or even the videos where influential celebrities and authorities appear doing funny things together (made as jokes, of course) are just a small sample of this type of content's potential.\nThis mix of false information and overstimulation can overwhelm people, leading some to distrust anything that doesn\u2019t align with their current beliefs. When added to exclusive online forums for people with the same ideas, technology can create bigger echo chambers of disinformation and even indoctrination. So, what can we do about it?\nApplying Media Literacy 101\nTo start, let\u2019s do a small class on media literacy. When you have a piece of media in front of you, you can first watch it, and then you should intentionally analyze it. The NAMLE website has a list of questions you can use to debate about what you just consumed or are about to consume. Questions like \u201cWho made this?,\u201d \u201cWhy was this made?\u201d or even \u201cWho paid for this?\u201d might sound trivial or too obvious, but understanding them is as important as the content itself.\nNow, if you cannot answer all the questions or require more information to understand what you are consuming, there are people you can ask. Many librarians and teachers have knowledge, skills and tools to navigate the ocean of knowledge and guide you as you learn how to navigate it. However, you do not need to become an expert in applying media literacy. Still, it takes time to learn about it, be conscious and intentional about what you consume, and share the ideas with others to debate its credibility and purpose.\nThis does not mean we cannot use technology in our favor to apply media literacy to our lives. Websites like FactCheck.org or the Associated Press fact check website can help verify information. You can also use artificial intelligence to check or discuss information\u2014OpenAI recently published an article about how students can use ChatGPT ethically. However, it is important to note that AI is limited in terms of information and accuracy.\nGiven the current status of our world, our battles with information and technology will not get easier. If we do not take steps to control what kind of information we consume, our world may become a chaos of unorganized ideas.\nThe education system, which involves teachers and parents, plays an essential role in teaching children about media literacy and how to interact ethically with AI. Governments and other institutions must address media literacy education as more concerns about the future of AI and information arise (check out this article). Accessible courses on media literacy should be available to everyone and incentives would help those who would have to sacrifice hours of work or study to learn such important skills for life. In the meantime, we as individuals can take the first steps, too.\nQuestion what you see, what you read and what you hear. Research more and do not believe anything you are told unless it is proven. Take your time to decide what you want to learn and what you think; do not let others decide that for you, not even technology. You are free to question and doubt my claims. Feel free to look at the linked sources and other websites and movements like Media Literacy Now. Learn to think critically\u2014it might not change the whole world, but it can change your world.\nThe Student Movement is the official student newspaper of Andrews University. Opinions expressed in the Student Movement are those of the authors and do not necessarily reflect the opinions of the editors, Andrews University or the Seventh-day Adventist church."
    },
    {
      "url": "https://carnegieendowment.org/research/2024/01/countering-disinformation-effectively-an-evidence-based-policy-guide?lang=en",
      "text": "Methodology\nThis report offers high-level, evidence-informed assessments of ten commonly proposed ways to counter disinformation. It summarizes the quantity and quality of research, the evidence of efficacy, and the ease of scalable implementation. Building on other work that has compiled policy proposals or collected academic literature, this report seeks to synthesize social science and practitioner knowledge for an audience of policymakers, funders, journalists, and others in democratic countries.1 Rather than recommending a specific policy agenda, it aims to clarify key considerations that leaders should weigh based on their national and institutional contexts, available resources, priorities, and risk tolerance.\nTo conduct this research, we compiled a list of nearly two dozen counter-disinformation measures frequently proposed by experts, scholars, and policymakers.2 We then selected ten for inclusion based on several factors. First, we prioritized proposals that had a fairly direct connection to the problem of disinformation. For example, we excluded antitrust enforcement against tech companies because it affects disinformation in an indirect way, making it difficult to evaluate in this report. Second, we focused on countermeasures that could plausibly be subject to meaningful empirical study. We therefore did not consider diplomatic efforts to build international norms against disinformation, for example, or changes to platforms\u2019 legal liability as intermediaries. Third, we sought to cover a diverse range of interventions. This meant including actions implementable by the government, the private sector, and civil society; tactical measures as well as structural reforms; and multiple theories of change such as resilience, disruption, and deterrence.\nThe ten selected interventions became the subjects of this report\u2019s ten case studies. Each case study defines the intervention, gives concrete use cases, and highlights additional reading. The case studies focus on three questions: How much is known about an intervention? How effective does it seem, given current knowledge? And how easy is it to implement at scale? To develop these case studies, we reviewed hundreds of academic papers, previous meta-analyses, programmatic literature, and other relevant materials. We also conducted a series of workshops and consultations with scholars, practitioners, policymakers, and funders. We drew on experts with domain knowledge to vet individual case studies, as well as those with a broader view of the counter-disinformation field to provide feedback on the project as a whole. The resulting report expresses the views of the authors alone.\nAlthough this report reviews a number of important, commonly proposed policy ideas, it is not comprehensive. In particular, we did not study the following significant categories of long-term, large-scale change. First, political institutions could try to perform stronger gatekeeping functions. This may involve reforms of party primaries, redistricting processes, and campaign finance systems. Second, tech platforms might need stronger incentives and capacity to curb disinformation. This could involve new regulation, diversification of revenue, and market power reductions that enable users, advertisers, activists, and others to provide checks on major platforms. Third, the public may need more encouragement to value truth and place trust in truthful institutions and figures. This might involve addressing the many root causes of popular alienation, fear, and anger, such as with local community-building efforts, a reversal of geographic sorting, improvements to economic prospects, and healing of racial grievances. Any of these ideas would be daunting to implement, and none are easy to assess. But they all have serious potential to help counter disinformation\u2014perhaps even more so than the ten interventions studied in this report.\nNotes\n1 See \u201cFinal Report: Commission on Information Disorder,\u201d Aspen Institute, November 2021, https://www.aspeninstitute.org/wp-content/uploads/2021/11/Aspen-Institute_Commission-on-Information-Disorder_Final-Report.pdf; Daniel Arnaudo et al., \u201cCombating Information Manipulation: A Playbook for Elections and Beyond,\u201d National Democratic Institute, International Republican Institute, and Stanford Internet Observatory, September 2021, https://www.ndi.org/sites/default/files/InfoManip%20Playbook%20updated%20FINAL.pdf; \u201cCenter of Excellence on Democracy, Human Rights, and Governance: Disinformation Primer,\u201d U.S. Agency for International Development, February 2021, https://cnxus.org/wp-content/uploads/2021/11/usaid-disinformation-primer.pdf; and Laura Courchesne, Julia Ilhardt, and Jacob N. Shapiro, \u201cReview of Social Science Research on the Impact of Countermeasures Against Influence Operations,\u201d Harvard Kennedy School Misinformation Review 2, no. 5 (September 2021): https://misinforeview.hks.harvard.edu/article/review-of-social-science-research-on-the-impact-of-countermeasures-against-influence-operations/.\n2 This list was drawn from multiple sources, including Kamya Yadav, \u201cCountering Influence Operations: A Review of Policy Proposals Since 2016,\u201d Carnegie Endowment for International Peace, November 30, 2020, https://carnegieendowment.org/2020/11/30/countering-influence-operations-review-of-policy-proposals-since-2016-pub-83333; a more detailed, unpublished database of policy proposals compiled by Vishnu Kannan in 2022; Courchesne, Ilhardt, and Shapiro, \u201cReview of Social Science Research\u201d; and \u201cThe 2022 Code of Practice on Disinformation,\u201d European Commission, accessed January 27, 2023, https://digital-strategy.ec.europa.eu/en/policies/code-practice-disinformation. These sources were supplemented by further literature review and expert feedback.\nCarnegie Technology and International Affairs Program\nReceive research announcements and event invitations from the Carnegie Technology and International Affairs Program.\nChallenges and Cautions\nBefore seeking to counter disinformation, policymakers should carefully consider what this idea means. \u201cDisinformation,\u201d usually defined as information known by the speaker to be false, is a notoriously tricky concept that comes with numerous limitations, contradictions, and risks.1\nConceptual Challenges\nIdentifying disinformation presents several puzzles. For one thing, labeling any claim as false requires invoking an authoritative truth. Yet the institutions and professions most capable of discerning the truth\u2014such as science, journalism, and courts\u2014are sometimes wrong and often distrusted. Moreover, true facts can be selectively assembled to create an overall narrative that is arguably misleading but not necessarily false in an objective sense. This may be even more common and influential than outright lies, yet it\u2019s unclear whether it counts as disinformation. In fact, \u201cdisinformation\u201d is frequently conflated with a range of other political and societal maladies such as polarization, extremism, and hate. All of these are technically distinct issues, though they can be causally related to disinformation and to each other. Finally, it is difficult to know whether someone spreading false claims does so intentionally. Disinformation typically passes through a long chain of both witting and unwitting speakers.\nThe challenges of the term \u201cdisinformation\u201d are not merely theoretical; they have influenced public debates. Despite the word\u2019s scientific-sounding imprimatur, it is often invoked quite loosely to denigrate any viewpoint seen as wrong, baseless, disingenuous, or harmful. Such usage has the effect of pathologizing swaths of routine discourse: after all, disagreements about what is wrong, baseless, disingenuous, or harmful are what drives democratic politics and social change. Moreover, today\u2019s talk of \u201cdisinformation\u201d can sometimes imply a more novel, solvable problem than really exists. Although the word has been familiar in the West for decades, it attained new currency just a few years ago after a series of catalyzing episodes\u2014such as Russian election interference in the United States\u2014involving social media. This led many people to see social media as the defining cause of disinformation, rather than one driver or manifestation of it. The messy battle for truth is, of course, an eternal aspect of human society.\nFor policymaking, reliance on a loaded but vague idea like \u201cdisinformation\u201d brings several risks. When the term is used to imply that normal and necessary public discourse is dangerously disordered, it encourages the empowerment of technocrats to manage speech and, in turn, potentially erodes legal and normative boundaries that sustain democracy. Moreover, the term\u2019s vagaries and contradictions are already well understood by segments of the public and have been seized upon, including by disinformers themselves, to undermine counter-disinformation efforts. In some cases, those accused of spreading disinformation have successfully sought to reclaim the term by arguing that counter-disinformation efforts are the real sources of disinformation, thus reversing the roles of perpetrator and victim.\nThis risk is most obvious in authoritarian regimes and flawed democracies, where leaders may suppress dissent by labeling it disinformation. But the problem can manifest in other ways too. A prominent U.S. example was the 2020 public letter by former intelligence officials warning that the then-recent disclosure of Hunter Biden\u2019s laptop data \u201chas all the classic earmarks of a Russian information operation.\u201d2 Later, when the data\u2019s authenticity was largely confirmed, those promoting the laptop story said the letter itself was a form of disinformation.3 Similar boomerang patterns have previously been seen with \u201cfake news,\u201d a phrase that originally described unethical content farms but was quickly repurposed to delegitimize truthful journalism. To be sure, such boomerangs often rest on exaggerated or bad faith claims. Yet they exploit a core truth: \u201cdisinformation\u201d is a flawed, malleable term whose implied assertion of authority can lead to overreach and blowback.\nFor these and other reasons, a growing number of experts reject the term \u201cdisinformation.\u201d Some prefer to focus instead on \u201cmisinformation\u201d (which elides intent) or \u201cinfluence/information operations\u201d (which de-emphasizes falsity). Others favor more self-consciously political terms such as \u201cpropaganda\u201d or \u201cinformation warfare,\u201d which they see as clearer warnings of the problem. A range of alternative conceptions have been proposed, including \u201cmalinformation\u201d and \u201cinformation disorder.\u201d Recently, some experts have advocated holistic concepts, like \u201cinformation ecology\u201d or \u201cinformation and society,\u201d that shift attention away from individual actors or claims and toward larger social systems. Meanwhile, platforms have developed their own quasi-legalistic argot\u2014such as Meta\u2019s \u201ccoordinated inauthentic behavior\u201d\u2014to facilitate governance and enforcement.\nThere is also a growing set of scholars and commentators who believe the field itself, not just its terminology, must be fundamentally rethought.4 Some point out that disinformation and its ilk are elastic notions which tend to reflect the biases of whoever invokes them. Others observe that disinformation isn\u2019t pervasive or influential enough to explain the ills often attributed to it. Several critics have gone so far as to label the disinformation crisis a moral panic, one suffered most acutely by elite groups. On this telling, privileged and expert classes\u2014such as the White liberals who for decades dominated academia and journalism in the United States\u2014have seized upon a perceived surge of disinformation to explain their recent loss of control over the national discourse. This story, rooted in nostalgia for a mythical era of shared truth, offers a comforting, depoliticized morality play: right-thinking in-groups are under siege by ignorant out-groups in the thrall of manipulative (often foreign) bogeymen. The narrative has troubling historical antecedents, such as baseless Cold War\u2013era fears of communist \u201cbrainwashing\u201d that led to curtailment of civil liberties in the West.\nDespite all these complications and pitfalls, this report begrudgingly embraces the term \u201cdisinformation\u201d for three primary reasons. First, it captures a specific, real, and damaging phenomenon: malicious falsehoods are undermining democratic stability and governance around the world. However difficult it may be to identify or define disinformation at the edges, a set of core cases clearly exists and deserves serious attention from policymakers. A paradigmatic example is the \u201cStop the Steal\u201d movement in the United States. The claim that the 2020 presidential election was stolen is provably false, was put forward with demonstrated bad faith, and has deeply destabilized the country. Second, other phrases have their own problems, and no single term has yet emerged as a clearly better alternative. Third, \u201cdisinformation\u201d remains among the most familiar terms for policymakers and other stakeholders who constitute the key audience for this report.\nEvaluation Challenges\nBeyond the conceptual issues, policymakers should also be aware of several foundational challenges in assessing the efficacy of disinformation countermeasures. Each of these challenges emerged time and again in the development of this report\u2019s case studies.\n- The underlying problem is hard to measure. It is hard to know how well a countermeasure works if analysts don\u2019t also know how much impact disinformation has, both before and after the countermeasure is implemented. In fact, countermeasures are only necessary insofar as disinformation is influential to begin with. Unfortunately, experts broadly agree that disinformation (like other forms of influence) is poorly understood and hard to quantify. A 2021 Princeton University meta-analysis commissioned by Carnegie found that \u201c[e]mpirical research on how influence operations can affect people and societies\u2014for example, by altering beliefs, changing voting behavior, or inspiring political violence\u2014is limited and scattered.\u201d5 It specifically noted that \u201cempirical research does not yet adequately answer many of the most pressing questions facing policymakers\u201d regarding the effectiveness of various influence tactics, the role of the medium used (such as specific online platforms), the duration of influence effects, and country-level differences. Until more is known about disinformation itself, the ability to assess countermeasures will remain limited.\n- Success can be defined in multiple ways. What makes an intervention successful in countering disinformation? An effective intervention might be one that stops someone from embracing a false belief, or discourages people from acting based on false claims, or slows the spread of false information, or protects the integrity of democratic decisionmaking, among other possibilities. All of these effects can be measured over varying time horizons. Additionally, effectiveness is tied to an intervention\u2019s cost, scalability, and the willingness of key stakeholders to facilitate implementation. The risk of blowback is another factor: decisionmakers should consider potential second-, third-, and higher-order effects on the information environment. In short, there is no single way to understand success. Policymakers must decide this for themselves.\n- Policies can coincide, synergize, and conflict with each other. This report offers discrete evaluations of ten countermeasure types. In reality, multiple kinds of interventions should be implemented at the same time. Simultaneous, interconnected efforts are necessary to address the many complex drivers of disinformation. Policymakers and analysts must therefore avoid judging any one policy option as if it could or should provide a comprehensive solution. An ideal assessment would consider how several interventions can work together, including potential synergies, conflicts, and trade-offs. Such holistic analysis would be extremely difficult to do, however, and is beyond the scope of this report.\n- Subpopulations matter and may react differently. Many studies of disinformation countermeasures focus on their overall efficacy with respect to the general population, or the \u201caverage\u201d person. However, atypical people\u2014those at the tails of the statistical distribution\u2014sometimes matter more. People who consume or share the largest amount of disinformation, hold the most extreme or conspiratorial views, have the biggest influence in their social network, or harbor the greatest propensity for violence often have disproportionate impact on society. Yet these tail groups are harder to study. Policymakers should take care not to assume that interventions which appear generally effective have the same level of impact on important tail groups. Conversely, interventions that look ineffective at a population level may still be able to influence key subpopulations.\n- Findings may not generalize across countries and regions. The feasibility and impact of an intervention can vary from place to place. For example, the United States is more polarized than most other advanced democracies, and it faces greater constitutional constraints and government gridlock. On the other hand, the United States has outsized influence over the world\u2019s leading social media platforms and possesses relatively wealthy philanthropic institutions and, at the national level, a robust independent press. These kinds of distinctive characteristics will shape what works in the United States, while other countries must consider their own national contexts. Unfortunately, much of the available research focuses on the United States and a handful of other wealthy Western democracies. This report incorporates some examples from other countries, but geographic bias remains present.\nThese evaluation challenges have no easy solutions. Researchers are working to fill knowledge gaps and define clearer policy objectives, but doing so will take years or even decades. Meanwhile, policymakers must somehow forge ahead. Ideally, they will draw upon the best information available while remaining cognizant of the many unknowns. The following case studies are designed with those twin goals in mind.\nNotes\n1 Alicia Wanless and James Pamment, \u201cHow Do You Define a Problem Like Influence?,\u201d Carnegie Endowment for International Peace, December 30 2019, https://carnegieendowment.org/2019/12/30/how-do-you-define-problem-like-influence-pub-80716. For more on the distinction between misinformation and disinformation, see Dean Jackson, \u201cIssue Brief: Distinguishing Disinformation From Propaganda, Misinformation, and \u2018Fake News,\u2019\u201d National Endowment for Democracy, October 17, 2017, https://www.ned.org/issue-brief-distinguishing-disinformation-from-propaganda-misinformation-and-fake-news/.\n2 Jim Clapper et al., \u201cPublic Statement on the Hunter Biden Emails,\u201d Politico, October 19, 2020, https://www.politico.com/f/?id=00000175-4393-d7aa-af77-579f9b330000.\n3 Luke Broadwater, \u201cOfficials Who Cast Doubt on Hunter Biden Laptop Face Questions,\u201d New York Times, May 16, 2023, https://www.nytimes.com/2023/05/16/us/politics/republicans-hunter-biden-laptop.html.\n4 See, for example, Joseph Bernstein, \u201cBad News: Selling the Story of Disinformation,\u201d Harper\u2019s, 2021, https://harpers.org/archive/2021/09/bad-news-selling-the-story-of-disinformation; Rachel Kuo and Alice Marwick, \u201cCritical Disinformation Studies: History, Power, and Politics,\u201d Harvard Kennedy School Misinformation Review, August 12, 2021, https://misinforeview.hks.harvard.edu/article/critical-disinformation-studies-history-power-and-politics; Alice Marwick, Rachel Kuo, Shanice Jones Cameron, and Moira Weigel, \u201cCritical Disinformation Studies: A Syllabus,\u201d Center for Information, Technology, and Public Life, 2021, https://citap.unc.edu/research/critical-disinfo; Ben Smith, \u201cInside the \u2018Misinformation\u2019 Wars,\u201d New York Times, November 28, 2021, https://www.nytimes.com/2021/11/28/business/media-misinformation-disinformation.html; Matthew Yglesias, \u201cThe Misinformation Cope,\u201d Slow Boring, April 20, 2022, https://www.slowboring.com/p/misinformation; Th\u00e9ophile Lenoir, \u201cReconsidering the Fight Against Disinformation,\u201d Tech Policy Press, August 1, 2022, https://www.techpolicy.press/reconsidering-the-fight-against-disinformation; Dan Williams, \u201cMisinformation Researchers Are Wrong: There Can\u2019t Be a Science of Misleading Content,\u201d Conspicuous Cognition, January 10, 2024, https://www.conspicuouscognition.com/p/misinformation-researchers-are-wrong; and Gavin Wilde, \u201cFrom Panic to Policy: The Limits of Propaganda and the Foundations of an Effective Response,\u201d Texas National Security Review (forthcoming 2024).\n5 Jon Bateman, Elonnai Hickok, Laura Courchesne, Isra Thange, and Jacob N. Shapiro, \u201cMeasuring the Effects of Influence Operations: Key Findings and Gaps From Empirical Research,\u201d June 28, 2021, Carnegie Endowment for International Peace, https://carnegieendowment.org/2021/06/28/measuring-effects-of-influence-operations-key-findings-and-gaps-from-empirical-research-pub-84824.\nCase Study 1: Supporting Local Journalism\nKey takeaways:\nThere is strong evidence that the decline of local news outlets, particularly newspapers, has eroded civic engagement, knowledge, and trust\u2014helping disinformation to proliferate. Bolstering local journalism could plausibly help to arrest or reverse such trends, but this has not been directly tested. Cost is a major challenge, given the expense of quality journalism and the depth of the industry\u2019s financial decline. Philanthropy can provide targeted support, such as seed money for experimentation. But a long-term solution would probably require government intervention and/or alternate business models. This could include direct subsidies (channeled through nongovernmental intermediaries) or indirect measures, such as tax exemptions and bargaining rights.\nKey sources:\n- \u201cINN Index 2022: Enduring in Crisis, Surging in Local Communities,\u201d Institute for Nonprofit News, July 27, 2022, https://inn.org/research/inn-index/inn-index-2022.\n- Penelope Muse Abernathy, \u201cNews Deserts and Ghost Newspapers: Will Local News Survive?,\u201d University of North Carolina, 2020, https://www.usnewsdeserts.com/reports/news-deserts-and-ghost-newspapers-will-local-news-survive/.\n- Emily Bell, \u201cFacebook Is Eating the World: It\u2019s the End of the News as We Know It,\u201d Columbia Journalism Review, March 7, 2016, https://www.cjr.org/60th/facebook-is-eating-the-world-emily-bell-end-of-news-as-we-know-it.php.\nDescription and Use Cases\nMany analysts have called for investing in local journalism\u2014especially print and digital media\u2014as a way to counter disinformation. The hope is that high-quality local journalism can inform democratic deliberation, debunk false claims, and restore the feelings of trust and community that help to keep conspiracy theories at bay.1 More specifically, new financial investments would aim to halt or reverse the industry\u2019s long-term financial deterioration. Local newspapers and other outlets have seen steady declines in ad revenue and readership for the last two decades, as the internet gave birth to more sophisticated forms of digital advertising and alternative sources of free information. According to one count, a fourth of the newspapers operating in the United States in 2004 had closed by the end of 2020.2 The COVID-19 pandemic accelerated this trend, causing widespread layoffs across print, broadcast, radio, and digital outlets.3 Such challenges have not been limited to the United States or Western countries: for example, COVID-19 \u201cravaged the revenue base\u201d of Nigerian media organizations, according to one local publisher.4\nNew funding for local journalism could come from governments, philanthropists, commercial sources, or a combination of these. One model for government funding is the New Jersey Civic Information Consortium, a state-supported nonprofit. The consortium receives money from government and private sources, then disburses grants to projects that promote the \u201cquantity and quality of civic information.\u201d5 The use of a nonprofit intermediary aims to reduce the risk that government officials would leverage state funds to influence news coverage.6 Another model is for governments to use tax exemptions and other policy tools to financially boost the journalism industry without directly subsidizing it.7 In the United Kingdom, newspapers, books, and some news sites are exempt from the Value-Added Tax because of their public benefit.8 In Canada, people who purchase a digital news subscription can claim a tax exemption.9 Australia has taken another approach by passing legislation that empowers news publishers to jointly negotiate for compensation when platforms like Facebook and Google link to their content.10 Other advocates have proposed a tax on digital advertising that would be used to support journalism.11\nPhilanthropic support for local journalism can also come in various forms. Not-for-profit news outlets in North America currently get about half of their revenue from foundation grants, but national and global outlets receive more than two-thirds of these grant dollars.12 To bolster local outlets, a greater portion of grants could be redirected to them. The next largest source of funding for nonprofit newsrooms is individual gifts, which make up about 30 percent of revenue and primarily come from donations of $5,000 or more.13 However, small-dollar donations are growing; NewsMatch, a U.S. fundraising effort, encourages audiences to donate to local media organizations and matches individual donations with other sources of philanthropy. NewsMatch has raised more than $271 million since 2017.14\nMultiple government, philanthropic, or commercial revenue streams can be combined in novel ways, as illustrated by Report for America. The initiative raised $8 million in 2022 to place reporting fellows in local newsrooms.15 A relatively small portion, about $650,000, was taxpayer money from the Corporation for Public Broadcasting.16 The remainder came from foundations and technology companies, matched dollar-for-dollar by contributions split between the local newsrooms themselves and other local funders.\nHow Much Do We Know?\nResearch is clear that the decline of local journalism is associated with the drivers of disinformation. However, the inverse proposition\u2014that greater funding for local journalists will reduce disinformation\u2014does not automatically follow and has not been empirically tested.\nGoing forward, decisionmakers and scholars could study the link between disinformation and the health of local media outlets more closely by monitoring and evaluating the impact of local news startups on a variety of metrics related to disinformation, such as polarization, professed trust in institutions like the media and government, civic engagement and voter turnout, and susceptibility to online rumors.\nHow Effective Does It Seem?\nStudies suggest at least two mechanisms whereby the decline of local media outlets can fuel the spread of disinformation.\nFirst, the decline contributes to civic ignorance and apathy as voters become less informed about the issues, candidates, and stakes in local elections. Research indicates that reduced access to local news is linked to lower voter turnout and civic engagement as well as increased corruption and mismanagement. At least one longitudinal study also finds a relationship between the decline of local news, on the one hand, and diminished civic awareness and engagement on the other hand.17 These conditions ultimately erode public trust, which can increase belief in misinformation and conspiracy theories.18 Conversely, scholarship has shown that strong media is linked to robust civic participation. Many studies correlate the existence of local newspapers with higher turnout in local elections. And, at an individual level, a person\u2019s consumption of local political news is associated with higher likelihood to vote.19 These patterns can be seen in a variety of electoral contexts\u2014including downballot and judicial elections\u2014and across historical periods, despite changing technology.20 A study of U.S. history from 1869 to 2004 found that a community\u2019s civic participation rose when its first newspaper was created, and that this connection persisted even after the introduction of radio and television.21\nWhen local media disappears, lower-quality information sources can fill the gap as people look elsewhere for information.\nSecond, when local media disappears, lower-quality information sources can fill the gap as people look elsewhere for information. Social media has emerged as a primary alternative.22 Although social media platforms contain plenty of accurate and authoritative voices, they also create opportunities for low-quality and hyperpartisan personalities and outlets (some of which pose as local newspapers) that spread misleading, divisive content.23 Indeed, research shows a connection between the decline of local media and the rise of polarization. For example, one study found that communities that lost their local newspaper became more polarized as voters replaced information from local media with more partisan cues picked up elsewhere, such as national cable TV.24 To be sure, polarizing content should not be equated with disinformation. Nevertheless, most analysts believe the two are linked: as voters drift away from the \u201cmainstream\u201d of the political spectrum\u2014often, but not always, toward the right\u2014they may become more accepting of less credible alternative media sources and misleading claims that align with their partisan preferences and demonize political opponents.25\nGiven the evidence that local media declines breed susceptibility to disinformation, it is reasonable to predict that efforts to bolster local media could have the opposite effect. However, that prediction has not yet been empirically tested. It is possible, for example, that people who have drifted from traditional local journalism toward social media as an information source might have developed new habits that would be difficult to reverse. Likewise, communities that have suffered a general loss of civic engagement and trust due to the decline of local media might now have less interest or faith in a startup newsroom than they previously would have.\nHow Easily Does It Scale?\nReversing the decline of local journalism is an extremely costly proposition, at least in the United States, because the scale of downsizing has been so large. A Georgetown University study found that newspapers employed 150,000 fewer people in 2022 compared to the 1980s\u2014a decline of 63 percent. Although web publishers have replaced about half of those jobs, replacing the rest would require tremendous investment. For example, the American Journalism Project raised over $100 million to partially fund thirty-three nonprofit newsrooms\u2014a small fraction of the 2,100 newsrooms that closed in the United States in the past two decades.26 Washington Post columnist Perry Bacon Jr. estimated in 2022 that it would cost at least $10 billion per year to hire 87,000 new journalists\u2014that is, to ensure that each U.S. congressional district had 200 journalists, plus operational support.27 More localized coverage could be even costlier. In 2022, Democracy Fund created a calculator to estimate the total cost of meeting the information needs of every community in the United States. Hiring several reporters to cover crucial issues in each township and municipality would cost $52 billion per year.28\nPhilanthropy can provide targeted investments in particularly needy areas\u2014for example, communities too small or poor to sustain local media on their own\u2014and offer seed money to run experiments. But given the sums required, a large-scale solution would demand some combination of long-term government support, new journalistic business models, or other structural changes in the marketplace. The Australian bargaining law provides one promising case study. While critics said the approach would be unlikely to generate much revenue and would mostly benefit large publishers, an Australian government review found that Google and Meta reached thirty agreements with publications of varying size, including some groups of outlets. In its first year, the law raised more than $140 million for these outlets, much of which was used to hire new journalists and purchase equipment.29 Similar schemes are now being implemented in Canada and under consideration in California\u2014though these efforts, like the Australia law, have faced strong initial pushback from big tech companies.30\nNotes\n1 Consider David Salvo, Jamie Fly, and Laura Rosenberger, \u201cThe ASD Policy Blueprint for Countering Authoritarian Interference in Democracies,\u201d German Marshall Fund, June 26, 2018, https://www.gmfus.org/news/asd-policy-blueprint-countering-authoritarian-interference-democracies; \u201cA Multi-dimensional Approach to Disinformation,\u201d European Commission, 2018, https://op.europa.eu/en/publication-detail/-/publication/6ef4df8b-4cea-11e8-be1d-01aa75ed71a1; and Edward Lucas and Peter Pomeranzev, \u201cWinning the Information War: Techniques and Counter-strategies to Russian Propaganda in Central and Eastern Europe,\u201d Center for European Policy Analysis, 2016, https://cepa.ecms.pl/files/?id_plik=2773.\n2 Tom Stites, \u201cA Quarter of All U.S. Newspapers Have Died in 15 Years, a New UNC News Deserts Study Found,\u201d Poynter Institute, June 24, 2020, https://www.poynter.org/locally/2020/unc-news-deserts-report-2020/.\n3 Penelope Muse Abernathy, \u201cNews Deserts and Ghost Newspapers: Will Local News Survive?,\u201d University of North Carolina, 2020, https://www.usnewsdeserts.com/reports/news-deserts-and-ghost-newspapers-will-local-news-survive/; and \u201cThe Tow Center COVID-19 Newsroom Cutback Tracker,\u201d Tow Center for Digital Journalism, September 9, 2020, https://www.cjr.org/widescreen/covid-cutback-tracker.php.\n4 For example, see Dapo Olorunyomi, \u201cSurviving the Pandemic: The Struggle for Media Sustainability in Africa,\u201d National Endowment for Democracy, January 2021, https://www.ned.org/wp-content/uploads/2021/01/Pandemic-Struggle-Media-Sustainability-Africa-Olorunyomi.pdf.\n5 \u201cAbout the Consortium,\u201d New Jersey Civic Information Consortium, accessed January 27, 2023, https://njcivicinfo.org/about/.\n6 Anya Schiffrin, ed., In the Service of Power: Media Capture and the Threat to Democracy, Center for International Media Assistance, 2017, https://www.cima.ned.org/resource/service-power-media-capture-threat-democracy/.\n7 Consider \u201cINN Mission & History,\u201d Institute for Nonprofit News, accessed January 27, 2023, https://inn.org/about/who-we-are/.\n8 Jim Waterson, \u201cVAT Ruling on Times Digital Edition Could Save News UK Millions,\u201d Guardian, January 6, 2020, https://www.theguardian.com/media/2020/jan/06/vat-ruling-on-times-digital-edition-could-save-news-uk-millions.\n9 \u201cAbout the Digital News Subscription Tax Credit,\u201d Government of Canada, accessed March 24, 2023, https://www.canada.ca/en/revenue-agency/services/tax/individuals/topics/about-your-tax-return/tax-return/completing-a-tax-return/deductions-credits-expenses/deductions-credits-expenses/digital-news-subscription.html.\n10 \u201cNews Media Bargaining Code,\u201d Australian Competition & Consumer Commission, accessed January 27, 2023, https://www.accc.gov.au/by-industry/digital-platforms-and-services/news-media-bargaining-code/news-media-bargaining-code.\n11 Julia Angwin, \u201cCan Taxing Big Tech Save Journalism?\u201d Markup, July 16, 2022, https://themarkup.org/newsletter/hello-world/can-taxing-big-tech-save-journalism.\n12 \u201cINN Index 2022: Enduring in Crisis, Surging in Local Communities,\u201d Institute for Nonprofit News, July 27, 2022, https://inn.org/research/inn-index/inn-index-2022/; and \u201cNewsmatch,\u201d Institute for Nonprofit News, accessed April 18, 2023, https://newsmatch.inn.org/.\n13 \u201cINN Index 2022,\u201d Institute for Nonprofit News.\n14 \u201cNewsmatch,\u201d Institute for Nonprofit News.\n15 \u201cAbout Us,\u201d Report for America, accessed January 27, 2023, https://www.reportforamerica.org/about-us/.\n16 \u201cSupporting Report for America,\u201d Report for America, accessed December 23, 2023, https://www.reportforamerica.org/supporters.\n17 Danny Hayes and Jennifer L. Lawless, \u201cThe Decline of Local News and Its Effects: New Evidence from Longitudinal Data,\u201d Journal of Politics 80, no. 1 (January 2018): https://www.dannyhayes.org/uploads/6/9/8/5/69858539/decline.pdf.\n18 The relationship between disinformation and trust in media, government, and other institutions is complex. Exposure to false content online is associated with lower trust in media but higher trust in government for conservatives when their preferred party is in power. Lack of trust in institutions is associated with higher belief in conspiracy theories, for example in the context of COVID-19 vaccination. See Katherine Ognyanova, David Lazer, Ronald E. Robertson, and Christo Wilson, \u201cMisinformation in Action: Fake News Exposure Is Linked to Lower Trust in Media, Higher Trust in Government When Your Side Is in Power,\u201d Harvard Kennedy School Misinformation Review, June 2, 2020, https://misinforeview.hks.harvard.edu/article/misinformation-in-action-fake-news-exposure-is-linked-to-lower-trust-in-media-higher-trust-in-government-when-your-side-is-in-power; and Will Jennings et al., \u201cLack of Trust, Conspiracy Beliefs, and Social Media Use Predict COVID-19 Vaccine Hesitancy,\u201d Vaccines 9, no. 6 (June 2021): https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8226842. See also Jay Jennings and Meghan Rubado, \u201cNewspaper Decline and the Effect on Local Government Coverage,\u201d University of Texas at Austin, November 2019, https://moody.utexas.edu/sites/default/files/Strauss_Research_Newspaper_Decline_2019-11-Jennings.pdf; Jackie Filla and Martin Johnson, \u201cLocal News Outlets and Political Participation,\u201d Urban Affairs Review 45, no. 5 (2010): https://journals.sagepub.com/doi/abs/10.1177/1078087409351947?journalCode=uarb; \u201c2021 Edelman Trust Barometer,\u201d Edelman, 2021, https://www.edelman.com/trust/2021-trust-barometer; and Jeffrey Hiday, \u201cCombating Disinformation by Bolstering Truth and Trust,\u201d RAND Corporation, May 24, 2020, https://www.rand.org/pubs/articles/2022/combating-disinformation-by-bolstering-truth-and-trust.html.\n19 Martin Baekgaard, Carsten Jensen, Peter B. Mortensen, and S\u00f8ren Serritzlew, \u201cLocal News Media and Voter Turnout,\u201d Local Government Studies 40 (2014): https://www.tandfonline.com/doi/abs/10.1080/03003930.2013.834253.\n20 Christopher Chapp and Peter Aehl, \u201cNewspapers and Political Participation: The Relationship Between Ballot Rolloff and Local Newspaper Circulation,\u201d Newspaper Research Journal 42, no. 2 (2021): https://journals.sagepub.com/doi/10.1177/07395329211014968; and \u201cDoes Local Journalism Stimulate Voter Participation in State Supreme Court Elections?,\u201d David Hughes, Journal of Law and Courts 8, no. 1 (2020): https://www.cambridge.org/core/journals/journal-of-law-and-courts/article/abs/does-local-journalism-stimulate-voter-participation-in-state-supreme-court-elections/CE8E2CBDF4CF9C58DF08A013AE8B05A3.\n21 Matthew Gentzkow, Jesse M. Shapiro, and Michael Sinkinson, \u201cThe Effect of Newspaper Entry and Exit on Electoral Politics,\u201d American Economic Review 101 (December 2011): https://web.stanford.edu/~gentzkow/research/voting.pdf. For a roundup of this research, see Josh Stearns and Christine Schmidt, \u201cHow We Know Journalism Is Good for Democracy,\u201d Democracy Fund, September 15, 2022, https://democracyfund.org/idea/how-we-know-journalism-is-good-for-democracy/.\n22 David S. Ardia, Evan Ringel, Victoria Ekstrand, and Ashley Fox, \u201cAddressing the Decline of Local News, Rise of Platforms, and Spread of Mis- and Disinformation Online: A Summary of Current Research and Policy Proposals,\u201d University of North Carolina, December 22, 2020, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3765576.\n23 Jessica Mahone and Philip Napoli, \u201cHundreds of Hyperpartisan Sites Are Masquerading as Local News. This Map Shows If There\u2019s One Near You,\u201d Nieman Lab, July 13, 2020, https://www.niemanlab.org/2020/07/hundreds-of-hyperpartisan-sites-are-masquerading-as-local-news-this-map-shows-if-theres-one-near-you/.\n24 Joshua P. Darr, Matthew P. Hitt, and Johanna L. Dunaway, \u201cNewspaper Closures Polarize Voting Behavior,\u201d Journal of Communication 68, no. 6 (December 2018): https://academic.oup.com/joc/article-abstract/68/6/1007/5160090.\n25 See Imelda Deinla, Gabrielle Ann S. Mendoza, Kier Jesse Ballar, and Jurel Yap, \u201cThe Link Between Fake News Susceptibility and Political Polarization of the Youth in the Philippines,\u201d Ateneo School of Government, Working Paper no. 21-029, November 2021, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3964492; and Mathias Osmundsen, Michael Bang Petersen, and Alexander Bor, \u201cHow Partisan Polarization Drives the Spread of Fake News,\u201d Brookings Institution, May 13, 2021, https://www.brookings.edu/articles/how-partisan-polarization-drives-the-spread-of-fake-news/. In the United States, Yochai Benkler and others have argued that asymmetric polarization\u2014with the right drifting from the center faster and farther than the left\u2014has been driven at least in part by media dynamics. Specifically, right-leaning media across cable television, radio, and the internet are less connected to mainstream media than their left-leaning counterparts. See Yochai Benkler, Robert Faris, Hal Roberts, and Ethan Zuckerman, \u201cStudy: Breitbart-Led Right-Wing Media Ecosystem Altered Broader Media Agenda,\u201d Columbia Journalism Review, March 3, 2017, https://www.cjr.org/analysis/breitbart-media-trump-harvard-study.php. Not all analysts believe polarization is a bad thing; for example, some argue that polarization provides voters more distinct choices and has led to increased political participation. Others have argued that polarization contributes to crisis flash points that disrupt a problematic status quo in ways that are ultimately healthy. Consider Jessica Rettig, \u201cWhy Political Polarization Might Be Good for America,\u201d U.S. News, May 27, 2010, https://www.usnews.com/opinion/articles/2010/05/27/why-political-polarization-might-be-good-for-america; see also \u201cThe US Is Suffering From Toxic Polarization. That\u2019s Arguably a Good Thing,\u201d Peter T. Coleman, Scientific American, April 2, 2021, https://www.scientificamerican.com/article/the-u-s-is-suffering-from-toxic-polarization-thats-arguably-a-good-thing. The United States is an international outlier on polarization. A review by Jennifer McCoy and Benjamin Press found that the United States is \u201cthe only advanced Western democracy to have faced such intense polarization for such an extended period.\u201d Their study suggests grim outcomes from high levels of polarization. McCoy and Press examine a sample of fifty-two democratic societies suffering \u201cpernicious polarization,\u201d defined \u201cas the division of society into mutually distrustful political camps in which political identity becomes a social identity.\u201d They find that half of cases faced democratic erosion, and fewer than a fifth were able to sustain a decline in pernicious polarization. Jennifer McCoy and Benjamin Press, \u201cWhat Happens When Democracies Become Perniciously Polarized?\u201d Carnegie Endowment for International Peace, January 18, 2022, https://carnegieendowment.org/2022/01/18/what-happens-when-democracies-become-perniciously-polarized-pub-86190.\n26 Stites, \u201cQuarter of All U.S. Newspapers\u201d; \u201cFiscal Year 2022 Operating Budget,\u201d Corporation for Public Broadcasting, accessed January 27, 2023, https://www.cpb.org/aboutcpb/financials/budget; Anthony P. Carnevale and Emma Wenzinger, \u201cStop the Presses: Journalism Employment and Economic Value of 850 Journalism and Communication Programs,\u201d Georgetown University Center on Education and Workforce, 2022, https://cewgeorgetown.wpenginepowered.com/wp-content/uploads/cew-journalism-fr.pdf.\n27 Perry Bacon, Jr., \u201cAmerica Should Spend Billions to Revive Local News,\u201d Washington Post, October 17, 2022, https://www.washingtonpost.com/opinions/2022/10/17/local-news-crisis-plan-fix-perry-bacon/.\n28 \u201cNational Ecosystem Calendar,\u201d Democracy Fund, accessed April 18, 2023, https://oneroyalace.github.io/news-ecosystem-model/national_calculator.html.\n29 See Brian Fung, \u201cMeta Avoids Showdown Over News Content in US After Journalism Bargaining Bill Shelved,\u201d CNN, December 7, 2022, https://www.cnn.com/2022/12/07/tech/meta-journalism-bargaining-bill/index.html; Joshua Benton, \u201cDon\u2019t Expect McConnell\u2019s Paradox to Help News Publishers Get Real Money Out of Google and Facebook,\u201d Nieman Lab, January 8, 2020, https://www.niemanlab.org/2020/01/dont-expect-mcconnells-paradox-to-help-news-publishers-get-real-money-out-of-google-and-facebook/; Jeff Jarvis, \u201cAs Rupert Murdoch Works to Dismantle the Internet, Why Are Other Media Outlets Helping Him?,\u201dCrikey, February 15, 2021, https://www.crikey.com.au/2021/02/15/rupert-murdoch-news-media-bargaining-code/; Josh Frydenberg, \u201cReview of the News Media and Digital Platforms Mandatory Bargaining Code,\u201d Australian Department of the Treasury, February 2022, https://ministers.treasury.gov.au/ministers/josh-frydenberg-2018/media-releases/review-news-media-and-digital-platforms-mandatory; and Anya Schiffrin, \u201cAustralia\u2019s News Media Bargaining Code Pries $140 Million From Google and Facebook,\u201d Poynter Institute, August 16, 2022, https://www.poynter.org/business-work/2022/australias-news-media-bargaining-code-pries-140-million-from-google-and-facebook.\n30 Max Matza, \u201cGoogle and Canada Reach Deal to Avert News Ban Over Online News Act,\u201d BBC, November 29, 2023, https://www.bbc.com/news/world-us-canada-67571027; and Jaimie Ding, \u201cCalifornia Bill Requiring Big Tech to Pay for News Placed on Hold Until 2024,\u201d Los Angeles Times, July 7, 2023, https://www.latimes.com/business/story/2023-07-07/california-journalism-bill-on-hold-until-2024.\nCase Study 2: Media Literacy Education\nKey takeaways:\nThere is significant evidence that media literacy training can help people identify false stories and unreliable news sources. However, variation in pedagogical approaches means the effectiveness of one program does not necessarily imply the effectiveness of another. The most successful variants empower motivated individuals to take control of their media consumption and seek out high-quality information\u2014instilling confidence and a sense of responsibility alongside skills development. While media literacy training shows promise, it suffers challenges in speed, scale, and targeting. Reaching large numbers of people, including those most susceptible to disinformation, is expensive and takes many years.\nKey sources:\n- Monica Bulger and Patrick Davison, \u201cThe Promises, Challenges, and Futures of Media Literacy,\u201d Data & Society, February 21, 2018, https://datasociety.net/library/the-promises-challenges-and-futures-of-media-literacy.\n- G\u00e9raldine Wuyckens, Normand Landry, and Pierre Fastrez, \u201cUntangling Media Literacy, Information Literacy, and Digital Literacy: A Systematic Meta-review of Core Concepts in Media Education,\u201d Journal of Media Literacy Education 14 (2022), https://digitalcommons.uri.edu/cgi/viewcontent.cgi?article=1531&context=jmle.\n- Erin Murrock, Joy Amulya, Mehri Druckman, and Tetiana Liubyva, \u201cWinning the War on State-Sponsored Propaganda: Gains in the Ability to Detect Disinformation a Year and a Half After Completing a Ukrainian News Media Literacy Program,\u201d Journal of Media Literacy Education 10 (2018): https://digitalcommons.uri.edu/cgi/viewcontent.cgi?article=1361&context=jmle.\nDescription and Use Cases\nIncreasing individuals\u2019 media literacy through education and training is one of the most frequently recommended countermeasures against disinformation.1 Proponents argue that \u201cmedia literacy and critical thinking are the first barrier to deception\u201d and that teaching people these skills therefore enables them to better identify false claims.2 The National Association for Media Literacy Education defines media literacy as \u201cthe ability to access, analyze, evaluate, create, and act using all forms of communication.\u201d However, scholars point to conceptual confusion around the term, and practitioners take many different approaches.3 Common goals include instilling knowledge of the media industry and journalistic practices, awareness of media manipulation and disinformation techniques, and familiarity with the internet and digital technologies.\nMedia literacy education initiatives target a range of different audiences, occur in multiple settings, and use a variety of methods\u2014including intensive classroom-based coursework as well as short online videos and games. Many programs focus on children and adolescents,4 with research suggesting that young people are less familiar with the workings of the internet and digital media and more susceptible to online hoaxes and propaganda than commonly assumed.5 For example, a 2016 study of over 7,800 students found many failed to distinguish sponsored content and untrustworthy websites in search results.6 Public education is therefore one major vehicle to reach large numbers of people early in their lives, alongside other kinds of youth programs. Aspects of media literacy have long been embedded in general education and liberal arts curricula in advanced democracies, especially in subjects that emphasize critical reading and thinking, such as language arts, essay writing, civics, and rhetoric. Public libraries have also historically promoted media literacy.\nNot all media literacy programs target young people. After all, people don\u2019t necessarily age out of their susceptibility to disinformation; in fact, older individuals seem more likely to share false stories on Facebook.7 Media literacy training for adults may happen at libraries, senior citizen centers, recreational events, or professional settings. Civil society and government agencies have also run public awareness campaigns and released gamified education tools. For example, Sweden established a Psychological Defence Agency in 2022. Its responsibilities include leading \u201ctraining, exercises and knowledge development\u201d to help residents \u201cidentify and counter foreign malign information influence, disinformation and other dissemination of misleading information directed at Sweden.\u201d8\nOne valuable case study is the International Research and Exchanges Board (IREX)\u2019s Learn to Discern program, which has used a \u201ctrain the trainers\u201d approach in Ukraine and a number of other countries since 2015. This program equips volunteers to deliver a media literacy curriculum to members of their community.9 Reaching more vulnerable adults (for example, racial and ethnic minorities and those with fewer economic resources, less education, or less experience with the internet) is a policy priority for governments focused on media literacy.10\nHow Much Do We Know?\nThe body of scholarship on media literacy is large relative to most other disinformation countermeasures. For example, a 2022 literature review on digital literacy\u2014one component of media literacy\u2014found forty-three English-language studies since 2001, with thirty-three of these published since 2017, when interest in the topic swelled.11 The existence of dedicated journals and conferences is another indicator of growth in this subfield. For example, the National Association for Media Literacy Education published the first issue of the Journal of Media Literacy Education in 2009.12 Other major repositories of research on media literacy include a database maintained by the United Nations Alliance of Civilizations.13\nReview of this literature shows that specific media literacy approaches have a strong theoretical basis and a large body of experimental evidence. However, variation in pedagogical approaches means the effectiveness of one program does not necessarily imply the effectiveness of another.14 Moreover, the lack of robust mechanisms for collecting data on classroom activities is a recognized gap. In 2018, the Media Literacy Programme Fund in the United Kingdom (considered a leader in media literacy education) cited grants to support evaluation as a priority.15 Since then, several studies have conducted real-time evaluation and sought to measure lasting improvements in student performance. Additional studies could expand the menu of possible approaches to evaluation; also useful would be to examine further the effectiveness of media literacy training for atypical individuals at the extremes, such as those who are especially motivated by partisanship, conspiracy theories, or radical ideologies.\nHow Effective Does It Seem?\nThere is significant evidence that media literacy training can help people identify false stories and unreliable news sources.16 Scholars sometimes refer to this as inoculation, because \u201cpreemptively exposing, warning, and familiarising people with the strategies used in the production of fake news helps confer cognitive immunity when exposed to real misinformation.\u201d17 One experiment found that playing an online browser game designed to expose players to six different disinformation strategies reduced subjects\u2019 susceptibility to false claims, especially among those users who were initially most vulnerable to being misled. Such laboratory findings are bolstered by studies of larger, real-world interventions. An evaluation of IREX\u2019s Learn to Discern program found durable increases in good media consumption habits, such as checking multiple sources, lasting up to eighteen months after delivery of the training. 18 Other studies support teaching students to read \u201claterally\u201d\u2014using additional, trusted sources to corroborate suspect information.19\nBecause media literacy comes in many forms, it is important to assess which variants are most effective at reducing belief in false stories so trainers and educators can prioritize them. Research suggests that the most successful variants empower motivated individuals to take control of their media consumption and seek out high-quality information. This has been described as \u201cactionable skepticism,\u201d or sometimes simply as \u201cinformation literacy.\u201d20 For example, a 2019 review in American Behavioral Scientist examined various factors that might enable someone to recognize false news stories. They found that people\u2019s \u201cabilities to navigate and find information online that is verified and reliable\u201d\u2014for example, differentiating between an encyclopedia and a scientific journal\u2014was an important predictor. In contrast, subjects\u2019 understanding of the media industry and journalistic practices or their self-reported ability to \u201ccritically consume, question, and analyze information\u201d were not predictive.21 Later research based on survey data also supported these findings.22\nThe most successful variants empower motivated individuals to take control of their media consumption and seek out high-quality information.\nImportantly, multiple studies have shown that effective media literacy depends not only on people\u2019s skills but also on their feelings and self-perceptions. Specifically, individuals who feel confident in their ability to find high-quality news sources, and who feel responsible for proactively doing so, are less likely to believe misleading claims. This factor is often called an individual\u2019s \u201clocus of control,\u201d and it has been identified as important in studies of multiple nationally and demographically diverse populations.23 People who purposefully curate their information diet are less likely to be misled; passive consumers, on the other hand, are more vulnerable. However, this may be truer of typical news consumers than of outliers like extremists and very motivated partisans. The latter groups might self-report confidence in curating their media diet while nevertheless selecting for misleading, radical, or hyper-partisan sources.\nA growing body of recent literature based on large-scale classroom studies shows how specific techniques can provide news consumers with greater agency and ability to seek out accurate information.24 Whereas past forms of online media literacy education often focused on identifying markers of suspicious websites\u2014like typographical errors or other indicators of low quality\u2014these signs are less useful in the modern information environment, where sources of misinformation can have the appearance of high production value for low cost.25 Recent studies have shown that lateral reading is more effective.26 In one study of students at a public college in the northeastern United States, only 12 percent of subjects used lateral reading before receiving training on how to do so; afterward, more than half did, and students showed an overall greater ability to discern true claims from fictional ones.27 A similar study on university students in California found these effects endured after five weeks.28 Another one-day exercise with American middle school students found that students had a difficult time overcoming impressions formed from \u201csuperficial features\u201d on websites and should be trained to recognize different types of information sources, question the motivation behind them, and\u2014crucially\u2014compare those sources with known trustworthy sites.29\nTeaching people to recognize unreliable news sources and common media manipulation tactics becomes even more effective when participants are also able to improve their locus of control, according to academic research and program evaluations. In a study of media literacy among 500 teenagers, researchers found that students with higher locus of control were more resilient against false stories. In another study based on survey data, researchers found that individuals who exhibited high locus of control and the ability to identify false stories were more likely to take corrective action on social media, such as reporting to the platform or educating the poster.30 (The participatory nature of social media increases the importance of educating users not only on how to recognize untrustworthy content but also on how to respond to and avoid sharing it.31)\nEvaluations of IREX\u2019s Learn to Discern program in Ukraine and a similar program run by PEN America in the United States shed further light on locus of control. These curricula\u2019s focus on identifying untrustworthy content led subjects to become overly skeptical of all media. While trainees\u2019 ability to identify disinformation and their knowledge of the news media increased, their locus of control changed only slightly. Ultimately, trainees\u2019 ability to identify accurate news stories did not improve, and they remained distrustful of the media as a whole.32 A major challenge, then, is news consumers who feel under threat from the information environment rather than empowered to inform themselves. One potential intervention point could be social media platforms, which can provide tools and make other design choices to help users compare on-platform information with credible external sources (see case study 4). This could reinforce users\u2019 locus of control while assisting them in exercising it.\nEducators should be mindful of media literacy expert Paul Mihailidis\u2019s warning that \u201ccritical thought can quickly become cynical thought.\u201d33 In a 2018 essay, media scholar danah boyd argued that individuals who are both cynical about institutions and equipped to critique them can become believers in, and advocates for, conspiracy theories and disinformation. To avoid this trap, media literacy education must be designed carefully. This means empowering people to engage with media critically, constructively, and discerningly rather than through the lenses of undifferentiated paranoia and distrust.34\nHow Easily Does It Scale?\nWhile media literacy training shows promise, it suffers challenges from speed, scale, and targeting. Many approaches will take years to reach large numbers of people, including many vulnerable and hard-to-reach populations. Attempts to reach scale through faster, leaner approaches, like gamified online modules or community-based efforts to train the trainers, are highly voluntary and most likely to impact already motivated individuals rather than large percentages of the public.\nMany media literacy projects are not particularly expensive to deliver to small audiences. However, achieving wide impact requires high-scale delivery, such as integrating media literacy into major institutions like public education\u2014a costly proposition. When a proposed 2010 bill in the U.S. Congress, the Healthy Media for Youth Act, called for $40 million for youth media literacy initiatives, leading scholars deemed the amount insufficient and advocated for larger financial commitments from the government, foundations, and the private sector.35\nOnce the resources and curricula are in place, it will still take time to develop necessary infrastructure to implement large-scale media literacy programs. For example, hiring skilled educators is a critical yet difficult task. Studies from the European Union (EU) and South Africa both identified major deficiencies in teachers\u2019 own abilities to define core media literacy concepts or practice those concepts themselves.36\nNotes\n1 For examples, see Lucas and Pomeranzev, \u201cWinning the Information War\u201d; Katar\u00edna Klingov\u00e1 and Daniel Milo, \u201cCountering Information War Lessons Learned from NATO and Partner Countries: Recommendations and Conclusions,\u201d GLOBSEC, February 2017, https://www.globsec.org/what-we-do/publications/countering-information-war-lessons-learned-nato-and-partner-countries; Claire Wardle and Hossein Derakhshan, \u201cInformation Disorder: Toward an Interdisciplinary Framework for Research and Policy Making,\u201d Council of Europe, September 2017, https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c; Daniel Fried and Alina Polyakova, \u201cDemocratic Defense Against Disinformation,\u201d Atlantic Council, February 2018, https://www.atlanticcouncil.org/wp-content/uploads/2018/03/Democratic_Defense_Against_Disinformation_FINAL.pdf; \u201cA Multi-Dimensional Approach,\u201d European Commission; Erik Brattberg and Tim Maurer, \u201cRussian Election Interference: Europe\u2019s Counter to Fake News and Cyber Attacks,\u201d Carnegie Endowment for International Peace, May 2018, https://carnegieendowment.org/files/CP_333_BrattbergMaurer_Russia_Elections_Interference_FINAL.pdf; \u201cAction Plan Against Disinformation,\u201d European Commission, May 2018, https://www.eeas.europa.eu/node/54866_en; Fly, Rosenberger, and Salvo, \u201cThe ASD Policy Blueprint\u201d; Jean-Baptiste Jeang\u00e8ne Vilmer, Alexandre Escorcia, Marine Guillaume, and Janaina Herrera, \u201cInformation Manipulation: A Challenge for Our Democracies,\u201d French Ministry for Europe and Foreign Affairs and the Institute for Strategic Research, August 2018, https://www.diplomatie.gouv.fr/IMG/pdf/information_manipulation_rvb_cle838736.pdf; Todd C. Helmus et al., \u201cRussian Social Media Influence: Understanding Russian Propaganda in Eastern Europe,\u201d RAND Corporation, 2018, https://www.rand.org/pubs/research_reports/RR2237.html; and Paul Barrett, \u201cTackling Domestic Disinformation: What the Social Media Companies Need to Do,\u201d New York University, March 2019, https://issuu.com/nyusterncenterforbusinessandhumanri/docs/nyu_domestic_disinformation_digital?e=31640827/68184927.\n2 Klingov\u00e1 and Milo, \u201cCountering Information War.\u201d\n3 \u201cMedia Literacy Defined,\u201d National Association for Media Literacy Education, accessed February 13, 2023, https://namle.net/resources/media-literacy-defined/. See also Monica Bulger and Patrick Davison, \u201cThe Promises, Challenges, and Futures of Media Literacy,\u201d Data & Society, February 21, 2018, https://datasociety.net/library/the-promises-challenges-and-futures-of-media-literacy/; and G\u00e9raldine Wuyckens, Normand Landry, and Pierre Fastrez, \u201cUntangling Media Literacy, Information Literacy, and Digital Literacy: A Systematic Meta-review of Core Concepts in Media Education,\u201d Journal of Media Literacy Education 14, no. 1 (2022): https://digitalcommons.uri.edu/cgi/viewcontent.cgi?article=1531&context=jmle.\n4 Renee Hobbs, \u201cDigital and Media Literacy: A Plan of Action,\u201d Aspen Institute, 2010, https://www.aspeninstitute.org/wp-content/uploads/2010/11/Digital_and_Media_Literacy.pdf; and \u201cOnline Media Literacy Strategy,\u201d UK Department for Digital, Culture, Media, & Sport, July 2021, https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1004233/DCMS_Media_Literacy_Report_Roll_Out_Accessible_PDF.pdf.\n5 Tiffany Hsu, \u201cWhen Teens Find Misinformation, These Teachers Are Ready,\u201d New York Times, September 8, 2022, https://www.nytimes.com/2022/09/08/technology/misinformation-students-media-literacy.html; \u201cA Global Study on Information Literacy: Understanding Generational Behaviors and Concerns Around False and Misleading Information Online,\u201d Poynter Institute, August 2022, https://www.poynter.org/wp-content/uploads/2022/08/A-Global-Study-on-Information-Literacy-1.pdf; and Elena-Alexandra Dumitru, \u201cTesting Children and Adolescents\u2019 Ability to Identify Fake News: A Combined Design of Quasi-Experiment and Group Discussions,\u201d Societies 10, no. 3 (September 2020): https://www.mdpi.com/2075-4698/10/3/71/htm.\n6 Sam Wineburg, Sarah McGrew, Joel Breakstone, and Teresa Ortega, \u201cEvaluating Information: The Cornerstone of Civic Online Reasoning,\u201d Stanford Digital Repository, November 22, 2016, https://purl.stanford.edu/fv751yt5934.\n7 For evidence that older users are more likely to share false stories on Facebook, see Andrew Guess, Jonathan Nagler, and Joshua Tucker, \u201cLess Than You Think: Prevalence and Predictors of Fake News Dissemination on Facebook,\u201d Science Advances 5, no. 1 (2019): https://www.science.org/doi/10.1126/sciadv.aau4586.\n8 Elisabeth Braw, \u201cCreate a Psychological Defence Agency to \u2018Prebunk\u2019 Fake News,\u201d Prospect, December 8, 2022, https://www.prospectmagazine.co.uk/politics/60291/create-a-psychological-defence-agency-to-prebunk-fake-news; and Adela Suliman, \u201cSweden Sets Up Psychological Defense Agency to Fight Fake News, Foreign Interference,\u201d Washington Post, January 6, 2022, https://www.washingtonpost.com/world/2022/01/06/sweden-fake-news-psychological-defence-agency.\n9 Erin Murrock, Joy Amulya, Mehri Druckman, and Tetiana Liubyva, \u201cWinning the War on State-Sponsored Propaganda: Gains in the Ability to Detect Disinformation a Year and a Half After Completing a Ukrainian News Media Literacy Program,\u201d Journal of Media Literacy Education 10, no. 2 (2018): https://digitalcommons.uri.edu/cgi/viewcontent.cgi?article=1361&context=jmle.\n10 \u201cOnline Media Literacy Strategy,\u201d UK Department for Digital, Culture, Media, & Sport; and Kara Brisson-Boivin and Samantha McAleese, \u201cFrom Access to Engagement: Building a Digital Media Literacy Strategy for Canada,\u201d MediaSmarts, 2022, https://mediasmarts.ca/research-reports/access-engagement-building-digital-media-literacy-strategy-canada.\n11 Hasan Tinmaz, Yoo-Taek Lee, Mina Fanea-Ivanovici, and Hasnan Baber, \u201cA Systematic Review on Digital Literacy,\u201d Smart Learning Environments 9 (2022), https://slejournal.springeropen.com/articles/10.1186/s40561-022-00204-y.\n12 \u201cHistory,\u201d National Association for Media Literacy Education, accessed February 13, 2023, https://namle.net/about/history/.\n13 \u201cMedia & Information Literacy,\u201d UN Alliance of Civilizations, accessed March 26, 2023, https://milunesco.unaoc.org/mil-organizations/acma-digital-media-literacy-research-program.\n14 \u201cMedia & Information Literacy,\u201d UN Alliance of Civilizations.\n15 \u201cOnline Media Literacy Strategy,\u201d UK Department for Digital, Culture, Media, & Sport; \u201cMedia Literacy Programme Fund,\u201d Government of the United Kingdom, accessed March 26, 2023, https://www.gov.uk/guidance/media-literacy-programme-fund; and Bulger and Davison, \u201cPromises, Challenges, and Futures.\u201d\n16 Consider Bulger and Davison, \u201cPromises, Challenges, and Futures,\u201d as well as Theodora Dame Adjin-Tettey, \u201cCombating Fake News, Disinformation, and Misinformation: Experimental Evidence for Media Literacy Education,\u201d Cogent Arts & Humanities 9 (2022): https://www.tandfonline.com/doi/full/10.1080/23311983.2022.2037229.\n17 Jon Roozenbeek and Sander van der Linden, \u201cFake News Game Confers Psychological Resistance Against Online Misinformation,\u201d Palgrave Communications 5 (2019): https://www.nature.com/articles/s41599-019-0279-9.\n18 Murrock, Amulya, Druckman, and Liubyva, \u201cWinning the War.\u201d\n19 Carl-Anton Werner Axelsson, Mona Guath, and Thomas Nygren, \u201cLearning How to Separate Fake From Real News: Scalable Digital Tutorials Promoting Students\u2019 Civic Online Reasoning,\u201d Future Internet 13, no. 3 (2021): https://www.mdpi.com/1999-5903/13/3/60.\n20 Jennifer Fleming, \u201cMedia Literacy, News Literacy, or News Appreciation? A Case Study of the News Literacy Program at Stony Brook University,\u201d Journalism & Mass Communication Educator 69, no. 2 (2013): https://journals.sagepub.com/doi/abs/10.1177/1077695813517885.\n21 Because the measurement of media literacy was self-reported, the study posits this as an example of the \u201cDunning-Kruger effect\u201d: an individual\u2019s (over)confidence in their ability to critically consume media is related to their susceptibility to deception. See Mo Jones-Jang, Tara Mortensen, and Jingjing Liu, \u201cDoes Media Literacy Help Identification of Fake News? Information Literacy Helps, but Other Literacies Don\u2019t,\u201d American Behavioral Scientist (August 2019): https://www.researchgate.net/publication/335352499_Does_Media_Literacy_Help_Identification_of_Fake_News_Information_Literacy_Helps_but_Other_Literacies_Don't.\n22 Brigitte Huber, Porismita Borah, and Homero Gil de Z\u00fa\u00f1iga, \u201cTaking Corrective Action When Exposed to Fake News: The Role of Fake News Literacy,\u201d Journal of Media Literacy Education 14 (July 2022): https://www.researchgate.net/publication/362513295_Taking_corrective_action_when_exposed_to_fake_news_The_role_of_fake_news_literacy.\n23 Murrock, Amulya, Druckman, and Liubyva, \u201cWinning the War\u201d; and \u201cImpact Report: Evaluating PEN America's Media Literacy Program,\u201d PEN America & Stanford Social Media Lab, September 2022, https://pen.org/report/the-impact-of-community-based-digital-literacy-interventions-on-disinformation-resilience. See also Yan Su, Danielle Ka Lai Lee, and Xizhu Xiao, \u201c\u2018I Enjoy Thinking Critically, and I\u2019m in Control\u2019: Examining the Influences of Media Literacy Factors on Misperceptions Amidst the COVID-19 Infodemic,\u201d Computers in Human Behavior 128 (2022): https://www.sciencedirect.com/science/article/pii/S0747563221004349, a study based on subjects in China. The similar findings between the United States, Ukraine, and China\u2014despite significant differences in the three countries\u2019 media systems and histories\u2014is noteworthy.\n24 See generally: Folco Panizza et al., \u201cLateral Reading and Monetary Incentives to Spot Disinformation About Science,\u201d Scientific Reports 12 (2022): https://www.nature.com/articles/s41598-022-09168-y; Sam Wineburg et al., \u201cLateral Reading on the Open Internet: A District-Wide Field Study in High School Government Classes,\u201d Journal of Educational Psychology 114, no. 5 (2022): https://www.studocu.com/id/document/universitas-kristen-satya-wacana/social-psychology/lateral-reading-on-the-open-internet-a-district-wide-field-study-in-high-school-government-classes/45457099; and Joel Breakstone et al., \u201cLateral Reading: College Students Learn to Critically Evaluate Internet Sources in an Online Course,\u201d Harvard Kennedy School Misinformation Review 2 (2021), https://misinforeview.hks.harvard.edu/article/lateral-reading-college-students-learn-to-critically-evaluate-internet-sources-in-an-online-course.\n25 For more on this method, its success in classroom trials, and its departure from previous forms of media literacy education, see D. Pavlounis, J. Johnston, J. Brodsky, and P. Brooks, \u201cThe Digital Media Literacy Gap: How to Build Widespread Resilience to False and Misleading Information Using Evidence-Based Classroom Tools,\u201d CIVIX Canada, November 2021, https://ctrl-f.ca/en/wp-content/uploads/2021/11/The-Digital-Media-Literacy-Gap-Nov-7.pdf.\n26 Axelsson, Guath, and Nygren, \u201cLearning How to Separate.\u201d\n27 Jessica E. Brodsky et al., \u201cAssociations Between Online Instruction in Lateral Reading Strategies and Fact-Checking COVID-19 News Among College Students,\u201d AERA Open (2021): https://journals.sagepub.com/doi/full/10.1177/23328584211038937.\n28 Sarah McGrew, Mark Smith, Joel Breakstone, Teresa Ortega, and Sam Wineburg, \u201cImproving University Students\u2019 Web Savvy: An Intervention Study,\u201d British Journal of Educational Psychology 89, no. 3 (September 2019): https://bpspsychub.onlinelibrary.wiley.com/doi/10.1111/bjep.12279.\n29 Angela Kohnen, Gillian Mertens, and Shelby Boehm, \u201cCan Middle Schoolers Learn to Read the Web Like Experts? Possibilities and Limits of a Strategy-Based Intervention,\u201d Journal of Media Literacy Education 12, no. 2 (2020): https://digitalcommons.uri.edu/cgi/viewcontent.cgi?article=1457&context=jmle.\n30 Adam Maksl, Seth Ashley, and Stephanie Craft, \u201cMeasuring News Media Literacy,\u201d Journal of Media Literacy Education 6 (2015), https://digitalcommons.uri.edu/jmle/vol6/iss3/3/; and Huber, Borah, and Z\u00fa\u00f1iga, \u201cTaking Corrective Action.\u201d\n31 Bulger and Davison, \u201cPromises, Challenges, and Futures.\u201d\n32 Like Jones-Jang, Mortensen, and Liu, the authors of the IREX evaluation suggest that the \u201cfalse sense of control\u201d already felt by individuals who did not receive media literacy training may also partially explain the relatively small improvements in these subjects\u2019 locus of control.\n33 Paul Mihailidis, \u201cBeyond Cynicism: Media Education and Civic Learning Outcomes in the University,\u201d International Journal of Learning and Media 1, no. 3 (August 2009): https://www.researchgate.net/publication/250958225_Beyond_Cynicism_Media_Education_and_Civic_Learning_Outcomes_in_the_University.\n34 \u201cYou Think You Want Media Literacy\u2026 Do You?\u201d danah boyd, apophenia, March 9, 2018, https://www.zephoria.org/thoughts/archives/2018/03/09/you-think-you-want-media-literacy-do-you.html.\n35 Hobbs, \u201cDigital and Media Literacy.\u201d\n36 Sandy Zinn, Christine Stilwell, and Ruth Hoskins, \u201cInformation Literacy Education in the South African Classroom: Reflections from Teachers\u2019 Journals in the Western Cape Province,\u201d Libri 66 (April 2016): https://www.degruyter.com/document/doi/10.1515/libri-2015-0102/html; and Maria Ranieri, Isabella Bruni, and Anne-Claire Orban de Xivry, \u201cTeachers\u2019 Professional Development on Digital and Media Literacy. Findings and Recommendations From a European Project,\u201d Research on Education and Media 9, no. 2 (2017): https://sciendo.com/article/10.1515/rem-2017-0009.\nCase Study 3: Fact-Checking\nKey takeaways:\nA large body of research indicates that fact-checking can be an effective way to correct false beliefs about specific claims, especially for audiences that are not heavily invested in the partisan elements of the claims. However, influencing factual beliefs does not necessarily result in attitudinal or behavioral changes, such as reduced support for a deceitful politician or a baseless policy proposal. Moreover, the efficacy of fact-checking depends a great deal on contextual factors\u2014such as wording, presentation, and source\u2014that are not well understood. Even so, fact-checking seems unlikely to cause a backfire effect that leads people to double down on false beliefs. Fact-checkers face a structural disadvantage in that false claims can be created more cheaply and disseminated more quickly than corrective information; conceivably, technological innovations could help shift this balance.\nKey sources:\n- Brendan Nyhan, Ethan Porter, Jason Reifler, Thomas Wood, \u201cTaking Fact-Checks Literally But Not Seriously? The Effects of Journalistic Fact-Checking on Factual Beliefs and Candidate Favorability,\u201d Political Behavior 42 (2019): https://link.springer.com/article/10.1007/s11109-019-09528-x.\n- Thomas Wood and Ethan Porter, \u201cThe Elusive Backfire Effect: Mass Attitudes\u2019 Steadfast Factual Adherence,\u201d Political Behavior 41 (2019): https://link.springer.com/article/10.1007/s11109-018-9443-y.\n- Emily Thorson, \u201cBelief Echoes: The Persistent Effects of Corrected Misinformation,\u201d Political Communication 33 (2015): https://www.tandfonline.com/doi/full/10.1080/10584609.2015.1102187.\nDescription and Use Cases\nFact-checking, in this report, refers broadly to the issuance of corrective information to debunk a false or misleading claim. A 2020 global survey by Carnegie identified 176 initiatives focused on fact-checking and journalism, while the Duke University Reporters\u2019 Lab counted more than 400 active fact-checking efforts across more than 100 countries in 2023.1 These initiatives come in many different forms. They include dedicated, stand-alone organizations, such as Snopes, as well as fact-checkers integrated into newspapers and TV programs. Some prioritize political claims, like the Washington Post\u2019s \u201cFact Checker\u201d and the website PolitiFact. Others address health claims, like the CoronaVirusFacts/DatosCoronaVirus Alliance Database led by the International Fact-Checking Network at the Poynter Institute.2\nCollaborative fact-checking models uniting the efforts of several organizations have also emerged, like Verificado 2018, an effort to collect rumors and disinformation circulating on WhatsApp during the 2018 Mexican elections and deliver corrections through private messaging.3 Projects like this attempt to quickly reach a large audience through a medium people already use. Other initiatives in multiple countries have attempted to crowdsource from citizen fact-checkers.\nIn recent years, some social media companies have highlighted fact-checks on their platforms and used the assessments of fact-checkers to inform other policy actions. For example, Meta\u2019s third-party fact-checking program routes Facebook and Instagram posts that contain potential falsehoods to fact-checkers certified through the International Fact-Checking Network and applies a label if the posts are false or disputed.4 (For more on social media labeling, see case study 4.) Beyond social media, fact-checks can also be disseminated on dedicated websites or during televised political debates, among other possibilities.\nHow Much Do We Know?\nFact-checking is well-studied\u2014markedly more so than other interventions. Nearly 200 articles related to fact-checking published since 2013 were reviewed for this case study. However, the strong empirical research base also reveals that fact-checking\u2019s effectiveness depends on a complex interplay of multiple factors which remain poorly understood. Research has only begun to probe the specific parameters that apparently affect fact-checking\u2019s impact, such as format, language, and source. Additionally, much of the academic literature on fact-checking comes from laboratory studies based on unrepresentative samples of university students, or from online quizzes based on crowdsourcing platforms like Amazon\u2019s Mechanical Turk\u2014raising questions about the findings\u2019 generalizability. Among other problems, the subjects of such studies may be more interested or engaged with fact-checking content presented to them by experimenters, as compared with members of the general public who encounter such content organically. More research evaluating the longitudinal impact of ongoing fact-checking efforts in a diverse set of real-time, real-world environments is still needed.\nHow Effective Does It Seem?\nA number of studies suggest that it is easier to cause people to disbelieve false claims but harder to change the behaviors related to those beliefs. For example, international studies have shown fact-checks to have some success at changing beliefs about viral diseases, but they do not always lead to increased intent to receive vaccines or improved public health behaviors.5 This disconnect may be especially large for politically charged topics in divided societies. Fact-checking the claims of political figures has limited impact on voters\u2019 support for a candidate or policy position\u2014even when the voters can correctly reject false claims.6\nIn general, studies find strong evidence of confirmation bias: subjects are more susceptible to false claims that align with preexisting beliefs or allegiances and are more resistant to fact-checks associated with an opposing political party or its positions.7 In fact, research suggests that accuracy is not always a top-of-mind issue for news consumers. For example, one 2013 study suggested that individuals put more stock in the perceived trustworthiness (or sincerity) of a corrective source than in the source\u2019s actual expertise on the relevant topic.8 In another study, right-leaning, U.S.-based participants who were asked to judge the validity of articles tended to provide \u201cexpressive\u201d assessments\u2014aimed more at demonstrating their partisan allegiance than at seriously evaluating a source\u2019s credibility.9 To be sure, many studies of fact-checking and confirmation bias focus on U.S. audiences, where political polarization is especially strong.10 It is possible that partisan barriers to fact-checking are less present in more unified societies.11\nSome research initially sparked concern that fact-checking might perversely cause audiences to double down on their false beliefs. The term \u201cbackfire effect\u201d was initially coined to describe this behavior in a 2010 article by political scientists Brendan Nyhan and Jason Reifler and took root in American public consciousness after the 2016 U.S. presidential election.12 However, more recent research (including by Nyhan) suggests that backfiring may be a rare phenomenon.\nThe efficacy of fact-checks depends on many factors. The precise wording of fact-checks matters, with more straightforward refutations being more effective than nuanced explanations. Additionally, one 2015 study found that a fact-check that provides an alternative \u201ccausal explanation for an unexplained event is significantly more effective than a denial even when the denial is backed by unusually strong evidence.\u201d13 In other words, replacing a false story with a true story works better than merely refuting the false story. However, many of these factors remain poorly understood; for example, research is inconclusive on whether fact-checks should repeat the false claim being debunked or avoid doing so.\nThe use of emotion and storytelling in fact-checks is another potentially important but under-researched area. One study found that \u201cnarrative correctives,\u201d which embed fact-checks within an engaging story, can be effective\u2014and stories that end on an emotional note, such as fear or anger, work better than those that do not.14 Another study suggested that anger and anxiety increase motivated reasoning and partisan reactions, although this did not seem to prevent fact-checks from influencing users.15\nOne of the most important outstanding research areas is the durability of fact-checks: how long is corrective information remembered and believed by the recipient? Studies have reached complicated or conflicting results. Some research, for example, has suggested that a recipient\u2019s increase in knowledge of truthful information may last longer than any change in deeper beliefs or attitudes related to that knowledge.16 This finding highlights an important difference between informational knowledge and affective feeling\u2014both of which influence people\u2019s beliefs and behaviors. A 2015 study found evidence that misinformation affected the audience\u2019s sentiment toward public figures even after false claims were immediately debunked.17\nHow Easily Does It Scale?\nThe large number of ongoing fact-checking efforts around the world indicates that this intervention can be undertaken at reasonable expense. Some efforts, such as those incorporated into for-profit journalistic enterprises, may even be self-sustaining\u2014whether on their own or as part of a larger business model. Initiatives like the International Fact-Checking Network have received financial and other support from philanthropists, tech companies, and universities.\nFact-checking does face at least two scaling challenges. First, it often takes much more time and expertise to produce a fact-check than to generate the false content being debunked. So long as fact-checkers face this structural disadvantage, fact-checking cannot be a comprehensive solution to disinformation. Rather than scale up to match the full scope of false claims, fact-checkers must instead do triage. Second, fact-checks require distribution mechanisms capable of competing effectively with the spread of disinformation. This means finding ways to reach the audience segments most vulnerable to disinformation. The faster and the more frequent the fact-checks, the better. Ideally, fact-checking should occur before or at the same time as the false information is presented. But this is no easy task. Given the significant investments already being made to produce fact-checks, funders should ensure that distribution mechanisms are sufficient to fully leverage fact-checkers\u2019 work.\nTechnological innovation may help to reduce the cost of producing high-quality fact-checks and enable their rapid dissemination. Crowdsourcing methods, such as Twitter\u2019s Birdwatch (later renamed Community Notes on X), are one approach that merits further study.18 Others have begun to test whether generative AI can be used to perform fact-checks. While today\u2019s generative AI tools are too unreliable to produce accurate fact-checks without human supervision, they may nevertheless assist human fact-checkers in certain research and verification tasks, lowering costs and increasing speed.19 Ultimately, both crowdsourcing and AI methods still depend on the availability of authoritative, discoverable facts by which claims can be assessed. Producing this factual baseline\u2014whether through science, journalism, or other knowledge-seeking efforts\u2014is an important part of the fact-checking cycle. This too requires funding.\nNotes\n1 Victoria Smith, \u201cMapping Worldwide Initiatives to Counter Influence Operations,\u201d Carnegie Endowment for International Peace, December 14, 2020, https://carnegieendowment.org/2020/12/14/mapping-worldwide-initiatives-to-counter-influence-operations-pub-83435; and \u201cFact-Checking,\u201d Duke Reporter\u2019s Lab, accessed January 27, 2023, https://reporterslab.org/fact-checking.\n2 \u201cThe CoronaVirusFacts/DatosCoronaVirus Alliance Database,\u201d Poynter Institute, accessed December 10, 2023, https://www.poynter.org/ifcn-covid-19-misinformation.\n3 \u201cVerificado 2018,\u201d Online Journalism Awards, accessed December 10, 2023, https://awards.journalists.org/entries/verificado-2018.\n4 \u201cAbout Fact-Checking on Facebook and Instagram,\u201d Meta, accessed March 22, 2023, https://www.facebook.com/business/help/2593586717571940?id=673052479947730.\n5 John M. Carey et al., \u201cThe Effects of Corrective Information About Disease Epidemics and Outbreaks: Evidence From Zika and Yellow Fever in Brazil,\u201d Science Advances 6 (2020), https://www.science.org/doi/10.1126/sciadv.aaw7449; Jeremy Bowles, Horacio Larreguy, and Shelley Liu, \u201cCountering Misinformation via WhatsApp: Preliminary Evidence From the COVID-19 Pandemic in Zimbabwe,\u201d PLOS ONE 15 (2020), https://doi.org/10.1371/journal.pone.0240005; and Sara Pluviano, Sergio Della Sala, and Caroline Watt, \u201cThe Effects of Source Expertise and Trustworthiness on Recollection: The Case of Vaccine Misinformation,\u201d Cognitive Processing 21 (2020), https://pubmed.ncbi.nlm.nih.gov/32333126/.\n6 See Brendan Nyhan, Ethan Porter, Jason Reifler, and Thomas Wood, \u201cTaking Fact-Checks Literally but Not Seriously? The Effects of Journalistic Fact-Checking on Factual Beliefs and Candidate Favorability,\u201d Political Behavior 42 (2019): https://link.springer.com/article/10.1007/s11109-019-09528-x; Briony Swire-Thompson, Ullrich K. H. Ecker, Stephan Lewandowsky, and Adam J. Berinsky, \u201cThey Might Be a Liar But They\u2019re My Liar: Source Evaluation and the Prevalence of Misinformation,\u201d Political Psychology 41 (2020), https://onlinelibrary.wiley.com/doi/abs/10.1111/pops.12586; Oscar Barrera, Sergei Guriev, Emeric Henry, and Ekaterina Zhuravskaya, \u201cFacts, Alternative Facts, and Fact Checking in Times of Post-Truth Politics,\u201d Journal of Public Economics 182 (2017), https://www.sciencedirect.com/science/article/pii/S0047272719301859; and Briony Swire, Adam J. Berinsky, Stephan Lewandowsky, and Ullrich K. H. Ecker, \u201cProcessing Political Misinformation: Comprehending the Trump Phenomenon,\u201d Royal Society Open Science 4 (2017), https://royalsocietypublishing.org/doi/10.1098/rsos.160802.\n7 Antino Kim and Alan R. Dennis, \u201cSays Who? The Effects of Presentation Format and Source Rating on Fake News in Social Media,\u201d MIS Quarterly 43, no. 3 (2019): https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2987866; Ethan Porter, Thomas J. Wood, and David Kirby, \u201cSex Trafficking, Russian Infiltration, Birth Certificates, and Pedophilia: A Survey Experiment Correcting Fake News,\u201d Journal of Experimental Political Science 5, no. 2 (2018): https://www.cambridge.org/core/journals/journal-of-experimental-political-science/article/sex-trafficking-russian-infiltration-birth-certificates-and-pedophilia-a-survey-experiment-correcting-fake-news/CFEB9AFD5F0AEB64DF32D5A7641805B6; and Jeong-woo Jang, Eun-Ju Lee, and Soo Yun Shin, \u201cWhat Debunking of Misinformation Does and Doesn\u2019t,\u201d Cyberpsychology, Behavior, and Social Networking 22, no. 6 (2019): https://pubmed.ncbi.nlm.nih.gov/31135182.\n8 Jimmeka J. Guillory and Lisa Geraci \u201cCorrecting Erroneous Inferences in Memory: The Role of Source Credibility,\u201d Journal of Applied Research in Memory and Cognition 2, no. 4 (2013): https://doi.org/10.1016/j.jarmac.2013.10.001; and Pluviano and Della Sala, \u201cEffects of Source Expertise.\u201d\n9 Maurice Jakesch, Moran Koren, Anna Evtushenko, and Mor Naaman, \u201cThe Role of Source, Headline and Expressive Responding in Political News Evaluation,\u201d SSRN, January 31, 2019, https://dx.doi.org/10.2139/ssrn.3306403.\n10 Consider Thomas Carothers and Andrew O\u2019Donohue, \u201cHow Americans Were Driven to Extremes: In the United States, Polarization Runs Particularly Deep,\u201d Foreign Affairs, September 25, 2019, https://www.foreignaffairs.com/articles/united-states/2019-09-25/how-americans-were-driven-extremes.\n11 Consider Michael J. Aird, Ullrich K. H. Ecker, Briony Swire, Adam J. Berinsky, and Stephan Lewandowsky, \u201cDoes Truth Matter to Voters? The Effects of Correcting Political Misinformation in an Australian Sample,\u201d Royal Society Open Science (2018), https://royalsocietypublishing.org/doi/10.1098/rsos.180593.\n12 The backfire effect was captured in Brendan Nyhan and Jason Reifler, \u201cWhen Corrections Fail: The Persistence of Political Misperceptions,\u201d Political Behavior 32 (2010): https://link.springer.com/article/10.1007/s11109-010-9112-2. The popular online comic The Oatmeal featured commentary about the backfire effect, demonstrating its breakthrough into popular imagination; see \u201cBelieve,\u201d The Oatmeal, accessed January 27, 2023, https://theoatmeal.com/comics/believe. However, other studies have since called the effect into question. See Thomas Wood and Ethan Porter, \u201cThe Elusive Backfire Effect: Mass Attitudes\u2019 Steadfast Factual Adherence,\u201d Political Behavior 41 (2019): https://link.springer.com/article/10.1007/s11109-018-9443-y; see also Kathryn Haglin, \u201cThe Limitations of the Backfire Effect,\u201d Research & Politics 4 (2017): https://journals.sagepub.com/doi/10.1177/2053168017716547; and Brendan Nyhan, \u201cWhy the Backfire Effect Does Not Explain the Durability of Political Misperceptions,\u201d PNAS 118 (2020): https://www.pnas.org/doi/10.1073/pnas.1912440117.\n13 Brendan Nyhan and Jason Reifler, \u201cDisplacing Misinformation About Events: An Experimental Test of Causal Corrections,\u201d Journal of Experimental Political Science 2 (2015): https://www.cambridge.org/core/journals/journal-of-experimental-political-science/article/abs/displacing-misinformation-about-events-an-experimental-test-of-causal-corrections/69550AB61F4E3F7C2CD03532FC740D05.\n14 Angeline Sangalang, Yotam Ophir, and Joseph N. Cappella, \u201cThe Potential for Narrative Correctives to Combat Misinformation,\u201d Journal of Communication 69, no. 3 (2019): https://academic.oup.com/joc/article-abstract/69/3/298/5481803?redirectedFrom=fulltext.\n15 Brian E. Weeks, \u201cEmotions, Partisanship, and Misperceptions: How Anger and Anxiety Moderate the Effect of Partisan Bias on Susceptibility to Political Misinformation,\u201d Journal of Communication 65, no. 4 (2015): https://onlinelibrary.wiley.com/doi/abs/10.1111/jcom.12164.\n16 Ethan Porter and Thomas Wood, \u201cThe Global Effectiveness of Fact-Checking: Evidence From Simultaneous Experiments in Argentina, Nigeria, South Africa, and the United Kingdom,\u201d PNAS 118, no. 37 (2021): https://www.pnas.org/doi/10.1073/pnas.2104235118; see also John M. Carey et al., \u201cThe Ephemeral Effects of Fact-Checks on COVID-19 Misperceptions in the United States, Great Britain and Canada,\u201d Nature Human Behaviour 6 (2022), https://www.nature.com/articles/s41562-021-01278-3; and Patrick R. Rich and Maria S. Zaragoza, \u201cCorrecting Misinformation in News Stories: An Investigation of Correction Timing and Correction Durability,\u201d Journal of Applied Research in Memory and Cognition 9, no. 3 (2020): https://www.sciencedirect.com/science/article/abs/pii/S2211368120300280.\n17 Emily Thorson, \u201cBelief Echoes: The Persistent Effects of Corrected Misinformation,\u201d Political Communication 33, no. 3 (2015): https://www.tandfonline.com/doi/full/10.1080/10584609.2015.1102187.\n18 Consider Mevan Babakar, \u201cCrowdsourced Factchecking: A Pie in The Sky?\u201d European Journalism Observatory, June 1, 2018, https://en.ejo.ch/specialist-journalism/crowdsourced-factchecking-a-pie-in-the-sky. Studies suggest interventions from users can be as or more effective than interventions from experts: consider Leticia Bode and Emily K. Vraga, \u201cSee Something, Say Something: Correction of Global Health Misinformation on Social Media,\u201d Health Communication 33, no. 9 (2018): https://www.tandfonline.com/doi/full/10.1080/10410236.2017.1331312; and Jonas Colliander, \u201cThis is Fake News: Investigating the Role of Conformity to Other Users\u2019 Views When Commenting on and Spreading Disinformation in Social Media,\u201d Computers in Human Behavior 97 (August 2019): https://linkinghub.elsevier.com/retrieve/pii/S074756321930130X.\n19 Sam Guzik, \u201cAI Will Start Fact-Checking. We May Not Like the Results,\u201d Nieman Lab, December 2022, https://www.niemanlab.org/2022/12/ai-will-start-fact-checking-we-may-not-like-the-results; and Grace Abels, \u201cCan ChatGPT Fact-Check? We Tested,\u201d Nieman Lab, May 31, 2023, https://www.poynter.org/fact-checking/2023/chatgpt-ai-replace-fact-checking.\nCase Study 5: Counter-messaging Strategies\nKey takeaways:\nThere is strong evidence that truthful communications campaigns designed to engage people on a narrative and psychological level are more effective than facts alone. By targeting the deeper feelings and ideas that make false claims appealing, counter-messaging strategies have the potential to impact harder-to-reach audiences. Yet success depends on the complex interplay of many inscrutable factors. The best campaigns use careful audience analysis to select the most resonant messengers, mediums, themes, and styles\u2014but this is a costly process whose success is hard to measure. Promising techniques include communicating respect and empathy, appealing to prosocial values, and giving the audience a sense of agency.\nKey sources:\n- Jacob Davey, Henry Tuck, and Amarnath Amarasingam, \u201cAn Imprecise Science: Assessing Interventions for the Prevention, Disengagement and De-radicalisation of Left and Right-Wing Extremists,\u201d Institute for Strategic Dialogue, 2019, https://www.isdglobal.org/isd-publications/an-imprecise-science-assessing-interventions-for-the-prevention-disengagement-and-de-radicalisation-of-left-and-right-wing-extremists.\n- Rachel Brown and Laura Livingston, \u201cCounteracting Hate and Dangerous Speech Online: Strategies and Considerations,\u201d Toda Peace Institute, March 2019, https://toda.org/assets/files/resources/policy-briefs/t-pb-34_brown-and-livingston_counteracting-hate-and-dangerous-speech-online.pdf.\n- Benjamin J. Lee, \u201cInformal Countermessaging: The Potential and Perils of Informal Online Countermessaging,\u201d Studies in Conflict & Terrorism 42 (2018): https://www.tandfonline.com/doi/full/10.1080/1057610X.2018.1513697.\nDescription and Use Cases\nCounter-messaging, in this report, refers to truthful communications campaigns designed to compete with disinformation at a narrative and psychological level instead of relying solely on the presentation of facts. Counter-messaging is premised on the notion that evidence and logic aren\u2019t the only, or even the primary, bases of what people believe. Rather, research has shown that people more readily accept claims which jibe with their preexisting worldviews and accepted stories about how the world works, especially if framed in moral or emotional terms.1Moreover, claims are more persuasive when the messenger is a trusted in-group member who appears to respect the audience members and have their best interests at heart. While such factors often facilitate the spread of disinformation, counter-messaging campaigns seek to leverage them in service of truthful ideas.\nIn a sense, counter-messaging is no different from ordinary political communication, which routinely uses narratives, emotion, and surrogate messengers to persuade. But counter-messaging is sometimes implemented with the specific goal of countering disinformation\u2014often because purely rational appeals, like fact-checking, seem not to reach or have much impact on hard-core believers of false claims. By changing the narrative frame around an issue and speaking in ways designed to resonate, counter-messaging aims to make audiences more open to facts and less ready to accept sensational falsehoods.\nOne example comes from Poland, where xenophobia toward migrants from the Middle East during the Syrian civil war was fueled in part by false stories of disease and criminality.2 A Polish counter-messaging campaign called Our Daily Bread featured a video of refugees and other marginalized people baking bread, a cherished Polish activity. Rather than presenting facts and evidence about the impact of migration on Polish society or refuting false stories about migrants, the video instead used personal vignettes, evocative imagery, and unifying words. The video attracted significant media attention and was viewed more than 1 million times in the first day after its release.3 Similarly, many efforts to promote COVID-19 vaccines and counter disinformation about them employed themes of personal responsibility. Other such efforts focused on recruiting local doctors as messengers, based on the premise that many people trust their family doctors more than national authorities.4 Vaccine-related public messaging campaigns also partnered with Christian, Jewish, and Muslim faith leaders to reach religious communities in Israel, the United Kingdom, and the United States.5\nAs these examples indicate, counter-messaging is not always exclusively aimed at countering false claims; other common objectives include promoting desirable behaviors, bolstering social cohesion, and rallying support for government policies. Many initiatives have sought specifically to thwart terrorist recruitment under the banner of \u201ccountering violent extremism\u201d and \u201cderadicalization.\u201d For example, the Redirect Method developed by Jigsaw and Moonshot used digital advertising to steer individuals searching for extremist content toward \u201cconstructive alternate messages.\u201d6 Other approaches have used one-on-one online conversations or in-person mentorship relationships to dissuade those showing interest in extremism.7 While many of these efforts were designed to address Islamic extremists, they have also been applied to White supremacist and other hate groups.\nHow Much Do We Know?\nFor decades, disciplines such as social psychology, political science, communications, advertising, and media studies have researched issues relevant to counter-messaging. Fields that have themselves been subject to persistent disinformation\u2014such as public health and climate science\u2014have also devoted a great deal of attention to counter-messaging in recent years. Efforts to study and suppress hate and extremist groups are particularly relevant, because such groups often employ disinformation.8 Nevertheless, these bodies of knowledge, though replete with useful insights, have generally not used disinformation as their primary frame for evaluating the efficacy of counter-messaging. This leaves us to rely on analogies and parallels rather than direct evidence.\nThe relevant literature highlights how hard it is to assess the impact of any form of persuasion. For example, many studies of COVID-19-related counter-messages measured changes in subjects\u2019 reported attitudes or beliefs but were unable to verify whether those shifts persisted or led to behavioral changes.9 Studies based on surveys or laboratory experiments are common, but these do not fully capture how audiences react in more natural settings. In the field of countering violent extremism, practitioners report lacking the expertise or resources to evaluate the impact of their work beyond using social media engagement metrics and their gut instinct.10 A review of online counter-extremism interventions similarly found \u201cvirtually all\u201d of the evaluations included in the study measured processes, like social media engagement, not outcomes. The review offered several proposals for more impact-based assessments, such as the inclusion of calls to action like contacting a hotline, which can be quantified as a sign of behavior.11\nHow Effective Does It Seem?\nThe core insight of counter-messaging\u2014that communications tailored to the narrative and psychological needs of a specific audience are more effective than generic, purely fact-based approaches\u2014is well-established.12 Beyond this basic premise, however, it is difficult to generalize about counter-messaging because of the intervention\u2019s breadth, diversity, and overlap with ordinary politics. Some forms seem capable of affecting individuals\u2019 beliefs and, more rarely, influencing the behaviors informed by those beliefs. Yet success may often depend on the interplay of a large number of factors that can be difficult to discern or control. A granular understanding of the audience should, in theory, enable the selection of mediums, messengers, messages, styles, and tones most likely to resonate with them.13 In practice, developing this audience understanding is a difficult task and determining the best communication approaches is an evolving science at best.\nOne theme that emerges from many assessments of counter-messaging . . . is the importance of communicating respect and empathy.\nOne theme that emerges from many assessments of counter-messaging, including public health and counter-extremism interventions, is the importance of communicating respect and empathy. People are often put off by the sense that they are being debated or chastised.14 For example, counselors working with White supremacists had the most success in changing subjects\u2019 views through sustained dialogue that avoided moral judgement.15 Encouraging empathy toward others, such as religious minorities or immigrants, can also be effective; one study found that such messages make individuals more likely to delete their previous hate speech and less likely use hate speech again in the future.16 Similar efforts may be useful in reaching the so-called moveable middle, such as social media spectators who do not spread hateful content or false information themselves but are open to persuasion in either direction. For example, a study on anti-Roma hate speech in Slovakia found more users left pro-Roma comments on anti-Roma posts after researchers intervened with counter-speech.17\nOther studies have explored how moral and emotional framings affect audiences, including their perceptions of what is true. Studies of climate change skepticism found that the most effective messages for countering misinformation offer individuals the sense that they can take meaningful action, as opposed to messages that portray the world as doomed.18 A review of public health messaging found some audience segments were moved more by calls to protect themselves or loved ones than by appeals to social responsibility.19\nThe speaker of the counter-message seems to be quite important. Studies in the rural United States found that friends and family members, community organizations, religious leaders, and medical professionals were the most effective messengers in responding to COVID-19 rumors. In India, health professionals and peers were found to be the most trusted.20 Given the influence of informal messengers like social peers, analysts have considered the possibility of using them for official objectives.21 Volunteer groups countering disinformation, such as the Lithuanian Elves or the North Atlantic Fella Organization, can bring scale, authenticity, and creativity\u2014traits that official efforts often lack.22 Likewise, organic content used to rebut extremist claims and narratives appears more persuasive than government-created content.\nThere is a risk that poorly designed counter-messaging campaigns can entrench or elevate the very views being rebutted.23 A U.S. Department of State campaign called Think Again, Turn Away illustrates this problem. The anti\u2013Islamic State campaign, launched in 2013, engaged directly with extremists on Twitter but was ultimately deemed counterproductive. Its graphic content and combative tone increased the visibility of Islamic State accounts that replied to the campaign\u2019s posts with anti-U.S. rhetoric, while forcing the State Department to engage on unflattering topics like the torture of Iraqi prisoners at the Abu Ghraib prison.24 Critics have claimed that Think Again, Turn Away was not focused on the drivers of online extremism and was too clearly affiliated with the U.S. government to serve as a credible messenger. These shortcomings point to the complexities of effective counter-messaging and the need to carefully think through message control, effective messengers, appropriate mediums, and characteristics of the target audience.\nHow Easily Does It Scale?\nCounter-messaging faces implementation challenges due to its often reactive nature. Campaigns frequently arise in response to a belated recognition that disinformation narratives have already grown in strength and impact. Such narratives may have roots going back years, decades, or longer, and their adherents can build up psychological investments over a lifetime. The narratives underpinning disinformation also often evoke powerful emotions, like fear, which can be difficult to defuse once activated.25 To mitigate disinformation\u2019s first-mover advantages, counter-messengers can try to anticipate such narratives before they spread\u2014for example, predicting attacks on mail-in voting during the 2020 U.S. election\u2014but this is not always feasible.\nThe need to tailor counter-messaging to a specific audience and context makes scaling more difficult. Reaching large audiences may require breaking them into identifiable subpopulations, each of which would then receive its own research, message development, and novel or even competing strategies. Opting instead for a more generic, large-scale campaign risks undercutting much of the specificity associated with effective counter-messaging. Moreover, broad campaigns increase the odds of misfires, such as the use of messages or messengers that persuade one audience while making another audience double down on its initial beliefs. Elevating rumors or extremist viewpoints is a particular concern. When a concerning narrative is not yet widespread, campaigners may want to pair strategic silence on the national stage with more discrete messaging that targets specific populations more likely to encounter the narrative.26 When the narrative at issue has already become popular, a broad counter-messaging strategy may be appropriate. New digital technologies have the potential to make counter-messaging cheaper and easier to scale, just as innovation can aid in spreading disinformation.\nGiven the costs of effective counter-messaging at scale, many campaigns seem only modestly funded. The State Department\u2019s now-shuttered Center for Strategic Counterterrorism Communications spent only $6 million on digital outreach in 2012, the year before it launched Think Again, Turn Away.27 The center\u2019s successor entity, the Global Engagement Center, had a budget of more than $74 million in 2020.28 Australia\u2019s COVID-19 vaccine awareness campaign\u2014which included multiple mediums and consultants for outreach to specific vulnerable communities\u2014cost about $24 million.29 For comparison, major brands spend much, much more on advertising (about 10 percent of total revenue, according to one survey).30 Volunteer-driven efforts, like the North Atlantic Fella Organization, may be appealing partners for external funders due to their low cost and high authenticity. However, overt official support for such activities can diminish their credibility. Extremism scholar Benjamin Lee suggests that looser relationships involving \u201cprovision of tools and training\u201d might mitigate this risk.31\nNotes\n1 See Laura Livingston, \u201cUnderstanding the Context Around Content: Looking Behind Misinformation Narratives,\u201d National Endowment for Democracy, December 2021, https://www.ned.org/wp-content/uploads/2021/12/Understanding-the-Context-Around-Content-Looking-Behind-Misinformation-Narratives-Laura-Livingston.pdf; and Rachel Brown and Laura Livingston, \u201cCounteracting Hate and Dangerous Speech Online: Strategies and Considerations,\u201d Toda Peace Institute, March 2019, https://toda.org/assets/files/resources/policy-briefs/t-pb-34_brown-and-livingston_counteracting-hate-and-dangerous-speech-online.pdf. Additionally, consider Claire Wardle, \u201c6 Types of Misinformation Circulated This Election Season,\u201d Columbia Journalism Review, November 18, 2016, https://www.cjr.org/tow_center/6_types_election_fake_news.php; see also Paul Goble, \u201cHot Issue \u2013 Lies, Damned Lies and Russian Disinformation,\u201d Jamestown Foundation, August 13, 2014, https://jamestown.org/program/hot-issue-lies-damned-lies-and-russian-disinformation. As another example, Charleston mass murderer Dylann Roof claimed to have been radicalized after a Google search for \u201cblack on White crime.\u201d See Rebecca Hersher, \u201cWhat Happened When Dylann Roof Asked Google for Information About Race?\u201d NPR, January 10, 2017, https://www.npr.org/sections/thetwo-way/2017/01/10/508363607/what-happened-when-dylann-roof-asked-google-for-information-about-race.\n2 For analysis of anti-refugee and anti-migrant disinformation, see Judit Szak\u00e1cs and \u00c9va Bogn\u00e1r, \u201cThe Impact of Disinformation Campaigns About Migrants and Minority Groups in the EU,\u201d European Parliament, June 2021, https://www.europarl.europa.eu/RegData/etudes/IDAN/2021/653641/EXPO_IDA(2021)653641_EN.pdf.\n3 To be sure, view count alone does not imply effectiveness. For more about the Our Daily Bread campaign, see \u201cVideo Campaign Aims to Unify Poland Through the Power of Bread,\u201d Olga Mecking, NPR, May 21, 2018, https://www.npr.org/sections/thesalt/2018/05/21/611345277/video-campaign-aims-to-unify-poland-through-the-power-of-bread.\n4 Kevin B. O\u2019Reilly, \u201cTime for Doctors to Take Center Stage in COVID-19 Vaccine Push,\u201d American Medical Association, May 21, 2021, https://www.ama-assn.org/delivering-care/public-health/time-doctors-take-center-stage-covid-19-vaccine-push; and Steven Ross Johnson, \u201cDoctors Can Be Key to Higher COVID Vaccination Rates,\u201d U.S. News & World Report, February 28, 2022, https://www.usnews.com/news/health-news/articles/2022-02-28/primary-care-doctors-can-be-key-to-higher-covid-vaccination-rates.\n5 Filip Viskupi\u010d and David L. Wiltse, \u201cThe Messenger Matters: Religious Leaders and Overcoming COVID-19 Vaccine Hesitancy,\u201d Political Science & Politics 55, no. 3 (2022): https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/abs/messenger-matters-religious-leaders-and-overcoming-covid19-vaccine-hesitancy/ED93D8BB6C73C8B384986D28B877E284; and Daniel Estrin and Frank Langfitt, \u201cReligious Leaders Had to Fight Disinformation to Get Their Communities Vaccinated,\u201d NPR, April 23, 2021, https://www.npr.org/2021/04/23/990281552/religious-leaders-had-to-fight-disinformation-to-get-their-communities-vaccinate.\n6 \u201cThe Redirect Method,\u201d Moonshot, accessed March 6, 2023, https://moonshotteam.com/the-redirect-method/; and \u201cADL & Moonshot Partnered to Reduce Extremist Violence During US Presidential Election, Redirected Thousands Towards Safer Content,\u201d Anti-Defamation League, February 1, 2021, https://www.adl.org/resources/press-release/adl-moonshot-partnered-reduce-extremist-violence-during-us-presidential.\n7 Jacob Davey, Jonathan Birdwell, and Rebecca Skellett, \u201cCounter-conversations: A Model for Direct Engagement With Individuals Showing Signs of Radicalization Online,\u201d Institute for Strategic Dialogue, February 2018, https://www.isdglobal.org/isd-publications/counter-conversations-a-model-for-direct-engagement-with-individuals-showing-signs-of-radicalisation-online; and Jacob Davey, Henry Tuck, and Amarnath Amarasingam, \u201cAn Imprecise Science: Assessing Interventions for the Prevention, Disengagement and De-radicalisation of Left and Right-Wing Extremists,\u201d Institute for Strategic Dialogue, 2019, https://www.isdglobal.org/isd-publications/an-imprecise-science-assessing-interventions-for-the-prevention-disengagement-and-de-radicalisation-of-left-and-right-wing-extremists.\n8 On the link between disinformation, hate speech, and hate crimes, consider Jonathan Corpus Ong, \u201cOnline Disinformation Against AAPI Communities During the COVID-19 Pandemic,\u201d Carnegie Endowment for International Peace, October 19, 2021, https://carnegieendowment.org/2021/10/19/online-disinformation-against-aapi-communities-during-covid-19-pandemic-pub-85515.\n9 Consider Viskupi\u010d and Wiltse, \u201cMessenger Matters\u201d; Scott Bokemper et al., \u201cTesting Persuasive Messaging to Encourage COVID-19 Risk Reduction,\u201d PLOS ONE 17 (2022): https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0264782; Rupali J. Limaye et al.,, \u201cMessage Testing in India for COVID-19 Vaccine Uptake: What Appeal and What Messenger Are Most Persuasive?,\u201d Human Vaccines & Immunotherapeutics 18, no. 6 (2022): https://www.tandfonline.com/doi/full/10.1080/21645515.2022.2091864; and Lan Li, Caroline E. Wood, and Patty Kostkova, \u201cVaccine Hesitancy and Behavior Change Theory-Based Social Media Interventions: A Systematic Review,\u201d Translational Behavioral Medicine 12, no. 2 (February 2022): https://academic.oup.com/tbm/article/12/2/243/6445967.\n10 Davey, Tuck, and Amarasingam, \u201cImprecise Science.\u201d\n11 Todd C. Helmus and Kurt Klein, \u201cAssessing Outcomes of Online Campaigns Countering Violent Extremism: A Case Study of the Redirect Method,\u201d RAND Corporation, 2018, https://www.rand.org/pubs/research_reports/RR2813.html. The metrics used to evaluate counter-messaging efforts should align with the messenger\u2019s desired outcome, which is not always a direct change in the original speaker\u2019s belief or behavior. Other goals of counter-messaging include influencing passive bystanders to speak out or showing solidarity with a victimized community. See Catherine Buerger, \u201cWhy They Do It: Counterspeech Theories of Change,\u201d Dangerous Speech Project, September 26, 2022, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4245211; and Bianca Cepollaro, Maxime Lepoutre, and Robert Mark Simpson, \u201cCounterspeech,\u201d Philosophy Compass 18, no. 1 (January 2023): https://compass.onlinelibrary.wiley.com/doi/full/10.1111/phc3.12890.\n12 Limaye et al., \u201cMessage Testing in India\u201d; and Li, Wood, and Kostkova, \u201cVaccine Hesitancy.\u201d\n13 \u201cKey Takeaways from Civil Society in the Visegr\u00e1d Region: Fall 2019 Practitioner Convening,\u201d Over Zero, 2019, https://www.projectoverzero.org/media-and-publications/key-takeaways-from-civil-society-in-the-visegrd-region-fall-2019-practitioner-convening.\n14 Consider Viskupi\u010d and Wiltse, \u201cMessenger Matters.\u201d\n15 Davey, Birdwell, and Skellett, \u201cCounter-Conversations\u201d; and Davey, Tuck, and Amarasingam, \u201cImprecise Science.\u201d\n16 Dominik Hangartner et al, \u201cEmpathy-based Counterspeech Can Reduce Racist Hate Speech in a Social Media Field Experiment,\u201d PNAS 118 (2021), https://www.pnas.org/doi/full/10.1073/pnas.2116310118.\n17 Buerger, \u201cWhy They Do It.\u201d\n18 Alysha Ulrich, \u201cCommunicating Climate Science in an Era of Misinformation,\u201d Intersect: The Stanford Journal of Science, Technology, and Society 16 (2023), https://ojs.stanford.edu/ojs/index.php/intersect/article/view/2395.\n19 Sanchin Banker and Joowon Park, \u201cEvaluating Prosocial COVID-19 Messaging Frames: Evidence from a Field Study on Facebook,\u201d Judgment and Decision Making 15 (2023), https://www.cambridge.org/core/journals/judgment-and-decision-making/article/evaluating-prosocial-covid19-messaging-frames-evidence-from-a-field-study-on-facebook/9EADFB1C6F591AE1A8376C1622FB59D5.\n20 Consider Viskupi\u010d and Wiltse, \u201cMessenger Matters\u201d; Angela K. Shen et al., \u201cTrusted Messengers and Trusted Messages: The Role for Community-based Organizations in Promoting COVID-19 and Routine Immunizations,\u201d Vaccine 41 (2023), https://www.sciencedirect.com/science/article/pii/S0264410X23001809; Angela K. Shen et al., \u201cPersuading the \u2018Movable Middle\u2019: Characteristics of Effective Messages to Promote Routine and COVID-19 Vaccinations for Adults and Children \u2013 The impact of COVID-19 on Beliefs and Attitudes,\u201d Vaccine 41 (2023), https://www.sciencedirect.com/science/article/pii/S0264410X2300141X; and Limaye et al., \u201cMessage Testing in India.\u201d\n21 Benjamin J. Lee, \u201cInformal Countermessaging: The Potential and Perils of Informal Online Countermessaging,\u201d Studies in Conflict & Terrorism 42 (2019): https://www.tandfonline.com/doi/full/10.1080/1057610X.2018.1513697.\n22 Suzanne Smalley, \u201cCollective of Anti-disinformation \u2018Elves\u2019 Offer a Bulwark Against Russian Propaganda,\u201d CyberScoop, August 9, 2022, https://cyberscoop.com/collective-anti-disinformation-elves-russian-propaganda; and Adam Taylor, \u201cWith NAFO, Ukraine Turns the Trolls on Russia,\u201d Washington Post, September 1, 2022, https://www.washingtonpost.com/world/2022/09/01/nafo-ukraine-russia.\n23 Davey, Tuck, and Amarasingam, \u201cImprecise Science.\u201d\n24 \u201cDigital Counterterrorism: Fighting Jihadists Online,\u201d Task Force on Terrorism and Ideology, Bipartisan Policy Center, March 2018, https://bipartisanpolicy.org/download/?file=/wp-content/uploads/2019/03/BPC-National-Security-Digital-Counterterrorism.pdf; Rita Katz, \u201cThe State Department\u2019s Twitter War With ISIS Is Embarrassing,\u201d Time, September 16, 2014, https://time.com/3387065/isis-twitter-war-state-department; Greg Miller and Scott Higham, \u201cIn a Propaganda War Against ISIS, the U.S. Tried to Play by the Enemy\u2019s Rules,\u201d Washington Post, May 8, 2015, https://www.washingtonpost.com/world/national-security/in-a-propaganda-war-us-tried-to-play-by-the-enemys-rules/2015/05/08/6eb6b732-e52f-11e4-81ea-0649268f729e_story.html.\n25 Samuel Woolley and Katie Joseff, \u201cDemand for Deceit: How the Way We Think Drives Disinformation,\u201d National Endowment for Democracy, January 2020, https://www.ned.org/wp-content/uploads/2020/01/Demand-for-Deceit.pdf.\n26 Consider Joan Donovan and danah boyd, \u201cStop the Presses? Moving From Strategic Silence to Strategic Amplification in a Networked Media Ecosystem,\u201d American Behavioral Scientist 65, no. 2 (2019): https://journals.sagepub.com/doi/abs/10.1177/0002764219878229.\n27 \u201cState, Socom Partner to Counter Cyberterrorism,\u201d Simons Center, June 6, 2012, https://thesimonscenter.org/ia-news/state-socom-partner-to-counter-cyberterrorism.\n28 \u201cInspection of the Global Engagement Center,\u201d Office of the Inspector General, U.S. Department of State, September 15, 2022, https://www.oversight.gov/report/DOS/Inspection-Global-Engagement-Center.\n29 \u201cAustralia\u2019s COVID-19 Vaccine Information Campaign Begins,\u201d Australian Department of Health and Aged Care, January 27, 2021, https://www.health.gov.au/ministers/the-hon-greg-hunt-mp/media/australias-covid-19-vaccine-information-campaign-begins.\n30 \u201cMarketing in a Post-Covid Era: Highlights and Insights Report,\u201d CMO Survey, September 2022, https://cmosurvey.org/wp-content/uploads/2022/09/The_CMO_Survey-Highlights_and_Insights_Report-September_2022.pdf.\n31 Lee, \u201cInformal Countermessaging.\u201d\nCase Study 6: Cybersecurity for Elections and Campaigns\nKey takeaways:\nThere is good reason to think that campaign- and election-related cybersecurity can be significantly improved, which would prevent some hack-and-leak operations and fear-inducing breaches of election systems. The cybersecurity field has come to a strong consensus on certain basic practices, many of which remain unimplemented by campaigns and election administrators. Better cybersecurity would be particularly helpful in preventing hack-and-leaks, though candidates will struggle to prioritize cybersecurity given the practical imperatives of campaigning. Election systems themselves can be made substantially more secure at a reasonable cost. However, there is still no guarantee that the public would perceive such systems as secure in the face of rhetorical attacks by losing candidates.\nKey sources:\n- \u201cRecommendations to Defend America\u2019s Election Infrastructure,\u201d Brennan Center for Justice, October 23, 2019, https://www.brennancenter.org/our-work/research-reports/recommendations-defend-americas-election-infrastructure.\n- Erik Brattberg and Tim Maurer, \u201cRussian Election Interference: Europe\u2019s Counter to Fake News and Cyber Attacks,\u201d Carnegie Endowment for International Peace, May 2018, https://carnegieendowment.org/files/CP_333_BrattbergMaurer_Russia_Elections_Interference_FINAL.pdf.\n- William Adler and Dhanaraj Thakur, \u201cA Lie Can Travel: Election Disinformation in the United States, Brazil, and France,\u201d Center for Democracy and Technology, December 2021, https://cdt.org/wp-content/uploads/2021/12/2021-12-13-CDT-KAS-A-Lie-Can-Travel-Election-Disinformation-in-United-States-Brazil-France.pdf.\nDescription and Use Cases\nCybersecurity improvements have been proposed as a way to mitigate two distinct kinds of election-related disinformation and influence threats. One threat is hack-and-leak operations, which involve the theft and public exposure of sensitive information about candidates, campaigns, and other political figures. Leaked data may be partially modified or fully authentic. Russian state actors carried out notable hack-and-leaks during the U.S. presidential election in 2016, the French presidential election in 2017, and the UK general election in 2019.1 To prevent hack-and-leaks, many experts have called for increased cybersecurity protection of candidates, campaigns, and political parties, as well as government offices involved in election processes. This can be done through improved adherence to cybersecurity best practices, donated or discounted cybersecurity services, and specialized training, among other options.2 Importantly, such efforts should extend to personal accounts and devices, not just official ones. In 2019, the U.S. Federal Election Commission issued an advisory opinion that some political campaigns could receive free cybersecurity assistance from private firms without violating rules on corporate campaign contributions.3\nThe second threat is that hackers may probe or compromise election systems, such as the networks that hold voter registration data or vote tallies. If these operations are discovered and publicized, they can heighten fear that election outcomes are subject to manipulation, thereby reducing confidence in the results\u2014even if this fear is unwarranted. For example, a declassified report by the U.S. Senate Select Committee on Intelligence found that in 2016, Russian actors were in a position to delete or modify voter registration data but did not do so. Other U.S. election infrastructure was probed for vulnerabilities, but there was no evidence to suggest vote totals were modified.4\nThe cybersecurity of election systems can often be improved by implementing standard best practices applicable to any organization, such as proactively monitoring network activity, conducting penetration testing, and developing incident response plans. But election systems may also need security measures tailored to their unique context. Such actions can include regularly backing up voter registration databases, certifying voting machines, maintaining a paper trail for electronic ballots, and conducting post-election audits.5 The cybersecurity of election systems is intertwined with other aspects of election administration. For example, maintaining accurate electronic tallies of votes depends in part on ensuring that any paper ballots are physically secure and that election workers are properly supervised. (The role of electronic voting machines, a major policy question, is beyond the scope of this report.6)\nCoordination, transparency, and communication are also areas of focus. The U.S. Department of Homeland Security has designated election systems as \u201ccritical infrastructure,\u201d allowing it to create structures for better communication between stakeholders and to provide security assistance, such as free cybersecurity assessments for election administrators.7 Other U.S. examples include the Elections Infrastructure Information Sharing & Analysis Center, a voluntary coordination body created in 2020, and proposals for a national public database of voting system defects.8\nHow Much Do We Know?\nThe threat of cyber operations against campaigns and election infrastructure is well documented across several countries, but there are few detailed evaluations of the cybersecurity response. In general, the cybersecurity field has come to a strong consensus on certain basic practices to protect against threats. These include multifactor authentication, routine backups (kept segregated from originals), frequent patching, and vulnerability testing. Other actions or principles that have gained favor in recent years include cloud migration, zero trust architecture, and threat intelligence. However, there is very little quantitative evidence of these practices\u2019 comparative cost-effectiveness. Additionally, it is hard to judge the efficacy of best practices in thwarting a highly capable, persistent state actor.\nThere is a clear causal link between improving campaign cybersecurity and reducing the risk of hack-and-leak operations. With election systems, however, cybersecurity is only half the battle. To maintain public confidence in election integrity, administrators must also convince people that systems are truly secure. This critical second step has received less attention from researchers and analysts.\nHow Effective Does It Seem?\nThere is good reason to think that campaign- and election-related cybersecurity can be significantly improved. A 2018 assessment of election administration in all fifty U.S. states found that a distressing number of states had not taken basic precautions, such as minimum cybersecurity standards for voter registration systems.9 This state of affairs may not be uncommon across government bodies in many countries. A 2022 cybersecurity audit of the U.S. federal government found that eight of the twenty-three assessed agencies showed significant deficiencies in their ability to detect cyber incidents and protect themselves through basic policies like multifactor authentication and data encryption.\nIn other words, there are still simple ways to improve cybersecurity in many governmental and political institutions, including campaign and election infrastructure.10 Moreover, such investments would probably prevent a number of intrusions. A 2022 study by the research consultancy ThoughtLab found that organizations which performed well against the National Institute of Standards and Technology (NIST) Cybersecurity Framework, a common benchmark used in many public- and private-sector organizations in the United States and elsewhere, suffered somewhat fewer damaging cyber incidents than lower-performing organizations.11\n| Table 2. U.S. Government Recommendations for Securing Election Systems | |\n| Best Practice | Summary |\n| Software and patch management | Create an inventory of software in use by the organization. Deploy patches in a timely manner. |\n| Log management | Maintain secure, centralized logs of devices on and off the network. Review logs to identify, triage, and assess incidents. |\n| Network segmentation | Create separate virtual or physical networks for each part of the organization. Use dedicated systems for election-related tasks. |\n| Block suspicious activity | Enable blocking, not just alerting, of suspicious activity by default. Scan emails and train employees on phishing attacks. |\n| Credential management | Require strong passwords and multi-factor authentication. |\n| Establish a baseline for host and network activity | Track the amount, timing, and destination of typical network traffic to identify anomalies. Create a \u201cgold image\u201d of hosts for comparison. |\n| Organization-wide IT guidance and policies | Maintain incident response and communications plans, an approved software list, and other policies for cyber hygiene. |\n| Notice and consent banners for computer systems | Require that users consent to monitoring, disclosing, and sharing of data for any purpose. |\n| Source: \u201cBest Practices for Securing Election Systems,\u201d U.S. Cybersecurity and Infrastructure Security Agency, November 11, 2022, https://www.cisa.gov/news-events/news/best-practices-securing-election-systems. |\nIn addition to prevention, the NIST framework also emphasizes preparedness to respond to and recover from an incident. The 2017 French presidential election provides a celebrated example: Emmanuel Macron\u2019s campaign prepared for an eventual Russian hack-and-leak operation by creating fake email addresses, messages, and documents so that stolen materials could not be verified and might discredit the leakers.12 Immediate disclosure of all hacking attempts, both to authorities and the public, also built awareness of the disinformation threat to the election. This could be seen as a form of inoculation, or \u201cpre-bunking,\u201d which refers to anticipating a specific disinformation narrative or technique and proactively confronting it before it spreads.13 However, it seems likely that other political, legal, and media factors also played a role in diminishing the influence of the Russian operation.\nUnfortunately, public fears of election irregularities cannot always be allayed by truthful assurances that election systems are secure. In United States (in 2020\u20132021) and Brazil (in 2022\u20132023), false rhetorical attacks on the integrity of the electoral process by losing candidates and their supporters led to organized postelection violence.14 A side-by-side comparison of the two examples is revealing, because the two countries have substantially different voting systems. In the United States, a complex set of rules and practices delayed the vote count in a number of states, which laid the groundwork for conspiracy theories of electoral manipulation despite the presence of extensive safeguards and paper-backed auditing mechanisms.15 Brazil, in contrast, has an all-electronic voting system that allows for rapid results\u2014though it lacks a paper trail to enable physical audits.16 Despite these divergent approaches, both countries were destabilized by disinformation about election security.\nHow Easily Does It Scale?\nImproving the cybersecurity of political campaigns faces significant cultural and leadership barriers. Campaigns are ephemeral, frenetic environments. They employ large numbers of temporary workers and volunteers who are minimally vetted and trained. Democratic politics also has an inherently open quality\u2014candidates and surrogates must interact with wide swaths of the public, both in person and online\u2014that runs at cross-purposes with physical and cyber security. Finally, a dollar spent on cybersecurity is a dollar not spent on winning votes.\nGiven these factors, campaigns and candidates often resist making cybersecurity a priority. In the EU, for example, political parties have chronically underfunded their own digital security.17 A dedicated EU fund could help, but politicians would still need to spend scarce time and attention on cybersecurity and accept the inconveniences that sometimes come with it. When the Netherlands offered cybersecurity training to politicians and government officials before the country\u2019s 2017 elections, few expressed interest.18 One-off or annual trainings are also less effective than more frequent trainings\u2014let alone cultural and organizational shifts in behavior mandated and enforced by leadership.19 While some cultural shifts have indeed occurred in recent years across many countries, in campaigns and more generally, political campaigns will likely continue to lag behind other major organizations in their cybersecurity practices.\nThe cost of securing election infrastructure, while not trivial, seems modest given its foundational importance to democracy.\nOne advantage of cybersecurity, as compared to other disinformation countermeasures, is that a proven set of best practices already exists and has been widely (if inconsistently) adopted in other sectors. This makes scaling much easier. However, cybersecurity is not necessarily cheap. The size and complexity of national elections and the number of necessary improvements mean that\u2014in the United States, at least\u2014the sums required are significant.20 In 2018, for example, the U.S. Congress allocated $380 million for election security improvements\u2014including cybersecurity\u2014with millions more given by state governments.21 And in 2020, the COVID-19 relief bill allocated another $400 million for elections, with state officials often prioritizing cybersecurity in their grant requests.22 Experts tend to propose even larger and more sustained expenditures.23 The Brennan Center for Justice has called for five-year allocations of $833 million to help state and local governments with cybersecurity, $486 million to secure voter registration infrastructure, and $316 million to protect election agencies from \u201cinsider threats.\u201d24\nThe cost of securing election infrastructure, while not trivial, seems modest given its foundational importance to democracy. Still, governments must find the political will to make such investments. Proposed measures to improve the security of the 2019 elections for the European Parliament faced resistance from member states that viewed the problem as overhyped or were themselves complicit in election disinformation.25\nNotes\n1 Hack-and-leak operations might be considered malinformation because the offending material is intended to harm yet is often authentic and factual. Alternatively, such operations could be seen as disinformation to the extent that the term encompasses true but highly misleading information (for example, when crucial context is omitted). For more on this taxonomy, and relevant cybersecurity recommendations, see Wardle and Derakhshan, \u201cInformation Disorder.\u201d For further examples of cybersecurity recommendations from this period, see also Jean-Baptiste Jeang\u00e8ne Vilmer, \u201cSuccessfully Countering Russian Electoral Influence: 15 Lessons Learned From the Macron Leaks,\u201d Center for Strategic International Studies, June 2018, https://csis-website-prod.s3.amazonaws.com/s3fs-public/publication/180621_Vilmer_Countering_russiam_electoral_influence.pdf; Brattberg and Maurer, \u201cRussian Election Interference\u201d; and Fly, Rosenberger, and Salvo, \u201cThe ASD Policy Blueprint.\u201d\n2 Robby Mook, Matt Rhoades, and Eric Rosenbach, \u201cCybersecurity Campaign Playbook,\u201d November 2017, https://www.belfercenter.org/publication/cybersecurity-campaign-playbook.\n3 \u201cCloudflare for Campaigns: United States,\u201d Cloudflare, accessed April 21, 2023, https://www.cloudflare.com/campaigns/usa.\n4 \u201cRussian Active Measures Campaigns and Interference in the 2016 U.S. Election, Volume 1: Russian Efforts Against Election Infrastructure With Additional Views,\u201d U.S. Senate Select Committee on Intelligence (16th Congress, Report 116-XX), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume1.pdf.\n5 Danielle Root, Liz Kennedy, and Michael Sozan, \u201cElection Security in All 50 States,\u201d Center for American Progress, February 12, 2018, https://www.americanprogress.org/article/election-security-50-states; Brattberg and Maurer, \u201cRussian Election Interference\u201d; \u201cStatement by Secretary Jeh Johnson on the Designation of Election Infrastructure as a Critical Infrastructure Subsector,\u201d U.S. Department of Homeland Security, January 6, 2017, https://www.dhs.gov/news/2017/01/06/statement-secretary-johnson-designation-election-infrastructure-critical; and \u201cRecommendations to Defend America\u2019s Election Infrastructure,\u201d Brennan Center for Justice, October 23, 2019, https://www.brennancenter.org/our-work/research-reports/recommendations-defend-americas-election-infrastructure.\n6 \u201cRecommendations,\u201d Brennan Center for Justice.\n7 \u201cStarting Point: U.S. Election Systems as Critical Infrastructure,\u201d U.S. Election Assistance Commission, accessed March 28, 2023, https://www.eac.gov/sites/default/files/eac_assets/1/6/starting_point_us_election_systems_as_Critical_Infrastructure.pdf; and \u201cDHS Cybersecurity Services Catalog for Election Infrastructure,\u201d U.S. Department of Homeland Security, accessed March 28, 2023, https://www.eac.gov/sites/default/files/eac_assets/1/6/DHS_Cybersecurity_Services_Catalog_for_Election_Infrastructure.pdf.\n8 Root, Kennedy, and Sozan, \u201cElection Security\u201d; \u201cRecommendations,\u201d Brennan Center for Justice ; and \u201cElections Infrastructure Information Sharing & Analysis Center,\u201d Center for Internet Security, accessed April 21, 2023, https://www.cisecurity.org/ei-isac.\n9 Root, Kennedy, and Sozan, \u201cElection Security.\u201d\n10 \u201cFederal Cybersecurity Progress Report for Fiscal Year 2022,\u201d U.S. General Services Administration, 2022, https://www.performance.gov/cyber. See also \u201cCross-Sector Cybersecurity Performance Goals,\u201d U.S. Cybersecurity and Infrastructure Security Agency, 2022, https://www.cisa.gov/sites/default/files/publications/2022_00092_CISA_CPG_Report_508c.pdf.\n11 \u201cFramework for Improving Critical Infrastructure Cybersecurity,\u201d National Institute of Standards and Technology, April 16, 2018, https://nvlpubs.nist.gov/nistpubs/cswp/nist.cswp.04162018.pdf; and \u201cCybersecurity Solutions for a Riskier World,\u201d ThoughtLab, 2022, https://thoughtlabgroup.com/cyber-solutions-riskier-world.\n12 See Jeang\u00e8ne Vilmer, \u201cSuccessfully Countering\u201d; and Brattberg and Maurer, \u201cRussian Election Interference.\u201d\n13 For more on pre-bunking, see case studies 3 and 7.\n14 Dean Jackson and Jo\u00e3o Guilherme Bastos dos Santos, \u201cA Tale of Two Insurrections: Lessons for Disinformation Research From the Jan. 6 and 8 Attacks,\u201d Lawfare, February 27, 2023, https://www.lawfaremedia.org/article/tale-two-insurrections-lessons-disinformation-research-jan-6-and-8-attacks-0.\n15 See William T. Adler, \u201cTo Stop Election-Related Misinformation, Give Election Officials the Resources They Need,\u201d Center for Democracy and Technology, November 13, 2020, https://cdt.org/insights/to-stop-election-related-misinformation-give-election-officials-the-resources-they-need.\n16 William T. Adler and Dhanaraj Thakur, \u201cA Lie Can Travel: Election Disinformation in the United States, Brazil, and France,\u201d Center for Democracy and Technology, December 2021, https://cdt.org/wp-content/uploads/2021/12/2021-12-13-CDT-KAS-A-Lie-Can-Travel-Election-Disinformation-in-United-States-Brazil-France.pdf. See also Philip Bump, \u201cThe Uncomplicated Reason Brazil Can Count Its Ballots So Quickly,\u201d Washington Post, October 31, 2022, https://www.washingtonpost.com/politics/2022/10/31/brazil-elections-vote-count-united-states.\n17 Sam van der Staak, \u201cThe Weak Link in Election Security: Europe\u2019s Political Parties,\u201d Politico, June 8, 2021, https://www.politico.eu/article/european-election-security-political-parties-cybersecurity.\n18 Brattberg and Maurer, \u201cRussian Election Interference.\u201d\n19 Isabella Harford, \u201cHow Effective Is Security Awareness Training? Not Enough,\u201d TechTarget, April 5, 2022, https://www.techtarget.com/searchsecurity/feature/How-effective-is-security-awareness-training-Not-enough.\n20 Lawrence Norden and Edgardo Cort\u00e9s, \u201cWhat Does Election Security Cost?\u201d Brennan Center for Justice, August 15, 2019, https://www.brennancenter.org/our-work/analysis-opinion/what-does-election-security-cost.\n21 Elizabeth Howard et al., \u201cDefending Elections: Federal Funding Needs for State Election Security,\u201d Brennan Center for Justice, July 18, 2019, https://www.brennancenter.org/our-work/research-reports/defending-elections-federal-funding-needs-state-election-security.\n22 Zach Montellaro, \u201cCoronavirus Relief Bill Allocates $400M for Election Response,\u201d Politico, March 26, 2020, https://www.politico.com/newsletters/morning-score/2020/03/26/coronavirus-relief-bill-allocates-400m-for-election-response-786407; and \u201cFunding Safe and Secure Elections During the COVID-19 Pandemic,\u201d e.Republic Center for Digital Government, 2020, https://papers.govtech.com/A-Better-Way-to-Find-New-Jobs-and-Careers-136728.html/Funding-Safe-and-Secure-Elections-During-COVID-19-129933.html. On the general state of election administration finances, see Tom Scheck, Geoff Hing, Sabby Robinson, and Gracie Stockton, \u201cHow Private Money From Facebook\u2019s CEO Saved the 2020 Election,\u201d NPR, December 8, 2020, https://www.npr.org/2020/12/08/943242106/how-private-money-from-facebooks-ceo-saved-the-2020-election.\n23 Rachel Orey, \u201cNew Election Security Funding Positive but Misses the Mark,\u201d February 28, 2023, Bipartisan Policy Center, https://bipartisanpolicy.org/blog/new-election-security-funding.\n24 Norden and Cort\u00e9s, \u201cWhat Does Election Security Cost?\u201d; and Lawrence Norden, Derek Tisler, and Turquoise Baker, \u201cEstimated Costs for Protecting Election Infrastructure Against Insider Threats,\u201d Brennan Center for Justice, March 7, 2022, https://www.brennancenter.org/our-work/research-reports/estimated-costs-protecting-election-infrastructure-against-insider. See also Derek Tisler and Lawrence Norden, \u201cEstimated Costs for Protecting Election Workers From Threats of Physical Violence,\u201d Brennan Center for Justice, May 3, 2022, https://www.brennancenter.org/our-work/research-reports/estimated-costs-protecting-election-workers-threats-physical-violence.\n25 Erik Brattberg, \u201cThe EU\u2019s Looming Test on Election Interference,\u201d Carnegie Endowment for International Peace, April 18, 2019, https://carnegieendowment.org/2019/04/18/eu-s-looming-test-on-election-interference-pub-78938; and Sam van der Staak and Peter Wolf, \u201cCybersecurity in Elections: Models of Interagency Collaboration,\u201d International IDEA, 2019, https://www.idea.int/sites/default/files/publications/cybersecurity-in-elections-models-of-interagency-collaboration.pdf.\nCase Study 7: Statecraft, Deterrence, and Disruption\nKey takeaways:\nCyber operations targeting foreign influence actors can temporarily frustrate specific foreign operations during sensitive periods, such as elections, but any long-term effect is likely marginal. There is little evidence to show that cyber operations, sanctions, or indictments have achieved strategic deterrence, though some foreign individuals and contract firms may be partially deterrable. Bans on foreign platforms and state media outlets have strong first-order effects (reducing access to them); their second-order consequences include retaliation against democratic media by the targeted state. All in all, the most potent tool of statecraft may be national leaders\u2019 preemptive efforts to educate the public. Yet in democracies around the world, domestic disinformation is far more prolific and influential than foreign influence operations.\nKey sources:\n- Keir Giles, \u201cCountering Russian Information Operations in the Age of Social Media,\u201d Council on Foreign Relations, November 21, 2017, https://www.cfr.org/report/countering-russian-information-operations-age-social-media.\n- Gabriel Band, \u201cSanctions as a Surgical Tool Against Online Foreign Influence,\u201d Lawfare, September 15, 2022, https://www.lawfaremedia.org/article/sanctions-surgical-tool-against-online-foreign-influence.\n- Yevgeniy Golovchenko, \u201cFighting Propaganda with Censorship: A Study of the Ukrainian Ban on Russian Social Media,\u201d The Journal of Politics 84 (2022), https://www.journals.uchicago.edu/doi/10.1086/716949.\nDescription and Use Cases\nWhen disinformation and other influence operations stem from abroad, governments can use a range of foreign policy tools to respond. These include sanctions, indictments, media regulation or bans, public statements by government officials, and cyber operations.\nThe U.S. government has been particularly prolific in many of these areas. After the Russian effort to interfere in the 2016 election, Washington announced a number of sanctions on Russian individuals and organizations.1 It also announced criminal charges\u2014in 2018 against five Russian organizations and nineteen Russian individuals, in 2021 against two Iranian men, and in 2022 against three Russian men, among others.2 Although indictments of foreign nationals for influence operation\u2013related activities are unusual globally, sanctions are becoming more common.3 In 2022, the United Kingdom sanctioned several individuals and media outlets accused of serving as propagandists for Moscow.4 The same year, a report from the European Parliament noted that the EU does not have a \u201cspecific regime of sanctions related to foreign interference and disinformation campaigns orchestrated by foreign state actors\u201d and called for one to be developed.5 Also that year, in the lead-up to the U.S. midterm elections, the U.S. government announced its use of \u201cfull-spectrum cyber operations\u201d to \u201cdefend and disrupt\u201d influence attempts and \u201cimpose costs on foreign actors who seek to undermine democratic processes.\u201d6\nOvert foreign influence activities can be regulated or banned altogether. The United States has in recent years stepped up enforcement of the Foreign Agents Registration Act, which requires state-affiliated media and others speaking on behalf of foreign interests to disclose their sponsorship. Similar rules went into effect in 2018 in Australia (where the government also made covert influence efforts a crime) and were proposed in 2022 in the United Kingdom.7 Restrictions can also be imposed on foreign state media outlets: the EU and United Kingdom both banned Russian state broadcaster RT following Russia\u2019s full-scale invasion of Ukraine.8 (In the United States, cable providers also dropped the station, leading it to cease operations there.) These bans extended to the outlet\u2019s online presence. Some governments have also banned foreign social media platforms seen as vehicles for adversarial influence and espionage: Ukraine banned Russia\u2019s VKontakte in 2017 and India banned TikTok, which is owned by a Chinese company, in 2020.\nFinally, many experts have called on political leaders to \u201cbe open and outspoken about the nature of the challenge\u201d because \u201cawareness . . . of Russian [and other] information warfare is the most potent defense against it.\u201d9 This may entail general warnings of the threat: for example, then Finnish defense minister Carl Haglund in 2014 and then British prime minister Theresa May in 2017 both gave blunt descriptions of the overall challenge posed by Russian influence operations.10 Analysts also suggest using more direct statements tactically during\u2014or, better yet, in advance of\u2014specific influence operations. Experts praised Macron\u2019s campaign for its preparedness against the Russian hack-and-leak operation in 2017, the UK government for its quick response to the poisoning of Sergei and Yulia Skripal in 2018, and the U.S. government for its tactical release of intelligence in 2022 to pre-bunk potential Russian false flag operations in Ukraine.11\nHow Much Do We Know?\nThere appears to be no empirical scholarship measuring the success of sanctions, indictments, or cyber operations as counter-disinformation tools. Some useful analogies can be drawn from cases where these tools were used against other kinds of hostile activities, such as foreign cyber operations. But this literature, too, is largely anecdotal. Intelligence agencies may be better positioned to assess the efficacy of foreign policy tools by directly observing how foreign actors privately perceive and react to such moves. Such intelligence is mostly kept secret, however, and government officials have not given clear public characterizations. Cyber operations against disinformation actors offer a qualified exception: U.S. officials have claimed some tactical and operational disruptions. An example is the U.S. cyber operation targeting the Internet Research Agency in Russia prior to the 2018 midterm elections.12 (Many of these government actions have occurred in tandem with platforms\u2019 removals of inauthentic asset networks, discussed in case study 8.)\nBans on both broadcast and digital foreign state media have been subject to a small number of limited empirical studies. The best-studied tool may be proactive and assertive statements by officials, which have a real (though circumstantial) research basis. Although these statements have not received direct empirical study, related areas of scholarship support the notion that they can help prepare and protect the public.\nHow Effective Does It Seem?\nForeign policy tools may have varied goals when used against influence operations. They can seek to deter further influence activity (by the same foreign actors or other foreign actors), disrupt foreign influence capabilities (especially during sensitive periods such as elections), or exert a signaling effect (educating the public, affirming redlines to adversaries, and rallying the international community).13\nA broad-based deterrence that leads foreign actors to halt all or much of their influence operations seems out of reach so far, probably because the punishments inflicted to date are not severe enough to outweigh the perceived benefits of influence operation for state perpetrators. For example, despite numerous U.S. sanctions and indictments, Russia and Iran persisted as the largest sources of influence operations removed by Facebook, with many of their operations across platforms targeting the United States.14 More realistically, democratic states could aim for so-called micro-level deterrence: by targeting low- and mid-level individual perpetrators with sanctions that limit their personal travel, finances, and relationships, these individuals and some others could be dissuaded from participating in influence operations.15 For foreign governments, micro-level deterrence would impose modest organizational costs and friction over time. There is little direct public evidence this works, but it is plausible under the right circumstances.16\nA concrete example of operational friction came in 2018, when U.S. Cyber Command reportedly disrupted the digital infrastructure of Russia\u2019s Internet Research Agency. Officials told the Washington Post that \u201c[t]he blockage was so frustrating to the trolls that they complained to their system administrators about the disruption.\u201d17 U.S. officials offered equivocal assessments of the operation\u2019s larger effects. One senator claimed that it successfully prevented \u201cvery serious\u201d Russian election interference, while a defense official said the goal was simply to \u201cthrow a little curveball, inject a little friction, sow confusion.\u201d As Washington continues to institutionalize this kind of activity as a routine part of its federal election plans, the goal of imposing \u201ca little friction\u201d on adversaries for specific time periods seems like a realistic long-term aspiration.18\nFor media bans, research on Ukraine\u2019s 2017 ban of the Russian social media service VKontakte provides a small window into the potential efficacy of similar tactics elsewhere. A study found that \u201cthe sudden censorship policy reduced activity on VKontakte,\u201d even among pro-Russia users and despite the ban being \u201clegally and technically\u201d easy to circumvent.19 This indicates that media bans can have impacts despite imperfect enforcement, because convenience of access remains an important driver of media consumption. Similar dynamics have been observed in other highly restricted media environments, such as China.20 Likewise, Russian state media channels on U.S. platforms like YouTube, Facebook, and Twitter suffered significant declines in engagement in 2022 due to platforms\u2019 efforts to block these pages or limit their reach, though a cat-and-mouse game ensued as Russian outlets created new accounts and channels to evade platform restrictions.21\nThese results, if generalizable, would imply that restrictions on foreign media have strong first-order effects. Further research on the VKontakte ban and similar bans should measure not only first-order effects (like activity on the banned platform) but second- and third-order effects as well\u2014to determine, for example, whether pro-Russia users migrated to other platforms, remained interested in pro-Russia propaganda, or lost further trust in the Ukrainian government. It should also examine whether any reciprocal bans of Western media by the Russian government counterbalanced the potential benefits of restrictions on Russian state media.\nLeaders\u2019 public statements calling attention to foreign influence operations, while not the subject of direct empirical study, have substantial indirect grounding in evidence. Long-standing psychological research holds that when individuals are aware of and plan to resist attempts at persuasion, it makes their original beliefs stronger; analysts today suggest this creates a first-mover advantage through which early warnings of an influence operation can harden resistance to it.22 A related idea also supported by the literature is pre-bunking.23 Bipartisan statements may be especially effective: evidence from fact-checking studies shows that corrective measures against disinformation are more effective when the speaker belongs to the same party as the audience (and are less effective when they do not).24 A barrier to this approach arises when partisan leaders see no advantage in debunking a disinformation narrative, or when they seek political advantages by discrediting the work of fact-checkers. There is also the potential risk of so-called perception hacking, when an operation causes public concern out of line with its actual effect, diminishing public confidence and trust. Officials should be wary of overreactions that play into the hands of disinformers.25\nThe most important limitation on statecraft as a counter-influence tool is the fact that foreign actors are responsible for only a small portion of disinformation.\nPerhaps the most important limitation on statecraft as a counter-influence tool is the fact that foreign actors are responsible for only a small portion of disinformation. Researchers and investigators around the world overwhelmingly agree on this broad principle\u2014notwithstanding the diverse information environments in different countries and the powerful professional and political incentives to emphasize foreign threats.26 Domestic actors are almost always more numerous, vocal, resourced, sophisticated, networked, and invested in local political outcomes than foreign entities. This does not mean that foreign influence should be ignored. But it suggests that policymakers\u2019 intense focus on the issue may not reflect a realistic assessment of risk.27 Rather, foreign disinformation may garner disproportionate attention for the simple reason that many democratic governments have more freedom of action in foreign than domestic policy, especially when it comes to regulating information.\nHow Easily Does It Scale?\nSanctions, indictments, and media regulations are generally cheap compared to other countermeasures, but they require nontrivial bureaucratic resources to design, develop, and enforce. In the United States, sanctions and indictments targeting foreign influence actors have sometimes been announced many months or even years after the influence activity. Others have been imposed much more quickly. This suggests that the difficulty of investigating and punishing foreign influence actors may depend on circumstantial factors, such as the amount of evidence immediately available, the preexisting intelligence on the responsible actors, and the perceived urgency of a response. Cyber operations are generally more time- and resource-intensive for governments than sanctions, indictments, or media regulations.\nIncreasing the use of these tools could come at the cost of other foreign policy objectives. Countries may worry that punitive measures will trigger retaliation, jeopardize unrelated negotiations with the targeted state, set diplomatic precedents that constrain their own behavior, or expose intelligence sources and methods, among other possibilities. In 2016, for example, the administration of then U.S. president Barack Obama took limited steps to thwart Russian influence but \u201cdid not know the full range of Moscow\u2019s capabilities\u201d and was afraid that harsh measures would prompt even more aggressive election disruption, according to a bipartisan Senate report.28 The administration also feared domestic confidence in the election\u2019s outcome and fairness would be negatively impacted if it did not tread carefully.29 Additionally, Washington was trying at the time to coax Russia into helping end the Syrian civil war.\nIn another case, Western countries\u2019 bans of RT in 2022 prompted Moscow to retaliate by banning the BBC, Voice of America, and other Western services in Russia\u2014restricting their ability to deliver alternative perspectives on the Ukraine war in Ukraine.30 Moscow and other state adversaries have used this kind of state media restriction to question Western countries\u2019 commitment to free speech abroad and have even used it as a badge of honor by establishing new channels like \u201c\u00a1Cens\u00farame otra vez!\u201d (\u201cCensor me again!\u201d) to target non-Western audiences.31\nNotes\n1 \u201cTreasury Sanctions Russian Cyber Actors for Interference With the 2016 U.S. Elections and Malicious Cyber-Attacks,\u201d U.S. Department of the Treasury, March 15, 2018, https://home.treasury.gov/news/press-releases/sm0312.\n2 Devlin Barrett, \u201cU.S. Indicts Two Iranian Hackers Over 2020 Election Disinformation Campaign,\u201d Washington Post, November 18, 2021, https://www.washingtonpost.com/national-security/iran-hackers-election-2020-indicted/2021/11/18/605ae112-4898-11ec-b05d-3cb9d96eb495_story.html; and Kevin Breuninger, \u201cDOJ Charges 3 Russians with Running \u2018Foreign Influence and Disinformation Network\u2019 in U.S.,\u201d CNBC, April 14 2022, https://www.cnbc.com/2022/04/14/doj-charges-3-russians-with-running-foreign-influence-and-disinformation-network-in-us.html.\n3 Fried and Polyakova, \u201cDemocratic Defense Against Disinformation.\u201d\n4 \u201cForeign Secretary Announces Sanctions on Putin\u2019s Propaganda,\u201d Foreign Ministry of the United Kingdom, March 31, 2022, https://www.gov.uk/government/news/foreign-secretary-announces-sanctions-on-putins-propaganda--2.\n5 \u201cReport on Foreign Interference in All Democratic Processes in the European Union, Including Disinformation,\u201d European Parliament, 2022, https://www.europarl.europa.eu/doceo/document/A-9-2022-0022_EN.html.\n6 \u201cHow U.S. Cyber Command, NSA Are Defending Midterm Elections: One Team, One Fight,\u201d U.S. Department of Defense, August 25, 2022, https://www.defense.gov/News/News-Stories/Article/Article/3138374/how-us-cyber-command-nsa-are-defending-midterm-elections-one-team-one-fight.\n7 On Australia, see \u201cForeign Influence Transparency Scheme,\u201d Australian Government Attorney-General\u2019s Department, accessed March 13, 2023, https://www.ag.gov.au/integrity/foreign-influence-transparency-scheme; Henry Belot, \u201cMalcolm Turnbull Announces Biggest Overhaul of Espionage, Intelligence Laws in Decades,\u201d Australian Broadcasting Corporation, December 4, 2017, https://www.abc.net.au/news/2017-12-05/turnbull-announces-foreign-interference-laws/9227514; and Matt Schrader, \u201cFriends and Enemies: A Framework for Understanding Chinese Political Interference in Democratic Countries,\u201d German Marshall Fund, April 2020, https://securingdemocracy.gmfus.org/wp-content/uploads/2020/05/Friends-and-Enemies-A-Framework-for-Understanding-Chinese-Political-Interference-in-Democratic-Countries.pdf. On the United Kingdom, see \u201cForeign Influence Registration Scheme to Make Clandestine Political Activity Illegal,\u201d UK Home Office, October 18, 2022, https://www.gov.uk/government/news/foreign-influence-registration-scheme-to-make-clandestine-political-activity-illegal.\n8 Mark Thompson, \u201cBritain Bans Russian State TV Channel RT,\u201d CNN Business, March 18, 2022, https://www.cnn.com/2022/03/18/media/uk-bans-russia-rt-tv/index.html; Foo Yun Chee, \u201cEU Bans RT, Sputnik Over Ukraine Disinformation,\u201d Reuters, March 2 2022, https://www.reuters.com/world/europe/eu-bans-rt-sputnik-banned-over-ukraine-disinformation-2022-03-02.\n9 Keir Giles, \u201cCountering Russian Information Operations in the Age of Social Media,\u201d Council on Foreign Relations, November 21, 2017, https://www.cfr.org/report/countering-russian-information-operations-age-social-media.\n10 For sources on Theresa May, see Paul M. Barrett, Tara Wadhwa, and Doroth\u00e9e Baumann-Pauly, \u201cCombating Russian Disinformation: The Case for Stepping Up the Fight Online,\u201d NYU Stern Center for Business and Human Rights, July 2018, https://issuu.com/nyusterncenterforbusinessandhumanri/docs/nyu_stern_cbhr_combating_russian_di?e=31640827/63115656; and Rowena Mason, \u201cTheresa May Accuses Russia of Interfering in Elections and Fake News,\u201d Guardian, November 14, 2017, https://www.theguardian.com/politics/2017/nov/13/theresa-may-accuses-russia-of-interfering-in-elections-and-fake-news. For sources on Finland, see Keir Giles, \u201cRussia\u2019s \u2018New\u2019 Tools for Confronting the West: Continuity and Innovation in Moscow\u2019s Exercise of Power,\u201d Chatham House, March 2016, https://www.chathamhouse.org/sites/default/files/publications/2016-03-russia-new-tools-giles.pdf; and Aleksi Teivainen, \u201cReport: Haglund Was Quick to Pick Up on Russia\u2019s Disinformation Campaigns,\u201d Helsinki Times, March 24, 2016, https://www.helsinkitimes.fi/finland/finland-news/domestic/13884-report-haglund-was-quick-to-pick-up-on-russia-s-information-campaigns.html.\n11 Lizzie Dearden, \u201cEmmanuel Macron Email Leaks \u2018Linked to Russian-Backed Hackers Who Attacked Democratic National Committee,\u2019\u201d Independent, May 6, 2017, https://www.independent.co.uk/news/world/europe/emmanuel-macron-leaks-hack-en-marche-cyber-attack-russia-dnc-marine-le-pen-election-france-latest-a7721796.html; Thomas Kent, \u201cDisinformation Response \u2014 the Critical Early Hours,\u201d Center for European Policy Analysis, March 31, 2021, https://cepa.org/article/disinformation-response-the-critical-early-hours; and Adam Taylor, \u201cU.S. Says Putin Could Use \u2018False Flag\u2019 as Excuse for War. Similar Accusations Have Defined Putin\u2019s Career,\u201d February 18, 2022, https://www.washingtonpost.com/world/2022/02/18/ukraine-putin-false-flag.\n12 Andy Greenberg, \u201cUS Hackers\u2019 Strike on Russian Trolls Sends a Message\u2014but What Kind?,\u201d Wired, February 27, 2019, https://www.wired.com/story/cyber-command-ira-strike-sends-signal.\n13 Jon Bateman, \u201cThe Purposes of U.S. Government Public Cyber Attribution,\u201d Carnegie Endowment for International Peace, March 28, 2022, https://carnegieendowment.org/2022/03/28/purposes-of-u.s.-government-public-cyber-attribution-pub-86696.\n14 See Barrett, Wadhwa, and Baumann-Pauly, \u201cCombating Russian Disinformation\u201d; Ben Nimmo and David Agranovich, \u201cRecapping Our 2022 Coordinated Inauthentic Behavior Enforcements,\u201d Meta, December 15, 2022, https://about.fb.com/news/2022/12/metas-2022-coordinated-inauthentic-behavior-enforcements; and \u201cDisinfodex,\u201d Disinfodex, accessed January 27, 2023, https://disinfodex.org.\n15 Gabriel Band, \u201cSanctions as a Surgical Tool Against Online Foreign Influence,\u201d Lawfare, September 15, 2022, https://www.lawfaremedia.org/article/sanctions-surgical-tool-against-online-foreign-influence.\n16 Bateman, \u201cThe Purposes of U.S. Government.\u201d\n17 Ellen Nakashima, \u201cU.S. Cyber Command Operation Disrupted Internet Access of Russian Troll Factory on Day of 2018 Midterms,\u201d Washington Post, February 27, 2019, https://www.washingtonpost.com/world/national-security/us-cyber-command-operation-disrupted-internet-access-of-russian-troll-factory-on-day-of-2018-midterms/2019/02/26/1827fc9e-36d6-11e9-af5b-b51b7ff322e9_story.html.\n18 Sean Lyngaas, \u201cUS \u2018Actively Defending Against Foreign Interference and Influence\u2019 in Midterms, Cyber Command Says,\u201d CNN, August 25, 2022, https://www.cnn.com/2022/08/25/politics/election-security-midterms-cyber-command/index.html.\n19 Yevgeniy Golovchenko, \u201cFighting Propaganda With Censorship: A Study of the Ukrainian Ban on Russian Social Media,\u201d Journal of Politics 84 (2022): https://www.journals.uchicago.edu/doi/10.1086/716949.\n20 Yuyu Chen and David Y. Yang, \u201cThe Impact of Media Censorship: 1984 or Brave New World?,\u201d American Economic Review 109, no. 6 (June 2019): https://www.aeaweb.org/articles?id=10.1257/aer.20171765.\n21 See Elizabeth Dwoskin, Jeremy B. Merrill, and Gerrit De Vynck, \u201cSocial Platforms\u2019 Bans Muffle Russian State Media Propaganda,\u201d Washington Post, March 16, 2022, https://www.washingtonpost.com/technology/2022/03/16/facebook-youtube-russian-bans; see also Will Oremus and Cat Zakrzewski, \u201cBig Tech Tried to Quash Russian Propaganda. Russia Found Loopholes,\u201d Washington Post, August 10, 2022, https://www.washingtonpost.com/technology/2022/08/10/facebook-twitter-russian-embassy-accounts-propaganda.\n22 Zakary L. Tormala and Richard E. Petty, \u201cSource Credibility and Attitude Certainty: A Metacognitive Analysis of Resistance to Persuasion,\u201d Journal of Consumer Psychology 14 (2004): https://www.sciencedirect.com/science/article/abs/pii/S1057740804701692; Christopher Paul and Miriam Matthews, \u201cThe Russian \u2018Firehose of Falsehood\u2019 Propaganda Model: Why It Might Work and Options to Counter It,\u201d RAND Corporation, 2016, https://www.rand.org/pubs/perspectives/PE198.html.\n23 Jon Roozenbeek et al., \u201cPsychological Inoculation Improves Resilience Against Misinformation on Social Media,\u201d Science Advances 8 (2022); and Laura Garcia and Tommy Shane, \u201cA Guide to Prebunking: A Promising Way to Inoculate Against Misinformation,\u201d First Draft, June 29, 2021, https://firstdraftnews.org/articles/a-guide-to-prebunking-a-promising-way-to-inoculate-against-misinformation.\n24 Nyhan, \u201cWhy the Backfire Effect.\u201d\n25 Greg Myre, \u201cA \u2018Perception Hack\u2019: When Public Reaction Exceeds the Actual Hack,\u201d NPR, November 1, 2020, https://www.npr.org/2020/11/01/929101685/a-perception-hack-when-public-reaction-exceeds-the-actual-hack.\n26 Carissa Goodwin and Dean Jackson, \u201cGlobal Perspectives on Influence Operations Investigations: Shared Challenges, Unequal Resources,\u201d Carnegie Endowment for International Peace, February 9, 2022, https://carnegieendowment.org/2022/02/09/global-perspectives-on-influence-operations-investigations-shared-challenges-unequal-resources-pub-86396.\n27 Consider Nimmo and Agranovich, \u201cRecapping Our 2022\u201d; and Goodwin and Jackson, \u201cGlobal Perspectives.\u201d\n28 Karoun Demirjian and Devlin Barrett, \u201cObama Team\u2019s Response to Russian Election Interference Fell Short, Senate Report Says,\u201d Washington Post, February 6, 2020, https://www.washingtonpost.com/national-security/obama-teams-response-to-russian-election-interference-fell-short-senate-report-says/2020/02/06/93c2fdac-48f2-11ea-9164-d3154ad8a5cd_story.html.\n29 Philip Ewing, \u201cFACT CHECK: Why Didn\u2019t Obama Stop Russia\u2019s Election Interference In 2016?,\u201d NPR, February 21, 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.\n30 \u201cRussia Blocks BBC Website, Says It\u2019s Only Beginning of Its Response,\u201d Reuters, March 16, 2022, https://www.reuters.com/world/russia-blocks-bbc-website-says-its-only-beginning-its-response-2022-03-16/\n31 Joseph Bodnar, \u201cRT en Espa\u00f1ol Won\u2019t Stay Off YouTube,\u201d German Marshall Fund, March 8, 2023, https://securingdemocracy.gmfus.org/rt-en-espanol-wont-stay-off-youtube.\nCase Study 8: Removing Inauthentic Asset Networks\nKey takeaways:\nThe detection and removal from platforms of accounts or pages that misrepresent themselves has obvious merit, but its effectiveness is difficult to assess. Fragmentary data\u2014such as unverified company statements, draft platform studies, and U.S. intelligence\u2014suggest that continuous takedowns might be capable of reducing the influence of inauthentic networks and imposing some costs on perpetrators. However, few platforms even claim to have achieved this, and the investments required are considerable. Meanwhile, the threat posed by inauthentic asset networks remains unclear: a handful of empirical studies suggest that such networks, and social media influence operations more generally, may not be very effective at spreading disinformation. These early findings imply that platform takedowns may receive undue attention in public and policymaking discourse.\nKey sources:\n- \u201cThreat Report: The State of Influence Operations 2017-2020,\u201d Meta, May 2021, https://about.fb.com/wp-content/uploads/2021/05/IO-Threat-Report-May-20-2021.pdf.\n- Camille Fran\u00e7ois and evelyn douek, \u201cThe Accidental Origins, Underappreciated Limits, and Enduring Promises of Platform Transparency Reporting about Information Operations,\u201d Journal of Online Trust & Safety 1 (2021), https://tsjournal.org/index.php/jots/article/view/17.\n- Gregory Eady et al., \u201cExposure to the Russian Internet Research Agency Foreign Influence Campaign on Twitter in the 2016 US Election and Its Relationship to Attitudes and Voting Behavior,\u201d Nature Communications 14 (2023), https://www.nature.com/articles/s41467-022-35576-9.\nDescription and Use Cases\nSocial media companies in the past five years have detected and removed many different networks of fake assets\u2014such as accounts, pages, groups, and events\u2014used to manipulate platforms. These assets are inauthentic, meaning they misrepresent their identity and purpose, and they work together as part of a disinformation campaign or influence operation. Such operations may involve automated activity, human control, or a blend of the two.1\nMajor platforms hire in-house investigators, contract out to third-party firms, and form partnerships with researchers to detect and respond to inauthentic asset networks. Platforms also receive tips from governments based on intelligence or law enforcement information. Separately, governments sometimes seek to induce platforms to remove content\u2014inauthentic or otherwise\u2014via legal processes, informal requests, or political pressure.2 (Removal of authentic content, such as accounts that openly belong to terrorist groups, is beyond the scope of this case study.)\nWhen social media companies remove influence operations asset networks, they often reference objectives like the preservation of authenticity, the right to access reliable information, or the importance of safeguarding elections.3 The policy terms and definitions they use to define the problem differ.4 Meta uses the term \u201ccoordinated inauthentic behavior\u201d when referring to the use of multiple assets to mislead the company or the public or to evade enforcement of Meta\u2019s policies; this term has become a shorthand for industry observers and has subsequently been adopted by TikTok (which provides fewer details on its definition).5 X refers to \u201cinformation operations\u201d in its policies on platform manipulation and spam, and it bans \u201cinauthentic engagements\u201d and \u201ccoordinated activity, that attempts to artificially influence conversations through the use of multiple accounts, fake accounts, automation and/or scripting.\u201d6 Google\u2019s threat analysis group (which also covers YouTube) refers to \u201ccoordinated influence operations.\u201d7\nHow Much Do We Know?\nMost information about platforms\u2019 takedowns (removals) of inauthentic asset networks comes from the platforms themselves. Major platforms have periodically disclosed takedown actions, sometimes in collaboration with outside investigators. The Disinfodex database contains 326 disclosures by Facebook, Twitter, Google/YouTube, and Reddit between September 2017 and August 2021.8 However, the amount of detail provided\u2014such as the number and type of illicit accounts identified, the narratives employed, the level of user engagement achieved, the perpetrator assessed to be responsible, and the platform policies violated\u2014varies considerably. Among efforts to improve transparency in this area is the EU\u2019s 2022 Strengthened Code of Practice on Disinformation, which calls for signatories to standardize data on influence operations across platforms and report them to governments in more granular detail.9\nDisclosures of individual takedowns, however informative, still leave open the more fundamental question: To what degree do these takedowns succeed in reducing the prevalence or impact of disinformation? There is virtually no published research that directly bears on this question. For one thing, the success of takedowns depends in part on the responses of bad actors, such as foreign governments and unscrupulous public relations firms. Do takedowns impose enough operational cost and potential public embarrassment on the bad actors to inhibit disinformation campaigns, or do they adjust fairly easily? Platforms and intelligence agencies each have some insight here, but adversarial behavior is inherently hard to observe, may differ from actor to actor, and can change over time.\nMoreover, platforms do not typically share many (or any) details from their internal research on takedowns, and when fragmentary findings do come to light, they are difficult to interpret in isolation. For example, some platforms have cited positive long-term impacts from their takedowns but did not quantify these claims, specify how they were measured, or share supporting data. Given this gap, leaked copies of internal platform research have provided valuable information to the public. Yet these leaks are infrequent and often come in forms (such as draft, historical, or incomplete documents) or contexts (such as personnel disputes) that partially cloud their meaning. Moreover, very little is known about the effectiveness of social media influence operations themselves and, therefore, how important it is to disrupt them.\nHow Effective Does It Seem?\nMajor social media platforms have greatly increased the number of disclosed takedowns since 2016, which is due in part to a surge of investigative resources. But the covert nature of influence operations makes it hard to say how many remain undetected. If the increase in reported takedowns stems in part from a growing number of influence operations being carried out globally, then the takedowns could be tactically effective but strategically insufficient. Platforms may also be disclosing a greater portion of the takedowns they perform in response to increased public demands for action. By the same token, news reports of influence operations are increasing year-over-year, which may mean either that operations are increasing or that there is greater public interest in the issue (or both).10\nIn terms of strategic impact, Facebook reported in 2021 that it had \u201cmade progress against [influence operations] by making [them] less effective and by disrupting more campaigns early, before they could build an audience.\u201d Furthermore, these efforts were said to have forced \u201cthreat actors to shift their tactics,\u201d pushing them to operate on less popular platforms and invest greater resources in secrecy.11 Such claims are difficult to independently evaluate, however, because the platform provides only limited data access to outside researchers.12\nFacebook\u2019s claim of strategic progress appears to be an outlier in the industry; other major platforms have not publicly claimed that their takedowns are having broad effects. This silence may itself be an important indication that broad effects remain difficult to achieve or at least measure. In fact, a draft outside review commissioned by Twitter in 2021 (and leaked by a former executive) found that \u201canalysts are unable to identify and analyze evolving threats or changes in the [tactics, techniques, and procedures] of threat actors, or measure the effectiveness of action and enforcement, because information is not being preserved.\u201d13 Twitter employees apparently believed that the company\u2019s system of \u201cremoval ultimately [did] not discourage adversaries from attempting to exploit and leverage the platform, or add costs to their operations because they can quickly adapt.\u201d\nFacebook\u2019s claim of strategic progress appears to be an outlier in the industry; other major platforms have not publicly claimed that their takedowns are having broad effects.\nThe U.S. intelligence community, which has its own unique vantage on foreign influence actors, has offered some tentative praise of platform takedowns. Intelligence analysts looking back at the 2020 election found that Russia\u2019s Internet Research Agency adopted some \u201cshort-lived\u201d and perhaps ineffectual new tactics \u201cprobably in response to efforts by U.S. companies and law enforcement to shut down\u201d the kind of inauthentic personas used in 2016.14 Additionally, repeated public disclosures of foreign influence campaigns \u201cprobably helped counter them to some degree\u201d in 2020 by improving societal awareness, reducing the deniability of Russia and Iran, and helping China see that covert influence was not \u201cadvantageous enough for [it] to risk getting caught meddling.\u201d Nevertheless, U.S. agencies in 2020 \u201ctracked a broader array of foreign actors taking steps to influence U.S. elections than in past election cycles.\u201d\nTo the extent that social media takedowns can reduce the number and impact of inauthentic asset networks, the ultimate benefit to society depends on the danger posed by those networks. The greater the likely negative effects of an influence operation on society, the more important it is to discover and remove the illicit asset network used to carry out the operation. Unfortunately, very little is known about the effects of online influence operations. Echoing the consensus of experts, Meta\u2019s global threat intelligence lead, Ben Nimmo, calls assessing influence operations\u2019 impact \u201cone of the most difficult questions for investigators.\u201d15 (U.S. intelligence agencies are prohibited from even trying to answer the question because it would require analyzing American politics.16)\nA Princeton University meta-analysis commissioned by Carnegie found only one rigorous, empirical study of \u201cwhat has arguably been the greatest focus of policymakers since 2016: the threat of foreign governments using social media to sway voters in democratic elections.\u201d17 That study, on Russia\u2019s efforts to influence U.S. Twitter users during the 2016 presidential election, found no effect on user beliefs. Another analysis found that the impact of Russia\u2019s Internet Research Agency in 2016 was likely small.18 Meanwhile, a landmark 2018 paper in Science suggested that human users are more responsible than automated accounts for the rapid spread of false information online.19 Although inauthentic asset networks are not necessarily automated, the finding calls attention to the huge quantity of disinformation being organically generated and disseminated online, unrelated to any covert influence campaign. These early findings suggest that platform takedowns\u2014while undoubtedly necessary\u2014may receive undue attention in policy conversations about how best to counter disinformation and influence operations.\nOne limit of removing inauthentic asset networks is that it does not address increasingly prominent coordinated efforts from authentic networks to spread disinformation\u2014for example, the online activists who organized the January 6 insurrection in the United States and the January 8 riot in Brazil.20 Platforms have fewer rules specifically prohibiting authentic coordinated behavior, even if it results in disinformation, because they are sensitive to accusations of viewpoint censorship and do not want to prevent genuine social movements from coordinating online. This gap in community standards led Facebook to draft a policy against \u201ccoordinated social harm,\u201d building on policies against \u201cviolence-inducing conspiracy networks,\u201d which the company previously used to justify a ban on the QAnon conspiracy movement.21 Recent scholarship suggests that removal of networks like these on one platform (which includes banning or deplatforming authentic user accounts) can have unintended consequences: banned users may migrate to fringe platforms where they create and engage with content more extreme and harmful than what is allowed on mainstream platforms, potentially accelerating their radicalization.22\nHow Easily Does It Scale?\nDetecting and removing inauthentic asset networks appears to be moderately expensive, though social media companies have not released specific cost breakdowns. More often, companies give total spending or staffing figures that aggregate many varied aspects of safety and security. As of 2021, Facebook reportedly had \u201chundreds\u201d of \u201cfull-time policy experts tackling foreign influence operations and misinformation\u201d\u2014of which an unknown subset were focused on threat intelligence and asset removal.23 Twitter/X has had far fewer dedicated staff (the exact number was disputed) even prior to mass layoffs in 2022\u20132023, and these employees complained internally about antiquated and inadequate tools and technology.24\nComparing the two companies raises challenging questions about what level of investment in takedowns is necessary, cost-effective, and affordable for different platforms. On the one hand, Meta has many times more users than Twitter/X and is a much larger company, so its level of investment should naturally be greater. On the other hand, in countries like the United States, the influence of Twitter/X on political discourse has long been disproportionate to the platform\u2019s overall size.25 Even so, Meta has had greater ability and incentive to invest in takedowns due to its superior financial performance and the extraordinary public scrutiny it faced after 2016. Zuckerberg told investors in 2017 that \u201cwe\u2019re [now] investing so much in security that it will impact our profitability\u201d\u2014a statement of financial strength\u2014whereas Twitter/X has only ever had two profitable years in its history.26 The gap in total safety investments has widened further since businessman Elon Musk bought Twitter and began implementing drastic cost cuts while repudiating many traditional trust and safety practices.\nRegardless, it is clear that the further scaling up of takedowns at any platform would require considerable new staffing, technology, and time. According to the 2021 Twitter memo, one employee believed that Twitter could plausibly aim to \u201cadd cost to adversaries\u201d (such as those who create inauthentic asset networks) and therefore make strategic progress against them, but that such an effort \u201cwould realistically take two years [to] build out.\u201d27\nAdditionally, the resources required to investigate illicit asset networks extend beyond the platforms themselves. A growing number of independent companies and nonprofits conduct similar investigations, often in collaboration with platforms. Outside investigators have reported chronic resource constraints and fiscal uncertainty.28\nIt is important to note that most major platforms have focused their investigative resources in lucrative Western markets, where advertisers, regulators, and civil society create the greatest pressure for visible action. Independent investigators, too, are heavily concentrated in North America and Europe. There is widespread concern that influence operations continue uninhibited in places where platforms and others have invested fewer investigative resources.29 This suggests a large untapped opportunity, but it also indicates the high cost of scaling takedowns globally.\nNotes\n1 The scope of this paper was informed by the European Union\u2019s 2022 Strengthened Code of Practice on Disinformation, which covers issues such as fake account creation, bot-driven amplification, and other forms of platform manipulation under \u201cintegrity of services.\u201d See \u201c2022 Strengthened Code of Practice on Disinformation,\u201d European Commission, June 16, 2022, https://digital-strategy.ec.europa.eu/en/library/2022-strengthened-code-practice-disinformation.\n2 See Jan Rydzak, \u201cThe Stalled Machines of Transparency Reporting,\u201d November 29, 2023, Carnegie Endowment for International Peace, https://carnegieendowment.org/2023/11/29/stalled-machines-of-transparency-reporting-pub-91085.\n3 See \u201cInauthentic Behavior,\u201d Meta, accessed January 27, 2023, https://transparency.fb.com/policies/community-standards/inauthentic-behavior; \u201cPlatform Manipulation and Spam Policy,\u201d X, March 2023, https://help.twitter.com/en/rules-and-policies/platform-manipulation; and \u201cCivic Integrity Policy,\u201d X, August 2023, https://help.twitter.com/en/rules-and-policies/election-integrity-policy.\n4 For more on how different platform policies address influence operations, see Jon Bateman, Natalie Thompson, and Victoria Smith, \u201cHow Social Media Platforms\u2019 Community Standards Address Influence Operations,\u201d April 1, 2021, https://carnegieendowment.org/2021/04/01/how-social-media-platforms-community-standards-address-influence-operations-pub-84201.\n5 \u201cInauthentic Behavior,\u201d Meta; evelyn douek, \u201cWhat Does \u2018Coordinated Inauthentic Behavior\u2019 Actually Mean?,\u201d Slate, July 2, 2020, https://slate.com/technology/2020/07/coordinated-inauthentic-behavior-facebook-twitter.html; and \u201cElection Integrity,\u201d TikTok, accessed January 27, 2023, https://www.tiktok.com/safety/en-sg/election-integrity.\n6 Vijaya Gadde and Yoel Roth, \u201cEnabling Further Research of Information Operations on Twitter,\u201d Twitter, October 17, 2021, https://blog.twitter.com/en_us/topics/company/2018/enabling-further-research-of-information-operations-on-twitter; and \u201cPlatform Manipulation and Spam Policy,\u201d X.\n7 Shane Huntley, \u201cTAG Bulletin: Q3 2022,\u201d Google, October 26, 2022, https://blog.google/threat-analysis-group/tag-bulletin-q3-2022.\n8 Carnegie analysis of \u201cDisinfodex,\u201d Disinfodex.\n9 \u201c2022 Strengthened Code,\u201d European Commission.\n10 Samantha Bradshaw, Hannah Bailey, and Philip N. Howard, \u201cIndustrialized Disinformation: 2020 Global Inventory of Organized Social Media Manipulation,\u201d Oxford Internet Institute, 2021, https://demtech.oii.ox.ac.uk/research/posts/industrialized-disinformation.\n11 \u201cThreat Report: The State of Influence Operations 2017-2020,\u201d Meta, May 2021, https://about.fb.com/wp-content/uploads/2021/05/IO-Threat-Report-May-20-2021.pdf.\n12 See Camille Fran\u00e7ois and evelyn douek, \u201cThe Accidental Origins, Underappreciated Limits, and Enduring Promises of Platform Transparency Reporting about Information Operations,\u201d Journal of Online Trust & Safety 1 (2021): https://tsjournal.org/index.php/jots/article/view/17; and Samantha Lai, Naomi Shiffman, Alicia Wanless, \u201cOperational Reporting by Online Services: A Proposed Framework,\u201d Carnegie Endowment for International Peace, May 18, 2023, https://carnegieendowment.org/2023/05/18/operational-reporting-by-online-services-proposed-framework-pub-89776.\n13 Joseph Menn, Elizabeth Dwoskin, and Cat Zakrzewski, \u201cFormer Security Chief Claims Twitter Buried \u2018Egregious Deficiencies,\u2019\u201d Washington Post, August 23, 2022, https://www.washingtonpost.com/technology/interactive/2022/twitter-whistleblower-sec-spam.\n14 \u201cForeign Threats to the 2020 US Federal Elections,\u201d U.S. National Intelligence Council, March 10, 2021, https://www.dni.gov/files/ODNI/documents/assessments/ICA-declass-16MAR21.pdf.\n15 Ben Nimmo, \u201cAssessing the Impact of Influence Operations Through the Breakout Scale,\u201d Carnegie Endowment for International Peace, October 25, 2022, https://carnegieendowment.org/2022/10/25/perspectives-for-influence-operations-investigators-pub-88208#breakout.\n16 \u201cForeign Threats to the 2020 US Federal Elections,\u201d U.S. National Intelligence Council.\n17 Bateman, Hickok, Courchesne, Thange, and Shapiro, \u201cMeasuring the Effects.\u201d\n18 Joshua A. Tucker, \u201cThe Limited Room for Russian Troll Influence in 2016,\u201d Lawfare, October 27, 2020, https://www.lawfaremedia.org/article/limited-room-russian-troll-influence-2016; see also Gregory Eady et al., \u201cExposure to the Russian Internet Research Agency Foreign Influence Campaign on Twitter in the 2016 US Election and Its Relationship to Attitudes and Voting Behavior,\u201d Nature Communications 14 (2023), https://www.nature.com/articles/s41467-022-35576-9.\n19 Soroush Vosoughi, Deb Roy, and Sinan Aral, \u201cThe Spread of True and False News Online,\u201d Science 359 (2018): https://www.science.org/doi/10.1126/science.aap9559.\n20 Jackson and Dos Santos, \u201cTale of Two Insurrections.\u201d\n21 Nathaniel Gleicher, \u201cRemoving New Types of Harmful Networks,\u201d Meta, September 16, 2021, https://about.fb.com/news/2021/09/removing-new-types-of-harmful-networks; and \u201cAn Update to How We Address Movements and Organizations Tied to Violence,\u201d Meta, October 17, 2022, https://about.fb.com/news/2020/08/addressing-movements-and-organizations-tied-to-violence.\n22 See Tamar Mitts, \u201cBanned: How Deplatforming Extremists Mobilizes Hate in the Dark Corners of the Internet,\u201d, Tel Aviv University, October 18, 2021, https://social-sciences.tau.ac.il/sites/socsci.tau.ac.il/files/media_server/Governemnt/Mitts_Digital_CT_Banned.pdf; and Tamar Mitts, Nilima Pisharody, and Jacob Shapiro, \u201cRemoval of Anti-vaccine Content Impacts Social Media Discourse,\u201d (paper presented at the 14th ACM Web Science Conference, Barcelona, June 26\u201329, 2022), https://dl.acm.org/doi/10.1145/3501247.3531548.\n23 Joseph Menn, Elizabeth Dwoskin, and Cat Zakrzewski, \u201cTwitter Can\u2019t Afford to Be One of the World\u2019s Most Influential Websites,\u201d Washington Post, September 4, 2022, https://www.washingtonpost.com/technology/2022/09/04/twitter-mudge-alethea-resources.\n24 Menn, Dwoskin, and Zakrzewski, \u201cTwitter Can\u2019t Afford\u201d; and Menn, Dwoskin, and Zakrzewski, \u201cFormer Security Chief.\u201d\n25 Menn, Dwoskin, and Zakrzewski, \u201cTwitter Can\u2019t Afford.\u201d\n26 Ben Popper, \u201cFacebook\u2019s Business Is Booming, but It Says Preventing Abuse Will Cut Into Future Profits,\u201d The Verge, November 1, 2017, https://www.theverge.com/2017/11/1/16593812/facebook-earnings-q3-third-quarter-2017; and Matthew Mahoney, \u201cTwitter and Its Fight for Profitability,\u201d Michigan Journal of Economics, December 21, 2022, https://sites.lsa.umich.edu/mje/2022/12/21/twitter-and-its-fight-for-profitability.\n27 \u201cCurrent State Assessment,\u201d Althea Group, as attached to Menn, Dwoskin, and Zakrzewski, \u201cFormer Security Chief.\u201d\n28 See Victoria Smith and Jon Bateman, \u201cBest Practice Guidance for Influence Operations Research: Survey Shows Needs and Challenges,\u201d Carnegie Endowment for International Peace, August 2, 2022, https://carnegieendowment.org/2022/08/02/best-practice-guidance-for-influence-operations-research-survey-shows-needs-and-challenges-pub-87601; Dean Jackson, \u201cInfluence Operations Researchers Want Guidance on Best Practice, But What Does That Mean?\u201d Carnegie Endowment for International Peace, December 5, 2022, https://carnegieendowment.org/2022/12/05/influence-operations-researchers-want-guidance-on-best-practice-but-what-does-that-mean-pub-88517; and Victoria Smith and Natalie Thompson, \u201cSurvey on Countering Influence Operations Highlights Steep Challenges, Great Opportunities,\u201d Carnegie Endowment for International Peace, December 7, 2020, https://carnegieendowment.org/2020/12/07/survey-on-countering-influence-operations-highlights-steep-challenges-great-opportunities-pub-83370.\n29 See Odanga Madung, \u201cJack Dorsey\u2019s Twitter Failed African Countries,\u201d Wired, December 3, 2021, https://www.wired.com/story/jack-dorseys-twitter-failed-african-countries; and Goodwin and Jackson, \u201cGlobal Perspectives.\u201d\nCase Study 9: Reducing Data Collection and Targeted Ads\nKey takeaways:\nData privacy protections can be used to reduce the impact of microtargeting, or data-driven personalized messages, as a tool of disinformation. However, nascent scholarship suggests that microtargeting\u2014while modestly effective in political persuasion\u2014falls far short of the manipulative powers often ascribed to it. To the extent that microtargeting works, privacy protections seem to measurably undercut its effectiveness. But this carries high economic costs\u2014not only for tech and ad companies, but also for small and medium businesses that rely on digital advertising. Additionally, efforts to blunt microtargeting can raise the costs of political activity in general, especially for activists and minority groups who lack access to other communication channels.\nKey sources:\n- Nathalie Mar\u00e9chal and Ellery Roberts Biddle, \u201cIt\u2019s Not Just the Content, It\u2019s the Business Model: Democracy\u2019s Online Speech Challenge,\u201d New America, March 17, 2020, https://www.newamerica.org/oti/reports/its-not-just-content-its-business-model.\n- Bal\u00e1zs Bod\u00f3, Natali Helberger, and Claes de Vreese, \u201cPolitical Micro-targeting: A Manchurian Candidate or Just a Dark Horse?\u201d Internet Policy Review 6 (2017), https://policyreview.info/articles/analysis/political-micro-targeting-manchurian-candidate-or-just-dark-horse.\n- Dipayan Ghosh and Ben Scott, \u201cDigital Deceit: The Technologies Behind Precision Propaganda on the Internet,\u201d New America, January 23, 2018, https://www.newamerica.org/pit/policy-papers/digitaldeceit.\nDescription and Use Cases\nBeginning in 2017, two major disclosures\u2014the Cambridge Analytica scandal and the revelations of Russian social media advertising during the 2016 U.S. election\u2014focused Western attention on how personal data can enable political influence.1 In the ensuing flurry of analysis, disinformation experts began recommending stronger data privacy laws and practices. While these had long been advocated on privacy grounds, they were now also put forth as a means of countering disinformation by reducing the power of microtargeting and algorithmic content moderation.2\nThere were at least two related concerns. First, observers feared that microtargeted messages were more effective at mobilizing, persuading, or even manipulating their audiences. Such persuasive power was the central value proposition of social media companies to advertisers, but it also positioned platforms as a potent means of spreading disinformation for both foreign and domestic actors. Today\u2019s digital microtargeting represents an evolution of earlier techniques: in the 2004 U.S. presidential campaign, Republican strategist Karl Rove assembled profiles of voters based on personal data, like credit card records, and sent differentiated direct mail ads to each segment.3 New technology now enables far more advanced methods: online advertisers can use automated tools to develop and deploy an ad in thousands of distinct variations, testing which ones get the most traction with various audiences.4\nSecond, the prevailing business model of social media\u2014use of personal data to curate content in ways that capture users\u2019 attention and serve them more, and more effective, advertisements\u2014also came under criticism. The model was seen as an engine for the spread of misleading, incendiary content, including disinformation, and therefore bore responsibility for serious harm to democracies around the world.5 (See case study 10 for more on social media algorithms.)\nThe largest and highest-profile policy response was the EU\u2019s General Data Protection Regulation (GDPR).6 The GDPR requires that commercial entities operating in the EU or \u201cmonitoring the behaviour of individuals in the EU\u201d receive user consent to collect personal data and that they collect the minimum necessary data for their purpose.7 Anonymized data is excluded from the regulation, and organizations must take steps to protect identity through pseudonymization processes like encryption as soon as feasible in the collection process. Larger companies must have a data protection officer charged with overseeing compliance; violations can incur large fines.8 Since the GDPR\u2019s passage, many policymakers, analysts, and activists have called for the United States and other countries to adopt more privacy policies of their own.9\nThe GDPR faced obstacles in limiting the use of personal data for political messaging: for example, some EU member states used their regulatory autonomy to make crucial exemptions for political parties, and many regulations are unclear about which entities are responsible for compliance and what counts as a political advertisement as opposed to an issue advertisement.10 Some of these gaps are being filled by the EU\u2019s Digital Services Act (DSA), which passed in 2022, and further political advertisement rules currently being finalized.11 They define political advertisements more clearly as ads run by politicians or campaigns or about legislation or elections. They also limit what type of data can be used for political microtargeting; only very basic information like age and language can be used during election periods, and there are permanent restrictions on the use of sensitive data like political orientation.12 These strengthened restrictions are weaker than some officials proposed. In January 2022, for instance, the EU\u2019s data protection agency called for a ban on all microtargeted political ads, as have the European Parliamentary delegations from several countries.13\nTechnology companies have also taken voluntary steps to reduce the granularity of microtargeting and the invasiveness of data collection. Perhaps most dramatically, in October 2019, Twitter banned all political advertising\u2014though the company struggled to differentiate political and issue advertisements and reversed this policy after its acquisition by Musk.14 In 2019, Google limited political ad targeting to \u201cage, gender, and general location\u201d; in 2021, the company also announced several new limits on how it would profile and target third-party ads across the internet.15 In 2021, Facebook also restricted microtargeting options for political and sensitive topics.16 Additionally, in early 2022, Apple made a change to its iOS software that prevented companies from tracking user activity across third-party apps and websites.\nHow Much Do We Know?\nUnlike some other types of countermeasures, data privacy has recent achievements that can be evaluated on real-world impact. Unfortunately, while analysts generally find that recent privacy efforts by the EU, tech companies, and others have somewhat reduced the amount and power of microtargeting, there has been very little scholarship that directly assesses their impact on disinformation.17 Much more analysis has focused on other impacts, such as the economic costs of privacy efforts, which may nevertheless have an indirect relationship to disinformation.18\nAdditionally, the efficacy of this intervention has much to do with how persuasive data-driven advertising is to begin with. Digital microtargeting\u2019s immense power is a key claim of technology companies, advertising firms, and political consultants. The sheer size of the digital ad industry attests to widespread belief in this marketing claim: $600 billion is spent annually in the sector, which has given rise to several of the world\u2019s most valuable companies. However, there is little scholarship or independent analysis to substantiate industry claims, particularly in the context of political advertising.19 A 2020 study noted that \u201cliterature on the effects of [political microtargeting] techniques is scarce.\u201d 20 The dangers of political microtargeting, while often discussed, are still largely unknown.21\nRecent studies provide some experimental evidence on the effects of political and commercial microtargeting.22 However, much of the literature on political advertising comes from the United States, which has several distinctive election dynamics\u2014including a polarized two-party system, a loose set of campaign finance regulations, and a remarkably long election season (allowing more advertising of all kinds).23 Research findings from the United States might not apply elsewhere.\nMoreover, studies of political microtargeting have generally focused on whether such advertisements change people\u2019s votes. Swaying voter preferences, while undoubtedly important, is not always the only or most important effect or purpose of political disinformation. Influencing voter turnout\u2014by energizing supporters, discouraging opponents, or tricking people about voting rules\u2014can be equally or more impactful in some elections. Microtargeted disinformation might also aim to alter political dynamics in more complicated and indirect ways, like by increasing levels of distrust, fear, or apathy. No studies specifically assessing such effects were found.\nHow Effective Does It Seem?\nNascent scholarship suggests that microtargeting is somewhat effective for political campaigns but falls far short of the manipulative powers often ascribed to it. A 2018 experiment in the Netherlands examined issue-based targeting\u2014a tactic used by candidates, parties, and other interest groups to show ads about specific topics, such as crime or reproductive rights, to the voters most likely to care about those topics. The study found that ads microtargeted by issue did not increase the salience of that issue but did modestly improve the likelihood that subjects would vote for the political party whose branding was used in the message.24 The authors stressed that microtargeted ads competed with many other sources of information that voters encounter, adulterating the ads\u2019 influence. For this reason, microtargeting\u2014like other forms of advertising\u2014may be more effective in smaller elections, like local or primary races, that attract less attention than national contests.25\nSimilar results were found in the few studies of personality-based (also called psychometric or psychographic) microtargeting. These techniques, famously practiced by Cambridge Analytica, seek to target individuals prone to certain feelings, such as anger.26 While Cambridge Analytica is now widely considered to have oversold its capabilities, academic experiments have found that personality-based microtargeted political ads can be more effective than regular ads at increasing positive feelings toward a candidate. However, evidence is mixed about whether such microtargeting does any more than traditional ads to influence viewers\u2019 voting preferences\u2014a crucial test of electoral persuasion.27\nIf microtargeting is modestly effective, then how much do privacy protections reduce its persuasive power? Evidence suggests the change can be meaningful. One study associated the GDPR with a 12 percent decrease in page views and e-commerce revenue following its implementation.28 Another study estimated that affected businesses suffered an 8 percent loss of profits and a 2.2 percent drop in sales.29 While these studies did not directly examine disinformation or political persuasion, they provide indirect evidence that privacy protections can make digital ads measurably less effective.\nHow Easily Does It Scale?\nSince the EU passed the GDPR, several countries and some U.S. states have implemented their own privacy laws.30 It seems likely that, in time, most democracies will have significantly more privacy protections than they do today. Moves by major tech companies, such as Apple and Google, also suggest a perceived market demand for better privacy.\nOne way to address disinformation would be to pair data privacy and microtargeting restrictions with broader campaign finance reforms.\nPrivacy has its own inherent and practical value, which should be a major (perhaps primary) factor in any cost-benefit analysis of expanded data protections. On the other hand, studies have shown high compliance costs and even higher lost revenue for firms and advertisers.31 The GDPR, according to some estimates, cost companies hundreds of billions of dollars.32 Similarly, Apple\u2019s iOS changes cost Meta an estimated $10 billion a year in revenue and contributed to a $250 billion decline in Meta\u2019s market value.33 Research by the Information Technology and Innovation Foundation, a pro-business think tank, estimates that stricter U.S. privacy laws could cost the American economy $122 billion annually.34 Some scholars argue the cost will be lower if many users opt out of the protections\u2014but this will also dilute the law\u2019s counter-disinformation potential.35 Although giant tech and advertising companies can most likely bear the cost of privacy regulations, much of the cost would fall on others\u2014such as small- and medium-sized enterprises\u2014that rely on digital advertising to attract customers.36\nRather than reducing data collection across the board, policymakers could instead place stricter limits on the use of microtargeting for political purposes. The EU\u2019s DSA takes this approach (albeit on top of existing GDPR rules). However, strict limits on political advertising make it harder for politicians to reach voters. If applied to issue ads, limits can also reduce the reach of activists, who have come to rely on digital advertising to compete with powerful interests and raise the salience of neglected issues or perspectives.37 Conversely, if restrictions on issue ads are too lenient, such ads become an easy way to avoid restrictions on political microtargeting. One way to address these problems would be to pair data privacy and microtargeting restrictions with broader campaign finance reforms, such as public financing of elections or stronger political spending disclosures.\nNotes\n1 Consider Nathaniel Persily, \u201cThe 2016 U.S. Election: Can Democracy Survive the Internet?\u201d Journal of Democracy 28 (April 2017): https://www.journalofdemocracy.org/articles/the-2016-u-s-election-can-democracy-survive-the-internet.\n2 One commentator, for example, called data privacy laws an \u201celegant arrow in the quiver of responses to online disinformation\u201d that can \u201cprotect against foreign and homegrown trolls alike.\u201d See Alex Campbell, \u201cHow Data Privacy Laws Can Fight Fake News,\u201d Just Security, August 15, 2019, https://www.justsecurity.org/65795/how-data-privacy-laws-can-fight-fake-news. See also Bal\u00e1zs Bod\u00f3, Natali Helberger, and Claes de Vreese, \u201cPolitical Micro-targeting: A Manchurian Candidate or Just a Dark Horse?\u201d Internet Policy Review 6 (2017): https://policyreview.info/articles/analysis/political-micro-targeting-manchurian-candidate-or-just-dark-horse; and Dipayan Ghosh and Ben Scott, \u201cDigital Deceit: The Technologies Behind Precision Propaganda on the Internet,\u201d New America, January 23, 2018, https://www.newamerica.org/pit/policy-papers/digitaldeceit.\n3 \u201cKarl Rove: The Architect,\u201d PBS Frontline, April 12, 2005, https://www.pbs.org/wgbh/pages/frontline/shows/architect. For more discussion on the definition of micro-targeting, see Tom Dobber, Damian Trilling, Natali Helberger, and Claes de Vreese, \u201cEffects of an Issue-Based Microtargeting Campaign: A Small-Scale Field Experiment in a Multi-party Setting,\u201d Information Society 39 (2022): https://www.tandfonline.com/doi/full/10.1080/01972243.2022.2134240.\n4 \u201cPersonal Data: Political Persuasion,\u201d Tactical Tech, March 2019, https://cdn.ttc.io/s/tacticaltech.org/methods_guidebook_A4_spread_web_Ed2.pdf.\n5 Nathalie Mar\u00e9chal and Ellery Roberts Biddle, \u201cIt\u2019s Not Just the Content, It\u2019s the Business Model: Democracy\u2019s Online Speech Challenge,\u201d New America, March 17, 2020, https://www.newamerica.org/oti/reports/its-not-just-content-its-business-model; see also Anthony Nadler, Matthew Crain, and Joan Donovan, \u201cWeaponizing the Digital Influence Machine: The Political Perils of Online Ad Tech,\u201d Data & Society, October 2018, https://datasociety.net/library/weaponizing-the-digital-influence-machine.\n6 For one example, see Karen Kornbluh, \u201cCould Europe\u2019s New Data Protection Regulation Curb Online Disinformation?,\u201d Council on Foreign Relations, February 20, 2018, https://www.cfr.org/blog/could-europes-new-data-protection-regulation-curb-online-disinformation.\n7 \u201cWho Does the Data Protection Law Apply To?\u201d European Commission, accessed December 10, 2023, https://commission.europa.eu/law/law-topic/data-protection/reform/rules-business-and-organisations/application-regulation/who-does-data-protection-law-apply_en.\n8 Matt Burgess, \u201cWhat Is GDPR? The Summary Guide to GDPR Compliance in the UK,\u201d Wired UK, March 24, 2020, https://www.wired.co.uk/article/what-is-gdpr-uk-eu-legislation-compliance-summary-fines-2018; \u201cAnonymisation and Pseudonymisation,\u201d University College London, accessed April 5, 2023, https://www.ucl.ac.uk/data-protection/guidance-staff-students-and-researchers/practical-data-protection-guidance-notices/anonymisation-and; and Joshua Gresham, \u201cIs Encrypted Data Personal Data Under the GDPR?,\u201d International Association of Privacy Professionals, March 6, 2019, https://iapp.org/news/a/is-encrypted-data-personal-data-under-the-gdpr.\n9 Zachey Kliger, \u201cA Federal Data Privacy Law May Be the Best Tool to Combat Online Disinformation,\u201d Tech Policy Press, April 16, 2021, https://techpolicy.press/a-federal-data-privacy-law-may-be-the-best-tool-to-combat-online-disinformation; see also Campbell, \u201cHow Data Privacy Laws.\u201d\n10 \u201cGDPR Loopholes Facilitate Data Exploitation by Political Parties,\u201d Privacy International, April 30, 2019, https://privacyinternational.org/news-analysis/2836/gdpr-loopholes-facilitate-data-exploitation-political-parties.\n11 \u201cThe Digital Services Act Package,\u201d European Commission, accessed April 5, 2023, https://digital-strategy.ec.europa.eu/en/policies/digital-services-act-package; and \u201cTransparency and Targeting of Political Advertising: EU Co-legislators Strike Deal on New Regulation,\u201d European Council, November 7, 2023, https://www.consilium.europa.eu/en/press/press-releases/2023/11/07/transparency-and-targeting-of-political-advertising-eu-co-legislators-strike-deal-on-new-regulation.\n12 Clothilde Goujard, \u201cEuropean Parliament Votes to Transform Online Political Campaigning,\u201d Politico Europe, February 2, 2023, https://www.politico.eu/article/european-parliament-approves-its-position-on-political-advertising-law; and Mark Scott and Clothilde Goujard, \u201c5 Things You Need to Know About Europe\u2019s Political Ad Rules,\u201d Politico Europe, November 23, 2021, https://www.politico.eu/article/political-ads-europe-facebook-google.\n13 \u201cOnline Targeting for Political Advertising: Stricter Rules Are Necessary,\u201d Office of the European Data Protection Supervisor, January 20, 2022, https://edps.europa.eu/press-publications/press-news/press-releases/2022/online-targeting-political-advertising-stricter_en; and Goujard, \u201cEuropean Parliament Votes.\u201d\n14 Kate Conger, \u201cTwitter Will Ban All Political Ads, C.E.O. Jack Dorsey Says,\u201d New York Times, October 30, 2019, https://www.nytimes.com/2019/10/30/technology/twitter-political-ads-ban.html; Kate Conger, \u201cWhat Ads Are Political? Twitter Struggles With a Definition,\u201d New York Times, November 15, 2019, https://www.nytimes.com/2019/11/15/technology/twitter-political-ad-policy.html; and Kate Conger, \u201cTwitter to Relax Ban on Political Ads,\u201d New York Times, January 3, 2023, https://www.nytimes.com/2023/01/03/technology/twitter-political-ads.html.\n15 Makena Kelly, \u201cGoogle Issues Harsh New Restrictions on Political Ad Targeting,\u201d The Verge, November 20, 2019, https://www.theverge.com/2019/11/20/20975054/google-advertising-political-rules-twitter-ban-election-uk-general-2020; and Kate Kaye, \u201c\u2018We Will Not Build Alternate Identifiers\u2019: In Drastic Shift, Google Will End Behavioral Targeting, Profile-Building in Its Ad Products,\u201d Digiday, March 3, 2021, https://digiday.com/media/we-will-not-build-alternate-identifiers-in-drastic-shift-google-will-end-behavioral-targeting-profile-building-in-its-ad-products.\n16 Jeff Horwitz, \u201cFacebook Parent Meta Limits Ad Targeting for Politics and Other Sensitive Issues,\u201d Wall Street Journal, November 9, 2014, https://www.wsj.com/articles/facebook-parent-meta-bans-targeting-for-political-ads-11636488053.\n17 Kliger, \u201cFederal Data Privacy Law\u201d; Iva Nenadi\u0107, \u201cUnpacking the \u201cEuropean Approach\u201d to Tackling Challenges of Disinformation and Political Manipulation,\u201d Internet Policy Review, December 31, 2019, https://policyreview.info/articles/analysis/unpacking-european-approach-tackling-challenges-disinformation-and-political; and Razieh Nokhbeh Zaeem and K. Suzanne Barber, \u201cThe Effect of the GDPR on Privacy Policies: Recent Progress and Future Promise,\u201d ACM Transactions and Management Information Systems 12 (2020): https://dl.acm.org/doi/abs/10.1145/3389685.\n18 Jeremy Kahn, Stephanie Bodoni, and Stefan Nicola, \u201cIt\u2019ll Cost Billions for Companies to Comply With Europe\u2019s New Data Law,\u201d Bloomberg, March 22, 2018, https://www.bloomberg.com/news/articles/2018-03-22/it-ll-cost-billions-for-companies-to-comply-with-europe-s-new-data-law; and Samuel Goldberg, Garrett Johnson, and Scott Shriver, \u201cRegulating Privacy Online: An Economic Evaluation of the GDPR,\u201d Law & Economics Center at George Mason University Scalia Law School, Research Paper Series no. 22-025, November 17, 2022, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3421731.\n19 Sara Lebow, \u201cWorldwide Digital Ad Spend Will Top $600 Billion This Year,\u201d Insider Intelligence, January 31, 2023, https://www.insiderintelligence.com/content/worldwide-digital-ad-spend-will-top-600-billion-this-year.\n20 Brahim Zarouali, Tom Dobber, Guy de Pauw, and Claes de Vreese, \u201cUsing a Personality-Profiling Algorithm to Investigate Political Microtargeting: Assessing the Persuasion Effects of Personality-Tailored Ads on Social Media,\u201d Communication Research 49 (2020): https://journals.sagepub.com/doi/full/10.1177/0093650220961965; see also Bod\u00f3, Helberger, and de Vreese, \u201cPolitical Micro-targeting.\u201d\n21 For example, see Bernstein, \u201cBad News.\u201d\n22 Bod\u00f3, Helberger, and de Vreese, \u201cPolitical Micro-targeting.\u201d Consider Peter J. Danaher, \u201cOptimal Microtargeting of Advertising,\u201d Journal of Marketing Research 60 (2022): https://journals.sagepub.com/doi/full/10.1177/00222437221116034; see also Brian Resnick, \u201cCambridge Analytica\u2019s \u2018Psychographic Microtargeting\u2019: What\u2019s Bullshit and What\u2019s Legit,\u201d Vox, March 26, 2018, https://www.vox.com/science-and-health/2018/3/23/17152564/cambridge-analytica-psychographic-microtargeting-what.\n23 Dobber, Trilling, Helberger, and de Vreese, \u201cEffects of Issue-Based Microtargeting\u201d; and Bod\u00f3, Helberger, and de Vreese, \u201cPolitical Micro-targeting.\u201d\n24 Dobber, Trilling, Helberger, and de Vreese, \u201cEffects of Issue-Based Microtargeting.\u201d\n25 Dobber, Trilling, Helberger, and de Vreese, \u201cEffects of Issue-Based Microtargeting\u201d; see also Resnick, \u201cCambridge Analytica\u2019s \u2018Psychographic Microtargeting.\u2019\u201d\n26 For more on Cambridge Analytica, see Resnick, \u201cCambridge Analytica\u2019s \u2018Psychographic Microtargeting.\u2019\u201d\n27 Zarouali, Dobber, de Pauw, and de Vreese, \u201cUsing a Personality-profiling Algorithm\u201d; and Lennart J. Krotzek, \u201cInside the Voter\u2019s Mind: The Effect of Psychometric Microtargeting on Feelings Toward and Propensity to Vote for a Candidate,\u201d International Journal of Communication 13 (2019): https://ijoc.org/index.php/ijoc/article/view/9605/2742.\n28 Goldberg, Johnson, and Shriver, \u201cRegulating Privacy Online.\u201d\n29 Giorgio Presidente and Carl Benedikt Frey, \u201cThe GDPR Effect: How Data Privacy Regulation Shaped Firm Performance Globally,\u201d VoxEU (blog), Centre for Economic Policy Research, March 10, 2022, https://cepr.org/voxeu/columns/gdpr-effect-how-data-privacy-regulation-shaped-firm-performance-globally; see also Pete Swabey, \u201cGDPR Cost Businesses 8% of Their Profits, According to a New Estimate,\u201d Tech Monitor, March 11, 2022, https://techmonitor.ai/policy/privacy-and-data-protection/gdpr-cost-businesses-8-of-their-profits-according-to-a-new-estimate.\n30 Fredric D. Bellamy, \u201cU.S. Data Privacy Laws to Enter New Era in 2023,\u201d Reuters, January 12, 2023, https://www.reuters.com/legal/legalindustry/us-data-privacy-laws-enter-new-era-2023-2023-01-12; \u201cData Privacy Laws by State: Comparison Charts,\u201d Bloomberg Law, July 11, 2023, https://pro.bloomberglaw.com/brief/privacy-laws-us-vs-eu-gdpr; Jonathan Keane, \u201cFrom California to Brazil: Europe\u2019s Privacy Laws Have Created a Recipe for the World,\u201d CNBC, April 8, 2021, https://www.cnbc.com/2021/04/08/from-california-to-brazil-gdpr-has-created-recipe-for-the-world.html.\n31 Goldberg, Johnson, and Shriver, \u201cRegulating Privacy Online.\u201d\n32 Kahn, Bodoni, and Nicola, \u201cIt\u2019ll Cost Billions\u201d; and Goldberg, Johnson, and Shriver, \u201cRegulating Privacy Online.\u201d\n33 Patience Haggin, Keach Hagey, and Sam Schechner, \u201cApple\u2019s Privacy Change Will Hit Facebook\u2019s Core Ad Business. Here\u2019s How,\u201d Wall Street Journal, January 9, 2021, https://www.wsj.com/articles/apples-privacy-change-will-hit-facebooks-core-ad-business-heres-how-11611938750; and Peter Kafka, \u201cApple Broke Facebook\u2019s Ad Machine. Who\u2019s Going to Fix It?\u201d Vox, February 14, 2022, https://www.vox.com/recode/22929715/facebook-apple-ads-meta-privacy.\n34 See Alan McQuinn and Daniel Castro, \u201cThe Costs of an Unnecessarily Stringent Federal Data Privacy Law,\u201d Information Technology & Innovation Foundation, August 5, 2019, https://itif.org/publications/2019/08/05/costs-unnecessarily-stringent-federal-data-privacy-law.\n35 Kilger, \u201cFederal Data Privacy Law.\u201d\n36 Megan Graham, \u201cAdvertising Market Keeps Growing Much Faster Than Expected, Forecasters Say,\u201d Wall Street Journal, December 6, 2021, https://www.wsj.com/articles/advertising-market-keeps-growing-much-faster-than-expected-forecasters-say-11638784800; and \u201cThe Online-ad Industry Is Being Shaken Up,\u201d Economist, July 28, 2022, https://www.economist.com/business/2022/07/28/the-online-ad-industry-is-being-shaken-up.\n37 Goujard, \u201cEuropean Parliament Votes.\u201d\n37 Goujard, \u201cEuropean Parliament Votes.\u201d\nCase Study 10: Changing Recommendation Algorithms\nKey takeaways:\nAlthough platforms are neither the sole sources of disinformation nor the main causes of political polarization, there is strong evidence that social media algorithms intensify and entrench these off-platform dynamics. Algorithmic changes therefore have the potential to ameliorate the problem; however, this has not been directly studied by independent researchers, and the market viability of such changes is uncertain. Major platforms\u2019 optimizing for something other than engagement would undercut the core business model that enabled them to reach their current size. Users could opt in to healthier algorithms via middleware or civically minded alternative platforms, but most people probably would not. Additionally, algorithms are blunt and opaque tools: using them to curb disinformation would also suppress some legitimate content.\nKey sources:\n- Tarleton Gillespie, \u201cDo Not Recommend? Reduction as a Form of Content Moderation,\u201d Social Media + Society 8 (2022): https://journals.sagepub.com/doi/full/10.1177/20563051221117552.\n- Paul Barrett, Justin Hendrix, and J. Grant Sims, \u201cFueling the Fire: How Social Media Intensifies U.S. Political Polarization \u2014 And What Can Be Done About It,\u201d NYU Stern Center for Business and Human Rights, September 13, 2021, https://bhr.stern.nyu.edu/polarization-report-page?_ga=2.126094349.1087885125.1705371436-402766718.1705371436.\n- Joshua A. Tucker et al., \u201cSocial Media, Political Polarization, and Political Disinformation: A Review of the Scientific Literature,\u201d Hewlett Foundation, March 2018, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3144139.\nDescription and Use Cases\nSocial media companies employ machine learning algorithms to recommend content to users through curated feeds or other delivery mechanisms. A separate set of algorithms is trained to detect undesirable content, which is then penalized by recommendation algorithms (what some scholars refer to as \u201creduction\u201d).1 These two processes work together to shape what individuals see on social media.\nA major concern is that algorithms contribute to the spread of disinformation on social media because they typically reward engaging content.2 The more users are engaged, the more ad and subscription revenue a company can earn\u2014and unfortunately, disinformation tends to be highly engaging. For instance, a landmark 2018 paper in Science found that human users spread false information more quickly than true information.3 Disinformation tends to be not only misleading but also sensationalist, divisive, and laden with negative emotions\u2014seemingly tailor-made for distribution by engagement-seeking algorithms.4 In 2018, internal Facebook research found that the company\u2019s recommendation algorithm promoted emotionally volatile content.5\nPolitical figures and a range of other actors have opportunistically seized on this dynamic. The term \u201cfake news\u201d was popularized during the 2016 U.S. election, when Macedonians and others responded to the financial incentives of this attention economy by generating viral false news stories for U.S. audiences.6 Scholars and journalists have documented how clickbait pages and public relations firms in other countries use similar strategies to drive engagement and revenue.7 Changes to platform algorithms, though difficult to study, could potentially alter financial and political incentives in ways that constrain the spread of disinformation and increase social resilience to it by reducing polarization. Further, by stopping short of outright removal, reduction can preserve greater freedom of speech while still limiting the impact of disinformation.8\nHow Much Do We Know?\nVery few published studies have directly assessed algorithmic adjustments as a counter-disinformation strategy. However, there is a strong circumstantial case\u2014based on related social science, leaked platform research, and theoretical inferences\u2014that platforms\u2019 existing algorithms have amplified disinformation. It is therefore plausible that changes to these same algorithms could ameliorate the problem.\nMore research is needed on the extent to which new algorithmic changes can help to slow, arrest, or reverse cycles of disinformation and polarization that are already deeply rooted in some democracies.9 For example, would an algorithmic reduction in divisive content cause some users to migrate to other, more sensational platforms? The answers may change as the social media marketplace continues to evolve. The U.S. market has been dominated for several years by a handful of companies that publicly (albeit imperfectly) embrace a responsibility to moderate their platforms. But major platforms\u2019 cuts in trust and safety budgets, Twitter\u2019s ownership change, and the rise of numerous alternative platforms suggest this moment may be passing.\nHow Effective Does It Seem?\nTo be sure, platforms are neither the sole sources of disinformation nor \u201cthe original or main cause of rising U.S. political polarization\u201d and similar patterns elsewhere.10 Moreover, what people view on platforms is not just a function of recommendation algorithms. One 2020 study suggested that individuals\u2019 conscious choices to subscribe to YouTube channels or navigate to them via off-site links were a bigger driver of views on extremist videos than algorithmic rabbit holes, for example.11\nNevertheless, there is good reason to believe that social media algorithms intensify and entrench on- and off-platform dynamics which foment disinformation. A 2018 literature review published by the Hewlett Foundation described a self-reinforcing cycle involving social media, traditional media, and political elites.12 It found that when algorithms amplify misleading and divisive content online, political elites and traditional media have greater incentive to generate disinformation and act and communicate in polarizing ways\u2014because the subsequent social media attention can help them earn support and money. In other words, a combination of online and offline dynamics leads to a degradation of the political-informational ecosystem.\nIf curation algorithms help to foment disinformation, then changes to those algorithms could potentially help to ameliorate the problem, or at least lessen platforms\u2019 contributions to it. Such changes could fall into at least two broad categories. First, platforms could expand their use of algorithms to reduce the prevalence of certain kinds of content through detection and demotion or removal. Second, they could train algorithms to recommend content in pursuit of values other than, or in addition to, engagement.13\nWhen algorithms amplify misleading and divisive content online, political elites and traditional media have greater incentive to generate disinformation and act and communicate in polarizing ways.\nFacebook temporarily used the first strategy during the 2020 U.S. election, employing machine learning to demote content more aggressively based on the probability it could incite violence or violate other policies.14 The use of machine learning to assess content in this way is called \u201cclassification.\u201d15 It allows platforms to moderate content at scale more efficiently than human review, but it is far from an exact science. Classifiers differ greatly in their precision, so any enhanced reliance on reduction strategies might require improving classifier reliability. Human-made rules and judgments are also still an important factor in reduction strategies. Platform staff must decide what types of content algorithms should search for and weigh the risks of penalizing permissible speech or permitting harmful content to go unmoderated. What level of reliability and statistical confidence should a classification algorithm demonstrate before its judgments are used to demote content? Should algorithms only demote content that might violate explicit terms of service, or should other concepts, such as journalistic quality, play a role? Answers to these questions have important implications for freedom of speech online. Regardless, stronger use of classifiers to demote sensational content could plausibly reduce the spread of disinformation.\nRecommendation algorithms could also be made to prioritize values, or \u201ccuratorial norms,\u201d other than engagement.16 While the major platforms fixate on maximizing engagement because of their commercial interests, a few smaller platforms design user experiences to promote constructive debate and consensus-building\u2014for example, by requiring users to earn access to features (including private messaging and hosting chat rooms) through good behavior.17 Recommendation algorithms can be used for a similar purpose: a 2023 paper explored how algorithms can \u201cincrease mutual understanding and trust across divides, creating space for productive conflict, deliberation, or cooperation.\u201d18 Similarly, others have advocated for drawing on library sciences to create recommendation algorithms that amplify the spread of authoritative content instead of eye-catching but potentially untrustworthy content.19\nAnother idea is to give users more control over what content they see. Several large platforms now allow users to opt in to a \u201cchronological feed\u201d that lists all followed content in order, with no algorithmic ranking. Others have proposed enabling users to pick their own algorithms. This could be done through middleware, or software that serves as an intermediary between two other applications\u2014in this case, between the user interface and the larger social media platform, allowing users to choose from competing versions of algorithmic recommendation.20 It is difficult to evaluate middleware as a counter-disinformation intervention because it has not been widely implemented. Critics say the recommendation algorithm that many users prefer may well be the most sensationalist and hyperpartisan, not the most measured and constructive.21 Political scientist Francis Fukuyama, perhaps the most prominent advocate for middleware, has said that the goal of middleware is not to mitigate misinformation but to dilute the power of large technology companies in the public square.22\nFinally, it should be noted that some users are unusually motivated to seek out and consume extreme, divisive, and inflammatory content. Scholarship holds that these users represent a small fraction of users overall, but they can have outsized political impact, both online and offline.23 These atypical users will likely find their way to the content they desire\u2014through searches, subscriptions, messages with other users, and other means.24\nHow Easily Does It Scale?\nThe market viability of algorithmic changes is uncertain. Today\u2019s large platforms grew to their current size by combining data collection, targeted advertising, and personalized systems for distributing compelling\u2014if often troublesome\u2014content. Dramatic departures from this model would have unknown business consequences, but analogous changes to user privacy suggest it could be in the tens of billions of dollars. When Apple made it more difficult to serve targeted advertisements on iOS devices, Meta claimed it cost the company $10 billion in annual revenue. Analysts estimated in 2023 that an EU legal ruling requiring Meta to let users opt out of targeted ads could cost the company between 5 and 7 percent of its advertising revenue, which was $118 billion in 2021.25\nIt is also unclear that civically oriented platforms, absent public support or heavy-handed regulation, can compete with social media companies which carefully calibrate their services to maximize engagement. Even some proponents of civically oriented platforms have suggested that these are unlikely to scale as well as today\u2019s largest platforms because they often serve communities with specific needs, such as those seeking anonymity or highly attentive content moderation. Such platforms may lack key features many users desire, like the ability to share photos or reply directly to posts.26 Regulations can help level the playing field: for example, the DSA now requires the biggest platforms to provide EU users with a chronological feed option.27\nFinally, new algorithms intended to reduce disinformation could be just as opaque as today\u2019s algorithms, while also having unintended consequences for online speech. Removing content through takedowns or other means is relatively apparent to the public, but algorithmic reduction requires complex, back-end changes that are more difficult for external analysts to detect or study. Additionally, efforts to curb the spread of sensationalist or emotionally manipulative content could also sap the online creativity that makes the internet a driver of culture and commerce. Using algorithms to reduce disinformation, and only disinformation, may well be impossible.\nNotes\n1 Tarleton Gillespie, \u201cDo Not Recommend? Reduction as a Form of Content Moderation,\u201d Social Media + Society 8 (2022): https://journals.sagepub.com/doi/full/10.1177/20563051221117552.\n2 Mar\u00e9chal and Biddle, \u201cIt\u2019s Not Just the Content.\u201d\n3 Vosoughi, Roy, and Aral, \u201cSpread of True and False News.\u201d\n4 Geoff Nunberg, \u201c\u2018Disinformation\u2019 Is the Word of the Year\u2014and a Sign of What\u2019s to Come,\u201d NPR, December 30, 2019, https://www.npr.org/2019/12/30/790144099/disinformation-is-the-word-of-the-year-and-a-sign-of-what-s-to-come.\n5 Jeff Horwitz and Deepa Seetharaman, \u201cFacebook Executives Shut Down Efforts to Make the Site Less Divisive,\u201d Wall Street Journal, May 26, 2020, https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499; and Loveday Morris, \u201cIn Poland\u2019s Politics, a \u2018Social Civil War\u2019 Brewed as Facebook Rewarded Online Anger,\u201d Washington Post, October 27, 2021, https://www.washingtonpost.com/world/2021/10/27/poland-facebook-algorithm.\n6 Samanth Subramanian, \u201cThe Macedonian Teens Who Mastered Fake News,\u201d Wired, February 15, 2017, https://www.wired.com/2017/02/veles-macedonia-fake-news.\n7 Consider Swati Chaturvedi, I Am a Troll: Inside the Secret World of the BJP\u2019s Digital Army (Juggernaut Books, 2016); and Jonathan Corpus Ong and Jason Vincent A. Caba\u00f1es, \u201cArchitects of Networked Disinformation: Behind the Scenes of Troll Accounts and Fake News Production in the Philippines,\u201d University of Massachusetts Amherst, Communications Department Faculty Publication Series, 2018, https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1075&context=communication_faculty_pubs.\n8 Ren\u00e9e DiResta, \u201cFree Speech Is Not the Same as Free Reach,\u201d Wired, August 30, 2018, https://www.wired.com/story/free-speech-is-not-the-same-as-free-reach.\n9 Jennifer McCoy, Benjamin Press, Murat Somer, and Ozlem Tuncel, \u201cReducing Pernicious Polarization: A Comparative Historical Analysis of Depolarization,\u201d Carnegie Endowment for International Peace, May 5, 2022, https://carnegieendowment.org/2022/05/05/reducing-pernicious-polarization-comparative-historical-analysis-of-depolarization-pub-87034.\n10 A review by New York University\u2019s Stern Center for Business and Human Rights found that while \u201cFacebook, Twitter, and YouTube are not the original or main cause of rising U.S. political polarization . . . use of those platforms intensifies divisiveness and thus contributes to its corrosive consequences.\u201d While observers sometimes attribute increased polarization to social media echo chambers, scholars note that most users see a diverse range of news sources. In fact, online heterogeneity might be related to increased polarization: one study based on Twitter data suggests that \u201cit is not isolation from opposing views that drives polarization but precisely the fact that digital media\u201d collapses the cross-cutting conflicts that occur in local interactions, thereby hardening partisan identities and deepening division. (Other, non-digital sources of national news are believed to promote similar dynamics.) And the evidence is not all in one direction: in a study on Bosnia and Herzegovina, abstinence from Facebook use was associated with lower regard for ethnic outgroups, suggesting Facebook could have a depolarizing effect on users. See Paul Barrett, Justin Hendrix, and J. Grant Sims, \u201cFueling the Fire: How Social Media Intensifies U.S. Political Polarization \u2014 And What Can Be Done About It,\u201d NYU Stern Center for Business and Human Rights, September 13, 2021, https://bhr.stern.nyu.edu/polarization-report-page?_ga=2.126094349.1087885125.1705371436-402766718.1705371436; Andrew Guess, Brendan Nyhan, Benjamin Lyons, and Jason Reifler, \u201cAvoiding the Echo Chamber About Echo Chambers,\u201d Knight Foundation, 2018, https://kf-site-production.s3.amazonaws.com/media_elements/files/000/000/133/original/Topos_KF_White-Paper_Nyhan_V1.pdf; Petter T\u00f6rnberg, \u201cHow Digital Media Drive Affective Polarization Through Partisan Sorting,\u201d PNAS 119 (2022): https://www.pnas.org/doi/10.1073/pnas.2207159119; Darr, Hitt, and Dunaway, \u201cNewspaper Closures Polarize\u201d; and Nejla A\u0161imovi\u0107, Jonathan Nagler, Richard Bonneau, and Joshua A. Tucker, \u201cTesting the Effects of Facebook Usage in an Ethnically Polarized Setting,\u201d PNAS 118 (2021): https://www.pnas.org/doi/10.1073/pnas.2022819118.\n11 Annie Y. Chen, Brendan Nyhan, Jason Reifler, Ronald E. Robertson, and Christo Wilson, \u201cSubscriptions and External Links Help Drive Resentful Users to Alternative and Extremist YouTube Videos,\u201d Science Advances 9 (2023): https://www.science.org/doi/10.1126/sciadv.add8080.\n12 As discussed in case study 1, polarization and its effect on spreading disinformation is not symmetrical across the political spectrum. In most (but not all) political contexts, the right side of the political spectrum has moved further from the mainstream both ideologically and in its media diet, creating more appetite for partisan disinformation. See Joshua A. Tucker et al., \u201cSocial Media, Political Polarization, and Political Disinformation: A Review of the Scientific Literature,\u201d Hewlett Foundation, March 2018, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3144139.\n13 Meta refers to \u201cprevalence\u201d of content on its platform as a measure of how many users see a specific piece of content, a metric which \u201cassumes that the impact caused by violating content is proportional to the number of times that content is viewed.\u201d See \u201cPrevalence,\u201d Meta, November 18, 2022, https://transparency.fb.com/policies/improving/prevalence-metric.\nSome companies may contest that \u201cengagement\u201d is the primary motive behind platform algorithms, or they may point to certain forms of engagement as positive for society and therefore an acceptable optimization goal for curation algorithms. Meta, for instance, says that it promotes \u201cmeaningful interactions\u201d between users instead of mere clicks. Engagement is used here as a shorthand for the broad goal of motivating users to continue using a service, especially for longer periods of time. See Adam Mosseri, \u201cNews Feed FYI: Bringing People Closer Together,\u201d Meta, January 11, 2018, https://www.facebook.com/business/news/news-feed-fyi-bringing-people-closer-together.\n14 Shannon Bond and Bobby Allyn, \u201cHow the \u2018Stop the Steal\u2019 Movement Outwitted Facebook Ahead of the Jan. 6 Insurrection,\u201d NPR, October 22, 2021, https://www.npr.org/2021/10/22/1048543513/facebook-groups-jan-6-insurrection.\n15 Robert Gorwa, Reuben Binns, and Christian Katzenbach, \u201cAlgorithmic Content Moderation: Technical and Political Challenges in the Automation of Platform Governance,\u201d Big Data & Society 7 (2020): https://journals.sagepub.com/doi/10.1177/2053951719897945.\n16 Ren\u00e9e DiResta, \u201cUp Next: A Better Recommendation System,\u201d Wired, April 11, 2018, https://www.wired.com/story/creating-ethical-recommendation-engines.\n17 Chand Rajendra-Nicolucci and Ethan Zuckerman, \u201cAn Illustrated Field Guide to Social Media,\u201d Knight First Amendment Institute, May 14, 2021, https://knightcolumbia.org/blog/an-illustrated-field-guide-to-social-media.\n18 Aviv Ovadya and Luke Thorburn, \u201cBridging Systems: Open Problems for Countering Destructive Divisiveness Across Ranking, Recommenders, and Governance?,\u201d Knight First Amendment Institute, October 26, 2023, https://knightcolumbia.org/content/bridging-systems.\n19 Joan Donovan, \u201cShhhh... Combating the Cacophony of Content with Librarians,\u201d National Endowment for Democracy, January 2021, https://www.ned.org/wp-content/uploads/2021/01/Combating-Cacophony-Content-Librarians-Donovan.pdf.\n20 See Francis Fukuyama, Barak Richman, and Ashish Goel, \u201cHow to Save Democracy from Technology: Ending Big Tech\u2019s Information Monopoly,\u201d Foreign Affairs, November 24, 2020, https://www.foreignaffairs.com/articles/united-states/2020-11-24/fukuyama-how-save-democracy-technology; and Francis Fukuyama, Barak Richman, Ashish Goel, Roberta R. Katz, A. Douglas Melamed, and Marietje Schaake, \u201cMiddleware for Dominant Digital Platforms: A Technological Solution to a Threat to Democracy,\u201d Stanford Cyber Policy Center, accessed March 13, 2023, https://fsi-live.s3.us-west-1.amazonaws.com/s3fs-public/cpc-middleware_ff_v2.pdf.\n21 See \u201cThe Future of Platform Power,\u201d various authors, Journal of Democracy 32 (2021): https://www.journalofdemocracy.org/issue/july-2021/.\n22 Katharine Miller, \u201cRadical Proposal: Middleware Could Give Consumers Choices Over What They See Online,\u201d Stanford University Human-Centered Artificial Intelligence, October 20, 2021, https://hai.stanford.edu/news/radical-proposal-middleware-could-give-consumers-choices-over-what-they-see-online.\n23 Consider, for example, Ronald E. Robertson, \u201cUncommon Yet Consequential Online Harms,\u201d Journal of Online Trust & Safety 1 (2022): https://tsjournal.org/index.php/jots/article/view/87.\n24 Ronald E. Robertson et al., \u201cUsers Choose to Engage With More Partisan News than They Are Exposed to on Google Search,\u201d Nature 618 (2022): https://www.nature.com/articles/s41586-023-06078-5.\n25 Adam Satariano, \u201cMeta\u2019s Ad Practices Ruled Illegal Under E.U. Law,\u201d New York Times, January 4, 2023, https://www.nytimes.com/2023/01/04/technology/meta-facebook-eu-gdpr.html.\n26 Rajendra-Nicolucci and Zuckerman, \u201cIllustrated Field Guide.\u201d\n27 Natasha Lomas, \u201cAll Hail the New EU Law That Lets Social Media Users Quiet Quit the Algorithm,\u201d TechCrunch, August 25, 2023, https://techcrunch.com/2023/08/25/quiet-qutting-ai.\nLooking Ahead: Generative AI\nDuring the course of this research project, rapid advances in generative AI\u2014which can create new content\u2014have led to heated speculation about the future disinformation landscape. AI experts, commentators, and politicians have predicted that generative AI will dramatically worsen the disinformation problem. Many disinformation experts have been more circumspect, but some are also worried. It is too soon to make strong predictions, and this report has primarily focused on assessing countermeasures rather than handicapping emergent threats. Still, some initial possibilities can be laid out, drawing on relevant parallels from this report\u2019s case studies and a review of disinformation research.\nGenerative AI algorithms, developed with machine learning techniques, can be used to produce a wide variety of text, images, video, and audio. Some results are strikingly similar to authentic, human-produced media\u2014though, at least for now, close observation can often reveal odd artifacts and incongruities. Generative algorithms can facilitate disinformation in countless ways.1 Deepfake videos and audio clips have been used to simulate specific individuals saying and doing things they never did, allowing perpetrators to defame or degrade their targets. AI-generated photos of nonexistent people have been incorporated into fake social media profiles to bolster their apparent authenticity. Synthetic text generation can automate the mass production of written propaganda, fraudulent documents, or online conversation in many languages and genres. Additionally, it\u2019s becoming easier to combine multiple generative AI techniques\u2014for example, automating the writing of a film script that is then acted out on video by a lifelike synthetic avatar.\nAs these examples illustrate, generative AI has several concerning qualities relevant to disinformation. It can enable the rapid, low-cost production of false or misleading content. It can lower the barriers to entry for creating such content\u2014for example, obviating the need for subject matter knowledge, charisma, or skills in video production, photo editing, and translation. AI-generated content can also be more realistic than what its creators could otherwise produce. Additionally, there is worry that algorithms will enable the production of tailor-made content that targets a specific audience by using personal information to predict what will resonate. Finally, generative AI can quickly reformulate preexisting content\u2014be it a terrorist\u2019s manifesto or malicious computer code\u2014in ways that may stymie detection and response.\nBut the theoretical dangers of new technology do not always manifest as initially feared. Deepfakes, for example, have generated much consternation since 2017, yet they\u2019ve had hardly any political impact so far. To be sure, deepfake-driven nonconsensual pornography is a real problem, and deepfakes are occasionally used to commit fraud. Moreover, technological improvements may make deepfakes harder to spot in the future. Still, it is noteworthy that the most dreaded type of deepfakes\u2014mass political disinformation\u2014has rarely been attempted and has largely failed. Two recent prominent examples were videos of Ukrainian President Volodymyr Zelenskyy and Russian President Vladimir Putin disseminated in their respective countries during the war. Each was carefully orchestrated and timed for maximum political effect.2 They were even broadcast on TV news networks that had been compromised by hackers, enhancing the verisimilitude. Yet neither video seemed to have real persuasive power, perhaps because the target audiences placed greater trust in the national authorities who debunked them. For now, bad actors seem to recognize that cruder techniques\u2014including so-called cheapfakes that employ traditional video manipulation or involve simply relabeling an old photo to change its apparent meaning\u2014remain easier and adequately effective.\nThe limited impact of political deepfakes so far is consistent with research on disinformation generally and has implications for other kinds of generative AI. Studies suggest that people\u2019s willingness to believe false (or true) information is often not primarily driven by the content\u2019s level of realism. Rather, other factors such as repetition, narrative appeal, perceived authority, group identification, and the viewer\u2019s state of mind can matter more. This has relevance for emergent policy efforts to counter AI-generated disinformation. For example, the Coalition for Content Provenance and Authenticity offers a digital \u201csigning authority\u201d that certifies the source of content and allows end users to verify its authenticity.3 Ultimately, though, such badges of truth depend on people choosing to trust and value them. Many forms of disinformation thrive today because their believers choose to discount existing sources of high-quality information\u2014such as rigorous professional journalism, enduring scientific consensus, and transparent independent investigations.\nPeople\u2019s willingness to believe false (or true) information is often not primarily driven by the content\u2019s level of realism.\nThe prediction that personalized AI content will enable extremely persuasive disinformation should also be treated with caution. Personalized persuasion is already an enormous industry: commercial and political advertisers spend hundreds of billions of dollars each year trying to reach audiences with content tailor-made for specific demographics, interests, and temperaments. Yet studies of microtargeting have been less than impressive, casting doubt on the notion that data-driven personalization is uniquely compelling. Perhaps generative AI will invent entirely new forms of microtargeting that are much more compelling than anything humans have come up with. But humans have already deployed similar tools\u2014such as big data, applied statistics, and previous forms of AI\u2014for years without any apparent revolutionary breakthroughs in the science of persuasion. As this report\u2019s case studies show, persuasive content\u2014however personalized\u2014must still compete with the cacophony of other influences on targets. Someone\u2019s beliefs are often shaped by a lifetime of narrative and psychological commitments, which are not easily dislodged.\nFinally, generative AI is a double-edged sword: it can be used to counter disinformation as well as foment it. Generative AI products like ChatGPT are marketed as general-use tools for information discovery, categorization, and reasoning. If that promise holds, then counter-disinformation practitioners can use generative AI to improve their overall productivity in countless ways. For example, future AI tools\u2014if responsibly used, supervised, and verified by humans\u2014may help fact-checkers more quickly triage and categorize claims, find relevant truthful information, and compare the former with the latter. Such tools could also facilitate the expanded use of social media labels\u2014working in tandem with humans to support faster judgments on source quality, which could then enable platforms to add more decisive labels to more content. AI has obvious applications for cybersecurity and is already a standard feature of many products and services. Algorithms also help social media companies\u2014which possess world-class AI capabilities\u2014identify inauthentic asset networks.4 While content curation algorithms are notorious for contributing to the spread of disinformation, the same engineering principles can be used to design more responsible algorithms. In short, generative AI and other machine learning technologies can be applied to many of the countermeasures explored in this report. In several cases, AI offers promising opportunities to address important cost and scaling challenges.\nIt is impossible to know the long-term impacts of generative AI. Like other new technologies, it will be employed by all sides of the information contest. If generative AI lives up to its current hype, it could mark the latest in a long series of what Carnegie\u2019s Alicia Wanless calls \u201cinformation disturbances\u201d\u2014historical developments that alter the information ecosystem, touching off a chaotic cycle of reaction and counterreaction which unsettles, at least for a time, whatever balance existed before.5 Future historians may debate whether the rise of generative AI turned out to be uniquely disturbing, or just another continuation of a long digital revolution.\nRegardless, the metaphor of an \u201cinformation ecosystem\u201d has a larger lesson for policymakers. The flow of information through society is extraordinarily complex, much like the many forms of competition and cooperation found in the natural world. People\u2019s beliefs, expressions, and actions are shaped by countless psychosocial factors that interact in still mysterious ways. Such factors are rarely, if ever, reducible to any single technology.\nPolicymakers concerned about disinformation should embrace complexity and acknowledge uncertainty. The effort to counter disinformation will be a long journey through a dark thicket, with many wrong turns and pitfalls along the way. Yet democracies have no choice but to undertake this difficult journey\u2014hopefully guided by the light of evidence, no matter how dim this light may be.\nNotes\n1 See, for example, Jon Bateman, \u201cDeepfakes and Synthetic Media in the Financial System: Assessing Threat Scenarios,\u201d Carnegie Endowment for International Peace, July 8, 2020, https://carnegieendowment.org/2020/07/08/deepfakes-and-synthetic-media-in-financial-system-assessing-threat-scenarios-pub-82237.\n2 Jane Wakefield, \u201cDeepfake Presidents Used in Russia-Ukraine War,\u201d BBC, March 18, 2022, https://www.bbc.com/news/technology-60780142.\n3 \u201cC2PA Explainer,\u201d Coalition for Content Provenance and Authenticity, accessed March 13, 2023, https://c2pa.org/specifications/specifications/1.0/explainer/Explainer.html.\n4 Karen Hao, \u201cHow Facebook Uses Machine Learning to Detect Fake Accounts,\u201d MIT Technology Review, March 4, 2020, https://www.technologyreview.com/2020/03/04/905551/how-facebook-uses-machine-learning-to-detect-fake-accounts.\n5 Alicia Wanless, \u201cThere Is No Getting Ahead of Disinformation Without Moving Past It,\u201d Lawfare, May 8, 2023, https://www.lawfaremedia.org/article/there-is-no-getting-ahead-of-disinformation-without-moving-past-it; and Alicia Wanless, \u201cInformation Ecology: Using Physical Ecology to Understand Information Struggle,\u201d King\u2019s College London, forthcoming, abstract accessed on December 11, 2023, https://www.kcl.ac.uk/people/alicia-wanless."
    }
  ],
  "argos_summary": "The rise of AI-powered narrative attacks, or misinformation campaigns, poses significant risks to businesses, brands, and individuals, as they can manipulate perceptions and spread falsehoods rapidly across social media. Experts emphasize the importance of media literacy and provide strategies to identify and counter these attacks, including verifying sources, using fact-checking tools, and fostering critical thinking. Additionally, organizations are encouraged to implement proactive measures, such as zero-trust architectures and employee training, to mitigate the risks associated with AI-driven cyber threats.",
  "argos_id": "XTTGCRPN9"
}