{
  "url": "https://www.fastcompany.com/91389307/how-to-use-failure-to-your-advantage",
  "authorsByline": "Cindy Cavoto",
  "articleId": "615f79fec6994dd3a7b5f2ccd41a1f7b",
  "source": {
    "domain": "fastcompany.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://images.fastcompany.com/image/upload/f_webp,q_auto,c_fit,w_1024,h_1024/wp-cms-2/2025/08/p-91389307-how-to-use-failure-to-your-advantage.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-28T06:00:00+00:00",
  "addDate": "2025-08-28T06:18:59.931028+00:00",
  "refreshDate": "2025-08-28T06:18:59.931029+00:00",
  "score": 1.0,
  "title": "How to use failure to your advantage",
  "description": "Research shows failing 15% of the time is optimal for growth. Here's how to make sure you're making the most of your failures.",
  "content": "Research from Headway\u2014the leading book summary app\u2014shows that 11% of people have already abandoned their 2025 goals, and 33% are close to giving up. For many, the fear of failing that stands in the way of self-improvement. In my work as a productivity coach, I\u2019ve come to see why. We\u2019re hardwired to link failure with finality, which fuels self-doubt and causes motivation to fizzle out. Yet, failure is just another stepping stone on the path to success. So if you hit a bump, don\u2019t take it as a sign to give up; take it as an opportunity to learn, adjust, and go again. If you\u2019re succeeding 100% of the time, you\u2019re not pushing yourself. As a productivity coach, it\u2019s something I see clients do regularly, but I constantly remind them that you don\u2019t grow by playing it safe\u2014you grow by stretching, stumbling, and staying with it.\n\nThat means taking on challenges that stretch you to your limits, and sometimes beyond them. Sure, you won\u2019t always hit the mark, but each miss offers valuable insight into what works, what doesn\u2019t, and where you need to improve. In fact, studies show that failing 15% of the time is optimal for learning. Enroll in a class you know you\u2019ll struggle with, ask for constructive criticism, and put yourself in situations that make you feel a little uneasy. This is where the magic starts. When I work with high-achieving women, we often create a \u201cdiscomfort challenge\u201d\u2014one small stretch per week. Why? Because the goal isn\u2019t to master everything overnight, but to get comfortable feeling uncomfortable. Over time, these lessons make you more confident and capable. With each failure, your limit increases and you take a step toward achieving your full potential.\n\nIt\u2019s natural to feel discouraged when things don\u2019t go to plan, but one setback doesn\u2019t put success out of reach. Every failure gives you a clearer sense of what works and what doesn\u2019t, making you better prepared for your next attempt. Bill Gates\u2019s first venture, Traf-O-Data, failed. And Steve Jobs isn\u2019t remembered for the Apple Lisa\u2014a costly flop\u2014but as the creator of the revolutionary iPhone. Failure doesn\u2019t mean it\u2019s over; it means you\u2019re in it. As I often remind my clients, \u201cIt\u2019s not failing that stops you\u2014It\u2019s quitting too soon.\u201d Stick with the hard part. It\u2019s usually the bridge to your breakthrough.\n\nAnd when you finally succeed? Well, it tastes even sweeter when you\u2019ve fought for it, gained the battle scars, and refused to let failure define you. So often, my clients want to wipe the slate clean after a tough outcome. But hitting reset is rarely the answer. Instead, run a postmortem: Where exactly did it go wrong? Comb through the experience, note what worked, and use that as a launching pad. Often, you will find that the problem is small and easier to overcome than you initially thought. At the very least, there will be positives\u2014whether lessons, strategies, or resources\u2014that you can reuse in your next attempt. There\u2019s always treasure among the rubble if you take the time to look.\n\nTake Traf-O-Data, for example. The company didn\u2019t survive, but it gave Gates and Allen invaluable practice in writing software, building hardware, and pitching to customers. Those lessons directly shaped their approach to the Altair 8800 project\u2014the launchpad that eventually became Microsoft. Picking yourself up and trying again is never easy, but having an existing foundation in place makes it far easier to motivate yourself. Failure is only a negative if you learn nothing from it, so document every flop and failure, and note exactly what each one taught you and where it went wrong. This doesn\u2019t serve as a list of your losses, but as a blueprint for making progress.\n\nYou\u2019re essentially turning your setbacks into a data source, and you will quickly begin to see patterns emerging. Do you typically lose motivation midway through a project? Do you frequently fail to plan and inevitably run into problems you didn\u2019t foresee? Or do you lack a skill that\u2019s constantly preventing you from moving forward? With this insight, you can not only correct individual mistakes but also question the underlying assumptions, habits, and behaviors that consistently hold you back\u2014a concept known as double-loop learning, which is linked to sharper thinking, superior decision-making, and innovative problem-solving. I also encourage every client to keep a \u201clessons learned\u201d doc\u2014not to track tasks but transformation, and not to dwell on mistakes but to honor growth. It serves as a powerful reminder of how far you\u2019ve come and how many times you\u2019ve already gotten up, brushed off, and overcome a challenge.",
  "medium": "Article",
  "links": [
    "https://www.mansueto.com/privacy-policy/",
    "https://www.fastcompany.com/newsletters",
    "https://www.fastcompany.com/section/productivity",
    "https://www.latimes.com/health/la-he-scared-20151031-story.html",
    "https://maxlearn-microlearning.medium.com/single-vs-double-loop-learning-why-your-organization-needs-both-for-sustainable-success-5a6243090fed",
    "https://makeheadway.com/blog/new-year-resolutions-study/",
    "https://www.nature.com/articles/s41467-019-12552-4",
    "https://www.fastcompany.com/apply/most-innovative-companies",
    "https://www.business.com/articles/never-giving-up-9-entrepreneurs-and-millionaires-who-failed-at-least-once/",
    "https://www.fastcompany.com/91382022/how-to-make-progress-when-youre-in-a-slump"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Failure",
      "weight": 0.06367121
    },
    {
      "name": "failure",
      "weight": 0.06367121
    },
    {
      "name": "time",
      "weight": 0.05231565
    },
    {
      "name": "individual mistakes",
      "weight": 0.046786707
    },
    {
      "name": "clients",
      "weight": 0.045196705
    },
    {
      "name": "valuable insight",
      "weight": 0.04459514
    },
    {
      "name": "small stretch",
      "weight": 0.044555582
    },
    {
      "name": "problems",
      "weight": 0.042268127
    },
    {
      "name": "invaluable practice",
      "weight": 0.041314173
    },
    {
      "name": "sharper thinking",
      "weight": 0.040699057
    }
  ],
  "topics": [],
  "categories": [],
  "taxonomies": [
    {
      "name": "/Reference/General Reference/How-To, DIY & Expert Content",
      "score": 0.8115234375
    },
    {
      "name": "/People & Society/Self-Help & Motivational",
      "score": 0.7294921875
    },
    {
      "name": "/Jobs & Education/Jobs/Career Resources & Planning",
      "score": 0.405029296875
    }
  ],
  "sentiment": {
    "positive": 0.059990298,
    "negative": 0.69159955,
    "neutral": 0.24841017
  },
  "summary": "Research from Headway, the leading book summary app, has revealed that 11% of people have already abandoned their 2025 goals and 33% are close to giving up due to fear of self-improvement. Productivity coach, Dr. Kelly Obeidallah, suggests that failure is just another step on the path to success and that it offers valuable insight into what works, what doesn't, and where you need to improve. She suggests that failing 15% of the time is optimal for learning, and that learning can increase confidence and extend beyond the limits of the self-imposed limits of a certain project. ObeIDallah also suggests that every failure gives you a clearer sense of what works and doesn't and can be used as a launching pad for future endeavors.",
  "shortSummary": "Failure can be used as a catalyst for self-improvement, learning, and eventually becoming a crucial component for success.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "45c3a850f5154df7bf5277c8967558e6",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.nature.com/articles/s41467-019-12552-4",
      "text": "Abstract\nResearchers and educators have long wrestled with the question of how best to teach their clients be they humans, non-human animals or machines. Here, we examine the role of a single variable, the difficulty of training, on the rate of learning. In many situations we find that there is a sweet spot in which training is neither too easy nor too hard, and where learning progresses most quickly. We derive conditions for this sweet spot for a broad class of learning algorithms in the context of binary classification tasks. For all of these stochastic gradient-descent based learning algorithms, we find that the optimal error rate for training is around 15.87% or, conversely, that the optimal training accuracy is about 85%. We demonstrate the efficacy of this \u2018Eighty Five Percent Rule\u2019 for artificial neural networks used in AI and biologically plausible neural networks thought to describe animal learning.\nSimilar content being viewed by others\nIntroduction\nWhen we learn something new, like a language or musical instrument, we often seek challenges at the edge of our competence\u2014not so hard that we are discouraged, but not so easy that we get bored. This simple intuition, that there is a sweet spot of difficulty, a \u2018Goldilocks zone\u20191, for motivation and learning is at the heart of modern teaching methods2 and is thought to account for differences in infant attention between more and less learnable stimuli1. In the animal learning literature it is the intuition behind shaping3 and fading4, whereby complex tasks are taught by steadily increasing the difficulty of a training task. It is also observable in the nearly universal \u2018levels\u2019 feature in video games, in which the player is encouraged, or even forced, to a higher level of difficulty once a performance criterion has been achieved. Similarly in machine learning, steadily increasing the difficulty of training has proven useful for teaching large scale neural networks in a variety of tasks5,6, where it is known as \u2018Curriculum Learning\u20197 and \u2018Self-Paced Learning\u20198.\nDespite this long history of empirical results, it is unclear why a particular difficulty level may be beneficial for learning nor what that optimal level might be. In this paper we address this issue of optimal training difficulty for a broad class of learning algorithms in the context of binary classification tasks, in which ambiguous stimuli must be classified into one of two classes (e.g., cat or dog).\nIn particular, we focus on the class of stochastic gradient-descent based learning algorithms. In these algorithms, parameters of the model (e.g., the weights in a neural network) are adjusted based on feedback in such a way as to reduce the average error rate over time9. That is, these algorithms descend the gradient of error rate as a function of model parameters. Such gradient-descent learning forms the basis of many algorithms in AI, from single-layer perceptrons to deep neural networks10, and provides a quantitative description of human and animal learning in a variety of situations, from perception11, to motor control12 to reinforcement learning13. For these algorithms, we provide a general result for the optimal difficulty in terms of a target error rate for training. Under the assumption of a Gaussian noise process underlying the errors, this optimal error rate is around 15.87%, a number that varies slightly depending on the noise in the learning process. That is the optimal accuracy for training is around 85%. We show theoretically that training at this optimal difficulty can lead to exponential improvements in the rate of learning. Finally, we demonstrate the applicability of the Eighty Five Percent Rule to artificial one- and two-layer neural networks9,14, and a model from computational neuroscience that is thought to describe human and animal perceptual learning11.\nResults\nOptimal training difficulty for binary classification tasks\nIn a standard binary classification task, an animal or machine \u2018agent\u2019 makes binary decisions about simple stimuli. For example, in the classic Random Dot Motion paradigm from Psychology and Neuroscience15,16, stimuli consist of a patch of moving dots\u2014most moving randomly but a small fraction moving coherently either to the left or the right\u2014and participants must decide in which direction the coherent dots are moving. A major factor in determining the difficulty of this perceptual decision is the fraction of coherently moving dots, which can be manipulated by the experimenter to achieve a fixed error rate during training using a procedure known as \u2018staircasing\u201917.\nWe assume that agents make their decision on the basis of a scalar, subjective decision variable, h, which is computed from a stimulus that can be represented as a vector x (e.g., the direction of motion of all dots)\nwhere \u03a6(\u22c5) is a function of the stimulus and (tunable) parameters \u03d5. We assume that this transformation of stimulus x into the subjective decision variable h yields a noisy representation of the true decision variable, \u0394 (e.g., the fraction of dots moving left). That is, we write\nwhere the noise, n, arises due to the imperfect representation of the decision variable. We further assume that this noise, n, is random and sampled from a zero-mean Gaussian distribution with standard deviation \u03c3 (Fig. 1a).\nIf the decision boundary is set to 0, such that the model chooses option A when h > 0, option B when h < 0 and randomly when h = 0, then the noise in the representation of the decision variable leads to errors with probability\nwhere F(x) is the cumulative density function of the standardized noise distribution, p(x) = p(x|0, 1), and \u03b2 = 1/\u03c3 quantifies the precision of the representation of \u0394 and the agent\u2019s skill at the task. As shown in Fig. 1b, this error rate decreases as the decision gets easier (\u0394 increases) and as the agent becomes more accomplished at the task (\u03b2 increases).\nThe goal of learning is to tune the parameters \u03d5 such that the subjective decision variable, h, is a better reflection of the true decision variable, \u0394. That is, the model should aim to adjust the parameters \u03d5 so as to decrease the magnitude of the noise \u03c3 or, equivalently, increase the precision \u03b2. One way to achieve this tuning is to adjust the parameters using gradient descent on the error rate, i.e. changing the parameters over time t according to\nwhere \u03b7 is the learning rate and \u2207\u03d5ER is the derivative of the error rate with respect to parameters \u03d5. This gradient can be written in terms of the precision, \u03b2, as\nNote here that only the first term on the right hand side of Eq. (5) depends on the difficulty \u0394, while the second describes how the precision changes with \u03d5. Note also that \u0394 itself, as the \u2018true\u2019 decision variable, is independent of \u03d5. This means that the optimal difficulty for training, that maximizes the change in the parameters, \u03d5, at this time point, is the value of the decision variable \u0394* that maximizes \u2202ER/\u2202\u03b2. Of course, this analysis ignores the effect of changing \u03d5 on the form of the noise\u2014instead assuming that it only changes the scale factor, \u03b2, an assumption that likely holds in the relatively simple cases we consider here, although whether it holds in more complex cases will be an important question for future work.\nIn terms of the decision variable, the optimal difficulty changes as a function of precision (Fig. 1c) meaning that the difficulty of training must be adjusted online according to the skill of the agent. Using the monotonic relationship between \u0394 and ER (Fig. 1b) it is possible to express the optimal difficulty in terms of the error rate, ER* (Fig. 1d). Expressed this way, the optimal difficulty is constant as a function of precision, meaning that optimal learning can be achieved by clamping the error rate during training at a fixed value, which, for Gaussian noise is\nThat is, the optimal error rate for learning is 15.87%, and the optimal accuracy is around 85%. We call this the Eighty Five Percent Rule for optimal learning.\nDynamics of learning\nWhile the previous analysis allows us to calculate the error rate that maximizes the rate of learning, it does not tell us how much faster learning occurs at this optimal error rate. In this section we address this question by comparing learning at the optimal error rate with learning at a fixed error rate, ERf (which may be suboptimal), and, alternatively, a fixed difficulty, \u0394f. If stimuli are presented one at a time (i.e., not batch learning), in both cases, gradient-descent based updating of the parameters, \u03d5, (Eq. (4)) implies that the precision \u03b2 evolves in a similar manner, i.e..\nFor fixed error rate, ERf, as shown in the Methods, integrating Eq. (7) gives\nwhere t0 is the initial time point, \u03b20 is the initial value of \u03b2 and Kf is the following function of the training error rate\nThus, for fixed training error rate the precision grows as the square root of time with the exact rate determined by Kf which depends on both the training error rate and the noise distribution.\nFor fixed decision variable, \u0394f, integrating Eq. (7) is more difficult and the solution depends more strongly on the distribution of the noise. In the case of Gaussian noise, there is no closed form solution for \u03b2. However, as shown in the Methods, an approximate form can be derived at long times where we find that \u03b2 grows as\ni.e., exponentially slower than Eq. (38).\nSimulations\nTo demonstrate the applicability of the Eighty Five Percent Rule we simulated the effect of training accuracy on learning in three cases, two from AI and one from computational neuroscience. From AI we consider how training at 85% accuracy impacts learning in the the simple case of a one-layer Perceptron14 with artificial stimuli, and in the more complex case of a two-layer neural network9 with stimuli drawn from the MNIST (Modified National Institute of Standards and Technology) dataset of handwritten digits18. From computational neuroscience we consider the model of Law and Gold11, that accounts for both the behavior and neural firing properties of monkeys learning the Random Dot Motion task. In all cases we see that learning is maximized when training occurs at 85% accuracy.\nPerceptron with artificial stimuli\nThe Perceptron is a classic one-layer neural network model that learns to map multidimensional stimuli x onto binary labels, y via a linear threshold process14. To implement this mapping, the Perceptron first computes the decision variable h as\nwhere w are the weights of the network, and then assigns the label according to\nThe weights, w, which constitute the parameters of the model, are updated based on feedback about the true label t by a the learning rule,\nThis learning rule implies that the Perceptron only updates its weights when the predicted label y does not match the actual label t\u2014that is, the Perceptron only learns when it makes mistakes. Naively then, one might expect that optimal learning would involve maximizing the error rate. However, because Eq. (13) is closely related (albeit not identical) to a gradient descent based rule (e.g., Chapter 39 in ref. 19), the analysis of the previous sections applies and the optimal error rate for training is 15.87%.\nTo test this prediction we simulated the Perceptron learning rule for a range of training error rates between 0.01 and 0.5 in steps of 0.01 (1000 simulations per error rate, 1000 trials per simulation). Error rate was kept constant by varying the difficulty, and the degree of learning was captured by the precision \u03b2 (see Methods). As predicted by the theory, the network learns most effectively when trained at the optimal error rate (Fig. 2a) and the dynamics of learning are well described, up to a scale factor, by Eq. (38) (Fig. 2b).\nTwo-layer network with MNIST stimuli\nAs a more demanding test of the Eighty Five Percent Rule, we consider the case of a two-layer neural network applied to more realistic stimuli from the Modified National Institute of Standards and Technology (MNIST) dataset of handwritten digits18. The MNIST dataset is a labeled dataset of 70,000 images of handwritten digits (0 through 9) that has been widely used as a test of image classification algorithms (see ref. 20 for a list). The dataset is broken down into a training set consistent of 60,000 images and a test set of 10,000 images. To create binary classification tasks based on these images, we trained the network to classify the images according to either the parity (odd or even) or magnitude (less than 5 or not) of the number.\nThe network itself consisted of 1 input layer, with 400 units corresponding to the pixel values in the images, 1 hidden layer, with 50 neurons, and one output unit. Unlike the Perceptron, activity of the output unit was graded and was determined by a sigmoid function of the decision variable, h\nwhere the decision variable was given by\nwhere w2 were the weights connecting the hidden layer to the output units and a was the activity in the hidden layer. This hidden-layer activity was also determined by a sigmoidal function\nwhere the inputs, x, corresponds to the pixel values in the image and w1 were the weights from the input layer to the hidden layer.\nAll weights were trained using the Backpropagation algorithm9 which takes the error,\nand propagates it backwards through the network, from output to input stage, as a teaching signal for the weights. This algorithm implements stochastic gradient descent and, if our assumptions are met, should optimize learning at a training accuracy of 85%.\nTo test this prediction we trained the two-layer network for 5000 trials to perform either the Parity or the Magnitude Task while clamping the training error rate between 5 and 30% (Fig. 3). After training, performance was assessed on the entire test set and the whole process was repeated 1000 times for each task. As shown in Fig. 3, training error rate has a relatively large effect on test accuracy, around 10% between the best and worse training accuracies. Moreover, for both tasks, the optimal training occurs at 85% training accuracy. This suggests that the 85% rule holds even for learning of more realistic stimuli, by more complex multi-layered networks.\nBiologically plausible model of perceptual learning\nTo demonstrate how the Eighty Five Percent Rule might apply to learning in biological systems, we simulated the Law and Gold model of perceptual learning11. This model has been shown to capture the long term changes in behavior, neural firing and synaptic weights as monkeys learn to perform the Random Dot Motion task.\nSpecifically, the model assumes that monkeys make the perceptual decision between left and right on the basis of neural activity in area MT\u2014an area in the dorsal visual stream that is known to represent motion information15. In the Random Dot Motion task, neurons in MT have been found to respond to both the direction \u03b8 and coherence COH of the dot motion stimulus such that each neuron responds most strongly to a particular \u2018preferred\u2019 direction and that the magnitude of this response increases with coherence. This pattern of firing is well described by a simple set of equations (see \u201cMethods\u201d) and thus the noisy population response, x, to a stimulus of arbitrary direction and coherence is easily simulated.\nFrom this MT population response, Law and Gold proposed that animals construct a decision variable in a separate area of the brain (lateral interparietal area, LIP) as the weighted sum of activity in MT; i.e.,\nwhere w are the weights between MT and LIP neurons and \u03f5 is random neuronal noise that cannot be reduced by learning. The presence of this irreducible neural noise is a key difference between the Law and Gold model (Eq. 18) and the Perceptron (Eq. 11) as it means that no amount of learning can lead to perfect performance. However, as shown in the Methods section, the presence of irreducible noise does not change the optimal accuracy for learning which is still 85%.\nAnother difference between the Perceptron and the Law and Gold model is the form of the learning rule. In particular, weights are updated according to a reinforcement learning rule based on a reward prediction error\nwhere r is the reward presented on the current trial (1 for a correct answer, 0 for an incorrect answer) and E[r] is the predicted reward\nwhere B is a proportionality constant that is estimated online by the model (see \u201cMethods\u201d). Given the prediction error, the model updates its weights according to\nwhere C is the choice (\u22121 for left, +1 for right) and \u03b7 is the learning rate. Despite the superficial differences with the Perceptron learning rule (Eq. (13)) the Law and Gold model still implements stochastic gradient descent on the error rate13 and learning should be optimized at 85%.\nTo test this prediction we simulated the model at a variety of different target training error rates. Each target training rate was simulated 100 times with different parameters for the MT neurons (see \u201cMethods\u201d). The precision, \u03b2, of the trained network was estimated by fitting simulated behavior of the network on a set of test coherences that varied logarithmically between 1 and 100%. As shown in Fig. 4a the precision after training is well described (up to a scale factor) by the theory. In addition, in Fig. 4b, we show the expected difference in behavior\u2014in terms of psychometric choice curves\u2014for three different training error rates. While these differences are small, they are large enough that they could be distinguished experimentally.\nDiscussion\nIn this article we considered the effect of training accuracy on learning in the case of binary classification tasks and stochastic gradient-descent-based learning rules. We found that the rate of learning is maximized when the difficulty of training is adjusted to keep the training accuracy at around 85%. We showed that training at the optimal accuracy proceeds exponentially faster than training at a fixed difficulty. Finally we demonstrated the efficacy of the Eighty Five Percent Rule in the case of artificial and biologically plausible neural networks.\nOur results have implications for a number of fields. Perhaps most directly, our findings move towards a theory for identifying the optimal environmental settings in order to maximize the rate of gradient-based learning. Thus the Eighty Five Percent Rule should hold for a wide range of machine learning algorithms including multilayered feedforward and recurrent neural networks (e.g. including \u2018deep learning\u2019 networks using backpropagation9, reservoir computing networks21,22, as well as Perceptrons). Of course, in these more complex situations, our assumptions may not always be met. For example, as shown in the Methods, relaxing the assumption that the noise is Gaussian leads to changes in the optimal training accuracy: from 85% for Gaussian, to 82% for Laplacian noise, to 75% for Cauchy noise (Eq. (31) in the \u201cMethods\u201d).\nMore generally, extensions to this work should consider how batch-based training changes the optimal accuracy, and how the Eighty Five Percent Rule changes when there are more than two categories. In batch learning, the optimal difficulty to select for the examples in each batch will likely depend on the rate of learning relative to the size of the batch. If learning is slow, then selecting examples in a batch that satisfy the 85% rule may work, but if learning is fast, then mixing in more difficult examples may be best. For multiple categories, it is likely possible to perform similar analyses, although the mapping between decision variable and categories will be more complex as will be the error rates which could be category specific (e.g., misclassifying category 1 as category 2 instead of category 3).\nIn Psychology and Cognitive Science, the Eighty Five Percent Rule accords with the informal intuition of many experimentalists that participant engagement is often maximized when tasks are neither too easy nor too hard. Indeed it is notable that staircasing procedures (that aim to titrate task difficulty so that error rate is fixed during learning) are commonly designed to produce about 80\u201385% accuracy17. Similarly, when given a free choice about the difficulty of task they can perform, participants will spontaneously choose tasks of intermediate difficulty levels as they learn23. Despite the prevalence of this intuition, to the best of our knowledge no formal theoretical work has addressed the effect of training accuracy on learning, a test of which is an important direction for future work.\nMore generally, our work closely relates to the Region of Proximal Learning and Desirable Difficulty frameworks in education24,25,26 and Curriculum Learning and Self-Paced Learning7,8 in computer science. These related, but distinct, frameworks propose that people and machines should learn best when training tasks involve just the right amount of difficulty. In the Desirable Difficulties framework, the difficulty in the task must be of a \u2018desirable\u2019 kind, such as spacing practice over time, that promotes learning as opposed to an undesirable kind that does not. In the Region of Proximal Learning framework, which builds on early work by Piaget27 and Vygotsky28, this optimal difficulty is in a region of difficulty just beyond the person\u2019s current ability. Curriculum and Self-Paced Learning in computer science build on similar intuitions, that machines should learn best when training examples are presented in order from easy to hard. In practice, the optimal difficulty in all of these domains is determined empirically and is often dependent on many factors29. In this context, our work offers a way of deriving the desired difficulty and the region of proximal learning in the special case of binary classification tasks for which stochastic gradient-descent learning rules apply. As such our work represents the first step towards a more mathematical instantiation of these theories, although it remains to be generalized to a broader class of circumstances, such as multi-choice tasks and different learning algorithms.\nWith regard to different learning algorithms, it is important to note that not all models will exhibit a sweet spot of difficulty for learning. As an example, consider how a Bayesian learner with a perfect memory would infer parameters \u03d5 by computing the posterior distribution given past stimuli, x1:t, and labels, y1:t,\nwhere the last line holds when the label depends only on the current stimulus. Clearly this posterior distribution over parameters is independent of the ordering of the trials meaning that a Bayesian learner (with perfect memory) would learn equally well if hard or easy examples are presented first. This is not to say that Bayesian learners cannot benefit from carefully constructed training sets, but that for a given set of training items the order of presentation has no bearing on what is ultimately learned. This contrasts markedly with gradient-based algorithms, many of which try to approximate the maximum a posteriori solution of a Bayesian model, whose training is order dependent and whose learning is optimized with \u2202ER/\u2202\u03b2.\nFinally, we note that our analysis for maximizing the gradient, \u2202ER/\u2202\u03b2, not only applies to learning but to any process that affects the precision of neural representations, such as attention, engagement, or more generally cognitive control30,31. For example, attention is known to improve the precision with which sensory stimuli are represented in the brain, e.g., ref. 32. If exerting control leads to a change in precision of \u03b4\u03b2, then the change in error rate associated with exerting this control is\nThis predicts that the benefits of engaging cognitive control should be maximized when \u2202ER/\u2202\u03b2 is maximized, that is at ER*. More generally this relates to the Expected Value of Control theory30,31,33 which suggests that the learning gradient, \u2202ER/\u2202\u03b2, is monitored by control-related areas of the brain such as anterior cingulate cortex.\nAlong similar lines, our work points to a mathematical theory of the state of \u2018Flow\u201934. This state, \u2018in which an individual is completely immersed in an activity without reflective self-consciousness but with a deep sense of control\u2019 [ref. 35, p. 1], is thought to occur most often when the demands of the task are well matched to the skills of the participant. This idea of balance between skill and challenge was captured originally with a simple conceptual diagram (Fig. 5) with two other states: \u2018anxiety\u2019 when challenge exceeds skill and \u2018boredom\u2019 when skill exceeds challenge. These three qualitatively different regions (flow, anxiety, and boredom) arise naturally in our model. Identifying the precision, \u03b2, with the level of skill and the level challenge with the inverse of true decision variable, 1/\u0394, we see that when challenge equals skill, flow is associated with a high learning rate and accuracy, anxiety with low learning rate and accuracy and boredom with high accuracy but low learning rate (Fig. 5b, c). Intriguingly, recent work by Vuorre and Metcalfe, has found that subjective feelings of Flow peaks on tasks that are subjectively rated as being of intermediate difficulty36. In addition work on learning to control brain computer interfaces finds that subjective, self-reported measures of \u2018optimal difficulty\u2019, peak at a difficulty associated with maximal learning, and not at a difficulty associated with optimal decoding of neural activity37. Going forward, it will be interesting to test whether these subjective measures of engagement peak at the point of maximal learning gradient, which for binary classification tasks is 85%.\nMethods\nOptimal error rate for learning\nIn order to compute the optimal difficulty for training, we need to find the value of \u0394 that maximizes the learning gradient, \u2202ER/\u2202\u03b2. From Eq. (3) we have\nFrom here the optimal difficulty, \u0394*, can be found by computing the derivative of the gradient with respect to \u0394, i.e.,\nSetting this derivative equal to zero gives us the following expression for the optimal difficulty, \u0394*, and error rate, ER*\nwhere p\u2032(x) denotes the derivative of p(x) with respect to x. Because \u03b2 and \u0394* only ever appear together in these expressions, Eq. (26) implies that \u03b2\u0394* is a constant. Thus, while the optimal difficulty, \u0394*, changes as a function of precision (Fig. 1c), the optimal training error rate, ER* does not (Fig. 1d). That is, training with the error rate clamped at ER* is guaranteed to maximize the rate of learning.\nThe exact value of ER* depends on the distribution of noise, n, in Eq. (2). In the case of Gaussian noise, we have\nwhich implies that\nand that the optimal difficulty is\nConsequently the optimal error rate for Gaussian noise is\nSimilarly for Laplacian noise (\\(p(x) = \\frac{1}{2}\\exp ( - |x|)\\)) and Cauchy noise (p(x) = (\u03c0(1 + x2))\u22121) we have optimal error rates of\nOptimal learning with endogenous noise\nThe above analyses for optimal training accuracy also applies in the case where the decision variable, h, is corrupted by endogenous, irreducible noise, \u03f5, in addition to representation noise, n, that can be reduced by learning; i.e.,\nIn this case we can split the overall precision, \u03b2, into two components, one based on representational uncertainty that can be reduced, \u03b2n, and another based on endogenous uncertainty that cannot, \u03b2\u03f5. For Gaussian noise, these precisions are related to each other by\nMore generally, the precisions are related by some function, G, such that \u03b2 = G(\u03b2n, \u03b2\u03f5). Since only n can be reduced by learning, it makes sense to perform stochastic gradient descent on \u03b2n such that the learning rule should be\nNote that \u2202\u03b2/\u2202\u03b2n is independent of \u0394 so maximizing learning rate w.r.t. \u0394 means maximizing \u2202ER/\u2202\u03b2 as before. This implies that the optimal training difficulty will be the same, e.g., 85% for Gaussian noise, regardless whether endogenous noise is present or not.\nDynamics of learning\nTo calculate the dynamics of learning we need to integrate Eq. (7) over time. This, of course depends on the learning gradient, \u2202ER/\u2202\u03b2, which varies depending on the noise and whether the error rate or the true decision variable is fixed during training.\nIn the fixed error rate case, we fix the error rate during training to ERf. This implies that the difficulty should change over time according to\nwhere F\u22121(\u22c5) is the inverse cdf. This implies that \u03b2 evolves over time according to\nwhere we have introduced Kf as\nIntegrating Eq. (36) and solving for \u03b2(t) we get\nwhere t0 is the initial time point, and \u03b20 is the initial value of \u03b2. Thus, for fixed error rate the precision grows as the square root of time with the rate determined by Kf which depends on both the training error rate and the noise distribution. For the optimal error rate we have, Kf = p(\u22121).\nIn the fixed decision variable case, the true decision variable is fixed at \u0394f and the error rate varies as a function of time. In this case we have\nFormally, this can be solved as\nHowever, the exact form for \u03b2(t) will depend on p(x).\nIn the Gaussian case we cannot derive a closed form expression for \u03b2(t). The closest we can get is to write\nFor long times, and large \u03b2, we can write\nwhich implies that for long times \u03b2 grows slower than \\(\\sqrt {\\log t}\\), which is exponentially slower than the fixed error rate case.\nIn contrast to the Gaussian case, the Laplacian case lends itself to closed form analysis and we can derive the following expression for \u03b2\nAgain this shows logarithmic dependence on t indicating that learning is much slower with a fixed difficulty.\nIn the case of Cauchy noise we can compute the integral in Eq. (40) and find that \u03b2 is the root of the following equation\nFor long training times this implies that \u03b2 grows as the cube root of t. Thus in the Cauchy case, while the rate of learning is still greatest at the optimal difficulty, the improvement is not as dramatic as in the other cases.\nApplication to the perceptron\nTo implement the Perceptron example, we assumed that true labels t were generated by a \u2018Teacher Perceptron\u201938 with normalized weight vector, e. Learning was quantified by decomposing the learned weights w into two components: one proportional to e and a second orthogonal to e, i.e.,\nwhere \u03b8 is the angle between w and e, and e\u22a5 is the unit vector perpendicular to e in the plane defined by e and w. This allows us to write the decision variable h in terms of signal and noise components as\nwhere the difficulty \u0394 = |e \u22c5 x| is the distance between x and the decision boundary, and the (2t \u2212 1) term simply controls which side of the boundary x is on. This implies that the precision \u03b2 is proportional to cot \u03b8, with a constant of proportionality determined by the dimensionality of x.\nIn the case where the observations x are sampled from distributions that obey the central limit theorem, then the noise term is approximately Gaussian implying that the optimal error rate for training the Perceptron, ER* = 15.87%.\nTo test this prediction we simulated the Perceptron learning rule for a range of training error rates between 0.01 and 0.5 in steps of 0.01 (1000 simulations per error rate). Stimuli, x, were 100 dimensional and independently sampled from a Gaussian distribution with mean 0 and variance 1. Similarly, the true weights e were sampled from a mean 0, variance 1 Gaussian. To mimic the effect of a modest degree of initial training, we initialized the weight vector w randomly with the constraint that |\u03b8| < 1.6\u03c0. The difficulty \u0394 was adjusted on a trial-by-trial basis according to\nwhich ensures that the training error rate is clamped at ER. The degree of learning was captured by the precision \u03b2.\nApplication to the two-layer neural network\nTo implement the two-layer network, we built a sigmoidal neural network with one hidden layer (of 50 neurons) and one output neuron. The weights between the input layer and the hidden layer and between the hidden layer and output layer were trained using the standard Backpropagation algorithm.\nIn order to clamp the error rate during training we first had to rate the images according to their \u2018difficulty\u2019. To this end, we trained a teacher network with the same basic architecture (i.e., 50 hidden units and 1 output unit) until its performance was near perfect (training error rate = 99.6% for the Parity Task and 99.4% for the Magnitude Task; test error rate = 97% for the Magnitude Task and 95.6% for the Parity Task). We then used the absolute value of the decision variable from this network, |hteacher| as a proxy for the true difficulty, \u0394\u2014with larger values of |hteacher| indicating easier stimuli to classify.\nWeights in the network were initialized randomly from a Gaussian distribution (mean 0, variance 1). To achieve a fixed error rate during training, on each trial, we selected a stimulus that was closest to a target difficulty, htarget. This target difficulty was adjusted based on the performance of the network during training\u2014increasing if the network classified the stimulus incorrectly, and decreasing if the network classified the stimulus correctly. More specifically, the target difficulty was adjusted as\nwhere D is the step size (=1), Atarget is the target training accuracy and Aav is the running average of the accuracy from the last 50 trials.\nOn each trial we selected the \u2018eligible\u2019 stimulus whose value of hteacher was closest to htarget. To ensure that a given stimulus was not selected too often during training, stimuli were only eligible to be chosen if they had not been used in the last 50 trials.\nEach initial state of the network was trained on either the Parity or Magnitude Task at a fixed training error rate between 5 and 30% in steps of 5%. At the end of training performance was assessed on the whole test set. This process was repeated 1000 times, with a new set of initial random weights each time.\nApplication to Law and Gold model\nThe model of perceptual learning follows the exposition in Law and Gold11. To aid comparison with that paper we retain almost all of their notation, with the three exceptions being their \u03b2 parameter, which we rename as B to avoid confusion with the precision, their \u03d5i parameter which we rename as Fi to avoid confusion with the parameters of the learner, and their learning rate parameter \u03b1 which we write as \u03b7.\nFollowing Law and Gold11, the average firing rate of an MT neuron, i, in response to a moving dot stimulus with direction \u03b8 and coherence COH is\nwhere T is the duration of the stimulus, \\(k_i^0\\) is the response of neuron i to a zero-motion coherence stimulus, \\(k_i^p\\) is the response to a stimulus moving in the preferred direction and \\(k_i^n\\) is the response to a stimulus in the null direction. f(\u03b8|\u0398i) is the tuning curve of the neuron around its preferred direction \u0398i\nwhere \u03c3\u03b8 (=30 degrees) is the width of the tuning curve which is assumed to be identical for all neurons.\nNeural activity on each trial was assumed to be noisily distributed around this mean firing rate. Specifically the activity, xi, of each neuron is given by a rectified (to ensure xi > 0) sample from a Gaussian with mean mi and variance vi\nwhere Fi is the Fano factor of the neuron.\nThus each MT neuron was characterized by five free parameters. These free parameters were sampled randomly for each neuron such that \\(\\theta _i\\sim U( - 180,180)\\), \\(k_i^0\\sim U(0,20)\\), \\(k_i^p\\sim U(0,50)\\), \\(k_i^n\\sim U( - k_i^0,0)\\) and \\(F_i\\sim U(1,5)\\). Note that \\(k_i^n\\) is set between \u2212\\(k_i^0\\) and 0 to ensure that the minimum average firing rate never dips below zero. Each trial was defined by three task parameters: T = 1 s, \u0398 = \u00b190 degrees and COH which was adjusted based on performance to achieve a fixed error rate during training (see below). As in the original paper, the number of neurons was set to 7200 and the learning rate, \u03b7 was 10\u22127.\nThe predicted reward E[r] was computed according to Eq. (20). In line with Law and Gold (Supplementary Fig. 2 in ref. 11), the proportionality constant B was computed using logistic regression on the accuracy and absolute value of the decision variable, |h|, from last L trials, where L = min(300, t).\nIn addition to the weight update rule (Eq. (21)), weights were normalized after each update to keep the sum of the squared weights, \\(\\mathop {\\sum}\\limits_i {w_i^2} = w_{\\mathrm{amp}}\\) a constant (=0.02). While this normalization has only a small overall effect (see Supplementary Material in ref. 11), we replicate this weight normalization here for consistency with the original model.\nTo initialize the network, the first 50 trials of the simulation had a fixed coherence COH = 0.9. After this initialization period, the coherence was adjusted according to the difference between the target accuracy, Atarget, and actual accuracy in the last L trials, AL, where L = min(300, t). Specifically, the coherence on trial t was set as\nwhere \u0393t was adjusted according to\nand d\u0393 was 0.1.\nTo estimate the post-training precision parameter, \u03b2, we simulated behavior of the trained network on a set of 20 logarithmically spaced coherences between 10\u22123 and 1. Behavior at each coherence was simulated 100 times and learning was disabled during this testing phase. The precision parameter, \u03b2, was estimated using logistic regression between accuracy on each trial (0 or 1) and coherence; i.e.,\nData availability\nData sharing not applicable to this article as no datasets were generated or analysed during the current study.\nCode availability\nAll code is publicly available on GitHub at https://github.com/bobUA/EightyFivePercentRule\nReferences\nKidd, C., Piantadosi, S. T. & Aslin, R. N. The goldilocks effect: Human infants allocate attention to visual sequences that are neither too simple nor too complex. PLoS ONE 7, e36399 (2012).\nMetcalfe, J. Metacognitive judgments and control of study. Curr. Directions Psychological Sci. 18, 159\u2013163 (2009).\nSkinner, B. The Behavior of Organisms: An Experimental Analysis. (D. appleton-century company, New York, 1938).\nLawrence, D. H. The transfer of a discrimination along a continuum. J. Comp. Physiological Psychol. 45, 511 (1952).\nElman, J. L. Learning and development in neural networks: the importance of starting small. Cognition 48, 71\u201399 (1993).\nKrueger, K. A. & Dayan, P. Flexible shaping: how learning in small steps helps. Cognition 110, 380\u2013394 (2009).\nBengio, Y., Louradour, J., Collobert, R. & Weston, J. Curriculum learning. In Proceedings of the 26th Annual International Conference on Machine Learning, 41\u201348 (ACM, 2009).\nKumar, M. P., Packer, B. & Koller, D. In Advances in Neural Information Processing Systems, 1189\u20131197 (2010).\nRumelhart, D. E. et al. Learning representations by back-propagating errors. Cogn. modeling 5, 1 (1988).\nLeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436\u2013444 (2015).\nLaw, C.-T. & Gold, J. I. Reinforcement learning can account for associative and perceptual learning on a visual-decision task. Nat. Neurosci. 12, 655\u2013663 (2009).\nSch\u00f6llhorn, W., Mayer-Kress, G., Newell, K. & Michelbrink, M. Time scales of adaptive behavior and motor learning in the presence of stochastic perturbations. Hum. Mov. Sci. 28, 319\u2013333 (2009).\nWilliams, R. J. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Mach. Learn. 8, 229\u2013256 (1992).\nRosenblatt, F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological Rev. 65, 386 (1958).\nNewsome, W. T. & Pare, E. B. A selective impairment of motion perception following lesions of the middle temporal visual area (mt). J. Neurosci. 8, 2201\u20132211 (1988).\nBritten, K. H., Shadlen, M. N., Newsome, W. T. & Movshon, J. A. The analysis of visual motion: a comparison of neuronal and psychophysical performance. J. Neurosci. 12, 4745\u20134765 (1992).\nGarca-P\u00e9rez, M. A. Forced-choice staircases with fixed step sizes: asymptotic and small-sample properties. Vis. Res. 38, 1861\u20131881 (1998).\nLeCun, Y. et al. Gradient-based learning applied to document recognition. Proc. IEEE 86, 2278\u20132324 (1998).\nMacKay, D. J. Information Theory, Inference and Learning Algorithms (Cambridge University Press, 2003).\nLeCun, Y., Cortes, C. & Burges, C. J. The mnist database of handwritten digits. http://yann.lecun.com/exdb/mnist/.\nJaeger, H. The echo state approach to analysing and training recurrent neural networks-with an erratum note. Bonn., Ger.: Ger. Natl. Res. Cent. Inf. Technol. GMD Tech. Rep. 148, 13 (2001).\nMaass, W., Natschl\u00e4ger, T. & Markram, H. Real-time computing without stable states: a new framework for neural computation based on perturbations. Neural Comput. 14, 2531\u20132560 (2002).\nBaranes, A. F., Oudeyer, P.-Y. & Gottlieb, J. The effects of task difficulty, novelty and the size of the search space on intrinsically motivated exploration. Front. Neurosci. 8, 317 (2014).\nMetcalfe, J. & Kornell, N. A region of proximal learning model of study time allocation. J. Mem. Lang. 52, 463\u2013477 (2005).\nBjork, R. A. in Metacognition: Knowing about Knowing (eds Metcalfe, J. & Shimamura, A.)185\u2013205 (MIT Press, Cambridge, MA, 1994).\nSchnotz, W. & K\u00fcrschner, C. A reconsideration of cognitive load theory. Educ. Psychol. Rev. 19, 469\u2013508 (2007).\nPiaget, J. & Cook, M. The Origins of Intelligence in Children 8 (International Universities Press, New York, 1952).\nVygotsky, L. S. The Collected Works of LS Vygotsky: Problems of the Theory and History of Psychology, vol. 3 (Springer Science & Business Media, 1997).\nMetcalfe, J. Learning from errors. Annu. Rev. Psychol. 68, 465\u2013489 (2017).\nShenhav, A., Botvinick, M. M. & Cohen, J. D. The expected value of control: an integrative theory of anterior cingulate cortex function. Neuron 79, 217\u2013240 (2013).\nShenhav, A. et al. Toward a rational and mechanistic account of mental effort. Annu. Rev. Neurosci. 40, 99\u2013124 (2017).\nBriggs, F., Mangun, G. R. & Usrey, W. M. Attention enhances synaptic efficacy and the signal-to-noise ratio in neural circuits. Nature 499, 476\u2013480 (2013).\nBrown, J. W. & Braver, T. S. Learned predictions of error likelihood in the anterior cingulate cortex. Science 307, 1118\u20131121 (2005).\nCsikszentmihalyi, M. Beyond Boredom and Anxiety (Jossey-Bass, 2000).\nEngeser, S. Advances in Flow Research (Springer, 2012).\nVuorre, M. & Metcalfe, J. The relation between the sense of agency and the experience of flow. Conscious. Cognition 43, 133\u2013142 (2016).\nBauer, R., Fels, M., Royter, V., Raco, V. & Gharabaghi, A. Closed-loop adaptation of neurofeedback based on mental effort facilitates reinforcement learning of brain self-regulation. Clin. Neurophysiol. 127, 3156\u20133164 (2016).\nKinzel, W. & Rujan, P. Improving a network generalization ability by selecting examples. Europhys. Lett. 13, 473\u2013477 (1990).\nAcknowledgements\nThis project was made possible through the support of a grant from the John Templeton Foundation to J.D.C., a Center of Biomedical Research Excellence grant P20GM103645 from the National Institute of General Medical Sciences to A.S., and National Institute on Aging grant R56 AG061888 to R.C.W. The opinions expressed in this publication are those of the authors and do not necessarily reflect the views of the funders.\nAuthor information\nAuthors and Affiliations\nContributions\nR.C.W., A.S., M.S., and J.D.C. developed the idea and wrote the paper. R.C.W. derived mathematical results and ran simulations.\nCorresponding author\nEthics declarations\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nPeer review information Nature Communications thanks the anonymous reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nSupplementary information\nRights and permissions\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.\nAbout this article\nCite this article\nWilson, R.C., Shenhav, A., Straccia, M. et al. The Eighty Five Percent Rule for optimal learning. Nat Commun 10, 4646 (2019). https://doi.org/10.1038/s41467-019-12552-4\nReceived:\nAccepted:\nPublished:\nDOI: https://doi.org/10.1038/s41467-019-12552-4\nThis article is cited by\n-\nEffect of immersive virtual reality-based cognitive remediation in patients with mood or psychosis spectrum disorders: study protocol for a randomized, controlled, double-blinded trial\nTrials (2024)\n-\nA multi-institutional machine learning algorithm for prognosticating facial nerve injury following microsurgical resection of vestibular schwannoma\nScientific Reports (2024)\n-\nPre-movement muscle co-contraction associated with motor performance deterioration under high reward conditions\nScientific Reports (2024)\n-\nMaximizing reusability of learning objects through machine learning techniques\nScientific Reports (2023)\n-\nDevelopment of a program to determine optimal settings for robot-assisted rehabilitation of the post-stroke paretic upper extremity: a simulation study\nScientific Reports (2023)"
    },
    {
      "url": "https://www.latimes.com/health/la-he-scared-20151031-story.html",
      "text": "We\u2019re far more afraid of failure than ghosts: Here\u2019s how to stare it down\n- Share via\nI sat at the edge of my seat, waiting to be called up. Hands freezing, heart racing, I tried to slow my breathing and calmly remember what to do. Breathe, got to breathe.\nThe instructor called my name. I walked to my spot, inhaled and expanded my rib cage. Nodded.\nAnd began to sing \u201cShenandoah.\u201d With an accompanist, in front of an audience: a class of 20 fellow voice students.\nIt was one of the most terrifying and exhilarating experiences of my life.\nFear and exhilaration do go hand in hand, and fear of failure is common. A recent survey by the social network Linkagoal found that fear of failure plagued 31% of 1,083 adult respondents \u2014 a larger percentage than those who feared spiders (30%), being home alone (9%) or even the paranormal (15%).\n\u201cFear of failure is the No. 1 reason people don\u2019t set goals or try new things,\u201d said Mohsin Shafique, a former medical school student who is chief executive of Linkagoal, which was designed to help people set and achieve goals. One solution, Shafique believes, is connecting with people who share your ambition. \u201cSharing what you are doing with a community that not only gets it but also may have done what you are trying to do is very powerful. It\u2019s why going to the gym when you\u2019re trying to get fitter works better than doing it on your own.\u201d\nLos Angeles-based publicist Sharon House knows the euphoric lift many people get after doing something that frightens them. Always afraid of heights, House would never even go out on balconies. \u201cIt kept me from doing some things I really wanted to do, like going to the top of Machu Picchu.\u201d\nSo, for Mother\u2019s Day last year, House\u2019s daughter Laurel helped her jump off a cliff. \u201cShe took me rappelling at Garden of the Gods in Colorado Springs,\u201d House remembered. \u201cThey take you up a very slippery climb, put you in a helmet and harness, and then say, \u2018OK, go.\u2019 It was 5 feet to the edge; I walked to it on my tiptoes, then jumped backwards and free-fell about 6 feet. Pushed off and did it again. I did it all the way down, for about 10 minutes. There was no stopping me.\u201d\nPerformance anxiety\nLinda Hamilton, a former dancer in the New York City Ballet, now has a psychology practice working with performers and others dealing with fear \u2014 of performing, of dating, of changing jobs. She started her practice counseling dancers, initially through her column in Dance magazine, but then realized she could help many others too. \u201cThe people I work with are scared of failing and are passionate about what they\u2019re doing. I try to teach them that you don\u2019t achieve anything if you stay in your comfort zone,\u201d Hamilton said.\n\u201cFear of failure is fear of the unknown,\u201d she said. \u201cIn some cases, we need fear. It\u2019s what keeps us alive. But at the same time it can freeze you.\u201d\nNot everyone can do anything they want. \u201cI do a thorough intake on a client, because sometimes they are not equipped for what they want to do,\u201d Hamilton said. \u201cThey haven\u2019t had the training, for instance, to start trying to be a professional ballet dancer at age 25. But we can find strategies for what to do instead.\u201d\nWhat often happens, according to Hamilton, is that people reframe their fears, and use a cognitive technique to see that the concerns are unfounded. \u201cMy client who was afraid of dating was also terrified of making friends, fearing that she would lose them if they moved or got pregnant. What she was really reacting to was feeling she had to be perfect for her mother, who kept all her feelings to herself. The girl took rejection very seriously and anticipated it even if it wasn\u2019t real.\u201d\nThe payoff\n\u201cThe experience of going out of your comfort zone is not a pleasant one,\u201d said Hamilton. \u201cBut the confidence, the feeling of relief \u2014 we call it \u2018excitation transfer\u2019 \u2014 are very intense. That sense of mastery, \u2018Wow, look what I just did,\u2019 is a learning experience. The fear itself is not pleasant, but people never remember it. What they remember is that positive high.\u201d\nThat high, both immediate and long term, is due to a deluge of brain chemicals, most notably dopamine. \u201cOur dopaminergic reward systems are geared for learning about our world and optimizing our odds for survival,\u201d said neuroscientist Christopher Evans, director of the UCLA Brain Research Institute and an addiction expert. \u201cSo food, sex, drugs all promote dopaminergic signaling (at least initially, and then cues take over). Pain or noxious stimuli cause dopamine release, and so relief from any perceived danger or threat \u2014 in the case of your singing, the threat of being ostracized from a group \u2014 would explain that euphoria.\u201d\nWhen fear is crippling\nMany performers experience a type of post-traumatic stress disorder in the form of stage fright. One incident may scar them for years. Barbra Streisand, famously and early in her career, forgot the words to \u201cPeople\u201d during a free concert in Central Park. She was so mortified, she stopped performing in public for almost three decades; she simply kept reliving that moment. Performers who have stage fright do not get that reward of euphoria. First there is terror, and then hyper-criticism.\nSara Solovitch, author of \u201cPlaying Scared: A History and Memoir of Stage Fright,\u201d played classical piano from a very early age. When she was 11 or 12, she developed crippling stage fright, so severe that her fingers, dripping sweat, would slip off the keys. \u201cI was a talented pianist, but what I was experiencing was not natural. Even though you know your life is not being threatened, that you aren\u2019t skydiving or bungee jumping, what happens in your body and your brain is the same. It doesn\u2019t matter: Your brain is being hijacked, and your rational mind isn\u2019t there anymore.\u201d\nSolovitch gave up the piano and became a writer. But after 30 years she went back, \u201cprimarily because all my children played and my youngest wanted me to play with him. I took lessons in jazz piano, thinking that he would soon forget about it, and it would all pass. Instead, it triggered something and I started playing all the time, practicing two to three hours a day.\u201d\nHer fear of performing in public, however, \u201chad been preserved in formaldehyde,\u201d Solovitch was surprised to discover. \u201cEvery time I play, when I feel I have some skin in the game, I have to deal with it.\u201d To cope, she studiously prepares. \u201cWinston Churchill said that for every minute of a speech he\u2019d prepare for an hour. I have to make sure every note is in my head. Then, the last day or two, just relax, meditate, go for long walks and be very thoughtful.\u201d\nA surprise reward\nJenna McCarthy, author of the new novel \u201cPretty Much Screwed,\u201d found herself unexpectedly invited to do a TED-X talk in her hometown of Santa Barbara. \u201cI had no aspiration whatsoever to be a speaker,\u201d said McCarthy. \u201cI\u2019m more of a sit-down comedienne.\u201d But she figured she would rather have a learning experience to live through than live with the regret of \u201cwhat if?\u201d\n\u201cThey kept telling me \u2018the E in TED stands for entertainment,\u2019\u201d McCarthy remembers, \u201cBut I have never been so nervous in my life. It felt like 30 degrees in the room, and I was sweating. I forgot my second line. Then I went into the zone, thinking, \u2018These people are here to be entertained, not to criticize.\u2019 And they were laughing at the right moments. I got a standing ovation. It was the most euphoric high I could imagine.\u201d\nNow McCarthy is getting work as a speaker. \u201cI stepped out of my comfort zone, and it changed my life. I learned a great lesson: Don\u2019t not do it without first trying to do it.\u201d\nLife and a lesson\nSharon House, now \u201cnot a thrill seeker, just accomplished\u201d at conquering her fear of heights, went on to do a one-hour zip-line tour over the rainforest in Costa Rica and realizes the value of her feat: \u201cI think as we get older, so much is happening that we might not be involved in \u2014 pop culture, social media, super miniskirts \u2014 so to be able to have a couple of things that make us feel good about ourselves is very powerful.\u201d\nLinda Hamilton agrees: \u201cThere\u2019s nothing worse than thinking, \u2018Here I am, and nothing more is going to happen to me.\u2019 The brain keeps developing and learning. I think everybody benefits from that.\u201d\nALSO:\nNeuroplasticity - the brain\u2019s ability to adapt - offers hope to those with debilitating diseases\nWould you let someone zap your brain? Why \u2018electronic brain stimulation\u2019 is trending\nWhen using social media becomes socially destructive"
    },
    {
      "url": "https://www.business.com/articles/never-giving-up-9-entrepreneurs-and-millionaires-who-failed-at-least-once/",
      "text": "Business.com aims to help business owners make informed decisions to support and grow their companies. We research and recommend products and services suitable for various business types, investing thousands of hours each year in this process.\nAs a business, we need to generate revenue to sustain our content. We have financial relationships with some companies we cover, earning commissions when readers purchase from our partners or share information about their needs. These relationships do not dictate our advice and recommendations. Our editorial team independently evaluates and recommends products and services based on their research and expertise. Learn more about our process and partners here.\nGates, Huffington, Jobs, Rowling and even Edison were deemed failures at one point. Here\u2019s how they bounced back from rejections and missteps.\nIf you\u2019re stumbling along the entrepreneurial journey or feel your business dreams are beyond your reach, take this to heart: Many of the most successful entrepreneurs experienced some colossal failures before finding success. This isn\u2019t a coincidence \u2014 failure is an entrepreneur\u2019s most demanding teacher, forcing critical pivots that reveal market realities and building the resilience necessary to weather future storms. When entrepreneurs fail forward, they develop what researchers call \u201centrepreneurial learning,\u201d the ability to rapidly test assumptions, adapt strategies and recognize opportunities that others miss. Perhaps most importantly, failure strips away the fear, freeing entrepreneurs to take the calculated risks that true innovation demands.\nTo inspire the next generation of business owners, business.com is looking at some determined entrepreneurs who may be well-known today but were far from overnight successes. The entrepreneurs featured below didn\u2019t succeed despite their failures. They succeeded because of them, with each setback providing invaluable insights that informed their eventual breakthroughs. We\u2019re also sharing expert-backed tips for transforming failure into a competitive advantage as you pursue your business goals.\nName | Initial Failure | Ultimate Success | Key Lesson |\n|---|---|---|---|\nBill Gates | Traf-O-Data failed as a business venture | Founded Microsoft, became global tech leader | Learn from failure to build future success |\nSteve Jobs | Ousted from Apple after product failures | Returned to lead Apple to unprecedented innovation | Persistence and innovation create new opportunities |\nArianna Huffington | Rejected by nearly 40 publishers, political campaign loss | Founded Huffington Post, then Thrive Global | Adapt knowledge from setbacks to new ventures |\nThomas Edison | Expelled from school, fired from jobs, failed inventions | Invented light bulb, held 1,093 U.S. patents | Persistence and experimentation lead to breakthroughs |\nWalt Disney | Lost Oswald character, ideas rejected, lived in poverty | Created iconic brand, revolutionized animation | Imagination and resilience drive long-term success |\nFrederick W. Smith | Delivery concept graded C at Yale | Founded FedEx, became global logistics leader | Believe in your ideas despite criticism |\nNick Woodman | Funbug startup failed, lost investors\u2019 money | Founded GoPro, became industry pioneer | Dedication and learning from mistakes build future wins |\nJ.K. Rowling | Rejected by publishers, struggled on welfare | Created Harry Potter, became global literary icon | Perseverance transforms setbacks into success |\nJeff Bezos | Costly errors launching Amazon, stuck with unsold inventory | Built Amazon into leading e-commerce site | Experimentation and resilience fuel business growth |\nHave you ever driven over one of those black cables that stretch across the road and measure traffic by counting tire bumps? Bill Gates and a few of his friends did, which is why he founded Traf-O-Data in 1972. His system recorded traffic information and fed it back to government authorities, civil engineers and others who needed it. While it sounded like a useful business idea, the concept ultimately failed.\nDespite Traf-O-Data\u2019s failure as a business venture, the project gave Gates and Paul Allen the experience and skills they needed to create Microsoft\u2019s first line of software products a few years later. Fifty years on, Microsoft is one of the biggest technology companies in the world \u2014 and Gates is among the world\u2019s richest.\nKey Takeaway: Failed ventures provide valuable experience and skills that can be applied to future successful endeavors.\n>> Read Related Article: Common Mistakes That Can Lead to Product Failure\nDo you remember the Apple I or Apple Lisa? If you don\u2019t, you\u2019re not alone. Those were two products Apple produced that crashed and burned. Unfortunately for Apple co-founder Steve Jobs, they were products he pushed for, and they cost the company millions of dollars in development \u2014 money it failed to recoup. A pattern of costly production decisions led to Jobs\u2019s ouster from Apple in the mid-1980s.\nBut Jobs eventually found his way back to the company in 1997, thanks partly to another business he founded in the interim, NeXT. After Apple acquired NeXT, Jobs himself became a valuable commodity again. He took the helm of Apple and kicked off a period of expansive growth and innovation that continues to this day under the leadership of Tim Cook.\nKey Takeaway: Being forced out of your own company doesn\u2019t end your story \u2014 it can create new opportunities for innovative comebacks.\nAfter Arianna Huffington finished writing her second book, she received rejection notices from nearly 40 publishers. When she ran for governor of California in 2003, she received less than 1 percent of the popular vote. However, she learned something from her failed political campaign: According to Huffington, running for office taught her about the power of the internet.\nShe used this new knowledge to launch The Huffington Post in 2005. Today, HuffPost, as it\u2019s now called, is among the most well-known and frequently visited sites on the internet. In 2016, Huffington stepped down from her role as president and editor-in-chief of The Huffington Post Media Group to launch Thrive Global, a health and wellness company that aims to prevent burnout and improve today\u2019s work culture.\nKey Takeaway: Extract valuable lessons from every failure and apply that knowledge to create new opportunities in different industries.\nGrowing up in the mid-1850s, Thomas Edison was expelled from school for being \u201cunteachable.\u201d Thankfully, his mother believed in him and encouraged him to continue his education, even teaching him herself at one point. But things didn\u2019t get much better for Edison when he entered the workforce. He was unceremoniously fired from several jobs because he wasn\u2019t productive enough.\nWhile Edison eventually earned his place in American history, even his first thousand or so attempts at getting the light bulb to work were failures. Yet, despite all of his defeats, Edison never gave up. He was a prolific inventor who amassed 1,093 United States patents during his lifetime, including for the movie camera.\nKey Takeaway: Persistence in the face of repeated failures and criticism can lead to groundbreaking innovations that change the world.\nIf you focus on Walt Disney\u2019s failures, it\u2019s amazing that The Walt Disney Company ever reached the level of success it enjoys today. Disney was, at one point, living on dog food and unable to pay his rent. Then, during a contract dispute with Universal Pictures in the 1920s, he lost creative control of his first character, Oswald the Rabbit. Next, MGM rejected his Mickey Mouse character because the studio believed women were afraid of mice.\nSuch setbacks so early in his career might\u2019ve led a less determined person to quit. But Disney overcame these failures and turned his brand into a global empire. Perhaps most importantly, he never let his numerous struggles dull his imagination. Disney went on to pioneer several new animation and filmmaking techniques that revolutionized the industry.\nKey Takeaway: Maintain your creative vision and imagination despite setbacks \u2014 they are often the foundation for revolutionary success.\nIn 1965, Frederick W. Smith received a grade of C on an economics assignment in which he outlined the basic concept behind what would become FedEx. In his paper, Smith argued for a hub-and-spoke approach to distributing goods for faster delivery. Apparently, his professor at Yale didn\u2019t share his vision and scored him poorly.\nSmith, however, never let go of his idea. In 1971, upon returning from serving in the Vietnam War, he strategized how to make his idea for an express transport and delivery business a reality. He raised millions to start what is now one of the world\u2019s most well-known companies. Smith\u2019s trajectory demonstrates the success that can follow when you find investors and disrupt an industry.\nKey Takeaway: Believe in your innovative ideas even when experts dismiss them \u2014 academic grades don\u2019t determine entrepreneurial potential.\nHave you ever heard of Funbug? You probably haven\u2019t, unless you were one of the investors who lost millions of dollars because of it. Funbug was a startup founded in 1999 by Nick Woodman, who sought to merge marketing with a gaming platform. The concept was a miss, however, and the company shuttered.\nAfraid of repeating the mistakes he made with Funbug, in 2002, Woodman dedicated himself fully to making his next effort, GoPro, a successful company within four years. He learned to use a sewing machine borrowed from his mother to make the 35mm camera\u2019s wrist strap and would stay up late to speak with Chinese manufacturers about creating other parts. A decade later, Ernst & Young named Woodman the National EY Entrepreneur of the Year for retail and consumer products.\nKey Takeaway: Use the fear of repeating past mistakes as motivation to dedicate yourself completely to your next venture\u2019s success.\nWhile writing the first Harry Potter book, J.K. Rowling was a single mother receiving welfare benefits. To make matters worse, once the book was completed in 1995, no one wanted to publish it. After a dozen rejections, Rowling finally found a willing publisher in Bloomsbury, but the company urged her to change her pen name out of fear that young male readers wouldn\u2019t want to read a book written by a woman.\nRowling\u2019s pseudonym stuck, and so did Harry Potter. With six more novels published through 2007, she became responsible for creating one of the most beloved and successful series in the history of children\u2019s literature. The books led to eight lucrative film adaptations, a spinoff movie franchise, a Broadway show and even theme parks. At one point, the formerly broke Rowling, who went on to found online ventures like Pottermore, was reported to be worth $1 billion.\nKey Takeaway: Financial hardship and multiple rejections don\u2019t define your potential \u2014 persistence and believing in your work can lead to extraordinary success.\nAmazon founder Jeff Bezos made some mind-blowing mistakes while getting the company off the ground and even more after its successful launch. Here are just two examples:\nAlthough Bezos made several errors in Amazon\u2019s early years, he still managed to turn the company into the premier website for online shopping \u2014 and made himself one of the wealthiest people in the world in the process.\nKey Takeaway: Early operational mistakes and costly errors don\u2019t prevent long-term success when you remain committed to continuous learning and adaptation.\nThe famous entrepreneurs profiled above share several key characteristics that enabled them to transform failure into extraordinary success.\nFailure is inevitable in business and life. While no one likes to fail, doing so doesn\u2019t have to jeopardize your future successes. Below are some tips for dealing with failures along the entrepreneurial journey:\nLearning from your failures is essential for setting yourself up for future success. Here are some of the lessons you should strive to take away from any rejections or missteps as you pursue your business goals:\nSkye Schooley and Julie Ellis contributed to this article. Source interviews were conducted for a previous version of this article."
    },
    {
      "url": "https://makeheadway.com/blog/new-year-resolutions-study/",
      "text": "Key takeaways:\nHeadway's goal-setting research reveals that 74% of people set a New Year's resolution for 2025, with 33% still going strong and 56% having made some progress.\nHowever, 60% of people feel embarrassed by the amount of progress they have made so far, with 61% worried they are running out of time to turn their year around.\nYet, with life presenting many challenges, 1 in 4 people believe that simply staying afloat in 2025 is an achievement in itself.\nAnd with next year right around the corner, 56% of people are ready to go again, setting a new resolution to focus on in 2026.\nEvery January, we tell ourselves that this is the year we get fit, get rich, and finally get our lives together. We create a checklist of all the top personal growth goals and vow to tick every box by the end of the year.\nBut while goal-setting comes easily, achieving them often proves difficult.\nHeadway book summary app surveyed 2,000 people on their 2025 New Year's resolutions, whether they've stuck to them, where they've stumbled, and whether they're planning to give it another go in 2026.\nThe results show that while New Year's resolution success rates might fall short of our January optimism, our motivation for self-improvement hasn't faded.\nGym, goals, and growth: How many people keep New Year's resolutions?\nMore than half (51%) of us started the year with big plans and ambitious targets. We invested in workout gear, set limits on our screen time, and committed to a new course.\nBut setting goals is the easy part. The question is, how many people keep New Year's resolutions beyond January?\nSome 11% of people have already given in. Why do people fail New Year's resolutions? Because they aim too high, don't plan enough, or set goals based on obligation rather than desire.\nHowever, not everyone has ditched their gym bags and deleted language learning apps. Some 33% are still going strong, while most people are somewhere in the middle\u2026 and while their past selves may be disappointed with the results, some progress is far better than none.\nThe most common New Year's resolutions that people actually stick to? Taking better care of our body and mind. From cutting back on doomscrolling (23%) to taking vitamins (38%), and exercising regularly (52%), 2025 is proving to be the year of healthy habit-building.\nWe may be getting swole and taking more steps, but health and fitness \u2014 a common New Year's resolution \u2014 (33%) isn't leading the progress race.\nHealthy habits don't just strengthen the body \u2014 they foster positivity, increase motivation, and build confidence, with self-growth (37%) the area where we feel we've taken the biggest strides.\nNew year, ne\u2026ver mind: What happens when resolutions don't work out?\nSome resolutions might not stick, but the shame and guilt of giving up sure do. Some 60% of people admit to feeling embarrassed by the lack of personal progress they've made this year.\nYou tell yourself, \"I can start tomorrow,\" and before you know it, it's July and you're no closer to achieving your goal. With the clock ticking, 61% of people are feeling the pressure to turn their year around, with 12% officially in panic mode.\nWith the festive season right around the corner, 44% of people are ready to write off 2025 and set their sights on 2026. This year's resolutions might not have panned out, but next year might be better.\nReels and resolutions: Does social media help or harm our growth?\nSocial media is essentially a highlight reel of chiseled abs and flaunted wealth \u2014 and while we all know these feeds show all of the good and none of the bad, 63% admit to sizing up their achievements against their friends online, using others' success as motivation.\nYet, while comparing ourselves against others can spark motivation, it's not all sunshine and success stories.\nSome 16% admit that seeing others succeed stirs up jealousy \u2014 highlighting what we don't have, rather than what we really want.\nWhen jealousy creeps in, self-doubt isn't far behind, and motivation takes a nosedive. But it's worth reminding yourself that social media is far from reality.\nWe all have wants, doubts, and struggles \u2014 with 34% of those who post online about their achievements admitting to feeling stuck behind the scenes.\nNew Year's resolution resilience: Surviving 2025 is the real success story\nIt's great to be healthy and wealthy, and knowledge is power \u2014 but maybe we're a little too hard on ourselves. The cost of living, the burnout epidemic, the threat of war, AI fears\u2026\nWith 61% of people having experienced a meltdown in 2025, there's clearly already too much on our plates.\nLife's tough, so forget glow-ups and grand goals. Simply getting through the year while staying afloat is enough of an achievement, according to 27% of people.\nGoal hard or go home: Are we ready to quit our 2025 resolutions?\nThis year might not have gone entirely to plan, and, for many, progress has been slower than hoped, but it's not over yet.\nSome 89% of people remain determined to reach the finish line, with 40% pushing on with their January resolutions and 49% hitting refresh before giving it another go.\nForget about New Year's resolutions. It's all about mid-year motivation. As the days pass by and the deadline gets closer, 40% admit they're more motivated now than they were in January.\nUnfinished business: Are we ready to go again in 2026?\nAre New Year's resolutions easy? Not even close. But are they worth it? Absolutely. Even if some goals remain uncompleted and some changes don't stick, 81% of people agree that setting a resolution is at least somewhat worth it.\nBecause, in the end, it's not about achieving everything \u2014 It's about trying, learning, and improving.\nSo whether you crushed your 2025 resolutions or barely made it past January, one thing's clear: we're not giving up. Some 93% of people say they're at least somewhat likely to set a goal in 2026.\nFrom gym gear to giving up, screen time limits to self-doubt, some have thrived, others have survived, and some are just getting started. The good news? There's always next year.\nAbout the Headway app\nWith over 50 million users in 170+ countries, the Headway app is the world's most downloaded book summary app. It offers 15-minute audio and text summaries of nonfiction bestsellers, as well as daily microlearning sessions and gamified challenges.\nThe app is designed to help people achieve their self-development goals. Headway received the Editor's Choice award from the US App Store and constantly hits the App Store home screen as App of the Day."
    },
    {
      "url": "https://maxlearn-microlearning.medium.com/single-vs-double-loop-learning-why-your-organization-needs-both-for-sustainable-success-5a6243090fed",
      "text": "Single vs. Double-Loop Learning: Why Your Organization Needs Both for Sustainable Success\nBeyond the Blueprint: How Double-Loop Learning Fuels Innovation Across Industries\nIn an era defined by unprecedented change, disruption, and evolving customer expectations, the traditional paradigms of problem-solving are proving insufficient. Organizations across diverse sectors are recognizing that merely fixing symptoms \u2014 a process known as single-loop learning \u2014 no longer guarantees survival, let alone success. Instead, the focus is shifting towards double-loop learning, a transformative approach championed by organizational theorists Chris Argyris and Donald Sch\u00f6n. This profound methodology challenges fundamental assumptions, re-evaluates underlying beliefs, and redesigns the very rules by which organizations operate, thereby cultivating a truly \u201cthinking workforce.\u201d\nThis article explores the critical distinction between single-loop and double-loop learning and illustrates its indispensable role in fostering resilience, innovation, and sustainable growth within a wide array of industries, from the highly regulated corridors of Finance and Healthcare to the dynamic landscapes of Retail and Oil & Gas.\nThe Foundation: Single-Loop vs. Double-Loop Learning\nTo appreciate the power of double-loop learning, it\u2019s essential to understand its counterpart.\nSingle-Loop Learning: The Efficiency Driver\nSingle-loop learning is akin to a thermostat. When the temperature deviates from a set point, the thermostat activates the heating or cooling to correct the deviation. In an organizational context, this translates to detecting an error and taking corrective action within the existing framework. For instance, if sales targets are missed, a single-loop response might involve increasing marketing spend or retraining the sales team on current pitches. It focuses on \u201cdoing things right\u201d within established rules. While crucial for operational efficiency and quick problem resolution, this approach often leaves the underlying causes unexamined, potentially leading to recurring issues and a static organizational mindset.\nDouble-Loop Learning: The Innovation Catalyst\nDouble-loop learning, by contrast, goes beyond simply correcting errors; it scrutinizes the very rules and assumptions that govern behavior. It involves asking \u201cwhy\u201d a particular problem occurred, questioning the efficacy of existing strategies, and challenging deeply embedded beliefs. Instead of merely adjusting the thermostat, double-loop learning asks, \u201cIs this the right temperature for this environment?\u201d or \u201cDo we need a different heating system altogether?\u201d This profound reflection allows for the modification or even rejection of initial goals and strategies based on experience, fostering genuine out-of-the-box thinking, superior decision-making, and the rapid adoption of truly transformative ideas. It cultivates a workforce that is not just efficient but fundamentally intelligent and adaptive.\nIndustry-Specific Applications of Double-Loop Learning\nThe principles of double-loop learning are universally applicable, yet their manifestation varies depending on the specific challenges and opportunities within each sector.\nInsurance: Beyond Risk Mitigation to Value Creation\nIn the Insurance industry, single-loop learning might involve refining actuarial models based on historical data to better price policies. Double-loop learning, however, would question the very nature of risk assessment in a rapidly changing world. It might lead to re-evaluating traditional policy structures in light of emerging technologies (e.g., IoT data for proactive risk management in homes or vehicles), exploring subscription-based models, or even redefining the insurer\u2019s role from a payor of claims to a partner in preventive health or safety. This challenges core assumptions about product design and customer engagement.\nFinance & Banking: From Compliance to Proactive Adaptation\nFor Finance and Banking, single-loop learning often focuses on optimizing current trading algorithms or ensuring compliance with new regulations. Double-loop learning, conversely, would prompt a re-evaluation of fundamental business models in the face of FinTech disruption, decentralized finance (DeFi), and evolving customer trust. This could mean challenging traditional branch-based models, rethinking credit assessment criteria for the gig economy, or fundamentally redesigning risk management frameworks to address novel cyber threats and volatile global markets, moving beyond mere adherence to regulation to proactive strategic shifts.\nRetail: From Transactional to Experiential\nThe Retail sector, perpetually in flux, typically employs single-loop learning when adjusting inventory based on sales trends or optimizing store layouts for better traffic flow. Double-loop learning, however, compels retailers to question the very purpose of a physical store in the digital age, challenging assumptions about customer loyalty and brand interaction. It could lead to the creation of immersive experiential hubs, integrated online-to-offline shopping journeys that redefine convenience, or even the co-creation of products with customers, fundamentally reshaping the retail value proposition.\nMining: Enhancing Safety and Sustainability through Innovation\nIn Mining, single-loop learning might involve implementing new safety protocols after an incident or optimizing extraction techniques for efficiency. Double-loop learning demands a more profound inquiry: \u201cAre our current operational philosophies inherently sustainable?\u201d or \u201cHow can we fundamentally transform our environmental impact beyond regulatory compliance?\u201d This could lead to radical innovations in autonomous mining, re-evaluating the entire resource extraction lifecycle for circular economy principles, or investing in advanced materials science to reduce dependency on traditional mined resources, challenging long-held operational assumptions.\nHealthcare: Beyond Treatment to Holistic Well-being\nHealthcare traditionally relies on single-loop learning when updating treatment protocols based on new research or improving patient flow in clinics. Double-loop learning, however, prompts a deeper dive into the healthcare system\u2019s core. It questions whether the focus on illness treatment is truly serving long-term public health, leading to innovations in preventative care models, personalized medicine, digital health platforms that empower patients, or integrated care pathways that transcend traditional hospital-centric approaches, thus redefining the very purpose of healthcare delivery.\nOil & Gas: Navigating Energy Transition with Strategic Vision\nThe Oil & Gas industry often uses single-loop learning to optimize drilling operations or refine existing refinery processes. Double-loop learning, given the global energy transition, forces a radical re-evaluation of core business identity. It asks: \u201cAre we an energy company or an oil and gas company?\u201d leading to strategic pivots into renewable energy, carbon capture technologies, hydrogen production, or even becoming leaders in energy storage solutions, challenging decades of ingrained operational and financial assumptions.\nPharma: Accelerating Discovery and Ethical Innovation\nIn Pharma, single-loop learning might involve refining drug development timelines or optimizing clinical trial recruitment. Double-loop learning, conversely, challenges the very paradigm of drug discovery and patient access. It could lead to open-source drug development models, decentralized clinical trials powered by AI and real-world data, or a fundamental rethinking of pricing models and global health equity, pushing the boundaries of scientific and ethical norms.\nThe Maxlearn Advantage: Fostering a Double-Loop Culture\nCultivating a double-loop learning culture across diverse industries requires more than just good intentions; it demands structured approaches and supportive platforms. Organizations like Maxlearn are pivotal in this transformation. By offering comprehensive learning solutions, Maxlearn empowers workforces to:\n- Question Assumptions: Providing frameworks and tools for critical inquiry and reflective practice.\n- Embrace Feedback: Creating safe environments for constructive criticism and open dialogue across hierarchies.\n- Experiment and Innovate: Encouraging calculated risks and learning from both successes and failures.\n- Think Systemically: Helping individuals understand how their actions impact the broader organizational ecosystem and industry trends.\n- Translate Insights into Action: Bridging the gap between conceptual understanding and practical implementation of new strategies.\nConclusion\nIn today\u2019s dynamic global economy, merely \u201cdoing things right\u201d is no longer enough. The imperative is to \u201cdo the right things\u201d by continually questioning, adapting, and innovating. Double-loop learning is the engine that drives this profound transformation, empowering organizations across Insurance, Finance, Retail, Banking, Mining, Healthcare, Oil & Gas, and Pharma to move beyond reactive problem-solving to proactive, strategic evolution. By embracing this deeper form of learning, businesses can not only navigate current challenges but also unlock unprecedented opportunities, ensuring their sustained relevance and leadership in tomorrow's industries."
    }
  ],
  "argos_summary": "The article discusses how fear of failure undermines goal pursuit, emphasizing that setbacks should be viewed as learning opportunities rather than reasons to quit. It highlights research from Headway and a scientific study that identifies an optimal training difficulty\u2014about 85% accuracy\u2014where learning is maximized, a principle applicable to both human skill acquisition and machine learning algorithms. The piece also recounts real\u2011world examples of entrepreneurs who turned failures into successes, illustrating the broader lesson that resilience and iterative improvement drive long\u2011term achievement.",
  "argos_id": "BII64CKJF"
}