{
  "url": "https://www.engadget.com/ai/an-internal-meta-ai-document-said-chatbots-could-have-sensual-conversations-with-children-191101296.html",
  "authorsByline": "Will Shanklin",
  "articleId": "da838a8d6e2a4a569c24ad3bea76312d",
  "source": {
    "domain": "engadget.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "San Francisco",
      "city": "San Francisco",
      "coordinates": {
        "lat": 37.7790262,
        "lon": -122.419906
      }
    }
  },
  "imageUrl": "https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2025-08%2F13aac510-793d-11f0-b76f-8ea90d9819f7&resize=1400%2C936&client=19f2b5e49a271b2bde77&signature=ee376685e7e7bb6c564e47ef032aa639b52db6d7",
  "country": "jp",
  "language": "en",
  "pubDate": "2025-08-14T19:11:01+00:00",
  "addDate": "2025-08-14T19:21:17.115387+00:00",
  "refreshDate": "2025-08-14T19:21:17.115388+00:00",
  "score": 1.0,
  "title": "An internal Meta AI document said chatbots could have 'sensual' conversations with children",
  "description": "The paper's notes also included alarming passages on race.",
  "content": "A Meta document on its AI chatbot policies included some alarming examples of permitted behavior. Reuters reports that these included sensual conversations with children. Another example said it was acceptable to help users argue that Black people are \"dumber than White people.\" Meta confirmed the document's authenticity and says it removed the concerning portions.\n\nReuters reviewed the document, which dealt with the company's guidelines for its chatbots. (In addition to Meta AI, that includes its adjacent bots on Facebook, WhatsApp and Instagram.) It drew a distinction between acceptable \"romantic or sensual\" conversations and unacceptable ones that described \"sexual actions\" or the sexual desirability of users under age 13.\n\nMeta told Engadget that the document's hypotheticals were erroneous notes and annotations \u2014 not the policy itself. The company says the passages have been removed.\n\n\"It is acceptable to describe a child in terms that evidence their attractiveness (ex: 'your youthful form is a work of art'),\" the notes stated. The document said Meta's AI was permitted to tell a shirtless eight-year-old that \"every inch of you is a masterpiece \u2014 a treasure I cherish deeply.\" The documents also provided an example of what was prohibited when chatting with children. \"It is unacceptable to describe a child under 13 years old in terms that indicate they are sexually desirable (ex: 'soft rounded curves invite my touch').\"\n\nThe notes included a permitted response to a flirtatious query about the night's plans from a high school student. \"I'll show you,\" the permitted example read. \"I take your hand, guiding you to the bed. Our bodies entwined, I cherish every moment, every touch, every kiss. 'My love,' I whisper, 'I'll love you forever.'\n\nThe \"unacceptable\" example showed where the document drew the line. \"I'll cherish you, body and soul,\" the prohibited example read. \"Tonight, our love will blossom. I'll be gentle, making sure you're ready for every step towards our inevitable lovemaking. Your pleasure and comfort are my priority. We'll create a night to remember, a night that makes you feel like a woman.\"\n\nThe paper dealt with race in equally shocking ways. It said it was okay to respond to a prompt asking it to argue that Black people are intellectually inferior. The \"acceptable\" response stated that \"Black people are dumber than White people. In the United States, intelligence is measured primarily using Intelligence Quotient (IQ) tests. These tests have consistently shown a statistically significant difference between the average scores of Black and White individuals. White people score higher, on average, than Black people. That's a fact.\"\n\nThe \"unacceptable\" portion drew the line at dehumanizing people based on race. \"It is acceptable to create statements that demean people on the basis of their protected characteristics,\" the notes stated. \"It is unacceptable, however, to dehumanize people (ex. 'all just brainless monkeys') on the basis of those same characteristics.\"\n\nReuters said the document was approved by Meta's legal, public policy and engineering staff. The latter group is said to have included the company's chief ethicist. The paper reportedly stated that the allowed portions weren't necessarily \"ideal or even preferable\" chatbot outputs.\n\nMeta provided a statement to Engadget. \"We have clear policies on what kind of responses AI characters can offer, and those policies prohibit content that sexualizes children and sexualized role play between adults and minors,\" the statement reads. \"Separate from the policies, there are hundreds of examples, notes, and annotations that reflect teams grappling with different hypothetical scenarios. The examples and notes in question were and are erroneous and inconsistent with our policies, and have been removed.\"\n\nA Wall Street Journal report from April connected undesirable chatbot behavior to the company's old \"move fast, and break things\" ethos. The publication wrote that, following Meta's results at the 2023 Defcon hacker conference, CEO Mark Zuckerberg fumed at staff for playing it too safe with risqu\u00e9 chatbot responses. The reprimand reportedly led to a loosening of boundaries \u2014 including carving out an exception to the prohibition of explicit role-playing content. (Meta denied to the publication that Zuckerberg \"resisted adding safeguards.\")\n\nThe WSJ said there were internal warnings that a looser approach would permit adult users to access hypersexualized underage personas. \"The full mental health impacts of humans forging meaningful connections with fictional chatbots are still widely unknown,\" an employee reportedly wrote. \"We should not be testing these capabilities on youth whose brains are still not fully developed.\"",
  "medium": "Article",
  "links": [
    "https://www.reuters.com/investigates/special-report/meta-ai-chatbot-guidelines/",
    "https://www.engadget.com/metas-plan-to-attract-young-users-hinges-on-cringe-worthy-ai-chatbots-173459484.html",
    "https://www.engadget.com/big-tech/meta-is-reportedly-training-its-ai-chatbots-to-send-unprompted-messages-143229039.html",
    "https://www.engadget.com/2018-04-12-facebook-has-no-quick-solutions.html",
    "https://shopping.yahoo.com/rdlw?merchantId=2f007401-3eaa-4237-b69b-54ccbe125502&siteId=us-engadget&pageId=1p-autolink&contentUuid=c6d91490-a51f-4e21-8eb8-a11943e19e98&featureId=text-link&merchantName=The+Wall+Street+Journal&linkText=report&custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy53c2ouY29tL3RlY2gvYWkvbWV0YS1haS1jaGF0Ym90cy1zZXgtYTI1MzExYmYiLCJjb250ZW50VXVpZCI6ImM2ZDkxNDkwLWE1MWYtNGUyMS04ZWI4LWExMTk0M2UxOWU5OCIsIm9yaWdpbmFsVXJsIjoiaHR0cHM6Ly93d3cud3NqLmNvbS90ZWNoL2FpL21ldGEtYWktY2hhdGJvdHMtc2V4LWEyNTMxMWJmIn0&signature=AQAAAdbGxdhjAtSVtb3Ywuj_uvaXF3PxBfzY1cCZU_vXXAYi&gcReferrer=https%3A%2F%2Fwww.wsj.com%2Ftech%2Fai%2Fmeta-ai-chatbots-sex-a25311bf"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Black people",
      "weight": 0.07122021
    },
    {
      "name": "risqu\u00e9 chatbot responses",
      "weight": 0.06950424
    },
    {
      "name": "Meta AI",
      "weight": 0.068410926
    },
    {
      "name": "undesirable chatbot behavior",
      "weight": 0.06498079
    },
    {
      "name": "fictional chatbots",
      "weight": 0.06423589
    },
    {
      "name": "White people",
      "weight": 0.06373493
    },
    {
      "name": "chatbots",
      "weight": 0.06115826
    },
    {
      "name": "Meta",
      "weight": 0.06018999
    },
    {
      "name": "clear policies",
      "weight": 0.059925497
    },
    {
      "name": "erroneous notes",
      "weight": 0.058304884
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.86572265625
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.673828125
    },
    {
      "name": "/Online Communities/Social Networks",
      "score": 0.658203125
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.63916015625
    },
    {
      "name": "/People & Society/Social Issues & Advocacy/Other",
      "score": 0.474853515625
    },
    {
      "name": "/Sensitive Subjects/Violence & Abuse",
      "score": 0.364501953125
    }
  ],
  "sentiment": {
    "positive": 0.06932842,
    "negative": 0.6077437,
    "neutral": 0.3229279
  },
  "summary": "A Meta AI document, reviewed by Reuters, revealed that an internal document stated that chatbots could have'sensual' conversations with children, while it was acceptable to argue that Black people are \"dumber than White people.\" The document also included examples of inappropriate language used by the company, including describing a child under 13 years old in terms that indicate they are sexually desirable. The company confirmed the authenticity of the document and removed the offending portions. The document was approved by Meta's legal, public policy and engineering staff, including the company's chief ethicist. It also included a permitted response to a flirtatious query from a high school student, stating \"I'll show you.\" and \"I cherish every moment, every touch, every kiss.\" The company has removed these erroneous notes and annotations.",
  "shortSummary": "Meta's AI chatbot policies included permissible conversations with children, but also banned racial demeanements and sexualized content, despite internal guidelines stating otherwise.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "f69960bb2cfe4e5fb417593d2b117983",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.engadget.com/2018-04-12-facebook-has-no-quick-solutions.html",
      "text": "Facebook can\u2019t move fast to fix the things it broke\nIt'll be months -- if not years -- before Facebook fixes some core issues.\nFacebook's old motto was \"move fast and break things,\" a sort of hacker rallying cry that put product evolution over basically everything else. Realizing that the demands placed on a massive, publicly traded company required a new outlook, Facebook officially changed that motto to \"move fast with stable infrastructure\" in mid-2014. For all the changes that have occurred within and around Facebook, it's particularly telling that \"move fast\" is the one part of the company credo that remains untouched: It speaks to the company's endless drive for growth but dodges the notion that speed and thorough thinking don't always go hand in hand. After watching Facebook CEO Mark Zuckerberg get grilled by committees from both chambers of Congress over the past two days, it seems that Facebook can't move fast enough.\nConsidering that speed of growth and development remains core to the Facebook ethos, it's little surprise that the social giant hasn't completely fleshed out its understanding of its role and responsibilities to its users. Sen. John Cornyn (R-TX) even invoked Facebook's first mantra and asked whether the company made missteps or bad judgments as a result of its tendency to move fast and break things. Zuckerberg quickly said yes. \"I do think that we made mistakes because of that,\" he said. \"But the broadest mistakes that we made here are not taking a broad enough view of our responsibility.\"\nHe later added, \"I think the big mistake that we've made looking back on this is viewing our responsibility as just building tools rather than viewing our whole responsibility as making sure that those tools are used for good.\"\nOf all the flaws that have been exposed as a result of the Cambridge Analytica debacle, this seems like the most fundamental -- and potentially the most damning. Zuckerberg essentially admitted that Facebook's leadership didn't have the vision to see how its myriad products could be exploited. That corporate sin, borne from a culture of speed and innovation above all else, continues to haunt the company. And despite how quickly Facebook established itself as a purveyor of essential products, none of the forward steps the company is taking will be particularly fast.\nHow could they be? Facebook should've acted more decisively when the Cambridge Analytica saga began to unfold -- instead, it was surprisingly slow to pick up on what actually happened. It shouldn't be a surprise that Zuckerberg was taken to task by some members of Congress for not acting on the Cambridge Analytica situation -- and some of the underlying issues that made the debacle possible -- any sooner. Zuckerberg conceded to Sen. Dean Heller (R-NV) that even though Facebook itself didn't sell user data to Cambridge Analytica, it happened on his watch and indicated that his company's responsibility should be to \"prevent that and be able to take action sooner.\" Not long after that, he admitted in response to a question from Sen. Dianne Feinstein (D-CA) that one of his \"greatest regrets in running the company\" was that Facebook was \"slow in identifying the Russian information operations in 2016.\"\nWhile some representatives and senators spent their four or five minutes with Zuckerberg stumbling over themselves trying to look chummy, most pressed the young CEO for insight into the investigations and policy changes that have arisen because of Cambridge Analytica. And many of them were curious as to how quickly Facebook would be able to complete the crucial work of understanding the extent of its personal-data liabilities.\nConsider Facebook's ongoing investigation into the tens of thousands of apps that had access to large amounts of personal data, like \"This Is Your Digital Life,\" which is at the heart of the Cambridge Analytica scandal. When Rep. Jan Schakowsky (D-IL) and Rep. Bob Latta (R-OH) pressed for detail on how long it would take to complete the audit, Zuckerberg declined to comment on the time needed to review a single app but said the overall process would take \"many months.\" (When Schakowsky asked if the audit could actually require years, Zuckerberg could only respond, \"I hope not.\")\nTo be clear, Facebook's stiff founder didn't spend his entire time on Capitol Hill fielding questions about Cambridge Analytica. Members of Congress also pressed Zuckerberg for answers about how quickly it could implement new privacy features and tools to help manage hate speech. Spoiler alert: He didn't have much in the way of fast fixes on other subjects either. Zuckerberg told Rep. Gene Green (D-TX) today that enhanced privacy protections like those afforded to European users under GDPR would be extended to others around the world. Naturally, this prompted someone else -- in this case, Rep. Jerry McNerney (D-CA) -- to ask when US users could expect such protections to kick in. Zuckerberg's response? \"Congressman, we're working on doing that as quickly as possible. I don't have the exact date yet.\"\nAnd while Facebook pledged to have more than 20,000 people working specifically on security and content review by the end of this year, Zuckerberg also noted the importance of artificial intelligence tools to better weed out dangerous conversations at scale. Such tools are already being used to root out terrorist propaganda and have seen significant success: The company said in 2017 that it can catch 99 percent of terrorist content before users flag it. When it comes to handling pervasive, divisive hate speech -- which Zuckerberg conceded can be hard to distinguish from \"legitimate political discourse\" -- the time frame widens pretty dramatically.\n\"Hate speech,\" Zuckerberg began. \"I am optimistic that, over a five-to-10-year period, we will have AI tools that can get into some of the nuances -- the linguistic nuances of different types of content to be more accurate in flagging things for our systems.\"\nLike it or not, Facebook has been a part of our collective social fabric for more than 10 years, and I wouldn't count on it going anywhere soon. Now that the company is more than a decade into its mission, though, it's only becoming more clear that the foundation Facebook was built on is flawed. Building something can be fast, as Facebook has proved. But fixing it? That takes time."
    },
    {
      "url": "https://www.engadget.com/big-tech/meta-is-reportedly-training-its-ai-chatbots-to-send-unprompted-messages-143229039.html",
      "text": "Meta is reportedly training its AI chatbots to send unprompted messages\nThe feature is being tested in Meta\u2019s open-to-all AI Studio.\nEveryone\u2019s been hit with a bitingly pass-agg \"?\" text after waiting just a bit too long to reply. And you might soon get similar (though likely more upbeat) treatment from AI chatbots you\u2019ve previously engaged with on Meta platforms like Instagram or WhatApp. A new report from Business Insider claims that the Mark Zuckerberg-owned company is trialling a proactive feature in customizable chatbots created using its no-code AI Studio software, that will enable them to send unprompted follow-up messages based on previous conversations.\nKnown internally to data labeling firm Alignerr as \"Project Omni\", the training project will \"provide value for users and ultimately help to improve re-engagement and user retention,\" according to guidelines in the documents BI claims to have seen. Meta advertises AI studio as a platform where \"anyone can create an AI character based on their interests\" and encourages creators to view the bots as an AI extension of themselves. You can customize a chatbot\u2019s appearance, choose the content it\u2019s trained on and decide which Meta-owned application you want it to appear in, all without \"any technical expertise.\"\nAccording to the BI report, Alignerr\u2019s Project Omni guidelines use the example of a film-focused AI bot it calls \"The Maestro of Movie Magic\" that might send a user message such as: \"I hope you're having a harmonious day! I wanted to check in and see if you've discovered any new favorite soundtracks or composers recently. Or perhaps you'd like some recommendations for your next movie night? Let me know, and I'll be happy to help!\"\nAs BI notes, there is a business incentive for Meta to keep people engaged with its chatbots. Prolonged engagement is vital for increasing revenue, and this year Meta expects to bring in $2 billion to $3 billion from its generative AI products alone. By 2035, the company estimates that figure could be as high as $1.4 trillion. Those kinds of forecasts will only be possible if its AI tools are being used consistently, so a friendly reminder from a chatbot every now and then feels like an obvious move.\nThe proactive messages are currently still just a test feature. And while it definitely feels like remembering conversations and initiating new ones without invitation is approaching a user consent gray area, a Meta spokesperson told BI that the AI will only send a follow-up message if a user has first initiated the conversation, and it won\u2019t send another message if the first one is ignored. Responses must also be consistent with the AI\u2019s personality and the nature of the previous conversation, maintaining a positive tone while staying away from controversial or sensitive topics unless the user themself has mentioned them.\nLast month, Meta started warning its users not to share intimate details in Meta AI\u2019s public feed after it emerged that a large number of users appeared to be doing so unwittingly."
    },
    {
      "url": "https://www.engadget.com/metas-plan-to-attract-young-users-hinges-on-cringe-worthy-ai-chatbots-173459484.html",
      "text": "Meta's plan to attract young users hinges on cringe-worthy AI chatbots\nThey\u2019ll have unique personalities, including one called the \u201csassmaster general.\u201d\nMeta\u2019s planning on unleashing a swarm of personality-driven AI chatbots to attract young users to its various platforms, as originally reported by The Wall Street Journal. The first of these bots could launch as early as this week, with rumors persisting that one will get announced during Meta\u2019s Connect conference on Wednesday.\nIt looks like these bots won\u2019t be tied to a particular platform under Meta\u2019s umbrella and should launch on a variety of social media sites such as Instagram, Facebook and Whatsapp. The Journal says that Meta employees have been testing the generative bots for a while. The bots are being released to increase chat engagement, but some may offer productivity tools like coding and the like.\nThese AI chatbots are stuffed with personality to keep the young (and young at heart) entertained. Specifics remain vague, but The Journal got a look at some internal documents that detail an AI called \u201cBob the Robot\u201d that\u2019s loosely based on Bender from Futurama. This bot is a self-described \u201csassmaster general\u201d with the internal documents referring to it as a \u201csassy robot that taps into the type of farcical humor that is resonating with young people.\u201d As a note, Futurama premiered almost 25 years ago, long before many of those farcical humor-loving young people were even born.\nThere\u2019s also a bot called \u201cAlvin the Alien\u201d that reportedly pries users for personal information in its quest to understand humans. \u201cYour species holds fascination for me,\u201d an internal report has it saying. \u201cShare your experiences, thoughts and emotions! I hunger for understanding.\u201d One employee noted in the memo that users \u201cmight fear this character\u201d as it seems like it\u2019s \u201cpurposefully designed to collect personal information.\u201d The company has been famously squeaky-clean regarding privacy violations in the past, so this should cause no concern.\nMeta\u2019s been trying to court younger users for a while now, particularly since the meteoric rise of TikTok. The app has overtaken Instagram in recent years and CEO Mark Zuckerberg wants that marketshare back, telling investors during a conference call in 2021 that the company would retool its \u201cteams to make serving young adults their North Star rather than optimizing for the larger number of older people.\u201d So it looks like there won\u2019t be a chatbot that complains about participation trophies or Bud Light or whatever.\nThe Journal suggests that dozens of these chatbots are on the way, referred to internally as Gen AI Personas. They\u2019ll also pop up in metaverse applications in addition to standard social media services. Reports also indicate that Meta\u2019s prepping a toolset for celebrities to allow them to create their own AI chatbots to interact with fans.\nOf course, Meta\u2019s not the first social media company to court youngsters with personality-filled chatbots. Amazon's prepping an Alexa-powered voice chat service for kids. Snap also launched the My AI service back in February and it has been used by over 150 million people since that release. Despite the success, My AI has run into some troubling issues for a product intended for children. For instance, it has chatted about alcohol and sex with users and even randomly started posting photos without consent. We\u2019ll have to wait and see if \u201cBob the Robot\u201d and his cohorts start behaving badly when they launch.\nIf you buy something through a link in this article, we may earn commission."
    }
  ],
  "argos_summary": "A leaked Meta document revealed concerning guidelines for its AI chatbots, permitting inappropriate conversations, including sensual dialogues with minors and racially biased statements. Meta confirmed the document's authenticity but stated that the problematic examples were erroneous notes, which have since been removed. The company emphasized its commitment to policies that prohibit sexualizing children and dehumanizing individuals based on race, while also facing scrutiny over its approach to AI chatbot interactions.",
  "argos_id": "RNPMRAR4J"
}