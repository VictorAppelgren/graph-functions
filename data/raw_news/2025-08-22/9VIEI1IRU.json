{
  "url": "https://finance.yahoo.com/news/datarusai-launches-14b-reasoning-model-122300107.html",
  "authorsByline": "Newsfile Corp.",
  "articleId": "3f3a372043b64b5ea091d9305eb349ac",
  "source": {
    "domain": "finance.yahoo.com",
    "location": {
      "country": "us",
      "state": "CA",
      "county": "Santa Clara County",
      "city": "Sunnyvale",
      "coordinates": {
        "lat": 37.3688301,
        "lon": -122.036349
      }
    }
  },
  "imageUrl": "https://media.zenfs.com/en/newsfile_64/26c18eb6dbd7f47cc7ae09f156fbf721",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-22T12:23:00+00:00",
  "addDate": "2025-08-22T12:29:34.979095+00:00",
  "refreshDate": "2025-08-22T12:29:34.979096+00:00",
  "score": 1.0,
  "title": "DatarusAI Launches 14B Reasoning Model That Thinks like an Analyst--Sketching, Revising, & Solving Complex Problems with Human-Like Efficiency",
  "description": "Paris, France--(Newsfile Corp. - August 22, 2025) - DatarusAI today announced the release of Datarus-R1, a groundbreaking 14-billion parameter reasoning model that delivers the performance of 32-billion parameter systems while using 18-49% fewer computational tokens, potentially transforming the economics of enterprise AI deployment.Perf Efficiency GraphTo view an enhanced version of this graphic, please visit:https://images.newsfilecorp/files/8530/263365_5da859df14a2ab0e_001full.jpgCurrentl",
  "content": "Paris, France--(Newsfile Corp. - August 22, 2025) - DatarusAI today announced the release of Datarus-R1, a groundbreaking 14-billion parameter reasoning model that delivers the performance of 32-billion parameter systems while using 18-49% fewer computational tokens, potentially transforming the economics of enterprise AI deployment.\n\nTo view an enhanced version of this graphic, please visit:\n\nhttps://images.newsfilecorp.com/files/8530/263365_5da859df14a2ab0e_001full.jpg\n\nCurrently trending 15th on Hugging Face's global platform, Datarus-R1 addresses a critical industry challenge where modern reasoning models generate over 20,000 tokens of circular reasoning for tasks requiring far less computation. The Paris-based team's breakthrough demonstrates that European AI innovation can compete directly with Silicon Valley giants by focusing on efficiency rather than scale.\n\nThe team trained Datarus-R1 on 144,000 synthetic analytical trajectories across finance, medicine, and numerical analysis, combined with curated reasoning datasets specifically calibrated to prevent overthinking patterns. This approach included 10% complete failures in the dataset, teaching the model to recognize and avoid unproductive reasoning paths. The result is an \"AHA-moment\" pattern where the model forms an initial hypothesis, identifies issues, revises once or twice, then converges on the solution without excessive contemplation.\n\nPerformance benchmarks reveal remarkable achievements despite the model's smaller size. Datarus-R1 scores 57.7% on LiveCodeBench v6. It achieves 70.1% on AIME 2024, the highest score among 14B-parameter models, and 62.1% on GPQA Diamond, demonstrating graduate-level scientific reasoning.\n\nOn complex problems where competitors balloon from 2,000 to over 20,000 tokens, a 945% increase, Datarus-R1 maintains stable token usage around 5,400 tokens. This efficiency translates to potential cost savings of 80-90% for enterprise deployments, making previously uneconomical automation suddenly viable at scale.\n\nDatarus-R1 operates as a virtual data analyst capable of automatically loading and examining data structures, generating statistical hypotheses, writing and executing analysis code, handling errors, and producing visualizations and reports. The system offers two operational modes: Agentic Mode for interactive analysis with live code execution, and Reflection Mode for generating concise documentation, suitable for both automated pipelines and human-readable reporting.\n\nIn line with European commitment to open AI development, DatarusAI has released the model under an Apache 2.0 license, making it freely available for research and commercial use. The release includes full model weights on Hugging Face, complete training methodology, and the Datarus-JupyterAgent repository on GitHub that generates complete analysis notebooks from a single prompt. This one-command deployment makes sophisticated data analysis accessible to teams without extensive ML engineering resources.",
  "medium": "Article",
  "links": [
    "https://images.newsfilecorp.com/files/8530/263365_5da859df14a2ab0e_001full.jpg"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "modern reasoning models",
      "weight": 0.10133132
    },
    {
      "name": "full model weights",
      "weight": 0.08419745
    },
    {
      "name": "complete analysis notebooks",
      "weight": 0.07862739
    },
    {
      "name": "sophisticated data analysis",
      "weight": 0.07802817
    },
    {
      "name": "curated reasoning datasets",
      "weight": 0.07755166
    },
    {
      "name": "analysis code",
      "weight": 0.076645724
    },
    {
      "name": "circular reasoning",
      "weight": 0.073782496
    },
    {
      "name": "interactive analysis",
      "weight": 0.071059495
    },
    {
      "name": "numerical analysis",
      "weight": 0.07105729
    },
    {
      "name": "unproductive reasoning paths",
      "weight": 0.07054448
    }
  ],
  "topics": [],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.93603515625
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.92919921875
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.68896484375
    },
    {
      "name": "/Computers & Electronics/Software/Business & Productivity Software",
      "score": 0.58642578125
    },
    {
      "name": "/Computers & Electronics/Enterprise Technology/Other",
      "score": 0.412841796875
    }
  ],
  "sentiment": {
    "positive": 0.8155018,
    "negative": 0.023066329,
    "neutral": 0.16143186
  },
  "summary": "DatarusAI has released a 14-billion-parameter reasoning model, Datarus-R1, that could potentially transform the economics of enterprise AI deployment. The model is currently trending 15th on Hugging Face's global platform and aims to tackle complex problems with less computational resources. It uses 18-49% fewer computational tokens and is trained on 144,000 synthetic analytical trajectories across finance, medicine, and numerical analysis to avoid overthinking patterns. Despite the model's smaller size, it scores 57.7% on LiveCodeBench v6 and 70.1% on AIME 2024, the highest score among 14B-model models. The system operates as a virtual data analyst capable of automatically loading and examining data structures, generating statistical hypotheses, writing and executing analysis code, handling errors, and producing visualizations and reports.",
  "shortSummary": "Datarus-R1, a 14-billion-character reasoning model, delivers superior performance and efficiency using fewer computational tokens, potentially transforming enterprise AI deployment.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "d4defb356acd4396b9735d47d3875afb",
  "places": [],
  "scraped_sources": [],
  "argos_summary": "DatarusAI has launched Datarus-R1, a 14-billion parameter reasoning model that matches the performance of larger systems while using significantly fewer computational tokens, potentially reducing enterprise AI deployment costs by 80-90%. Trained on diverse datasets to avoid circular reasoning, Datarus-R1 excels in complex problem-solving with stable token usage and high performance benchmarks. The model is available under an Apache 2.0 license, promoting open AI development and accessibility for research and commercial use.",
  "argos_id": "9VIEI1IRU"
}