{
  "url": "https://appleinsider.com/articles/25/08/11/airpods-could-soon-get-live-translation-ios-26-beta-code-suggests",
  "authorsByline": "Marko Zivkovic",
  "articleId": "a9383185cafb41418c25c05f9ae6ad80",
  "source": {
    "domain": "appleinsider.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "Santa Clara County",
      "city": "Cupertino",
      "coordinates": {
        "lat": 37.3228934,
        "lon": -122.0322895
      }
    }
  },
  "imageUrl": "https://photos5.appleinsider.com/gallery/64692-134790-62965-130712-62801-130316-62417-129368-61404-126856-60788-125128-60675-124869-AirPods-Pro-2-stems-xl-xl-(1)-xl-(1)-xl-xl-xl-(1)-xl.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-11T22:56:58+00:00",
  "addDate": "2025-08-11T22:59:57.120386+00:00",
  "refreshDate": "2025-08-11T22:59:57.120388+00:00",
  "score": 1.0,
  "title": "AirPods could get Live Translation, iOS 26 beta code suggests",
  "description": "Apple's iconic AirPods may gain the Live Translation feature, as iOS 26 beta code already contains a gesture related to the functionality.",
  "content": "Apple's iconic AirPods may gain the Live Translation feature, as iOS 26 beta code already contains a gesture related to the functionality.\n\nRumors as far back as March 2025 have suggested AirPods would be able to translate in-person conversations from one language to another. While the iPhone maker announced Live Translation back in June, during WWDC 2025, the feature is still nowhere to be found on AirPods.\n\nCurrently, Live Translation works in calls and Messages with Apple Intelligence-compatible iPhones, but the company's AirPods still can't translate real-world conversations. Apple has never announced that the feature would be available with any AirPods model.\n\nThat could soon change, however, as a newly discovered gesture suggests Apple is working on introducing the feature to the AirPods Pro 2 and AirPods 4. According to 9to5Mac , iOS 26 beta 6 contains a new system asset, one that features a gesture activated by pressing both AirPod stems simultaneously.\n\nApple's AirPods Pro 2 have received new features via software updates in the past, so it makes sense for Apple to go this route with its Live Translation feature. The AirPods Pro 2 previously gained Hearing Health features, which offer hearing aid and hearing test functionality approved by the FDA.\n\nIf Apple ultimately decides to implement Live Translation for AirPods, it'll more than likely only be available with devices that already support the feature. This means you'll probably need an iPhone 15 Pro or newer, an Apple Intelligence-compatible iPad, or a Mac with an M1 or newer Apple Silicon chip.\n\nCurrently, the Live Translation feature can immediately translate text into other languages as you type out a message in iMessage. As texts in other languages come in, the Apple Intelligence feature can instantly translate them for you.\n\nLive Translation doesn't work with AirPods at the time of writing, though. Apple's Translate app has a conversation feature, but it's more clunky than a direct translation feature in AirPods.\n\nWhen Live Translation was unveiled, Apple said that the new feature works seamlessly across its first-party apps, even if the person you're talking to isn't using an iPhone. The company also previously announced a Call Translation API for developers to use in third-party apps.\n\nSamsung already has its own Live Translate feature, which is available with OneUI version 6.1 or later. Google's Pixel Buds offer virtually the same functionality through a dedicated Conversation Mode, yet Apple's AirPods still lack Live Translation support.\n\nWhether or not Apple will announce the debut of Live Translation on AirPods remains to be seen. The company has scrapped and renamed various projects over the years, so there's always a chance it won't be released at all.",
  "medium": "Article",
  "links": [
    "https://appleinsider.com/inside/iphone-15-pro",
    "https://support.google.com/googlepixelbuds/answer/7573100?hl=en",
    "https://appleinsider.com/inside/translate",
    "https://appleinsider.com/articles/24/06/19/heres-which-features-apple-changed-ahead-of-their-wwdc-2024-debut",
    "https://appleinsider.com/inside/iphone",
    "https://appleinsider.com/articles/25/08/11/new-ringtones-and-app-launch-speed-up-whats-new-in-ios-26-beta-6",
    "https://appleinsider.com/articles/24/10/24/airpods-pro-2-receive-support-for-hearing-health-features-with-new-firmware-update",
    "https://appleinsider.com/inside/mac",
    "https://appleinsider.com/inside/m1",
    "https://www.samsung.com/us/support/answer/ANS10000935/",
    "https://appleinsider.com/inside/airpods-pro-2",
    "https://appleinsider.com/inside/ipad",
    "https://appleinsider.com/inside/apple-silicon",
    "https://appleinsider.com/inside/wwdc",
    "https://appleinsider.com/inside/imessage",
    "https://appleinsider.com/articles/25/06/09/apple-brings-live-translation-to-imessage-phone-calls-and-more",
    "https://9to5mac.com/2025/08/11/ios-26-beta-hints-at-upcoming-airpods-live-translation-gesture/",
    "https://appleinsider.com/articles/25/07/15/airpods-pro-2-hearing-support-goes-global-with-wider-rollout",
    "https://appleinsider.com/articles/25/06/06/apple-intelligence-translation-for-users-new-ai-tools-for-developers-coming-at-wwdc",
    "https://appleinsider.com/inside/apple-intelligence",
    "https://appleinsider.com/inside/airpods",
    "https://appleinsider.com/articles/24/09/12/fda-approves-airpods-pro-2-hearing-aid-features",
    "https://appleinsider.com/articles/24/07/09/an-exclusive-real-world-look-at-the-haptic-buttons-apple-developed-for-the-iphone-15-pro",
    "https://forums.appleinsider.com/discussion/239583/your-existing-airpods-could-gain-a-new-live-translation-feature-in-ios-19"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Live Translation",
      "weight": 0.12982394
    },
    {
      "name": "new features",
      "weight": 0.12319854
    },
    {
      "name": "Live Translation support",
      "weight": 0.121683605
    },
    {
      "name": "Apple Intelligence",
      "weight": 0.11016562
    },
    {
      "name": "newer Apple Silicon chip",
      "weight": 0.10669456
    },
    {
      "name": "Hearing Health features",
      "weight": 0.103723325
    },
    {
      "name": "Apple",
      "weight": 0.10220865
    },
    {
      "name": "AirPods",
      "weight": 0.1017298
    },
    {
      "name": "Live Translate",
      "weight": 0.09752831
    },
    {
      "name": "its Live Translation feature",
      "weight": 0.0893763
    }
  ],
  "topics": [
    {
      "name": "Electronics"
    },
    {
      "name": "AirPods"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/Computers & Electronics/Software/Operating Systems",
      "score": 0.93115234375
    },
    {
      "name": "/News/Technology News",
      "score": 0.916015625
    },
    {
      "name": "/Internet & Telecom/Mobile & Wireless/Mobile Phones",
      "score": 0.8203125
    },
    {
      "name": "/Shopping/Consumer Resources/Product Reviews & Price Comparisons",
      "score": 0.50244140625
    }
  ],
  "sentiment": {
    "positive": 0.23106857,
    "negative": 0.17179422,
    "neutral": 0.5971372
  },
  "summary": "Apple's AirPods may be introduced with the Live Translation feature, as iOS 26 beta code contains a gesture activated by pressing both AirPod stems simultaneously. Currently, Live Translation can only be used in calls and Messages with Apple Intelligence-compatible iPhones. However, this could change if Apple chooses to implement the feature on any AirPod model. If implemented, it will likely require devices that already support Live Translation. The feature will also be available for third-party apps.",
  "shortSummary": "Apple's AirPods may soon feature Live Translation, allowing real-time translations, but only if Apple Intelligence-compatible devices are available.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "ec262303402b4783abc34c1e1046698e",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://appleinsider.com/articles/25/08/11/new-ringtones-and-app-launch-speed-up-whats-new-in-ios-26-beta-6",
      "text": "The sixth developer beta of iOS 26 has arrived, and it introduces an onboarding sequence, along with six additional iPhone ringtones. Here's what's new.\nOn Monday, a week after the debut of the fifth developer beta, Apple released iOS 26 developer beta 6. The update increments the build number to 23A5318c, up from the previous 23A5308g.\nAs a whole, the iOS 26 update introduced a variety of meaningful upgrades, including improvements to Image Playground, Shortcuts, and new features for the Messages and Phone apps.\nAlong with a dedicated Games app, Apple unveiled a Foundation Models framework that lets developers utilize Apple Intelligence tools in third-party apps, while Visual Intelligence now supports screenshots. Some of these enhancements are ideal for creative work on iPhone, while others are arguably better for business users.\nStill, iOS 26 is largely known for its controversial \"Liquid Glass\" design language, which is used across all of the company's platforms. The software features dynamic user interface elements that mimic the look of real-world glass, replacing the flat aesthetic used from iOS 7 through iOS 18.\nThe sixth developer beta of iOS 26 builds upon the design choices introduced in prior releases through updates to animations and UI elements. There's even a new sequence detailing the most noteworthy changes of iOS 26.\nNew intro sequence and improved app animations\nMonday's developer beta features an entirely new onboarding sequence. Through a series of animated splash screens, Apple details the key changes within iOS 26, namely its \"Liquid Glass\" design language.\nThe macOS Tahoe beta got a similar onboarding video, along with an updated splash screen for the Photos app.\nThe intro sequence highlights the customization options of iOS 26, as well as the dynamic user interface elements that were introduced as part of the \"Liquid Glass\" redesign. Apple also emphasizes how iOS 26 makes searching within apps significantly easier through UI changes.\nWith iOS 26 developer beta 6, Apple altered the animations used when applications are launched. The new animations are imperceptibly faster, and they now feature a genie-type effect, making them somewhat reminiscent of iPadOS.\nApple also fixed the way priority notifications are displayed, eliminating a cutoff bug that was present in earlier developer betas of iOS 26.\nThe Lock Screen clock, meanwhile, has received an improved \"Liquid Glass\" effect, more closely resembling what Apple previewed during WWDC 2025. Some of the changes in iOS 26 beta 6, however, have more to do with sounds rather than imagery.\nMore ringtones, removed Camera toggle\nBy opening the Settings app and navigating to Sounds & Haptics > Ringtone, you'll see six new options under the \"Reflection\" ringtone. The melodies offer different takes on the existing Reflection ringtone, and they're no less recognizable than the original, which is still the default iPhone ringtone.\nThe different \"Reflection\" ringtone variants in iOS 26 developer beta 6 are labeled as follows:\n- Default\n- Buoyant\n- Dreamer\n- Pond\n- Pop\n- Reflected\n- Surge\nThe iOS 26 update itself also makes it much easier to add custom iPhone ringtones. The company's decision to include a new ringtone variant goes well with its improved customization options. Apple first added an alternate version of its \"Reflections\" ringtone with the second developer beta of iOS 26.\niOS 26 developer beta 6, meanwhile, removed a toggle for the Camera app that was added in the previous beta. The fifth developer beta featured a \"Camera Mode Switching\" toggle that let users swipe through camera modes like they did with prior iOS releases, disabling the navigation method implemented with iOS 26.\nWith iOS 18, for instance, users were able to swipe through camera modes as though they were interacting with a dial. iOS 26, meanwhile, replaced this with a loupe-type element that's arguably more clunky. Unfortunately, Apple has now made it impossible to revert to the previous method of navigation without downgrading to iOS 18.\nOverall, iOS 26 developer beta 6 offers a few new ringtones, but not much else beyond quality-of-life improvements. Apple deploys new developer betas of iOS nearly every week or two, meaning that we'll likely see additional features and changes with subsequent software releases."
    },
    {
      "url": "https://9to5mac.com/2025/08/11/ios-26-beta-hints-at-upcoming-airpods-live-translation-gesture/",
      "text": "When Apple announced Live Translation at WWDC25, it highlighted use cases like FaceTime, phone calls, and messages. But one major use case was missing: real-world conversations. As it turns out, that was in the works too.\nNew image hints at new AirPods gesture\nIn today\u2019s iOS 26 developer beta 6, we spotted a new system asset that appears to depict a gesture triggered by pressing both AirPods stems at once.\nThe image displays text in English, Portuguese, French, and German, and it is associated with the Translate app. For now, we can confirm it\u2019s associated specifically with the AirPods Pro (2nd generation) and AirPods (4th generation).\nReal-world live translation is right up the wearable wheelhouse\nWhile Apple didn\u2019t mention real-world translation for AirPods during the WWDC25 keynote, Bloomberg had reported earlier in the year that this feature was in the works. This feels like a natural extension of the Live Translation features already announced for FaceTime, Messages, and Phone, and it is also a strong use case for wearables in general, something we\u2019ve already seen with devices like the Meta Ray-Bans.\nAt this point, it\u2019s unclear which iPhones will support the new gesture, as it is very unlikely that the feature will run entirely on the AirPods. But it\u2019s reasonable to assume the cutoff will align with Apple\u2019s official hardware requirements for other Live Translation features:\nLive Translation in Messages is available in Chinese (Simplified), English (UK, US), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil) and Spanish (Spain) when Apple Intelligence is enabled on a compatible iPhone, iPad or Mac, as well as on Apple Watch Series 9 and later and Apple Watch Ultra 2 when paired with an Apple Intelligence\u2013enabled iPhone.\nLive Translation in Phone and FaceTime is available for one-to-one calls in English (UK, US), French (France), German, Portuguese (Brazil) and Spanish (Spain) when Apple Intelligence is enabled on a compatible iPhone, iPad or Mac.\nBit of speculation\nGiven the need of an even lower latency for real-world interactons, it is possible that this feature may be exclusive to the iPhone 17 lineup, which could help explain why Apple has kept it under wraps until now.\nSpeculation aside, what we do know is that Apple appears to be prepping the release of a live translation feature associated with AirPods, and that\u2019s exciting enough, especially for anyone living abroad or traveling somewhere the language is unfamiliar.\nCould you see yourself using AirPods for live translation? Let us know in the comments.\nAirPods deals on Amazon\n- AirPods Max, USB-C Charging: $479.99 ($549 off)\n- AirPods Pro 2, USB-C Charging: $169 ($80 off)\n- AirPods 4 USB-C Charging: $99 (was $129)\n- AirPods 4, USB-C and Wireless Charging: $148.99 (was $179)\nFTC: We use income earning auto affiliate links. More.\nComments"
    },
    {
      "url": "https://appleinsider.com/articles/25/06/06/apple-intelligence-translation-for-users-new-ai-tools-for-developers-coming-at-wwdc",
      "text": "Apple will be concentrating its Apple Intelligence launches at WWDC 2025 on developer tools, and wide-ranging translation for users, including live translation via AirPods.\nThis latest of many pre-WWDC leaks concerns the much-anticipated next announcements regarding Apple Intelligence. After last year's launch, it had been expected that WWDC 2025 would be light on Apple Intelligence news.\nHowever, according to Bloomberg, Apple has two major focuses for Apple Intelligence this time, and two more minor ones.\nThe major focus for users will be on translation. It's reported that Apple Intelligence will bring translation features across more of iOS, iPadOS, and macOS. Specifically, it will be used in automatically translating Messages \u2014 as previously reported \u2014 and also live translation of phone calls.\nApple is also said to be working to launch live conversation translation via AirPods. Previous reports on this have further claimed that the feature will automatically recognize the language being spoken, too.\nThe other major feature is for developers, who are again said to be getting access to Apple Intelligence tools. This would mean developers being able to use the same AI tools that Apple has for Genmoji and Writing Tools.\nGenmoji is also the one of the smaller areas of focus for Apple Intelligence at WWDC 2025. It's claimed that they will get a small upgrade that will see Genmoji able to combine existing, standard ones into new images.\nThen alongside these specific features, Apple is expected to upgrade its Shortcuts app, giving it tools to help users more easily make automations on their Macs, iPhones, and iPads.\nThese features are all now expected launch alongside a considerable redesign of macOS, iOS, and iPadOS. It is all to be revealed during the WWDC opening keynote on June 9."
    },
    {
      "url": "https://support.google.com/googlepixelbuds/answer/7573100?hl=en",
      "text": "Whether you travel abroad or connect with multilingual friends and family, Google Pixel Buds help you translate easily with your Pixel or Android 6.0+ phone. Use Conversation Mode to talk directly or Transcribe Mode to follow along with translations.\nTo use with Google Translate, make sure you have:\n- Google Pixel Buds connected to your phone\n- A Google Assistant enabled Android device (The device must meet all requirements within the linked article)\n- The latest version of the Google app\n- The latest version of the Google Translate app\n- An internet connection\nUse Conversation Mode and talk with someone\nHow To Translate with Google Pixel Buds Pro | Google Pixel Buds Pro\nWith the assistance of the Google Translate app on your phone, your Google Pixel Buds can translate conversations between the following languages:\n|\nAfrikaans |\nEnglish |\nJapanese |\nSerbian |\n|\nArabic |\nFinnish |\nKhmer |\nSinhala |\n|\nArmenian |\nFrench |\nKorean |\nSlovak |\n|\nBengali |\nGerman |\nLatvian |\nSpanish |\n|\nCatalan |\nGreek |\nNepali |\nSwahili |\n|\nChinese (Mandarin only) |\nHindi |\nNorwegian |\nSwedish |\n|\nCroatian |\nHungarian |\nPolish |\nTamil |\n|\nCzech |\nIcelandic |\nPortuguese |\nThai |\n|\nDanish |\nIndonesian |\nRomanian |\nTurkish |\n|\nDutch |\nItalian |\nRussian |\nVietnamese |\nStep 1: Select language\nWith Google Assistant: Ask Google Assistant to help translate on Google Pixel Buds\n- While wearing your Pixel Buds, touch and hold either earbud or say, \"Hey Google.\"\n- Ask Assistant to translate, like saying \"Help me speak Spanish.\"\nThis launches Google Translate in conversation mode with your default language and the language that you request.\nWithout Google Assistant: Select your languages\n- Open Translate .\n- In the bottom left corner, choose the language you speak.\n- In the bottom right corner, choose the language the other person is speaking.\n- Tap Conversation .\nStep 2: Begin your conversation\n- Touch and hold either earbud.\n- Speak your message.\n- Release the earbud when you finish. Your phone translate and reads your message aloud into your selected language.\nStep 3: Receive a response\n- In Google Translate, tap microphone .\n- Have the other person speak. Their response translates into your language and plays through your Pixel Buds.\nListen to another language with Transcribe mode\nIn Transcribe Mode, your Pixel Buds continuously translate spoken language into your ear, showing a transcript on your phone. You can currently, translate from English to French, German, Italian, or Spanish.\nUse the transcribe feature in a quiet environment with one person speaking at a time for the best accuracy.\nWith Google Assistant\nStep 1: Ask Google Assistant to help transcribe with Google Pixel Buds\n- While you're wearing Pixel Buds, touch and hold either earbud or say, \"Hey Google.\"\n- Request assistance, such as saying, \"Ay\u00fadame a entender ingl\u00e9s.\"\nThis launches Google Translate in transcribe mode listening to the language you request (English) and translating to your default language (French, German, Italian or Spanish).\nAssistant queries for transcribe mode\nFrench: Hey Google, aide-moi \u00e0 comprendre l'anglais.\nGerman: Hey Google, hilf mir, Englisch zu verstehen.\nItalian: Hey Google, aiutami a capire l'inglese.\nSpanish: Hey Google, ay\u00fadame a entender ingl\u00e9s.\nStep 2: Begin listening\nListen through your Pixel Buds along with the transcript on your phone. The text is read aloud after each sentence is translated.\nWithout Google Assistant\nStep 1: Select your languages\n- Open Translate .\n- Tap micorphone Transcribe .\n- In the bottom left corner, select the language you want to listen to (supported language: English).\n- In the bottom right corner, select the language with the spoken words to be translated into (supported languages: French, German, Italian or Spanish).\nStep 2: Begin listening\nListen through your Pixel Buds along with the transcript on your phone. The text is read aloud after each sentence is translated.\nTips for Best Results\nTroubleshoot if you encounter issues:\n- Move closer to the audio source.\n- Ask the speaker to talk louder, slower, or more clearly.\n- Toggle the microphone on and off.\n- Check that your input/output languages are correct.\n- Verify your Wi-Fi connection.\nRequires a Google Assistant-enabled Android 6.0+ device, Google Account, and an internet connection. Data rates may apply. Translation isn't instantaneous. For available languages go to g.co/pixelbuds/help"
    },
    {
      "url": "https://appleinsider.com/inside/imessage",
      "text": "iMessage\nAll about iMessage\nTable of Contents\nApple's iMessage is an instant messaging service baked into the Messages app on iOS, iPadOS, and macOS. It has end-to-end encryption for maximum privacy and a growing feature list that allows for greater self-expression than standard text messaging.\nWhen a chat in Messages contains only Apple device users, the chat uses the iMessage protocol. All parties will need to have the service turned on and linked to their iCloud account in their device settings.\nWhen you send a message on an Apple device, the Messages app will check with Apple whether the cellular number is registered with iMessage. This determines whether it will use iMessage or standard text messaging (SMS/MMS).\niMessages appear as blue bubbles in the Messages app, while SMS messages use green bubbles. Group chats will only use blue bubbles and iMessage protocols if every member of the chat has an Apple device with the feature enabled.\nInternet-based messaging services have become popular because of the number of features they enable. Stickers, TapBack reactions, and improved image quality are just some of the perks of using iMessage, WeChat, or Facebook Messenger. SMS is an old protocol that relies upon aging phone systems with limited text messaging length and few features.\nApple's iMessage has become popular, especially in the United States, because it resides within the default texting app and doesn't cost money to use. All of these features combined to create the \"blue bubble\" versus \"green bubble\" social split. Android users or anyone using SMS are often pressured to switch to iPhone due to the lack of iMessage features.\nSome describe this as a feature lock-in on Apple's part, as well as a source of bullying for some users. Apple has acknowledged that it has a competitive advantage in keeping iMessage within its ecosystem but doesn't see it as a form of lock-in.\niMessage Features\nThe Messages app started out as a simple alternative to SMS with improved image and video messaging tools. It has evolved into an end-to-end encrypted advanced messaging service with apps, stickers, games, and more.\nApple rearranged some of the features for iMessage in iOS 17, placing apps, stickers, and the camera behind a plus button.\nEnd-to-End Encryption\nApple encrypts iMessage on your device, so even they can't read them while they're in transmission between devices. The only way anyone could read your messages is if they had access to either an unlocked Apple device that was participating in the chat, its passcode or biometric login, or the device's backups.\nIn your device's settings, you can choose to leave messages on your device for 30 days, one year, or indefinitely. Note that the other party will have access to any sent message even if it is deleted from your device, so no deletion is 100% gone.\nUsers who want even more protection for their messages can choose to enroll in Advanced Data Protection with iOS 16.2. Once every device attached to the user's iCloud has been updated to its corresponding current OS, users can turn on the feature, which brings end-to-end encryption to more iCloud services.\nIf Advanced Data Protection is not enabled, and the user has an iCloud backup that includes iMessage, Apple will have access to the encryption key for the messages. Again, even with Advanced Data Protection on, the people you're chatting with may not have it enabled, leaving your messages in a less secure state \u2014 at least with that individual.\nChatting in iMessage\nThe Messages app on iOS, iPadOS, and macOS supports both iMessage and SMS. RCS, a messaging protocol backed by Google and the GSMA, will be adopted by Apple with iOS 18.\nIf you don't use any effects, apps, or stickers, chatting in iMessage will look similar to texting with a contact through SMS. The primary difference is blue chat bubbles for iMessage and green bubbles for SMS. You will also see the light gray \"iMessage\" status in the empty text box for iMessage chats vs. a light gray \"Text Message\" for SMS.\nAnother significant difference is that you would see typing indicators (an animated ellipsis) when an iMessage contact typed in their text box. If the person you're chatting with has read receipts turned on, you would also see the words \"Delivered\" change to \"Read\" once they open the Messages app to read your message.\nYou can universally toggle the sending of read receipts on or off. You can also switch them on or off for individual chats. Receiving others' read receipts depends entirely on their settings, not yours.\niOS 16 introduces the ability to undo send or edit messages for up to fifteen minutes after being sent in an iMessage chat. The recipient also needs to be on iOS 16 or later to see the change take place.\niOS 18 brings send later to iMessage. Users can now type up a message and choose to send it at a specific time.\nThe introduction of RCS will give green bubble text more abilities like sending high-resolution photos and videos, typing indicators, and reactions.\nSharing Media\niMessage supports photos, Live Photos, videos, and animated GIFs.\nMedia can be shared via a plus button located next to the text entry box starting in iOS 17. Alternatively, you could choose a photo from the Photos app and share it directly or even convert it to a sticker.\nYou can take a picture or video directly from an iMessage chat by choosing the camera app in the plus menu. After taking a pic or recording a video, you can edit it or add effects. You can also use Markup to draw on photos before sending them.\nAudio messages have also been relocated to the plus menu and will be transcribed so the recipient doesn't have to listen to the sent audio. By default, the Messages app deletes audio messages after two minutes, but you can change that setting to allow them to stay on your device indefinitely.\nYou can attach any other kind of file in iMessage using the Share Sheet from the Files app.\nSharePlay has made its way to iMessage, so users can start a SharePlay session and chat via iMessage instead of starting a FaceTime call. The feature works the same as it does on FaceTime with synced video and audio playback with individual controls.\niMessage Filtration and Blocking\nThe Messages app allows you to mute conversations, so you no longer receive notifications from them. To do this, swipe left on the chat from the conversations list and choose \"Hide Alerts.\"\nYou can block iMessage contacts by navigating to their contact info and choosing \"Block this contact.\"\nIf someone contacts you and you want to report it as spam, you'll see an option to \"Report as Junk\" at the bottom of their unsolicited message. This option will only be there for incoming messages from unknown numbers.\nApps, Effects, and Tapback\nStarting with iOS 10, Apple enhanced iMessage with effects, stickers, reactions, and support for third-party apps. While this app store didn't become wildly popular, it is still available in iOS 18.\nEffects send a message with an animation that your recipient will see on their screen. Holding down on the send button brings up the option for bubble effects (slam, loud, gentle, or invisible ink) or screen effects (echo, spotlight, balloons, confetti, love, lasers, fireworks, or celebration).\nMore text effects are available in iOS 18 and can be applied per word.\niMessage apps reside in a menu beside the text box in an iMessage chat. Apple gives you default iMessage apps for the following:\n- Photos - share your images and videos\n- Stickers - create custom stickers from photos or use stickers from apps\n- Music - share Apple Music songs, albums, artists, and playlists\n- Cash - send Apple Pay Cash\n- Digital Touch - send haptic animations like a heartbeat, sketch, tap, etc.\n- Check In - share when you leave a location and arrive at a destination with someone you trust\n- Memoji - share animated or sticker versions of yourself or a cartoon animal\n- #images - search for GIFs and images to share\n- Location - share location with the chat\n- App Store - discover third-party iMessage apps, games, and stickers\niMessage apps can include games, where friends in the same chat can play together. Third-party iMessage apps don't have access to any of your info or data.\nStickers differ slightly from regular images or GIFs. If you send a sticker on its own, it will appear as an image or animation, but you can also drag and drop one or more stickers on top of chat bubbles, photos, videos, or other stickers.\nTapback lets you react to a specific message without typing a new message. Long-pressing or double-tapping on a chat bubble enables you to choose from several emoji reactions: love, like, dislike, laugh, emphasize, and question. The emoji appears as a pop-up bubble on top of the chat bubble.\nGoogle began rolling out support for Apple's Tapback reactions in its messaging client on Android. Now some Android users will see emoji reactions in conversations with iPhone users.\nReactions are upgraded in iOS 18 to include access to the entire colorful emoji library. Users can still react with stickers, but emoji reactions appear in the bubble above the text.\nMemoji and Animoji\nIntroduced with the iPhone X in 2017, Animoji are animal characters that play your voice and mirror facial expressions using Face ID sensors. The following year, Apple added Memoji, which does the same with an avatar that you can customize to look like you.\nIn addition to these tracked animations, you can also send static Memoji and Animoji stickers, posing in various pre-designed reactions such as thumbs-up, laughing, in love, and mind blown.\nMemoji have spread to various parts of the operating system and can be used for contact images too.\nMessages in iCloud\nMessages in iCloud syncs messages \u2013 both iMessage and SMS \u2013 so they're automatically in sync on all your Apple devices. It saves attachments in the cloud to free up device storage, and if you delete a message on one device, it disappears on all of them.\nMessages in iCloud can be toggled on and off in device settings.\nGroup Chats in iMessage\nIn addition to one-on-one chats, iMessage supports group chats with up to 32 participants. Users can easily begin a SharePlay session or collaboration project directly from these chats.\nUsers can share stickers, images, or invite participants to collaborate on projects, files, or notes. Apple Cash payments can't be performed in a group chat.\nIf a single Android users enters a group chat, it automatically converts to SMS. This is where the blue versus green bubble social arguments stem from.\nAttempts at iMessage on Android\nMultiple entities have tried to find ways to add iMessage to Android with little success. The attempts are usually made by asking users to sign into a server or run a server application on a Mac, but those methods prove to be riddled with security and privacy concerns.\nThe closest attempt to true iMessage on Android occurred in December 2023. Developers of Beeper Mini managed to reverse engineer the iMessage protocol and use Apple's own servers to provide iMessage to an Android app.\nThe initial attempt asked users to provide phone numbers, but Apple closed this option within days. The second attempt asked users to sign in with an email, but this proved faulty within days of implementation as well.\nIf Apple ever brings iMessage to Android, it will be via a first-party solution. The company asserts that attempts like Beeper Mini could cause problems with privacy and security of user messages.\nRCS support in iOS 18\nAmid increasing regulatory pressure and accusations of user lock in, Apple has finally relented and is working to bring Rich Communication Services, or RCS, to iPhone. It is due to release in 2024 as an iOS 18 feature.\nRCS will enable iPhone and Android users to communicate at a much higher standard than what SMS offers. Images and video can be shared at a much higher resolution, rich links and stickers will work too.\nApple says RCS messages will still be a green bubble. SMS fallback isn't going anywhere as much of the world still relies on SMS.\nGoogle's flavor of RCS offers end-to-end encryption for certain circumstances, but Apple won't be adopting that version. Instead, Apple is working to adopt the universal profile offered by the GSMA.\nApple says it is committed to working with the GSMA on bringing encryption to the universal profile, which will benefit all RCS users instead of those using Google's messaging platform.\nRCS will arrive as a part of iOS 18, which was announced during WWDC on June 10. New operating systems tend to release in late September."
    },
    {
      "url": "https://appleinsider.com/inside/airpods-pro-2",
      "text": "AirPods Pro 2\nAll about AirPods Pro 2\nTable of Contents\nApple unveiled the AirPods Pro 2 during the Far Out Apple Event on September 9, 2022. The updated Apple headphones offer improved audio quality and functionality in the same first-generation design.\nThis model replaces the original at the same $249 price point. For the purposes of this guide, we refer to this product as AirPods Pro 2, but Apple simply calls them AirPods Pro (2nd generation) in marketing.\nTo make matters more confusing, Apple released an updated version of AirPods Pro 2 with a USB-C port in September 2023. This set is identical to the other second-generation model except for the USB-C port and the ability to connect to Apple Vision Pro via a 5 gigahertz connection using the H2 chip.\nThat means the updated USB-C version of AirPods Pro 2 are necessary to use Apple Vision Pro with lossless audio. Customers can purchase the USB-C charging case separately if they really want the port.\nRumors of the next-generation AirPods Pro 3 suggest the new earbuds won't debut until 2025 at the earliest. An altered design and improvements to ANC and battery life are expected.\nA suite of hearing health features were revealed alongside the iPhone 16 launch. The AirPods Pro 2 will support a hearing test, hearing protection, and hearing aid features that have already been FDA approved.\nAirPods Pro 3 rumors\nApple is rumored to be working on the AirPods Pro 3, which would presumably use the H3 chipset. Additional health features and improved existing ANC modes are likely the focus of these next-generation earbuds.\nPatents and rumors show Apple is working on heart rate detection for AirPods Pro 3. The PowerBeats Pro 2 have the feature, but the heart rate detection isn't working in tandem with Apple Watch \u2014 instead the Health app prioritizes Apple Watch data.\nApple could also be working on camera features with the new earbuds, but it isn't clear what they'd be used for. Either they are sensors for tracking or a reference to a potential Meta Ray-Bans-like product.\nAirPods Pro 3 are expected sometime in 2025, though there haven't been many signs of them actually releasing. Apple may not update the earbuds until 2026.\nAirPods Pro 2 Features\nThe H2 processor is at the center of the new feature set of AirPods Pro 2. It offers high-bandwidth connectivity thanks to Bluetooth 5.3 and improved audio processing.\nRumors suggested Apple would introduce a lossless audio codec that would work over Bluetooth 5.3, but that never came to pass. Instead, the USB-C AirPods Pro 2 have a 5Ghz radio for lossless audio when paired with Apple Vision Pro.\nUsers get access to 48kHz audio over SharePlay.\nThe earbuds have a new low-distortion audio driver and a custom amplifier powering it. Users should notice a wider range of frequencies that offer clearer audio and more detail.\nSpatial Audio is still a tentpole feature and benefits from the improved processing power as well. Gyroscopes in the earbuds determine head position so users can \"move\" through the 3D audio space.\nANC and Adaptive Transparency\nActive Noise Cancellation is improved thanks to the H2 with twice as much noise canceled. Algorithms work with multiple microphones to determine what audio needs to be blocked.\nThe new Adaptive Transparency feature uses the same microphones and algorithms to eliminate unwanted audio while letting other sounds in. For example, a loud vehicle or construction noise would be canceled out while a person's voice would be allowed through.\nThe H2 processor analyzes sound 48,000 times per second, so fast changes in environmental noise can be processed near instantly.\nWith the ear tip fit test, users can determine if a chosen ear tip size is providing a suitable seal. A new feature of iOS 16 also allows users to scan their ear using the 3D dot projector found in Face ID-equipped iPhones.\nAdaptive Audio\nApple introduced a new feature for AirPod Pro 2 during WWDC 2023 called Adaptive Audio. It acts as an intelligent middle between Transparency Mode and Active Noise Cancelation.\nFor devices running iOS 17 or later, it shows up as a new third option that users can select when pressing and holding on the AirPods stem. It blocks external noise intelligently based on the environment, ducking audio when a user begins talking and allowing nearby voices in to help get the user's attention.\nLike Active Noice Canceling, Adaptive Audio only works with both earbuds in.\nDesign and controls\nThe AirPods Pro 2 have the same bulbous earpiece, short stems, and changeable ear tips. Apple included a smaller ear tip size for a better range of fits.\nAs before, a quick squeeze on the stem will play or pause audio. Squeeze and hold to switch audio modes between ANC and Transparency modes.\nThe stem is touch-sensitive now, too, so swipe up or down to control the volume.\nProximity sensors will determine if the AirPods are located in the person's ear or not. When removed, audio playback will be paused and then resume again when placed back in the user's ear.\nThe microphone is located at the bottom of the stem. It uses beamforming to isolate the user's voice for calls and commands. \"Hey Siri\" can be used to control audio playback, give Apple Home commands, or activate a Shortcut.\nCharging Case and battery life\nA single charge will provide up to 6 hours of battery life. The Charging Case has enough power to allow up to 30 hours of total listening time before needing a charge.\nThe Charging Case can be charged via Lightning, MagSafe, and the Apple Watch charger. It magnetically aligns with the chargers to ensure proper alignment.\nThere are multiple changes to the Charging Case to address previous user complaints. The case can be located via Find My, and thanks to a speaker cutout, it can play a chime to help find it nearby.\nThe Charging Case also has a U1 chip. So, iPhones that also have U1 can pinpoint the case's location within a few feet.\nApple also added a lanyard hole for attaching a lanyard without the need for an extra case. While Apple doesn't sell a lanyard, it is a standard hole that will work with most lanyards.\nThe Charging Case can be charged via Lightning or wirelessly via MagSafe.\nWhen Apple announced the iPhone 15 with USB-C, the company also revealed AirPods Pro 2 with USB-C. Customers have to purchase the new model to get USB-C as the new case isn't compatible with the original AirPods Pro 2 earbuds.\nAirPods Pro 2 (Lightning) review\nEverything about the second generation of AirPods Pro is new besides the design. The sound is improved, the ANC and Transparency modes got a boost, and battery life is even longer.\nWe feel that AirPods Pro 2 recapture the magic we felt with the original AirPods and their successors. It is delightful to switch between listening modes and hear our favorite songs in Spatial Audio.\nThe H2 processor is responsible for most of the new updates. For example, it samples incoming audio at 48,000 times per second to adjust Adaptive Transparency on the fly.\nSince the stem is still here, Apple took advantage of it and made it possible to control volume with a gesture. While this gesture can be tricky to master, it is useful when you've only one free hand to adjust volume.\nThe MagSafe Charging Case also got a bevy of updates to address some obvious user concerns. It can play a chirping noise from a built-in speaker and has a U1 chip for precise finding via Find My.\nWe'd have liked it if Apple included different color options or USB-C in the case, but these aren't deal breakers. Lossless is also still a hopeful feature since these earbuds support Bluetooth 5.3.\nAnyone who hasn't purchased AirPods Pro recently should consider an upgrade to the new set. They offer improved features across the board, and Apple users get a lot of ecosystem benefits.\nRead the full AirPods Pro 2 Review from AppleInsider and see why we gave it a 4 out of 5.\nBeats bringing the competition\nApple has plenty of competitors in the headphone space, but one of its biggest come from inside the same house \u2014 Beats by Dre. The brand was acquired by Apple in 2014 to assimilate Beats Music and create Apple Music, but the hardware brand remained active.\nBeats has evolved since, retaining a bass-heavy signature sound and the Beats brand, but otherwise becoming more Apple like throughout. Since the earbuds and headphones are used by a wide variety of consumers, the products have moved to a proprietary Beats chipset that make them work well across Apple and Android devices.\nAirPods Pro have a few close competitors in the Beats lineup. Those include the Beats Studio Buds, Beats Fit Pro, and Beats Solo Buds.\nThe premium option, Beats Studio Buds+, offers ANC and Transparency features that rival Apple's original AirPods Pro. They also come in at a much lower price of $169.\nIt is clear Apple has no fear competing with itself in the earbud space. Between the two brands, Apple and Beats, they own an incredible portion of the market.\nAirPods Pro 2 pricing\nApple kept AirPods Pro 2 priced at the same $249 and removed the original set from sale. They are only available in white, but third-party companies offer various cases to customize the Charging Case."
    },
    {
      "url": "https://www.samsung.com/us/support/answer/ANS10000935/",
      "text": "Use Live Translate on Galaxy phones and tablets\nYou can effortlessly break through language barriers when making phone calls and sending messages with the Live translate feature on select Galaxy phones and tablets. This AI feature automatically translates voice calls, face to face conversations, and text messages into your preferred languages, so you can easily understand the person you're speaking with.\nUse Live Translate on Galaxy phones and tablets\nNote\n- The One UI 6.1 software update is required to use Galaxy AI features. Live translation during calls is available on the Galaxy S25 Ultra, S25 Edge, S25+, S25, S24 Ultra, S24+, S24, S23 Ultra, S23+, S23, S22 Ultra, S22+, S22, Z Fold7, Z Fold6, Z Fold5, Z Fold4, Z Flip7, Z Flip7 FE, Z Flip6, Z Flip5, Z Flip4, Tab S10+ 5G, Tab S9+ 5G, and Tab S8+ 5G. The feature is not supported on the Tab S10 Wi-Fi series, Tab S9 Wi-Fi series, Tab S10 FE series, Tab S9 FE series, Tab S8 Wi-Fi series, A series phones or tablets, or on other models.\n- English and Spanish are pre-installed in the Interpreter app. Additional languages require a free download. Translation results may vary.\n- Certain regions and languages may not be supported. Arabic, Chinese (Simplified, Cantonese), English (US, Great Britain, India, Australia), French (France, Canada), German, Hindi, Indonesian, Italian, Japanese, Korean, Polish, Portuguese (Brazil), Russian, Spanish (US, Spain, Mexico), Thai, Vietnamese, Turkish, Romanian, Swedish, and Dutch are supported languages.\n- Live translation is available through the Samsung phone dialer and some third-party apps, such as WhatsApp, Facebook Messenger, Instagram, Signal, Line, WeChat, Telegram, Meet, and Kakao Talk.\n- Some features require active service or an internet connection.\nUse Live translate during phone calls\nBefore jumping on a call, you will need to enable the Live translate feature in your phone's Settings menu.\n- Navigate to and open Settings, and then tap Galaxy AI.\n- Tap Call assist, and then tap Live translate.\n- Tap the switch to turn on Live translate.\n- You will be prompted to select your desired languages or download new languages.\nNote: You can also change the languages in the Phone app. - Next, navigate to and open the Phone app. Select a recipient from the Recents or Contacts tabs, or type in a phone number using the Keypad tab.\n- Tap the green Phone icon to begin the call, and wait for the other person to respond.\n- Once you are both speaking, tap Call assist, and then tap Live translate.\nNote: Only one person should use Live Translate at a time, otherwise translation errors will occur. If the selected language doesn't match what's being spoken, the conversation may be mistranslated.\n- A real-time translation will appear on the screen, and you will hear the translation as your conversation continues.\n- Tap the red Phone icon to end the call.\n- To adjust Live translate's options from the Phone app, tap More options (the three vertical dots), then tap Settings, and then tap Live translate. From here, you can change the languages and voice types.\nTo get real-time translation in other apps:\n- Navigate to and open Settings, and then tap Galaxy AI.\n- Tap Call assist, then swipe to and tap Live translate in other apps.\n- Turn on the switch next to the available apps.\n- During a call, use two fingers to swipe down from the top right corner of the screen to open the Quick panel, and then tap Live translate to start translating.\nRead less\nUse Live translate for in-person interpreting\nWith the new Interpreter feature, you can use your Galaxy phone or tablet as an interpreter when having in-person conversations in real-time.\n- Swipe down from the top right corner of the screen to open the Quick settings panel, and then tap the Interpreter icon.\n- Tap Continue, and then increase the volume on your device. Allow the necessary permissions when prompted.\n- Tap OK, and then select your desired languages.\n- Tap Menu icon (three horizontal lines) in the top left corner of the screen, and then tap Conversation mode (the two chat bubbles). Conversation mode is useful when you're speaking with someone.\n- Next, tap the microphone icon next to your desired language to begin recording and interpreting the conversation.\nNote: Only one person should use the Interpreter feature at a time, otherwise translation errors will occur. If the selected language doesn't match what's being spoken, the conversation may be mistranslated. - You can view the language translations on the top and bottom portions of the screen.\n- You can also tap the Listening mode icon (the chat bubble) from the Menu to get real-time speech translations, and then tap Record at the bottom of the screen.\nNote: Only one person should use the Interpreter feature at a time, otherwise, translation errors will occur. If the selected language doesn't match what's being spoken, the conversation may be mistranslated. - To copy the conversation to a new note in the Samsung Notes app, tap More options (the three vertical dots), and then tap Recents. Tap the Copy icon (the square) next to your desired conversation to copy the contents to the clipboard.\n- Now navigate to and open Samsung Notes, then tap the Pencil icon to create a new note, and then paste the contents of the conversation into the note.\nRead less\nUse Dual screen Interpreter with the Z Fold and Z Flip\nYou can take advantage of the dual screens on your Z Fold or Z Flip when using Conversation and Listening modes in the Interpreter app. Conversation mode is useful when you're speaking with someone who uses a different language, and Listening mode provides real-time translations when you or another person is speaking.\n- Open the Interpreter app, and then select your desired languages.\n- Fold the phone to enable Flex mode and then select the Conversation mode icon (the two chat bubbles). Conversation mode is useful when you're speaking with someone.\n- Next, tap the microphone icon next to your desired language to begin recording and interpreting the conversation.\n- You can view the language translations on the top and bottom portions of the screen.\nNote: Only one person should use the Interpreter feature at a time, otherwise translation errors will occur. If the selected language doesn't match what's being spoken, the conversation may be mistranslated. - Tap the Cover screen icon at the top of the screen to display the translations of what you say on the cover screen.\n- You can also use Listening mode, which provides real-time speech translations. Tap the Listening mode icon (the chat bubble), and then tap Record at the bottom of the screen.\nNote: Only one person should use the Interpreter feature at a time, otherwise translation errors will occur. If the selected language doesn't match what's being spoken, the conversation may be mistranslated. - You can also copy the conversation to a new note in the Samsung Notes app. Tap History (the clock icon), and then select your desired conversation. Select and copy the contents to the clipboard.\n- Navigate to and open Samsung Notes, then tap Create note (the pencil icon) to create a new note, and then paste the contents of the conversation into the note.\nRead less\nUse Chat translation with messages\nNote\nChat assist is called Writing assist on the Galaxy S25, Z Fold7, Z Flip7, and Z Flip7 FE.\nThe Writing assist or Chat assist feature provides live translations when you're sending and receiving text messages on your Galaxy phone.\n- Navigate to and open a messaging app, such as Samsung Messages, Google Messages, or WhatsApp.\n- Select a recipient to open a current chat conversation, or start a new conversation. Tap the Writing assist or Chat assist icon (the stars) on the keyboard's toolbar.\nNote: The Writing assist or Chat assist icon may appear differently in other messaging apps.\n- Tap Chat translation, and then use the translation bar at the top of the screen to select your desired languages.\nNote: If Chat translation is missing, go to Settings, then tap Security and privacy, and then tap More privacy settings. Tap the switch next to Android personalization service to enable it. - Real-time translations will appear during your conversation!\n- To change the languages during the conversation, tap the Writing assist or Chat assist icon again, then tap Chat translation, and then configure the languages using the translation bar.\nNote: You can also use the Writing style and Spelling and grammar features while sending messages! Tap the Writing assist or Chat assist icon, and then select your desired feature.\nRead less\nRecommended Articles\nCompare Galaxy Z Fold7, Z Flip7, and Z Flip7 FE\nCompare Galaxy Z Fold7, Z Flip7, and Z Flip7 FE Samsung's newest foldable models have arrived! The Galaxy Z Fold7, Z Flip7, and Z Flip7 FE are Samsung's sleekest, most convenient foldables, and feature impressive screens, cameras, batteries, and storage. You can review our guide to find each model's specs and information, so you\u2019ll know which phone\nDifferences between the Galaxy Z Fold6 and Z Flip6\nDifferences between the Galaxy Z Fold6 and Z Flip6 Samsung\u2019s newest phone models, the Galaxy Z Fold6 and Z Flip6, are here! Each phone is packed with familiar Galaxy AI features from the S24 series, plus some new features that will help you get the most from your new device. For instance, Drawing Assist brings your sketches to life and AI Select pr\nUse features with Galaxy AI on your Galaxy phone and tablet\nUse features with Galaxy AI on your Galaxy phone and tablet Whether you're editing photos, browsing the web, or calling loved ones, you can use the new AI app features on your Galaxy phone or tablet to simplify daily tasks! For example, you can effortlessly organize and summarize your ideas in Samsung Notes, receive text message assistance, find co\nWe're here for you\nContact Samsung Support\nContact us online through chat and get support from an expert on your computer, mobile device or tablet. Support is also available on your mobile device through the Samsung Members App.\nCall or Text Us\nGive us a call\nHow can we help you?\n1-800-SAMSUNG\n1-800-SAMSUNG\n1-800-726-7864\n1-800-726-7864\n-\nMobile 8 AM - 9 PM EST Mon - Fri 8 AM - 6 PM EST Sat - Sun\n-\nHome Electronics & Appliance 8 AM - 9 PM EST Mon - Fri 8 AM - 6 PM EST Sat - Sun\n-\nIT/Computing 8 AM - 9 PM EST Mon - Fri 8 AM - 6 PM EST Sat - Sun\n-\nText Support 24 hours a day 7 days a week\nFast, easy checkout with Shop Samsung App\nEasy sign-in, Samsung Pay, notifications, and more!\nOr continue shopping on Samsung.com\n\u00d7\n\u00d7\n\u00d7\nYou Are About To Be Redirected To Investor Relations Information for U.S.\nThank you for visiting Samsung U.S. Investor Relations. You will be redirected via a new browser window to the Samsung Global website for U.S. investor relations information.\u00d7\nRedirect Notification\nAs of Nov. 1, 2017, the Samsung Electronics Co., Ltd. printer business and its related affiliates were transferred to HP Inc.For more information, please visit HP's website: http://www.hp.com/go/samsung\n- * For Samsung Supplies information go to: www.hp.com/go/samsungsupplies\n- * For S.T.A.R. Program cartridge return & recycling go to: www.hp.com/go/suppliesrecycling\n- * For Samsung printer support or service go to: www.hp.com/support/samsung\nSelect CONTINUE to visit HP's website."
    },
    {
      "url": "https://appleinsider.com/articles/24/06/19/heres-which-features-apple-changed-ahead-of-their-wwdc-2024-debut",
      "text": "Apple previewed a multitude of OS features and AI-related improvements during WWDC that didn't quite align with leaks and rumors. Here's everything Apple changed along the way.\nIn the months leading up to WWDC, AppleInsider published a series of exclusive reports detailing the different features Apple was set to debut at the event. In speaking to people familiar with the matter, we obtained a large amount of information on then-unannounced operating system features.\nAlong the way, Apple changed some of the features we described. Some features were renamed, others had alterations to altering design elements, removed functionality, or elimination entirely.\nIt is impossible to know why some features were changed or removed. One plausible explanation is our initial information may have been outdated and obtained from people familiar with earlier internal builds of Apple's operating systems.\nAltered Calculator app\nApple's new Calculator application, developed under the codename GreyParrot and revealed by AppleInsider back in April, has received some unusual changes on macOS.\nThe core functionality and new features remain exactly the same as in pre-release versions of the app, as both Math Notes and the improved unit conversion system are present. That being said, however, the Calculator Apple shipped with macOS Sequoia beta is arguably worse than its internal development-era counterpart.\nIn the months leading up to WWDC, the Calculator app lost both its window resizing feature as well as the new history tape button on macOS. This means that it is no longer possible to resize the application window or activate the history tape without using the menu bar - even though both features were present in pre-release versions of macOS Sequoia.\nApple also made the Calculator application translucent, presumably as a way of distancing it from its iOS 18 and iPadOS 18 counterparts. It is not entirely clear why the company decided to go this route, as the GreyParrot project was conceived as a universal Calculator with a consistent look across all three platforms.\nThe tale of two Siri icons\nIn May, AppleInsider revealed that Apple was internally testing a new menu bar icon for Siri for macOS Sequoia, known then as project Glow. The discovered icon was monochromatic and replaced the previous colorful orb, allowing it to blend in with the other icons in the menu bar.\nIt appeared briefly at Apple's WWDC keynote on June 10, but only during one segment demonstrating the company's new iPhone mirroring feature for macOS. Throughout the majority of the keynote, macOS Sequoia was shown without a Siri menu bar icon.\nOnly towards the end of the keynote did we see a different, multi-colored icon with a new user interface for Siri on macOS. This icon was the one Apple ended up using for its developer betas of macOS Sequoia - though the new icon and new Siri UI are deliberately disabled by default.\nUsers of the social media platform X have found ways to activate Siri's redesigned user interface on both iOS 18 and macOS Sequoia beta. In the process, a pop-up message revealed that Apple considered the new Siri UI to be sensitive information and that it was not to be used \"within 50 feet of undisclosed individuals.\"\nIt is possible that Apple removed the monochromatic menu bar icon for Siri on macOS Sequoia because a sensitive UI element was leaked. This is not the only possibility, though, as the icon could have been changed for any number of reasons.\nAs for the new monochromatic icon Apple created for Siri, it can still be seen in some of Apple's instructional videos as well. It appears as though the new multi-colored icon is meant to debut alongside Apple Intelligence, rather than the earlier monochromatic one.\nSafari and Music missing features\nSafari 18's Intelligent Search feature, which isolates useful webpage information and generates article summaries, was renamed to simply be called \"Highlights.\" Earlier versions of this feature on macOS had iPadOS-like rounded buttons, but those are gone in the beta.\nThe most significant change made to Safari 18 was the complete removal of Apple's in-house content blocker, known as Web Eraser. With it, selecting and removing specific webpage elements, such as images, banner ads, text, or even entire page sections, was possible.\nThe Web Eraser feature may have been removed because of the massive controversy its reveal ultimately caused. Apple had received complaints from the UK's News Media Association and a group of French publishers about the unannounced feature, which we explained in our dedicated report on the feature's removal.\nAs AppleInsider revealed in an earlier report, pre-release versions of the Apple Music application featured an entirely new feature known as Smart Song Transitions. While this feature was in testing during the development of Apple's latest operating systems \u2014 iOS 18 and macOS 15 \u2014 it is not present in the publicly available developer betas.\nThere are seemingly no references to this new feature within the systems themselves, and Apple may have removed it or delayed it to a subsequent OS update.\nThe feature could still make its debut later in 2024 when Apple Intelligence becomes available. Given the feature's name, Smart Song Transitions, it may utilize artificial intelligence to create an improved crossfade effect or another type of transition between songs.\nWhat else did Apple modify during development?\nFreeform Scenes, a feature initially revealed in a March report and later expanded upon by AppleInsider, has also received a similar change. Apple decided to give Scenes a recognizable star-type icon, replacing the sandwich-bar icon with three vertical lines used during development.\nSeveral OS features received new names ahead of launch. Generative Playground received the name Image Playground. The name change was seemingly so rushed that Apple left the development-era name as the application title in its publicly available betas of macOS Sequoia.\nImage Playground is an all-new system application that will let users generate images through Apple Intelligence on iOS 18, iPadOS 18, and macOS Sequoia. The application can create images in three distinct styles: Animation, Illustration, and Sketch, while a fourth style, dubbed Line Art, was scrapped ahead of release.\nOne of Apple's new accessibility features for 2024, originally known as Adaptive Voice Shortcuts, was given the new name Vocal Shortcuts. The company announced the feature ahead of WWDC, along with several other accessibility features.\nWhy does Apple sometimes make changes ahead of WWDC?\nThe company's in-development features and operating systems can change for a variety of different reasons. Sometimes, Apple isn't satisfied with the quality of a certain feature, or it takes more time than originally anticipated to complete it.\nSometimes, leaks can catch wind of features that may not see the light of day for years. Internal builds for iOS might contain features destined for multiple releases later, so it is pulled at the last second.\nIn 2020, an Internal UI development build of iOS 14 was leaked to a select few individuals, and eventually made its way to the press. Allegedly sourced from a development-fused iPhone 11 in China, the build contained references to a then-unreleased feature known as Wallpaper Collections.\nFollowing the leak, the Wallpaper Collections feature was nowhere to be seen until two years later with iOS 16, when Apple finally announced it.\nApple also seemingly changed the name of its 2023 virtual reality headset and its associated operating system. Initially expected to debut as Reality Pro and xrOS, the company instead went on to announce the Apple Vision Pro and visionOS, respectively. Executives revealed that this was an intentional deception to keep the name hidden until launch, with only a handful of employees knowing the true name prior to launch.\nSimilar to the monochromatic Siri icon discussed earlier, clear mentions of the name xrOS could be found in the instructional videos Apple released following the WWDC 2023 keynote.\nWhatever the reason, Apple's development process for new operating systems is long and complex. Leaks often come from snapshots in time that may represent old versions of concepts that have already been ditched. It's important to always approach leaks with some level of doubt."
    },
    {
      "url": "https://appleinsider.com/inside/iphone-15-pro",
      "text": "iPhone 15 Pro\n-\nActive Discussions\n-\niPhone 15 Pro set to get Visual Intelligence in a future iOS update\nAll about iPhone 15 Pro\nTable of Contents\n- iPhone 15 Pro\n- 1. What's next for iPhone\n- 2. iPhone 15 Pro Features and Design\n- 3. Action button\n- 4. Spatial Video\n- 5. Stolen Device Protection\n- 6. iPhone 15 Pro Max Review\n- Review: Design\n- Display\n- Cameras\n- A17 Pro\n- USB-C\n- Action button\n- 7. iPhone 15 Pro Review\n- 8. iOS 18\n- Apple Intelligence\n- Photos update\n- Messages updates\n- Game Mode\n- Locked and Hidden apps\n- Home Screen, Lock Screen, and Control Center customization options\n- 10. The iPhone 15 Pro rumor cycle\n- 11. Apple AI\n- Titanium\n- End of Lightning\n- Portless\n- Touch ID returns\n- Periscoping cameras\n- Apple 5G Modem\n- A17 Bionic\n- Two selfie cameras\n- Capacitive buttons\n- Action button\n- Super bright OLED\nApple revealed the iPhone 15 Pro and iPhone 15 Pro Max during its Wonderlust event on September 12, 2023. These models are lighter, faster, and more durable than the previous generation thanks to several upgrades.\niPhone 15 and iPhone 15 Plus also received a handful of upgrades focused on an updated 48MP camera and Dynamic Island.\nApple hasn't separated its pro-class devices with differing features since the iPhone 12 series. In this case, the iPhone 15 Pro Max has a tetraprism lens that enables a fixed 120mm focal length, 5x the Main Camera, for the first time on an iPhone.\nOtherwise, the products are mostly identical besides the size. The iPhone 15 Pro has a 6.1-inch display while the iPhone 15 Pro Max has a 6.7-inch display. The iPhone 15 Pro Max sees about 20% longer battery life over the iPhone 15 Pro.\nWhat's next for iPhone\nApple revealed the iPhone 16 lineup during the It's Glowtime event in September 2024. It brought the Action button and Camera Control to all models, plus it ushered in the Apple Intelligence era.\nWith no more mystery around the 2024 iPhone, all eyes and rumors have turned to what's next in 2025. It seems Apple could ditch the Plus model in favor of a new \"Slim\" variant.\niPhone 15 Pro Features and Design\nThe bezels have shrunk even further in the iPhone 15 Pro, enabling Apple to shave a few millimeters from the now curved sides. The Dynamic Island is still present, covering the sensor housing for Face ID components and the selfie camera.\nPro models have a USB 3.2 Gen 2 Type-C port that enables up to 10Gbps data transfer. That's why users recording in ProRes can capture 4K 60Hz video directly onto an external SSD.\nThe Main Camera now defaults to a 24MP HEIF image, which is a higher resolution than 12MP while offering more dynamic range than 48MP. Users can choose to shoot in ProRAW via the camera app and get massive image files.\nThe A17 Pro is the first Apple Silicon processor built with the 3nm process. It is more powerful, more efficient, and can perform hardware ray tracing for games running on the iPhone 15 Pro. It has a 6-core CPU and a 6-core GPU.\nThe chipset is powerful enough to run more powerful games like \"Resident Evil 4\" and \"Death Stranding.\" While not as performant as a dedicated gaming console, it does well enough as a modern handheld.\nWi-Fi 6e is now available, plus there's a second-generation Ultra Wideband chip set for precision finding. The satellite communication feature also got an update that enables calls for roadside assistance.\nLike the iPhone 12, the iPhone 15 Pro and iPhone 15 Pro Max do not include a power adapter in the box. They do, however, have a USB-C cable. The same cable can be used to charge newer iPad models, as well.\nAction button\nThe Ring/Silent Switch has been replaced by the Action button. The user can press and hold the button to perform a task that was assigned from the Settings app.\nThe Action button has several basic tasks it can perform, but there are two functions that open up a near infinite combination of actions. These are accessibility and Shortcuts.\nSelect from the following options for the Action button:\n- Silent mode\n- Focus\n- Camera\n- Flashlight\n- Voice Memo\n- Translate\n- Magnifier\n- Shortcut\n- Accessibility\nUsers that can develop advanced Shortcuts have also taken to programming an Action button Shortcut that will perform different tasks based on different variables. When pressed, the executed Shortcut could run one action based on device orientation or the open app, for example.\nApple is expected to bring the Action button to all iPhone models in 2024.\nSpatial Video\nThe iPhone 15 Pro and iPhone 15 Pro Max allows for spatial video recording that is viewable on the Apple Vision Pro. It uses the wide and ultra wide cameras to capture 3D video, though with very little separation.\nRecording in spatial video is only possible while holding the iPhone horizontally. It captures video in 1080p at 30fps.\nSpatial video requires at least some moderate lighting or else it won't record. It can be activated at any time by tapping a small Apple Vision Pro icon while in video mode in the Camera app.\nUsers can't capture Spatial Photos with the iPhone without access to third-party apps like Spatialify, Apple's native camera and Photos app do not support it. Developers have found ways to capture 3D photos and even 4K video in Apple's spatial format for Apple Vision Pro.\nStolen Device Protection\nReports of thieves stealing iPhones and device passcodes leading to complete Apple ID takeovers led Apple to release a new feature to stop it \u2014 Stolen Device Protection. The feature must be toggled on in iOS 17.3, and it changes how the passcode can be used to alter Apple ID and device settings.\nWith Stolen Device Protection on, users must use biometrics to authenticate changing certain features with no passcode fallback. For example, if a user is away from a trusted location like home or work and tries to change their Apple ID password, the iPhone will request Face ID then place a one-hour delay before requesting it again.\nUsers can disable the trusted location feature in iOS 17.4 so a time delay is always required.\nIf a thief steals the iPhone and passcode, goes to Settings, and requests to change the Apple ID password while standing in front of you, then uses your face to get past the first biometric, they still would have to wait another hour to scan your face a second time. The hour delay also gives users time to login to iCloud from another device and lock their iPhone by placing it in Lost Mode.\niPhone 15 Pro Max Review\nApple's annual iPhone update cycle creates a significant challenge for the company. We believe iPhone 15 Pro Max is an excellent year-over-year upgrade with titanium sides, a new 5x Telephoto Camera, and the promise of A17 Pro.\nWhile the smaller iPhone 15 Pro saw many of the same upgrades, we believe the 5x camera is a must-have for photographers. A larger display and longer battery life make this the best iPhone you can buy.\nHighlights from this review\n- Lighter, smaller titanium frame with fewer color options\n- Same great always-on display\n- Seven cameras in your pocket\n- 29 hours battery life\n- 23 hour video playback, 95 hour audio playback\n- A17 Pro introduces the future of mobile gaming\n- USB 3.2 gen 2 Type-C opens up new possibilities\n- Action button brings a new interaction paradigm to iPhone\n- Despite new materials and design tweaks, it's more an evolved iPhone 12 than a new generation\nRead the full iPhone 15 Pro Max review for a detailed evaluation and photos, or keep reading ahead for the summary.\nReview: Design\nApple's shift from stainless steel to titanium is evident in the device's weight and finish. The edges have a soft matte coloring that is less prone to fingerprints, and the weight is reduced by about 10%.\nThe central frame is an aluminum structure housing the battery, processor, and other components. This makes it more repairable by having the front and back glass be separate components.\nThe IP68 water resistance rating returns, meaning the iPhone still can't be submerged \u2014 at least not on purpose. Apple won't cover water damage, though the iPhone should survive splashes and quick dunks.\nSince the bezel shrunk, the device frame could be pulled in slightly. While it's not a big change, it's enough to notice the smaller size in hand.\nReview: Display\nApple didn't change anything about its pro displays on the iPhone 15 Pro or iPhone 15 Pro Max other than the bezel getting smaller. It's still a Super Retina XDR always-on display with ProMotion.\nThe Dynamic Island is now a part of every iPhone 15 model, so developers are more likely to embrace the feature and Live Activities. New system features like the flashlight also use the Dynamic Island.\nStandBy remains a favorite feature of ours from iOS 17. The always-on display enhances the feature, so pro users benefit from information at a glance.\nReview: Cameras\nApple touted that the iPhone 15 Pro Max brought seven cameras to your pocket. This is technically accurate thanks to the various optical focal lengths and macro mode within the camera system.\nThe Main Camera's 48MP sensor in the iPhone 15 Pro can capture 24MP images anywhere between 1x and 2x with three pre-selected stops available \u2014 24 mm, 28 mm, and 35 mm.\nWe found that images captured with the Main Camera at the new 24MP default were sharp and well contrasted. The various focal lengths provide plenty of options for framing the subject.\nThe 2x Telephoto crop from the Main Camera, the Ultra Wide Camera, and Macro modes still shoot 12MP images. However, they do benefit from improved image processing and better HDR.\nThe most important iPhone 15 Pro Max camera upgrade was the 120 mm fixed 5x Telephoto Camera. It enables incredible reach from a smartphone with good performance, even in poor lighting.\nReview: A17 Pro\nAt the time of the review, no games or apps took full advantage of Apple's latest silicon in the iPhone 15 Pro. The A17 Pro has a lot of promise for the future of mobile gaming, but it's difficult to discuss, having not experienced it firsthand.\nBenchmark scores proved promising, which coincided with Apple's claims of a 10% faster CPU and 20% faster GPU. Hardware accelerated ray tracing will be interesting to experience once a game launches with the feature.\nSome concerns about overheating were raised during our review period that have since been addressed. The issue wasn't widespread and didn't affect our handset, but Apple released an update to fix the issue.\nReview: USB-C\nApple's iPhone has finally moved on from Lightning in favor of the more universal USB-C port. It is a USB 3.2 gen 2 Type-C port for the pro models.\nThe move to USB-C has been a long time coming. Apple stopped offering other ports on MacBooks only a few years after Lightning was introduced, then iPads moved to USB-C, and now, finally, iPhones. Just in time to comply with EU regulations, too.\nMost users shouldn't notice differences in day-to-day use cases. The iPhone charges at the same 20W speeds, and data transfer over a cable is a niche need.\nApple did enable a useful feature for videographers for the 10Gbps port \u2014 4K60 ProRes recording directly to an SSD. This requires the SSD, cable, and any intermediary docks to support the USB 3.2 gen 2 speeds for best results.\nReview: Action button\nIt isn't often that Apple introduces a new interaction paradigm to iPhone, but we're two years running with Dynamic Island and now the Action button. The new button replaces the mute switch and offers a range of custom functionality.\nThere's nothing particularly remarkable about the Action button itself. Apple could have introduced it at any time previously, but its functionality is amplified by the existence of Shortcuts.\nUsers are presented with a handful of control options that can be activated with the Action button, but the key ones are Shortcuts and Accessibility. These open the door to a near-infinite number of customizable controls.\nA press and brief hold will activate the function anywhere in the operating system. Assigning a Shortcut folder enables a menu with seven Shortcuts to pop up.\nSome apps map specific in-app functions to the Action button. We expect the functionality will improve as Apple introduces new features and developer-facing APIs.\niPhone 15 Pro Review\nThe above iPhone 15 Pro Max review covered most of what was new with the updated 2023 lineup. However, there are a few differences between the large and small pros.\nThe lightweight titanium is even lighter in the smaller iPhone 15 Pro. Plus, some users will prefer the 3x optical zoom to the new 5x found in iPhone 15 Pro Max.\nHighlights from this review\n- Same display with more easily repairable glass\n- USB-C enhances what iPhone can do when paired with accessories\n- Action button brings new utility to iPhone\n- A17 Pro is faster and has great potential\n- 23 hour battery life\n- Up to 20 hours video playback, 75 hours audio playback\n- Camera hardware remains largely unchanged year over year\nRead the full iPhone 15 Pro review for a detailed evaluation and photos. An iPhone 15 Pro three months later review is also available.\niOS 18\nAnnounced at WWDC 2024, iOS 18 is set to arrive in the fall alongside the iPhone 16. Here are some of the features users can expect to see.\nApple Intelligence\nThe most notable upgrade to Apple's upcoming operating systems is the integration of what Apple calls Apple Intelligence. It is a personal context based artificial intelligence designed to work primarily on-device and help streamline tasks in a personal way.\nSome new features coming to the iPhone include on-device image generation, AI-powered writing and editing tools, and improved notification management.\nIt's worth noting that Apple Intelligence is only supported on the iPhone 15 Pro, M-series iPads, and M-series Macs. The iPhone 15 Pro and iPhone 15 Pro Max run the A17 Pro processor and have 8GB of RAM, which enable access to the new AI features.\nPhotos update\nA new Collections feature in iOS 18 automatically organizes the library by topics like Recent Days, Trips, and People & Pets. If you have a few favorite collections, you can pin them for quick access to the collections or albums most important to you.\nMessages updates\nApple has expanded Tapback options, now allowing users to respond to messages with any emoji, rather than the initial six it provided.\nThe new Send Later feature allows users to schedule when to send a message, which is perfect for ensuring you don't send someone a message when they're sleeping or when you want to schedule a birthday or anniversary message.\nApple has confirmed that RCS support will arrive in iOS 18. RCS will improve messaging with Android devices by supporting read receipts, typing indicators, sending over Wi-Fi, and higher-quality media.\nThose who have an iPhone 14 or later will be able to use Messages via satellite. This new feature will allow users to send messages over iMessage and SMS, even without cellular or Wi-Fi service.\nWhen using iMessage, users can still use key features like sending emoji and Tapbacks, and anything sent via iMessage is end-to-end encrypted.\nGame Mode\nIn 2023, Apple introduced Game Mode to Mac \u2014 and a year later Game Mode is coming to the iPhone.\nGame Mode minimizes background activity while gaming. This allows the iPhone to sustain high frame rates for long gaming sessions.\nLocked and Hidden apps\nUsers can lock apps and require Face ID, Touch ID, or a passcode to unlock them, lessening the fear of handing off your iPhone to someone else. Locked apps will not appear in search and notifications, either.\nApps can also be hidden by dragging them to a hidden apps folder, requiring users to unlock the folder via biometrics or passcode before viewing the contents.\nHome Screen, Lock Screen, and Control Center customization options\nNow, on the Lock Screen, you can replace the controls at the bottom with something else, such as taking a note or quickly capturing a moment for your social media. If you have an iPhone 15 Pro, you can access these controls using the Action button.\nAs part of the expanded customization features, app icons, and widgets can now be scaled up to appear larger.\nUsers are no longer restricted to the standard app icon layout anymore. The new iOS 18 adds the ability to arrange apps along the bottom for quicker access or along the side to frame a favorite wallpaper.\nEach page of the Home Screen can feature a unique layout.\niPhone 15 Pro price and release date\nPre-orders began on Friday, September 15 and the online Apple Store inventory ran out within the hour for pro models. Initial deliveries and in-store availability began on September 22.\nThe price didn't increase for the iPhone 15 Pro, but the iPhone 15 Pro Max has a new starting price since it no longer offers the 128GB option. Customers can choose from blue, white, black, and natural titanium color options.\nThe iPhone 15 Pro rumor cycle\nEverything below this point was written before the product's respective announcements. This information will remain as a record of what was rumored so it can be compared to what has been released.\niPhone 15 Pro and Apple AI \u2014 Pre-WWDC 2024\nApple is set to reveal a slew of updates related to artificial intelligence and iPhone owners won't need an iPhone 16 to take advantage. The on-device models Apple is working on in addition to server-side models will work great on iPhone 15 Pro with the A17 Pro's advanced Neural Engine.\nThere are a lot of rumors and mounting evidence around Apple's plans for AI, but nothing is set in stone just yet. It seems the company could focus on a two-pronged approach by building proprietary AI tools that run locally in tandem with third-party tools that run in the cloud.\nThe push for on-device models would ensure privacy and security are maintained for users. One of the biggest concerns with AI and large language models is data privacy \u2014 as users don't want their private information training chatbots.\nApple researchers have published papers detailing image learning models, generation tools, and more. WWDC is being held on June 10 and it is expected to reveal Apple's AI strategy with iOS 18.\nThe rumor cycle around the iPhone 15 Pro lineup was as busy as ever. Many leaked features focused on the pro models because Apple tends keep updates for standard models small by comparison.\nApple naming conventions are difficult to predict because the infamous \"s\" could pop up at any time. Rumors stuck to Apple's standard naming convention for the most part, with one exception.\nMultiple sources suggested that the iPhone 15 Pro Max would instead be called iPhone 15 Ultra. This rumor was around for the iPhone 14 rumors cycle as well, and has extended into the iPhone 16 rumors since.\nAnalyst and rumor monger Ming-Chi Kuo says the \"Ultra\" name will be used in 2024, but act as a new higher tier, rather than replacing iPhone 16 Pro Max.\niPhone 15 Pro rumors \u2014 Pre-September 2023\nA lot of information was leaked about the iPhone 15 Pro lineup in the year leading up to its release. A few sources proved more reliable than others, but most of the biggest features were known ahead of Apple's September 12 event.\nColor rumors pointed to a dark red option being possible. This rumor stopped being shared after a while and most reliable sources started suggesting a series of gray options and blue for the pro colors.\nTitanium curved edges and thin bezels (Likely)\nThe rim around iPhone 15 Pro models could be made from titanium and feature a rounded edge design similar to the MacBook Pro lineup. The back edge would curve slightly as it meets the back glass panel.\nThis material change from stainless steel could decrease the weight of the phone significantly. Apple could choose to polish the titanium and have a similar finish to the existing stainless steel rim.\nRumors also suggest that the display bezel will be thinner than ever, though it will remain symmetrical thanks to the Dynamic Island. There isn't a lot of space to shrink the bezels further, but it could happen.\nEnd of the Lightning Port (Likely)\nThe iPhone 15 Pro could finally be moving to USB-C after a decade with the Lightning port. This aging port replaced the 30-pin connector and offered novelty features like a reversible port and a more water-tight enclosure.\nThe prevalence of Lightning throughout Apple's lineup including iPhone could make a port transition difficult, despite many user's requesting the feature. The number of iPhone users with Lightning ports in their iPhones, iPads, and AirPods far outnumber Mac users with USB-C ports.\nApple may be caught in another lose-lose situation for its PR team if the iPhone 15 shifts to USB-C. Like when it transferred from the 30-pin connector, the shift to USB-C cable could face heavy scrutiny from customers and regulators alike.\nMany businesses took years to shift away from Lightning, with some locations still sporting the 30-pin connector. It may be similar for the move to USB-C, though there will be more motivation since it is a global standard port.\nKuo shared that Apple may introduce USB-C to the iPhone 15 in 2023. It isn't clear if this is based on supply chain data or a leak, but he did say he took a survey. Presumably, the survey would have been taken from his supply chain consultants, but that isn't known.\nThe European Union has passed legislation that requires smartphone manufacturers to adopt the USB-C port as a uniform connector by 2024. However, the two-year deadline for the requirement gives Apple enough time to perfect another option entirely \u2014 going portless.\nRumors had previously indicated that Apple will remove all ports from its iPhone lineup in the near future, and USB-C will never make it onto iPhone. Those rumors haven't panned out, and it seems USB-C is going to happen in 2023 in at least the iPhone 15 Pro.\nIn late 2022, Apple is still releasing products with a Lightning port. The latest AirPods Pro 2 still use the connector despite rumors of Apple moving away from it in less than a year. The updated Siri Remote did shift to USB-C, a sign of the upcoming transition.\nRumors suggest that Apple could include Thunderbolt capabilities in the iPhone 15 Pro. That would enable the fast transfer of large files like ProRes video.\nEven as the company moves to USB-C, it is expected to maintain the Made for iPhone (MFi) program. This would likely limit what third-party accessories and cables can do without Apple's MFi certification.\nPortless (Unlikely)\nSince their inception, having a physical connector for transferring power and data has been a staple of portable electronics. Despite that, Apple may ditch the physical connector in the iPhone 15 line entirely in favor of alternatives like MagSafe wireless charging, Qi charging, wireless data transfer, and smart connectors.\nThere aren't many apparent reasons why Apple would want to ditch a physical connector, but like the headphone jack before it, the company may be seeking more internal space for components. In addition, while a USB-C port can be waterproofed, having no connector at all would ensure improved water integrity.\nFor Apple to achieve a portless iPhone 15, it must first offer users suitable alternatives. The port is currently used for many accessories, from SD card dongles to musical recording equipment. Apple isn't likely to entirely remove such vital functionality from iPhone, though customers may have to pay for a new adapter.\nEven Apple's own CarPlay uses the physical port to connect. Unfortunately, most modern vehicles don't come standard with wireless CarPlay, so again, Apple will have to address those customers. An obvious half-step solution would be to include a magnetic Smart Connector like on some iPad models.\nRumors of a Smart Connector coming to iPhone have circulated since the connector's inception on the first iPad Pro in 2015. Although the three-prong connection supports some data transfer, it isn't suitable for large files or streams of information.\nApple's MagSafe accessory system for iPhone is another possible solution. Though the current iteration only supports power transfer on the iPhone 13, a future version could include some data transfer elements.\nAs we get closer to September 2023, it is becoming more clear that USB-C is coming to iPhone 15. The idea of a portless model isn't gone, but it will take a large leap in wireless technology to come to fruition.\nReturn of Touch ID (Unlikely)\nTouch ID was replaced by Face ID when Apple introduced the iPhone X. This new technology enabled all-screen Apple devices with no Home Button, though it did mean introducing a notch.\nIt wasn't a solution without its problems, as the feature needed to see a user's eyes, nose, and mouth to unlock the device. It faced issues with sunglasses and other face coverings, but did open up the ability for users to wear gloves without issue.\nWhen the pandemic struck, this created an unprecedented issue with Face ID as iPhone users around the globe donned masks. Users complained of the now-impeded unlocking process and demanded Apple bring back Touch ID as a solution.\nInstead, Apple offered a compromise for Apple Watch owners. If Face ID detected the user was wearing a mask, it would verify if the Apple Watch was authenticated then unlock the iPhone. Of course, this solution applied only to Apple Watch wearers \u2014 a much smaller population than iPhone users.\nApple announced a new version of Touch ID for the iPad Air 4, and later the iPad mini 6, which moved Touch ID to the power button. This ramped up speculation that Apple would surely include Touch ID in the iPhone 13's power button, but to no avail.\nRumors and patents show that Apple has been working on a Touch ID solution for iPhone, but not in the power button. Ming-Chi Kuo had believed that Apple would implement Touch ID under the display by 2023, but has since changed his prediciton. With advances in how the iPhone detects faces with masks, Apple may not need to bring back Touch ID at all.\nAndroid devices have used under-display fingerprint readers since at least 2018 to some success. But as with 120Hz display refresh, Apple likely wants the technology to be perfected before implementing it in their smartphone \u2014 if at all.\nPeriscoping Cameras (Likely)\nA new camera system could be used on the \"iPhone 15\" to enable more optical zoom. The iPhone could have a much longer zoom by utilizing a folding camera system within the device to put more space between the lens and the sensor. It isn't clear if this would replace Apple's existing Telephoto lens or add a fourth lens with this capability.\nWhile the iPhone 14 Pro can zoom to 3x, a 77mm equivalent, that isn't too distant a zoom. The 77mm focal length is great for portraits or getting closer to a relatively close subject, but it still isn't enough for wildlife photography or sporting events. Those situations require much longer lenses to capture the subject.\nSamsung utilizes periscoping and algorithms to enable clear capture of subjects at 100x magnification. Thanks to the long lens hidden away within the phone's body, this is possible. Apple has been testing such a lens for future iPhones, but it wasn't clear if or when it would be implemented.\nKuo released another report in December 2021, restating that the \"iPhone 15\" may have a periscope lens system. It is still unclear if this is an upgrade to the existing telephoto lens or if it will be included as a new fourth lens. Rumors suggest the former.\nAccording to supply chain reports released in April 2022, multiple manufacturers have been tapped to produce components needed for a periscope camera system. The components are allegedly on order for use in the \"iPhone 15.\"\nReports throughout 2023 have increasingly suggested the periscope camera is coming to the larger iPhone 15 Pro. Kuo even states that the upgrade will be a primary driver of sales for the device.\nApple 5G Modem (Possible)\nIntel exited the modem business and left Apple an opportunity to enter yet another vertical. However, progress in developing an in-house modem has been slow and it isn't clear when one would appear.\nIn the interim, Apple has used Qualcomm to provide 5G modems to the iPhone. This renewed partnership may extend much longer than initially expected, as Apple has allegedly stopped development of in-house Wi-Fi and cellular chips.\nApple Silicon could gain modem-based superpowers thanks to greater integrations. Apple prides itself on vertically integrated technology and adding modems to the stack could present a significant boon to users.\nIt is expected that Apple will resume development of its in-house wireless chipsets after the move to 3nm is completed for A17 and M3. Priorities had to shift to the 3nm transition, so modem development took a back seat.\nApple A17 Bionic processor\nThe iPhone 15 lineup will get a new processor \u2014 at least the pro models will. The standard models will get the A16 Bionic used in the iPhone 14 Pro.\nThe A17 Bionic is expected to make a leap to the next processor manufacturing process from 5 nanometer to 3 nanometer. This will increase the power and efficiency of the processor.\nA rumor suggests that the A17 pro chip will have 6 CPU and 6 GPU cores and will run at 3.70 GHz. This is an increase over the A16's 6-core CPU and a 5-core GPU.\nTwo selfie cameras (Unlikely)\nThere may be more for the Dynamic Island to cover on the updated iPhone. Rumors suggest one model may have two selfie cameras, though the use case is unknown.\nTwo selfie cameras may create an issue for the Dynamic Island software, as smaller devices will quickly run out of space to show app information on either side of the hardware. Apple could move more sensors under the glass and shrink the size of the housing to allow two cameras to fit neatly, but it isn't yet clear if that is its approach.\nThis rumor was shared early by a somewhat reliable source. It hasn't been repeated since, and more reliable leakers haven't mentioned it.\nCapacitive buttons (unlikely)\nSeveral rumors have suggested Apple wants to get rid of physical, pressable buttons. That includes the mute switch that's been on every iPhone so far.\nThe volume buttons would join into one large capacitive surface, and the power button would also become capacitive. In place of the mute switch would be a small capacitive button.\nThese buttons would operate similarly to the capacitive Home Button that used a haptic engine to simulate a button press. Some expect the volume button to be controllable via sliding gestures as well.\nThe mute button could have a single function, but some hope Apple would open up its functionality to act similar to the Apple Watch Ultra's Action Button \u2014 programmable based on certain apps or conditions.\nAction button (Possible)\nMultiple reliable sources have reported that Apple has backed away from capacitive buttons. It seems the iPhone 15 Pro models will instead have the standard buttons found on older models, but the mute switch may still be replaced with a programmable \"Action\" button.\nDummy models used to help case makers prepare case designs prior to Apple's iPhone announcement show the new button in place of a mute switch. Since it is a button and not a switch that has to travel up and down, the cutout is smaller.\nThis smaller cutout is also shown in cases believed to be for the updated iPhone, showed in a leak in June. The sources have revealed such components and cases accurately before.\nEvidence is mounting that Apple could move to an action button for iPhone 15 Pro, though it isn't set in stone. Many of these leaks could be based on older production testing models and not the final shipping model.\nCase makers seem to believe the Action Button exists as leaks keep pouring in from reliable sources showing the button cutout in cases. These could be guesses, but it's increasingly unlikely.\nCode in iOS 17 suggests users will be able to choose from nine options to control when the Action Button is pressed.\n- Accessibility\n- Camera\n- Flashlight\n- Focus\n- Magnifier\n- Shortcuts\n- Silent Mode\n- Translate\n- Voice Memos\nSuper bright OLED (Possible)\nOne rumor suggests that Samsung is working on releasing a new OLED display type that can support up to 2,500 nits. The current iPhone 14 Pro can output up to 2,000 nits in direct sunlight.\nThe basis of this rumor is loose at best. Samsung is allegedly working on this display type for use in its own smartphone lineup, and it isn't clear if it would be used in Apple's.\n\"iPhone 15\" Price and Release Date\nPredicting the price of a device that will be released so far in the future isn't exactly a science, but looking at Apple's pricing trends can give a hint. Apple didn't deviate from its usual pricing structure for iPhone 14, and it could do the same in 2023.\nApple could introduce a new storage tier at 2TB for the iPhone 15 Pro to make space for its increasingly demanding features like ProRes video. That could bring an iPhone's price dangerously close to $2,000. Also, \"iPhone 15 Fold\" would be sold as an ultra-premium model and likely start at around $1,499.\nRumors have pointed to price increases at the high end. Pro models could cost up to $200 more due to the materials used, periscope camera, and new processor.\nOne analyst believes the Pro Max model could be delayed into October due to Sony being unable to supply a camera part in time for the periscope upgrade. If this is true, the other models could launch in September separately.\nApple is expected to announce its \"iPhone 15\" lineup in September 2023."
    },
    {
      "url": "https://appleinsider.com/articles/25/07/15/airpods-pro-2-hearing-support-goes-global-with-wider-rollout",
      "text": "Apple is continuing to expand access to its AirPods Pro 2 hearing aid features, with a growing number of countries now cleared to use the tools for hearing support.\nIn September 2024, Apple introduced a slate of new, clinical-grade hearing aid and hearing aid features to the AirPods Pro 2. The features included a hearing health test, allowing AirPods Pro 2 to function as hearing aids, which Apple calls \"clinical grade\" for moderate hearing loss.\nApple has recently expanded the list of countries that can use these features, as discovered by MacRumors.\nThe countries listed below can now utilize the hearing test feature to assess their potential level of hearing loss.\n- Argentina\n- Ecuador\n- Honduras\n- Indonesia\n- Israel\n- Kazakhstan\n- Moldova\n- Palestinian Territories\n- Serbia\n- Taiwan\n- Thailand\n- Ukraine\n- Vietnam\nAirPods Pro 2 uses your Hearing Test results to personalize how ambient sounds are amplified. These real-time adjustments are tailored to your hearing profile.\nThe test is available in the AirPods Pro section within the iPhone or iPad Settings app. It takes roughly five minutes to complete.\nAfter the test, users receive a summary showing the level of hearing loss in each ear. This audiogram is securely stored in the Health app.\nUsers have the option to share their audiogram with a healthcare provider for additional guidance. As always, the information stays private and fully under the user's control at all times.\nIn addition to the above list, users in the following countries can use the AirPods Pro 2 as Hearing Aids:\n- Cyprus\n- Ecuador\n- Honduras\n- Indonesia\n- Israel\n- Kazakhstan\n- Moldova\n- Palestinian Territories\n- Serbia\n- Taiwan\n- Thailand\n- Ukraine\n- Vietnam\nThe Hearing Aid feature helps users stay engaged with people and surroundings. They also improve clarity in media like music, calls, videos, and games by applying the same personalized profile.\nAirPods Pro 2 also includes Loud Sound Reduction to limit harmful environmental noise. It helps protect hearing during everyday exposure to loud sounds.\nHearing Protection features are currently supported in:\n- Antigua and Barbuda\n- Canada\n- Colombia\n- Costa Rica\n- Ecuador\n- Guam\n- Puerto Rico\n- Saint Kitts and Nevis\n- Sint Maarten\n- United States\n- US Minor Outlying Islands\n- US Virgin Islands\nThe rollout of Hearing Aid features has been a bit asynchronous, largely because many regions require approval from local health authorities before the AirPods Pro 2 can legally be used that way. Apple maintains an up-to-date breakdown of which hearing features are supported where on its AirPods Pro Hearing Health Availability page.\nIn March, Apple expanded the features to Australia, Brazil, Colombia, and Saudi Arabia."
    },
    {
      "url": "https://appleinsider.com/inside/apple-silicon",
      "text": "Apple Silicon\nAll about Apple Silicon\nTable of Contents\n- Apple Silicon\n- 1. Ecosystem\n- M4: Apple Intelligence at its core\n- M3: More than a third-generation spec bump\n- M2: The second generation of Apple Silicon\n- M1: The Mac's first custom processor\n- M1 Pro and M1 Max\n- M1 Ultra\n- A-series processors\n- 2. Benchmarks\n- M2\n- M1\n- A15 Bionic\n- A14 Bionic\n- A13 Bionic\n- A12X Bionic and A12Z Bionic\n- A12 Bionic\n- A11 Bionic\n- 3. Transition\n- Universal 2\n- Rosetta 2\n- Virtualization\nApple Silicon doesn't refer to a specific chipset or processor but to the company's custom silicon as a whole. Its development lets the company focus on performance and vertical integration across platforms rather than needing to optimize software to work with another company's hardware.\nThe custom processors developed by Apple have benefitted iPhone and iPad for years. The Mac began using them in 2020.\nFollowing more than a decade of chip architecture experience gleaned from developing the A-series processors, Apple prepared the way for Apple Silicon on Mac with macOS Big Sur, Mac Catalyst, and several other developer platforms.\nIt took the next step for more vertical integration with the C1 modem in iPhone 16e. Ultimately, Apple is expected to ditch Qualcomm modems in favor of its in-house solution.\nApple Silicon Ecosystem\nApple made its first custom processors out of necessity because Intel did not want to design chips for the iPhone. Because of this, Apple built custom processors for the iPhone, ensuring complete vertical integration with the software.\nThe A-series chips went on to become the most powerful and efficient mobile chipsets available at the time, and Qualcomm and even Intel could not keep up. Now the Mac has M-series chips pushing beyond what was possible when running Intel on the Mac.\nM4: Apple Intelligence at its core\nApple introduced the M4 processor alongside redesigned 13-inch iPad Pro and 11-inch iPad Pro. It is built on the 3-nanometer process with a 10-core CPU and a 10-core GPU.\nThe Neural Engine got an upgrade with a focus on Apple Intelligence. It jumps to 38 trillion operations per second.\nM4 is also included in the Mac mini, iMac, and base MacBook Pro. Mac mini also uses the M4 Pro.\nM4 Pro and M4 Max were introduced in the MacBook Pro. Mac Studio also uses M4 Max and can be upgraded to M3 Ultra.\nM3: More than a third-generation spec bump\nWhen Apple transitioned to Apple Silicon, it did so when the world's supply chain was upended by global instability and a pandemic. Product launches seemed to stretch out on a longer pattern than what Apple wanted, but it seems with M3 the cycle has achieved regularity.\nThe M3, M3 Pro, and M3 Max were all revealed by Apple simultaneously during the \"Scary Fast\" event in October 2023. The chips were announced alongside refreshed MacBook Pros and the M3 24-inch iMac.\nThe 14-inch MacBook Pro replaced the 13-inch MacBook Pro on the low end with a base M3 model. External designs were unchanged for the upgraded 14-inch and 16-inch MacBook Pro.\nApple released the M3 MacBook Air models in March 2024. Both the 13-inch and 15-inch options were updated at the same time.\nThe M3 family of processors are built with the 3-nanometer process. They have features like Dynamic Caching, hardware-accelerated ray tracing and mesh shading, and faster processing cores.\nRumors suggest that Apple has no plans to release an M3 Ultra since the M4 was revealed in May 2024 for the iPad Pro update. No Mac Studio or Mac Pro updates were revealed during WWDC in June 2024.\nM2: The second generation of Apple Silicon\nThe M2 is around 18% faster than the M1 it replaces, has 25% more transistors, and can be configured with up to 10 GPU cores. It was announced for the 13-inch MacBook Air and 13-inch MacBook Pro first, then brought to other products like iPad Pro and the 15-inch MacBook Air.\nIt has the Media Engine, which wasn't introduced in the first generation until the M1 Pro. That means developing video and other media is much faster on an M2 machine when using optimized software.\nJust like with the M1, the M2 Pro and M2 Max followed and are used in the 14-inch MacBook Pro, 16-inch MacBook Pro, and Mac Studio. Finally, the M2 Ultra was revealed during WWDC 2023 and is used in the Mac Studio and Mac Pro.\nApple introduced two iPad Air models with the M2 processor in May 2024.\nM1: The Mac's first custom processor\nWhile Apple has already spent well over a decade making powerful chipsets for the iPhone and iPad, the company isn't using those in the new Macs. Instead, there is a specific system-on-a-chip architecture used for Macs and MacBooks called the M1. The first Macs to use Apple Silicon are the late 2020 models of the MacBook Air, 13-inch MacBook Pro, and Mac mini.\nIn early 2021, Apple introduced the 24-inch iMac and iPad Pro with the M1 processor.\nThe M1 uses a 5nm architecture with 16 billion transistors, four high-performance cores, four high-efficiency cores, and eight GPU cores. Even in the MacBook Air, which lacks external cooling and has one of the GPU cores disabled, the machine still runs faster than 98% of consumer notebooks on the market.\nApple boasted the M1 as the world's fastest CPU in low-power silicon, the world's best CPU performance per watt, the world's fastest graphics in a personal computer, and breakthrough machine learning (ML) thanks to the Neural Engine. This adds up to the M1 having a 3.5x faster CPU, 6x faster GPU, and 15x faster ML than previous Macs using Intel.\nThe GPU is capable of running nearly 25,000 threads simultaneously with 2.6 teraflops of throughput. Apple says this makes it the fastest integrated GPU in a consumer PC.\nThe webcam used on the new MacBooks remains 720p, but the M1's ML and ISP upgrades improve the overall image.\nM1 Pro and M1 Max\nApple introduced the M1 Pro and M1 Max during its \"Unleashed\" event in October 2021. They are the pro-tier chipsets used in the 14-inch MacBook Pro and 16-inch MacBook Pro.\nThese processors offer up to 3.7x CPU performance, 13x GPU performance, and 11x machine learning performance when compared to equivalent Intel models. The efficiency gained by the M1 Pro and M1 Max also enables battery life gains with up to 21 hours of use in some configurations.\nThe M1 Pro has up to a 10-core CPU, up to a 16-core GPU, and can be configured with 32GB of RAM. The M1 Max has up to a 10-core CPU, up to a 32-core GPU, and can be configured with 64GB of RAM.\nM1 Ultra\nThe M1 Ultra has a 20-core CPU and can be configured with up to a 64-core GPU and 128GB of RAM. It is the first desktop-only Apple Silicon processor, and it was built by essentially combining two M1 Max processors with an UltraFusion connector.\nThe 20-core processor can outperform a 28-core Xenon-powered Mac Pro by 60% during normal operations. Even with all of this performance, the M1 Ultra consumes 1000KWh less power per year than competing high-end PCs.\nThe Mac Studio with M1 Ultra lacks the I/O of the Mac Pro tower it replaced.\nA-series processors\nDuring the 2020 WWDC, Apple boasted about successfully bringing 10 billion chips to devices through the years and wanting to bring that expertise to Mac. The company believed that it could hit the sweet spot between power consumption and performance by offering chips that are very powerful while remaining very efficient.\nOver a decade of custom chip building through 2020, Apple has been able to increase CPU performance by 100x and GPU performance by 1000x.\nApple also designed new system architectures and technologies to specifically take advantage of its design, like the Neural Engine for machine learning or the Secure Enclave for encryption. Combine those technologies with the existing software implementations like Metal and Swift, and Apple can utilize its custom chipsets far better than with Intel.\nApple Silicon Benchmarked\nApple A-series chips have powered iPhone and iPad since the iPhone 4, and the most recent generations have proven to be as powerful as consumer laptops running Intel. While these are designed to be mobile-first with battery life as the primary concern, they still pack a punch.\nBenchmarks across different system architectures are not representative of performance for each, but give a good snapshot of how performative a mobile device on ARM can be when compared to the aging Intel chips.\nM2\nThe M2 processor is an improvement over the M1 in every metric. Of course, it doesn't outperform the higher-end M1 Pro or beyond because it isn't meant to \u2014 this is the entry chip.\nThe single core score of 1869 for the M2 is a slight bump over the M1's 1707. Graphics, however, show a significant jump from 7395 to 8900. These scores are in line with Apple's performance claims.\nThese devices run the M2:\n- 13-inch MacBook Pro\n- M2 MacBook Air\nM1\nAppleInsider's benchmarks showed that the M1 is faster than nearly every Intel Mac chip. In single-core performance, the MacBook Pro with Apple Silicon outshined all of the Macs on test, with a 54% better Geekbench score than its nearest rival, the Intel-based 16-inch MacBook Pro. This makes it faster than the Intel Core i9 and the Mac Pro's Xeon, a chip family considered a processing workhorse.\nt's a somewhat similar story when you turn to the multi-core test, as the 7,395 achieved by the M1 is very impressive and beats the vast majority of the field. While it narrowly beats the 7,067 scored by the Core i9 in the 16-inch MacBook Pro, the Mac Pro's Xeon-W beat it with a 8,632 score.\nFor multi-core tasks, the M1 outpaced many Macs available today, and can keep pace with the high-performance processors used in the more premium end of the market. Only the Mac Pro's Xeon beat it in the multi-core benchmark.\nThese devices run the M1:\n- 13-inch MacBook Pro\n- MacBook Air\n- Mac mini\n- 24-inch iMac\n- fifth-generation 12.9-inch iPad Pro\n- third-generation 11-inch iPad Pro\n- iPad Air 5\nThese devices run the M1 Pro and M1 Max:\n- 16-inch MacBook Pro\n- 14-inch MacBook Pro\nThe Mac Studio runs the M1 Max and is the only Mac with the M1 Ultra processor.\nA15 Bionic\nThe A15 has a 6-core CPU with two performance cores and four efficiency cores. The GPU has 4 cores or 5 cores depending on what device it is used in.\nThe Neural Engine is faster, with 15.8 trillion operations per second. The chip includes a new image signal processor for improved photos and new features.\nThe A15 average single-core score is 1730, a roughly 10% increase from the A14 score of 1575. Multi-core scores average out to 4621, or nearly 21% higher than the previous model.\nThese devices run the A15 Bionic:\n- iPhone 13\n- iPhone 13 mini\n- iPhone 13 Pro\n- iPhone 13 Pro Max\n- iPad mini 6\n- Third-generation iPhone SE\nA14 Bionic\nThe A14 packs in 11.8 billion transistors onto the chip, up from the 8.5 billion of the A13, with the changes enabling Apple to be more precise in how it uses the chip to shape the user's experience. The higher transistor count translates directly into compute power that can be used in games or apps.\nThe Neural Engine is 16 cores versus 8 cores in the previous generation. This enables things like better computational photography or improved learning algorithms in applications.\nThe A14 boasts a 6-core CPU and 4-core GPU in a 5-nanometer process. Benchmarks for the A14 Bionic in the iPhone 12 Pro score about 20% faster than the A13 in the iPhone 11 Pro.\nThese devices run the A14 Bionic:\nA13 Bionic\nThe 2.66GHz, 6-core processor scores 1325 single-core and 3382 multi-core in Geekbench 5. The 13-inch MacBook Pro with an 8th-generation Intel Core i5 processor scores similar.\nThese devices run the A13 Bionic:\n- Second-generation iPhone SE\n- iPhone 11\n- iPhone 11 Pro\n- iPhone 11 Pro Max\n- 9th-generation 10.2-inch iPad\nA12X Bionic and A12Z Bionic\nThe iPad-specific processors in the A12 series are unique in the fact that they are the same chipset. The A12Z is a re-binned A12X with the extra GPU core active. Because of this they score very similarly.\nThe single-core score is 1115 and multi-core is 4626 in Geekbench 5. The mid-range 16-inch MacBook Pro with an Intel Core i7 processor scores similar.\nWhen placed within the Apple Developer Transition Kit, it scores single-core 1005 and multi-core 4555.\nThese devices run the A12Z Bionic:\n- 2nd-generation 11-inch iPad Pro\n- 4th-generation 12.9-inch iPad Pro\n- Apple Developer Transition Kit\nA12 Bionic\nThe 2.5GHz processor scores 1106 single-core and 2687 multi-core in Geekbench 5. An iMac 4K with the Intel Core i5 scores similar.\nThese devices run the A12 Bionic:\n- iPhone XR\n- iPhone XS\n- iPhone XS Max\n- iPad Air 3\n- 5th-generation iPad mini\nA11 Bionic\nThe first Apple Silicon with a dedicated Neural Engine, thus dubbed \"Bionic,\" scored 917 single-core and 2350 multi-core on Geekbench 5. The 2020 MacBook Air with the Intel Core i3 scores similar.\nThese devices run the A11 Bionic:\n- iPhone 8\n- iPhone 8 Plus\n- iPhone X\nThe specs and year-over-year gains in Apple's mobile chipsets may hint at the degree to which the M1 and future Apple Silicon for Mac will improve.\nThe Apple Silicon Transition\nAfter the initial Apple Silicon announcement, Apple provided a Developer Transition Kit that developers could order using the \"Universal App Quick Start Program.\" The DTK is a Mac mini running on an A12Z with 16GB of RAM and 512GB of storage. Developers had to pay $500 to rent the machine, which they later had to return.\nWith this kit, devs can get started making apps run natively on macOS and Apple Silicon. However, hardware is not all that Apple included to help with the process.\nDuring WWDC 2020, developers could attend virtual sessions or discuss issues with engineers within the forums and the Apple Developer app. Apple also provided day-one documentation on developing and testing Universal apps.\nAny app built for iOS or iPadOS runs natively on the Apple Silicon Mac as well.\nOn macOS Big Sur, there are multiple applications built just for the transition. Apple called out three specific ones: Universal 2, Rosetta 2, and Virtualization.\nApple technically completed the transition away from Intel with its Mac Studio release in 2022. The company hinted at a Mac Pro running an M-series processor, but it didn't arrive in 2022.\nThe tower Mac Pro with Intel is still for sale, and the future of the product isn't yet known. Apple could still introduce an M2-variant of the product in 2023.\nUniversal 2\nUniversal 2 is a universal binary that works on Intel and Apple Silicon-based Macs. With the same binary developers can make apps that work on both platforms.\nThird-party developers like Microsoft and Adobe have already begun building apps to work on the new chipset. The WWDC demo showed the new apps running easily even while editing 4K video live.\nRosetta 2\nAs Rosetta allowed PowerPC apps to run on Intel Macs, Rosetta 2 is fulfilling the same role to allow Intel apps to run on the new architecture.\nInstead of a \"just in time\" (JIT) process that the original Rosetta used, Rosetta 2 does the heavy lifting on installation with the translation of the code, front-loading the processing load. Code in third-party browsers executing Java and similar other technologies are still using JIT technologies for execution.\nAs demonstrated at WWDC, Rosetta 2 is powerful enough to run some games built for Intel without significant issues.\nVirtualization\nVirtualization software also runs on Apple Silicon Macs, but the extent of what and how is not fully known yet. Apple has demonstrated Linux use through virtualization apps like Parallels desktop, and Parallels offers an M1-friendly variant of its software that can run ARM-based Windows.\nM1 Macs don't support BootCamp for running Windows. Apple's Craig Federighi has said that it's up to you Microsoft whether to support M1 Macs with its desktop OS.\nApple mentioned that other platforms like Docker will also work on Apple Silicon and that devs will be able to take full advantage of the software."
    },
    {
      "url": "https://forums.appleinsider.com/discussion/239583/your-existing-airpods-could-gain-a-new-live-translation-feature-in-ios-19",
      "text": "Your existing AirPods could gain a new live translation feature in iOS 19\nApple's iconic AirPods are rumored to receive an entirely new feature that translates in-person conversations from one language to another.\nApple is reportedly working on a new live translation feature for AirPods.\nThe rumored live translation capability will make it significantly easier for speakers of two different languages to communicate. The feature is expected to roll out in 2025 alongside the iOS 19 and macOS 16 updates. Beyond that, both operating systems are said to feature major design changes.\nIf an English speaker with AirPods is listening to a person speaking in another language, such as Spanish, the iPhone will detect the audio of the Spanish speaker and translate it into English. The English translation will then be played via the AirPods.\nThe English speaker's response is said to be translated and played in Spanish via the iPhone speakers. The process allegedly utilizes the Translate app and is tied to the iOS 19 update, according to a Bloomberg report.\nSamsung already has a similar Live Translate feature, which is available with OneUI version 6.1 or later. Google's Pixel Buds offer virtually the same functionality through a dedicated Conversation Mode.\nIf you're looking for new hardware, Apple is also said to be working on a new generation of AirPods Pro, as well as an AirPods model with built-in cameras. The latter will reportedly be able to analyze the surrounding environment with the help of artificial intelligence.\nRumor Score: Likely\nRead on AppleInsider\nComments\nIf Apple can shove that tech into AirPods Pro or regular AirPods via the iPhone, that would be astounding.\nFFS."
    },
    {
      "url": "https://appleinsider.com/inside/wwdc",
      "text": "WWDC\nAll about WWDC\nTable of Contents\nWWDC is an Apple event that takes place over five days, with the keynote address on the first day. The keynote has become increasingly popular among non-developers due to the presentation and the hype it generates.\nBefore the COVID-19 pandemic, Apple would invite thousands of developers to attend the conference in person. Attendees would fill the Steve Jobs Theater on the Apple Park campus to catch a glimpse of the future and get a chance to interact with Apple engineers face-to-face.\nAfter the threat of the pandemic was understood, Apple pivoted to a digital-only conference in 2020. The keynote presentation was filled with panning drone shots, high-quality editing, and fast-moving segments. All sessions and other keynotes were digital as well, with sessions taking place via Webex video chats.\nThe 2021 WWDC was digital-only as well due to the ongoing pandemic. With the shift back to normalcy in 2022, Apple relied on a hybrid approach.\nAt each WWDC, Apple unveils its latest operating system updates, software changes, and Apple Intelligence upgrades. Though the conference is meant to be dedicated to developers, Apple sometimes sneaks in hardware or service updates as well.\nUpdates are expected for the following operating systems:\nThe following developer tools are also usually updated:\nThe keynote address isn't able to reveal every change and update to all of Apple's platforms, so the remainder of the week is dedicated to sessions. These sessions cover all the new features and documentation surrounding what updates developers will need to perform before the software's fall release.\nApple has been known to announce some details ahead of WWDC to keep the conference focused on developers. The keynote is often packed to the brim with software details, so some hardware features or service updates are announced via a press release before the event.\nThe company has diverted from its usual announcement cycle to reveal hardware or services during a WWDC keynote before. Some notable exceptions included Apple Music in 2015, HomePod in 2017, the M2 MacBook Air in 2022, and Apple Vision Pro in 2023.\nWWDC 2025\nJune 9, 2025\nThe biggest redesign since iOS 7 was revealed during WWDC 25, and along with it, every OS was renamed to have version number 26. The Liquid Glass design opened up a lot of new tweaks and changes across the ecosystem.\nApple Intelligence didn't get any real upgrades in capability, but new features were added. Live Translation appears in Messages, FaceTime, and the Music app, while Image Playground has a ChatGPT option.\nOperating systems expected:\nNo hardware was announced, so no Apple Vision Pro updates or Mac Pro with M3 Ultra. Apple Intelligence took a back seat, and there was almost no mention of Apple's work on the app intent-based Siri.\niOS and iPadOS saw some of the biggest changes across the ecosystem. iPadOS has a new multitasking system that adds a Menu Bar and traffic lights, while iOS gained more functionality in several apps.\nWWDC 2024\nJune 10, 2024\nApple held WWDC 2024 to announce the usual range of operating system updates. But instead of surprising with new hardware, the company finally unveiled its plans for Apple Intelligence.\nThe trend of adding new customization options to iOS and iPadOS continued, while Apple meshed some app features together as well. Despite AI catching everyone's attention, it was still a feature-filled set of OS updates.\nOperating systems announced:\nSome expected an M3 Ultra and updates to the Mac Studio and Mac Pro, but that didn't happen. It seems Apple will skip M3 Ultra and wait for M4 Ultra in 2025.\nApple Intelligence focused on local models that run on-device, but can call out to a Private Cloud Compute server run by Apple if more power is needed. Users will benefit from a more intelligent Siri, Writing Tools, and Image Playground.\nWWDC 2023\nJune 5-9\nApple continued its trend of announcing social and customization features across its operating systems. A few surprises were also revealed, like the Apple Vision Pro and the Mac Pro with Apple Silicon.\nOperating system releases\nRumors had suggested 2023 would be a quiet year for software, but Apple pushed back on that notion with interactive widgets on iOS, a redesigned watchOS, and an all-new platform called visionOS. Developers are in for a busy summer as they prepare for spatial computing.\nWWDC 2022\nJune 6-10\nThis hybrid in-person and digital event focused on customization in iOS and developer APIs. Stage Manager stole the conversation as a new multitasking feature for iPad and Mac.\nUpdates announced\nApple also announced the M2 processor and M2 MacBook Air during the keynote. This was a surprise, as the M1 still hadn't arrived in the Mac Pro and never would.\nWWDC 2021\nJune 7-11\nThis digital-only event focused on social features and privacy. Cross-platform features were also enhanced thanks to Universal Control and SharePlay.\nUpdates announced\nApple also introduced Focus Mode, a feature that replaces Do Not Disturb with refined controls over what notifies you when. Other improvements include bringing Shortcuts to macOS and free widget placement in iPadOS.\nWWDC 2020\nJune 22-26\nThe ongoing pandemic created a lot of uncertainty going into June 2020, but Apple managed to come out swinging with a high-quality pre-recorded event. Since many of the features are worked on over the previous year, Apple didn't have any time to prep for work-from-home-focused releases.\nUpdates announced\n- iOS 14\n- iPadOS 14\n- macOS Big Sur\n- watchOS 7\n- tvOS 14\nApple continued the trend of pushing more iOS-like features to the Mac and unveiled App Tracking Transparency. Now, apps must notify users when they are going to track them, what data is collected, and how it is used.\nMost importantly, Apple announced it would transition the Mac to custom Apple Silicon, away from Intel. The transition would take two years at most and bring ARM to the Mac.\nWWDC 2019\nJune 3-7\nThere were some surprises outside of the usual operating system updates during the 2019 developer conference. Apple revealed iPadOS, the new operating system for the iPad that takes advantage of the larger display. It also shared a preview of the Mac Pro and Pro Display XDR, a top-end Mac for professionals that would debut later in the year.\nUpdates announced\n- iOS 13\n- iPadOS 13\n- macOS Catalina\n- watchOS 7\n- tvOS 14\nOther new features included SideCar, which enables using iPads as an external display for the Mac. Also, Apple Watch gained menstrual cycle tracking."
    },
    {
      "url": "https://appleinsider.com/articles/24/10/24/airpods-pro-2-receive-support-for-hearing-health-features-with-new-firmware-update",
      "text": "Apple has released a new firmware update for AirPods Pro 2, which ushers in support for an all-new set of Hearing Health features.\nThursday's firmware increases the build number to 7B19, from the previous 7A305. The company's latest firmware update for AirPods 2 was deployed on October 24, following the release of firmware updates intended for developer testing.\nIn June, at WWDC 2024, Apple announced that the AirPods Pro 2 would receive an assortment of Hearing Health features, which includes Hearing Test, Hearing Aid, and Hearing Protection. Of these three, the clinical-grade Hearing Aid feature is intended for users with mild to moderate hearing loss.\nFollowing the FDA approval of Apple's Hearing Health features in September, settings for them appeared in developer betas of iOS 18.1.\nOn October 21, the first reviews of Hearing Health came out, confirming the release date of the features. iOS 18.1 is scheduled for release on October 28, alongside iPadOS 18.1, macOS Sequoia 15.1, and more.\nWhile the main focus of the iOS 18.1 update is Apple Intelligence, a suite of generative AI features, the software also ensures compatibility with the Hearing Health features of the AirPods Pro 2. IOS 18.1 is nearing the end of beta testing, as release candidate versions of the operating system were issued on October 21.\nThursday's new firmware update is installed automatically for users when the AirPods are plugged into their charging case and connected to an iOS device. There is no manual installation method for this firmware update.\nHow to check your AirPods firmware version\nAirPods users can check the current firmware for their audio accessories by accessing the Settings app on their iPhone or iPad.\n- Open the Settings App\n- Select General\n- Select About\n- Select the AirPods you wish to view\nA menu will appear showing relevant device information."
    },
    {
      "url": "https://appleinsider.com/inside/airpods",
      "text": "AirPods\nAll about AirPods\nTable of Contents\nApple may not have been the first to make \"true-wireless earbuds,\" but it has undoubtedly popularized and perfected them with AirPods. When the company revealed an iPhone without a headphone jack, it gave users a solution \u2014 a $160 set of Apple headphones.\nThe AirPods brand has evolved to become an entire product line ranging from affordable to ultra-premium. With the introduction of the AirPods 4, there are now two entry models, AirPods Pro 2, and AirPods Max in the lineup.\nPreviously, and still possibly for sale at a discount, there were the budget second-generation AirPods, the AirPods 3 with entry-level features, and the original AirPods Pro with more premium features. Apple updated AirPods Max with new colors and USB-C in 2024, but nothing else changed.\nWhat makes something an \"AirPod\" is its Apple-first design and vertical hardware and software integration. In AirPods, the H1 and H2 chips lead to better battery life, \"Hey Siri\" or \"Siri\" support, better connectivity with low latency, and operating-system-specific integrations in software.\nWhen a set of AirPods is near an iPhone or iPad, it will show up on the screen in a UI card for pairing and viewing battery life. Any device with a W1, H1, or H2 chipset is paired with the user's iCloud account and will fast-switch between devices when selected in the AirPlay menu.\nIf automatic switching is enabled, any time audio is played from a device, that device's audio output will switch to the user's active AirPods. However, this can also lead to frustrating experiences if a user did not intend this switch to occur. Users can set automatic switching to AirPods on a per-device basis.\nWhen paired with any Apple product, various controls on AirPods are available from within the UI and Control Center. These include switching between Active Noise Canceling and Transparency mode, selecting Spatial Audio mode, and shared audio controls.\nNew AirPods rumors\nAirPods Pro 3 likely aren't due until at least 2025 given the recent USB-C update. However, AirPods Max could get a chip upgrade at some point in the future, considering they still run the aging H1.\nRumors suggest Apple isn't actively developing AirPods Max 2. So, it could be some time before an update arrives, if ever.\nAirPods Pro 3 are in development but there aren't any concrete rumors about a release window. These likely would continue the trend of adding health features to the earbuds. Signs point to heart rate detection or cameras.\nSince Apple Intelligence requires powerful chipsets with large Neural Engines and significant RAM, there's no possibility of seeing on-device Apple AI in AirPods anytime soon. However, improvements in a potential H3 processor could improve language processing before passing requests to the iPhone's on-device models.\nThe next generation of low-end AirPods could have a new H3 processor, but it may be some time before that update. Once AirPods Pro 3 and a new H2-variant of AirPods Max are released, the cycle of new products should start again.\nSoftware Updates\nFind My AirPods was introduced in iOS 10.3, allowing a user's Apple devices, such as an iPhone, iPad, or Mac to keep tabs on the whereabouts of the tiny earphones. Utilizing the host device's positioning hardware, GPS, Wi-Fi, or other component packages, the connected device could tell a user where a missing AirPod was last seen.\niOS 13 and later allow a user to pair two sets of AirPods to one iPhone or iPad. This lets two people watch a movie or listen to music in tandem.\nThe latest versions of iOS also allow text-to-speech reading of messages from iMessage and third-party apps like WhatsApp. This lets users keep tabs on their messages when it isn't practical to look at their iPhones.\niOS 14 enables \"auto-switching\" of AirPods with an H1 chip, including all current models of AirPods and select Beats by Dre headphones. Alongside iOS 14, Apple launched a firmware update that added Spatial Audio to AirPods Pro.\niOS 15.1 adds improved Find My features, including a new Lost Mode and Find My network integration. Users who misplace their AirPods will see their device's location updated as other Apple devices on the Find My network pass nearby.\niOS 16 adds a new feature that uses the 3D dot projector to scan a user's ear and determine the best way to play back Spatial Audio through AirPods.\niOS 17 and software updates for every AirPods model add new features like press to mute, Adaptive Audio, improved Personalized Volume, and Conversation Awareness. Most new features are reserved for AirPods Pro 2.\niOS 18 revealed a new gesture that lets users shake their head no or nod yes to Siri. For example, Siri could announce an incoming call and you shake your head to decline.\nVoice isolation is also included on AirPods, which will attempt to reduce noises that aren't the user's voice. These features require an H2 processor.\nApple Intelligence isn't coming to AirPods specifically, but it is coming to Siri on iPhone, which is controlled from connected AirPods. Users with Apple Intelligence features enabled on their iPhone, iPad, or Mac will have access to a more intelligent Siri that understands mid-sentence corrections and additional context.\nWhile every new Siri with Apple Intelligence feature may not be ready until early 2025, some of the updates are already present in the iOS 18.1 beta.\nOne significant update for AirPods Pro 2 includes hearing health features. Users can take a hearing test, activate hearing protection for certain environments, or use the earbuds as hearing aids.\niOS 26 continues to add features to AirPods 4 and AirPods Pro 2 thanks to the advanced H2 processor. There's also Workout Buddy, which speaks to the user through headphones and AirPods when performing specific workouts while wearing Apple Watch.\nUsers can set a press or a hold to start and stop video recording while in the Camera app or third-party app. It replaces whatever function is assigned to the gesture, but only when the Camera is active.\nThe microphones have also been improved to capture better audio and isolate the user's voice. There's also the voice isolation mode that blocks out nearly every noise besides the user's.\nOther new features include alerts to charge AirPods or when they have finished charging, an option to keep audio in headphones when connecting to CarPlay, and the ability to pause audio when the user falls asleep.\nHow to clean your AirPods\nApple's AirPods can get very dirty because they are worn in your ears and travel within your lint-filled pockets, so cleaning them regularly is a must. You don't need to douse AirPods in water or scrub them with abrasive materials. Instead, you need an AirPods cleaning kit or isopropyl alcohol.\nIt is quite easy to damage AirPods speakers and microphone grilles, so do not start poking around with sharp instruments, needles, or toothpicks to try and extract dried wax. A cloth with a dab of water or isopropyl alcohol may do the trick, but aged grime stuck on AirPods may need a better approach.\nThere are tools, like the one mentioned in the above video, with soft brushes and metal tips for cleaning hard-to-reach places on the AirPods that are sold for a relatively low price. These are not Apple-certified so use the tools at your own risk.\nRead our tip for how to clean AirPods and the AirPods Charging Case or find out more about the best tool to safely clean your AirPods or AirPods Pro.\nAirPods Pro 2\nAirPods Pro 2 use the H2 processor for improved Active Noise Cancellation, Adaptive Transparency, and improved audio. They have Bluetooth 5.3 for a higher bandwidth connection.\nThe AirPods Pro second-generation use the same design but offer several new features. They include a new extra small earbud for a better fit, and the Charging Case has several quality-of-life improvements.\nActive Noise Cancellation now blocks twice as much noise as before. Also, Transparency Mode gets upgraded with Adaptive Transparency, which samples sound at 48,000 times per second for instantaneous noise blocking.\nUsers can swipe on the stem for volume control. Also, the battery lasts six hours on a single charge.\nThe AirPods Pro Charging Case can be charged via Lightning, MagSafe, or Apple Watch charger. It has a speaker for Find My, a U1 chip for precise finding, and a lanyard hole for securing them to an object.\nApple introduced a new feature called Adaptive Audio during WWDC 2023 that only work in the AirPods Pro 2. It combines Transparency Mode and Active Noise Cancelation in a single mode that intelligently adapts audio based on surroundings and active conversation.\nAn updated set of AirPods Pro 2 were released in 2023 with a USB-C MagSafe Charging Case. They are nearly identical, but include a 5GHz radio for lossless audio playback from Apple Vision Pro.\nThe H2 in the new model can communicate directly with the H2 in the headset for the connection. The older AirPods Pro 2 with Lightning have an H2, but lack the 5GHz band.\nApple keeps adding new features for the H2 chipset. Users can nod or shake their head to answer Siri, like when an incoming call is announced or a message needs a reply.\nAirPods Pro 2 got a set of new hearing health-focused features in 2024, which were approved by the FDA. A hearing protection mode, hearing test, and hearing aid feature help users with their hearing health.\nAirPods 4\nThere are two tiers of AirPods 4 meant to replace both the bottom tier, discounted gen 2 AirPods still for sale and the mid-tier AirPods 3. They share most of the same base functions, but the more expensive AirPods 4 gain ANC and charging case upgrades.\nThe AirPods 4 take on the small AirPods 3 design with no changes. The higher-priced model gets a speaker for Find My in the charging case, plus the case supports MagSafe and Qi.\nThe cheaper model charges only over USB-C and doesn't have a speaker in the case. It lacks ANC, Transparency, and Conversation Awareness that are available in the higher priced model.\nAirPods 3\nThe third generation of AirPods takes on a new design that mimics the AirPods Pro. The shorter stems on the newest AirPods have pressure-sensitive controls for pausing audio and summoning Siri. The earbuds are bulbous and direct sound into the ear.\nApple implemented a few AirPods Pro features into its new mid-tier earbud. For example, these have Adaptive EQ, which has customized audio adjusted in real-time based on the listener's ear shape and earbud fit.\nApple also made the new AirPods water-resistant. That means sweat and rain won't damage the earbuds, but they still aren't optimized for anything more intense.\nThe battery life of each earbud is now six hours. The charging case can fully recharge the earbuds four times, leading to 30 hours of use. Five minutes of charging enables one hour of use.\nThe charging case is also capable of wireless charging and can be placed on a MagSafe Charger. Magnets lock the charging case in place but still charge at the same rate as a Qi charger.\nThe third-generation AirPods cost $179 and are available in white. A new fourth-generation set could introduce multiple tiers to create a better price ladder.\nReview\nAppleInsider scored the third-generation AirPods a 4 out of 5. The new features and design in the newest AirPods are worthy upgrades to Apple's wireless earbuds, but they occupy a strange place in the lineup.\nDesign\nThe earbuds themselves are a cross between the original AirPods and the AirPods Pro design. The stem is shorter and has a more bulbous earpiece, but there aren't silicone tips for a custom fit. Apple heralds the design as a \"universal\" fit, but your results may vary.\nThe charging case is squatter than the original case but not as wide as the pro case. It ensures four additional charges are available to your AirPods when not in use, however.\nWe liked that the charging case can magnetically attach to MagSafe Chargers. The extra security of that grip ensures the wireless charger is aligned and makes charging the case less of a hassle.\nSound\nThe sound quality is improved when compared to the second-generation model. There are other wireless earbuds in the $180 price range with better sound quality, however, and the AirPods Pro isn't that much more expensive when found on sale. Even the Beats Fit Pro seems to have a better bass-heavy sound with changeable ear tips and ANC modes for $20 more. Audio quality and style will be a personal choice, so there are options for users within Apple's ecosystem if AirPods don't quite cut it.\nSpatial Audio with dynamic head tracking is an interesting feature that won't appeal to everyone. We've enjoyed listening to Dolby Atmos music and viewing movies via Apple TV with this option enabled, but the feature can be turned off for those seeking a more traditional listening experience.\nOverall Value\nAs a set of AirPods, these are the obvious choice for those seeking the latest and greatest feature set while avoiding the complications of exchangeable ear tips or ANC modes. AirPods 2nd generation are still for sale at a much lower price point, so those may be a better choice if budget is a concern above all else.\nIn the $150 to $200 range, there are many earbuds and headphones a user can pick from, several of which are Beats earbuds with Apple's proprietary H1 processor. This means the customer will have to decide based on fit, finish, and sound reproduction \u2014 all of which are personal decisions.\nPros\n- Improved audio quality\n- Smaller stem\n- Force stems replace the fickle tapping controls\n- MagSafe charging case is wonderful\n- Smaller stems look better while wearing\n- Very comfortable\n- Adaptive EQ tunes audio automatically\n- Spatial Audio with head tracking is great for movies, sometimes audio\n- IPX4 resistance helps for workouts or weather\n- Skin detection sensor helps prevent audio starting inadvertently\n- Battery life is fantastic\nCons\n- No tight seal in your ears\n- Case still scratches easily\n- Hard market position between second-generation AirPods, AirPods Pro, and new Beats\n- No color options\nAirPods Max\nThe AirPods Max is Apple's first over-the-ear headphones. They use the proprietary H1 chip and include Adaptive EQ, Active Noise Cancellation, Transparency Mode, and Spatial Audio.\nApple is shipping the over-ear headphones in five colors: space gray, silver, sky blue, green, and pink. The unique design aims to achieve ultimate comfort while remaining easily identifiable as an Apple product.\nAirPods Max introduced Adaptive EQ to the line, adjusting audio based on the ear-cup seal and sound within the headphones. It measures the sound signal and adjusts the low and mid-frequencies in real-time. Apple's goal is to use real-time data to provide richer and more detailed audio.\nSpatial Audio with Dolby Atmos support enables music to surround the listener when properly formatted for the feature. Thanks to further updates to the format, users can use the gyroscopes in the AirPods Max to move their head within the sound as of iOS 15.\nAirPods Max were updated with a USB-C port and nothing else in 2024. A true second generation model that is lighter with a better chipset isn't expected until 2027.\nReview\nAppleInsider scored the AirPods Max 4 out of 5 shortly after their release in 2020. Its integration into Apple's ecosystem, premium design, and good quality audio add up to justify the $550 price point, but just barely.\nThe following review observes the headphones in that 2020 market, but much changed in the years to the 2024 USB-C update. While they still produce premium sound, they are being left behind thanks to their aging H1 processor.\nDesign\nWe believe the AirPods Max have one of the most bespoke designs ever created for a set of headphones. The stainless steel headband is coated with a soft-touch material similar to silicone. The canopy is made of a proprietary mesh that lets the headband rest atop your head while evenly distributing weight.\nThe steel and aluminum construction, the internal batteries, and everything else add up to a heavy set of headphones. At 14 ounces, these weigh more than competitors', which are usually nearly half the weight. However, we've worn AirPods Max for many hours, and the weight hasn't been an issue.\nOf course, weight feel and tolerance of that weight will vary from person to person. Accessories and third-party earpad options will let users customize the fit and weight distribution of the headphones as they see fit.\nThe Case\nApple chose design over function for the AirPods Max case. While other AirPods have charging, pairing, and other functions built into their case, this one is a simple piece of fabric with magnets.\nCustomers and pundits alike have had rather visceral reactions to the case, and while we don't hate it, we believe it could be better. Apple seems to have chosen a form factor for the sake of being different, which sacrifices functionality and practicality.\nThe fabric cover does little to protect the expensive headphones and offers only one essential feature \u2014 low-power mode. A magnet within the case activates a low-power sleep function of the AirPods Max that keeps them from pairing to devices. After 18 hours of being in this state, Bluetooth and Find My is disabled entirely.\nThird-party cases can build in this functionality, so those who dislike this case can find one that fits their needs. We didn't mind some aspects of the case, like having the headband exposed. This makes them easier to grasp when taking them out of your bag and takes up less space when packing.\nOur biggest critique of the case is its lack of protection for the ear cups. The soft aluminum casing seems to be the most vulnerable part of the AirPods Max, yet the case barely protects it. We'd be happier if Apple made a case that completely encased the ear cups.\nSound modes\nThe Active Noise Cancellation for AirPods Max is easily best-in-class and performs much better than the AirPods Pro. The larger drivers, ear isolation, and additional microphones make the ANC perform great compared to other models.\nThe Transparency Mode is also quite good, though we ran into a few shortcomings during our tests. This mode allows external noise to be passed through the headphones into your ears, so things like vehicles passing by or people's voices can get through. While Transparency Mode works great in most conditions, high-pitched noises and subtle rustling can creep through, and there's no way to fix this.\nThe effect of watching properly mixed media can be pretty jarring for first-timers on AirPods Max. Thanks to the Spatial Audio with head tracking feature, central channel audio will always sound like it is coming from the device, like your iPad. This makes it seem like your headphones aren't working since it sounds like the audio is playing from the device speakers.\nWhen listening to multi-channel content, especially content mixed in Dolby Atmos, this effect expands to surround you. So, if a sound is coming from your left during a video, you can physically turn your head and \"face\" the sound.\nSince our review, Apple has added the ability to listen to Apple Music in Dolby Atmos. The same head-tracking effect will occur when enabled and let users move their heads through the music audio.\nAudio Quality\nWe were underwhelmed by the audio produced by Apple's ultra-premium headphones. While the audio is pleasing and improves at higher volumes, audiophiles and those expecting $550 sound will be disappointed.\nApple built these headphones to offer premium sound and a range of features to cater to its customers. The combination of technology and premium materials pushed the price higher, not the audio fidelity. However, we believe the average consumer will be fine with the sound produced.\nOverall Value\nThose who want premium headphones deeply integrated with Apple's ecosystem will find value in the AirPods Max. They are above average and compare favorably to popular consumer choices in the $350 range, but it is difficult to justify the higher $550 price tag.\nWe believe the price is worth it, however, and Apple users will enjoy all the deeply integrated experiences. Customers shouldn't be buying these based on sound quality alone, but the feature set, build quality, and sound as a whole.\nPros\n- Excellent, premium design\n- Dual H1 chips for audio processing, range, and signal robustness\n- Extremely comfortable\n- Deep iOS integration\n- Spatial audio is killer\n- Better than average audio\n- Good battery life\n- Excellent ANC\n- Solid physical controls\nCons\n- The case \u2014 enough said\n- Controls are easy to bump when removing the headset\n- Audio quality could be better\n- Transparency mode harsh on highs\n- No aux cable included and Apple's is expensive and fragile\nAirPods Pro (1st generation)\nIn 2019, Apple introduced the AirPods Pro \u2013 a new high-end version of Apple's earbuds. While they look similar, the pro-level earphones have silicone ear tips that allow noise isolation and customizable wear.\nFeatures include Active Noise Cancellation, a new touch-control system, and a Transparency Mode that allows users to mix ambient noises with audio from the user's device.\nThis model has similar battery life to the previous generation, though using Active Noise Cancellation will reduce that somewhat. They utilize the same H1 chip, enabling quick switching between devices and \"Hey Siri\" voice commands.\nApple added Spatial Audio to the AirPods Pro in a September 2020 firmware update alongside iOS 14. The feature uses accelerometers and sensors to determine which direction sound should be coming from. It supports Dolby Atmos and multiple-channel surround sound up to 7.1 channels.\nThe update also included automatic device switching when users start playback from different devices. Users can turn off automatic switching on specific devices to make the experience more useful.\nReview\nAppleInsider scored the AirPods Pro 4.5 out of 5. The improved audio quality, ANC and Transparency modes, and sweat resistance make this an obvious choice for anyone looking for a truly wireless earbud. Still, existing AirPods users may not need to make the jump.\nFit and Audio Quality\nWhen testing the AirPods Pro, we knew we wanted only a few things to justify the upgrade from the standard model. First and foremost was a more secure fit.\nWe hit the gym and tested our everyday routines with the AirPods Pro in our ears. To our surprise, we made it through an hour and a half without a single earbud coming free.\nApple includes three sizes of ear tips with your purchase, so you have some choice out of the box. We'd have preferred more size choices but appreciated the ear tip fit test that told us if our fit was secure enough and the sound wasn't bleeding out.\nSpeaking of sound, the quality was excellent. While it isn't audiophile quality or able to compete with over-the-ear cans, the sound was enough for us to say \"wow.\"\nANC and Transparency Mode\nActive Noise Cancelling came in handy in some situations, but we feel that we're not using it as much as others may. The sound mode we defaulted to most was Transparency Mode.\nBeing able to hear your environment, hold conversations, and move around safely with Transparency Mode active made this one of our favorite features. The sound felt more natural when compared to the noise blocking ANC mode.\nOverall Value\nWe feel that customers will fall into one of three camps when shopping for AirPods Pro \u2014 existing AirPods users, new users, or budget-concerned users.\nIf you're looking at the AirPods without the wireless charging case, then the $100 price jump is difficult to justify. Those whose priority is the price should look to Apple's cheaper models. However, if you're at all tempted by the AirPods with wireless charging case, then the $50 price bump is a no-brainer.\nExisting AirPods owners will be the most difficult to convince. The customizable fit, better audio quality, and water resistance may be enough to justify an upgrade, but only just.\nPros\n- Smaller design\n- Much better audio quality\n- Great ANC\n- Transparency mode is outstanding\n- Stay in much better\n- Work with Audio Sharing\n- Announce messages with Siri is particularly useful\n- Water/sweat resistant\nCons\n- Needs more granular ear tips\n- Force sensors are awkward to use\n- Charging case is awkward\n- Higher price tag and no price decrease on second-gen\nAirPods (original)\n2nd Generation\nApple launched the second-generation AirPods in March 2019, with the first hardware update providing a host of new features that improved Apple's earbuds.\nSwapping out the W1 chip for the H1 processor means second generation AirPods are twice as fast when switching between active devices and one-and-a-half times faster for phone calls, with 30 percent lower gaming latency. The H1 chip in the second generation AirPods included support for hands-free \"Hey Siri\" functionality, allowing users to control volume and swap songs via voice commands, so owners of this version don't have to tap the earphones with a finger to activate Siri.\nBeam-forming speakers work in tandem with accelerometers to detect vibrations in a user's skull, giving AirPods improved background noise reduction. Tap gestures let users change tracks or volume and activate Siri if one doesn't want to use \"Hey Siri.\" A separate voice accelerometer kicks in to block ambient sound.\nAirPods provide up to five hours of battery life when listening to music, and the case provides an additional 24 hours of use. The addition of the H1 chipset increased talk time an entire hour to three total. According to Apple, popping them in their case for 15 minutes yields more than three hours of playtime.\nSecond-generation AirPods use Bluetooth 5, which improves stability and range, especially on newer iPhones.\nIn addition to a new processor chip and Bluetooth 5, the second-generation earphones also add a new Wireless Charging Case. The Wireless Charging Case is compatible with any Qi-enabled charging mat. Users can also purchase it separately for $79 to upgrade the first-generation AirPods.\nWhen opening the Charging Case, the earphones inside automatically connect to a nearby device. Using built-in sensors and an accelerometer, they can detect when they are in-ear, playing, and pausing audio accordingly.\n1st Generation\nPhil Schiller, Apple's former SVP of Worldwide Marketing, debuted the AirPods on stage at the September 2016 iPhone event that debuted the iPhone 7 and Apple Watch Series 2. Inside the AirPods is Apple's custom W1 wireless chip, which affords a fast and robust connection while allowing for five hours of use.\nApple had filed its first AirPods-related patent in June 2015. The primary motivation for creating an all-wireless earbud was the headphone jack and the desire to remove it.\n\u201cWe\u2019ve got this 50-year-old connector \u2014 just a hole filled with air \u2014 and it\u2019s just sitting there taking up space, really valuable space,\" said SVP of Hardware Engineering Dan Riccio. \u201cIt was holding us back from a number of things we wanted to put into the iPhone. It was fighting for space with camera technologies and processors and battery life. And frankly, when there's a better, modern solution available, it's crazy to keep it around.\u201d\nThe additional space allowed Apple to more easily install the Taptic Engine that powers the solid-state iPhone 7 home button; include bigger batteries; and remove a key point of liquid ingress, permitting the company to meet the IPX7 water-resistance specification. The AirPods went on sale in December 2016 and started shipping later that month.\nSince their debut, Apple's AirPods have made a sizable impact on the wireless headphone market, with the audio accessory reportedly capturing more than a quarter of the market by early 2017.\nReview\nAppleInsider scored the first generation AirPods 5 out of 5 stars. The update added more features to an already near-perfect set of earbuds.\nAudio\nAudiophiles will tell us that there are better-sounding headphones out there, but we won't care. In our testing, we found the audio of Apple's truly wireless earbuds to be great and an improvement over the first-generation model.\nThe louder volume and better audio quality make for great sounding headphones in a compact form factor. Combine that with Apple's integration into its device ecosystem, and you'll have trouble finding something that matches these earbuds feature-for-feature.\nSiri\nA game-changer is the ability to summon Siri with the \"Hey Siri\" command rather than a double-tap. Having hands-free Siri at our beck and call enabled us to interact with the assistant more frequently and more accessible than ever.\nApple also sped up the interaction to belt out your entire command without waiting for the \"beep\" to indicate Siri was listening. While this leaves you wondering if it heard you correctly, it does make each interaction faster and smoother.\nSiri isn't without its downfalls, however. The \"Hey Siri\" command will activate any device within listening range, and the devices will poll who is meant to answer based on several metrics. While this polling works, it isn't foolproof, and we've had a HomePod and AirPods respond to the same command.\nAirPods versus other earbuds\nThe third-generation AirPods are Apple's latest earbuds meant to have the largest market appeal thanks to a mix of features and a decent price point. AppleInsider has compared each of Apple's earbuds with each other and the competition, and this is what we've discovered.\nAirPods versus AirPods Pro (1st generation)\nThe third-generation AirPods may offer a handful of new features and a pro-like design, but it becomes difficult to choose when you consider AirPods Pro. Fit, sound modes, and battery life will be the biggest deciding factors for customers.\nIf you're in the market for new true wireless earbuds and don't need fancy features like ANC or Transparency Mode, then you'd be well served by third-generation AirPods. They are cheaper and have Adaptive EQ and Spatial Audio like AirPods Pro.\nHowever, those who want a more custom fit, sound isolation, and ANC modes will want the AirPods Pro. As a bonus, these earbuds have been on the market for over two years, which means sales will drive the price down within dollars of the standard AirPods.\nRead the spec breakdown and more feature differences in our full comparison.\nAirPods vs Beats Fit Pro\nWhen considering third-generation AirPods versus the Beats Fit Pro, the same considerations have to be made when comparing AirPods Pro. The Beats Fit Pro have a different, more custom fit, with ANC modes and different battery life.\nThe Beats Fit Pro are $199, have a slightly \"cheaper\" plastic feel, and use the Beats brand signature sound programming. However, they are more friendly with Android devices thanks to a dedicated app experience, so switching between an iPad and an Android phone is much more seamless than with AirPods.\nThe charging case for the Beats Fit Pro is much larger than the AirPods case but only provides up to 24 hours of the total charge to the earbuds. AirPods get 30 hours total when using the charging case.\nCustomers also get color options with the Beats Fit Pro, while AirPods are only available in white. Beats Fit Pro are available in Beats White, Beats Black, Sage Gray, and Stone Purple.\nRead the spec breakdown and more feature differences in our full comparison.\n3rd generation AirPods versus 2nd generation AirPods\nThose who have a budget in mind above all else will buy the second-generation AirPods, but the decision isn't quite so clear if the price isn't your only consideration. The third-generation AirPods are a solid upgrade and have a price right between the previous models.\nThe new features like Spatial Audio with head tracking and improved water resistance will appeal to most customers. This is especially Audio quality has improved too, but the fit has changed. Even if the original version fits your ears, the new more-bulbous design may not.\nBattery life improvements are also a big gain for those considering the third-generation model. Also, there are no ANC modes to complicate battery life, the earbuds simply get six hours of listening time when in use.\nRead the spec breakdown and more feature differences in our full comparison.\nAirPods Pricing\nAirPods with standard charging case cost $129. The third-generation AirPods model is $179, and the AirPods Pro 2nd genration ring up for $249. AirPods Max cost a premium of $549."
    },
    {
      "url": "https://appleinsider.com/inside/translate",
      "text": "Translate\n-\nActive Discussions\n-\nHow to use Google Translate as the iPhone's default translation app\nAll about Translate\nTable of Contents\nApple added the Translate app via its 2020 software updates, and improved the functionality in 2021. Appearing in Siri, Safari, and a standalone Translate app, the on-device intelligence lets users quickly translate spoken and written text between two languages without using any third-party apps.\nWhile non-Apple translation apps have been in the App Store since the earliest days of the iPhone and iPad, iOS 14 marks the first time Apple has offered its own translation app.\nThe Translate app\nTranslate is a Siri-powered standalone app that Apple launched with iOS 14. It converts spoken or written words or phrases between two chosen languages.\nApple's translation app is initially launched as an iPhone-only app, but was later added to iPad as part of iPadOS 15 when it released in the fall of 2021.\nAvailable Languages\nThe app, which comes pre-installed on iOS 14 and later, has a minimalistic interface. You choose languages by tapping on the two language buttons at the top of the screen. By default, the first button will be the native language you use for iOS.\nThe Translate app currently supports the following languages:\n- Arabic\n- Chinese\n- English (UK)\n- English (US)\n- French\n- German\n- Italian\n- Japanese\n- Korean\n- Portuguese\n- Russian\n- Spanish\nSpoken and Written Translations\nThe app allows you to either type or speak the text you want to translate. If you say your words or phrase aloud, it will speak the answer in an AI voice and also display it onscreen. If you type your text, it will only show the translation, but you can still tap a \"Play\" button to hear it spoken.\nThere's a dictionary button that lets you look up individual words by tapping on them and a star button that allows you to add that translation to your favorites. Favorites reside in a separate tab you can navigate to at the bottom of the screen.\nTranslate Conversations\nTranslate also has a conversation mode that allows two people to use one iPhone to speak to one another in two separate languages. The app listens to each person speaking and plays spoken translations immediately afterward.\nAfter choosing the two languages at the top of the screen in portrait mode, you can enter conversation mode by turning the iPhone into landscape mode. Each person taps the mic button before speaking. The Translate app will play the verbal translation immediately after someone says something.\nIf you turn on \"automatic detection,\" the app will figure out on its own which language you're speaking and translate accordingly. You can toggle automatic detection on or off in settings.\nWhile in conversation mode, you can also tap on the full-screen button to display the resulting translation in extra-large type. This can be useful for showing someone a translation from a distance.\nOffline Translation\nThe Translate app supports offline languages. The language selection menu lets you choose any available languages to download to your device. Offline languages also enable you to use the app without a data connection.\nIn the iOS Settings app, you can also set the app to only support offline languages even when it has a data connection. While Apple cautions that this mode may be less accurate, it prevents any of your data from leaving your device, adding extra privacy assurances.\nSystem-wide translation\nTranslate in Safari\nApple also added native translation to its Safari web browser in iOS 14, iPadOS, and macOS Big Sur. It translates entire web pages from their original language into your native language.\nTo use Safari translation:\n- Tap on the \"AA\" button at the left end of the address field. If the page is translatable, you'll see a \"Translate to\" option in the menu. Tap that, and if it prompts you to \"Enable Translation,\" choose that as well.\n- You should then see the entire webpage displayed in your chosen language.\n- To return to the original language, tap the translate button on the left of the address field that's now in place of the \"AA\" button.\nTranslate with Siri\nThough all of Apple's translation features use Siri intelligence, you can also use the Siri voice assistant to translate words and phrases to another language. Siri first gained translation abilities in iOS 11.\nWhen used in the voice assistant rather than the standalone app, Siri can only translate your spoken words and phrases to a destination language. Unlike in the app, Siri won't convert words and phrases from other languages back to your native language.\nTranslate with Live Text in Photos\nLive Text is included in Apple's 2021 operating system releases available in the fall. Machine learning algorithms see text via the Camera app or via photos already taken in the Photos app. Select text by highlighting it and perform various operations like making a call or setting a calendar event.\nThanks to system-wide translation, users can also translate text directly from their camera's viewfinder. Select the text in the image and pick \"Translate\" as an option. This feature was previously seen as a powerful third-party app on the App Store, but is now baked into the operating system."
    },
    {
      "url": "https://appleinsider.com/articles/24/07/09/an-exclusive-real-world-look-at-the-haptic-buttons-apple-developed-for-the-iphone-15-pro",
      "text": "The iPhone 15 Pro was rumored to feature haptic buttons with an all-new design, but Apple's project never saw the light of day \u2014 until now. Here's what those buttons looked like, and what Apple scrapped along the way to a finished product.\nEarly development prototypes of the iPhone 15 Pro and iPhone 15 Pro Max had haptic volume and power buttons, developed under the codename Project Bongo. While these mysterious haptic buttons were widely rumored to exist, they have previously never been seen on actual hardware.\nSpeaking to a collector of Apple prototypes, AppleInsider has obtained exclusive imagery of a prototype iPhone 15 Pro Max, equipped with the elusive Project Bongo. We have also received numerous details about the buttons themselves, and the user experience relative to standard mechanical buttons.\nThe device in question is an EVT-stage prototype of the iPhone 15 Pro Max, known during its development period by the device identifier D84 and project codename \"Veyron.\" EVT prototypes of the iPhone 15 Pro and iPhone 15 Pro Max were the last to include Apple's haptic buttons, as the feature was abruptly scrapped in early April of 2023.\nIn terms of software, the EVT prototype runs an InternalUI build of iOS 17. This means the device contains a specialized variant of the iPhone operating system used internally by Apple engineers for development and testing purposes.\nWith the later CRB and DVT prototype stages, Apple changed the iPhone 15 Pro and replaced its new haptic buttons with standard mechanical ones. This means that CRB, DVT-stage, and later prototypes of the iPhone 15 Pro and iPhone 15 Pro Max do not contain any exterior differences compared to their mass-production counterparts, making them less interesting to collectors as a result.\nThe Action button, the multi-purpose, user-configurable mechanical button located above the volume button, also changed during development, but to a much smaller extent. While the haptic volume and power buttons were completely phased out, the Action button only received minor changes affecting the overall shape, making it more round and wide.\nThough it was developed alongside the haptic volume and power buttons, the Action button itself was always a mechanical button, which explains why it was left more or less unchanged. According to the prototype collector interviewed by AppleInsider, the Action button behaves differently from the unified volume button on the EVT prototype discussed earlier.\nHow Apple's canceled haptic buttons behave versus traditional mechanical buttons\nThe haptic buttons initially planned for the iPhone 15 Pro are somewhat similar to traditional mechanical buttons because they both apparently move when pressed. If the device is on, the haptic volume and power buttons generate feedback along with a clicking sound whenever they are pressed.\nAppleInsider was told that the unreleased buttons generate haptic feedback when pressure is applied, and immediately after the button is released. In doing so, Apple likely tried to mimic the overall feedback and noise mechanical buttons typically produce, essentially the same way that the Magic Trackpad works.\nAlthough the project was canceled, and the final mass production units do not feature Apple's Project Bongo, the EVT device referenced throughout this article paints a pretty good picture of what could have been. We were told that the device accurately replicates the tactile sensation and feedback created by ordinary mechanical buttons.\nIf the device is off, and cannot display the usual charge indicator due to a completely drained battery, the buttons will still move but will not provide haptic feedback to the user. In short, no power, no click.\nThe iPhone 7, for instance, featured a solid-state home button that used Apple's Taptic Engine to provide vibration feedback similar to the press of a physical button. The button itself never actually moved, though, unlike the Bongo buttons the company initially developed for the iPhone 15 Pro.\nWhen an iPhone 7 was powered down, its solid-state home button never provided any vibration feedback or moved. The haptic buttons on the iPhone 15 Pro Max EVT both move and generate haptic feedback, even when powered down, as long as the device has at least enough power to display the charging indicator.\nAccording to people familiar with the matter, the Bongo-type buttons used dedicated firmware, containing references to a \"deep sleep\" mode. It's possible this deep sleep mode was activated once the device was powered off or inactive for large periods of time.\nInterestingly, the collector we spoke to also told us that the buttons responded to pressure even when touched with a gloved finger, or when used inside of a pocket. This means that the buttons are capable of detecting changes in pressure without direct skin contact.\nThe key hardware components of Apple's Bongo Project, and how it worked\nApple's Project Bongo accomplishes this through carefully designed hardware. The button detects pressure through flexures and strain gauges, which then cause a change in resistance within an electrical circuit.\nThis change in resistance is measured, and a signal is sent to the main logic board (MLB), indicating the button was pressed.\nFlexures and strain gauges were used to detect changes in pressure, in specific areas of the unified volume button. This means that even though the volume button was a singular button, the iPhone would still be able to tell if the user wanted to decrease or increase their current volume based on where the strain from the touch was sensed.\nAfter touch and location interpretation, the main logic board provides power to the components that generate haptic feedback. In the case of the Bongo Project, Apple created an electromagnetically driven reluctance motor known as the \"Bongo Haptic Engine.\"\nThe Bongo Haptic Engine was an electromagnetic reluctance motor, consisting of a ferromagnetic core and copper coil, that together constitute a solenoid. It generated haptic feedback the same way the regular Taptic Engine does, by oscillating in relation to an attraction plate located underneath.\nThe Bongo Haptic Engine was a significant change, but it was ultimately in line with Apple's previous hardware upgrades. The iPhone 4s received a Linear resonant actuator (LRA), which ultimately led to a reduction in noise and an improved response time. With the iPhone 6s, Apple introduced a haptic LRA via the Taptic Engine, which can be found in every iPhone iteration since then.\nThe earliest known designs for the Bongo project date back to 2021, two years before the release of the iPhone 15 Pro. The goal of the project was to replace the iPhone's traditional mechanical buttons with an updated design featuring improved haptic technology.\nAt the same time, Apple may have wanted to reduce the inherent hardware failure rate of mechanical buttons by implementing new technology.\nThe home button on the iPhone 7 allowed for improved water and dust resistance because no moving parts were involved. But, the same cannot be said for the Bongo buttons, indicating that this was likely not a goal or priority in development.\nWas Apple's unified volume button an intentional nod to earlier iPhone designs?\nThe Bongo module design merged the two separate volume buttons into a unified pill-shaped volume button, with an indentation in the middle to indicate the volume up and volume down position. This means that early prototypes of the iPhone 15 Pro had a volume arguably button similar to those found on the original iPhone.\nThe first-generation iPhone, the iPhone 3G, and iPhone 3Gs all featured a singular volume rocker on the left side of the device. Apple only changed this with the iPhone 4, which received a dedicated volume up and volume down button.\nApple often tries to make visually defining changes to its latest iPhones to make them stand out. This is done to make them different enough from the previous generation, but still keep the overall visual identity and recognizable look of the iPhone. The iPhone 15 Pro introduced titanium as the housing material, and was supposed to feature a new look for its buttons.\nWhile the design of the iPhone has changed through the years and various different generations Apple produced, every model up to the iPhone 15 Pro featured separate volume buttons. The company apparently sought to change this with its 2023 flagship as a way of differentiating it, but ended up scrapping the idea.\nWho worked on the Bongo project, and how did its cancellation influence iPhone 16?\nThrough people familiar with the matter, AppleInsider has learned that Robert Rivers Ingersoll was among those who worked on the haptic buttons for the iPhone 15 Pro. According to his publicly available LinkedIn page and personal website, Ingersoll is an engineer with a doctorate in mechanical engineering from Stanford University.\nIngersoll was the tech lead for the Haptic Engine in the iPhone and Apple Watch. Prior to his work at Apple, he studied and analyzed the flight and hovering of hummingbirds and bats.\nWhile the exact reasons for the cancellation of the Bongo Project remain unclear, it was allegedly scrapped because of unresolved technical issues and unsatisfactory test results. Prior to cancellation, the Bongo-style haptic buttons were supposed to appear on the entire iPhone 16 lineup as well.\nAs the Bongo design was eventually phased out, more recent prototypes of the iPhone 16 instead feature an all-new capacitive Capture Button. People familiar with the matter have told AppleInsider that the button has been developed under the codename \"Project Nova.\"\nThe capacitive button is expected to appear on the same side as the power button, only lower. This suggests that it is likely a camera-related button.\nFirst revealed in September 2023, the Capture Button features pressure-sensing technology and is capacitive in nature. According to a report from January 2024, the button will be able to recognize gestures \u2014 meaning that users will be able to swipe left or right to zoom in or out.\nThe Capture Button is only one of many upgrades Apple has in store for its iPhone 16 lineup. Scheduled to debut in September of 2024, the iPhone 16 range is expected to feature a new A18 chip with a greatly improved neural engine. The base model iPhone 16 is expected to receive a vertical camera arrangement."
    },
    {
      "url": "https://appleinsider.com/inside/mac",
      "text": "Mac\nAll about Mac\nTable of Contents\n- Mac\n- M-series Mac models for sale\n- 1. Features\n- macOS\n- Apps\n- M-series Processors\n- Intel\n- Magic Keyboard\n- Magic Mouse and Trackpad\n- Pro Display XDR\n- Studio Display\n- Thunderbolt\n- Touch Bar\n- 2. History\n- 3. 1984\n- 4. Early 90s\n- 5. Late 90s - Jobs returns\n- 6. Jobs and the iMac save Apple\n- 7. Apple, Intel, and the late '00s\n- 8. Mac Pro and consumer Macs\n- 9. Apple Silicon\nThe Mac is not a single computer but a lineup of models spanning laptops and desktops. It has been the center of Apple's successes for generations \u2014 from the first one released in 1984 to the one that saved the company from bankruptcy in 1998. Today, Apple's Mac lineup is used to develop apps for all of its platforms and remains essential to the ecosystem.\nThe transition to Apple Silicon breathed new life into the aging Mac platform thanks to the high speed and efficiency of the chipsets. Apple originally promised a two-year transition, but it took three years for the high-end desktop Macs to get Apple Silicon.\nM-series Mac models for sale\nMac Features\nPick up any Mac, and it will function the same as the others \u2014 with some caveats. Thanks to macOS, there will be little to no difference between how a desktop and a laptop perform. Much of the differences today lie in the processor type being used, not the machine's form factor.\nTouch ID is available on all modern Macs via either the built-in keyboard or an external Magic Keyboard sold by Apple. The Touch Bar has been retired and was used until the 13-inch MacBook Pro was discontinued in 2023.\nmacOS\nThe current version of macOS reflects Apple's decade of work trying to perfect the operating system. Mac OS X was the tenth iteration of the Mac operating system and debuted in 2001. The Mac OS X name stuck around for fifteen years but changed to macOS in 2016 to bring the naming scheme in line with Apple's other operating systems.\nThe OS stayed with 10.x versioning until 2020 when the shift to Apple Silicon and a foundational change in how specific systems were managed led to the version number increasing for the first time in a decade. macOS Big Sur was the first to buck the trend as it was version 11. The 2021 operating system release was macOS Monterey 12.0, followed by macOS Ventura 13.0, then macOS Sonoma 14.0, and now macOS Sequoia 15.0.\nThe Unix-based operating system should be instantly familiar to anyone who has interacted with a Mac in the past. Graphic elements and features change over time, but the overall layout and interaction schemes remained relatively the same. Opening an app would create an app instance in a window. However, closing a window would not close the app but rather leave it running in the background. The traffic light icons control the window management.\nThe most significant user-facing changes in recent years have revolved around security and bringing the desktop closer to iOS design paradigms. Windows have rounded corners now, apps use sidebars for navigation, and app permissions are more robust than ever.\nThe blend between iOS and macOS hit its peak with macOS Tahoe 26, which introduced Liquid Glass to the platform. The material is meant to emulate the transparent characteristics of visionOS.\nApps\nWhile the Mac went through its two-year transition to Apple Silicon, it used a program called Rosetta 2 that translated Intel-based Apps on the fly. This process is so efficient that the M1 Macs can run some Intel apps better than premium Intel Macs.\nUltimately, Rosetta 2 is only a stopgap that Apple will remove in future updates \u2014 developers are expected to transition their apps to Apple Silicon or be left behind. Rosetta 2 is still available in macOS Sonoma.\nAll of Apple's apps have already been written for the ARM, so Final Cut Pro and Logic work at full speed on the new machines.\nWhile Apple continues to push users to the Mac App Store, apps can still be downloaded directly from the web. Some apps require some additional security hoops to jump through, but still work.\nM-series Processors\nApple released its first three Macs with an M-series processor at the end of 2020. The 13-inch MacBook Pro, the M1 MacBook Air, and the Mac Mini. The processor was an immediate success, with users noting performance gains and quality-of-life improvements across the board.\nThe first iteration, the M1, is what Apple says the company can do when it brings its processor expertise to the Mac without much effort. The first machines are identical in every way to their Intel counterparts except for the processor.\nWith the release of the 2021 MacBook Pros, Apple announced the M1 Pro and M1 Max. These processors take the magic of the M1 even further with 10-core processors and up to 32-core GPUs. Very few Intel-based machines are able to compete in pure computing power.\nApple announced the M1 Ultra for use in the Mac Studio during a 2022 March event. It is the last M1 processor variant in the lineup and is expected to be included in a Mac Pro update later in 2022.\nThe M2 processor was announced during WWDC 2022 alongside an M2 MacBook Air and a processor bump in the 13-inch MacBook Pro. It is a slightly more powerful processor and a direct successor to the M1.\nThe M2 Pro and M2 Max were revealed in January 2023 and included in a spec-bumped MacBook Pro lineup. The Mac mini also gained the M2 and M2 Pro, widening its range of usability and performance greatly.\nDuring WWDC 2023 in June, the M2 Ultra was revealed. It is available in the Mac Studio and Mac Pro.\nContinuing the blistering pace, Apple released the M3 family of chips all at once in October 2023 \u2014 M3, M3 Pro, and M3 Max. These chips launched in the 24-inch iMac and the MacBook Pro.\nApple revealed M4 with the iPad Pro in early 2024 and brought the chip to Mac in October. A redesigned smaller Mac mini got the M4 and M4 Pro, while the iMac was updated with M4.\nM4, M4 Pro, and M4 Max were included in the new MacBook Pro lineup. Little else changed in the spec update beyond a brighter displays, Thunderbolt 5 in high end models, and a Nano Texture option.\nThe Mac Studio and Mac Pro were skipped over in 2024 as Apple seemed intent on skipping over M3 Ultra. The 3nm process used for M3 is undesirable, so Apple quickly moved the lineup to M4.\nHowever, Apple did update the Mac Studio with M4 Max in 2025, but it did not reveal an M4 Ultra. Instead, the top-tier Mac Studio uses M3 Ultra and no M4 Ultra has been revealed.\nIntel\nApple cut off Intel entirely at the beginning of the Apple Silicon transition. Intel has had years of near-identical processor bumps with little user-facing improvements along the way. This led Apple to jump to internally-designed processors to ensure Mac's future was in its full control.\nWith each new M-series processor and Mac using it, Apple cut out more and more Intel machines from the lineup. After the M2 Ultra made it into Mac Pro, Apple no longer sells Intel models.\nSome Intel-based machines are still for sale at non-Apple distributors, but they will sell out eventually. The Intel-based Mac mini, for example, is now considered obsolete.\nMagic Keyboard\nApple refers to multiple products as the Magic Keyboard, but when discussing Macs, it applies to two \u2014 the built-in MacBook keyboards and the wireless keyboard. The new built-in Magic Keyboard uses scissor-switch mechanisms to ensure the keys function correctly with each press.\nApple tried using a \"butterfly\" mechanism in its MacBook keyboards, but this proved to be a reliability disaster. Users reported that keys would stick or fail regularly, so Apple finally reverted to the scissor switch, but with a new slimmer design.\nApple's wireless keyboards all use the old scissor-switch mechanism but remain thin and light despite the aging design. The external Mac desktop keyboards were updated with Touch ID and colors that match the 24-inch iMac, but little was changed about the overall shape and layout.\nMagic Mouse and Trackpad\nApple's trackpad has always been ahead of the competition in terms of reliability and usefulness. The Magic Mouse, however, is a bit of an anomaly.\nThe Magic Trackpad can connect via Bluetooth or a USB-C cable and uses taptic engines to simulate a click. The entire surface of the trackpad is \"clickable\" and doesn't physically move when pressed. The taptic engine vibrates during operation to fool users into thinking the device actually clicked.\nThe Magic Mouse is a small classically-designed mouse that uses touch-sensitive glass for input. Rather than having traditional mouse buttons, the entire top front of the mouse is clickable, and each side can recognize when pressed to simulate right and left clicks. Instead of a scroll wheel, the Magic Mouse uses a touch surface that users can swipe on.\nThe Magic Mouse is controversial because it can only be used over Bluetooth and charges via USB-C when upside-down. The port placement was an obvious form-over-function choice from an \"old Apple\" that wanted the mouse to look seamless \u2014 even at the detriment of usefulness.\nPro Display XDR\nApple may have said it is out of the display business, but it revealed the Pro Display XDR alongside the Mac Pro in 2019. This 6K display has been calibrated to represent near-perfect color and contrast representation when showing images. Apple says it is competitive with $24K reference monitors used by film professionals.\nCustomers can add a nano-texture to the display for an additional $1,000. Controversially the monitor doesn't come with a stand. Customers must choose between an expensive VESA adapter or a $1,000 stand.\nThe Pro Display XDR results from Apple's desire to achieve perfection and features a price to match. Some rumors speculate that Apple is planning on more consumer-friendly monitors in the future.\nStudio Display\nApple introduced the Studio Display as a companion to the Mac Studio. It is a 27-inch 5K display with True Tone and P3 color. It connects via Thunderbolt 3 and integrates with macOS features like Spatial Audio and Center Stage.\nThis new monitor runs an A13 for audio, microphone, and camera processing. It works with modern Intel Macs, all M-series Macs, and the latest iPads with the M1 processor.\nThe 27-inch iMac was discontinued after the Studio Display was announced. It isn't clear if Apple could still revive the product at a later date with Apple Silicon.\nThunderbolt\nApple uses Intel's Thunderbolt spec across all of its Mac computers. M1 Macs use Thunderbolt/USB-4 connectors while the M1 Pro/M1 Max MacBook Pros use Thunderbolt 4.\nThunderbolt 4 allows up to 100W of power and 40GB/s of data over a single USB-C cable and is fully backward compatible with previous cable specs. The spec also allows multiple Thunderbolt devices to be chained together to maximize the one connection's utility.\nThe M1-based Macs have some limitations when using Thunderbolt, however. Users can only connect one external monitor via a Thunderbolt connection and cannot use e-GPUs. The monitor support is expected to increase in future iterations of the M-series processor, but e-GPU support may never come.\nThe 2021 and later MacBook Pros can connect multiple external displays thanks to improvements with the included Thunderbolt controllers.\nM4 Macs can connect to two 6K external displays, or three in the case of the Mac mini. The high end Mac mini and MacBook Pros have three Thunderbolt 5 ports.\nTouch Bar\nThe Touch Bar is an OLED strip that appeared at the top of old MacBook Pro models. It replaced the function row keys as a new variable input device for certain apps. Apple had iterated slightly on the Touch Bar design, like re-introducing a physical escape key, but little else changed over the years.\nThe Touch Bar had been neglected in software too. Apple paid little attention to the hardware when updating macOS or its apps, and third parties have mostly ignored it as well.\nApple originally introduced the Touch Bar as a new interaction paradigm that would give pro users a new way to interact with apps. It offered a novel way to scrub timelines or switch between tools in certain apps but left a lot to be desired otherwise. The lack of haptics and accidental touches made the Touch Bar more of a nuisance for some users than a boon.\nWith the release of the 2021 MacBook Pros, Apple removed the Touch Bar in favor of full-sized function keys. The company didn't bother to mention the Touch Bar once during the announcement, signaling its demise.\nIt survived in only one model thanks to a lack of redesign \u2014 the 13-inch MacBook Pro. Apple discontinued that model in 2023, thus finally killing the Touch Bar entirely.\nHistory of the Mac\nThe Mac began in 1979 with Jef Raskin, initially Apple's 31st employee and taken on as Manager of Publications. Having broad experience in computing and regularly using what he called his \"honorary beanbag chair\" at Xerox PARC, he knew about its graphical user interfaces (GUIs) before Steve Jobs did.\nRaskin consequently wanted a graphical bitmapped screen for a computer, but he also had very many more aims for what he saw as the future of the technology. Sometime around March 1979, he lobbied then Apple chairman Mike Markkula to begin a project he initially called \"Annie,\" but later renamed Macintosh.\nFar more than some verbal pitch or vague request to work on a new project, Raskin wrote up an entire set of papers that he ultimately called \"The Book of Macintosh.\" The complete text, now available online, ranges from an \"Annie\" memo of May 1979 to a \"January 1980 Overall Summary.\"\nRight from the start, though, the core aim was to make a computer that was simple to use.\n\"This is an outline for a computer designed for the Person In The Street (or, to abbreviate: the PITS),\" wrote Raskin. \"[One] that will be truly pleasant to use, that will require the user to do nothing that will threaten his or her perverse delight in being able to say: 'I don't know the first thing about computers, and one which will be profitable to sell, service and provide software for.\nWhen he first proposed \"Annie\" \u2013\u2013 what he really thought would eventually be called the Apple V \u2013\u2013 Raskin knew that the company was developing the Apple Lisa. However, Raskin predicted that the Lisa would be \"overpriced and too slow.\"\nSo as well as a computer for the Person in the Street, he wanted it to be affordable. Raskin's plan was for a computer that cost $500, ran on the low-cost Motorola 6809 processor \u2013\u2013 and did not include a mouse.\nThat lack of a mouse, and so the lack of being able to point and click, means that Raskin may not have envisaged the kind of GUI that we now imagine. At the same time, the Apple Lisa may not have always been planned to have a GUI \u2013\u2013 until Steve Jobs saw one at Xerox PARC.\nJef Raskin and Steve Jobs did not get along, but Raskin wanted Jobs to see the work being done at PARC. He called on Bill Atkinson, a principal designer of the Lisa and Mac GUIs, to talk Jobs into visiting Xerox.\nThe famous visits to PARC in November and December 1979 ultimately led to the Macintosh, but initially, they transformed the Apple Lisa. That project now definitely had to have a GUI, and if Steve Jobs had stayed with the Lisa, Jef Raskin might have got his simple, cheap Macintosh.\nHowever, Jobs reportedly antagonized people enough that Apple's then-president Michael Scott removed him from the Lisa project. Jobs then decided to take over Macintosh and effectively make it better than the Lisa.\nThis did push Raskin aside, which lead him to leave the project in summer 1981. However, his overall ethos of simplicity, and especially of it being an appliance, stayed. \"The computer must be one lump,\" Raskin had written. \"Seeing the guts is taboo.\"\nThe low cost, though, and everything that contributed to that did not stay. Raskin formed the Macintosh team, but it was because of Jobs that the Mac ran on the more costly Motorola 68000 and that it got a mouse.\n1984 - The Macintosh debuts\nBy the time it was launched, Raskin's $500 Macintosh had become Jobs's $2,495 one. Some of that was due to then-CEO John Sculley wanting to make back Apple's considerable spending on advertising.\nMuch of it, though, was Steve Jobs pressing for better components and a better experience for the user. Despite being willing to do that even as it pushed the price up, though, Jobs was not willing to do it enough. The Mac that launched in 1984 was underpowered.\nIt was also a flop. It changed the world \u2013\u2013 truly \u2013\u2013 but that original Mac did not change Apple. At least, not at first. For its initial several years, the Mac and Apple were supported by the high sales of the Apple II.\nThat machine faded away as the original Macintosh became the \"Fat Mac,\" with double the RAM, in September 1984. Then in 1987, came the Macintosh II and the Macintosh SE.\nThese initial successors just addressed shortcomings in the original Mac. That ranged from the lack of RAM to how it initially only ran in black and white.\nThen in January 1989, Apple launched the upgraded Macintosh SE/30. And in 1990, it brought out the \"wicked fast\" Macintosh IIfx. While other models were popular, and some like the IIci are fondly remembered, these two were arguably the workhorses of the Mac range.\nThe early 1990s \u2014 from innovation to complication with Centris, Quadra, and Performa\nSteve Jobs was long gone by the time the SE/30 and IIfx were beloved. His time away from Apple is perhaps more remembered now, though, for what happened next with the Macintosh.\nThe answer is simultaneously a lot and not very much. The Mac grew steadily more capable and steadily more successful in the late '80s, including the over-engineered but significant Macintosh Portable in 1989.\nUnfortunately, the Mac started to become only a little more capable, and it steadily became less successful in the early '90s.\nApple decided to provide a model of Mac at every possible price point and for every conceivable type of customer. Businesses got the Macintosh Quadra range from 1991 and the Macintosh Centris models from 1992, but both were gone by 1995.\nConsumers got the Macintosh Performa range, which lasted from 1992 to 1997, but these were just renamed versions of the Quadra, Centris, and LC models. They were given new names, a plethora of marketing model numbers based on starting specs, some cosmetic differences. Then they were sold through big-box stores such as Sears, Service Merchandise, and just about anywhere else that had a pulse and a sufficiently large retail footprint.\nOr rather, they weren't. The Performa range, with its dozens of different configurations and models, sold poorly.\nHowever, the two bright spots in this period were the PowerBook range, from 1991, and the transition from 68000 processors to the PowerPC from 1994.\nPowerBooks were the \"Mac in a book\" that Steve Jobs had been pressing for from the start, and their design completely transformed laptops. They moved the keyboard to the back, meaning users' palms rested on the machine instead of awkwardly hanging over the edge. Every single laptop since has copied this.\nSimilarly, the PowerBook Macs later introduced the trackpad, and practically every laptop since then has followed along.\nEven with the PowerBook range's success, though, and the move to PowerPC, Apple struggled because it was spread very thin.\nThe late 1990s - Jobs returns\nApple was trying to get an updated Mac OS off the ground alongside countless indistinguishable Mac models. With years of effort having nothing to show for it, eventually, Apple began to look at buying in an alternative from outside the company \u2013\u2013 and it did.\nApple bought the basis of what would become OS X, but it also brought back Steve Jobs. Apple bought Jobs's failing NeXT Computer in 1996.\n\"This is a complementary arrangement,\" then-CEO Gil Amelio said at the time, \"The pieces fit together better than any alternative we looked at, and it will launch a new round of technology.\"\nIn the long term, Amelio would prove to be correct. But in the short term, he found himself out of a job. It wasn't that Steve Jobs took over \u2013\u2013 not at first. Instead, it was the fortunes of Apple that kept on declining, at one point requiring the laying off of 3,000 employees.\nThere were also public-facing debacles such as Amelio, presenting at Macworld and entirely forgetting to introduce the guest of honor Muhammad Ali. Behind the scenes, Oracle tried and failed to make a hostile takeover bid for Apple \u2013\u2013 and it was later revealed that Jobs had supported it.\nOn July 4, 1997, Apple's board told Gil Amelio he was no longer wanted. He officially resigned as CEO on July 9. Steve Jobs was actually put in charge of finding a replacement, and after a few months, became the interim CEO himself.\n\"I couldn't even figure out the damn product line after a few weeks,\" Steve Jobs then said in September 1997. \"I kept saying what is this model, how does this fit? I started talking to customers and they couldn't figure it out either, and so you're gonna see the product line get much simpler and you're gonna see the product line get much better.\"\nJobs' iMac saved Apple\nJobs came in As interim CEO, and then fully the CEO, Jobs sought to save Apple from bankruptcy and did so initially with the Macintosh. Working with Apple designer Jony Ive, Jobs created the iMac.\nAnnounced in 1998, 14 years after the original Macintosh, the new iMac was visually striking, and introduced new technologies that the rest of the industry then emulated.\nIt also introduced new colors so that the Mac was no longer a kind of yellowing beige, and instead was vivid Bondi Blue, and more. \"The one thing Apple is providing now is leadership in colors,\" Bill Gates said in 1998. \"It won't take long for us to catch up with that, I don't think.\"\nThat was an example of Gates missing a point because, as Jobs later said, \"the only problem with Microsoft is that they have no taste.\" Where Gates saw color as a quick paint job, Apple saw design as being about everything from how something looked to how it was used.\nSo alongside its painted exterior, the iMac brought approachability. Jef Raskin had wanted his Macintosh to have a handle, and the iMac still had one. Maybe you never picked it up, but it always felt as if you could, so it seemed lighter than it was, it seemed approachable.\nThen it also introduced USB to the wider world. True, the iMac used that technology in the iMac's \"hockey puck\" mouse, and that was excruciatingly poor. But it brought USB into the mainstream, and rival manufacturers soon fell into the now-familiar pattern of mocking an Apple decision, then copying it.\nIn 1999, Jobs took the iMac ideas and put them into the iBook. It had similar bright colors, it had a handle, but it also had Wi-Fi. It was the first consumer notebook to have Wi-Fi built-in, and Jobs demonstrated that as if he were a magician, loading up internet pages with no visible wires.\nApple, Intel, and the late '00s\nThe iMac and the iBook saved Apple, and then from 2001, it did seem as if the company went iPod-mad. That music player became an incredible source of revenue for Apple, and it also introduced Apple to very many users.\nPlenty of those users then learned about the Mac, and consequently, its share of the market rose. But with more people using the Mac came more demands on it, and the PowerPC processor was not keeping up.\nSo in 2005, Steve Jobs announced that Apple was going to undertake another transition, this time from PowerPC to Intel.\n\"Why are we going to do this?\" he said. \"Didn't we just get through going from OS 9 to OS X? Isn't the business great right now? Why do we want another transition? Because we want to make the best computers for our customers going forward.\"\nMoving to Intel gave the Macintosh a boost it could not have got from PowerPC. Although it tied Apple to Intel's schedule of releases, it also enabled ever more powerful Macs, including the iMac Pro.\nMac Pro and consumer Macs\nWhen it launched in 2017, the iMac Pro was praised but seen as a stopgap while Apple worked on a revised Mac Pro. Very unusually, the company had even said that it was working on one \u2013\u2013 and it did so because, at this point, the Mac Pro was languishing.\nOriginally introduced as the top-end Mac for power users in 2006, the \"cheese grater\" machine that evolved from the PowerMac G5, had hit its limits long before the range was replaced in late 2013. That December 2013 Mac Pro was the cylindrical \"trash can\" model and it failed, mostly because Apple didn't predict the increasing focus on GPU power versus CPU.\nIt was gorgeous to look at, but unlike its predecessor, it had barely any expandability. Apple would later say that thermal issues in its design limited it.\nWhat it looked to the outside world, and most particularly to power user creatives, was that Apple was focusing more on consumers. It was, too, with the iPhone, and then to a lesser extent the iPad, becoming what Apple was known for.\nBy 2015, there were eighteen iPhone users for every individual Mac user, and this number has only grown since. Of course, the company served its new core audience \u2013\u2013 but the old core audience was drifting away.\nHence the 2017 iMac Pro, then the 2019 Mac Pro. The 2019 Mac Pro was the most expensive Mac in decades, surpassed only by the IIfx, and it could be expanded at a cost greater than all but the most pro users could contemplate.\nApple was telling the power users that the Mac was back. It just very shortly afterward told them the Mac was changing.\nNext stop, Apple Silicon\nDespite the extremely high performance of the 2019 Mac Pro, being tied to Intel was limiting how much Apple could do when Intel itself was not sticking to its own development plans. Intel processors, as a whole, were hitting limits that Apple needed to exceed.\nCustomers could see the limitations and the delays, so of course, Apple could as well. In 2020, Tim Cook announced the long-rumored, much-awaited next transition.\nThe Mac in 2020 would still follow Jef Raskin's aim of being the simplest computer to use, but it is the Apple Silicon M1 processor that would be unrecognizably fast. That's unrecognizably faster than anyone from Raskin's time could imagine, but also faster than even present-day Intel users could.\nAfter releasing the M1, M1 Pro, M1 Max, and M1 Ultra, Apple introduced the M2, restarting the cycle anew. M2 Pro and M2 Max followed in early 2023, with the M2 Ultra arriving later in June.\nM3, M3 Pro, and M3 Max were announced in October 2023 with even more improvements. They are the first Apple Silicon chips for Mac built on the 3nm process.\nM4 arrived in the Mac in October 2024. The M4 Pro was revealed with the redesigned Mac mini while the M4 is used in the base Mac mini and iMac. M4, M4 Pro, and M4 Max are available in the MacBook Pros, which also have brighter displays with optional Nano Texture.\nThe M4 Ultra is due in the Mac Studio and Mac Pro in the summer of 2025. The M5 processor should debut before the end of 2025 in select Macs."
    },
    {
      "url": "https://appleinsider.com/inside/m1",
      "text": "All about M1\nTable of Contents\nThe M1 and its high-end variants are Apple's first processors meant to replace Intel chips across its Mac lineup. Each processor is optimized for the hardware and software stack it is intended to run, enabling more power and efficiency in every task.\nApple announced the M1 at its November 2020 \"One More Thing\" event. It was used in consumer-grade devices like the MacBook Air, Mac mini, iPad Air 5, iPad Pro, and 24-inch iMac.\nIn late 2021, the pro-grade M1 Pro and M1 Max were introduced for use in the updated MacBook Pros. They incorporated more cores, better GPUs and enabled high-end RAM and storage configurations.\nAn Apple event in March 2022 introduced the M1 Ultra, the final processor in the M1 series. It is used in the Mac Studio, a desktop Mac made for professionals seeking to replace their Intel-based Mac Pro or iMac Pro.\nThese four processors are built upon the same 5nm foundation and act as distinct entry points into Apple hardware. The M1 is used in the widest variety of consumer-grade devices with more than enough performance to tackle any day-to-day task. The M1 Pro is the middle-tier \"prosumer\" chip that acts as the base option for the new MacBook Pros but is still limited when compared to the high-end.\nThe M1 Max is a professional-grade processor. It has more GPU cores and more RAM at its disposal for the more complex workflows in professional projects.\nM1 Ultra goes even further by offering the maximum amount of RAM and GPU processing power in an SoC with a 20-core CPU. It can go head-to-head with a top-end 28-core Xeon processor in the Mac Pro.\nApple later introduced the M2 and M3 processor families. After the release of the M3 MacBook Air in March 2024, Apple no longer sells any M1 Mac model.\nSystem-on-a-chip\nAll M-series processors are integrated systems-on-a-chip. This means the CPU, GPU, Neural Engine, and other processes are set on the same system package and use a unified memory pool.\nOn Intel-based systems, these were all separate chips with individual memory pools, which means data had to be copied between the memory pools before the CPU or GPU could act on the data. Apple says the integrated approach maximizes efficiency.\nVertical integration also allows Apple to optimize performance. That's opposed to Intel's one-size-fits-all chips, which are designed to power computers running macOS, Windows, Chrome OS, and Linux.\nFurther complicating matters, Intel's processors need to work across a range of hardware from HP and Dell to Samsung, LG, and Microsoft's Surface line. Meanwhile, Apple can design its chips, hardware, and software from the ground up to work together seamlessly.\nM1\nThe entry-level M1 includes eight processing cores and up to eight additional GPU cores. The processing cores are split between four high-performance cores and four efficiency cores.\nThe integrated GPU handles graphically intense tasks like photo and video editing, playing a game, or outputting video to an external display. Apple said the M1's graphics cores could simultaneously handle nearly 25,000 threads.\nApple's silicon has a unified memory architecture (UMA) that merges high-bandwidth and low-latency memory into one pool within a custom package. The UMA lets all segments of the M1 access the same data without copying between different memory pools, boosting both performance and power management. Apple says the UMA will allow for up to 3.9x faster video processing and 7.1x speedier image processing.\nLike Apple's mobile chips, the M1 also includes a 16-core Neural Engine for machine learning (ML). The M1's Neural Engine can execute up to 11 trillion ML operations per second, working with the GPU to boost tasks like complex photo and video filters.\nApple says the M1 delivers up to 3.5x faster CPU performance, up to 6x faster GPU performance, and up to 15x faster machine learning when compared to Intel-based Macs. All this and the battery life is doubled too.\nBenchmarks show that MacBooks running the M1 could outperform any but the most powerful Intel-based MacBook Pro. Even when running Intel apps through Rosetta 2, most operations performed better than on native Intel.\nAlong with enormous performance boosts, the M1's efficiency also allows for longer battery life. Apple says the M1-equipped MacBook Air can last for 15 hours of wireless web browsing and 18 hours of video playback. Those estimates for the 13-inch MacBook Pro jump to 17 hours for web and 20 hours for video. Those are up to 10 hours longer than Apple's estimates for their Intel-based equivalents.\nApple's integration between the M1 and macOS also helps with both performance and efficiency. For example, devices wake from sleep instantly on Apple Silicon, similar to iPhones and iPads. Apple states that apps also launch nearly instantly, animations are snappier, and Safari scrolling is smoother due to vertical integration.\nConfigurations\nWhile the M1 is an impressive piece of technology, it isn't without its limitations. Customers buying a computer with this processor should be aware of the few, but significant, drawbacks when compared to Intel machines.\nM1 Macs max out at 16GB of RAM, can only connect to one display over Thunderbolt, and can only have up to two Thunderbolt ports. These limitations won't affect all customers, but for pros, this was problematic until Apple revealed the newer processors.\nOf course, Apple wasn't limited to Thunderbolt ports, so the 24-inch iMac had the option of adding two USB-C ports and the Mac mini had an HDMI port.\nAll M1 processors have an 8-core CPU and vary between a 7-core and 8-core GPU based on the performance tier chosen.\nCustomers can choose between 8GB or 16GB of RAM and up to 2TB of storage. For iPad Pros, the RAM was dependent on storage chosen \u2014 8GB of RAM with 512GB or less and 16GB of RAM for 1TB or 2TB models.\nComputers with M1 processors:\n- 13-inch MacBook Pro\n- MacBook Air\n- Mac mini\n- 24-inch iMac\n- 12.9-inch iPad Pro\n- 11-inch iPad Pro\nM1 Pro\nThe M1 Pro is designed for professionals who rely on the MacBook Pro. Rather than use a discrete GPU like other professional notebooks, Apple included it in the system-on-a-chip with a unified memory architecture.\nThe 10-core CPU has eight high-performance cores and two high-efficiency cores. That's six more performance cores than the standard processor. That translates to about 70% faster CPU performance than M1.\nThe 16-core GPU enables 2x graphics performance when compared to the smaller chip. Apple also included a ProRes acceleration module to enable faster processing of the large file format.\nThere are improvements to the display engine and Thunderbolt I/O, enabling more external displays and more ports. The new MacBook Pros have three Thunderbolt 4 ports and can connect to two external displays.\nConfigurations\nThere are multiple configurations for this chipset with 8-core or 10-core CPU options, 14-core or 16-core GPU options, and 16GB or 32GB of RAM. Customers can also purchase up to 8TB of integrated SSD storage.\nOnly the 14-inch MacBook Pro and 16-inch MacBook Pro use the M1 Pro at this time.\nM1 Max\nThe M1 Max takes Apple Silicon even further as the largest system-on-a-chip Apple has ever made. Its massive 57-billion transistor die supports up to 64GB of RAM at 400GB/s.\nThe 10-core CPU is the same as the M1 Pro, but the GPU can be increased to 32 cores. That translates to 4x faster graphics performance.\nThe M1 Max also benefits from the improved Thunderbolt I/O and display engine. However, this processor can handle up to four external display connections.\nPower and efficiency is the goal of Apple's custom silicon, so performance per watt is industry-leading. When compared to a maxed-out Intel-based machine with a powerful GPU, the M1 Max consumed 100W less power at its peak performance. Due to this effect, the high-end Intel computer has to stay plugged into power in order to achieve its high performance while the Mac can sustain peak performance even on battery power.\nConfigurations\nCustomers can configure the M1 Max with a 24-core or 32-core GPU and up to 64GB of RAM. Maxing out this processor adds $700 to the base price of the laptop, costing another $800 for the maximum RAM.\nOnly the 14-inch MacBook Pro, 16-inch MacBook Pro and Mac Studio use the M1 Max at this time.\nM1 Ultra\nThe M1 Ultra combines two M1 Max using UltraFusion technology to create a new, more powerful chip. That doubles the specs to a 114-billion transistor die that supports up to 128GB of RAM at 800GB/s.\nThis also means the CPU is now 20-cores and the GPU can be increased to 64 cores. That translates to 8x faster graphics performance.\nWhen compared to a maxed-out Intel-based machine with the latest GPUs, the M1 Max consumed 200W less power at its peak performance. Apple says that the M1 Ultra can consume up to 1000kWh less than competing machines over the course of a year.\nConfigurations\nCustomers can configure the M1 Ultra with a 48-core or 64-core GPU and up to 128GB of RAM. Maxing out this processor adds $1,000 to the base price of the Mac Studio, costing another $800 for the maximum RAM.\nThe Mac Studio is the only Mac using the M1 Ultra.\nComparing Apple's M-series processors\nEach of the M-series processors are 5nm chips with similar baseline functions. These are the same class of chips each with bigger dies meant to enable more cores, graphics, and functionality for each improved version.\nThe M1 has 16 billion transistors while the M1 Pro has 33.7 billion and the M1 Max has 57 billion. The transistor count doesn't translate directly to performance but does indicate how much larger each chip is to its lesser version.\nThe M1 has eight cores \u2014 four high efficiency and four high performance. This processor was built first with consumer-grade laptops in mind.\nThe M1 Pro is configured with two high-efficiency cores and either six or eight high-performance cores depending on the model. This processor is used in mid-tier laptops meant for prosumers and professionals alike.\nThe M1 Max has only one ten-core configuration with two high-efficiency cores and eight high-performance cores. This processor is aimed at high-end professional models for intensive graphics work.\nDouble the numbers from the M1 Max and you have the M1 Ultra. It is a 20-core CPU with four high-efficiency cores and sixteen high-performance cores. Apple targets this processor as a viable competitor to the Intel Xeon chips used in the Mac Pro.\nBenchmarks indicate similar single-core performance since all of the processors use the same high-performance cores. The multi-core score differs between the low-end and high-end processors thanks to the increased core count.\nGraphics performance is an obvious ladder since each processor has more and more graphics cores available. The same goes for media processing thanks to the Media Engines included in the high-end chips.\nComparing these chips on paper shows a clear line from good to best \u2014 clarity that was missing from the Intel era.\nRead the spec breakdown and more feature differences in our full comparison.\nThe M2 processor\nApple announced the M2 processor during WWDC 2022 as the second generation of Apple Silicon. It is a slightly larger, more performative chip than the one it replaces.\nThe first computers with M2 are the 13-inch MacBook Pro and the 13-inch MacBook Air. It slowly replaced the M1 processor series throughout the year until the M2 Ultra was revealed in 2023.\nApple wasn't able to complete the Apple Silicon transition during the M1 generation since the Mac Pro wasn't updated. But M2 Ultra finally brought Apple Silicon to Apple's most premium desktop, thus completing the transition after three years."
    },
    {
      "url": "https://appleinsider.com/inside/iphone",
      "text": "iPhone\nAll about iPhone\nTable of Contents\n- iPhone\n- 1. Features\n- Apps\n- Camera\n- Display\n- Security and Privacy\n- Apple Silicon\n- Ports\n- Accessories\n- Services\n- 2. iOS 18\n- Apple Intelligence\n- Photos update\n- Messages updates\n- Game Mode\n- Locked and Hidden apps\n- Home Screen, Lock Screen, and Control Center customization options\n- 3. Manufacturing iPhone in the United States\n- 4. Learn more about iPhone\nWhen Steve Jobs introduced the iPhone in 2007, it was meant to be a crossroads between communication, technology, and design. After a few years of ramping up the supply chain and gaining popularity, the iPhone began to dominate the smartphone market.\nSince the iPhone 4, no other device line has penetrated the market in the same way. Despite concerns from analysts that Apple was becoming too reliant on the iPhone, the company pivoted to services and software sales that fed off the increasing install base.\nHaving one central device act as a magnet to other portions of a company's business has been referred to as the \"halo effect,\" and this phenomenon plays a vital role in the Apple ecosystem.\niPhone Features\nThe basic slab-of-glass-and-aluminum design hasn't changed much over the lifetime of the iPhone. Interaction paradigms have shifted, and Apple has moved from Touch ID to Face ID, but overall the concept of a piece of glass displaying relevant information has remained constant.\nApple developed specialized software specifically for the iPhone and touch interfaces called iOS. The operating system shares many elements with its macOS cousin but focuses on a touch-only interface. As of iOS 13, Apple branched the OS into two different forks, iOS and iPadOS, to address hardware-specific features more directly.\nApps\nThe App Store operates as the sole storefront for software on iOS devices. Apple does not allow users to side-load apps from the web or use other app stores on iOS.\nMany anti-trust investigations surrounding the App Store and how business is conducted have shown no evidence of a rigged system or monopoly. Even so, some companies like Microsoft or third-party developers still call for investigations into Apple's business practices.\nAll apps and subscriptions sold in the App Store are subject to a 30% service fee on Apple Platforms. Subscriptions that retain a subscriber for over a year are only charged 15%.\nApple pre-loads every iPhone sold with several default apps, and they are all first-party apps. Once users finish the onboarding process on a new iPhone, they can go to the App Store and download free and paid apps via their Apple ID.\nApp updates are free, but some features may be locked behind paywalls called in-app purchases or IAP. Some apps charge a subscription fee instead of IAP, which will unlock features once a user subscribes.\nThe App Store makes most of the profits in the mobile app market despite having a smaller user base than Google Play.\nCamera\nThe smartphone camera was a relatively new concept when the iPhone was released in 2007. Since then, Apple has used its expertise in tying hardware and software together to produce industry-leading mobile photography engines that fit in your pocket.\nApple releases new photography-focused features with each new hardware or OS release, as consumers have shown that to be a high priority for new-device purchases.\nThe iPhone 14 Pro and newer can shoot 48MP photos using the ProRAW format to capture large and detailed photos. It is also capable of recording ProRES video in 4K.\nComputational photography has only improved in recent generations. For iPhone 16, Apple now offers reversible Photographic Styles that basically enable the user to apply styles and reprocess a photo as if it were freshly captured.\nLive Photos\nThe iPhone will capture 1.5 seconds of video before and after the camera shutter is pressed. This produces a playable video with sound to show off the events surrounding the image capture. When editing Live photos, users can select which frame is shown as the still, and all edits made to the still photo are applied to the entire Live Photo.\nSwiping up on a live photo within the Photos app will let users change the still image into a looping GIF or a long exposure. These changes show up as live tiles within the day-view of the Photos app.\nPortrait Mode\nWhen using Portrait mode, the iPhone will utilize multiple cameras to determine the depth map of what is being photographed, then produce a simulated bokeh effect live on the screen. The iPhone SE has only one camera but still takes portrait mode photos using algorithms to determine the borders of objects, which can detect even fine hair for use in the image.\nQuick Take\nA feature introduced in iOS 13 called Quick Take lets users quickly start recording a video when using the Camera app. While in the camera section of the Camera app, holding down the shutter button will begin recording in 1080p video. This is much faster than switching to the video mode if you're already snapping photos.\nNight Mode\nApple's Neural Engine can capture multiple exposures of a single scene and stitch it together into a fully exposed image. This is called Night Mode, and it occurs exclusively from every other camera operation. Bright scenes use HDR, medium scenes use standard exposure, and darker scenes default to Night Mode.\nWhen Night Mode is active, users can adjust the exposure time to multiple seconds, and the available time extends if the iPhone is used on a tripod. Capturing nearly pitch-black scenes or night skies is now easily done without technical skill. The resulting image will be exposed, so it still appears to be a nighttime or dark photo, an alternate approach to Apple's competitors.\nThe iPhone 12 Pro series added Night Mode portraits, and the entire iPhone 12 series supported Night Mode selfies, which carries over into newer models.\nDeep Fusion\nThis enigmatic feature was announced as a part of the iPhone 11 release in 2019. The user couldn't control or select it, and there is no setting anywhere in the OS for enabling it. The feature does not work with \"capture outside the frame\" enabled.\nWhen the shutter is clicked, the Neural Engine observes a still subject in medium lighting and automatically switches to multiple exposures. The iPhone will capture nine different images when this happens, with the one on the shutter press acting as the anchor image.\nThe Neural Engine and machine learning algorithms break all nine images down pixel by pixel and \"decide\" which pixel will remain in the final composite image. This results in a photo created by machine learning rather than based on what was captured by the sensor.\nA Deep Fusion photo will contain a higher amount of detail, color and shadow accuracy, and exposure when compared to images captured without the process. The feature is designed to be completely invisible, and users will not know if it has occurred or not without specialized software that searches metadata within the photo.\nApple upgraded its Deep Fusion system on iPhone 14 by moving it to earlier in the process, so images could retain more color and texture.\nDisplay\nSuper Retina XDR with ProMotion\n- Used on the iPhone Pro models\n- All-Screen OLED\n- HDR-ready\n- 2,000,000:1 contrast ratio\n- 120Hz variable refresh\n- True Tone\n- P3 Color\n- 1000 nits of brightness\nSuper Retina XDR\n- Used on the standard iPhone models\n- All-Screen OLED\n- HDR-ready\n- 2,000,000:1 contrast ratio\n- True Tone\n- P3 Color\n- 800 nits of brightness\nThe iPhone 11 and iPhone XR use a Liquid Retina HD display that is a LED with lower pixel density (326 PPI) and contrast ratio (1,400:1). The iPhone SE and older Touch ID-based iPhones use a screen called the Retina HD display, and it has the same specs as the Liquid Retina HD display but is a wide-screen display.\nSecurity and Privacy\nAny iOS device you buy comes fully encrypted by default. When setting up the device for the first time, Apple prompts users to secure their iPhone with a passcode or passphrase, then locks it with biometrics.\nBiometric data is end-to-end encrypted and stored within the Secure Enclave on the device. The actual biometric information is discarded. Instead, a mathematical representation of the data is stored in the Secure Enclave for comparison at each prompt.\nApple says privacy is a fundamental human right, and it designs its products with that in mind.\nFace ID\nAt the top of the iPhone, the sensor array contains infrared scanning technology that will collect depth and image data of the face being scanned every time Face ID is used. Machine learning algorithms also look for a \"live\" subject with eyes open and looking at the camera to prevent 3D models from fooling the technology.\nThe infrared scanner sprays the target with 30,000 dots to gather the face data. The eyes, nose, and mouth must be visible for the system to recognize the face when using traditional Face ID.\nHowever, Apple has added a new version of Face ID that uses the unique features found around a person's eyes to identify them. This allows for Face ID use while wearing a mask but isn't as secure as the traditional version.\nApple stated that Face ID is much more secure than Touch ID, and there is a 1 million to 1 chance of a random stranger unlocking your phone. Identical twins are the only exception, and Apple is looking to eliminate this anomaly through more advanced scanning technology.\nTouch ID\nThe Home Button on the iPhone acted as an iconic part of the device for its first ten years of existence until the iPhone X removed it in favor of a full-screen display. The iPhone 5S introduced Touch ID to the Home Button, which would scan for a fingerprint by taking a high-resolution image of the finger presented to compare to what is stored on the Secure Enclave.\nThe steel ring surrounding the Touch ID button would complete an electrical circuit with the user's finger\u2014 a fake finger or deceased person could not unlock the phone. The introduction of Touch ID brought secure encryption to the masses and still exists on some iPads and MacBooks.\nThe iPhone SE was the last iPhone with Touch ID. It was discontinued in February, 2025.\nApple Silicon\nApple builds its custom processors for the iPhone, iPad, Apple Watch, Apple TV, and the Mac. By developing its chipsets, Apple can customize its software to work directly with the hardware in a way that competitors cannot imitate.\nThese chipsets are the brains behind Apple's software platforms, machine learning algorithms, graphics processing, and Apple Intelligence. The built-in Neural Engine makes many operations much more efficient, from taking photos to editing video.\nThe A16 was introduced with the iPhone 14 lineup but was only used in the Pro and Pro Max models. The iPhone 14 and iPhone 14 Plus got the A15 instead, likely as a differentiator and cost-cutting decision.\nApple's A17 Pro is used in the iPhone 15 Pro models and is the first chipset built on the 3nm process. It has hardware-accelerated ray tracing to push video games even further.\nA18 is used in the iPhone 16 lineup including the entry iPhone 16e. It enables powerful graphics processing and Apple Intelligence.\nPorts\nThe iPhone has used the Lightning port and cable since it debuted in the iPhone 5. Apple had always shipped its iPhones with a single Lightning cable and 5W adapter until the iPhone 11 Pro, which shipped with an 18W adapter.\nThe iPhone 12 did not ship with any power adapter or headphones, a move beneficial to the environment and Apple due to lower costs. This means the box is much smaller, so plastic and rare metal use are reduced, and shipping weight and size are also reduced. This is the equivalent of removing 400,000 vehicles from the road.\nWhile the iPhone 13 was rumored to be \"portless,\" the actual release used a Lightning port as usual. Apple continued to ship the iPhone 13 without earphones or a charger.\nThe iPhone 14 was the last new product with a Lightning port as EU regulations helped spur Apple to USB-C. The first iPhone with USB-C was the iPhone 15 released in 2023, and the last with Lightning was the iPhone SE discontinued in 2025.\nGoing forward, all iPhones will use USB-C. Apple differentiates the port between standard and pro models by offering USB 2.0 on the former and USB 3.2 gen 2 on the latter.\nAccessories\nEntire industries exist to provide accessories to the iPhone user base of over 1.5 billion users. Apple offers a few first-party accessories built to offer unique experiences, but third-party manufacturers provide most of the accessories made.\nMade For iPhone Program (MFi)\nApple lets companies license proprietary hardware for their products to produce accessories that work directly with iPhone and Apple technologies. The program still exists despite the move from Lightning, but involves different products and chips for licensing.\nMFi Software:\n- AirPlay\n- CarPlay\n- HomeKit\n- GymKit\n- iPod Accessory Protocol (iAP)\n- MFi Lightning Game Controller\n- MFi Hearing Aid\n- Wi-Fi Accessory Configuration (WAC)\nMFi Hardware:\n- Authentication coprocessors\n- Headset Remote and Mic\n- Audio Module\n- Lightning Analog Headset Module\n- Lightning to Headset Jack Adapter Module\n- Lightning connectors and receptacles\n- Magnetic Charging Module\n- Smart Connector\n- MagSafe\nCases\nApple makes premium and silicone cases for the iPhone and changes out the options and colors available on a seasonal basis. Third-party companies exist by the dozen that build custom cases to personalize users' iPhones.\nApple eliminated leather from its lineup in 2023, shifting to a material called FineWoven.\nWhile cases usually exist to provide protection and add personality to a device, many features and technology that otherwise do not exist within the iPhone. For example, Lifeproof makes a case that can be fully submerged for underwater video or photography.\nThere are many specialized cases available that include infrared scanners, microphones, game controllers, and modular camera lens mounts. There was even a first-party Apple Smart Battery Case that added additional battery life with a unique design that was ultimately replaced by the MagSafe Battery Pack.\nThe iPhone 12 and later, including the phones themselves and official cases, have built-in magnets. Apple calls its magnet system MagSafe, recycling an old branding name from defunct MacBook chargers. The magnets will work with an ecosystem of accessories, including wireless-charging pads and docks, car mounts, wallets, and sleeves. Both Apple and hardware partners like Belkin are making official MagSafe accessories.\nAudio\nApple purchased Beats by Dre to absorb their music-streaming service and talent, but along with that came an entire hardware branch. The company still exists as a branch within Apple, and it sells Beats branded headphones with custom chipsets made by Apple.\nBeats By Dre with Apple Silicon:\n- Beats Studio\n- Beats Solo\n- Powerbeats\n- Powerbeats Pro 2\n- Beats X\nApple has its brand of earbuds as well. The AirPods came about as Apple removed the headphone jack from their devices and ushered in a new era of totally wireless audio. Since their release, third-party manufacturers have raced to mimic the all-wireless design, but very few have come close to capturing the same form factor, and battery life found within AirPods.\nApple first-party audio:\nMagSafe and charging\nThe iPhone can use wireless charging, fast charging over USB-C PD, and standard charging over USB. To take advantage of wireless charging or fast charging, users must purchase those accessories separately.\nApple announced but never released a proprietary wireless charging system called AirPower. The charging mat was meant to simplify charging devices wirelessly by enabling users to place their iPhone, AirPods, and Apple Watch anywhere on the mat. The charging mat was ultimately canceled when Apple allegedly could not solve overheating issues.\nApple has since released a new charging and accessory system called MagSafe, which charges the iPhone at 15W and connects via a circular magnet. It is assumed that MagSafe will ultimately replace the Lightning port and handle data and charging on future iPhones.\nWith the iPhone 13, Apple introduced a new MagSafe feature, adding Find My support to the MagSafe wallet. Rather than checking for a ping from a tracker, the system instead tells users when and where the wallet was detached from the back of the iPhone.\nThe MagSafe Battery Pack with a Lightning port is no longer for sale as of 2023. Apple could revive the product with a USB-C port, but there hasn't been any signs of it being announced.\nPhotography and Videography\nThe mobile phone camera is probably one of the most important things customers consider before purchasing. Since the iPhone became such a popular pocket camera, manufacturers have developed accessories and tools specifically to aid video and photo production.\nGimbles, mounts, flash sync systems, camera lenses, and iPhone-connected smart cameras have created a large market centered around the iPhone camera. When browsing the iPhone homepage on Apple's website, most of the page is dedicated to discussing photo and video capabilities.\nWhen paired with the right talent and equipment, the iPhone can produce competitive high-quality content. A few movies have been made with the iPhone, like \"Unsane.\" During the COVID-19 pandemic, multiple TV shows recorded episodes using the iPhone to observe proper quarantine and distancing.\nApple introduced ProRes support in its iPhone 13 Pro range to play into home movie making. Pro users can record 4K 60Hz ProRes directly to an external USB-C SSD with iPhone 15 Pro and iPhone 16 Pro.\nServices\nThe iPhone wouldn't be what it is today without the help of software and services. Apple has slowly built an entire software ecosystem surrounding its ever-popular pocket computer. Through each of these services, paid or not, Apple adds to the base value of every iPhone sold.\nAfter years of being told that Apple was too reliant on the iPhone as a single majority source of income, the company uses its services branch to build out and diversify its revenue. Services have become the size of a Fortune 500 company itself and continue to grow with each new effort from Apple.\nUsers can bundle Apple's paid services under a tiered subscription service called Apple One.\nSiri\nWhen the iPhone 4S was released with a virtual assistant, no one took it seriously. Initially, Siri could only act as a voice-controlled assistant that handled the most simple task or query.\nNow, Siri is a powerhouse piece of machine learning that exists on every Apple device sold. On the iPhone, Siri not only acts as a user-facing assistant with deep app connections and controls, and it also serves as the background intelligence that powers everyday operations.\nContacts, Calendar, Photos, and even the system keyboard rely on Siri Intelligence to manage information and surface what is most relevant to the user. Siri also acts as the brains behind Shortcuts, which can be activated via the assistant, through widgets, or in-app.\nApple does not directly monetize Siri, but it does use the assistant as a primary selling point for iPhone and accessories like HomePod mini and AirPods.\niMessage\nApple has often stated that the Messages app is the most used app on the iPhone. An iMessage is an Apple proprietary technology using end-to-end encryption to send messages via the web. Sending and receiving iMessages is exclusive to Apple products and has been cited as a significant source of consumer lock-in.\nWhen communicating via iMessage, a user sees \"blue-bubble\" messages, can share complex multi-media files, and use sticker packs and message effects. Apple also enhances iMessage group chats with unique features like message threads and custom group chat images.\nApple Music\nThe music streaming service that birthed Apple's push into services debuted in 2015. Apple Music is $10.99 a month and offers student and family plans. The service lives within the Music app on iPhone, iPad, Mac, and on the web.\nUsers can purchase music from iTunes when it is not available on the service, and it will be populated into their Apple Music library. If a user adds a physical CD to their Music app on macOS, the music will be synced across their account as well.\nApple Arcade\nApple Arcade is a monthly subscription service to games across all Apple platforms. A $6.99 per month subscription gains customers access to the entire game catalog and any new releases or updates.\nThe service has games from multiple genres and can be played with touch, though most titles support third-party controllers. Apple's push into gaming has made them embrace controllers like the Playstation Dualshock 4 and the Xbox Elite controller.\nApple TV+\nApple Studios is a new media branch within Apple that purchases and manages content for the video streaming service Apple TV+. The subscription costs $9.99 a month and exists on every Apple platform and several competitor devices.\nThe Apple TV app is needed for viewing Apple TV+ and is available in the following places:\n- Apple TV (Set-top-box)\n- iPhone\n- iPad\n- Mac\n- Roku\n- FireTV\n- Samsung Smart TV\n- LG Smart TV\n- PC\nApple News+\nApple News is a news aggregation app, and the company offers a premium content tier called Apple News+. The subscription is $12.99 per month and gives customers access to premium articles from newspapers and magazines.\nApple News Audio stories are exclusive to the iPhone application. Users can listen to articles read out loud and manage an independent queue of audio stories.\nApple Fitness+\nApple Fitness+ is a streaming fitness service with several workout types. Designed for Apple Watch users, it combines regularly updated workout videos with Apple Watch live health stats. It costs $9.99/month.\nApple revealed a SharePlay feature update to the service in 2021, enabling group workouts to be conducted remotely on multiple devices. In 2022, Apple removed the requirement for users to have an Apple Watch to participate in the service.\niCloud Storage\nThe term \"iCloud\" is a catch-all for Apple's syncing and storage service across devices and apps. The service portion of iCloud is specifically iCloud Storage.\nApple charges a monthly fee for the following storage tiers:\n- 5GB is free\n- 50GB is $0.99\n- 200GB is $2.99\n- 2TB is $9.99\n- 6TB is $29.99\n- 12TB is $59.99\nApple Card\nThe Apple Card doesn't seem to be a big earner for Apple but does add to the halo effect of capturing more customers who buy more Apple products. The card works best when used to buy more Apple products from Apple Stores and even allows customers to make interest-free purchases of nearly all Apple devices.\nDepending on the customer's credit score and other variables, the interest rate can vary from 13.24% to 24.24%. Purchases made with the physical card get 1% cashback, the card in Apple Wallet will net 2% cashback, and when used with specific partners and Apple itself, customers will get 3% cashback. Cashback rewards are automatically deposited into the customer's Apple Pay Cash balance.\nApple Card holders can open an Apple Savings account that can earn at 4.50% APY.\niOS 18\nAnnounced at WWDC 2024, iOS 18 is set to arrive in the fall alongside the iPhone 16. Here are some of the features users can expect to see.\nApple Intelligence\nThe most notable upgrade to Apple's upcoming operating systems is the integration of what Apple calls \"Apple Intelligence.\" Apple Intelligence is a personal-context based artificial intelligence. It is designed to work primarily on-device and help streamline tasks in a personal way.\nSome new features coming to the iPhone include on-device image generation, AI-powered writing and editing tools, and improved notification management.\nIt's worth noting that Apple Intelligence is only supported on the iPhone 15 Pro, M-series iPads, and M-series Macs.\nPhotos update\nA new Collections feature in iOS 18 automatically organizes the library by topics like Recent Days, Trips, and People & Pets. If you have a few favorite collections, you can pin them for quick access to the collections or albums most important to you.\nMessages updates\nApple has expanded Tapback options, now allowing users to respond to messages with any emoji, rather than the initial six it provided.\nThe new Send Later feature allows users to schedule when to send a message, which is perfect for ensuring you don't send someone a message when they're sleeping or when you want to schedule a birthday message.\nApple has confirmed that RCS support will arrive in iOS 18. RCS will improve messaging with Android devices by supporting read receipts, typing indicators, sending over Wi-Fi, and higher-quality media.\nThose who have an iPhone 14 or later will be able to use Messages via satellite. This new feature will allow users to send messages over iMessage and SMS, even without cellular or Wi-Fi service.\nWhen using iMessage, users can still use key features like sending emoji and Tapbacks, and anything sent via iMessage is end-to-end encrypted.\nGame Mode\nIn 2023, Apple introduced Game Mode to Mac \u2014 and a year later Game Mode is coming to the iPhone.\nGame Mode minimizes background activity while gaming. This allows the iPhone to sustain high frame rates for long gaming sessions.\nLocked and Hidden apps\nUsers can lock apps and require Face ID, Touch ID, or a passcode to unlock them, lessening the fear of handing off your iPhone to someone else. Locked apps will not appear in search and notifications, either.\nApps can also be hidden by dragging them to a hidden apps folder, requiring users to unlock the folder via biometrics or passcode before viewing the contents.\nHome Screen, Lock Screen, and Control Center customization options\nNow, on the Lock Screen, you can replace the controls at the bottom with something else, such as taking a note or quickly capturing a moment for your social media. If you have an iPhone 15 Pro, you can access these controls using the Action button.\nAs part of the expanded customization features, app icons, and widgets can now be scaled up to appear larger.\nUsers are no longer restricted to the standard app icon layout anymore. The new iOS 18 adds the ability to arrange apps along the bottom for quicker access or along the side to frame a favorite wallpaper.\nEach page of the Home Screen can feature a unique layout.\nManufacturing iPhone in the United States\nThere has been a lot of talk around the possibility of building an iPhone in the United States. Simply put, it isn't possible \u2014 at least not without incredible changes to the workforce, material availability, factories, and more.\nEven if Apple could perform final assembly in the United States by maximizing automation, most of the parts and materials would be sourced from abroad. The iPhone is a global product and the United States simply doesn't have the resources to make iPhone farm to table.\nThe discussions around manufacturing iPhone in the United States peaked in 2025 when the Trump administration levied extreme tariffs on countries around the globe. Tariffs were particularly high on China, which affects Apple the most.\nLearn more about iPhone\nLatest iPhone models:\n- iPhone 16e\n- iPhone 16\n- iPhone 16 Plus\n- iPhone 16 Pro\n- iPhone 16 Pro Max\nPrevious iPhone models:\n- iPhone 15\n- iPhone 15 Plus\n- iPhone 15 Pro\n- iPhone 15 Pro Max\n- iPhone 14\n- iPhone 14 Plus\n- iPhone 14 Pro\n- iPhone 14 Pro Max\n- iPhone 13\n- iPhone 13 mini\n- iPhone 13 Pro\n- iPhone 13 Pro Max\n- iPhone SE\n- iPhone 12\n- iPhone 12 mini\n- iPhone 11\nRumored iPhones:"
    },
    {
      "url": "https://appleinsider.com/inside/apple-intelligence",
      "text": "Apple Intelligence\nAll about Apple Intelligence\nTable of Contents\nMachine learning led to more powerful technologies people ultimately dubbed \"artificial intelligence.\" While it is mostly a misnomer based on science fiction, Apple eventually began to embrace the term until it moved past it with Apple Intelligence.\nApple CEO Tim Cook will tell you that Apple Intelligence isn't named because of the \"AI\" that came before it. Instead, he'll insist that it was given the name that best described the technology.\nRegardless, Apple Intelligence is Apple's take on generative technologies that have taken the world by storm. OpenAI, Google, and others have flooded the market with their imperfect implementations in the hope of wrestling away some early market share.\nDespite pundit declarations that Apple was behind and would never catch up, the company has had a hand in machine intelligence for over a decade. Now, finally, Apple has chosen to appease these complainers by introducing a more nuanced version of the technology.\nA limited set of features like Writing Tools and the new Siri animation became available as of iOS 18.1, released in October 2024.\niOS 18.2 released on December 11, 2024. It includes Image Playground, ChatGPT integration, Visual Intelligence for iPhone 16, and Genmoji.\nApple released iOS 18.3 in January 2025 with few updates focused on AI. The company announced that the app intent system that would create a more contextually aware Apple Intelligence and Siri is delayed into the coming year.\nWhat's next for Apple Intelligence\nApple Intelligence is an on-device model with custom prompts depending on the mode it is being used in, like Writing Tools or Image Playground. Siri will get smarter thanks to Apple Intelligence, integrations with ChatGPT, and third-party app intents, but it still doesn't have an LLM backend.\nSiri may have new features that let it understand user prompts better and will soon gain a better understanding of what's on the display, but these are AI parts in a machine learning product, not a full overhaul. Such an overhaul of Siri's backend may come, but not until sometime in 2026.\nA rumor suggests Apple will rebuild Siri with an LLM backend that will fundamentally change the assistant into a full-on chatbot similar to ChatGPT. That wasn't announced during WWDC 2025, but Apple may be holding back on pre-announcing features until they are closer to being ready.\nMeanwhile, users are still waiting on the more contextual Siri and Apple Intelligence promised with iOS 18. That feature set was delayed and may not appear until early 2026 in a version of iOS 26.\nAnother rumor says Apple may abandon using Apple Intelligence as the backend for Siri and opt for something built by OpenAI or Anthropic. However, it seems more likely that this rumor suggests Apple is working to bring new models to Private Cloud Compute rather than replacing their own.\nIn essence, it would mean users could call out to private and secure versions of ChatGPT, Claude, Gemini, and Apple Intelligence via Private Cloud Compute. Previous rumors called this a sort of AI App Store where users could choose the models and access any or all of them from iPhone, iPad, and Mac.\niOS 26 and AI updates\nApple Intelligence was the focus of WWDC 2024 and mentioned constantly throughout the keynote, so it is understandable to believe Apple forgot about it during WWDC 2025. There was a brief mention at the top of the 2025 keynote and new features sprinkled throughout, but it's still a big year for Apple's AI efforts.\nDevelopers get access to Apple Intelligence via Apple's new Foundation Models framework. That means developers can perform tasks using Apple's on-device, private, and secure models instead of having to pay for an external model that sucks up user data.\nShortcuts gets new Apple Intelligence functions, enabling users to add steps for including Writing Tools or calling out to the Private Cloud Compute model directly. Responses and results can be fed back into the Shortcut for complex actions.\nVisual Intelligence is now available via the screenshot action. Users can screenshot objects, event posters, or text and search Google or ask ChatGPT to take action on the item.\nImage Playground and Genmoji can now be generated using ChatGPT as a prompt. The ChatGPT tool inside of the app has presets and lets users type out descriptions for manipulating an image.\nApple Watch got some AI action thanks to Workout Buddy in watchOS 26. A virtual assistant will now provide encouragement while working out and generate voice output based on available data.\nLive Translation\nApple devices will now provide translation in various systems across the ecosystem. In addition to the translation features already available for webpages in Safari and the Translate app, Apple has added automatic and Live Translation to other apps.\nOne of the features includes Live Translaton of lyrics in Apple Music. Some songs will show the English equivalent of a lyrics while others will provide a pronunciation guide \u2014 there's a UI option to toggle it on and off.\nLive Translation is also available in Messages, Phone, and FaceTime. Calls can be translated back and forth to both users on the call to help overcome language barriers when needed.\nConcerns regarding Apple Intelligence\nSo-called artificial intelligence hit the market running and has been iterated at a full sprint since. The explosive growth of the AI industry relied on having access to mountains of data gathered from the internet and its users.\nSome companies, like Google, had a strong foundation to train their models thanks to the literal mountains of data collected from users. However, there wasn't any way to predict exactly how models would react to learning from the trove of human-produced data.\nThe result, so far, has been chatbots and search engines that hallucinate because of poorly sourced data from non-factual sources. Replies to searches and chats can sometimes result in funny suggestions like glue on pizza, but other times result in something potentially dangerous.\nOther competitors, like OpenAI's ChatGPT, release updates that seem to lean into the meme culture of the internet. The image generation tool became viral as users created Studio Ghibli-inspired art based on photos they fed the tool.\nApple Intelligence is a group of foundational models built to run either at a smaller scale for iPhone, iPad, and Mac or at twice the size or bigger on a server. It is a testament to Apple's vertical integration of hardware and software.\nSince the models are local to the user's device, they can access sensitive data like contacts, photos, and location without the user needing to worry about compromising that data. Everything gathered by the Appel AI never leaves the device and isn't used to train the model.\nIn the event a request can't be run on the device, it can be sent to a server owned by Apple, running Apple Silicon with a Secure Enclave. All data sent off the device is encrypted and treated with the same protections it would have if it stayed local. This server-side technology is called Apple Cloud Compute.\nEven with privacy and security at its foundation, Apple Intelligence still had to be trained on something. Apple purchased licensed content for some of the training, but other data was sourced from Applebot, a web scraper that has existed since 2015 for surfacing Spotlight search data.\nThere is an ethical conundrum surrounding Apple's model training practices, but the company has assured that it has taken steps to ensure all public data is freely available on the web, lacks copyrighted or personal content, and is filtered for low-quality content. It's a small reassurance, given other companies had no regard for such precautions.\nThere has also been some concern about Apple Intelligence and the environment. On-device models don't have an impact on Apple's green energy initiatives, and server-side computation is performed on Apple Silicon, which is powered by green energy sources.\nApple Intelligence launch features\nApple Intelligence is made up of several models that have specific training to accomplish different tasks with minimal risk of error or hallucinations. There were several planned features at launch, with more arriving over 2024 and 2025 with iOS 18, iPadOS 18, and macOS Sequoia.\nWriting Tools works anywhere text entry is supported across the device's operating system. It analyzes text to proofread for errors, change the tone of the text to be more professional, or summarize the text.\nPriority Notifications analyze incoming notifications to ensure only the most important are at the top, and they are summarized too. It ensures messages, deliveries, and other important information is available at a glance.\nData summarization is everywhere in the supported operating systems. Summarize web pages, emails, text threads, and more.\nApple has come under fire due to notification summaries sometimes combining different news headlines into one that's wrong, confusing, or suggests someone is dead that isn't. As a result, notifications that are summarized will get an updated UI element to ensure users know it is an AI summary and not a headline.\nImage Playground is a app from Apple that generates images like emoji or cartoon-styled art. There is a standalone app, but the function appears in different locations, such as in iMessage. It was included in iOS 18.2 with mixed reviews as the results are not flattering or useful in their launch state.\nApple has more AI features separate from its proprietary systems thanks to a partnership with OpenAI. They are off by default, but if enabled, users can send some requests to ChatGPT. Every request must be screened and approved by the user, and all data from the interaction is discarded.\nUsers can to carry out more natural conversations with Siri, even if they make a mistake and correct themselves mid sentence. And as long as the user asks questions within the same relative timeframe, Siri will remember context from previous queries.\nMore advancements are coming to Siri later thanks to a planned update involving app intents.\nApp intents & contextual AI\nSiri is set to get a huge boost from Apple Intelligence by having access to data presented by the various on-device models. The smart assistant is more knowledgeable about the user, their plans, who they're talking to, and what data is within apps.\nThe voice interactions with Siri will primarily serve as a way to activate Apple Intelligence features from anywhere. However, Siri will have additional abilities thanks to app intents providing context for what is visible on the display.\nApps with Apple Intelligence Siri support:\n- Books\n- Calendar\n- Camera\n- Contacts\n- Files\n- Freeform\n- Keynote\n- Magnifier\n- News\n- Notes\n- Photos\n- Reminders\n- Safari\n- Stocks\n- Settings\n- Voice Memos\nThe upgrade to Siri could take some time. Rumors suggested Apple would not release the new Siri until iOS 18.4 sometime in spring 2025, but that has been delayed \u2014 likely an iOS 26 release.\nIt's Glowtime\nApple's iPhone 16 event occured on September 9, 2024 and had a clear theme around Apple Intelligence. The \"Glowtime\" name is a reference to the new Siri glow, which was a core part of the event.\nThe entire iPhone 16 lineup can take advantage of Apple Intelligence features. The A18 and A18 Pro have a more powerful neural engine, and the new devices are what Apple calls the first iPhones designed from the ground up for AI.\nThe Visual Intelligence features attached to the Camera Control button was also revealed. It is an exclusive AI feature for the iPhone 16 lineup.\niPhone 16 supercycle\nAnalysts expect Apple to have a record release cycle with iPhone 16 thanks to Apple Intelligence. Anyone that doesn't own an iPhone 15 Pro or iPhone 15 Pro Max, which is most people, will have to upgrade for access to Apple's AI.\nThat means 2024 was expected to be a significant year for iPhone sales similar to the 5G boom and the bigger iPhone craze launched with iPhone 6 Plus. Consumers know about AI like ChatGPT and want access to it, and Apple's promise of private, on-device models could have been enticing.\nHowever, evidence showed that while demand was strong for the iPhone 16 lineup, a supercycle didn't happen. It could be attributed to the slow rollout of AI features or lack of overtly exciting party tricks at launch.\nApple has since toned down its approach to AI and advertising the features. WWDC 2025 had Apple Intelligence sprinkled throughout, but it definitely wasn't front and center like it was in 2024.\nThe iPhone 17 lineup will likely have more AI features associated with them, but this time it seems they will only be ones available at launch. Apple was clearly burned from announcing features that weren't ready for prime time and likely won't make that mistake again anytime soon.\nVisual Intelligence\nPress and hold on the Camera Control button on any iPhone 16 and the Visual Intelligence experience will launch. It acts as a Google Lens-like feature that lets the iPhone \"see\" the world and interact with different elements.\nPoint the camera at a concert poster to add the concert to the user's calendar. Or, launch directly into the visual lookup feature and check dog breeds or flower names just by taking a photo.\nTwo buttons at the bottom will take whatever is in the viewfinder and pass it to Google for search or ChatGPT for parsing. As is standard with Apple Intelligence and AI on the iPhone, all interactions with AI is user controlled.\nVisual Intelligence was later spread to the iPhone 15 Pro and iPhone 16e via the Action button. Apple upgraded the feature to include it in the screenshot tool with iOS 26.\nApple Intelligence requirements\nApple claims that Apple Intelligence couldn't exist until it could run locally on a device, and that wasn't possible until the A17 Pro. So, the available devices for the technology are very limited.\nThe base requirements appear to be tied to the size of the Neural Engine and the amount of RAM. The iPhone 15 Pro and iPhone 15 Pro Max have 8GB of RAM and run the A17 Pro with a sizeable Neural Engine.\nThe launch of the iPhone 16 lineup added four more devices that support Apple Intelligence, which could spur demand.\nMacs and iPads can run Apple Intelligence as long as they have an M-series processor. The desktop-class processor has always had a large Neural Engine and enough RAM at 8GB minimum for the chipset.\nApple Intelligence release date\nApple Intelligence launched to the public with iOS 18.1, iPadOS 18.1, and macOS Sequoia 15.1 on October 28, 2024. The initial features included Writing Tools, Photos Clean Up, and system-wide summaries.\niOS 18.2 arrived in December 2024 with Image Playground, ChatGPT integration, and Visual Intelligence. More features are delayed until iOS 26.\nEverything below this point is based on pre-WWDC 2024 rumors and leaks. It has been preserved for reference.\nPre-announcement AI rumors\nApple is known to adopt its own marketing terms to describe existing phenomenons, like calling VR or MR by the in-house term \"spatial computing.\" It seemed like Apple was going to lean into Artificial Intelligence, or AI, as a term, but it is expected to add a twist by calling it \"Apple Intelligence.\"\nWhatever Apple calls it, the result is the same. There will be system-wide tools that run using generative technologies that are much more advanced than the machine learning algorithms they'll replace or augment.\nApple may reveal plans for a server-side LLM during WWDC, but rumors suggest it isn't ready for prime time. Instead, the focus will be on local models made by Apple that can call out to third-party server-side LLMs like ChatGPT.\nLocal Apple Intelligence\nOpenAI's ChatGPT and Google's Gemini Large Language Models (LLMs) have one thing in common \u2014 they are gigantic models trained on every ounce of available data on the internet that live in servers.\nThe \"Large\" in LLM is literal, as these models can't live on something like an iPhone or Mac. Instead, users call the models and their various versions through the cloud via APIs. That requires data to leave the user's device and head to a server they don't control.\nServer-side models are a must for such enormous data sets, but they come at the cost of privacy and security. It may be harmless to ask an LLM to generate a photo or write an essay about historical events, but asking it to perform a budget may cross a line.\nApple hopes to address these types of concerns by providing more limited local models across the iPhone, iPad, Mac, and Apple Vision Pro. The pre-trained models will serve specific purposes and will contain very limited but specialized data sets.\nThe on-device models will learn based on user data. The data will never leave the device without explicit permission.\nUpgrading Siri\nA part of local Apple Intelligence will be providing significant upgrades to Siri. Apple's assistant is expected to become much more conversational and understand contexts better.\nA specific model, likely based on the \"Apple Ask\" pre-trained model that's been tested internally, will be the driver behind Siri. Its limited data set is said to be a protection against hallucinations, which plague LLMs like Google Gemini and ChatGPT.\nUsers can ask Siri to perform many tasks across Apple-made apps, from simple to complex. It isn't yet known if an API will allow developers to target this new Siri, but it is likely.\nApps with Apple Intelligence Siri support:\n- Books\n- Calendar\n- Camera\n- Contacts\n- Files\n- Freeform\n- Keynote\n- Magnifier\n- News\n- Notes\n- Photos\n- Reminders\n- Safari\n- Stocks\n- Settings\n- Voice Memos\nMany Siri functions in these apps involve general navigation and search. Like opening a specific book or creating a new slide.\nIt seems many of the functions found in the new Siri commands are derived from previously available accessibility options that could control the device via voice. This melding of features will provide more control for all users, not just ones relying on accessibility options.\nApple Intelligence at WWDC\nAll will be revealed during WWDC 2024. Apple is expected to reveal Apple Intelligence during its keynote, where iOS 18, iPadOS 18, macOS 15, tvOS 18, watchOS 11, and visionOS 2 will also be announced."
    },
    {
      "url": "https://appleinsider.com/inside/ipad",
      "text": "iPad\nAll about iPad\nTable of Contents\n- iPad\n- 1. New iPad\n- 2. 11-inch iPad\n- 3. iPad mini\n- 4. iPad Air\n- 5. iPad Pro\n- 6. iPad lineup features\n- Display and design\n- 7. iPadOS 26\n- 8. Apple Intelligence\n- 9. Previous iPadOS releases\n- iPadOS 18\n- iPad apps\n- Smart Keyboard and Magic Keyboard\n- Apple Pencil\n- Apple Silicon\n- Security\n- Ports and Connectivity\n- Photography and Videography\n- 10. iPad Services\n- Siri on iPad\n- iMessage on iPad\n- Apple Arcade on iPad\n- Apple TV+ on iPad\n- Apple News+\n- Apple Music on iPad\n- iCloud Storage\n- Apple Pay\n- 11. Which iPad to buy\nApple often refers to the iPad as the future of computing with its slim form factor and touch display. The company offers a wide variety iPads, from a budget-friendly model for students to a high-end powerhouse aimed at professionals.\nThe iPad was the last new hardware product category Steve Jobs announced before his passing. In the company's 2010 launch event, Jobs described the experience of using the tablet as \"holding the internet in your hands.\"\nDespite post-launch-event blowback mocking the iPad's name and dismissing it as an oversized iPhone or iPod touch, both consumers and critics hailed Apple's iPad as another breakthrough. It stormed its way to 15 million sales from April to December of that first year alone.\nCurrent models for sale:\nNew iPad\nApple revealed the updated base iPad and the iPad Air in March 2025. These devices go against many of the rumors, so it places the M5 iPad Pro into question.\nThe iPad Pro line could get M5 sometime in 2025, but rumors place it after the release of an M5-equipped MacBook Pro. That means the new iPad Pro may not be announced until the end of the year or early 2026.\nHowever, another wrinkle has been thrown into this release pipeline. The M5 MacBook lineup is now rumored for early 2026, which means either Apple will reveal the M5 in the iPad Pro alone in 2025, or wait until early 2026 for the new tablet.\nThere are also rumors of a series of foldable products coming from Apple. It could start with an iPhone Fold, but there are also rumors of a foldable iPad and even a foldable Mac.\nIt is unclear if Apple will ever release these long-rumored products. There is plenty of evidence that they exist, at least internally in testing, but the technology may never reach a level acceptable for Apple's perfectionism.\n11-inch iPad\nApple's entry level iPad is in its 11th generation. It was formerly referred to as the 10.9-inch iPad, but Apple's trend of simplifying names continues as it is referred to the 11-inch iPad. Apple calls it the iPad (A16).\nThe device surprisingly only made it to the A16 chipset, which means no Apple Intelligence. It may be due to the need to hit a target price point for education.\nOtherwise, the device is unchanged externally. It has the full-screen Retina LED display, USB-C port, and single 12MP rear camera.\nThe selfie camera is on the landscape edge and supports Center Stage. A Magic Keyboard Folio is available that adds a trackpad and keyboard via the Smart Connector.\nApple Pencil USB-C and Apple Pencil (1st generation) work with the 11-inch iPad.\niPad mini\nApple's iPad mini sits somewhere between the base model and iPad Air. It has better specs than the low end, but it is also the smallest device in the lineup.\nIt uses the A17 Pro chipset so it has access to Apple Intelligence features. The 8.3-inch Liquid Retina Display is LED backlit, offers 500 nits of brightness, and works with Apple Pencil Pro.\niPad mini is an excellent portable gaming machine, e-reader, and casual consumption device. It's the best iPad-as-a-tablet form factor in the lineup.\niPad Air\nApple's iPad Air sits firmly in the middle of the lineup. It comes in 13-inch and 11-inch sizes, uses the M3 chipset, and has a USB-C port.\nThis tablet acts as a more-affordable entry point to better specs and Apple Intelligence. Artists may find the lower-priced 13-inch iPad Air much more approachable.\nIt lacks ProMotion, Thunderbolt, Face ID, OLED, and Nano Texture. The M3 chip is less powerful, but plenty capable for most needs.\niPad Pro\nApple's iPad Pro is the flagship tablet with all the top-end specs. It is also available in 11-inch and 13-inch sizes, but the displays are tandem OLED with ProMotion.\nThe M4 processor debuted in the iPad Pro and offers powerful graphics processing. Configurations with 1TB or 2TB of storage get 16GB of RAM and an extra CPU performance core.\nCustomers seeking to get access to every spec and feature can choose iPad Pro with the Apple Pencil Pro and Magic Keyboard for iPad Pro. Thunderbolt connectivity allows it to be easily swapped into a Thunderbolt docking station with an external monitor and accessories.\niPad lineup features\nThe iPad was first positioned as a content-consumption device for reading or viewing videos. However, Apple later improved iPad performance and added accessories that transformed this simple tablet into a complex computing platform.\nDisplay and design\nThough the basic design is still a glass and aluminum slab, Apple's iPad has grown thinner and lighter through the years, with shrinking bezels, bigger and better displays, and the home button removal.\nEvery iPad model today has a Retina Display, Apple's marketing term indicating that human eyes won't differentiate individual pixels from a standard viewing distance.\nUltra Retina XDR Display\n- Used on the 11-inch and 13-inch iPad Pro\n- 264 ppi\n- Tandem OLED\n- P3 color gamut\n- True Tone\n- 1,000 nits SDR/HDR, 1,600 nits HDR peak\n- Fingerprint-resistant oleophobic coating\n- Fully laminated dispaly\n- Anti-reflective coating with Nano Texture option\n- ProMotion technology\nUltra Retina XDR display for iPad Pro\n- 264 ppi\n- Tandem OLED\n- ProMotion 10Hz to 120Hz refresh rate\n- P3 color gamut\n- True Tone\n- 1000 nits max brightness, 1600 nits max HDR brightness\n- Fingerprint-resistant oleophobic coating\n- Fully laminated display\n- Anti-reflective coating\nLiquid Retina Display on iPad Air\n- 264 ppi\n- LED\n- P3 color gamut\n- True Tone\n- Max brightness: 11-inch 500 nits, 13-inch 600 nits\n- Fingerprint-resistant oleophobic coating\n- Fully laminated display\n- Anti-reflective coating\nRetina Display on 11-inch iPad\n- 264 ppi\n- LED\n- 500 nits max brightness\n- sRGB\n- True Tone\n- Fingerprint-resistant oleophobic coating\nRetina Display on iPad mini 6\n- 326 ppi\n- All-screen LED\n- P3 color gamut\n- True Tone\n- 500 nits max brightness\n- Fingerprint-resistant oleophobic coating\n- Fully laminated display\n- Anti-reflective coating\nTrue Tone, included on all iPads in today's lineup, uses ambient light sensors to adjust the screen's white balance based on your environment.\nProMotion technology, available only on iPad Pro models, supports up to a 120Hz refresh rate for \"fluid scrolling, greater responsiveness, and smoother motion content.\" It also provides more responsive Apple Pencil input and varies the iPad screen refresh rate to reduce power consumption.\niPadOS 26\nApple revealed iPadOS 26 during WWDC 2025 with a complete redesign built with Liquid Glass material and a whole new multitasking system. It is a complete rethinking of iPadOS that ditches Split View and Slide Over in favor of resizable, tileable windows.\nOther significant updates include the ability to record local audio, customize folders in Files, set default apps for files and extensions, and the Preview app. Journal also arrived on iPad along with several other features.\nSome feature highlights in iPadOS 26:\n- Liquid Glass changes the look and feel of iPadOS\n- Updated Phone app with unified layout\n- Messages gets new filters with spam screening\n- Live Translation across the system, like in Messages, FaceTime, and Apple Music\n- Apple Intelligence comes to Shortcuts\n- Image Playground and Genmoji get new styles and ChatGPT support\n- Reminders gains Apple Intelligence suggestions and sorting\n- Apple Games app adds discovery and social tools to one central location\n- Safari is redesigned with a floating, rounded tab layout\n- Messages gains backgrounds, polls, and group chat typing indicators\n- Journal app on iPad, users can create multiple journals in the Journal app\n- Photos gets more customization, new tab design with Liquid Glass\n- FaceTime gets a new landing page with Contact Posters\n- Notes gains import and export of Markdown files\n- Passwords gets a history view to access old passwords\n- The tool palette gets a new reed pen\nApple Intelligence\nApple Intelligence is Apple's initiative to incorporate artificial intelligence into its products. Due to Apple's emphasis on security and privacy, most of the Apple Intelligence processes take place on the device itself or in an apple controlled Private Cloud Compute server.\nAdditionally, Apple defines Apple Intelligence as \"personal intelligence,\" with a focus on improving how users engage with the apps and services they already use, rather than concentrating on new use cases. The initial AI tools included Writing Tools, notification summaries, and Image Playground.\nThe initial rollout was slow, but most of what Apple announced during WWDC 2024 was available by the end of the year. However, what was likely the most significant feature, contextual AI and Siri, was delayed into late 2025 or early 2026.\nMore features were introduced with iPadOS 26, including a new Live Translation feature in Phone, FaceTime, and Apple Music. Shortcuts also gained an Apple Intelligence function.\nApple Intelligence is only available on M-series Macs, iPads, and iPhones equipped with the A17 Pro chip or newer.\nPrevious iPadOS releases\niPadOS is an operating system branched from iOS that Apple is now developing in parallel. Previously, iPads would only see a few changes year-over-year in software, and this dedicated OS indicates Apple wants to do more for the iPad.\niPadOS and iOS share much of the same code base, meaning iPadOS is only distinct in a few key features. These differences have increased and become more varied as Apple updated the two.\nWith iOS 9, the tablet software showed a significant shift from the iPhone with the added ability to have multiple apps on the same screen. Slide Over adds a second floating app you can bring onscreen by swiping from the edge. Split View, meanwhile, places two apps next to each other, spaced evenly or asymmetrically.\nMultitasking and productivity were later refined in iOS 11 with better file sharing and drag-and-drop gestures. iOS 13 arrived in 2019 with many new features across the ecosystem, and with it, iPadOS. With its improved split-screen, multi-window app states, and external storage support, Apple's iPad took a significant leap forward as a laptop replacement.\niPadOS 15 was released in 2021 with minor alterations to the multitasking system to help users understand how to initiate and switch apps more easily. A new ellipsis appears at the top of each active window with options to place the app into different positions.\nStage Manager was introduced in iPadOS 16, bringing the software to another level with a native app windowing system. It went through a rocky beta cycle after it was announced in the spring of 2022. It is only available to iPads with an A12X, A12Z, M1, or M2 processor.\niPadOS 17 improved on Stage Manager, but otherwise didn't do much to push iPad productivity forward. The release also included support for customizable Lock Screens and interactive Home Screen widgets.\niPadOS 18\nAnnounced at WWDC 2024, iPadOS 18 debuted in the fall and will bring a handful of new features to Apple's flagship tablet. Many new features are shared with iOS 18, but several are iPad-exclusive.\nIntroduced as a part of the Notes app, iPadOS now lets users perform text editing on their handwriting through a feature called Smart Script. For handwritten notes in Notes, users can now spellcheck their text, with changes made to blend into the user's scribbles.\nAfter years of user request, Calculator has finally come to iPad. As part of its debut, Apple has created a new Math Notes feature, allowing users to handwrite their math problems. When writing in expressions, the Calculator will immediately solve problems once an equal sign is written.\nA redesigned Collections feature in the Photos app automatically organizes the library by topics like Recent Days, Trips, and People & Pets. If you have a few favorite collections, you can pin them for quick access to the collections or albums most important to you.\nControl Center now has more robust customization options. This includes the ability to sort controls under categories, as well as swapping out controls on the main screen.\nUsers are no longer restricted to the standard app icon layout anymore. The new iOS 18 adds the ability to arrange apps along the bottom for quicker access or along the side to frame a favorite wallpaper. Icons on the home screen can also be tinted to fit your theme better.\nNew text effects allow you to animate words and emojis with various effects. Some words and phrases will automatically display a suggestion, but users can add text effects to any text they select. Users can now bold, underline, italicize, and cross out text.\nApple has expanded Tapback options for Messages, now allowing users to respond with any emoji or sticker, including live stickers and stickers from packs purchased through the Messages App Store.\nSend Later allows users to schedule when to send a message, perfect for ensuring you don't send someone a message when they're sleeping or when you want to schedule a birthday message.\nGame Mode minimizes background activity while gaming. This allows the iPhone to sustain high frame rates for long gaming sessions.\nApple has added the ability to create, view, edit, and complete reminders from the Reminders app in the Calendar app. It has also redesigned the month view for easier browsing.\niPad apps\nThe App Store operates as the sole storefront for software on iPads. Apple does not allow users to side-load apps from the web or use other app stores on iPadOS.\nMany apps draw from the same codebase as their iPhone counterpart, with the iPad version making better use of the larger display. Developers often use multiple panels for iPad apps that wouldn't fit on an iPhone's screen.\nApple pre-loads every iPad with various first-party apps. Once users finish the onboarding process on a new device, they can go to the App Store and download free and paid apps via their Apple ID.\nApp updates are free, but developers may lock some features behind paywalls called in-app purchases or IAP. Some apps charge a subscription fee instead of IAP, unlocking features once a user subscribes.\nSmart Keyboard and Magic Keyboard\nApple's first iPad keyboard accessory was a Keyboard Dock for the first-generation iPad that propped up the tablet in portrait mode. For several generations, Apple didn't release dedicated tablet keyboards.\nWhen the first iPad Pro launched in late 2015, Apple began marketing the tablet as a new computing category that could replace a laptop for some customers. The Apple Smart Keyboard was an integral part of that strategy.\nThe Smart Keyboard is similar to the Smart Cover, snapping magnetically to the tablet and connecting instantly through Apple's Smart Connector. It has fabric-covered and water-resistant keys.\nThe Apple Smart Keyboard (or Smart Keyboard Folio), sold in several different sizes through the years, supports the following iPads:\n- 12.9-inch iPad Pro\n- 11-inch iPad Pro\n- iPad Air 4 and iPad Air 5\n- 9.7-inch iPad Pro\n- 10.5-inch iPad Pro\n- iPad Air 3\n- 10.2-inch iPad (seventh- and eight-generation)\nThe Smart Keyboard was an iPad Pro exclusive until 2019 when Apple launched the iPad Air 3 and the seventh generation iPad, both supporting the keyboard accessory. The Smart Keyboard was officially discontinued with the release of the 2024 iPad updates.\nIn early 2020, Apple launched the Magic Keyboard for iPad Pro, which added Mac-style scissor-switch keys and a glass trackpad that took advantage of cursor support. The accessory has a stand that magnetically mounts the tablet, making it float above the keys while dynamically tilting at various angles.\nThe Magic Keyboard for iPad supports the following models:\n- 11-inch iPad Pro (first-generation through fourth-generation)\n- 12.9-inch iPad Pro (third-generation through sixth-generation)\n- iPad Air 4 and up\nAn updated Magic Keyboard for iPad Pro was introduced in 2024 to support the new ultra-thin iPad Pro models. It has a similar design, but has a function row, bigger trackpad, and an aluminum wrist rest.\nIn 2022 Apple announced the updated 10.9-inch iPad and a keyboard case to go with it. Since the Smart Connector was in a different location to other iPads, it needed its own keyboard, so Apple released the Magic Keyboard Folio.\nThis keyboard only works with the 10.9-inch iPad for now. It is a two-piece system with a case and kickstand on the back and a keyboard attached via a magnetic base.\nApple Pencil\nThe first-generation iPad Pro also marked the arrival of the Apple Pencil. Its primary use case was targeted at drawing and taking notes.\nFor sketching, the Apple Pencil has low latency, pressure sensitivity, and support for tilting and shading. You can also use it as a pointer to edit text, navigate apps or web pages, or sign documents.\nThe first-generation Apple Pencil has fully rounded sides. It pairs and charges through the iPad Lightning port, one of the limits of the original Apple Pencil. It leaves the iPad with a protruding stylus and simultaneously prevents users from charging the tablet and Apple Pencil.\nThe first-generation Apple Pencil is compatible with the following models:\n- 11-inch iPad\n- 10.9-inch iPad\n- 12.9-inch iPad Pro (first- and second-generation)\n- 9.7-inch iPad Pro\n- 10.5-inch iPad Pro\n- iPad Air 3\n- 9.7-inch iPad (sixth-generation)\n- 10.2-inch iPad (seventh-generation and up)\n- iPad mini 5\nIn late 2018, Apple introduced a second-generation Apple Pencil with several key improvements. Rather than being fully rounded, the second-generation model is flat on one edge, making it more ergonomic in hand and preventing it from rolling off surfaces.\nThe Apple Pencil 2 also supports wireless charging, mounting magnetically to the side of a compatible iPad to draw power. It also adds tap gestures, with sensors on the accessory's side registering finger taps as customizable responses. These customizable tap actions can include switching between tools and toggling the color palette.\nThe second-generation Apple Pencil supports:\n- 11-inch iPad Pro (first-generation through fourth-generation)\n- 12.9-inch iPad Pro (third-generation through sixth-generation)\n- iPad Air 4 and iPad Air 5\n- iPad mini 6\nApple released a new Apple Pencil with USB-C in 2023. It serves as a lower-end model that works with any flat-sided iPad model.\nAn Apple Pencil Pro was introduced in 2024 that supports wireless charging with the new magnetic charging system in iPads with landscape-oriented selfie cameras. It only works with the 2024 iPad Pro and iPad Air models.\nIt supports features like Barrel Roll, Hover, and provides haptic feedback.\nApple Silicon\nApple builds its custom processors for the iPhone, iPad, Apple Watch, Apple TV, and Mac. By developing its chipsets, Apple can customize its software to work directly with the hardware so that competitors cannot imitate it.\nApple Silicon isn't a single processor but a system-on-a-chip (SoC) that combines multiple technologies into a single wafer.\nThe iPad Air 4 contains the A14 Bionic chip, which is found in the iPhone 12 series. It utilizes a 5nm architecture and offers up to double the graphics performance of the previous generation. The chip has a six-core CPU and 11.8 billion transistors, 40% more than the A13.\nThe 2018 and 2020 iPad Pro lines use an A12X chip. While it's older than the A14 found in the cheaper iPad Air 4, the A12X has eight dedicated GPU cores that should give it an edge in graphically-intensive tasks.\nThe 2021 iPad Pros and iPad Air 5 use the M1 processor, the first Apple Silicon processor designed for Mac. Users can get 8GB or 16GB of RAM based on internal storage choice, but the iPad Air 5 only gets 8GB of RAM because it doesn't have the higher storage options.\nThe M2 came to iPad Pro in 2022 with little other new changes to the products. Other updates included WiFi 6E and an Apple Pencil hover feature.\nApple introduced the M4 processor and included it in the 11-inch iPad Pro and 13-inch iPad Pro in 2024. It improves on the M3 processor, which wasn't used in any model until the iPad Air in 2025.\nThe iPad mini 6 uses the A15 processor, the same one used in the iPhone 13. The 10.9-inch iPad used the A14 processor, and moved up to the A16 for the 11-inch iPad released in 2025.\nSecurity\nThe first iPad biometric sensors arrived in 2014, with the arrival of Touch ID in the iPad Air 2 and iPad mini 3. After that, every new model Apple released used one form of biometric security.\nThe third-generation iPad Pro gained an all-screen design, replacing the Touch ID home button with Face ID. In late 2020, the iPad Air also went all-screen, but, perhaps to cut costs compared to Face ID, Apple instead opted for Touch ID in the device's power button.\nThe iPad mini 6 and 11-inch iPad uses the same power button Touch ID.\nApple moved the Face ID sensors and the selfie camera to the landscape side of the iPad with the 10.9-inch iPad then 2024 iPad Pro and 2025 iPad Air.\nPorts and Connectivity\nThe first three iPads used Apple's old 30-pin connectors. In late 2012, Apple switched to a Lightning port for charging and syncing, starting with the fourth-generation model and iPad mini.\nThe following change arrived with the 2018 iPad Pro lineup, which shifted to USB-C for broader accessory compatibility. The iPad Air 4 and iPad mini 6 also use USB-C.\nThe 2021 iPad Pro lineup moved to Thunderbolt 3 when updated with the M1 processor.\nThe 10.2-inch iPad was the last model still using a Lightning port. It's successor, the 10.9-inch iPad, also moved to USB-C. The 11-inch iPad also offers USB-C.\nApple sells each model in both WiFi-only and more expensive WiFi-with-cellular-data variants. Cellular models are sold unlocked at full price and subsidized through wireless carriers.\nPhotography and Videography\nFor most people, cameras aren't as necessary on a large iPad as on a pocketable iPhone. iPads typically have cameras at least one or two generations behind the latest iPhone cameras.\nCompared to other iPads, the iPad Pro line has higher-end sensors that can record video or create other professional content. The 2018 models have two cameras, including one 12-megapixel Wide Camera and a 10-megapixel Ultra Wide Camera.\nApple ditched the Ultra WIde Camera in the 2024 models.\nThe iPad Pro lineup also has a LiDAR sensor, supporting enhanced augmented reality (AR) content. It aids developers in creating content and improves user experiences for mapping spaces for AR.\nIn 2022, iPad Pros gained the ability to shoot video in the ProRes format. Multi-cam shoots with up to four iPhones can be controlled using Final Cut Pro on an iPad Pro.\niPad Services\nApple's tablet wouldn't be what it is today without the help of software and services. The company has slowly built an entire software ecosystem surrounding its ever-popular mobile devices. Through each of these services, paid or not, Apple adds to the base value of every iPad sold.\nSiri on iPad\nSiri is a powerful voice assistant that exists across Apple's product ecosystem. On the iPad, it acts as a user-facing assistant with deep app connections and controls, and it also serves as the background intelligence that powers everyday operations.\nContacts, Calendar, Photos, and even the system keyboard rely on Siri Intelligence to manage information and surface what is most relevant to the user. Siri also acts as the brains behind Shortcuts, which users can activate via the assistant, widgets, or in-app.\nApple does not directly monetize Siri, but it does use the assistant as a primary selling point for its mobile devices and audio gear like HomePod and AirPods.\niMessage on iPad\niMessage is an Apple proprietary technology using end-to-end encryption to send messages via the web. Sending and receiving iMessages is exclusive to Apple products and has been cited as a significant consumer lock-in source.\nWhen communicating via iMessage, a user will see messages as blue bubbles, be able to share complex multi-media files, and use sticker packs and message effects. Apple also enhances iMessage group chats with unique features like message threads and custom group chat images.\nApple Arcade on iPad\nApple Arcade is a monthly subscription service to games across all Apple platforms. A $9.99 monthly subscription provides access to the entire game catalog and any new releases or updates.\nThough most support third-party controllers, the service has games from multiple genres and can be played with touch. Apple's push into gaming has made them embrace controllers like the Playstation DualShock 4 and the Xbox Elite controller.\nApple TV+ on iPad\nApple Studios is a new media branch within Apple that purchases and manages content for the video-streaming service Apple TV+. The subscription costs $4.99 monthly and exists on every Apple platform and several competitor devices.\nThe Apple TV app is needed for viewing Apple TV+ and is available on iPadOS.\nApple News+\nApple News is a news-aggregation app, and the company offers a premium content tier called Apple News+. The monthly subscription is $9.99, giving customers access to premium articles from newspapers and magazines.\nApple Music on iPad\nThe music-streaming service that birthed Apple's push into services debuted in 2015. Apple Music is $9.99 a month and offers student and family plans. The service lives within the Music app on Apple's mobile devices, Mac, and the web.\nUsers can purchase music from iTunes when it is unavailable on the service, which will populate into their Apple Music library. If a user adds a physical CD to their Music app on macOS, the music will also be synced across their account.\niCloud Storage\nThe term \"iCloud\" is a catch-all for Apple's syncing and storage service across devices and apps. The service portion of iCloud is specifically iCloud Storage.\nApple charges the following monthly fees for its storage tiers:\n- 5GB is free\n- 50GB is $0.99\n- 200GB is $2.99\n- 2TB is $9.99\nApple Pay\nApple's tablets support Apple Pay, the company's secure payment service.\nApple Pay on iPad works in apps, in Safari, and with person-to-person and business chats. iPads don't support the NFC portion of Apple Pay used with in-store terminals.\nWhich iPad to buy\nThere is a distinct price ladder for iPad from $349 to $1,299 for base models. Add extra storage and cellular to climb easily to $2,599.\nThe 11-inch iPad is Apple's budget-friendly option. It has many of the features users expect from an iPad without any flashy technology that would increase the price, including Apple Intelligence.\niPad mini serves as Apple's small but mighty next step in iPad usage. It is more capable than the budget option with a better display, but more compact for a very portable and focused tablet experience.\niPad Air is the consumer-focused model with better processors and display technology than the budget option. It comes in 11-inch and 13-inch sizes and supports the Magic Keyboard and Apple Pencil Pro.\niPad Pro is Apple's flagship iPad that pulls out all the stops for display technology and processing power. It supports the Magic Keyboard for iPad Pro, has 120Hz ProMotion, and has a Thunderbolt port for a range of connectivity options."
    },
    {
      "url": "https://appleinsider.com/articles/24/09/12/fda-approves-airpods-pro-2-hearing-aid-features",
      "text": "The U.S. Food and Drug Administration has cleared the AirPods Pro 2 to get the announced clinical-grade hearing aid features in a future software update.\nDuring Apple's \"Glowtime\" special event, a software update for the AirPods Pro 2 was revealed, one which could help millions deal with hearing loss. At the time, the FDA was in the process of approving the software, but by Thursday, it had given it the green light.\nThe FDA's confirmation says the update is its first authorization of an \"over-the-counter hearing aid software device\" in the form of the AirPods Pro update. The feature is intended to amplify sounds for users aged 18 years or older with \"perceived mild to moderate hearing impairment,\" the FDA adds.\n\"Hearing loss is a significant public health issue impacting millions of Americans,\" explains Michelle Tarver, M.D., Ph.D., acting director of the FDA's Center for Devices and Radiological Health. \"Today's marketing authorization of an over-the-counter hearing aid software on a widely used consumer audio product is another step that advances the availability, accessibility and acceptability of hearing support for adults with perceived mild to moderate hearing loss\"\nIt was evaluated in a clinical study with 118 people with mild to moderate hearing loss. The results determined that the AirPods Pro with the update had a similar perceived benefit when self-installed by users as those who had it installed by professionals.\nThere was also a comparable performance for tests measuring amplification levels in the ear canal. Benefits were also seen when measuring how they faired listening to speech within noise.\nThe results mean Apple can roll out the update to the AirPods Pro 2 in the near future to its users. Timetable is as yet unclear, beyond before the end of 2024"
    }
  ],
  "argos_summary": "Apple's AirPods Pro 2 are set to receive a Live Translation feature, as indicated by a newly discovered gesture in the iOS 26 beta. This feature, which has been rumored since March 2025, would allow real-time translation of in-person conversations, enhancing communication between speakers of different languages. Currently, Live Translation is available in calls and Messages on compatible Apple devices, but not yet on AirPods. The feature is expected to be compatible with newer iPhones and iPads that support Apple Intelligence.",
  "argos_id": "LVV9ZLJO7"
}