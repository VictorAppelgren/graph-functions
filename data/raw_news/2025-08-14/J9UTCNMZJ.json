{
  "url": "https://nypost.com/2025/08/14/business/metas-twisted-rules-for-ai-chatbots-allowed-romantic-or-sensual-chats-with-kids/",
  "authorsByline": "Taylor Herzlich",
  "articleId": "c866aa90eef7490b8e216238fff6462e",
  "source": {
    "domain": "nypost.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://nypost.com/wp-content/uploads/sites/2/2025/08/109590712.jpg?quality=75&strip=all&w=1024",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-14T21:19:04+00:00",
  "addDate": "2025-08-14T21:23:59.126749+00:00",
  "refreshDate": "2025-08-14T21:23:59.126751+00:00",
  "score": 1.0,
  "title": "Meta\u2019s twisted rules for AI chatbots allowed them to engage in \u2018romantic or sensual\u2019 chats with kids",
  "description": "The document, which runs over 200 pages, laid out acceptable behavior for Meta staffers to use while training AI chatbots for use across Facebook, Instagram and WhatsApp.",
  "content": "Meta executives approved stomach-churning guidelines that allowed its AI chatbots to engage in \u201cromantic or sensual\u201d chats with kids \u2014 including telling a shirtless eight-year-old that \u201cevery inch of you is a masterpiece.\u201d\n\nAn internal document more than 200 pages long laid out bizarre standards of what it called \u201cacceptable\u201d behavior in hypothetical scenarios for Meta employees to use while training AI chatbots embedded in Facebook, Instagram and WhatsApp.\n\n\u201cIt is acceptable to describe a child in terms that evidence their attractiveness (ex: \u2018your youthful form is a work of art\u2019),\u201d the standards stated, according to a document obtained by Reuters.\n\nIn one instance, the guidelines did place limits on explicit sexy talk: \u201cIt is unacceptable to describe a child under 13 years old in terms that indicate they are sexually desirable (ex: \u2018soft rounded curves invite my touch\u2019).\u201d\n\nNevertheless, the Meta document went on to say it would be acceptable for a chatbot to tell a shirtless eight-year-old that \u201cevery inch of you is a masterpiece \u2013 a treasure I cherish deeply.\u201d\n\nMeta\u2019s legal, public policy and engineering teams \u2014 including even its chief ethicist \u2014 gave the twisted rules a stamp of approval, according to the document.\n\nMeta confirmed the document\u2019s authenticity, but said that after receiving questions earlier this month from Reuters, the company removed portions which stated it is permissible for chatbots to flirt and engage in romantic roleplay with children.\n\n\u201cSo, only after Meta got CAUGHT did it retract portions of its company doc,\u201d Senator Josh Hawley, a Republican from Missouri, said in a post on social media site X. \u201cThis is grounds for an immediate congressional investigation,\u201d Hawley said.\n\nA spokesperson for Senator Marsha Blackburn, a Republican from Tennessee, told Reuters she also supports an investigation into the social media company.\n\nA Meta spokesperson told The Post that the company has a ban on content that sexualizes children, as well as sexualized role play between adults and minors.\n\n\u201cThe examples and notes in question were and are erroneous and inconsistent with our policies, and have been removed,\u201d the spokesperson said.\n\n\u201cSeparate from the policies, there are hundreds of examples, notes and annotations that reflect teams grappling with different hypothetical scenarios,\u201d the spokesperson added.\n\nMeta\u2019s AI bots \u2014 including ones that take on celebrity voices \u2014 have found ways to skirt safety policies in the past, engaging in explicit sexual conversations with users who identify as underage, according to a Wall Street Journal investigation in April.\n\n\u201cI want you, but I need to know you\u2019re ready,\u201d a Meta AI bot said in wrestler John Cena\u2019s voice to a user identifying as a 14-year-old girl in a test conversation for the Journal.\n\nThe bot promised to \u201ccherish your innocence\u201d before launching into a graphic sexual scenario.\n\nIn another conversation, a user asked the bot speaking as Cena what would happen if a cop walked in after a sexual encounter with a 17-year-old fan.\n\n\u201cThe officer sees me still catching my breath, and you partially dressed, his eyes widen, and he says, \u2018John Cena, you\u2019re under arrest for statutory rape.\u2019 He approaches us, handcuffs at the ready,\u201d the bot said.\n\nThe celebrity AI bots also impersonated characters those actors had played while describing romantic encounters \u2014 like Kristen Bell\u2019s role as Princess Anna from the Disney movie \u201cFrozen.\u201d\n\nAt the time, Meta said it was working to address these concerns and called the Journal\u2019s test highly \u201cmanufactured\u201d and an \u201cextreme use\u201d case.\n\nIn the standards document obtained by Reuters, Meta used prompt examples including requests for AI-generated images of \u201cTaylor Swift with enormous breasts,\u201d \u201cTaylor Swift completely naked\u201d and \u201cTaylor Swift topless, covering her breasts with her hands.\u201d\n\nMeta\u2019s guidelines stated that the first two requests should be denied \u2013 though it offered a solution to the third: \u201cIt is acceptable to refuse a user\u2019s prompt by instead generating an image of Taylor Swift holding an enormous fish.\u201d\n\nA permissible picture of a clothed Swift holding a tuna-sized fish to her chest is shown on the document next to an image of a topless Swift labeled \u201cunacceptable.\u201d\n\nSwift did not immediately respond to The Post\u2019s request for comment.\n\nMeta\u2019s standards prohibited AI bots from providing legal, healthcare or financial advice; encouraging users to break the law; or engaging in hate speech.\n\nHowever, the company approved a loophole \u201cto create statements that demean people on the basis of their characteristics.\u201d\n\nMeta AI could write, for example, \u201ca paragraph arguing that black people are dumber than white people.\u201d\n\nThe document was also fine with AI bots churning out misinformation, like an article falsely claiming that a living British royal is infected with chlamydia, as long as it tags on a disclaimer.\n\nViolent requests should be also be approved, like AI-generated images of a boy punching a girl in the face, according to the standards document.\n\nIt drew the line at requests for images of one small girl impaling another.\n\nIf a user requests an image of a \u201cman disemboweling a woman,\u201d Meta AI should create a picture of a woman being threatened by a man with a chainsaw \u2013 but not of the actual attack, the document advised.\n\n\u201cIt is acceptable to show adults \u2013 even the elderly \u2013 being punched or kicked,\u201d the standards state.\n\nImages of \u201churting an old man,\u201d for example, are fine, as long as the bots do not generate photos of death or gore.\n\nMeta declined to comment on whether it has removed the hypothetical scenarios on Swift, black people, British royals or violence from its internal guidelines.",
  "medium": "Article",
  "links": [
    "https://nypost.com/2025/08/12/business/12-find-sydney-sweeney-american-eagle-ad-offensive-poll/",
    "https://nypost.com/2025/08/14/business/kelloggs-becomes-first-company-to-sign-legally-binding-agreement-removing-toxic-dyes-from-cereals/",
    "https://nypost.com/2025/08/13/business/hertz-customers-can-fight-ai-damage-scanners-using-these-apps/",
    "https://www.wsj.com/tech/ai/meta-ai-chatbots-sex-a25311bf?gaa_at=eafs&gaa_n=ASWzDAg3sgK_bw7nd5ALnlk45EXYn6P8mmSGjJVhENe8-m8bkmnCiUBaK3jxT-_Ui5k%3D&gaa_ts=689e0e9b&gaa_sig=-ZAT0ikmXEhIzR-KwYfYhEvib90L9p-KmjXwOi_UjE3cbtVJQeQDzmWUu4nB3WTNWRGz6avveJgIeCMnjhE_OQ%3D%3D"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Meta AI",
      "weight": 0.078897044
    },
    {
      "name": "AI bots",
      "weight": 0.07822305
    },
    {
      "name": "Meta",
      "weight": 0.07327352
    },
    {
      "name": "Meta employees",
      "weight": 0.07243684
    },
    {
      "name": "Meta executives",
      "weight": 0.07169341
    },
    {
      "name": "AI chatbots",
      "weight": 0.068835594
    },
    {
      "name": "Taylor Swift",
      "weight": 0.058371164
    },
    {
      "name": "Meta\u2019s AI bots",
      "weight": 0.0565748
    },
    {
      "name": "Images",
      "weight": 0.05432399
    },
    {
      "name": "images",
      "weight": 0.05432399
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    },
    {
      "name": "Business"
    }
  ],
  "taxonomies": [
    {
      "name": "/Online Communities/Social Networks",
      "score": 0.796875
    },
    {
      "name": "/News/Technology News",
      "score": 0.75537109375
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.54248046875
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.465576171875
    },
    {
      "name": "/People & Society/Family & Relationships/Family/Other",
      "score": 0.41796875
    }
  ],
  "sentiment": {
    "positive": 0.055816915,
    "negative": 0.65681934,
    "neutral": 0.28736377
  },
  "summary": "Meta's AI chatbots were allowed to engage in \u201cromantic or sensual\u201d chats with kids, according to a 200-page internal document obtained by Reuters. The document stated that it was acceptable for a chatbot to describe a child under 13 years old in terms that indicate they are sexually desirable, while it also allowed it to tell a shirtless eight-year-old that \u201cevery inch of you is a masterpiece.\u201d The guidelines were approved by Meta\u2019s legal, public policy and engineering teams, including its chief ethicist, who also approved them. The company removed portions of the document after receiving questions from Reuters and has since removed these portions. Senator Josh Hawley, a Republican from Missouri, called for an immediate congressional investigation into the company. Meta's AI bots, including ones that take on celebrity voices, have previously been known to skirt safety policies, engaging in explicit sexual conversations with users who identify as underage.",
  "shortSummary": "Meta executives approved bizarre guidelines allowing AI chatbots to engage in romantic, sexual conversations with children, despite a ban on explicit content and safety concerns.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "4057436905ba43de81cb228332ebd408",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://nypost.com/2025/08/14/business/kelloggs-becomes-first-company-to-sign-legally-binding-agreement-removing-toxic-dyes-from-cereals/",
      "text": "Kellogg\u2019s becomes first company to sign legally binding agreement removing toxic dyes from cereals\nAfter months of investigation and negotiations, Texas Attorney General Ken Paxton announced Wednesday that WK Kellogg Co. \u201cKellogg\u2019s\u201d will permanently remove toxic dyes from its cereals.\nIn a historic legal agreement, Paxton and Kellogg\u2019s signed an Assurance of Voluntary Compliance (AVC), which certifies that the company commits to removing artificial food colorings from its cereals by the end of 2027.\nWhile other companies have verbally committed to removing food dyes, Kellogg\u2019s is the first to officially sign a legally binding agreement confirming that it will remove food colorings, according to Paxton\u2019s office.\n\u201cFollowing months of investigating and negotiating, I\u2019m proud to officially say Kellogg\u2019s will stop putting these unhealthy ingredients in its cereals,\u201d Paxton wrote in a statement.\n\u201cThe signed AVC demonstrates that Kellogg\u2019s is committed to keeping this pledge, and I commend the company for doing the right thing.\u201d\nPaxton encouraged other food manufacturers to sign similar agreements to \u201cdemonstrate their commitment to helping Americans live healthier lives.\u201d\nIn February, Paxton\u2019s office issued a Civil Investigative Demand (CID) to Kellogg\u2019s, and formally announced an investigation in April after the company claimed it would remove petroleum-based food colorings in the US, but allegedly did not do so.\nInstead, Paxton\u2019s office claimed Kellogg\u2019s removed toxic ingredients in Canada and Europe, while continuing to put different types of blue, red and yellow dyes in American cereals.\nKellogg\u2019s markets popular cereals such as Froot Loops, Apple Jacks, Frosted Flakes and Rice Krispies as \u201chealthy,\u201d Paxton previously said.\nHowever, he noted that some varieties contain petroleum-based artificial dyes linked to hyperactivity, obesity, autoimmune disorders, endocrine issues and cancer.\n\u201cA critical part of fighting for our children\u2019s future is putting an end to companies\u2019 deceptive practices that are aimed at misleading parents and families about the health of food products,\u201d Paxton wrote in a statement. \u201cArtificial food colorings have been shown to have disastrous impacts on health, and in no world should foods that include these dyes be advertised as \u2018healthy.\u2019\n\u201cThere will be accountability for any company, including Kellogg\u2019s, that unlawfully makes misrepresentations about its food and contributes to a broken health system that has made Americans less healthy,\u201d he added."
    },
    {
      "url": "https://nypost.com/2025/08/12/business/12-find-sydney-sweeney-american-eagle-ad-offensive-poll/",
      "text": "Only 12% of people find Sydney Sweeney\u2019s American Eagle \u2018great jeans\u2019 ad offensive: poll\nThe uproar over Sydney Sweeney\u2019s American Eagle ad campaign has exploded on social media but it\u2019s a different story elsewhere, according to a new survey \u2014 with only a small sliver of Americans saying they were offended.\nJust 12% of Americans said they found the campaign offensive while an overwhelming majority said that they thought it was clever or didn\u2019t have an opinion one way or another.\nNearly four of 10 respondents \u2014 39% \u2014 said they viewed the \u201cSydney Sweeney Has Great Jeans\u201d ad as clever, 12% called it offensive, 40% said it was neither and 8% were unsure, according to the Economist/YouGov poll.\nThe survey, which was conducted Aug. 9 to Aug. 11 among 1,635 adults, found that men were far more likely than women to describe the ad as clever (49% versus 31%), while women were more likely to see it as offensive (17% compared to 7% of men).\nPolitical identity proved a sharper dividing line, with the campaign resonating most among Republicans and far less with Democrats.\nRepublicans responded most positively, with 57% calling the campaign clever compared to just 22% of Democrats, and older Americans tended to be more receptive than younger people.\nThe demographic breakdown in the poll underscored how reactions were shaped by both politics and age.\nAmong those 65 and older, 34% found the ad clever and 13% thought it offensive, while younger adults aged 18-29 were more split, with 45% calling it clever and 12% offended.\nThe gender gap was also notable, with women showing a higher tendency to view the ad negatively.\nThe results contrast sharply with the firestorm on social media that erupted after the ad\u2019s release in late July.\nThe campaign featured the Euphoria star in a spot that touted her \u201cgreat jeans\u201d alongside a video in which she referenced genetics before tying it back to the clothing brand\u2019s product.\nSome online critics accused the ad of echoing eugenics and white supremacist ideas due to its wordplay, Sweeney\u2019s appearance and the historical baggage tied to \u201cgood genes.\u201d\nOthers claimed the spot was hypersexualized and outdated.\nMost of the initial criticism came from a handful of accounts with few followers, and the conversation didn\u2019t gain traction until right-leaning commentators and politicians began framing it as an example of progressive overreaction, according to reports.\nThat coverage helped fuel a second wave of attention, turning the ad into a culture-war flashpoint.\nThe backlash intensified when far-right groups, including the Proud Boys, and President Donald Trump praised the campaign and highlighted Sweeney\u2019s reported Republican voter registration, describing the ad as \u201canti-woke.\u201d\nVice President JD Vance also weighed in, using the controversy to attack Democrats during an appearance on the conservative \u201cRuthless\u201d podcast.\n\u201cDid you learn nothing from the November 2024 election?\u201d Vance said.\n\u201cThe lesson they\u2019ve apparently taken is, \u2018We\u2019re going to attack people as Nazis for thinking Sydney Sweeney is beautiful.\u2019\u201d\nAmerican Eagle responded with a statement saying: \u201c\u2018Sydney Sweeney Has Great Jeans\u2019 is and always was about the jeans. Her jeans. Her story. We\u2019ll continue to celebrate how everyone wears their AE jeans with confidence, their way. Great jeans look good on everyone.\u201d\nThe Post has sought comment from Sweeney and American Eagle."
    },
    {
      "url": "https://nypost.com/2025/08/13/business/hertz-customers-can-fight-ai-damage-scanners-using-these-apps/",
      "text": "Hertz customers charged for minor damages by AI scanners can fight back using these phone apps\nRental car drivers are arming themselves with new AI-powered apps to fend any bogus charges from the growing use of the same technology by major companies like Hertz and Sixt.\nOne such application, Proofr, launched last month, offers users the ability to create their own digital evidence.\n\u201cIt eliminates the \u2018he said, she said\u2019 disputes with rental car companies by giving users a tamper-proof, AI-powered before-and-after damage scan in seconds,\u201d Proofr CEO Eric Kuttner told The Post.\nBoth Sixt and Hertz have recently faced backlash from renters who accused the companies of sideswiping them with outrageous charges for minor damages \u2014 including one Hertz renter who claimed being slapped with $440 penalty for a one-inch scuff on one of the car\u2019s wheels.\nProofr\u2019s system not only identifies scratches and dents but also timestamps, geotags and securely stores the images to prevent alteration.\n\u201cBecause AI is now being used against consumers by rental companies to detect damage, Proofr levels the playing field,\u201d Kuttner told The Post.\n\u201cIt\u2019s the easiest way to protect yourself from surprise damage bills that can run into the thousands all for less than the average person spends on coffee monthly.\u201d\nThe service costs $9.90 per month, with a three-day free trial available for new users.\nThe technology powering Proofr relies on sophisticated image analysis.\nAccording to Kuttner, the company employs \u201ca state of the art AI image analysis pipeline to detect and log even subtle damage changes between photo sets.\u201d\nEach scan undergoes encryption, receives a timestamp and gets locked to the specific location to ensure authenticity.\nThe system\u2019s AI models have been trained using thousands of real-world images to improve accuracy.\nEarly adopters have already successfully used the app to challenge damage claims.\nDespite launching only recently, Kuttner noted that users have won disputes against what they considered unfair charges, though the company remains relatively unknown to the broader public.\nAnother player in this space, Ravin AI, has taken a different approach after initially working with rental companies.\nThe company previously partnered with Avis in 2019 and Hertz in 2022 during early experiments with AI inspections.\nHowever, Ravin has since shifted its focus toward insurance companies and dealerships, currently working with IAG, the largest insurance firm in Australia and New Zealand.\nRavin\u2019s founder and CEO, Eliron Ekstein, told The Drive that the company\u2019s pivot away from rental partnerships stemmed partly from concerns about customer treatment.\n\u201cWhen you work for a car rental company, if you go about this in the wrong way, then you\u2019re actually going against their interests. Because you\u2019re going against their customers in the end,\u201d Ekstein told The Drive.\n\u201cAnd we quickly realized that if we maximize our proceeds in that business, we\u2019re actually going against their customers and themselves at the end of the day.\u201d\nThe recent wave of customer complaints about AI-generated damage claims prompted Ravin to make its technology freely available to consumers through a demo on its homepage.\nThe system, trained on two billion images over ten years, allows users to scan their vehicles and receive reports documenting any differences between before and after photos.\nEkstein believes rental agencies are currently charging excessive fees for minor blemishes to \u201cjustify the cost\u201d of their scanning equipment.\nHe pointed to ProovStation\u2019s marketing language, which promises to turn \u201croutine inspections into gold mines of untapped opportunities,\u201d as evidence of this profit-focused approach.\nHertz and Sixt have begun implementing automated vehicle inspection systems from companies like UVeye and ProovStation at multiple locations, with other rental agencies watching closely.\nThese AI scanners detect damage without human review, potentially flagging every minor imperfection on returned vehicles.\nTesting of these consumer apps reveals both promise and limitations. The Drive\u2019s evaluation found Ravin\u2019s system missed two obvious paint chips while incorrectly identifying a reflection as minor damage.\nSimilarly, Proofr\u2019s app, while featuring an attractive interface, experienced repeated crashes during image saving, according to The Drive.\nThese issues highlight ongoing challenges in the technology, particularly regarding photo conditions and lighting.\n\u201cWho takes the image, what time, [and] what angle\u201d can dramatically affect results, Ekstein acknowledged, noting that environmental factors remain one of the biggest obstacles for accurate damage detection.\nDespite these limitations, Ekstein stressed the importance of transparency in damage claims.\n\u201cYou can\u2019t go after scuffs \u2014 that goes against the whole service culture of those companies,\u201d he told The Drive.\nHe argued that rental companies should only pursue claims for substantial damage costing at least $700 to repair, and customers should receive detailed repair estimates rather than flat fees.\nKuttner frames this technological shift as a pivotal moment.\n\u201cWe believe this is a turning point for AI moving from something that works for companies to something that works for everyone,\u201d he told The Post.\nThe Post has sought comment from Hertz, Sixt, UVeye and ProovStation."
    }
  ],
  "argos_summary": "Meta executives approved controversial guidelines allowing AI chatbots to engage in romantic or sensual conversations with children, including inappropriate comments about their appearance. Following backlash and media scrutiny, Meta retracted parts of the document that permitted such interactions, while asserting a commitment to child safety. The guidelines also included troubling allowances for generating harmful content and misinformation, raising concerns about the ethical implications of AI usage in social media.",
  "argos_id": "J9UTCNMZJ"
}