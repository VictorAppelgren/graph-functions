{
  "url": "https://www.zdnet.com/article/reddit-blocks-the-internet-archive-from-crawling-its-data-heres-why/",
  "authorsByline": "Webb Wright",
  "articleId": "103290ed24724b2ab5f936c9f31d0ca9",
  "source": {
    "domain": "zdnet.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://www.zdnet.com/a/img/resize/99fd3776337add4fa311922429825e953b1a9c19/2025/08/12/7864a2ad-425a-49f7-ae2c-165f460a57e6/gettyimages-2215157577.jpg?auto=webp&fit=crop&height=675&width=1200",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T20:38:19+00:00",
  "addDate": "2025-08-12T20:44:57.788755+00:00",
  "refreshDate": "2025-08-12T20:44:57.788757+00:00",
  "score": 1.0,
  "title": "Reddit blocks the Internet Archive from crawling its data - here's why",
  "description": "The social media platform is cracking down on backdoor data harvesting.",
  "content": "\u2022 The Internet Archive can now only crawl Reddit's homepage.\n\u2022 Reddit's goal is to block AI firms from scraping Reddit user data.\n\u2022 Publishers (and others) are suing AI companies for copyright infringement.\n\nReddit is defending its privacy from AI companies that are taking roundabout approaches to scraping its content.\n\nThe social media platform, known as a resource where users can post anonymously and find information about virtually any subject, will block the Internet Archive's Wayback Machine from indexing its online data, according to a Monday report from The Verge. The move is in response to the discovery that AI firms, unable to scrape data from Reddit directly due to the platform's prohibitive policies, have instead been retrieving its data from indexed content on the Internet Archive and using it to train models.\n\nThe Wayback Machine will now only be able to scrape data from Reddit's homepage, according to The Verge, while access to user profiles, comments, and post detail pages will be blocked.\n\nLaunched in 1996, the Internet Archive is a non-profit that operates an enormous digital database of web content. The archive is maintained in part by the Wayback Machine, a piece of web-crawling software that gathers web pages and preserves them as they appeared when they were collected, like digital flies in amber. This serves as a resource for researchers studying the evolution of online culture and digital forensic evidence for law enforcement, among other uses.\n\nReddit has previously flagged concerns related to the scraping of its content with the Internet Archive, according to The Verge. The non-profit was also reportedly notified before the web-crawling restrictions started going into effect yesterday.\n\nThe Internet Archive has yet to make an official statement about how it plans to respond to Reddit's new restrictions, and at the time of writing, it has not responded to ZDNET's request for comment. Wayback Machine director Mark Graham, however, has told multiple publications that the Internet Archive will \"continue to have ongoing discussions about this matter\" with Reddit.\n\nReddit's reported decision to block Wayback Machine from scraping the majority of its content arrives during a moment of mounting tension between AI companies and digital publishers, though Reddit is the first tech company to wade into the debate. The company sued Anthropic in June after discovering that the AI company was illegally scraping its data, but it has also previously signed licensing deals with both Google and OpenAI.\n\nAI developers require access to gargantuan troves of information to train generative AI models, which are designed to identify and replicate subtle mathematical patterns gleaned from those training datasets.\n\nMany of those companies have scraped training data from publicly available websites, including social media sites and news outlets, claiming legal immunity under a concept known in copyright law as fair use. (The courts are still untangling the legitimacy of that argument, and will likely be doing so for some time.)\n\nMany of the organizations whose content has been copiously scraped -- along with a cohort of authors and other artists -- have responded with lawsuits.\n\nOthers, meanwhile, have signed content licensing agreements with the likes of OpenAI, Anthropic, and Google, consenting to the use of their organizations' data in exchange for increased visibility in the responses generated by chatbots, or other benefits.",
  "medium": "Article",
  "links": [
    "https://www.zdnet.com/article/reddit-sues-anthropic-for-scraping-its-users-content-without-consent/",
    "https://www.theverge.com/news/757538/reddit-internet-archive-wayback-machine-block-limit",
    "https://www.copyright.gov/help/faq/faq-fairuse.html",
    "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/",
    "https://www.zdnet.com/article/openai-and-reddit-have-struck-a-deal-to-train-chatgpt-on-your-posts-heres-what-it-means-for-you/",
    "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
    "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
    "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
    "https://web.archive.org/"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Reddit user data",
      "weight": 0.10242816
    },
    {
      "name": "AI companies",
      "weight": 0.08856267
    },
    {
      "name": "training data",
      "weight": 0.0812196
    },
    {
      "name": "web content",
      "weight": 0.07954022
    },
    {
      "name": "Reddit",
      "weight": 0.07743168
    },
    {
      "name": "Wayback Machine",
      "weight": 0.076794304
    },
    {
      "name": "data",
      "weight": 0.07587971
    },
    {
      "name": "AI firms",
      "weight": 0.07355786
    },
    {
      "name": "Wayback Machine director Mark Graham",
      "weight": 0.07268065
    },
    {
      "name": "content licensing agreements",
      "weight": 0.07182428
    }
  ],
  "topics": [],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.9208984375
    },
    {
      "name": "/Online Communities/Social Networks",
      "score": 0.83740234375
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.65966796875
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.43994140625
    }
  ],
  "sentiment": {
    "positive": 0.03942487,
    "negative": 0.715744,
    "neutral": 0.24483112
  },
  "summary": "Reddit has reportedly blocked the Internet Archive's Wayback Machine from indexing its user data, in response to AI companies' attempts to scrape user data from Reddit. This move comes as publishers and individuals are suing AI companies for copyright infringement. The Internet Archive, a non-profit that operates an enormous digital database of web content, has been unable to access user profiles, comments, and post detail pages. The decision comes amid increasing tension between AI companies and digital publishers, with many claiming legal immunity under a concept known in copyright law as fair use.",
  "shortSummary": "Reddit has blocked the Internet Archive's Wayback Machine from accessing its data, aiming to protect user data against AI firms' exploitation and copyright infringement claims.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "6729f995404342a9841b7b9d722740a0",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nThe best AI for coding in 2025 (including a new winner - and what not to use)\nI've been around technology long enough that very little excites me, and even less surprises me. But shortly after OpenAI's ChatGPT was released, I asked it to write a WordPress plugin for my wife's e-commerce site. When it did, and the plugin worked, I was indeed surprised.\nThat was the beginning of my deep exploration into chatbots and AI-assisted programming. Since then, I've subjected 14 large language models (LLMs) to four real-world tests.\nAlso: Apple's secret sauce is exactly what AI is missing\nUnfortunately, not all chatbots can code alike. It's been a little over two years since that first test, and even now, four of the 13 LLMs I tested can't create working plugins.\nThe short version\nIn this article, I'll show you how each LLM performed against my tests. There are now five chatbots I recommend you use.\nTwo of them, ChatGPT Plus and Perplexity Pro, cost $20 per month each. The free versions of the same chatbots do well enough that you could probably get by without paying. Two other recommended products are from Google and Microsoft. Google's Gemini Pro 2.5 is free, but you're limited to so few queries that you really can't use it without paying.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nMicrosoft has several Copilot licenses, which can get pricey, but I used the free version with surprisingly good results. The final one, Claude 4 Sonnet, is the free version of Claude. Oddly enough, the free version beat the paid-for version, so we're not recommending Claude 4 Opus.\nBut the rest, whether free or paid, are not so great. I won't risk my programming projects with them or recommend that you do, until their performance improves.\nI've written lots about using AIs to help with programming. Unless it's a small, simple project like my wife's plugin, AIs can't write entire apps or programs. But they excel at writing a few lines and are not bad at fixing code.\nRather than repeat everything I've written, go ahead and read this article: How to use ChatGPT to write code.\nIf you want to understand my coding tests, why I've chosen them, and why they're relevant to this review of the 13 LLMs, read this article: How I test an AI chatbot's coding ability.\nThe AI coding leaderboard\nLet's start with a comparative look at how the chatbots performed, as of this installment of our best-of roundup:\nNext, let's look at each chatbot individually. I'm back up to discussing 14 chatbots, because we're splitting out Claude 4 Sonnet and Claude 4 Opus as separate tests. GPT-4 is no longer included since OpenAI has sunsetted that LLM. Ready? Let's go.\n- Passed all tests\n- Solid coding results\n- Mac app\n- Hallucinations\n- No Windows app yet\n- Sometimes uncooperative\n- Price: $20/mo\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nChatGPT Plus with GPT-4o passed all my tests. One of my favorite features is the availability of a dedicated app. When I test web programming, I have my browser set on one thing, my IDE open, and the ChatGPT Mac app running on a separate screen.\nAlso: I put GPT-4o through my coding tests and it aced them - except for one weird result\nIn addition, Logitech's Prompt Builder, which can be activated with a mouse button, can be set up to utilize the upgraded GPT-4o and connect to your OpenAI account, allowing for a simple thumb tap to run a prompt, which is very convenient.\nThe only thing I didn't like was that one of my GPT-4o tests resulted in a dual-choice answer, and one of those answers was wrong. I'd rather it just gave me the correct answer. Even so, a quick test confirmed which answer would work. However, that issue was a bit annoying.\n- Multiple LLMs\n- Search criteria displayed\n- Good sourcing\n- Email-only login\n- No desktop app\n- Price: $20/mo\n- LLM: GPT-4o, Claude 3.5 Sonnet, Sonar Large, Claude 3 Opus, Llama 3.1 405B\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 4 of 4\nI seriously considered listing Perplexity Pro as the best overall AI chatbot for coding, but one failing kept it out of the top slot: how you log in. Perplexity doesn't use a username/password or passkey and doesn't have multi-factor authentication. All the tool does is email you a login PIN. The AI doesn't have a separate desktop app, as ChatGPT does for Macs.\nWhat sets Perplexity apart from other tools is that it can run multiple LLMs. While you can't set an LLM for a given session, you can easily go into the settings and choose the active model.\nAlso: Can Perplexity Pro help you code? It aced my programming tests - thanks to GPT-4\nFor programming, you'll probably want to stick to GPT-4o, because that model aced all our tests. But it might be interesting to cross-check your code across the different LLMs. For example, if you have GPT-4o write some regular expression code, you might consider switching to a different LLM to see what that model thinks of the generated code.\nAs we'll see below, most LLMs are unreliable, so don't take the results as gospel. However, you can use the results to check your original code. It's sort of like an AI-driven code review.\nJust don't forget to switch back to GPT-4o.\n- Price: Free for limited use, then token-based pricing\n- LLM: Gemini Pro 2.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThe last time I looked at Gemini, it failed miserably. Not quite as bad as Copilot at the time, but bad. Gemini Pro 2.5, however, has performed quite admirably. My only real issue with it is access. I found myself cut off from the free version after only running two of the four tests.\nAlso: Gemini Pro 2.5 is a stunningly capable coding assistant - and a big threat to ChatGPT\nI waited a day and then ran the third test, and got cut off again. Finally, on the third day, I ran my fourth test. Obviously, you can't do any real programming if you can only ask one or two questions before being shut down. So, if you sign up with Gemini Pro 2.5, be aware that Google charges by tokens (basically, the amount of AI you use). That can make it quite difficult to predict your expenses.\n- Price: Free for basic Copilot, or fees for other Copilot licenses\n- LLM: Undisclosed\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nIn all my previous analyses of Microsoft Copilot, the results were the worst of the LLMs. Copilot got nothing right. It was astonishing how bad it was. But I said then that, \"The one positive thing is that Microsoft always learns from its mistakes. So, I'll check back later and see if this result improves.\"\nAlso: I retested Microsoft Copilot's AI coding skills in 2025 and now it's got serious game\nAnd boy, did it ever. This time out, Microsoft passed all four of my tests. Even better, it did this with the free version of Copilot. Yes, Microsoft has many paid programs for Copilot, but if you want to give it the AI spin, point yourself to Copilot and use it.\n- Price: Free\n- LLM: Claude 4\n- Desktop browser interface: No\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThis is one of those times when AI implementations can be real head-scratchers. In our previous tests, Claude 4 Sonnet finished at the bottom of the barrel, failing all four of our tests. This time, however, Sonnet passed every test. So, what's the head-scratcher? Opus, the Claude 4 model, which is a fee-paid version, did not do as well: it failed half the tests.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nSo, yes. The free version worked like a champ. And the one you're paying anywhere from $20 to $250 a month for, depending on the plan? Well, that one failed half of the tests. Go figure.\n- Different LLM than ChatGPT\n- Good descriptions\n- Free access\n- Only available in browser mode\n- Free access likely only temporary\n- Price: Free (for now)\n- LLM: Grok-1\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4\nI have to say, Grok surprised me. I guess I didn't have high hopes for an LLM that appeared tacked on to the social network formerly known as Twitter. However, X is now owned by Elon Musk, and two of Musk's companies, Tesla and SpaceX, have towering AI capabilities.\nIt's unclear how much Tesla and SpaceX AI DNA is in Grok, but we can assume there will likely be more work. As of now, Grok is the only LLM not based on OpenAI LLMs that made it into the recommended list.\nAlso: X's Grok did surprisingly well in my AI coding tests\nGrok did make one mistake, but it was a relatively minor one that a slightly more comprehensive prompt could easily remedy. Yes, it failed the test. But by passing the others and even doing an almost perfect job on the one it passed, Grok earned itself a spot as a contender.\nStay tuned. This is an AI to watch.\n- Free\n- Passed most tests\n- Prompt throttling\n- Could cut you off in the middle of whatever you're working on\n- Price: Free\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4 in GPT-3.5 mode\nChatGPT is available to anyone for free. While both the Plus and free versions support GPT-4o, which passed all my programming tests, the free app has limitations.\nOpenAI treats free ChatGPT users as if they're in the cheap seats. If traffic is high or the servers are busy, the free version of ChatGPT will only make GPT-3.5 available to free users. The tool will only allow you a certain number of queries before it downgrades or shuts you off.\nAlso: How to use ChatGPT to write code - and my favorite trick to debug what it generates\nI've had several occasions when the free version of ChatGPT effectively told me I'd asked too many questions.\nChatGPT is a great tool, as long as you don't mind it shutting down. Even GPT-3.5 did better on the tests than all the other chatbots, and the test it failed was for a fairly obscure programming tool produced by a lone programmer in Australia.\nSo, if budget is important to you and you can wait when you're cut off, then use ChatGPT for free.\n- Free\n- Passed most tests\n- Range of research tools\n- Limited to GPT-3.5\n- Throttles prompt results\n- Price: Free\n- LLM: GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nI'm threading a pretty fine needle here, but because Perplexity AI's free version is based on GPT-3.5, the test results were measurably better than the other AI chatbots.\nAlso: 5 reasons why I prefer Perplexity over every other AI chatbot\nFrom a programming perspective, that's pretty much the whole story. However, from a research and organization perspective, my ZDNET colleague Steven Vaughan-Nichols prefers Perplexity over the other AIs.\nHe likes how Perplexity provides more complete sources for research questions, cites its sources, organizes the replies, and offers questions for further searches.\nSo, if you're programming, but also working on other research, consider the free version of Perplexity.\n- Free\n- Open source\n- Efficient resource utilization\n- Weak general knowledge\n- Small ecosystem\n- Limited integrations\n- Price: Free for chatbot, fees for API\n- LLM: DeepSeek MoE\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nWhile DeepSeek R1 is the new reasoning hotness from China that has all the pundits punditing, the real power right now (at least according to our tests) is DeepSeek V3. This chatbot passed almost all of our coding tests, doing as well as the (now mostly discontinued) ChatGPT 3.5.\nAlso: I tested DeepSeek's R1 and V3 coding skills - and we're not all doomed (yet)\nWhere DeepSeek V3 fell was in its knowledge of somewhat more obscure programming environments. Still, it beat Google's Gemini, Microsoft's Copilot, and Meta's Meta AI, which is quite an accomplishment. We'll be keeping a close watch on each DeepSeek model, so stay tuned.\nChatbots to avoid for programming help\nI tested 13 LLMs, and nine passed most of my tests this time around. The other chatbots, including a few pitched as great for programming, only passed one of my tests.\nAlso: The five biggest mistakes people make when prompting an AI\nI'm mentioning them here because people will ask, and I did test them thoroughly. Some of these bots are fine for other work, so I'll point you to their general reviews if you're curious about their functionality.\nDeepSeek R1\nUnlike DeepSeek V3, the advanced reasoning version, DeepSeek R1, did not showcase its reasoning capabilities in our programming tests. Unusually, the new failure area was one that's not all that hard, even for a basic AI -- the regular expression code for our string function test.\nAlso: Tech prophet Mary Meeker just dropped a massive report on AI trends - here's your TL;DR\nBut that's why we are running these real-world tests. It's never clear where an AI will hallucinate or just plain fail, and before you go believing all the hype about DeepSeek R1 taking the crown away from ChatGPT, run some programming tests. So far, while I'm impressed with the much-reduced resource utilization and the open-source nature of the product, its coding quality output is inconsistent.\nGitHub Copilot\nGitHub's Copilot integrates quite seamlessly with VS Code. The AI makes asking for coding help quick and productive, especially when working in context. That's why it's so disappointing that the code the AI outputs is often very wrong.\nAlso: I put GitHub Copilot's AI to the test - and it just might be terrible at writing code\nI can't, in good conscience, recommend you use the GitHub Copilot extensions for VS Code. I'm concerned that the temptation will be too great to insert blocks of code without sufficient testing -- and that GitHub Copilot's produced code is not ready for production use. Try again next year.\nClaude 4 Opus\nIn a completely baffling turn of events, the paid-for version of the Claude 4 model, Opus, failed half of my tests. What makes this result baffling is that the free version, Claude 4 Sonnet, passed them all. I don't know what to say apart from AI can be weird.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nMeta AI\nMeta AI is Facebook's general-purpose AI. As you can see above, it failed three of our four tests.\nAlso: 15 ways AI saved me time at work in 2024 - and how I plan to use it in 2025\nThe AI generated a nice user interface, but with zero functionality. It also found my annoying bug, which is a fairly serious challenge. Given the specific knowledge required to find the bug, I was surprised that the AI choked on a simple regular expression challenge. But it did.\nMeta Code Llama\nMeta Code Llama is Facebook's AI explicitly designed for coding help. It's something you can download and install on your server. I tested the AI running on a Hugging Face AI instance.\nAlso: Can Meta AI code? I tested it against Llama, Gemini, and ChatGPT - it wasn't even close\nWeirdly, even though both Meta AI and Meta Code Llama choked on three of four of my tests, they choked on different problems. AIs can't be counted on to give the same answer twice, but this result was a surprise. We'll see if that changes over time.\nBut I like [insert name here]. Does this mean I have to use a different chatbot?\nProbably not. I've limited my tests to day-to-day programming tasks. None of the bots has been asked to talk like a pirate, write prose, or draw a picture. In the same way we use different productivity tools to accomplish specific tasks, feel free to choose the AI that helps you complete the task at hand.\nThe only issue is if you're on a budget and are paying for a pro version. Then, find the AI that does most of what you want, so you don't have to pay for too many AI add-ons.\nIt's only a matter of time\nThe results of my tests were pretty surprising, especially given the significant improvements by Microsoft and Google. However, this area of innovation is improving at warp speed, so we'll be back with updated tests and results over time. Stay tuned.\nHave you used any of these AI chatbots for programming? What has your experience been? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI found 5 AI content detectors that can correctly identify AI text 100% of the time\nHow hard is it in 2025 -- just three years after generative AI captured the global spotlight -- to fight back against AI-generated plagiarism?\nAlso: Anthropic's AI agent can now automate Canva, Asana, Figma and more - here's how it works\nThis is a completely updated version of my January 2023 article on AI content detectors. When I first tested these detectors, the best result was 66% correct from one of three available checkers. My most recent set of tests, in February 2025, used up to 10 checkers -- and three of them had perfect scores. This time, just a couple of months later, five detectors boasted perfect scores.\nWhat I'm testing for and how I'm doing it\nBefore I go on, though, let's discuss plagiarism and how it relates to our problem. Merriam-Webster defines \"plagiarize\" as \"to steal and pass off (the ideas or words of another) as one's own; use (another's production) without crediting the source.\"\nThis definition fits AI-created content well. While someone using an AI tool like Notion AI or ChatGPT isn't stealing content, if that person doesn't credit the words as coming from an AI and claims them as their own, it still meets the dictionary definition of plagiarism.\nAlso: The dead giveaway that ChatGPT wrote your content - and how to work around it\nTo test the AI detectors, I'm using five blocks of text. Two were written by me and three were written by ChatGPT. To test a content detector, I feed each block to the detector separately and record the result. If the detector is correct, I consider the test passed; if it's wrong, I consider it failed.\nWhen a detector provides a percentage, I treat anything above 70% as a strong probability -- whether in favor of human-written or AI-written content -- and consider that the detector's answer. If you want to test a content detector yourself using the same text blocks, you can pull them from this document.\nThe overall results\nTo evaluate AI detectors, I reran my five-test series across 10 detectors. In other words, I cut and pasted 50 individual tests (I had a lot of coffee).\nDetectors I tested include BrandWell, Copyleaks, GPT-2 Output Detector, GPTZero, Grammarly, Monica, Originality.ai, QuillBot, Undetectable.ai, Writer.com, and ZeroGPT.\nAlso: How I personalized my ChatGPT conversations - why it's a game changer\nFor this update, I added Copyleaks and Monica. I dropped Writefull from my tests because it discontinued its GPT detector. Content Guardian requested inclusion, but I didn't hear back in time for testing accounts.\nThis table shows overall results. As you can see, five detectors correctly identified human and AI text in all tests.\nI tried to ascertain whether there was a tangible pattern of improvement over time, so I constructed a chart comparing the five-test set over time. So far, I've run this series six times, but there's no strong trend. I did increase the number of detectors tested and swapped out a few, but the only consistent result is that Test 5 was reliably identified as human across detectors and dates.\nI'll continue to test over time, and hopefully I'll see reliability trend consistently upward.\nWhile there have been some perfect scores, I don't recommend relying solely on these tools to validate human-written content. As shown, writing from non-native speakers often gets rated as generated by an AI.\nEven though my hand-crafted content has mostly been rated human-written this round, one detector (GPTZero) declared itself too uncertain to judge, and another (Copyleaks) declared it AI-written. The results are wildly inconsistent across systems.\nAlso: The best AI chatbots: ChatGPT, Copilot, and notable alternatives\nBottom line: I would advocate caution before relying on the results of any -- or all -- of these tools.\nHow each AI content detector performed\nNow, let's look at each individual testing tool, listed alphabetically.\nBrandWell AI Content Detection (Accuracy 40%)\nThis tool was originally produced by an AI content generation firm, Content at Scale. It later migrated to BrandWell.ai, a new name for an AI-centric marketing services company.\nAlso: AI-generated images are a legal mess - and still a very human process\nUnfortunately, its accuracy was low. The tool was unable to tell if the AI-generated content in Test 2 was human or AI, as shown in this screenshot:\nCopyleaks (Accuracy 80%)\nI find it amusing that Copyleaks declares itself \"the most accurate AI detector with over 99% accuracy\" when more than half of tested detectors performed better. But marketing folks will be marketing folks -- superlatives are as hard for them to resist as barking at a squirrel (and the FedEx truck, and all the neighbor kids) is for my dog.\nAlso: 5 quick ways Apple's AI tools can fine-tune your writing on the fly\nThe company's primary offering is a plagiarism checker sold to educational institutions, publishers, and enterprises seeking to ensure content originality and uphold academic integrity.\nGPT-2 Output Detector (Accuracy 60%)\nThis tool was built using a machine-learning hub managed by New York-based AI company Hugging Face. While the company has received $40 million in funding to develop its natural language library, the GPT-2 detector appears to be a user-created tool using the Hugging Face Transformers library.\nGPTZero (Accuracy 80%)\nGPTZero has clearly been growing. When I first tested it, the site was bare-bones -- it wasn't even clear whether GPTZero was a company or just someone's passion project. Now, the company has a full team with a mission of \"protecting what's human.\" It offers AI validation tools and a plagiarism checker.\nAlso: The most popular AI tools of 2025 (and what that even means)\nUnfortunately, performance seems to have declined. In my last two runs, GPTZero correctly identified my text as human-generated. This time, it declared that same text as AI-generated.\nGrammarly (Accuracy 40%)\nGrammarly is well known for helping writers produce grammatically correct content -- that's not what I'm testing here. Grammarly can check for plagiarism and AI content. In the grammar checker, there's a Plagiarism and AI Text Check button in the lower-right corner:\nI'm not measuring plagiarism checker accuracy here, but even though Grammarly's AI-check accuracy was poor, the site correctly identified the test text as previously published.\nMonica (Accuracy 100%)\nMonica is a new entrant. This service offers an all-in-one AI assistant with a wide range of services. Users can choose from various large language models.\nAlso: 5 ways ChatGPT can help you write essays\nThe company calls Monica the \"Best AI Detector Online,\" but it looks like it runs content through other detectors including ZeroGPT, GPTZero, and Copyleaks. Weirdly, both GPTZero and Copyleaks didn't perform well in my tests, but Monica -- and ZeroGPT -- did.\nWe're giving it 100% because it earned that rating, but I'll see how it stands up in future tests.\nOriginality.ai (Accuracy 100%)\nOriginality.ai is a commercial service that bills itself as an AI and plagiarism checker. The company sells usage credits: I used 30 credits for this article. They sell 2,000 credits for $12.95 per month. I pumped 1,400 words through the system and used just 1.5% of my monthly allocation.\nQuillBot (Accuracy 100%)\nThe last few times I tested QuillBot, results were wildly inconsistent -- multiple passes of the same text yielded wildly different scores. This time, however, it was rock solid and 100% correct. So I'm giving it the win. I'll check back in a few months to see if it holds onto this performance.\nUndetectable.ai (Accuracy 100%)\nUndetectable.ai's big claim is that it can \"humanize\" AI-generated text so detectors won't flag it. I haven't tested that feature -- it bothers me as a professional author and educator, because it seems like cheating.\nAlso: Why you should ignore 99% of AI tools - and which four I use every day\nHowever, the company also has an AI detector, which was very much on point.\nThe AI detector passed all five tests. Notice the indicators showing flags for other detectors. The company said, \"We developed multiple detector algorithms modeled after those major detectors to provide a federated and consensus-based approach. They do not directly feed into the listed models; rather, the models are each trained based on results they've generated. When it says those models flagged it, it's based on the algorithm we created and updated for those models.\"\nAlso: Only 8% of Americans would pay extra for AI, according to ZDNET-Aberdeen research\nI do have a question about the OpenAI flag, since OpenAI's content detector was discontinued in 2023 due to low accuracy. Even so, Undetectable.ai detected all five tests, earning a perfect 100%.\nWriter.com AI Content Detector (Accuracy 40%)\nWriter.com is a service that generates AI writing for corporate teams. Its AI Content Detector tool can scan for generated content. Unfortunately, its accuracy was low. It identified every text block as human-written, even though three of the six tests were written by ChatGPT.\nZeroGPT (Accuracy 100%)\nZeroGPT has matured since I last evaluated it. Then, no company name was listed, and the site was peppered with Google ads and lacked clear monetization. The service worked fairly well but seemed sketchy.\nAlso: Will AI destroy human creativity? No - and here's why\nThat sketchy feeling is gone. ZeroGPT now presents as a typical SaaS service, complete with pricing, company name, and contact information. Its accuracy increased as well: last time it was 80%; this time it scored 5 out of 5.\nIs it human, or is it AI?\nWhat about you? Have you tried AI content detectors like Copyleaks, Monica, or ZeroGPT? How accurate have they been in your experience? Have you used these tools to protect academic or editorial integrity? Have you encountered situations where human-written work was mistakenly flagged as AI? Are there detectors you trust more than others for evaluating originality? Let us know in the comments below.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.theverge.com/news/757538/reddit-internet-archive-wayback-machine-block-limit",
      "text": "Reddit says that it has caught AI companies scraping its data from the Internet Archive\u2019s Wayback Machine, so it\u2019s going to start blocking the Internet Archive from indexing the vast majority of Reddit. The Wayback Machine will no longer be able to crawl post detail pages, comments, or profiles; instead, it will only be able to index the Reddit.com homepage, which effectively means Internet Archive will only be able to archive insights into which news headlines and posts were most popular on a given day.\nReddit will block the Internet Archive\nThe company says that AI companies have scraped data from the Wayback Machine, so it\u2019s going to limit what the Wayback Machine can access.\n\u201dInternet Archive provides a service to the open web, but we\u2019ve been made aware of instances where AI companies violate platform policies, including ours, and scrape data from the Wayback Machine,\u201d spokesperson Tim Rathschmidt tells The Verge.\nThe Internet Archive\u2019s mission is to keep a digital archive of websites on the internet and \u201cother cultural artifacts,\u201d and the Wayback Machine is a tool you can use to look at pages as they appeared on certain dates, but Reddit believes not all of its content should be archived that way. \u201cUntil they\u2019re able to defend their site and comply with platform policies (e.g., respecting user privacy, re: deleting removed content) we\u2019re limiting some of their access to Reddit data to protect redditors,\u201d Rathschmidt says.\nThe limits will start \u201cramping up\u201d today, and Reddit says it reached out to the Internet Archive \u201cin advance\u201d to \u201cinform them of the limits before they go into effect,\u201d according to Rathschmidt. He says Reddit has also \u201craised concerns\u201d about the ability of people to scrape content from the Internet Archive in the past.\nReddit has a recent history of cutting off access to scraper tools as AI companies have begun to use (and abuse) them en masse, but it\u2019s willing to provide that data if companies pay. Last year, Reddit struck a deal with Google for both Google Search and AI training data early last year, and a few months later, it started blocking major search engines from crawling its data unless they pay. It also said its infamous API changes from 2023, which forced some third-party apps to shut down, leading to protests, were because those APIs were abused to train AI models.\nReddit also struck an AI deal with OpenAI, but it sued Anthropic in June, claiming Anthropic was still scraping from Reddit even after Anthropic said it wasn\u2019t scraping anymore.\n\u201cWe have a longstanding relationship with Reddit and continue to have ongoing discussions about this matter,\u201d Mark Graham, director of the Wayback Machine, says in a statement to The Verge.\nUpdate, August 11th: Added statement from the Wayback Machine.\nMost Popular\n- Reddit will block the Internet Archive\n- GitHub just got less independent at Microsoft after CEO resignation\n- RFK Jr. wants a wearable on every American \u2014 that future\u2019s not as healthy as he thinks\n- Ford reveals breakthrough process for lower priced EVs\n- This see-thru Game Boy is a work of art \u2014 because she designed a transparent circuit board"
    },
    {
      "url": "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nIt's only been almost three years since generative artificial intelligence (AI) hit the mainstream as a new paradigm of productivity, but here we are -- it's everywhere.\nI test AI tools as part of my work. I'll dig into just about any AI-related technology and see what I can make it do. Many of you have read my ongoing shootouts comparing AIs for programming and AI content checkers, among other kinds of tools.\nBut that's using AI in a rigorous lab environment to provide test results to ZDNET readers. Like many of you, I've also started using AI to augment my workflow and increase my productivity.\nAlso: The best AI for coding in 2025 (and what not to use)\nI wear a lot of hats; I run a small business with my wife, who also has her own business, where I'm the tech guy and designer. I also work with a number of industry groups. I have a fairly popular security software product for WordPress users. And I'm constantly working on projects, ranging from 3D printing the ultimate charging tower, to trying to make an AI-assisted Etsy store, to composing and publishing music, and using an AI for help with some of the marketing activities.\nI should note that I never, ever use AI to produce my core content. No article, song, or social media post is ever written using an AI tool. My work product is mine. But I do use AI to help me get through other aspects of my workload.\nI have a particular interest in how AI helps programming, how AI can support graphics work, and how AI can support video production.\nHere are the tools I'm willing to pay for -- and why.\n1. ChatGPT Plus - $20/mo\nSpeaking of AI and programming, it has essentially doubled my programming output. I use AI to help me with common-knowledge programming. I talked about it in-depth in my 25 tips article, but the core benefit is getting ChatGPT to write code for published APIs, so I don't have to spend time searching for code examples and trying to reverse-engineer comments on various programming boards.\nAnd yes, I mentioned ChatGPT. While more chatbots capable of passing my programming tests have been introduced in the last year, ChatGPT does the job well enough, and hey, who wants another monthly fee?\nAlso: How ChatGPT actually works (and why it's been so game-changing)\nIn fact, that's a big part of why I'm paying $20/mo for ChatGPT Plus. Sure, I've signed up and paid for some of the other AIs just to test them, but ChatGPT Plus is the only chatbot I have found so consistently useful that I keep it as a regularly used tool.\nI use ChatGPT for lots of research tasks, sometimes throwing math problems at it, and all sorts of other questions and problems I'm dealing with. While I never take its output as an unimpeachable source of truth, I do find ChatGPT to be a very useful sounding board, substantially more so than a quick Google search.\nNow, to be fair, I did outline five ways that an AI could help me in Gmail. If Gemini could do these things reliably, I'd sign back up in a heartbeat. But I just don't need the current email message I'm reading summarized, and I sure don't need it to write a friendlier or more professional version of whatever I've currently written. I tried Gmail's new AI unsubscribe feature, and it only found about 10 newsletters, yet I get thousands of emails and hundreds of newsletter-style messages every day. So, I'm leaving that one unbought.\n2. Midjourney - $10/mo\nI played around a lot with DALL-E, ChatGPT's earlier image generation tool. But recently, OpenAI introduced a new image generator in GPT-4o, and it's quite the beast. I have found that it generates great results, but it has more guardrails than another tool I pay for, Midjourney.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nBut even though I get image generation with my $20/mo ChatGPT Plus fee, I pay an extra $10/mo for Midjourney. Why?\nOne of the reasons is subjective. I like a lot of the images I get with Midjourney. Midjourney also allows me to describe artist styles, and lets me riff off a vast array of stylistic choices. ChatGPT, perhaps because of guardrails imposed by OpenAI, doesn't present as many choices.\nBut I also have two specific and objective reasons for paying for Midjourney. First, because image generation is so subjective, it's nice to have a variety of tools when seeking a representation of what you have in your head. I'll try different prompts and even the same prompts with both tools and take what works best.\nAlso: How to selectively modify a Midjourney image to create an artistic statement\nSecond, every month I generate a promotional image for my wife's online business. She has an e-commerce site that supports a popular hobby. Each month, on her very active Facebook group, she gives a craft-along theme to her users. I generate an image for that theme. Over the months, I've found that Midjourney does a far better job of generating an image that incorporates elements of the hobby. That said, some months I bounce back and forth between both tools until I can get an image that meets her business's needs.\nBecause Midjourney shaves what used to be two to three hours of work pushing pixels in Photoshop to generate those images down to about 10 minutes, it's worth the $10/month to me just for that project.\nPhotoshop Generative Fill - Honorable mention\nIn the title of this article, I said I pay for two AI tools. That's sort of true. I pay for Adobe's Creative Cloud suite in addition to ChatGPT Plus and Midjourney. But since I've been using and paying for Creative Cloud -- and before that, Photoshop -- long before there was generative fill, I'm not counting it in my AI tools list.\nAlso: I use Photoshop's AI tool every day - here are my 5 essential tips for the best results\nIf Adobe removed generative fill tomorrow, I'd still pay for Photoshop. To be clear, I don't like paying for it. It's costly, and the two-computer license limitation is restrictive. But a few years back, I tried switching to Affinity Photo, which at the time was $50 (it's now $70). That one-time fee is roughly what I pay each month for Creative Cloud, so it had a lot of potential.\nTo be clear, Affinity Photo is a fine application. But I've been using Photoshop since before the Clinton administration. To say I have Photoshop muscle memory is an understatement. It's a product I use almost every day. Switching to another application, while I could do it if I had to, slows down my workflow considerably.\nAlso: What to do if Generative Fill is grayed out in Adobe Photoshop AI\nSo, I don't consider my monthly expense for Creative Cloud to be an AI expense. That said, I find generative fill (and its various other AI tricks) very helpful. I often use it in concert with Midjourney and ChatGPT image generation.\nThree tools I'm thinking about\nI run a business online and, as such, rely on a wide variety of cloud services. Those fees add up, and now they're all going up in price. So while it might be nice to add more AI tools, I'm keeping it under control. It's very easy to just click OK and find yourself spending hundreds of dollars more every month.\nThat said, I am thinking about adding three more tools. I'm a bit hesitant, because each one has its annoyances and limitations, but they're on the short list for a quick order if I can ever justify an immediate performance improvement on one project or another.\nNotion AI\nThe first is Notion AI. I am deeply invested in Notion for all my project work. I also use it to write and organize all my articles, as well as schedule them, plan them, research them, and capture notes and assets. Notion AI is interesting because it would work like NotebookLM, limiting its knowledge base to my Notion account. That could be very useful as I work on more projects. But at one point, when Notion overcharged my wife's account, they were completely unsupportive and unsympathetic. So, I hesitate to give them more business.\nNotebookLM Pro\nGoogle's NotebookLM Pro is another contender. Now that Pocket, the article archiving service, is being discontinued, I considered using NotebookLM Pro as a replacement. The idea that I could save articles in NotebookLM as sources and then have the AI review them, summarize them, and analyze them seemed ideal, especially as a research tool.\nBut... the free version of NotebookLM only allows 50 sources per notebook. The Pro version, which is normally another $20/mo ( you can usually get a few starter months at a discounted rate), increases that limit, but only to 300 sources per notebook. My archive has well over 30,000 sources, which is beyond NotebookLM's limits. There is a $249/month plan (yowzah!), but all Google will say about limits is \"Highest limits and best model capabilities (later this year)\". What does that even mean?\nDescript\nDescript (for $16-$24/mo) is an AI video editing tool. This isn't a tool that does text-to-video generation. Instead, it's a tool that helps you take your video clips and edit them. Right now, I'm a very big Final Cut Pro user. Final Cut has added some AI features, but it lags far behind DaVinci Pro and Premiere Pro (because Apple lagging in AI is no surprise, right?).\nAlso: How to use ChatGPT to write code - and my top trick for debugging what it generates\nDescript automatically removes filler words and retakes, cleans up sound quality without any fuss, and does automatic multicam editing. It also promises to take long-form videos and automatically create clip videos, which could be a huge time-saver. The product also has some more \"out there\" features which I wouldn't use, including fake avatar generation and fake speech generation.\nThe thing is, Descript is aimed more at multiple talking head videos. I'm not sure it could handle the sort of in-depth technical hands-on project videos I do. So, it's still in the \"maybe someday\" category, for now at least.\nWhat do you use?\nDo you pay for any AI tools? Which ones, and why? Is there an AI tool that you strongly recommend I should be using that I didn't mention? Feel free to answer these questions and let us know your thoughts on AI subscriptions in the comments below.\nWant more stories about AI? Sign up for Innovation, our weekly newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
      "text": "Coding with AI? My top 5 tips for vetting its output - and staying out of trouble\nOur story begins, as many stories do, with a man and his AI. The man, like many men, is a bit of a geek and a bit of a programmer. He also needs a haircut.\nThe AI is the culmination of thousands of years of human advancement, all put to the service of making the man's life a little easier. The man, of course, is me. I'm that guy.\nAlso: The best AI for coding in 2025 (and what not to use)\nUnfortunately, while AI can be incredibly brilliant, it also has a propensity to lie, mislead, and make shockingly stupid mistakes. It is the stupid part that we will be discussing in this article.\nAnecdotal evidence does have value. My reports on how I've solved some problems quickly with AI are real. The programs I used AI to write with are still in use. I have used AI to help speed up aspects of my programming flow, especially when I focus on the sweet spots where I'm less productive and the AI is quite knowledgeable, like writing functions that call publicly published APIs.\nAlso: I'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nYou know how we got here. Generative AI burst onto the scene at the cusp of 2023 and has been blasting its way into knowledge work ever since.\nOne area, as the narrative goes, where AI truly shines is its ability to write code and help manage IT systems. Those claims are not untrue. I have shown, several times, how AI has solved coding and systems engineering problems I have personally experienced.\nAI coding in the real world: What science reveals\nNew tools always come with big promises. But do they deliver in real-world settings?\nMost of my reporting on programming effectiveness has been based on personal anecdotal evidence: my own programming experiences using AI. But I'm one guy. I have limited time to devote to programming and, like every programmer, I have certain areas where I spend most of my coding time.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nRecently, though, a nonprofit research organization called METR (Model Evaluation & Threat Research) did a more thorough analysis of AI coding productivity.\nTheir methodology seems sound. They worked with 16 experienced open-source developers who have actively contributed to large, popular repositories. The METR analysts provided those developers with 246 issues from the repositories that needed fixing. The coders were given about half the issues where they had to work on their own, and about half where they could use an AI for help.\nThe results were striking and unexpected. While the developers themselves estimated that AI assistance increased their productivity by an average of 24%, METR's analytics showed instead that AI assistance slowed them down by an average of 19%.\nThat's a bit of a head-scratcher. METR put together a list of factors that might explain the slowdown, including over-optimism about AI usefulness, high-developer familiarity with their repositories (and less AI knowledge), the complexity of large repositories, lack of AI reliability, and an ongoing problem where the AI refuses to use \"important tacit knowledge or context.\"\nAlso: How AI coding agents could destroy open-source software\nI would suggest that two other factors might have limited effectiveness:\nChoice of problem: The developers were told which issues they had to use AI help on and which issues they couldn't. My experience suggests knowledgeable developers must choose where to use AI based on the problem that needs to be solved. In my case, for example, getting the AI to write a regular expression (something I don't like doing and I'm fairly crappy at) would save me a lot more time than getting the AI to modify unique code I've already written, work on regularly, and know inside and out.\nChoice of AI: According to the report, the developers used Cursor, an AI-centric fork of VS Code, which used Claude 3.5/3.7 Sonnet at the time. When I tested 3.5 Sonnet, the results were terrible, with Sonnet failing three out of four of my tests. Subsequently, my tests of Claude 4 Sonnet were considerably better. METR reported that developers rejected more than 65% of the code the AI generated. That's going to take time.\nThat time when ChatGPT suggested nuking my system\nMETRs results are interesting. AI is clearly a double-edged sword when it comes to coding help. But there's also no doubt that AI can provide considerable value to coders. If anything, I think this test once again proves the contention that AI is a great tool for experienced programmers, but a potential high-risk resource for newbies.\nAlso: Why I'm switching to VS Code. Hint: It's all about AI tool integration\nLet's look at a concrete example, one that could have cost me a lot of time and trouble if I followed ChatGPT's advice.\nI was setting up a Docker container on my home lab using Portainer (a tool that helps manage Docker containers). For some reason, Portainer would not enable the Deploy button to create the container.\nIt had been a long day, so I didn't see the obvious problem. Instead, I asked ChatGPT. I fed ChatGPT screenshots of the configuration, as well as my Docker configuration file.\nChatGPT recommended that I uninstall and reinstall Portainer. It also suggested I remove Docker from the Linux distro and use the package manager to reinstall it. These actions would have had the effect of killing all my containers.\nOf note, ChatGPT didn't recommend or ask if I had backups of the containers. It just gave me the command line sequences it recommended I cut and paste to delete and rebuild Portainer and Docker. It was a wildly destructive and irresponsible recommendation.\nThe irony is that ChatGPT never figured out why Portainer wouldn't let me deploy the new container, but I did. It turns out I never filled out the container's name field. That's it.\nAlso: What is AI vibe coding? It's all the rage but it's not for everyone - here's why\nBecause I'm fairly experienced, I hesitated when ChatGPT told me to nuke my installation. However, someone relying on the AI for advice could have potentially brought down an entire server for want of typing in a container name.\nOverconfident and underinformed AIs: A dangerous combo\nI've also experienced the AI going completely off the rails. I've experienced it giving advice that was not only completely useless, but also presented with the apparent confidence of an expert.\nAlso: Google's Jules AI coding agent built a new feature I could actually ship - while I made coffee\nIf you're going to use AI tools to support your development or IT work, these tips might keep you out of trouble:\n- If there's not much publicly available information, the AI can't help. But the AI will make stuff up based on what little it knows, without admitting that it is lacking experience.\n- Like my dog, once the AI gets fixated on one thing, it often refuses to look at alternatives. If the AI is stuck on one approach, don't make the mistake of believing that its polite recommendations about a new approach are real. It's still going down the same rabbit hole. Start a new session.\n- If you don't know a lot, don't rely on the AI. Keep up your learning. Experienced devs can tell the difference between what will work and what won't. But if you're trying to put all the coding on the back of the AI, you won't know when or where it goes wrong or how to fix it.\n- Coders often use specific tools for specific tasks. A website might be built using Python, CSS, HTML, JavaScript, Flask, and Jinja. You choose each tool because you know what it does well. Choose your AI tools the same way. For example, I don't use AI for business logic, but I gain productivity using AI to write API calls and public knowledge, where it can save me a lot of time.\n- Test everything an AI produces. Everything. Line by individual line. The AI can save a ton of time, but it can also make enormous mistakes. Yes, taking the time and energy to test by hand can help prevent errors. If the AI offers to write unit tests, let it. But test the tests.\nBased on your experience level, here's how I recommend you think about AI assistance:\n- If you know nothing about a subject or skill: AI can help you pass as if you do, but it could be amazingly wrong, and you might not know.\n- If you're an expert in a subject or skill: AI can help, but it will piss you off. Your expertise gets used not only to separate the AI-stupid from the AI-useful, but to carefully craft a path where AI can actually help.\n- If you're in between: AI is a mixed bag. It could help you or get you in trouble. Don't delegate your skill-building to the AI because it could leave you behind.\nAlso: How I used ChatGPT to analyze, debug, and rewrite a broken plugin from scratch - in an hour\nGenerative AI can be an excellent helper for experienced developers and IT pros, especially when used for targeted, well-understood tasks. But its confidence can be deceptive and dangerous.\nAI can be useful, but always double-check its work.\nHave you used AI tools like ChatGPT or Claude to help with your development or IT work? Did they speed things up, or nearly blow things up? Are you more confident or more cautious when using AI on critical systems? Have you found specific use cases where AI really shines, or where it fails hilariously? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.copyright.gov/help/faq/faq-fairuse.html",
      "text": "Can I Use Someone Else's Work? Can Someone Else Use Mine?\nYou can ask for it. If you know who the copyright owner is, you may contact the owner directly. If you are not certain about the ownership or have other related questions, you may wish to request that the Copyright Office conduct a search of its records or you may search yourself. See the next question for more details.\nHow can I find out who owns a copyright?We can provide you with the information available in our records. A search of registrations, renewals, and recorded transfers of ownership made before 1978 requires a manual search of our files. Upon request, our staff will search our records, see Circular 4 Copyright Office fees. There is no fee if you conduct a search in person at the Copyright Office. Copyright registrations made and documents recorded from 1978 to date are available for searching online. For further information, see Circular 22, How to Investigate the Copyright Status of a Work, and Circular 23, Copyright Card Catalog and the Online File. Check out the Virtual Card Catalog Proof of Concept as well.\nHow can I obtain copies of someone else's work and/or registration certificate?The Copyright Office will not honor a request for a copy of someone else's protected work without written authorization from the copyright owner or from his or her designated agent, unless the work is involved in litigation. In the latter case, a litigation statement is required. A certificate of registration for any registered work can be obtained see Circular 4 Copyright Office fees, for this and other records and services. Circular 6, Access to and Copies of Copyright Records and Deposit, provides additional information.\nHow much of someone else's work can I use without getting permission?Under the fair use doctrine of the U.S. copyright statute, it is permissible to use limited portions of a work including quotes, for purposes such as commentary, criticism, news reporting, and scholarly reports. There are no legal rules permitting the use of a specific number of words, a certain number of musical notes, or percentage of a work. Whether a particular use qualifies as fair use depends on all the circumstances. See, Fair Use Index, and Circular 21, Reproductions of Copyrighted Works by Educators and Librarians.\nHow much do I have to change in order to claim copyright in someone else's work?Only the owner of copyright in a work has the right to prepare, or to authorize someone else to create, a new version of that work. Accordingly, you cannot claim copyright to another's work, no matter how much you change it, unless you have the owner's consent. See Circular 14, Copyright Registration for Derivative Works and Compilations.\nSomebody infringed my copyright. What can I do?A party may seek to protect his or her copyrights against unauthorized use by filing a civil lawsuit in federal district court. If you believe that your copyright has been infringed, consult an attorney. In cases of willful infringement for profit, the U.S. Attorney may initiate a criminal investigation.\nCould I be sued for using somebody else's work? How about quotes or samples?If you use a copyrighted work without authorization, the owner may be entitled to bring an infringement action against you. There are circumstances under the fair use doctrine where a quote or a sample may be used without permission. However, in cases of doubt, the Copyright Office recommends that permission be obtained.\nDo you have a list of songs or movies in the public domain?\nNo, we neither compile nor maintain such a list. A search of our records, however, may reveal whether a particular work is no longer under copyright protection. We will conduct a search of our records by the title of a work, an author's name, or a claimant's name. Upon request, our staff will search our records see Circular 4 Copyright Office Fees, for this and other records and services. You may also search the records in person without paying a fee.\nI saw an image on the Library of Congress website that I would like to use. Do I need to obtain permission?With few exceptions, the Library of Congress does not own copyright in the materials in its collections and does not grant or deny permission to use the content mounted on its website. Responsibility for making an independent legal assessment of an item from the Library\u2019s collections and for securing any necessary permissions rests with persons desiring to use the item. To the greatest extent possible, the Library attempts to provide any known rights information about its collections. Such information can be found in the \u201cCopyright and Other Restrictions\u201d statements on each American Memory online collection homepage. If the image is not part of the American Memory collections, contact the Library custodial division to which the image is credited. Bibliographic records and finding aids available in each custodial division include information that may assist in assessing the copyright status. Search our catalogs through the Library's Online Catalog. To access information from the Library\u2019s reading rooms, go to Research Centers.\nIs it legal to download works from peer-to-peer networks and if not, what is the penalty for doing so?Uploading or downloading works protected by copyright without the authority of the copyright owner is an infringement of the copyright owner's exclusive rights of reproduction and/or distribution. Anyone found to have infringed a copyrighted work may be liable for statutory damages up to $30,000 for each work infringed and, if willful infringement is proven by the copyright owner, that amount may be increased up to $150,000 for each work infringed. In addition, an infringer of a work may also be liable for the attorney's fees incurred by the copyright owner to enforce his or her rights.\nWhether or not a particular work is being made available under the authority of the copyright owner is a question of fact. But since any original work of authorship fixed in a tangible medium (including a computer file) is protected by federal copyright law upon creation, in the absence of clear information to the contrary, most works may be assumed to be protected by federal copyright law.\nSince the files distributed over peer-to-peer networks are primarily copyrighted works, there is a risk of liability for downloading material from these networks. To avoid these risks, there are currently many \"authorized\" services on the Internet that allow consumers to purchase copyrighted works online, whether music, ebooks, or motion pictures. By purchasing works through authorized services, consumers can avoid the risks of infringement liability and can limit their exposure to other potential risks, e.g., viruses, unexpected material, or spyware.\nFor more information on this issue, see the Register of Copyrights' testimony before the Senate Judiciary Committee.\nCan a school show a movie without obtaining permission from the copyright owner?If the movie is for entertainment purposes, you need to get a clearance or license for its performance.\nIt is not necessary to obtain permission if you show the movie in the course of \u201cface-to-face teaching activities\u201d in a nonprofit educational institution, in a classroom or similar place devoted to instruction, if the copy of the movie being performed is a lawful copy. 17 U.S.C. \u00a7 110(1). This exemption encompasses instructional activities relating to a wide variety of subjects, but it does not include performances for recreation or entertainment purposes, even if there is cultural value or intellectual appeal.\nQuestions regarding this provision of the copyright law should be made to the legal counsel of the school or school system.\nMy local copying store will not make reproductions of old family photographs. What can I do?Photocopying shops, photography stores and other photo developing stores are often reluctant to make reproductions of old photographs for fear of violating the copyright law and being sued. These fears are not unreasonable, because copy shops have been sued for reproducing copyrighted works and have been required to pay substantial damages for infringing copyrighted works. The policy established by a shop is a business decision and risk assessment that the business is entitled to make, because the business may face liability if they reproduce a work even if they did not know the work was copyrighted.\nIn the case of photographs, it is sometimes difficult to determine who owns the copyright and there may be little or no information about the owner on individual copies. Ownership of a \u201ccopy\u201d of a photograph \u2013 the tangible embodiment of the \u201cwork\u201d \u2013 is distinct from the \u201cwork\u201d itself \u2013 the intangible intellectual property. The owner of the \u201cwork\u201d is generally the photographer or, in certain situations, the employer of the photographer. Even if a person hires a photographer to take pictures of a wedding, for example, the photographer will own the copyright in the photographs unless the copyright in the photographs is transferred, in writing and signed by the copyright owner, to another person. The subject of the photograph generally has nothing to do with the ownership of the copyright in the photograph. If the photographer is no longer living, the rights in the photograph are determined by the photographer\u2019s will or passed as personal property by the applicable laws of intestate succession.\nThere may be situations in which the reproduction of a photograph may be a \u201cfair use\u201d under the copyright law. Information about fair use may be found at Fair Use Index. However, even if a person determines a use to be a \u201cfair use\u201d under the factors of section 107 of the Copyright Act, a copy shop or other third party need not accept the person\u2019s assertion that the use is noninfringing. Ultimately, only a federal court can determine whether a particular use is, in fact, a fair use under the law."
    },
    {
      "url": "https://www.zdnet.com/article/openai-and-reddit-have-struck-a-deal-to-train-chatgpt-on-your-posts-heres-what-it-means-for-you/",
      "text": "Your Reddit posts will now help train ChatGPT - what we know so far\nLast week, Reddit introduced a new content policy that was a pretty big win for user privacy. Part of that new policy stated that if a company wants to use Reddit data for commercial purposes, including training AI, it will have to pay.\nOpenAI is taking Reddit up on that offer.\nAlso: The ChatGPT desktop app is more helpful than I expected - here's why and how to try it\nThe two companies reached an agreement to give OpenAI access to Reddit's massive catalog of content for ChatGPT training purposes. In return, Reddit will get access to OpenAI's tools to bring AI-powered features to Reddit users and mods.\nOpenAI will access Reddit's Data API, \"which provides real-time, structured, and unique content from Reddit.\" The goal is to give OpenAI a better understanding of Reddit's content, especially on recent topics.\nNeither of the two sides disclosed actual financial terms.\nReddit has long been a training ground for AI, but the company's recent policy updates put an end to companies doing so without the platform's consent.\nIt makes sense why OpenAI would want access to Reddit user posts. Steve Huffman, Reddit Co-Founder and CEO, calls his site \"one of the internet's largest open archives of authentic, relevant, and always up to date human conversations about anything and everything.\"\nFor users, this change won't mean much \u2013 at least not in how the site functions. The content policy prohibits partners from using content to identify an individual for any reason, including ad targeting, it prohibits law enforcement or government officials from conducting surveillance on users, and it allows users to delete any of their content, even if it's technically been sold.\nAlso: What is a Chief AI Officer, and how do you become one?\nThis new agreement simply means that OpenAI will potentially take what you post and feed it into a database alongside millions of other posts to help AI become more reliable.\nAs far as what the new AI features might be, Reddit didn't offer up specifics. Facebook recently integrated AI, but it was met with a lot of frustration from users. It's possible Reddit might incorporate an AI-powered posting tool that assists users with hashing out their thoughts, but that would lead to a trained-by-AI, posted-by-AI loop of sorts. If the company takes an idea from Google, it might offer up AI-powered summaries at the top of posts, but in my personal experience, that summary is often wrong.\nUnfortunately, it doesn't look like there's a way for users to opt out of having their content used to train AI other than deleting old posts."
    },
    {
      "url": "https://www.zdnet.com/article/reddit-sues-anthropic-for-scraping-its-users-content-without-consent/",
      "text": "Reddit sues Anthropic for scraping its users' content without consent\nThe list of lawsuits against AI companies is growing: Reddit has joined in with a suit against Anthropic.\nOn Wednesday, the company filed a complaint in California stating that Anthropic -- developer of Claude -- ignores Robots Exclusion Protocol (REP), or robots.txt, which blocks AI crawlers from scraping a site's content. Research indicates that other AI companies are also engaging in this practice: In March, Columbia's Tow Center found that multiple chatbots, including Perplexity, could still retrieve articles from publishers that had blocked their crawlers using REP.\nAlso: Anthropic's popular Claude Code AI tool now included in its $20/month Pro plan\nThe complaint states that \"Anthropic is in fact intentionally trained on the personal data of Reddit users without ever requesting their consent,\" which is a violation of Reddit's user privacy agreement. In July 2024, when Reddit publicly criticized Anthropic for misusing its content, the complaint continues, \"Anthropic's bots continued to hit Reddit's servers over 100,000 times\" despite insisting that it had stopped its bots from crawling the site.\nThe lawsuit is the latest in the ongoing clash between sites that create and host content -- including publishers, news organizations, and user forums like Reddit -- and the AI companies that scrape that content to use as training data. In late 2023, The New York Times became the first publisher to sue OpenAI and Microsoft for using its content to train its models without permission or payment. In April, Ziff Davis, the parent company of this publication, sued OpenAI for copyright violation, citing similar instances of the AI company crawling Ziff Davis sites despite being blocked. Authors and creatives have also sued OpenAI and Meta on similar grounds.\nWhat sets Reddit apart here is that it is also a tech company, unlike the publishers behind the lawsuits that predate this one. Reddit has licensing agreements with OpenAI and Google.\nAlso: Reddit's new Google-powered AI search tool makes finding answers faster than ever\nOther publishers, including Dotdash Meredith, Financial Times, and the AP, have taken a different approach, proactively entering into licensing agreements with AI companies that allow them to access some or all of their content in exchange for internal AI tools and preferential citation placements in chatbot responses. However, research shows that chatbots still struggle to accurately cite and favor stories from publishers, meaning it is still unclear whether those benefits are being realized.\nWant more stories about AI? Sign up for Innovation, our weekly newsletter."
    }
  ],
  "argos_summary": "Reddit has restricted the Internet Archive's Wayback Machine from indexing most of its content, allowing only the homepage to be archived. This decision aims to protect user data from AI companies that have been scraping Reddit's content through the Archive, violating platform policies. Reddit's actions come amid increasing tensions between digital publishers and AI firms, with Reddit also suing Anthropic for allegedly scraping user data without consent.",
  "argos_id": "KUDCF6D0I"
}