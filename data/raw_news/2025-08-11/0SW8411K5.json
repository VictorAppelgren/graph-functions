{
  "url": "https://www.businessinsider.com/google-deepmind-ceo-demis-hassabis-agi-consistency-2025-8",
  "authorsByline": "Lee Chong Ming",
  "articleId": "131be571af5f41bfa17ebc007a72823e",
  "source": {
    "domain": "businessinsider.com",
    "paywall": true,
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://i.insider.com/689aaf4da17a8c5b4052ae96?width=1200&format=jpeg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T03:56:14+00:00",
  "addDate": "2025-08-12T04:01:47.779962+00:00",
  "refreshDate": "2025-08-12T04:01:47.779964+00:00",
  "score": 1.0,
  "title": "Google DeepMind CEO says one flaw is holding AI back from reaching full AGI",
  "description": "Demis Hassabis says AI's next leap to AGI will require fixing a key flaw: consistency.",
  "content": "The one thing keeping AI from full AGI? Consistency, said Google DeepMind CEO Demis Hassabis.Hassabis said on an episode of the \"Google for Developers\" podcast published Tuesday that advanced models like Google's Gemini still stumble over problems most schoolkids could solve.\"It shouldn't be that easy for the average person to just find a trivial flaw in the system,\" he said.He pointed to Gemini models enhanced with DeepThink \u2014 a reasoning-boosting technique \u2014 that can win gold medals at the International Mathematical Olympiad, the world's most prestigious math competition.But those same systems can \"still make simple mistakes in high school maths,\" he said, calling them \"uneven intelligences\" or \"jagged intelligences.\"\"Some dimensions, they're really good; other dimensions, their weaknesses can be exposed quite easily,\" he added.Hassabis's position aligns with Google CEO Sundar Pichai, who has dubbed the current stage of development \"AJI\" \u2014 artificial jagged intelligence. Pichai used this term on an episode of Lex Fridman's podcast that aired in June to describe systems that excel in some areas but fail in others.Hassabis said solving AI's issues with inconsistency will take more than scaling up data and computing. \"Some missing capabilities in reasoning and planning in memory\" still need to be cracked, he added.He said the industry also needs better testing and \"new, harder benchmarks\" to determine precisely what the models excel at, and what they don't.Hassabis and Google did not respond to a request for comment from Business Insider.Big Tech players like Google and OpenAI are working toward achieving AGI, a theoretical threshold where AI can reason like humans.Hassabis said in April that AGI will arrive \"in the next five to 10 years.\"AI systems remain prone to hallucinations, misinformation, and basic errors.OpenAI CEO Sam Altman had a similar take ahead of last week's launch of GPT-5. While calling his firm's model a significant advancement, he told reporters it still falls short of true AGI.\"This is clearly a model that is generally intelligent, although I think in the way that most of us define AGI, we're still missing something quite important, or many things quite important,\" Altman said during a press call on Wednesday before the release of GPT-5.Altman added that one of those missing elements is the model's ability to learn independently.\"One big one is, you know, this is not a model that continuously learns as it's deployed from the new things it finds, which is something that to me feels like AGI. But the level of intelligence here, the level of capability, it feels like a huge improvement,\" he said.",
  "medium": "Article",
  "links": [],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Google DeepMind CEO Demis Hassabis",
      "weight": 0.0905135
    },
    {
      "name": "Google DeepMind CEO",
      "weight": 0.09043924
    },
    {
      "name": "Google CEO Sundar Pichai",
      "weight": 0.08865002
    },
    {
      "name": "Gemini models",
      "weight": 0.08654369
    },
    {
      "name": "advanced models",
      "weight": 0.08358637
    },
    {
      "name": "Google DeepMind",
      "weight": 0.0825164
    },
    {
      "name": "Google",
      "weight": 0.07811276
    },
    {
      "name": "full AGI",
      "weight": 0.075126305
    },
    {
      "name": "OpenAI CEO Sam Altman",
      "weight": 0.072602026
    },
    {
      "name": "AGI",
      "weight": 0.06788311
    }
  ],
  "topics": [
    {
      "name": "Business Leaders"
    },
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Business"
    },
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.97705078125
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.931640625
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.875
    }
  ],
  "sentiment": {
    "positive": 0.1070864,
    "negative": 0.52529925,
    "neutral": 0.36761436
  },
  "summary": "Google DeepMind CEO, Demis Hassabis, has stated that consistency is the primary issue preventing AI from reaching full AGI, a theoretical threshold where AI can reason like humans. He highlighted that advanced models like Google's Gemini, which can win gold medals at the International Mathematical Olympiad, can still make simple mistakes in high school maths. Hassabis said that solving this issue will take more than scaling up data and computing to begin. He also suggested the industry needs better testing and new benchmarks to identify what models excel at and what they don't.",
  "shortSummary": "Google DeepMind CEO Demis Hassabis emphasizes that inconsistent AI models are hindering the industry's efforts to achieve AGI, despite recent successes.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "2b658637866a43e9b4c3d2d358cd759e",
  "places": [],
  "scraped_sources": [],
  "argos_summary": "Google DeepMind CEO Demis Hassabis highlighted that the inconsistency of AI models, such as Google's Gemini, is a major barrier to achieving artificial general intelligence (AGI). Despite their capabilities in advanced tasks, these models still make basic errors, which Hassabis describes as 'uneven intelligences.' He emphasized the need for improved reasoning, planning, and better testing benchmarks to address these inconsistencies. This perspective aligns with Google CEO Sundar Pichai's concept of 'artificial jagged intelligence,' indicating that while AI has made significant strides, it still lacks the comprehensive reasoning abilities characteristic of human intelligence.",
  "argos_id": "0SW8411K5"
}