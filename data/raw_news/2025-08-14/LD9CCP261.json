{
  "url": "https://www.yahoo.com/news/articles/instagram-users-angry-confused-meta-010054604.html",
  "authorsByline": "Graham Fraser - Technology Reporter",
  "articleId": "d7f8e6260bd74d9a928405ddfdb1e176",
  "source": {
    "domain": "yahoo.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "Santa Clara County",
      "city": "Sunnyvale",
      "coordinates": {
        "lat": 37.3688301,
        "lon": -122.036349
      }
    }
  },
  "imageUrl": "https://edgecast-img.yahoo.net/mysterio/api/8469742bb9aa29ae59c296205dcf1ba3f231d0195f1c057444434c623159ad04/ynews/resizefill_w1200/https://media.zenfs.com/en/bbc_us_articles_995/64f68d93b7ec1b82597074ef63dcf9ba",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-15T01:00:54+00:00",
  "addDate": "2025-08-15T01:47:34.613839+00:00",
  "refreshDate": "2025-08-15T01:47:34.613843+00:00",
  "score": 1.0,
  "title": "Instagram users angry and confused as Meta overturns yet more account bans",
  "description": "Hundreds of people have contacted the BBC to say they have wrongly been shut out of their accounts.",
  "content": "Instagram users have told the BBC of their confusion, fear and anger after having their accounts suspended, often for being wrongly accused by parent company Meta of breaching the platform's child sex abuse rules.\n\nFor months, tens of thousands of people around the world have been complaining Meta has been banning their Instagram and Facebook accounts in error.\n\nThey say they have been wrongly accused of breaching site rules - including around child sexual exploitation.\n\nMore than 500 of them have contacted the BBC to say they have lost cherished photos and seen businesses upended - but some also speak of the profound personal toll it has taken on them, including concerns that the police could become involved.\n\nMeta acknowledged a problem with the erroneous banning of Facebook Groups in June, but has denied there is wider issue on Facebook or Instagram at all.\n\nIt has repeatedly refused to comment on the problems its users are facing - though it has frequently overturned bans when the BBC has raised individual cases with it.\n\nHere are some of the stories users have shared with BBC News.\n\n'I put all of my trust in social media'\n\nYassmine Boussihmed, 26, from the Netherlands, spent five years building an Instagram profile for her boutique dress shop in Eindhoven.\n\nIn April, she was banned over account integrity. Over 5,000 followers, gone in an instant. She lost clients, and was devastated.\n\n\"I put all of my trust in social media, and social media helped me grow, but it has let me down,\" she told the BBC.\n\nThis week, after the BBC sent questions about her case to Meta's press office, her Instagram accounts were reinstated.\n\n\"I am so thankful,\" she said in a tearful voice note.\n\nFive minutes later, her personal Instagram was suspended again - but the account for the dress shop remained.\n\nLucia, not her real name, is a 21-year-old woman from Austin, Texas.\n\nShe was suspended from Instagram for just over two weeks for breaching Meta's policy on child sexual exploitation (CSE), abuse and nudity.\n\nAs with all the other cases, she was not told what post breached the platform's rules.\n\nThat has left wondering if a picture she posted of herself and her 21-year-old friend wearing bikini tops somehow triggered the artificial intelligence (AI) moderation tools, as she thinks they \"look a little bit younger\".\n\nShe also uses her account to interact with under 18s, such as sending Reels to her younger sister.\n\n\"It is deeply troubling to have an accusation as disgusting as this one,\" she told BBC News.\n\n\"Given that I have a desire to work in juvenile justice as an attorney and advocate on behalf of children, I am appalled to have been suspended for something I know I did not do and would never do.\"\n\nShe appealed, and then about seven hours after the BBC highlighted Lucia's case to Meta's press office, her account was restored with no explanation.\n\u2022 None 'There is a problem': Facebook and Instagram users complain of account bans\n\nOver 36,000 people have signed a petition accusing Meta of falsely banning accounts; thousands more are in Reddit forums or on social media posting about it.\n\nTheir central accusation - Meta's AI is unfairly banning people, with the tech also being used to deal with the appeals. The only way to speak to a human is to pay for Meta Verified, and even then many are frustrated.\n\nMeta has not commented on these claims. Instagram states AI is central to its \"content review process\" and Meta has outlined how technology and humans enforce its policies.\n\nDuncan Edmonstone, from Cheshire, has stage four ALK+ lung cancer. The 55-year-old finds solace in the support network he has on private Facebook groups.\n\nFor 12 days at the end of June, he was banned for breaking cybersecurity guidelines before being reinstated.\n\n\"The support groups are my lifeline, and there are actual examples of where advice from group members has made a difference to other patient's treatment,\" he said.\n\n\"I draw satisfaction and meaning, in a life that is probably going to be cut short, from helping other people in that group.\"\n\nRyan - not his real name - has been banned, reinstated, and banned again from Instagram over the past few months.\n\nThe former teacher from London was thrown off the platform in May after he was accused of breaching the CSE policy.\n\nHe spent a month appealing. In June, the BBC understands a human moderator double checked and concluded Ryan had breached the policy.\n\nThen his account was abruptly restored at the end of July.\n\n\"We're sorry we've got this wrong,\" Instagram said in an email to him, adding that he had done nothing wrong.\n\n\"'Sorry we called you a paedophile for two months - here is your account back,'\" is how he characterised the tone of the message.\n\nBut that wasn't the end of the story.\n\nHours after the BBC contacted Meta's press office to ask questions about his experience, he was banned again on Instagram and, for the first time, Facebook.\n\n\"I am devastated and I don't know what to do,\" he told the BBC.\n\n\"I can't believe it has happened twice.\"\n\nHis Facebook account was back two days later - but he was still blocked from Instagram.\n\nRyan says he has been left feeling deeply isolated - and worried the police are going to \"knock on the door\".\n\nHis experiences mirrors those of other Instagram users who told the BBC of the \"extreme stress\" of having their accounts banned after being wrongly accused of breaching the platform's rules on CSE.\n\nWhat has Meta said?\n\nDespite taking action on Yassmine, Lucia and Ryan's accounts, Meta has not made any comment to the BBC.\n\nIn common with all big technology firms, it has come under pressure from authorities to make its platforms safer.\n\nIn July, Meta said it was taking \"aggressive action\" on accounts breaking its rules - including the removal of 635,000 Instagram and Facebook accounts over sexualised comments and imagery in relation to children.\n\nMeta's wide-ranging policy on child sexual exploitation has changed three times since Boxing Day last year, with all amendments occurring since 17 July.\n\nIt has not said what impact, if any, these changes had on the cases the BBC has raised with it.\n\u2022 None Facebook and Instagram get rid of fact checkers\n\u2022 None What is AI and how does it work?\n\nSign up for our Tech Decoded newsletter to follow the world's top tech stories and trends. Outside the UK? Sign up here.",
  "medium": "Article",
  "links": [
    "https://www.bbc.co.uk/news/articles/cly74mpy8klo?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
    "https://cloud.email.bbc.com/techdecoded-newsletter-signup",
    "https://help.instagram.com/423837189385631",
    "https://www.bbc.co.uk/news/technology-65855333?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
    "https://www.bbc.co.uk/news/articles/c3r9nwgvwy3o?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
    "https://www.bbc.co.uk/news/articles/cvgnp9ykm3xo?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
    "https://about.fb.com/news/2025/07/expanding-teen-account-protections-child-safety-features/",
    "https://www.meta.com/en-gb/meta-verified/?srsltid=AfmBOor4ZqM84FXxAjCYyWzyR7CBtZr8eB2ZHU7srlVwWlDimUKdQesx",
    "https://www.bbc.co.uk/news/articles/cy8kjdz9nr3o?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
    "https://transparency.meta.com/en-gb/policies/community-standards/account-integrity/",
    "https://transparency.meta.com/en-gb/enforcement/",
    "https://www.bbc.co.uk/newsletters/zxh6cxs?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
    "https://transparency.meta.com/en-gb/policies/community-standards/child-sexual-exploitation-abuse-nudity/",
    "https://transparency.meta.com/en-gb/policies/community-standards/cybersecurity/"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "other Instagram users",
      "weight": 0.084261924
    },
    {
      "name": "Instagram users",
      "weight": 0.08318907
    },
    {
      "name": "account bans",
      "weight": 0.07941833
    },
    {
      "name": "accounts",
      "weight": 0.0767572
    },
    {
      "name": "Meta",
      "weight": 0.07614477
    },
    {
      "name": "Meta Verified",
      "weight": 0.0754141
    },
    {
      "name": "account integrity",
      "weight": 0.074555196
    },
    {
      "name": "Instagram",
      "weight": 0.07385517
    },
    {
      "name": "parent company Meta",
      "weight": 0.07175601
    },
    {
      "name": "BBC News",
      "weight": 0.06883194
    }
  ],
  "topics": [
    {
      "name": "Social Media"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/Online Communities/Social Networks",
      "score": 0.89892578125
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.740234375
    },
    {
      "name": "/Sensitive Subjects/Violence & Abuse",
      "score": 0.5634765625
    },
    {
      "name": "/News/Technology News",
      "score": 0.38330078125
    },
    {
      "name": "/People & Society/Social Issues & Advocacy/Other",
      "score": 0.331298828125
    }
  ],
  "sentiment": {
    "positive": 0.041355353,
    "negative": 0.7603836,
    "neutral": 0.19826108
  },
  "summary": "Instagram users have complained about having their accounts suspended, often for breaching the platform's child sex abuse rules, often by mistake. The issue has been widespread for months, with tens of thousands complaining that Meta has been banning their accounts in error. They have been accused of breaching site rules, including around child sexual exploitation. Over 500 of these users have contacted the BBC, expressing their confusion, fear and anger. Meta acknowledged a problem with the erroneous banning of Facebook Groups in June but has denied there is a wider issue on Facebook or Instagram. The only way to speak to a human is to pay for Meta Verified.",
  "shortSummary": "Instagram users are upset and frustrated after being wrongly accused of child sex abuse, leading to multiple account bans and personal consequences.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": true,
  "reprintGroupId": "8a87b157477c406fa5ae9e5374fc6539",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.bbc.co.uk/news/articles/cly74mpy8klo?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
      "text": "Facebook and Instagram get rid of fact checkers\n- Published\nMeta is abandoning the use of independent fact checkers on Facebook and Instagram, replacing them with X-style \"community notes\" where commenting on the accuracy of posts is left to users.\nIn a video posted alongside a blog post, external by the company on Tuesday, chief executive Mark Zuckerberg said third-party moderators were \"too politically biased\" and it was \"time to get back to our roots around free expression\".\nThe move comes as Zuckerberg and other tech executives seek to improve relations with US President-elect Donald Trump before he takes office later this month.\nTrump and his Republican allies have criticised Meta for its fact-checking policy, calling it censorship of right-wing voices.\nSpeaking after the changes were announced, Trump told a news conference he was impressed by Zuckerberg's decision and that Meta had \"come a long way\".\nAsked whether Zuckerberg was \"directly responding\" to threats Trump had made to him in the past, the incoming US president responded: \"Probably\".\nJoel Kaplan, a prominent Republican who is replacing Sir Nick Clegg as Meta's global affairs chief, wrote that the company's reliance on independent moderators was \"well-intentioned\" but had too often resulted in censoring.\nCampaigners against hate speech online reacted with dismay to the change - and suggested it was really motivated by getting on the right side of Trump.\n\"Zuckerberg's announcement is a blatant attempt to cozy up to the incoming Trump administration \u2013 with harmful implications\", said Ava Lee, from Global Witness, a campaign group which describes itself as seeking to hold big tech to account.\n\"Claiming to avoid \"censorship\" is a political move to avoid taking responsibility for hate and disinformation that platforms encourage and facilitate,\" she added.\nEmulating X\nMeta's current fact checking programme, introduced in 2016, refers posts that appear to be false or misleading to independent organisations to assess their credibility.\nPosts flagged as inaccurate can have labels attached to them offering viewers more information, and be moved lower in users' feeds.\nThat will now be replaced \"in the US first\" by community notes.\nMeta says it has \"no immediate plans\" to get rid of its third-party fact checkers in the UK or the EU.\nThe new community notes system has been copied from X, which introduced it after being bought and renamed by Elon Musk.\nIt involves people of different viewpoints agreeing on notes which add context or clarifications to controversial posts.\n\"This is cool,\" he said of Meta's adoption of a similar mechanism.\nAfter concerns were raised around self-harm and depressive content, Meta clarified that there would be \"no change to how we treat content that encourages suicide, self-injury, and eating disorders\".\nFact-checking organisation Full Fact - which participates in Facebook's program for verifying posts in Europe - said it \"refutes allegations of bias\" made against its profession.\nThe body's chief executive, Chris Morris, described the change as a \"disappointing and a backwards step that risks a chilling effect around the world.\"\n'Facebook jail'\nAlongside content moderators, fact checkers sometimes describe themselves as the internet's emergency services.\nBut Meta bosses have concluded they have been intervening too much.\n\"Too much harmless content gets censored, too many people find themselves wrongly locked up in \"Facebook jail,\" and we are often too slow to respond when they do,\" wrote Joel Kaplan on Tuesday.\nBut Meta does appear to acknowledge there is some risk involved - Zuckerberg said in his video the changes would mean \"a trade off\".\n\"It means we're going to catch less bad stuff, but we'll also reduce the number of innocent people's posts and accounts that we accidentally take down,\" he said.\nThe approach is also at odds with recent regulation in both the UK and Europe, where big tech firms are being forced to take more responsibility for the content they carry or face steep penalties.\nSo it's perhaps not surprising that Meta's move away from this line of supervision is US-only, for now at least.\n'A radical swing'\nMeta's blog post said it would also \"undo the mission creep\" of rules and policies.\n\"It's not right that things can be said on TV or the floor of Congress, but not on our platforms,\" it added.\nIt comes as technology firms and their executives prepare for Trump's inauguration on 20 January.\nSeveral CEOs have publicly congratulated Trump on his return to office, while others have travelled to Trump's Florida estate Mar-Lago to meet with the incoming president, including Zuckerberg in November. Meta has also donated $1m to an inauguration fund for Trump.\n\"The recent elections also feel like a cultural tipping point towards, once again, prioritising free speech,\" said Zuckerberg in Tuesday's video.\nMeta notified Trump's team of the policy change before the announcement, the New York Times reported, external.\nKaplan replacing Sir Nick - a former Liberal Democrat deputy prime minister - as the company's president of global affairs has also been interpreted as a signal of the firm's shifting approach to moderation and its changing political priorities.\nThe company also announced on Monday that Dana White, a close Trump ally and president of the Ultimate Fighting Championship, would join its board of directors.\nKate Klonick, associate professor of law at St John's University Law School, said the changes reflected a trend \"that has seemed inevitable over the last few years, especially since Musk's takeover of X\".\n\"The private governance of speech on these platforms has increasingly become a point of politics,\" she told BBC News.\nWhere companies have previously faced pressure to build trust and safety mechanisms to deal with issues like harassment, hate speech, and disinformation, a \"radical swing back in the opposite direction\" is now underway, she added.\nRelated topics\n- Published7 January\n- Published11 November 2024\n- Published17 October 2024"
    },
    {
      "url": "https://www.bbc.co.uk/news/articles/cy8kjdz9nr3o?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
      "text": "Instagram wrongly accuses some users of breaching child sex abuse rules\n- Published\nInstagram users have told the BBC of the \"extreme stress\" of having their accounts banned after being wrongly accused by the platform of breaching its rules on child sexual exploitation.\nThe BBC has been in touch with three people who were told by parent company Meta that their accounts were being permanently disabled, only to have them reinstated shortly after their cases were highlighted to journalists.\n\"I've lost endless hours of sleep, felt isolated. It's been horrible, not to mention having an accusation like that over my head,\" one of the men told BBC News.\nMeta declined to comment.\nBBC News has been contacted by more than 100 people who claim to have been wrongly banned by Meta.\nSome talk of a loss of earnings after being locked out of their business pages, while others highlight the pain of no longer having access to years of pictures and memories. Many point to the impact it has had on their mental health.\nOver 27,000 people have signed a petition that accuses Meta's moderation system, powered by artificial intelligence, external (AI), of falsely banning accounts and then having an appeal process that is unfit for purpose.\nThousands of people are also in Reddit forums dedicated to the subject, and many users have posted on social media about being banned.\nMeta has previously acknowledged a problem with Facebook Groups but denied its platforms were more widely affected.\n'Outrageous and vile'\nThe BBC has changed the names of the people in this piece to protect their identities.\nDavid, from Aberdeen in Scotland, was suspended from Instagram on 4 June. He was told he had not followed Meta's community standards on child sexual exploitation, abuse and nudity, external.\nHe appealed that day, and was then permanently disabled on Instagram and his associated Facebook and Facebook Messenger accounts.\nDavid found a Reddit thread, where many others were posting that they had also been wrongly banned over child sexual exploitation.\n\"We have lost years of memories, in my case over 10 years of messages, photos and posts - due to a completely outrageous and vile accusation,\" he told BBC News.\nHe said Meta was \"an embarrassment\", with AI-generated replies and templated responses to his questions. He still has no idea why his account was banned.\n\"I've lost endless hours of sleep, extreme stress, felt isolated. It's been horrible, not to mention having an accusation like that over my head.\n\"Although you can speak to people on Reddit, it is hard to go and speak to a family member or a colleague. They probably don't know the context that there is a ban wave going on.\"\nThe BBC raised David's case to Meta on 3 July, as one of a number of people who claimed to have been wrongly banned over child sexual exploitation. Within hours, his account was reinstated.\nIn a message sent to David, and seen by the BBC, the tech giant said: \"We're sorry that we've got this wrong, and that you weren't able to use Instagram for a while. Sometimes, we need to take action to help keep our community safe.\"\n\"It is a massive weight off my shoulders,\" said David.\nFaisal was banned from Instagram on 6 June over alleged child sexual exploitation and, like David, found his Facebook account suspended too.\nThe student from London is embarking on a career in the creative arts, and was starting to earn money via commissions on his Instagram page when it was suspended. He appealed after feeling he had done nothing wrong, and his account was then banned a few minutes later.\nHe told BBC News: \"I don't know what to do and I'm really upset.\n\"[Meta] falsely accuse me of a crime that I have never done, which also damages my mental state and health and it has put me into pure isolation throughout the past month.\"\nHis case was also raised with Meta by the BBC on 3 July. About five hours later, his accounts were reinstated. He received the exact same email as David, with the apology from Meta.\nHe told BBC News he was \"quite relieved\" after hearing the news. \"I am trying to limit my time on Instagram now.\"\nFaisal said he remained upset over the incident, and is now worried the account ban might come up if any background checks are made on him.\nA third user Salim told BBC News that he also had accounts falsely banned for child sexual exploitation violations.\nHe highlighted his case to journalists, stating that appeals are \"largely ignored\", business accounts were being affected, and AI was \"labelling ordinary people as criminal abusers\".\nAlmost a week after he was banned, his Instagram and Facebook accounts were reinstated.\nWhat's gone wrong?\nWhen asked by BBC News, Meta declined to comment on the cases of David, Faisal, and Salim, and did not answer questions about whether it had a problem with wrongly accusing users of child abuse offences.\nIt seems in one part of the world, however, it has acknowledged there is a wider issue.\nThe BBC has learned that the chair of the Science, ICT, Broadcasting, and Communications Committee at the National Assembly in South Korea, said last month that Meta had acknowledged the possibility of wrongful suspensions, external for people in her country.\nDr Carolina Are, a social media researcher at Northumbria University's Centre for Digital Citizens, said it was hard to know what the root of the problem was because Meta was not being open about it.\nHowever, she suggested it could be due to recent changes to the wording of some its community guidelines and an ongoing lack of a workable appeal process.\n\"Meta often don't explain what it is that triggered the deletion. We are not privy to what went wrong with the algorithm,\" she told BBC News.\nIn a previous statement, Meta said: \"We take action on accounts that violate our policies, and people can appeal if they think we've made a mistake.\"\nMeta, in common with all big technology firms, have come under increased pressure in recent years from regulators and authorities to make their platforms safe spaces.\nMeta told the BBC it used a combination of people and technology to find and remove accounts that broke its rules, and was not aware of a spike in erroneous account suspension.\nMeta says its child sexual exploitation policy, external relates to children and \"non-real depictions with a human likeness\", such as art, content generated by AI or fictional characters.\nMeta also told the BBC a few weeks ago it uses technology to identify potentially suspicious behaviours, external, such as adult accounts being reported by teen accounts, or adults repeatedly searching for \"harmful\" terms.\nMeta states that when it becomes aware of \"apparent child exploitation\", it reports it to the National Center for Missing and Exploited Children (NCMEC) in the US. NCMEC told BBC News it makes all of those reports available to law enforcement around the world.\n- Published7 January\nSign up for our Tech Decoded newsletter to follow the world's top tech stories and trends. Outside the UK? Sign up here."
    },
    {
      "url": "https://about.fb.com/news/2025/07/expanding-teen-account-protections-child-safety-features/",
      "text": "At Meta, we work to protect young people from both direct and indirect harm. Our efforts range from Teen Accounts, which are designed to give teens age-appropriate experiences and prevent unwanted contact, to our sophisticated technology that finds and removes exploitative content.\nToday, we\u2019re announcing a range of updates to bolster these efforts, and we\u2019re sharing new data on the impact of our latest safety tools.\nProtecting Teens from Potentially Unsafe or Unwanted Contact\nWe\u2019ve added new safety features to DMs in Teen Accounts to give teens more context about the accounts they\u2019re messaging and help them spot potential scammers. Now, teens will see new options to view safety tips and block an account, as well as the month and year the account joined Instagram, all prominently displayed at the top of new chats.\nWe\u2019ve also launched a new block and report option in DMs, so that people can take both actions together. While we\u2019ve always encouraged people to both block and report, this new combined option will make this process easier, and help make sure potentially violating accounts are reported to us, so we can review and take action.\nThese new features complement the Safety Notices we show to remind people to be cautious in private messages and to block and report anything that makes them uncomfortable \u2013 and we\u2019re encouraged to see teens responding to them. In June alone, they blocked accounts 1 million times and reported another 1 million after seeing a Safety Notice.\nIn June, teens and young adults also saw our new Location Notice on Instagram 1 million times, with 1 in 10 tapping on the notice to learn more about the steps they could take. Our Location Notice lets people know when they\u2019re chatting with someone who may be in a different country, and is designed to help protect people from potential sextortion scammers who often misrepresent where they live.\nSince rolling out our nudity protection feature globally, 99% of people \u2013 including teens \u2013 have kept it turned on, and in June, over 40% of blurred images received in DMs stayed blurred, significantly reducing exposure to unwanted nudity. Nudity protection, on by default for teens, also encourages people to think twice before forwarding suspected nude images, and in May people decided against forwarding around 45% of the time after seeing this warning.\nBringing Some Teen Account Protections to Adult-Managed Accounts Primarily Featuring Children\nWe\u2019re also strengthening our protections for accounts run by adults that primarily feature children. These include adults who regularly share photos and videos of their children, and adults \u2013 such as parents or talent managers \u2013 who run accounts that represent teens or children under 13. While you have to be at least 13 to use Instagram, we allow adults to run accounts representing children under 13 if it\u2019s clear in the account bio that they manage the account. If we become aware that the account is being run by the child themselves, we\u2019ll remove it.\nWhile these accounts are overwhelmingly used in benign ways, unfortunately there are people who may try to abuse them, leaving sexualized comments under their posts or asking for sexual images in DMs, in clear violation of our rules. Today we\u2019re announcing steps to help prevent this abuse.\nWe\u2019re extending some Teen Account protections to adult-managed accounts that primarily feature children. These include automatically placing these accounts into our strictest message settings to prevent unwanted messages, and turning on Hidden Words, which filters offensive comments. We\u2019ll show these accounts a notification at the top of their Instagram Feed, letting them know we\u2019ve updated their safety settings, and prompting them to review their account privacy settings too. These changes will roll out in the coming months.\nWe also want to prevent potentially suspicious adults, for example adults who have been blocked by teens, from finding these accounts in the first place. We\u2019ll avoid recommending them to potentially suspicious adults and vice versa, make it harder for them to find each other in Search and hide comments from potentially suspicious adults on their posts. This builds on last year\u2019s update to stop allowing accounts primarily featuring children to offer subscriptions or receive gifts.\nTaking Action on Harmful Accounts Across the Internet\nIn addition to these new protections, we\u2019re also continuing to take aggressive action on accounts that break our rules. Earlier this year, our specialist teams removed nearly 135,000 Instagram accounts for leaving sexualized comments or requesting sexual images from adult-managed accounts featuring children under 13. We also removed an additional 500,000 Facebook and Instagram accounts that were linked to those original accounts. We let people know that we\u2019d removed an account that had interacted inappropriately with their content, encouraging them to be cautious and to block and report.\nPeople who seek to exploit children don\u2019t limit themselves to any one platform, which is why we also shared information about these accounts with other tech companies through the Tech Coalition\u2019s Lantern program."
    },
    {
      "url": "https://www.bbc.co.uk/news/technology-65855333?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
      "text": "What is AI, how does it work and why are some people concerned about it?\n- Published\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\nWhat is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\nWhat is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\nWhy is AI controversial?\nWhile acknowledging AI's potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the \"godfathers\" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow \"AI godfather\", Yann LeCun.\nCritics also highlight the tech's potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to \"hallucinate\" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple's AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to \"cheat\" on assignments, or employees \"smuggling\" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Bj\u00f6rn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement, external in October 2024 calling AI a \"major, unjust threat\" to their livelihoods.\nHow does AI effect the environment?\nIt is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands.\nCreating the powerful computer chips needed to run AI programmes requires lots of power and water.\nDemand for generative AI services has also meant an increase in the number of data centres which power them.\nThese huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool.\nSome large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling.\nHowever, some experts and activists fear that AI will worsen water supply problems.\nThe BBC was told in February that government plans to make the UK a \"world leader\" in AI could put already stretched supplies of drinking water under strain.\nIn September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought.\nAre there laws governing AI?\nSome governments have already introduced rules governing how AI operates.\nThe EU's Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement or elections. It bans some AI use altogether.\nGenerative AI developers in China are required to safeguard citizens' data, and promote transparency and accuracy of information. But they are also bound by the country's strict censorship laws.\nIn the UK, Prime Minister Sir Keir Starmer has said the government \"will test and understand AI before we regulate it\".\nBoth the UK and US have AI Safety Institutes that aim to identify risks and evaluate advanced AI models.\nIn 2024 the two countries signed an agreement to collaborate on developing \"robust\" AI testing methods.\nHowever, in February 2025, neither country signed an international AI declaration which pledged an open, inclusive and sustainable approach to the technology.\nSeveral countries including the UK are also clamping down on use of AI systems to create deepfake nude imagery and child sexual abuse material.\nSign up for our Tech Decoded newsletter to follow the world's top tech stories and trends. Outside the UK? Sign up here."
    },
    {
      "url": "https://www.bbc.co.uk/news/articles/cvgnp9ykm3xo?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
      "text": "'There is a problem': Facebook and Instagram users complain of account bans\n- Published\nFacebook and Instagram users have been contacting the BBC complaining about having their accounts arbitrarily banned, and struggling to get them reinstated.\nLast week Meta - which owns the platforms - acknowledged a \"technical error\" which it said was causing the wrongful suspension of some Facebook Groups.\nSince then, people who use what is the world's biggest social media company have been getting in touch with the BBC to describe the impact it is having on them - and say the problem goes much wider than Meta has indicated.\nSome say they have been shut out of pages that are key to their working lives, while others highlight the digital connections to loved ones that have been cut.\nThere is also frustration that - despite Meta saying it is fixing the problem - there is often no human to speak to about an issue they suspect is caused by moderation decisions powered by artificial intelligence (AI).\nThey have also described how Instagram accounts have been affected, despite Meta saying it does not have evidence of a problem on its platforms more widely.\nMore than 25,000 people have signed a petition in the last few weeks which says the problem is being experienced across Facebook, Instagram, and WhatsApp.\nThousands of people are in Reddit forums dedicated to the subject, many users are posting on social media about being banned by Meta, and some say they plan on taking a class action lawsuit against the social media giant.\nHere's what people have told the BBC about what it means to them to be locked out of their social media accounts.\n'More than just an app'\nThe online petition about this issue was started by Brittany Watson, a 32-year-old from Ontario, in Canada.\nShe decided to act after her Facebook account was disabled for nine days in May before it was reinstated. She claims her page was cancelled over \"account integrity, external\", and Meta has not provided her with any answers as to why.\n\"Facebook wasn't just an app for me,\" she told BBC News. \"It was where I kept years of memories, connected with family and friends, followed pages that brought me joy, and found support communities for mental health.\"\nWhen her account was banned, Brittany said she felt \"ashamed, embarrassed and anxiety-stricken\".\n\"The weight of feeling exiled from everyone takes a pretty strong hold on you,\" she added.\nShe quickly discovered she wasn't the only one affected - thousands have signed the petition she started.\n\"There is a problem - it is personal accounts, it is business accounts, Facebook pages and Groups. I can't believe they [Meta] are only saying it is just Groups.\"\nMeta has told BBC News that it takes action on accounts that violate our policies, and \"people can appeal if they think we've made a mistake\".\nIt has also outlined in detail how it moderates accounts using a combination of people and technology to find and remove accounts that broke its rules.\nIt says it is not aware of a spike in erroneous account suspension.\n'There is no customer service'\nAnother user who recently lost access to his Facebook account is John Dale, a former journalist who runs a local news group in west London with over 5,000 members.\nHis account was first suspended on 30 May for breaking community standards, and the page he administers has briefly come back twice since then.\nHe has no idea why.\nAs he was the only administrator of the group, he currently cannot approve new posts. Additionally, his own posts have been removed from the group.\n\"It's frozen in time, [while] quite a lot of material has been deleted,\" he told BBC News.\nMr Dale is appealing his suspension, but if he loses his appeal his account will be permanently deleted. He says he has received limited information on why he was banned.\n\"There is no customer service,\" he said.\n'My income has taken a huge hit'\nMichelle DeMelo, who is also from Canada, says she has suffered financially since her Facebook and Instagram accounts were suspended in the middle of June.\nThey were reinstated on Wednesday, a day after the BBC contacted Meta about her case.\nShe runs several pages, with some associated with her businesses in digital marketing, and also uses Facebook Marketplace to buy and sell goods.\nAll her accounts are linked, so when her personal Instagram page was suspended for \"violating the terms\" of a Meta policy, it triggered all of her pages to be suspended.\n\"My income's taken a huge hit in the past couple of weeks,\" she told BBC News from her home in Niagara Falls.\n\"People think I blocked them or think something happened to me.\"\nMichelle can't think of anything which triggered the suspension, and is worried about the reputational hit as some of her clients were left unable to contact her.\nShe told the BBC she was relieved that after \"weeks of complete confusion and uncertainty\" her accounts had now been abruptly restored.\nBut she said the episode had been very badly handled.\n\"It's insulting that a company as powerful as Meta, built by its users, offers no real human support or clear pathways for resolution in these situations.\"\nAI suspicions\nAnother person left frustrated at Meta's moderation policies and its appeal process is Sam Tall, a 21-year-old from Bournemouth.\nHe told BBC News that he discovered his Instagram page was suspended last week for breaching \"community standards\".\nHe decided to appeal, and it was rejected two minutes later - making Sam suspect the process was entirely handled by AI.\n\"There is absolutely no way that was seen by a human,\" he told BBC News.\n\"All the memories, all my friends who I can no longer talk to because I don't have them on any other platform - gone\".\nAs his Facebook account was linked, that was removed too.\n\"No explanation. I'm a bit baffled, to be honest.\"\nSam says it is time for some serious action from Meta - and not just for his sake.\n\"If I know it is quite a few people, then there is a chance of Meta waking up and realising 'oh, this actually is an issue - let's reinstate them all.'\"\nGet in touch\nHave you been affected by the issues raised in this story?\nSign up for our Tech Decoded newsletter to follow the world's top tech stories and trends. Outside the UK? Sign up here."
    },
    {
      "url": "https://www.bbc.co.uk/news/articles/c3r9nwgvwy3o?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Blink%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
      "text": "Meta admits wrongly suspending Facebook Groups but denies wider problem\n- Published\nMeta says it is \"fixing\" a problem which has led to Facebook Groups being wrongly suspended - but denied there is a wider issue on its platforms.\nIn online forums, Group administrators say they have received automated messages stating, incorrectly, that they had violated policies so their Groups had been deleted.\nSome Instagram users have complained of similar problems with their own accounts, with many blaming Meta's artificial intelligence (AI) systems.\nMeta has acknowledged a \"technical error\" with Facebook Groups, but says it has not seen evidence of a significant increase in incorrect enforcement of its rules on its platforms more widely.\nOne Facebook group, where users share memes about bugs, was told it did not follow standards on \"dangerous organizations or individuals,\" according to a post by its founder.\nThe group, which has more than 680,000 members, was removed but has now been restored.\nAnother admin, who runs a group on AI which has 3.5 million members, posted on Reddit to say his group and his own account had been suspended for a few hours, with Meta telling him later: \"Our technology made a mistake suspending your group.\"\nThousands of signatures\nIt comes as Meta faces questions from thousands of people over the mass banning or suspension of accounts on Facebook and Instagram.\nA petition entitled \"Meta wrongfully disabling accounts with no human customer support\" has gathered almost 22,000 signatures at the time of writing on change.org.\nMeanwhile, a Reddit thread dedicated to the issue features many people sharing their stories of being banned in recent months.\nSome have posted about losing access to pages with significant sentimental value, while others highlight they had lost accounts linked to their businesses.\nThere are even claims that users have been banned after being accused by Meta of breaching its policies on child sexual exploitation.\nUsers have blamed Meta's AI moderation tools, adding it is almost impossible to speak to a person about their accounts after they have been suspended or banned.\nBBC News has not independently verified those claims.\nIn a statement, Meta said: \"We take action on accounts that violate our policies, and people can appeal if they think we've made a mistake.\"\nIt said it used a combination of people and technology to find and remove accounts that broke its rules, and was not aware of a spike in erroneous account suspension.\nInstagram states on its website, external AI is \"central to our content review process\". It says AI can detect and remove content against its community standards before anyone reports it, while content is sent to human reviewers on certain occasions.\nMeta adds, external accounts may be disabled after one severe violation, such as posting child sexual exploitation content.\nThe social media giant also told the BBC it uses a combination of technology and people to find and remove accounts that break its rules, and shares data about what action it takes in its Community Standards Enforcement Report, external.\nIn its last version, covering January to March this year, Meta said it took action on 4.6m instances of child sexual exploitation - the lowest since the early months of 2021. The next edition of the transparency report is due to be published in a few months.\nMeta says its child sexual exploitation policy, external relates to children and \"non-real depictions with a human likeness\", such as art, content generated by AI or fictional characters.\nMeta also told the BBC it uses technology to identify potentially suspicious behaviours, external, such as adult accounts being reported by teen accounts, or adults repeatedly searching for \"harmful\" terms.\nThis could result in those accounts not being able to contact young people in future, or having their accounts removed completely.\nGet in touch\nIf you are in a Facebook Group that has been affected, tell us about the experience.\nSign up for our Tech Decoded newsletter to follow the world's top tech stories and trends. Outside the UK? Sign up here."
    }
  ],
  "argos_summary": "Many Instagram users have expressed confusion and distress after being wrongfully suspended for allegedly breaching child sexual exploitation rules, with reports indicating that tens of thousands have faced similar issues. Users have lost access to cherished memories and business accounts, leading to significant personal and financial repercussions. Despite Meta acknowledging some technical errors related to Facebook Groups, it denies a broader issue exists on its platforms, while users claim that the AI moderation system is flawed and lacks adequate human oversight.",
  "argos_id": "LD9CCP261"
}