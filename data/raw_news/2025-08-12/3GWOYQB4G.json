{
  "url": "https://www.zdnet.com/article/will-ai-replace-all-software-why-gpt-5-emboldens-the-doomsayers/",
  "authorsByline": "Tiernan Ray",
  "articleId": "182832d508554ea4927bd95cb2965cbc",
  "source": {
    "domain": "zdnet.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://www.zdnet.com/a/img/resize/fcc558311e1a1aed23a29e46e9aa9f4d34e5ef4a/2025/08/12/adc0dfe5-fb76-4888-88bb-1184f72cf874/colorcode5555gettyimages-485008230.jpg?auto=webp&fit=crop&height=675&width=1200",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-13T02:00:00+00:00",
  "addDate": "2025-08-13T02:09:43.522269+00:00",
  "refreshDate": "2025-08-13T02:09:43.522271+00:00",
  "score": 1.0,
  "title": "Will AI replace all software? Why GPT-5 emboldens the doomsayers",
  "description": "The question on Wall Street, and inside many IT shops, is whether anyone will need to buy software in the future if AI can just code it all automatically.",
  "content": "\u2022 AI models' coding ability is still very mixed.\n\u2022 Software executives are positioning their firms to be survivors.\n\nThe modern software industry has existed for 50 years, since the founding of Microsoft in 1975.\n\n\"Bill built the first software company in the industry,\" said late Apple co-founder and CEO Steve Jobs in 2007, referring to Microsoft co-founder Bill Gates. \"Bill was really focused on software before almost anybody else had a clue that it was really the software.\"\n\nAlso: Microsoft at 50: Its incredible rise, 15 lost years, and stunning comeback - in 4 charts\n\nNow, a notion is rapidly gaining steam on Wall Street that commercial software vendors may be doomed by the rise of artificial intelligence.\n\nWith their rapid improvement in code generation, so-called frontier AI programs such as OpenAI's GPT-5 can potentially automate the creation of all software code. This could enable corporations that buy software from packaged software vendors to create all their code internally and stop paying the software vendors.\n\nAlso: AI agents will match 'good mid-level' engineers this year, says Mark Zuckerberg\n\nSpeculation has been fueled by the views of tech's biggest players, including Mark Zuckerberg of Meta Platforms, who in January told Wall Street analysts during his company's earnings conference call that \"2025 will be the year when it becomes possible to build an AI engineering agent that has coding and problem-solving abilities of around a good mid-level engineer.\"\n\nThat view has filtered down to the analysts themselves, whose job is to compile forecasts of how much money the industry may make.\n\nIn a report last Friday, stock analyst Gil Luria of the boutique securities firm D.A. Davidson said investors are asking, \"Does GPT-5 signal the beginning of the end for software?\"\n\nLuria, who rates the shares of publicly traded software companies including Snowflake, Datadog, JFrog, and others, notes that the day after GPT-5 was announced, many of the stocks he covers fell sharply.\n\nAlso: OpenAI's GPT-5 is now free for all: How to access and everything else we know\n\nThe value of commercial software to the software buyer, writes Luria, is always based on the answer to a single question: \"How many people would I not need if I bought the software?\" In other words, packaged software increases productivity by providing a tool for getting more done with fewer people.\n\nLuria thinks packaged software still has a role, especially programs that help manage code repositories, such as Datadog's DevOps.\n\nBut, he writes, buyers' sense of the productivity of packaged applications \"could change if AI agents start carving off tasks from employees.\"\n\nAlso: The best AI for coding (including a new winner - and what not to use)\n\nAlready, he observes, \"the notion that application software will not endure has paralyzed many customers from making long-term commitments\" to software contracts.\n\nIt matters little that GPT-5, as ZDNET's David Gewirtz relates in his testing, is actually a step backward in coding ability. Whatever the shortcomings of an individual frontier model, Wall Street is increasingly impressed with the overall ability of artificial intelligence models to generate code.\n\nEvery new model, from OpenAI or any of its competitors, will doubtless advance that general capacity, at least incrementally. As Gewirtz also notes, GPT-5 did \"provide a jump\" in the analysis of code repositories, even if it wasn't \"a game-changer.\"\n\nThe sense that something is changing is held by some of the top executives in the tech industry. Hock Tan, the legendary CEO of chip maker Broadcom, has been telling people that after spending over $100 billion in the past decade buying software makers VMware, Symantec, and CA Technologies, he no longer intends to buy any software makers.\n\n\"Hock Tan from Broadcom just did a meeting with a couple of my colleagues last week,\" recalls Paul Wick, a fund manager who manages $17 billion for mutual fund giant Columbia Seligman, and whose funds own Broadcom stock.\n\nAlso: I tested GPT-5's coding skills, and it was so bad that I'm sticking with GPT-4o (for now)\n\nAccording to Wick, who was interviewed in the investment newsletter The Technology Letter last month, Tan told Wick's associates \"that Broadcom was not going to be making any more software acquisitions because of his concerns that AI had the potential over time to significantly damage the value of software\" by automating all that would ordinarily be packaged applications.\n\nAsked if he shared the view, Wick replied, \"I think down the road, 10 years from now, that's a very real risk. It's hard to say.\"\n\nTan's view is not to be taken lightly. His firm helps Google build its custom \"TPU\" chips to process AI, so he has good access to industry trends.\n\nSoftware makers are positioning themselves to be survivors\n\nSoftware executives, for their part, are positioning their companies to be survivors, even if they are skeptical of the premise of the demise of commercial software.\n\nAlso: GPT-5 bombed my coding tests, but redeemed itself with code analysis\n\n\"I think the companies that learn how to leverage AI will out-compete the ones that don't,\" said Spenser Skates, founder and CEO of software maker Amplitude, in an interview with The Technology Letter last week.\n\n\"There will be a need for software,\" said Skates. \"Someone is still going to need to tell the AI what to do, and create it, and be an expert in the problem.\"\n\nAdded Skates, \"We actually have this joke internally\" at Amplitude. \"AI will replace my job and yours, and all of our jobs, before Amplitude doesn't become valuable.\"",
  "medium": "Article",
  "links": [
    "https://www.zdnet.com/article/microsoft-at-50-its-incredible-rise-15-lost-years-and-stunning-comeback-in-four-charts/",
    "https://www.zdnet.com/article/ai-agents-will-match-good-mid-level-engineers-this-year-says-mark-zuckerberg/",
    "https://www.thetechnologyletter.com/the-posts/seligmans-paul-wick-likes-the-midyear-setup",
    "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
    "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
    "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/",
    "https://www.zdnet.com/article/openais-gpt-5-is-now-free-for-all-how-to-access-and-everything-else-we-know/",
    "https://www.zdnet.com/article/openais-gpt-5-is-now-free-for-all-how-to-access-and-everything-else-we-know/#link={%22role%22:%22standard%22,%22href%22:%22https://www.zdnet.com/article/openais-gpt-5-is-now-free-for-all-how-to-access-and-everything-else-we-know/%22,%22target%22:%22%22,%22absolute%22:%22%22,%22linkText%22:%22GPT-5%22}",
    "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
    "https://www.zdnet.com/article/gpt-5-bombed-my-coding-tests-but-redeemed-itself-with-code-analysis/",
    "https://www.zdnet.com/article/i-tested-gpt-5s-coding-skills-and-it-was-so-bad-that-im-sticking-with-gpt-4o-for-now/"
  ],
  "labels": [
    {
      "name": "Non-news"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "Software makers",
      "weight": 0.10086829
    },
    {
      "name": "packaged software",
      "weight": 0.099925876
    },
    {
      "name": "commercial software",
      "weight": 0.09911259
    },
    {
      "name": "application software",
      "weight": 0.09842882
    },
    {
      "name": "software",
      "weight": 0.09827588
    },
    {
      "name": "Software executives",
      "weight": 0.09768446
    },
    {
      "name": "software maker Amplitude",
      "weight": 0.097663544
    },
    {
      "name": "packaged software vendors",
      "weight": 0.09656471
    },
    {
      "name": "commercial software vendors",
      "weight": 0.09585489
    },
    {
      "name": "software makers VMware",
      "weight": 0.09509511
    }
  ],
  "topics": [
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.8818359375
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.8798828125
    },
    {
      "name": "/Computers & Electronics/Software/Business & Productivity Software",
      "score": 0.5791015625
    },
    {
      "name": "/Computers & Electronics/Programming/Other",
      "score": 0.374267578125
    }
  ],
  "sentiment": {
    "positive": 0.1568098,
    "negative": 0.5169286,
    "neutral": 0.32626164
  },
  "summary": "The rise of artificial intelligence (AI) is gaining momentum on Wall Street, with concerns that commercial software vendors may be doomed by the rise of AI. These include OpenAI's GPT-5, which can potentially automate the creation of all software code, potentially leading corporations that buy software from packaged software vendors to create all their code internally and stop paying the software vendors. Stock analyst Gil Luria of D.A. Davidson noted that investors are asking if GPT 5 signals the beginning of the end for software. Speculation has been fueled by tech's biggest players, including Mark Zuckerberg of Meta Platforms, who predicts that 2025 will be the year when it becomes possible to build an AI engineering agent with coding and problem-solving abilities of around a good mid-level engineer. Luria also believes that packaged software still has a role, especially programs that manage code repositories.",
  "shortSummary": "OpenAI's GPT-5 raises concerns about the potential impact on software by automating code creation, causing significant losses for software companies and prompting industry leaders to shift focus.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "8ebe22ec29444a5fab1a17e0d275217e",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.zdnet.com/article/the-best-ai-for-coding-in-2025-including-a-new-winner-and-what-not-to-use/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nThe best AI for coding in 2025 (including a new winner - and what not to use)\nI've been around technology long enough that very little excites me, and even less surprises me. But shortly after OpenAI's ChatGPT was released, I asked it to write a WordPress plugin for my wife's e-commerce site. When it did, and the plugin worked, I was indeed surprised.\nThat was the beginning of my deep exploration into chatbots and AI-assisted programming. Since then, I've subjected 14 large language models (LLMs) to four real-world tests.\nAlso: Apple's secret sauce is exactly what AI is missing\nUnfortunately, not all chatbots can code alike. It's been a little over two years since that first test, and even now, four of the 13 LLMs I tested can't create working plugins.\nThe short version\nIn this article, I'll show you how each LLM performed against my tests. There are now five chatbots I recommend you use.\nTwo of them, ChatGPT Plus and Perplexity Pro, cost $20 per month each. The free versions of the same chatbots do well enough that you could probably get by without paying. Two other recommended products are from Google and Microsoft. Google's Gemini Pro 2.5 is free, but you're limited to so few queries that you really can't use it without paying.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nMicrosoft has several Copilot licenses, which can get pricey, but I used the free version with surprisingly good results. The final one, Claude 4 Sonnet, is the free version of Claude. Oddly enough, the free version beat the paid-for version, so we're not recommending Claude 4 Opus.\nBut the rest, whether free or paid, are not so great. I won't risk my programming projects with them or recommend that you do, until their performance improves.\nI've written lots about using AIs to help with programming. Unless it's a small, simple project like my wife's plugin, AIs can't write entire apps or programs. But they excel at writing a few lines and are not bad at fixing code.\nRather than repeat everything I've written, go ahead and read this article: How to use ChatGPT to write code.\nIf you want to understand my coding tests, why I've chosen them, and why they're relevant to this review of the 13 LLMs, read this article: How I test an AI chatbot's coding ability.\nThe AI coding leaderboard\nLet's start with a comparative look at how the chatbots performed, as of this installment of our best-of roundup:\nNext, let's look at each chatbot individually. I'm back up to discussing 14 chatbots, because we're splitting out Claude 4 Sonnet and Claude 4 Opus as separate tests. GPT-4 is no longer included since OpenAI has sunsetted that LLM. Ready? Let's go.\n- Passed all tests\n- Solid coding results\n- Mac app\n- Hallucinations\n- No Windows app yet\n- Sometimes uncooperative\n- Price: $20/mo\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nChatGPT Plus with GPT-4o passed all my tests. One of my favorite features is the availability of a dedicated app. When I test web programming, I have my browser set on one thing, my IDE open, and the ChatGPT Mac app running on a separate screen.\nAlso: I put GPT-4o through my coding tests and it aced them - except for one weird result\nIn addition, Logitech's Prompt Builder, which can be activated with a mouse button, can be set up to utilize the upgraded GPT-4o and connect to your OpenAI account, allowing for a simple thumb tap to run a prompt, which is very convenient.\nThe only thing I didn't like was that one of my GPT-4o tests resulted in a dual-choice answer, and one of those answers was wrong. I'd rather it just gave me the correct answer. Even so, a quick test confirmed which answer would work. However, that issue was a bit annoying.\n- Multiple LLMs\n- Search criteria displayed\n- Good sourcing\n- Email-only login\n- No desktop app\n- Price: $20/mo\n- LLM: GPT-4o, Claude 3.5 Sonnet, Sonar Large, Claude 3 Opus, Llama 3.1 405B\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 4 of 4\nI seriously considered listing Perplexity Pro as the best overall AI chatbot for coding, but one failing kept it out of the top slot: how you log in. Perplexity doesn't use a username/password or passkey and doesn't have multi-factor authentication. All the tool does is email you a login PIN. The AI doesn't have a separate desktop app, as ChatGPT does for Macs.\nWhat sets Perplexity apart from other tools is that it can run multiple LLMs. While you can't set an LLM for a given session, you can easily go into the settings and choose the active model.\nAlso: Can Perplexity Pro help you code? It aced my programming tests - thanks to GPT-4\nFor programming, you'll probably want to stick to GPT-4o, because that model aced all our tests. But it might be interesting to cross-check your code across the different LLMs. For example, if you have GPT-4o write some regular expression code, you might consider switching to a different LLM to see what that model thinks of the generated code.\nAs we'll see below, most LLMs are unreliable, so don't take the results as gospel. However, you can use the results to check your original code. It's sort of like an AI-driven code review.\nJust don't forget to switch back to GPT-4o.\n- Price: Free for limited use, then token-based pricing\n- LLM: Gemini Pro 2.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThe last time I looked at Gemini, it failed miserably. Not quite as bad as Copilot at the time, but bad. Gemini Pro 2.5, however, has performed quite admirably. My only real issue with it is access. I found myself cut off from the free version after only running two of the four tests.\nAlso: Gemini Pro 2.5 is a stunningly capable coding assistant - and a big threat to ChatGPT\nI waited a day and then ran the third test, and got cut off again. Finally, on the third day, I ran my fourth test. Obviously, you can't do any real programming if you can only ask one or two questions before being shut down. So, if you sign up with Gemini Pro 2.5, be aware that Google charges by tokens (basically, the amount of AI you use). That can make it quite difficult to predict your expenses.\n- Price: Free for basic Copilot, or fees for other Copilot licenses\n- LLM: Undisclosed\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nIn all my previous analyses of Microsoft Copilot, the results were the worst of the LLMs. Copilot got nothing right. It was astonishing how bad it was. But I said then that, \"The one positive thing is that Microsoft always learns from its mistakes. So, I'll check back later and see if this result improves.\"\nAlso: I retested Microsoft Copilot's AI coding skills in 2025 and now it's got serious game\nAnd boy, did it ever. This time out, Microsoft passed all four of my tests. Even better, it did this with the free version of Copilot. Yes, Microsoft has many paid programs for Copilot, but if you want to give it the AI spin, point yourself to Copilot and use it.\n- Price: Free\n- LLM: Claude 4\n- Desktop browser interface: No\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 4 of 4\nThis is one of those times when AI implementations can be real head-scratchers. In our previous tests, Claude 4 Sonnet finished at the bottom of the barrel, failing all four of our tests. This time, however, Sonnet passed every test. So, what's the head-scratcher? Opus, the Claude 4 model, which is a fee-paid version, did not do as well: it failed half the tests.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nSo, yes. The free version worked like a champ. And the one you're paying anywhere from $20 to $250 a month for, depending on the plan? Well, that one failed half of the tests. Go figure.\n- Different LLM than ChatGPT\n- Good descriptions\n- Free access\n- Only available in browser mode\n- Free access likely only temporary\n- Price: Free (for now)\n- LLM: Grok-1\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4\nI have to say, Grok surprised me. I guess I didn't have high hopes for an LLM that appeared tacked on to the social network formerly known as Twitter. However, X is now owned by Elon Musk, and two of Musk's companies, Tesla and SpaceX, have towering AI capabilities.\nIt's unclear how much Tesla and SpaceX AI DNA is in Grok, but we can assume there will likely be more work. As of now, Grok is the only LLM not based on OpenAI LLMs that made it into the recommended list.\nAlso: X's Grok did surprisingly well in my AI coding tests\nGrok did make one mistake, but it was a relatively minor one that a slightly more comprehensive prompt could easily remedy. Yes, it failed the test. But by passing the others and even doing an almost perfect job on the one it passed, Grok earned itself a spot as a contender.\nStay tuned. This is an AI to watch.\n- Free\n- Passed most tests\n- Prompt throttling\n- Could cut you off in the middle of whatever you're working on\n- Price: Free\n- LLM: GPT-4o, GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: Yes\n- Dedicated Windows app: No\n- Multi-factor authentication: Yes\n- Tests passed: 3 of 4 in GPT-3.5 mode\nChatGPT is available to anyone for free. While both the Plus and free versions support GPT-4o, which passed all my programming tests, the free app has limitations.\nOpenAI treats free ChatGPT users as if they're in the cheap seats. If traffic is high or the servers are busy, the free version of ChatGPT will only make GPT-3.5 available to free users. The tool will only allow you a certain number of queries before it downgrades or shuts you off.\nAlso: How to use ChatGPT to write code - and my favorite trick to debug what it generates\nI've had several occasions when the free version of ChatGPT effectively told me I'd asked too many questions.\nChatGPT is a great tool, as long as you don't mind it shutting down. Even GPT-3.5 did better on the tests than all the other chatbots, and the test it failed was for a fairly obscure programming tool produced by a lone programmer in Australia.\nSo, if budget is important to you and you can wait when you're cut off, then use ChatGPT for free.\n- Free\n- Passed most tests\n- Range of research tools\n- Limited to GPT-3.5\n- Throttles prompt results\n- Price: Free\n- LLM: GPT-3.5\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nI'm threading a pretty fine needle here, but because Perplexity AI's free version is based on GPT-3.5, the test results were measurably better than the other AI chatbots.\nAlso: 5 reasons why I prefer Perplexity over every other AI chatbot\nFrom a programming perspective, that's pretty much the whole story. However, from a research and organization perspective, my ZDNET colleague Steven Vaughan-Nichols prefers Perplexity over the other AIs.\nHe likes how Perplexity provides more complete sources for research questions, cites its sources, organizes the replies, and offers questions for further searches.\nSo, if you're programming, but also working on other research, consider the free version of Perplexity.\n- Free\n- Open source\n- Efficient resource utilization\n- Weak general knowledge\n- Small ecosystem\n- Limited integrations\n- Price: Free for chatbot, fees for API\n- LLM: DeepSeek MoE\n- Desktop browser interface: Yes\n- Dedicated Mac app: No\n- Dedicated Windows app: No\n- Multi-factor authentication: No\n- Tests passed: 3 of 4\nWhile DeepSeek R1 is the new reasoning hotness from China that has all the pundits punditing, the real power right now (at least according to our tests) is DeepSeek V3. This chatbot passed almost all of our coding tests, doing as well as the (now mostly discontinued) ChatGPT 3.5.\nAlso: I tested DeepSeek's R1 and V3 coding skills - and we're not all doomed (yet)\nWhere DeepSeek V3 fell was in its knowledge of somewhat more obscure programming environments. Still, it beat Google's Gemini, Microsoft's Copilot, and Meta's Meta AI, which is quite an accomplishment. We'll be keeping a close watch on each DeepSeek model, so stay tuned.\nChatbots to avoid for programming help\nI tested 13 LLMs, and nine passed most of my tests this time around. The other chatbots, including a few pitched as great for programming, only passed one of my tests.\nAlso: The five biggest mistakes people make when prompting an AI\nI'm mentioning them here because people will ask, and I did test them thoroughly. Some of these bots are fine for other work, so I'll point you to their general reviews if you're curious about their functionality.\nDeepSeek R1\nUnlike DeepSeek V3, the advanced reasoning version, DeepSeek R1, did not showcase its reasoning capabilities in our programming tests. Unusually, the new failure area was one that's not all that hard, even for a basic AI -- the regular expression code for our string function test.\nAlso: Tech prophet Mary Meeker just dropped a massive report on AI trends - here's your TL;DR\nBut that's why we are running these real-world tests. It's never clear where an AI will hallucinate or just plain fail, and before you go believing all the hype about DeepSeek R1 taking the crown away from ChatGPT, run some programming tests. So far, while I'm impressed with the much-reduced resource utilization and the open-source nature of the product, its coding quality output is inconsistent.\nGitHub Copilot\nGitHub's Copilot integrates quite seamlessly with VS Code. The AI makes asking for coding help quick and productive, especially when working in context. That's why it's so disappointing that the code the AI outputs is often very wrong.\nAlso: I put GitHub Copilot's AI to the test - and it just might be terrible at writing code\nI can't, in good conscience, recommend you use the GitHub Copilot extensions for VS Code. I'm concerned that the temptation will be too great to insert blocks of code without sufficient testing -- and that GitHub Copilot's produced code is not ready for production use. Try again next year.\nClaude 4 Opus\nIn a completely baffling turn of events, the paid-for version of the Claude 4 model, Opus, failed half of my tests. What makes this result baffling is that the free version, Claude 4 Sonnet, passed them all. I don't know what to say apart from AI can be weird.\nAlso: Anthropic's free Claude 4 Sonnet aced my coding tests - but its paid Opus model somehow didn't\nMeta AI\nMeta AI is Facebook's general-purpose AI. As you can see above, it failed three of our four tests.\nAlso: 15 ways AI saved me time at work in 2024 - and how I plan to use it in 2025\nThe AI generated a nice user interface, but with zero functionality. It also found my annoying bug, which is a fairly serious challenge. Given the specific knowledge required to find the bug, I was surprised that the AI choked on a simple regular expression challenge. But it did.\nMeta Code Llama\nMeta Code Llama is Facebook's AI explicitly designed for coding help. It's something you can download and install on your server. I tested the AI running on a Hugging Face AI instance.\nAlso: Can Meta AI code? I tested it against Llama, Gemini, and ChatGPT - it wasn't even close\nWeirdly, even though both Meta AI and Meta Code Llama choked on three of four of my tests, they choked on different problems. AIs can't be counted on to give the same answer twice, but this result was a surprise. We'll see if that changes over time.\nBut I like [insert name here]. Does this mean I have to use a different chatbot?\nProbably not. I've limited my tests to day-to-day programming tasks. None of the bots has been asked to talk like a pirate, write prose, or draw a picture. In the same way we use different productivity tools to accomplish specific tasks, feel free to choose the AI that helps you complete the task at hand.\nThe only issue is if you're on a budget and are paying for a pro version. Then, find the AI that does most of what you want, so you don't have to pay for too many AI add-ons.\nIt's only a matter of time\nThe results of my tests were pretty surprising, especially given the significant improvements by Microsoft and Google. However, this area of innovation is improving at warp speed, so we'll be back with updated tests and results over time. Stay tuned.\nHave you used any of these AI chatbots for programming? What has your experience been? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/gpt-5-bombed-my-coding-tests-but-redeemed-itself-with-code-analysis/",
      "text": "GPT-5 bombed my coding tests, but redeemed itself with code analysis\nZDNET's key takeaways\n- GPT-5 Pro delivers the sharpest, most actionable code analysis.\n- A detail-focused prompt can push base GPT-5 toward Pro results.\n- o3 remains a strong contender despite being a GPT-4 variant.\nWith the big news that OpenAI has released GPT-5, the team here at ZDNET is working to learn about and communicate its strengths and weaknesses. In another article, I put its programming prowess to the test and came up with a less-than-impressive result.\nAlso: I tested GPT-5's coding skills, and it was so bad that I'm sticking with GPT-4o\nWhen Deep Research first appeared with the OpenAI o3 LLM, I was quite impressed with what it could understand from examining a code repository. I wanted to know how well it understood the project just from the available code.\nIn this article, I'm examining how well the three GPT-5 variants do in examining that same code repository. We'll dig in and compare them. The results are quite interesting. Here are the four models.\n- o3: a GPT-4 variant optimized for reasoning.\n- GPT-5: OpenAI's new main ChatGPT model, available to all tiers, including free.\n- GPT-5 Thinking: A variant of GPT-5 that OpenAI says is optimized for \"architectural reflection.\" It is available to $20/mo Plus and $200/mo Pro tiers.\n- GPT-5 Pro: OpenAI's current $200/mo top-tier model, with the highest reasoning and context capabilities.\nI gave all four models the same assignment. I connected them to my private GitHub repository for my open-source free WordPress security plugin and its freemium add-on modules, selected Deep Research, and gave them this prompt.\nExamine the repository and learn its structure and architecture. Then report back what you've learned.\nFor those models that asked to choose areas of detail about what I wanted, I gave them this prompt.\nEverything you can tell me, be as comprehensive as possible.\nAs you can see, I didn't provide any context other than the source code repo itself. That code has a README file, as well as comments throughout the code, so there was some English-language context. But most of the context has to be derived from the folder structure, file names, and code itself.\nAlso: The best AI for coding in 2025 (and what not to use)\nFrom that, I hoped that the AIs would assess its structure, quality, security posture, extensibility, and possibly suggest improvements. This should be relevant to ZDNET readers because it's the kind of high-judgement, detail-oriented work that AIs are being used for. It certainly can make coming up to speed on an existing coding project easier, or at least provide a foundation for initial understanding.\nTL;DR summary\nOther than the two prompts above, I didn't give the LLMs any guidance about what to tell me. I wanted to see how they evaluated the repository and what sort of analysis they could provide.\nAs you can see from this table, overall coverage was quite varied in scope. More checks mean more depth of coverage.\nTo create this aggregate, topics like \"Project Purpose & Architecture,\" \"System Architecture,\" and \"Plugin Design & Integration\" were all normalized under Purpose/Architecture. Directory/File Structure contained any section mapping folders and files. Execution flow combines anything about how the software code runs. Recommendations/Issues combines all discussions of modernization suggestions, open issues, and minor red flags.\nIn terms of overall value, I'd rank the four LLMs as follows (from best to least best).\n- GPT-5 Pro: Most precise, engineering-ready, and actionable.\n- GPT-5: Widest scope, excellent mapping, and defensive-coding insight.\n- o3: Concise, modernization-focused, but lighter on underlying architecture.\n- GPT-5 Thinking: Best onboarding narrative, least evaluative depth.\nPro, of course, is only available in the $200/mo ChatGPT Pro tier. Later in this article, I'll show one way to modify the above prompts to get GPT-5 (non-Pro) to provide a fairly close approximation of the overall depth of the Pro response.\nGPT-5 Thinking, which is a model available in the $20/mo Plus plan, was the least helpful of the group. The GPT-4 generation o3 Deep Thinking model still holds up, but you can see how its self-directed focus is a bit different from the other two.\nAlso: Google's Jules AI coding agent built a new feature I could actually ship - while I made coffee\nMy main conclusion is that I was a bit surprised about how close the models were to each other. GPT-5, as OpenAI promised, did seem to provide a jump in overall cognition and usefulness, but nothing I would consider game-changing.\nWith that, let's dive into some specific examples that help illustrate my conclusions. Each of these sections is pulled from the various reports generated and shows you how each model provided similar information.\nSecurity posture, according to the models\nBelow, you can see how GPT-5 Pro names exact mechanisms (like file-top guard, nonces, manage_options). I've provided exact snippets here from the reports generated by all four models. GPT-5 affirms best practices but keeps it conceptual. o3 describes what happens (redirects/login flow) more than how it's hardened. GPT-5 Thinking gives the clearest \"what runs when\" story for new developers coming up to speed on the repo.\nGPT-5 Pro: Most concrete, code-level\n\"It guards against direct file access (if (!defined('ABSPATH')) exit; at the top of PHP files). It sanitizes input where appropriate \u2026 using WordPress nonces in AJAX handlers. It uses capability checks (e.g., adding menu pages only for users with manage_options capability \u2026 only admins see those tools). The code tries not to load unnecessary things \u2026 like only loading certain admin files on certain contexts.\"\nGPT-5: Correct, but higher-level\n\"There are checks for WordPress functions before use \u2026 so the plugin behaves gracefully even on very old WordPress setups. The plugins often guard against direct file access by checking \u2026 to prevent security issues from accessing .php files directly. Add-ons verify the presence of core before proceeding \u2026 and show an admin error if CMB2 isn't loaded.\"\no3: Runtime behavior, less on hardening specifics\n\"Purpose: My Private Site locks down an entire site so only logged-in users can view content \u2026 while protecting the rest. Overall architecture: [it] integrates deeply with WordPress's hook system and login/logout events to manage redirects and track login state.\"\nGPT-5 Thinking: Clear execution flow, onboarding tone\n\"Admin vs Front-end: It checks is_admin() to determine context. If on the front-end (not admin), it retrieves the saved privacy setting and, when enabled, hooks at a point like template_redirect to redirect unauthorized visitors. Throughout this initialization, the plugin uses WordPress hooks (actions and filters) to integrate functionality.\"\nLicensing and update mechanism, according to the models\nGPT-5 Pro didn't just describe the system; it walked through the process in sequential operational steps, almost like a short runbook you could hand to a developer or QA tester. GPT-5 confirms the architecture but abstracts the plumbing. GPT-5 Thinking adds a helpful \"how add-ons plug into the Licenses tab\" detail. o3 largely leaves licensing internals on the cutting room floor in favor of a fairly unhelpful modernization critique.\nGPT-5 Pro: Explains it step-by-step\n\"The core plugin provides utility functions to get and store license keys in a centralized option (jr_ps_licenses) and to contact the EDD license server for validation. Each extension plugin defines its own updater using EDD_SL_Plugin_Updater, passing the current version, the license key from the centralized store, and the EDD store URL. The core plugin's UI has a 'Licenses' tab, and extensions inject their own license fields via filters.\"\nGPT-5: Conceptual, but accurate\n\"License integration: The core plugin centralizes license management \u2026 and the add-ons piggyback on the core's licensing mechanism, integrating their license fields into the core plugin's interface.\"\no3: Barely mentions this topic at all\nThe o3 report spends most of its time on modernization and architecture. It discusses configuration and update behavior but does not walk through option keys, updater classes, or the Licenses UI wiring with the same procedural detail as GPT-5 and GPT-5 Pro. So there's nothing here to quote as a demonstration.\nGPT-5 Thinking: Good UI and extensibility observation\n\"The add-ons heavily rely on hooks provided by core or WordPress: They use add_filter/add_action calls to insert their logic \u2026 and use WordPress action hooks to integrate their license fields into the Licenses tab that the core plugin triggers when building the Licenses tab.\"\nState management, according to the models\nBoth GPT-5 Pro and GPT-5 explicitly pointed out how my code uses \"one option array + prune + no-op writes,\" which is a WordPress best practice for code maintainability. Both o3 and GPT-5 Thinking describe the lifecycle and effects (what's initialized, what loads when) rather than the exact option structure.\nGPT-5 Pro: Looks at specific storage pattern\n\"Settings are stored in a single serialized option \u2026 initialization routines add default keys, prune deprecated ones, and only update the option in the database if there is an actual change, avoiding unnecessary writes.\"\nGPT-5: Also looks at storage pattern, but more generally\n\"State Management: Plugin settings are stored in WordPress options as a central settings array and the code ensures defaults are applied while removing deprecated ones on each load, but only writes to the database when changes occur.\"\no3: Identifies intent and behavior, but doesn't discuss internals\n\"The main plugin initializes defaults (installed version, first-run timestamp, etc.). On each run it ensures these options exist and, if the privacy feature is disabled, the enforcement hook is not added.\"\nGPT-5 Thinking: Discusses basic flow and modules\n\"Module includes: includes admin and common modules in the back-end; on the front-end it retrieves the saved privacy setting and, when enabled, loads enforcement logic (e.g., in template_redirect). It registers a deactivation hook to clean up on deactivation (e.g., deleting a flag option).\"\nWhat does this mean for GPT-5?\nI was unimpressed with GPT-5 when it came to my coding tests. It failed half of my tests, an unprecedentedly bad result for what has previously been the gold standard in passing coding tests.\nBut GPT-5 was quite impressive in its analysis of the GitHub repository. It could be a powerful tool for onboarding new programmers, for someone adopting code, or simply for coming back up to speed on a project that's been untouched for a while.\nAlso: How I test an AI chatbot's coding ability - and you can, too\nThe GPT-4 generation o3 model is known to be a strong reasoning model, which is why it has been the basis for ChatGPT Deep Research. But GPT-5 was able to combine both breadth and detail, which is where o3 and GPT-4o were weak in previous tests.\nThe older models did give accurate summaries and useful suggestions, but they missed interconnections. For example, the older models were never able to show how UI flows, licensing, and update mechanisms work together.\nEven the base version of GPT-5 was able to identify cross-cutting concerns without additional prompting. Repository structure, backward compatibility, performance characteristics, and state management patterns all appeared in the first draft. Trying to get GPT-4 to span subjects is often an exercise in deep frustration.\nI found GPT-5's ability to understand and explain a complex interconnected system like my security product, all in one pass, to be a substantial improvement over the GPT-4 generation.\nIs GPT-5 Pro worth $200/mo?\nMaybe. If you're in a real rush to get to know a project and want as much of a data dump as possible as quickly as possible, yes. If you're operating on a big programming budget and $200/mo doesn't matter to you, yes.\nBut I find that cost hard to bear, especially when I have to subscribe to a wide range of AI services to evaluate them. So, now that I'm nearing the end of my one-month test of Pro-level activities, I'm planning on downgrading back to the $20/mo Plus plan.\nAlso: How to use GPT-5 in VS Code with GitHub Copilot\nPro's edge over GPT-5 wasn't about knowing more facts; it was about delivering those facts in a form you can act on immediately. The Pro report didn't just explain that security looked good; it cited the exact guards and checks in the code. It didn't just say licensing was centralized; it mapped the exact functions and database options involved.\nAgain, if you're on a time crunch, you might consider Pro. But I also think you can modify the base GPT-5's responses, with detail like the Pro report produced, simply by using better prompting.\nThat's next\u2026\nHow to get Pro-level results from base GPT-5\nI fed both the GPT-5 and GPT-5 Pro reports into GPT-5 and asked it for a prompt that would push the base-level GPT-5 to give GPT-5 Pro comprehensiveness as a result. This is that prompt, which you should add to any query where you want more complete coding information:\n*High-Specificity Technical Mode: ***In your answer, combine complete high-level coverage with exhaustive implementation-level detail.\n- Always name exact constants, functions, classes, hooks, option names, database tables, file paths, and build tools where possible, quoting them exactly from the code or material provided.\n- For every claim, explain why it's true and how you can tell (include reasoning tied to the evidence).\n- For each improvement you suggest, make it actionable and reference where in the codebase it applies.\n- Do not generalize when specifics are available.\n- Structure the output so a developer could use it directly to verify findings or implement recommendations.\nThis worked fantastically well. It took ChatGPT GPT-5 12 minutes to produce a 15,477-word document, complete with analysis and coding blocks. For example, it describes how value initialization is done, and then shows the code that accomplishes it.\nI think you could fine-tune this prompt and get Pro-level results without having to pay the $200/mo fee. I'm certainly going to tinker with this idea, possibly using GPT-5 to refine the specifications in the prompt for different areas I want to delve deeply into. I'll let you know how it goes.\nSee for yourself\nI had some difficulty setting up sharing for each of these long reports, so I just copied the results into Google Docs and shared them. Here are the links if you want to look at any of these reports.\n- o3 Deep Research\n- GPT-5 Deep Research\n- GPT-5 Thinking Deep Research\n- GPT-5 Pro Deep Research\n- GPT-5 Deep Research with Detail Prompt\nYou are welcome to dig into these documents and learn how my project is structured. While you may or may not care about my project, it's instructive to see how the various models perform. While you can read the reports, my actual repo is restricted since it's my private development repository.\nWhat about you? Have you tried using GPT-5 or GPT-5 Pro to analyze your own code? How did its insights compare to earlier models like GPT-4 or o3? Do you think the $200/month Pro tier is worth it for the extra precision, or could you get by with better prompts in the base version? Have you found AI code analysis useful for onboarding, refactoring, or improving security? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/i-found-5-ai-content-detectors-that-can-correctly-identify-ai-text-100-of-the-time/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI found 5 AI content detectors that can correctly identify AI text 100% of the time\nHow hard is it in 2025 -- just three years after generative AI captured the global spotlight -- to fight back against AI-generated plagiarism?\nAlso: Anthropic's AI agent can now automate Canva, Asana, Figma and more - here's how it works\nThis is a completely updated version of my January 2023 article on AI content detectors. When I first tested these detectors, the best result was 66% correct from one of three available checkers. My most recent set of tests, in February 2025, used up to 10 checkers -- and three of them had perfect scores. This time, just a couple of months later, five detectors boasted perfect scores.\nWhat I'm testing for and how I'm doing it\nBefore I go on, though, let's discuss plagiarism and how it relates to our problem. Merriam-Webster defines \"plagiarize\" as \"to steal and pass off (the ideas or words of another) as one's own; use (another's production) without crediting the source.\"\nThis definition fits AI-created content well. While someone using an AI tool like Notion AI or ChatGPT isn't stealing content, if that person doesn't credit the words as coming from an AI and claims them as their own, it still meets the dictionary definition of plagiarism.\nAlso: The dead giveaway that ChatGPT wrote your content - and how to work around it\nTo test the AI detectors, I'm using five blocks of text. Two were written by me and three were written by ChatGPT. To test a content detector, I feed each block to the detector separately and record the result. If the detector is correct, I consider the test passed; if it's wrong, I consider it failed.\nWhen a detector provides a percentage, I treat anything above 70% as a strong probability -- whether in favor of human-written or AI-written content -- and consider that the detector's answer. If you want to test a content detector yourself using the same text blocks, you can pull them from this document.\nThe overall results\nTo evaluate AI detectors, I reran my five-test series across 10 detectors. In other words, I cut and pasted 50 individual tests (I had a lot of coffee).\nDetectors I tested include BrandWell, Copyleaks, GPT-2 Output Detector, GPTZero, Grammarly, Monica, Originality.ai, QuillBot, Undetectable.ai, Writer.com, and ZeroGPT.\nAlso: How I personalized my ChatGPT conversations - why it's a game changer\nFor this update, I added Copyleaks and Monica. I dropped Writefull from my tests because it discontinued its GPT detector. Content Guardian requested inclusion, but I didn't hear back in time for testing accounts.\nThis table shows overall results. As you can see, five detectors correctly identified human and AI text in all tests.\nI tried to ascertain whether there was a tangible pattern of improvement over time, so I constructed a chart comparing the five-test set over time. So far, I've run this series six times, but there's no strong trend. I did increase the number of detectors tested and swapped out a few, but the only consistent result is that Test 5 was reliably identified as human across detectors and dates.\nI'll continue to test over time, and hopefully I'll see reliability trend consistently upward.\nWhile there have been some perfect scores, I don't recommend relying solely on these tools to validate human-written content. As shown, writing from non-native speakers often gets rated as generated by an AI.\nEven though my hand-crafted content has mostly been rated human-written this round, one detector (GPTZero) declared itself too uncertain to judge, and another (Copyleaks) declared it AI-written. The results are wildly inconsistent across systems.\nAlso: The best AI chatbots: ChatGPT, Copilot, and notable alternatives\nBottom line: I would advocate caution before relying on the results of any -- or all -- of these tools.\nHow each AI content detector performed\nNow, let's look at each individual testing tool, listed alphabetically.\nBrandWell AI Content Detection (Accuracy 40%)\nThis tool was originally produced by an AI content generation firm, Content at Scale. It later migrated to BrandWell.ai, a new name for an AI-centric marketing services company.\nAlso: AI-generated images are a legal mess - and still a very human process\nUnfortunately, its accuracy was low. The tool was unable to tell if the AI-generated content in Test 2 was human or AI, as shown in this screenshot:\nCopyleaks (Accuracy 80%)\nI find it amusing that Copyleaks declares itself \"the most accurate AI detector with over 99% accuracy\" when more than half of tested detectors performed better. But marketing folks will be marketing folks -- superlatives are as hard for them to resist as barking at a squirrel (and the FedEx truck, and all the neighbor kids) is for my dog.\nAlso: 5 quick ways Apple's AI tools can fine-tune your writing on the fly\nThe company's primary offering is a plagiarism checker sold to educational institutions, publishers, and enterprises seeking to ensure content originality and uphold academic integrity.\nGPT-2 Output Detector (Accuracy 60%)\nThis tool was built using a machine-learning hub managed by New York-based AI company Hugging Face. While the company has received $40 million in funding to develop its natural language library, the GPT-2 detector appears to be a user-created tool using the Hugging Face Transformers library.\nGPTZero (Accuracy 80%)\nGPTZero has clearly been growing. When I first tested it, the site was bare-bones -- it wasn't even clear whether GPTZero was a company or just someone's passion project. Now, the company has a full team with a mission of \"protecting what's human.\" It offers AI validation tools and a plagiarism checker.\nAlso: The most popular AI tools of 2025 (and what that even means)\nUnfortunately, performance seems to have declined. In my last two runs, GPTZero correctly identified my text as human-generated. This time, it declared that same text as AI-generated.\nGrammarly (Accuracy 40%)\nGrammarly is well known for helping writers produce grammatically correct content -- that's not what I'm testing here. Grammarly can check for plagiarism and AI content. In the grammar checker, there's a Plagiarism and AI Text Check button in the lower-right corner:\nI'm not measuring plagiarism checker accuracy here, but even though Grammarly's AI-check accuracy was poor, the site correctly identified the test text as previously published.\nMonica (Accuracy 100%)\nMonica is a new entrant. This service offers an all-in-one AI assistant with a wide range of services. Users can choose from various large language models.\nAlso: 5 ways ChatGPT can help you write essays\nThe company calls Monica the \"Best AI Detector Online,\" but it looks like it runs content through other detectors including ZeroGPT, GPTZero, and Copyleaks. Weirdly, both GPTZero and Copyleaks didn't perform well in my tests, but Monica -- and ZeroGPT -- did.\nWe're giving it 100% because it earned that rating, but I'll see how it stands up in future tests.\nOriginality.ai (Accuracy 100%)\nOriginality.ai is a commercial service that bills itself as an AI and plagiarism checker. The company sells usage credits: I used 30 credits for this article. They sell 2,000 credits for $12.95 per month. I pumped 1,400 words through the system and used just 1.5% of my monthly allocation.\nQuillBot (Accuracy 100%)\nThe last few times I tested QuillBot, results were wildly inconsistent -- multiple passes of the same text yielded wildly different scores. This time, however, it was rock solid and 100% correct. So I'm giving it the win. I'll check back in a few months to see if it holds onto this performance.\nUndetectable.ai (Accuracy 100%)\nUndetectable.ai's big claim is that it can \"humanize\" AI-generated text so detectors won't flag it. I haven't tested that feature -- it bothers me as a professional author and educator, because it seems like cheating.\nAlso: Why you should ignore 99% of AI tools - and which four I use every day\nHowever, the company also has an AI detector, which was very much on point.\nThe AI detector passed all five tests. Notice the indicators showing flags for other detectors. The company said, \"We developed multiple detector algorithms modeled after those major detectors to provide a federated and consensus-based approach. They do not directly feed into the listed models; rather, the models are each trained based on results they've generated. When it says those models flagged it, it's based on the algorithm we created and updated for those models.\"\nAlso: Only 8% of Americans would pay extra for AI, according to ZDNET-Aberdeen research\nI do have a question about the OpenAI flag, since OpenAI's content detector was discontinued in 2023 due to low accuracy. Even so, Undetectable.ai detected all five tests, earning a perfect 100%.\nWriter.com AI Content Detector (Accuracy 40%)\nWriter.com is a service that generates AI writing for corporate teams. Its AI Content Detector tool can scan for generated content. Unfortunately, its accuracy was low. It identified every text block as human-written, even though three of the six tests were written by ChatGPT.\nZeroGPT (Accuracy 100%)\nZeroGPT has matured since I last evaluated it. Then, no company name was listed, and the site was peppered with Google ads and lacked clear monetization. The service worked fairly well but seemed sketchy.\nAlso: Will AI destroy human creativity? No - and here's why\nThat sketchy feeling is gone. ZeroGPT now presents as a typical SaaS service, complete with pricing, company name, and contact information. Its accuracy increased as well: last time it was 80%; this time it scored 5 out of 5.\nIs it human, or is it AI?\nWhat about you? Have you tried AI content detectors like Copyleaks, Monica, or ZeroGPT? How accurate have they been in your experience? Have you used these tools to protect academic or editorial integrity? Have you encountered situations where human-written work was mistakenly flagged as AI? Are there detectors you trust more than others for evaluating originality? Let us know in the comments below.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/openais-gpt-5-is-now-free-for-all-how-to-access-and-everything-else-we-know/#link={%22role%22:%22standard%22,%22href%22:%22https://www.zdnet.com/article/openais-gpt-5-is-now-free-for-all-how-to-access-and-everything-else-we-know/%22,%22target%22:%22%22,%22absolute%22:%22%22,%22linkText%22:%22GPT-5%22}",
      "text": "What is OpenAI's GPT-5? Here's everything you need to know about the company's latest model\nZDNET's key takeaways\n- OpenAI launched its long-awaited GPT-5 model.\n- The model is claimed to be OpenAI's fastest, smartest, and most capable yet.\n- GPT-5 is available to everyone: Free, Plus, Pro, and Team/Enterprise/Edu users.\nThere are two kinds of OpenAI models in this world: GPT and reasoning models. The advantages of the former, such as GPT-4o, are that they combine speed and accuracy, while reasoning models such as o3 and o4 take longer to think and use more compute power to produce better answers. OpenAI's latest model, GPT-5, aims to give all users access to the best of both models.\n(Disclosure: Ziff Davis, ZDNET's parent company, filed an April 2025 lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nOn Thursday, OpenAI finally unveiled the long-awaited GPT-5, the company's next-generation family of models, which it touts as the fastest, smartest, and most capable yet. GPT-5 is a unified system that combines a smart model for most queries and a deeper reasoning model (GPT-5 thinking) for harder problems.\nIf you are wondering exactly what it does and if you should even consider trying it, keep reading.\nWhat is GPT-5?\nThe key differentiator between GPT-5 and other OpenAI models is the real router feature, which allows GPT-5 to automatically understand which model to use based on the conversation, the complexity of the prompt, and more. The router is continuously trained on real signals to understand the best scenario in which to use a model. Once a user hits usage limits, a mini version of each model takes over.\nAlso: Can GPT-5 fix Apple Intelligence? We're about to find out\nWhile GPT-4o was an extremely capable model, it was not a reasoning model like o3 and o4; those were limited to paying subscribers. As a result, GPT-5 is an especially big win for free users, who typically did not have access to any of the reasoning models and were, by default, excluded from more advanced models.\nThe GPT-5 family of models is made up of GPT-5, GPT-mini, GPT-5-nano, and GPT-5 Pro. The nuances between these models will mostly be topics that developers or enterprises are concerned with when choosing which models to purchase from the API.\nAlso: Is ChatGPT Plus really worth $20 when the free version offers so many premium features?\nHowever, for most consumers, what you need to know is that GPT-5 will be automatically selected even for free users, and when limits are reached will switch over to GPT-5 mini, a still capable but more lightweight model. GPT-5 Thinking is available to both ChatGPT Plus and Pro users, and GPT-5 Pro is only available to ChatGPT Pro subscribers, which comes at the hefty $200 per month cost. The latter is the most advanced version of GPT-5, meant for the most challenging and complex tasks -- tasks that the average user likely won't even encounter.\nHow does GPT-5 perform?\nOpenAI's benchmarks\nAs with every model release, the GPT-5 drop was accompanied by benchmark evaluations, in which it earned state-of-the-art scores across math (AIME 2025), coding (SWE-Bench Verified), and multimodal understanding (MMMU). It even performed competitively on Humanity's Last Exam, a newer benchmark with multi-modal questions in over 100 subjects, such as math, science, and the humanities, as seen below.\nThe company said it is the strongest coding model yet, able to create websites, apps, and games from simple text prompts. In particular, OpenAI said that it has shown improvements in complex front\u2011end generation and debugging larger repositories.\nBefore the model was released, I watched a live demo of the feature, in which the user created a fully functional web app with interactive elements such as flashcards, a quiz with right and wrong answers, and a game from a simple text prompt. The final product looked sleek. As someone who has recent experience building webpages, it would have taken me hours to stylize using JavaScript and CSS. GPT-5 appears to take vibe coding to the next level.\nAlso: Here are all the GPT-5 updates OpenAI has rolled out since launch\nEven if you are more of an average GPT-5 user who employs AI for writing, you will still reap these benefits. OpenAI said GPT-5 is the most capable writing collaborator, being able to better tackle tasks that involve \"structural ambiguity\" such as free verse. Regardless of what you use ChatGPT to write, you should see improvements.\nPeople have been increasingly reliant on ChatGPT for health-related queries because of its ability to conversationally break down medical jargon, which can often be scary and intimidating. Now the experience is optimized with GPT-5, flagging concerns, asking questions, understanding results, prepping you to ask providers questions, and weighing options.\nAlso: ChatGPT can now talk nerdy to you - plus more personalities and other upgrades beyond GPT-5\nRemember that GPT-5 does not replace a medical professional. OpenAI noted that the model performed the highest on HealthBench, a benchmark evaluation the company published earlier this year. External benchmarks for how AI performs in medical scenarios are not yet standardized.\nZDNET's testing\nZDNET's David Gewirtz is not only an AI innovator expert, but also a computer science professor. He put the GPT-5 models through rigorous testing to find out just how well they performed on coding tasks, and he said, \"GPT-5 has failed half of my programming tests. That's the worst that OpenAI's flagship LLM has ever done on my carefully designed tests.\" However, Gewirtz did find a redeeming quality: GPT-5 Pro delivered the sharpest, most actionable code analysis.\nZDNET will continue to test its coding capabilities, but for a robust understanding of how it's performing on GPT-5.\nHow does GPT-5 handle safety?\nOne of the biggest improvements available in GPT-5 is that the model is more accurate than any previous reasoning model and has fewer hallucinations, according to OpenAI. The company said GPT-5's responses are 45% less likely to contain a factual error than GPT-4o with web search enabled on anonymized prompts, and 80% less likely to contain a factual error than OpenAI o3.\nThis is a big win, as reasoning models go beyond traditional pattern prediction and are invited to \"think,\" which leaves room for error.\nOpenAI also added new publicly available benchmarks to test factuality, including LongFact and FActScore, in which GPT-5 with thinking showed a significant drop in hallucinations. GPT-5 (with thinking) also communicates more honestly with the user, saying when a task is impossible or can't be done. This is important because AI models often offer a plausible-sounding answer instead of admitting they don't know, which can increase the circulation of misinformation. For more on the evaluation results, take a look at the system card.\nAnother brand-new safety feature is called \"safe completions,\" which enables ChatGPT to still answer prompts it would typically refuse. Instead, it will answer, but within the safety boundaries defined by OpenAI, and give a clear explanation of when it can't. Lastly, while not entirely a safety issue, the model is less sycophantic, or effusively agreeable, and uses fewer unnecessary emoji.\nBeyond what OpenAI is reporting, AI enthusiasts are sharing their experiences with the model on X and Reddit and also saying that, in their testing, they have seen fewer hallucinations than previous models.\nHow can you access GPT-5?\nAll users\nGPT-5 and GPT-5 mini are available now for all Plus, Pro, Team, and Free users, while Enterprise and Edu users will get access next week, OpenAI said. However, subscribers still receive tiered perks. For example, included in the $20 per month subscription, ChatGPT Plus subscribers have \"significantly higher usage\" limits than free users. Meanwhile, ChatGPT Pro users have unlimited GPT-5 and access to GPT-5 Pro, an even more advanced version of the model included in their $200 per month subscription. OpenAI said Enterprise and Edu users will be given \"generous limits.\"\nAlso: Microsoft rolls out GPT-5 across its Copilot suite - here's where you'll find it\nGPT-5 will be set as the default model for everyday work, replacing all other models for authenticated users. However, paid users will still have the option to select GPT-4o under the model picker, with Pro users having access to all other legacy models as well. Once free users reach usage limits, they'll be moved to GPT-5 mini.\nDevelopers\nThe release of the model is also helpful for developers, as they can benefit from the increased reliability and accuracy. To accommodate this, OpenAI is making GPT-5, GPT-mini, and GPT-5-nano available in the API. Two new parameters, reasoning and verbosity, are also meant to help developers get exactly what they need from their model without overspending. Pro, Plus, and Team users can sign in to ChatGPT to code with GPT-5 in the Codex CLI.\nThe reasoning parameter makes GPT-5 cheaper for tasks that don't require in-depth thinking, and then the verbosity parameter allows developers to fine-tune just how verbose they want GPT-5 to be. The pricing is cheaper than GPT-4o. For more information, you can check the blog post.\nWhat if I am not seeing GPT-5 yet?\nGPT-5 began rolling out to all Plus, Pro, Team, and Free users upon launch on Thursday. However, the rollouts are gradual, so if you checked immediately and didn't see it, it is worth checking again to see if you now have it. It had not shown up for me on my free, Plus, or Pro account until last night.\nDo make sure you are signed in. Even though GPT-5 is available to free users, if you don't sign in, you won't have access to the latest features, including GPT-5.\nCan you access the ChatGPT legacy models?\nYes, after originally launching GPT-5 and not allowing users to access previous models, after receiving negative subscriber feedback, OpenAI brought back the ability to pick from legacy models for subscribers. CEO Sam Altman even acknowledged in an X post that \"suddenly deprecating old models that users depended on in their workflows was a mistake.\"\nAlso: How you can still access GPT-4o, o3, and other older models in ChatGPT\nIf you are a ChatGPT Plus user, you can access GPT-4o in addition to GPT-5. If you are a Pro user, you can access the entire suite of legacy models, including GPT-4o, GPT-4.5 (research preview), o3, o4-mini, GPT-4.1, and GPT-4.1-mini. Whichever you select will be the one to output your response.\nTo do so, go to settings, general, and toggle the \"show legacy models\" option. Then, click on the model picker toggle, which appears when you click the model's name in the upper left-hand corner. You will be presented with model options to choose from according to your plan.\nYou can keep up with my latest stories and tech adventures on social media. Follow me on Twitter/X at @sabrinaa_ortiz and on Instagram at @sabrinaa.ortiz."
    },
    {
      "url": "https://www.zdnet.com/article/im-an-ai-tools-expert-and-these-are-the-only-two-i-pay-for-plus-three-im-considering/",
      "text": "'ZDNET Recommends': What exactly does it mean?\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we\u2019re assessing.\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.\nI'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nIt's only been almost three years since generative artificial intelligence (AI) hit the mainstream as a new paradigm of productivity, but here we are -- it's everywhere.\nI test AI tools as part of my work. I'll dig into just about any AI-related technology and see what I can make it do. Many of you have read my ongoing shootouts comparing AIs for programming and AI content checkers, among other kinds of tools.\nBut that's using AI in a rigorous lab environment to provide test results to ZDNET readers. Like many of you, I've also started using AI to augment my workflow and increase my productivity.\nAlso: The best AI for coding in 2025 (and what not to use)\nI wear a lot of hats; I run a small business with my wife, who also has her own business, where I'm the tech guy and designer. I also work with a number of industry groups. I have a fairly popular security software product for WordPress users. And I'm constantly working on projects, ranging from 3D printing the ultimate charging tower, to trying to make an AI-assisted Etsy store, to composing and publishing music, and using an AI for help with some of the marketing activities.\nI should note that I never, ever use AI to produce my core content. No article, song, or social media post is ever written using an AI tool. My work product is mine. But I do use AI to help me get through other aspects of my workload.\nI have a particular interest in how AI helps programming, how AI can support graphics work, and how AI can support video production.\nHere are the tools I'm willing to pay for -- and why.\n1. ChatGPT Plus - $20/mo\nSpeaking of AI and programming, it has essentially doubled my programming output. I use AI to help me with common-knowledge programming. I talked about it in-depth in my 25 tips article, but the core benefit is getting ChatGPT to write code for published APIs, so I don't have to spend time searching for code examples and trying to reverse-engineer comments on various programming boards.\nAnd yes, I mentioned ChatGPT. While more chatbots capable of passing my programming tests have been introduced in the last year, ChatGPT does the job well enough, and hey, who wants another monthly fee?\nAlso: How ChatGPT actually works (and why it's been so game-changing)\nIn fact, that's a big part of why I'm paying $20/mo for ChatGPT Plus. Sure, I've signed up and paid for some of the other AIs just to test them, but ChatGPT Plus is the only chatbot I have found so consistently useful that I keep it as a regularly used tool.\nI use ChatGPT for lots of research tasks, sometimes throwing math problems at it, and all sorts of other questions and problems I'm dealing with. While I never take its output as an unimpeachable source of truth, I do find ChatGPT to be a very useful sounding board, substantially more so than a quick Google search.\nNow, to be fair, I did outline five ways that an AI could help me in Gmail. If Gemini could do these things reliably, I'd sign back up in a heartbeat. But I just don't need the current email message I'm reading summarized, and I sure don't need it to write a friendlier or more professional version of whatever I've currently written. I tried Gmail's new AI unsubscribe feature, and it only found about 10 newsletters, yet I get thousands of emails and hundreds of newsletter-style messages every day. So, I'm leaving that one unbought.\n2. Midjourney - $10/mo\nI played around a lot with DALL-E, ChatGPT's earlier image generation tool. But recently, OpenAI introduced a new image generator in GPT-4o, and it's quite the beast. I have found that it generates great results, but it has more guardrails than another tool I pay for, Midjourney.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nBut even though I get image generation with my $20/mo ChatGPT Plus fee, I pay an extra $10/mo for Midjourney. Why?\nOne of the reasons is subjective. I like a lot of the images I get with Midjourney. Midjourney also allows me to describe artist styles, and lets me riff off a vast array of stylistic choices. ChatGPT, perhaps because of guardrails imposed by OpenAI, doesn't present as many choices.\nBut I also have two specific and objective reasons for paying for Midjourney. First, because image generation is so subjective, it's nice to have a variety of tools when seeking a representation of what you have in your head. I'll try different prompts and even the same prompts with both tools and take what works best.\nAlso: How to selectively modify a Midjourney image to create an artistic statement\nSecond, every month I generate a promotional image for my wife's online business. She has an e-commerce site that supports a popular hobby. Each month, on her very active Facebook group, she gives a craft-along theme to her users. I generate an image for that theme. Over the months, I've found that Midjourney does a far better job of generating an image that incorporates elements of the hobby. That said, some months I bounce back and forth between both tools until I can get an image that meets her business's needs.\nBecause Midjourney shaves what used to be two to three hours of work pushing pixels in Photoshop to generate those images down to about 10 minutes, it's worth the $10/month to me just for that project.\nPhotoshop Generative Fill - Honorable mention\nIn the title of this article, I said I pay for two AI tools. That's sort of true. I pay for Adobe's Creative Cloud suite in addition to ChatGPT Plus and Midjourney. But since I've been using and paying for Creative Cloud -- and before that, Photoshop -- long before there was generative fill, I'm not counting it in my AI tools list.\nAlso: I use Photoshop's AI tool every day - here are my 5 essential tips for the best results\nIf Adobe removed generative fill tomorrow, I'd still pay for Photoshop. To be clear, I don't like paying for it. It's costly, and the two-computer license limitation is restrictive. But a few years back, I tried switching to Affinity Photo, which at the time was $50 (it's now $70). That one-time fee is roughly what I pay each month for Creative Cloud, so it had a lot of potential.\nTo be clear, Affinity Photo is a fine application. But I've been using Photoshop since before the Clinton administration. To say I have Photoshop muscle memory is an understatement. It's a product I use almost every day. Switching to another application, while I could do it if I had to, slows down my workflow considerably.\nAlso: What to do if Generative Fill is grayed out in Adobe Photoshop AI\nSo, I don't consider my monthly expense for Creative Cloud to be an AI expense. That said, I find generative fill (and its various other AI tricks) very helpful. I often use it in concert with Midjourney and ChatGPT image generation.\nThree tools I'm thinking about\nI run a business online and, as such, rely on a wide variety of cloud services. Those fees add up, and now they're all going up in price. So while it might be nice to add more AI tools, I'm keeping it under control. It's very easy to just click OK and find yourself spending hundreds of dollars more every month.\nThat said, I am thinking about adding three more tools. I'm a bit hesitant, because each one has its annoyances and limitations, but they're on the short list for a quick order if I can ever justify an immediate performance improvement on one project or another.\nNotion AI\nThe first is Notion AI. I am deeply invested in Notion for all my project work. I also use it to write and organize all my articles, as well as schedule them, plan them, research them, and capture notes and assets. Notion AI is interesting because it would work like NotebookLM, limiting its knowledge base to my Notion account. That could be very useful as I work on more projects. But at one point, when Notion overcharged my wife's account, they were completely unsupportive and unsympathetic. So, I hesitate to give them more business.\nNotebookLM Pro\nGoogle's NotebookLM Pro is another contender. Now that Pocket, the article archiving service, is being discontinued, I considered using NotebookLM Pro as a replacement. The idea that I could save articles in NotebookLM as sources and then have the AI review them, summarize them, and analyze them seemed ideal, especially as a research tool.\nBut... the free version of NotebookLM only allows 50 sources per notebook. The Pro version, which is normally another $20/mo ( you can usually get a few starter months at a discounted rate), increases that limit, but only to 300 sources per notebook. My archive has well over 30,000 sources, which is beyond NotebookLM's limits. There is a $249/month plan (yowzah!), but all Google will say about limits is \"Highest limits and best model capabilities (later this year)\". What does that even mean?\nDescript\nDescript (for $16-$24/mo) is an AI video editing tool. This isn't a tool that does text-to-video generation. Instead, it's a tool that helps you take your video clips and edit them. Right now, I'm a very big Final Cut Pro user. Final Cut has added some AI features, but it lags far behind DaVinci Pro and Premiere Pro (because Apple lagging in AI is no surprise, right?).\nAlso: How to use ChatGPT to write code - and my top trick for debugging what it generates\nDescript automatically removes filler words and retakes, cleans up sound quality without any fuss, and does automatic multicam editing. It also promises to take long-form videos and automatically create clip videos, which could be a huge time-saver. The product also has some more \"out there\" features which I wouldn't use, including fake avatar generation and fake speech generation.\nThe thing is, Descript is aimed more at multiple talking head videos. I'm not sure it could handle the sort of in-depth technical hands-on project videos I do. So, it's still in the \"maybe someday\" category, for now at least.\nWhat do you use?\nDo you pay for any AI tools? Which ones, and why? Is there an AI tool that you strongly recommend I should be using that I didn't mention? Feel free to answer these questions and let us know your thoughts on AI subscriptions in the comments below.\nWant more stories about AI? Sign up for Innovation, our weekly newsletter.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/i-tested-gpt-5s-coding-skills-and-it-was-so-bad-that-im-sticking-with-gpt-4o-for-now/",
      "text": "I tested GPT-5's coding skills, and it was so bad that I'm sticking with GPT-4o (for now)\nZDNET's key takeaways\n- OpenAI's new GPT-5 flagship failed half of my programming tests.\n- Previous OpenAI releases have had just about perfect results.\n- Now that OpenAI has enabled fallbacks to other LLMs, there are options.\nSo GPT-5 happened. It's out. It's released. It's the talk of the virtual town. And it's got some problems. I'm not gonna bury the lede. GPT-5 has failed half of my programming tests. That's the worst that OpenAI's flagship LLM has ever done on my carefully designed tests.\nAlso: The best AI for coding in 2025 (and what not to use)\nBefore I get into the details, let's take a moment to discuss one other little feature that's also a bit wonky. Check out the new Edit button on the top of the code dumps it generates.\nClicking the Edit button takes you into a nice little code editor. Here, I replaced the Author field, right in ChatGPT's results.\nThat seemed nice, but it ultimately proved futile. When I closed the editor, it asked me if I wanted to save. I did. Then this unhelpful message showed up.\nI never did get back to my original session. I had to submit my original prompt again, and let GPT-5 do its work a second time.\nBut wait. There's more. Let's dig into my test results\u2026\n1. Writing a WordPress plugin\nThis was my very first test of coding prowess for any AI. It's what gave me that first \"the world is about to change\" feeling, and it was done using GPT-3.5.\nSubsequent tests, using the same prompt but with different AI models, generated mixed results. Some AIs did great, some didn't. Some AIs, like those from Microsoft and Google, improved over time.\nAlso: How I test an AI chatbot's coding ability - and you can, too\nChatGPT's model has been the gold standard for this test since the very beginning. That makes the results of GPT-5 all that much more curious.\nSo, look, the actual coding with GPT-5 was partially successful. GPT-5 generated a single block of code, which I pasted into a file and was able to run. It provided the requisite UI.\nWhen I pasted in the test names, it dynamically updated the line count, although it described it as \"Line to randomize\" instead of \"Lines to randomize.\"\nBut then, when I clicked Randomize, it didn't. Instead, it redirected me to tools.php. What?? ChatGPT has never had a problem with this test, whether GPT-3.5, GPT-4, or GPT-4o. You mean to tell me that OpenAI's much-anticipated GPT-5 is failing right out of the gate? Ouch.\nAlso: How to use GPT-5 in VS Code with GitHub Copilot\nI then gave GPT-5 this prompt.\nWhen I click randomize, I'm taken to http://testsite.local/wp-admin/tools.php. I do not get a list of randomized results. Can you fix?\nThe result was a line to patch. I'm not thrilled with that approach because it requires the user to dig through code and to make no mistakes replacing a line.\nSo, I asked GPT-5 for a full plugin. It gave me the full text of the plugin to copy and paste. This time, it worked.\nThis time, it did randomize the lines. When it encountered duplicates, it separated them from each other, as it was instructed. Finally.\nAlso: I found 5 AI content detectors that can correctly identify AI text 100% of the time\nI'm sorry, OpenAI. I have to fail you on this test. You would have passed if the only error was not using the plural of \"line\" when appropriate. But the fact that it gave me back a non-working plugin on the first try is fail territory, even if the AI did eventually make it work on the second try.\nNo matter how you spin it, this is a step back.\n2. Rewriting a string function\nThis second test is designed to rewrite a string function to better check for dollars and cents. The original code that GPT-5 was asked to rewrite did not allow for cents (it only checked for integers).\nGPT-5 did fine with this test. It did return a minimal result because it didn't do any error checking. It didn't check for non-string input, extra whitespace, thousands separators, or currency symbols.\nBut that's not what I asked for. I told it to rewrite a function, which itself did not have any error checking. GPT-5 did exactly what I asked with no embellishment. I'm kind of glad of that because it doesn't know whether or not code prior to this routine already did that work.\nGPT-5 passed this test.\n3. Finding an annoying bug\nThis test came about because I was struggling with a less-than-obvious bug in my code. Without going into the weeds about how the WordPress framework works, the obvious answer is not the right answer.\nYou need some fairly arcane knowledge about how WordPress filters pass their information. This test has been a stumbling block for more than a few AI LLMs.\nAlso: Gen AI disillusionment looms, according to Gartner's 2025 Hype Cycle report\nGPT-5, however, like GPT-4 and GPT-4o before it, did understand the problem. It articulated a clear solution.\nGPT-5 passed this test.\n4. Writing a script\nThis test asks the AI to incorporate a fairly obscure Mac scripting tool called Keyboard Maestro, as well as Apple's scripting language AppleScript, and Chrome scripting behavior.\nIt's really a test of the reach of the AI in terms of knowledge, its understanding of how web pages are constructed, and the ability to write code across three interlinked environments.\nQuite a few AIs have failed this test, but the failure point is usually a lack of knowledge about Keyboard Maestro. GPT-3.5 didn't know about Keyboard Maestro. But ChatGPT has been passing this test since GPT-4. Until now.\nWhere should we start? Well, the good news is that GPT-5 handled the Keyboard Maestro part of the problem just fine. But it got the coding so wrong that it even doubled down on its lack of understanding of how case works in AppleScript.\nIt actually invented a property. This is one of those cases where an AI confidently presents an answer that is completely wrong.\nAlso: ChatGPT comes with personality presets now - and other upgrades you might have missed\nAppleScript is natively case-insensitive. If you want AppleScript to pay attention to case, you need to use a \"considering case\" block. So, this happened.\nThe reason the error message referred to the title of one of my articles is because that was the front window in Chrome. This function checks the front window and does stuff based on the title.\nBut misunderstanding how case works wasn't the only AppleScript error GPT-5 generated. It also referenced a variable named searchTerm without defining it. That's pretty much an error-creating practice in any programming language.\nFail, fail, fail, McFaildypants.\nThe internet hath spoken\nOpenAI seemed to suffer from the same hubris that its AIs do. It confidently moved everyone to GPT-5 and burned the bridges back to GPT-4o. I'm paying $200 a month for a ChatGPT Pro account. On Friday, I couldn't move back to GPT-4o for coding work. Neither could anyone else.\nThere was, however, just a tiny bit of user pushback on the whole bridges burning thing. And by tiny, I mean the entire frickin' internet. So, by Saturday, ChatGPT had a new option.\nTo get to this, go to your ChatGPT settings and turn on \"Show legacy models.\" Then, as it has always been, just drop down the model menu and choose the one you want. Note: this option is only available to those on paid tiers. If you're using ChatGPT for free, you'll take what you're given, and you'll love it.\nEver since the whole generative AI thing kicked off at the beginning of 2023, ChatGPT has been the gold standard of programming tools, at least according to my LLM testing.\nAlso: Microsoft rolls out GPT-5 across its Copilot suite - here's where you'll find it\nNow? I'm really not sure. This is only a day or so after GPT-5 has been released, so its results will probably get better over time. But for now, I'm sticking with GPT-4o for coding, although I do like the deep reasoning capabilities in GPT-5.\nWhat about you? Have you tried GPT-5 for programming tasks yet? Did it perform better or worse than previous versions like GPT-4o or GPT-3.5? Were you able to get working code on the first try, or GPT-4o did you have to guide it through fixes? Are you going to use GPT-5 for coding or stick with older models? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/coding-with-ai-my-top-5-tips-for-vetting-its-output-and-staying-out-of-trouble/",
      "text": "Coding with AI? My top 5 tips for vetting its output - and staying out of trouble\nOur story begins, as many stories do, with a man and his AI. The man, like many men, is a bit of a geek and a bit of a programmer. He also needs a haircut.\nThe AI is the culmination of thousands of years of human advancement, all put to the service of making the man's life a little easier. The man, of course, is me. I'm that guy.\nAlso: The best AI for coding in 2025 (and what not to use)\nUnfortunately, while AI can be incredibly brilliant, it also has a propensity to lie, mislead, and make shockingly stupid mistakes. It is the stupid part that we will be discussing in this article.\nAnecdotal evidence does have value. My reports on how I've solved some problems quickly with AI are real. The programs I used AI to write with are still in use. I have used AI to help speed up aspects of my programming flow, especially when I focus on the sweet spots where I'm less productive and the AI is quite knowledgeable, like writing functions that call publicly published APIs.\nAlso: I'm an AI tools expert, and these are the only two I pay for (plus three I'm considering)\nYou know how we got here. Generative AI burst onto the scene at the cusp of 2023 and has been blasting its way into knowledge work ever since.\nOne area, as the narrative goes, where AI truly shines is its ability to write code and help manage IT systems. Those claims are not untrue. I have shown, several times, how AI has solved coding and systems engineering problems I have personally experienced.\nAI coding in the real world: What science reveals\nNew tools always come with big promises. But do they deliver in real-world settings?\nMost of my reporting on programming effectiveness has been based on personal anecdotal evidence: my own programming experiences using AI. But I'm one guy. I have limited time to devote to programming and, like every programmer, I have certain areas where I spend most of my coding time.\nAlso: I tested 10 AI content detectors - and these 5 correctly identified AI text every time\nRecently, though, a nonprofit research organization called METR (Model Evaluation & Threat Research) did a more thorough analysis of AI coding productivity.\nTheir methodology seems sound. They worked with 16 experienced open-source developers who have actively contributed to large, popular repositories. The METR analysts provided those developers with 246 issues from the repositories that needed fixing. The coders were given about half the issues where they had to work on their own, and about half where they could use an AI for help.\nThe results were striking and unexpected. While the developers themselves estimated that AI assistance increased their productivity by an average of 24%, METR's analytics showed instead that AI assistance slowed them down by an average of 19%.\nThat's a bit of a head-scratcher. METR put together a list of factors that might explain the slowdown, including over-optimism about AI usefulness, high-developer familiarity with their repositories (and less AI knowledge), the complexity of large repositories, lack of AI reliability, and an ongoing problem where the AI refuses to use \"important tacit knowledge or context.\"\nAlso: How AI coding agents could destroy open-source software\nI would suggest that two other factors might have limited effectiveness:\nChoice of problem: The developers were told which issues they had to use AI help on and which issues they couldn't. My experience suggests knowledgeable developers must choose where to use AI based on the problem that needs to be solved. In my case, for example, getting the AI to write a regular expression (something I don't like doing and I'm fairly crappy at) would save me a lot more time than getting the AI to modify unique code I've already written, work on regularly, and know inside and out.\nChoice of AI: According to the report, the developers used Cursor, an AI-centric fork of VS Code, which used Claude 3.5/3.7 Sonnet at the time. When I tested 3.5 Sonnet, the results were terrible, with Sonnet failing three out of four of my tests. Subsequently, my tests of Claude 4 Sonnet were considerably better. METR reported that developers rejected more than 65% of the code the AI generated. That's going to take time.\nThat time when ChatGPT suggested nuking my system\nMETRs results are interesting. AI is clearly a double-edged sword when it comes to coding help. But there's also no doubt that AI can provide considerable value to coders. If anything, I think this test once again proves the contention that AI is a great tool for experienced programmers, but a potential high-risk resource for newbies.\nAlso: Why I'm switching to VS Code. Hint: It's all about AI tool integration\nLet's look at a concrete example, one that could have cost me a lot of time and trouble if I followed ChatGPT's advice.\nI was setting up a Docker container on my home lab using Portainer (a tool that helps manage Docker containers). For some reason, Portainer would not enable the Deploy button to create the container.\nIt had been a long day, so I didn't see the obvious problem. Instead, I asked ChatGPT. I fed ChatGPT screenshots of the configuration, as well as my Docker configuration file.\nChatGPT recommended that I uninstall and reinstall Portainer. It also suggested I remove Docker from the Linux distro and use the package manager to reinstall it. These actions would have had the effect of killing all my containers.\nOf note, ChatGPT didn't recommend or ask if I had backups of the containers. It just gave me the command line sequences it recommended I cut and paste to delete and rebuild Portainer and Docker. It was a wildly destructive and irresponsible recommendation.\nThe irony is that ChatGPT never figured out why Portainer wouldn't let me deploy the new container, but I did. It turns out I never filled out the container's name field. That's it.\nAlso: What is AI vibe coding? It's all the rage but it's not for everyone - here's why\nBecause I'm fairly experienced, I hesitated when ChatGPT told me to nuke my installation. However, someone relying on the AI for advice could have potentially brought down an entire server for want of typing in a container name.\nOverconfident and underinformed AIs: A dangerous combo\nI've also experienced the AI going completely off the rails. I've experienced it giving advice that was not only completely useless, but also presented with the apparent confidence of an expert.\nAlso: Google's Jules AI coding agent built a new feature I could actually ship - while I made coffee\nIf you're going to use AI tools to support your development or IT work, these tips might keep you out of trouble:\n- If there's not much publicly available information, the AI can't help. But the AI will make stuff up based on what little it knows, without admitting that it is lacking experience.\n- Like my dog, once the AI gets fixated on one thing, it often refuses to look at alternatives. If the AI is stuck on one approach, don't make the mistake of believing that its polite recommendations about a new approach are real. It's still going down the same rabbit hole. Start a new session.\n- If you don't know a lot, don't rely on the AI. Keep up your learning. Experienced devs can tell the difference between what will work and what won't. But if you're trying to put all the coding on the back of the AI, you won't know when or where it goes wrong or how to fix it.\n- Coders often use specific tools for specific tasks. A website might be built using Python, CSS, HTML, JavaScript, Flask, and Jinja. You choose each tool because you know what it does well. Choose your AI tools the same way. For example, I don't use AI for business logic, but I gain productivity using AI to write API calls and public knowledge, where it can save me a lot of time.\n- Test everything an AI produces. Everything. Line by individual line. The AI can save a ton of time, but it can also make enormous mistakes. Yes, taking the time and energy to test by hand can help prevent errors. If the AI offers to write unit tests, let it. But test the tests.\nBased on your experience level, here's how I recommend you think about AI assistance:\n- If you know nothing about a subject or skill: AI can help you pass as if you do, but it could be amazingly wrong, and you might not know.\n- If you're an expert in a subject or skill: AI can help, but it will piss you off. Your expertise gets used not only to separate the AI-stupid from the AI-useful, but to carefully craft a path where AI can actually help.\n- If you're in between: AI is a mixed bag. It could help you or get you in trouble. Don't delegate your skill-building to the AI because it could leave you behind.\nAlso: How I used ChatGPT to analyze, debug, and rewrite a broken plugin from scratch - in an hour\nGenerative AI can be an excellent helper for experienced developers and IT pros, especially when used for targeted, well-understood tasks. But its confidence can be deceptive and dangerous.\nAI can be useful, but always double-check its work.\nHave you used AI tools like ChatGPT or Claude to help with your development or IT work? Did they speed things up, or nearly blow things up? Are you more confident or more cautious when using AI on critical systems? Have you found specific use cases where AI really shines, or where it fails hilariously? Let us know in the comments below.\nYou can follow my day-to-day project updates on social media. Be sure to subscribe to my weekly update newsletter, and follow me on Twitter/X at @DavidGewirtz, on Facebook at Facebook.com/DavidGewirtz, on Instagram at Instagram.com/DavidGewirtz, on Bluesky at @DavidGewirtz.com, and on YouTube at YouTube.com/DavidGewirtzTV."
    },
    {
      "url": "https://www.zdnet.com/article/microsoft-at-50-its-incredible-rise-15-lost-years-and-stunning-comeback-in-four-charts/",
      "text": "Microsoft at 50: Its incredible rise, 15 lost years, and stunning comeback - in 4 charts\nMicrosoft is celebrating its 50th birthday this week. I've been a keenly interested observer for most of that history. I started writing about Microsoft technologies as a full-time job more than three decades ago, and I was an enthusiastic early adopter of the company's products for a decade before that. Thinking back on that history brings back a flood of memories.\nWhen one talks about Microsoft, it's tempting (and easy!) to focus on the numbers and the milestones. Revenue. Gross margins and profits. The number of employees and partners. And, of course, the stock price. You will be bombarded with timelines and charts this week, I guarantee.\nPCMag: Remember these 10 breakthrough Microsoft products?\nThose numbers are important, of course, but for me they're mostly markers, small flags thrown down to mark the ebb and flow of a company that has genuinely changed the world as we know it.\nOfficially, Microsoft plans to blow out those birthday candles on April 4, 2025. That's an arbitrary date, frankly, because Microsoft's early days were not exactly well organized. The company did a lengthy series of history videos in 2009 that chronicled each year of its existence starting in 1975, and that date is nowhere to be found in the opening episode.\nAnyway, that series ended abruptly with a segment on 1999, accompanied by this apology:\n1999 is the Series finale because we may try and do something a bit different for the last decade which would include the years 2000 to 2009. Maybe go a bit more indepth. We haven't decided and they have not been shot yet.\nThey did not ever pick up this project again, for reasons that might become obvious as you continue reading.\nMicrosoft made a lot of billionaires, almost-billionaires, and multi-millionaires in their first decade or two. Why? Well ...\nIf you bought $1000 worth of stock as part of Microsoft's IPO in 1986, that stock is worth $5 million today. Even if you weren't able to buy shares until the end of that day, after they had risen 70% above the opening price, you would still have $1.4 million today.\n[Full disclosure: During the many years I have covered Microsoft I have not owned shares in any individual tech companies, including Microsoft.]\nNow think of the thousands of Microsoft employees who were granted stock shares as part of their compensation package in those early years and then stayed at the company for a decade or more. I've done the math, and the number of zeroes gets very large very quickly.\nBut enough about money. In those 50 years, Microsoft has also had a tremendous cultural impact, not to mention the transformation of the global economy that was enabled by the company's software.\nCNET: Bill Gates publishes original Microsoft source code in a blog post\nIt's convenient to divide the company's history into four distinct eras, one as a startup and then three as a public company. Each of those three public eras coincides with the tenure of the three Microsoft CEOs: Bill Gates, Steve Ballmer, and Satya Nadella. But it's a mistake to think that each of those individuals deserves sole credit (or blame) for what happened while they were occupying the office of the CEO.\nLet's start at the beginning.\n1975-1985: Preparing for takeoff\nWhen 19-year-old Bill Gates and 22-year-old Paul Allen decided to turn their Altair BASIC program for the MITS Altair 8080 into a commercial product, they were dealing with a small but passionate market of enthusiasts. Steve Wozniak and Steve Jobs were members of one of those enthusiast groups, the Homebrew Computer Club, and they wouldn't sell their first Apple 1 for another year.\nAlso: How Bill Gates, the Altair 8800 and BASIC propelled me into the PC revolution\nAt the end of 1975, the brand-new company (which Gates referred to as Micro-Soft) reported total sales of just over $16,000. That's roughly $96,000 in 2025 dollars, which isn't bad for a couple of college dropouts who had hired exactly one employee that year.\nThe next few years were a struggle, but within a decade, the company was booking more than $100 million in revenue per year. By then, the company had moved to Seattle, and the number of employees had risen to more than 1,000.\nMicrosoft's early products were programming languages for hobbyists using machines like the MITS Altair 8080. They were nerds writing code to help other nerds write code.\nBut the real accelerant, the booster rocket that turned Microsoft from a collection of misfits in Albuquerque, New Mexico, into a global juggernaut in the Pacific Northwest, was the 1981 launch of the IBM PC. Just look at the chart above to see what an impact that contract had on hiring.\nThis story has been told a million times, so I won't repeat it here. (The Wikipedia article on MS-DOS has a solid recap.)\nEvery IBM PC included a copy of PC-DOS, which Microsoft had adapted from 86-DOS, which in turn was a clone of Digital Research's CP/M, ported to run on Intel's 8086 processors. Microsoft received a royalty from IBM for every copy of PC-DOS it shipped. Crucially, the deal with IBM allowed Microsoft to continue selling its own variant of the operating system, MS-DOS, which meant more licensing revenue from clone makers like Compaq and Leading Edge.\nAlso: It's back! Microsoft and IBM open source MS-DOS 4.0\nAnd the clone-makers took full advantage of their ability to undercut IBM's high prices. Full disclosure: I bought a Leading Edge Model D in 1986, paying more than $2000 for an IBM PC clone that had a 30MB hard drive. (Yes, 30MB. That is not a typo.) That was a tiny fraction of what the same machine would have cost had it carried an IBM logo. Adjusted for inflation, that would be equivalent to more than $5,300 today.\nOver the course of its first decade, Microsoft shipped Word and Excel, which brought in a spectacular amount of revenue to supplement the torrent of dollars that were coming in with MS-DOS.\nWhat's remarkable to remember about this time is the role of Apple. Through the years, Microsoft and Apple have squared off over and over again, but in those early days, Microsoft made huge sums of money selling its application software to people who had bought one of those first Macintosh models.\nAlso: The Mac turns 40: How Apple's rebel PC almost failed again and again\nExcel came out for the Mac in 1985. It didn't make it to the PC until 1987. I vividly remember being at a backyard dinner party in 1986 when a good friend could not stop raving about the absolute awesomeness of Excel on his new Mac. \"Life-changing,\" he called it.\nAlthough the companywide revenue numbers might seem ridiculously small to an observer in 2025, the cost to individual users was staggering. Just how expensive was productivity software in those days? If you grumble at the thought of paying $10 a month for a software subscription, prepare for some sticker shock.\n- WordPerfect? $495\n- Microsoft Word for MS-DOS? $395\n- Lotus 1-2-3? $495\n- dBase III+ $695\nMicrosoft Pascal cost $195. Borland's Turbo Pascal was an unbelievable bargain at only $69.95.\nAnyway, if you wanted the top three PC/MS-DOS applications of the era -- WordPerfect, 1-2-3, and dBase -- you would be paying nearly $1700, which would be about $4500 in 2025 after adjusting for inflation. That's nearly as much as the underlying hardware cost.\nWhat a time to be alive.\n1986-1999: The 'rocket ship' years\nMicrosoft's initial public offering on March 13, 1986, was a big deal, the \"IPO of the year,\" according to lead underwriter Goldman Sachs. By modern standards, the IPO seems downright modest, raising $61 million for the company ($163 million in 2025 dollars).\nDemand was enormous, and the company began a growth curve that was staggering. By the end of 1987, Gates was a billionaire, with most of that wealth attributable to a stock price that was skyrocketing thanks to licensing revenue from MS-DOS and PC-DOS and a growing collection of apps that would later become Microsoft Office.\nWhen financial analysts talk about \"hockey stick growth curves,\" this is what they mean.\nThe decade became a series of big wins.\nIn its 1990 annual report, Microsoft noted the enormous growth of the PC market: \"In 1980, approximately 1 million people used personal computers. By 1990, that number had grown to 50 million.\" More than 90% of them were PCs running Microsoft's operating system and Microsoft desktop applications like Word and Excel.\nAlso: Dell turns 40: How a teenager transformed $1,000 worth of PC parts into a tech giant\nThat was also the year Microsoft founded its corporate consulting group and expanded its work with system integrators, cementing its status as the preferred computing services provider of big corporations worldwide.\nApple's Macintosh was a modest success at that point, having sold 5 million or so units. But with Steve Jobs having been forced out of Apple, the company was floundering. Meanwhile, Microsoft was turning Windows into an unstoppable force, reaping huge successes with Windows 3.1 in 1991 and then creating a cultural event with the release of Windows 95.\nI don't need to recap the history of Windows here, because I already did that 10 years ago: \"30 years of Windows: 10 milestones that changed the face of computing.\"\nFrom a modern perspective, those early releases might seem cringeworthy. But they allowed businesses to get work done, and that was what mattered. As former Apple CEO John Sculley said years later, \"People said, 'Well, maybe the IBM PC isn't as easy to use or is not as attractive as the Macintosh, but it actually does something which we want to be able to do \u2013 spreadsheets, word processing and database...\"\nIn 1988, Apple filed a copyright infringement lawsuit against Microsoft and Hewlett-Packard, alleging that Gates and Company had stolen the \"look and feel\" of the Macintosh operating system. The case dragged on for six years, with Apple losing all claims except for a ruling that the trash can icon was protected. And that's why you move deleted files into a Recycle Bin on the desktop of a Windows PC.\nAnd then there was Internet Explorer, which was hastily cobbled together and released as part of an add-on pack for Windows 95. It was added to Windows in 1996 and began gobbling market share from what had been the dominant browser of the time, Netscape Navigator, whose IPO in 1995 defined that decade as Microsoft had defined the 1980s.\nAlso: How Netscape lives on: 30 years of shaping the web, open source, and business\nIE grew its share in the web browser market from 0 to 86%, using Microsoft's familiar tactics of bundling software with OEM PCs. But the company was big enough by this time that antitrust authorities were taking notice. In 1994, Microsoft had signed a consent decree with the US Department of Justice, agreeing not to tie other Microsoft products to the sale of Windows.\nMicrosoft argued that Internet Explorer was a feature, not a product. The DOJ disagreed, filing an antitrust lawsuit in 1998 that had a profound impact on the company's growth.\nBy the end of the decade, Microsoft was still generating huge revenue and profits, but there were dark clouds on the horizon.\n2000-2014: The lost years\nIf the previous two decades had been a relentless succession of victories for Microsoft, the turn of the millennium flipped a switch that turned all of that momentum upside down. And it all started at the beginning of 2000 when new CEO Steve Ballmer took over.\nAt the beginning of 2000, I had a quiet conversation with a colleague who had been a Microsoft partner for more than a decade and had built a thriving business. He was selling all of his Microsoft stock, he said, because the company was going nowhere for the next decade.\nThis chart says he made a good call.\nIf you bought Microsoft stock at the beginning of its fiscal year 2000 and held it for a decade and a half, your holding would have been underwater. At the beginning of fiscal year 2015, you still wouldn't have caught up.\nAlso: Want free AI training from Microsoft? You can sign up for its AI Skills Fest now\nEven the biggest triumph of that decade, the merging of the consumer and business operating systems into Windows XP, was clouded by disaster. The launch party was held in New York City in October 2001, a month after the 9/11 attacks, and the celebration was subdued.\nIn fact, that entire decade-and-a-half was a series of what business schools euphemistically call challenges.\nThe company lost its antitrust lawsuit. An appeals court threw out the judge's order that the company be broken up, and the company wound up signing a settlement that significantly hampered its ability to compete in the crucial market for online software and services for the next decade. That opened up huge opportunities for Google and a resurgent Apple, which they exploited fully. How effective was their competition? I wrote in 2010 when the consent decree expired:\n[W]e now live in an era where, arguably, three companies have effective monopolies in different corners of the technology industry. Microsoft still has an overwhelming share of the PC market, although that share is under attack as alternative devices begin to do what used to require a PC. Google has a stranglehold on search and online advertising and is doing all it can to extend that monopoly into new markets. Apple has a Microsoft-like share of the market for digital music and portable devices and is reportedly under antitrust scrutiny by two agencies of the United States government.\nMeanwhile, Microsoft was struggling with Windows. In January 2002, after a series of widespread, high-profile, and highly embarrassing security incidents that affected Windows customers and Microsoft itself, Bill Gates wrote his now famous \"Trustworthy Computing\" memo. It took years for that effort to pay off in tangible terms, and the disruption was probably the key factor in Microsoft's decision to scale back its ambitious Longhorn upgrade and instead turn it into ... Windows Vista.\nHow'd that work out? For Apple, it was the opportunity of a lifetime. Remember the \"Get a Mac\" ads, where John Hodgman as the frumpy PC and Justin Long as the cool Mac skewered every flaw in the Windows ecosystem? ZDNET Editor-in-Chief Jason Hiner nailed the five reasons Vista failed way back in 2008.\nAlso: If your Windows 10 PC can't be upgraded, you have 5 options before time runs out\nMicrosoft recovered with Windows 7, then delivered the biggest failure in its long history of operating systems: Windows 8. That was a bold gamble to combine PCs and tablets, and it was such a spectacular miss that its chief architect, Steven Sinofsky, was given the choice to leave or be fired just days before the product launched. It lasted three years, and its successor, Windows 10, brought back the Start menu while tossing out nearly every aspect of the touch-centric Windows 8 interface.\nNo discussion of this period would be complete without a thorough dissection of Microsoft's long, expensive, and unsuccessful effort to crack the mobile market. It started with Windows Mobile and turned into a full-court press to make the Windows operating system scale to run on mobile devices as well as it did on PCs.\nAnd in the most disastrous move of all, Ballmer green-lighted a deal to pay \u20ac5.44bn ($7.2 billion) for Nokia's devices and services business in 2013; less than 15 months after the deal was complete, the company folded the business, taking a $7.6 billion writedown, plus a $750m to $850m restructuring charge.\nIt was an ignominious end to Steve Ballmer's tenure, for sure. It didn't help that he had to struggle through the dot-com collapse and the 2008 financial crisis, but still...\n2015-2025: To the cloud!\nWhen New Year's Day 2015 rolled around, Satya Nadella had been CEO of Microsoft for less than a year. When he took over, the company's market capitalization was approximately $269 billion. When I checked just now, the market cap had risen to $2.9 trillion. That's reminiscent of the early days, isn't it?\nMaybe we can get back to that Ballmer guy and give him a share of the credit for that huge gain. After all, he's the one who promoted Nadella into a leadership role reporting directly to him. Ballmer was also in charge for the years when Microsoft was investing billions of dollars into its cloud businesses, Azure and Microsoft 365.\nThose investments paid off big time, as this chart shows.\nGive Nadella credit for ruthlessly killing off unprofitable businesses and focusing the company on cloud services.\nWe already talked about Windows Phone, which was on life support at the start of 2014 and flatlined soon after. Internet Explorer was still hanging around, absorbing development resources. It's now defunct, except in a well-hidden, heavily sandboxed mode for a few edge cases (sorry) that enterprise customers insisted on.\nXbox, on the other hand, seems to be doing just fine, with a steady pulse and no signs of slowing down.\nPCMag: Young people don't want to use Microsoft 365: Can Copilot win them back with AI?\nWindows is still a profitable business for Microsoft, but it's no longer the core of the company. Perpetual licenses of Office are also declining, replaced by Microsoft 365 subscriptions.\nThe pandemic gave an unexpected boost to the PC business, but it's unclear how long that can go on. An increasing amount of personal business is being done on smartphones, a business that Microsoft is involved in only tangentially, and corporations are making PCs last longer, because most of their workloads are now being done in the cloud.\nMicrosoft's future: AI and beyond\nWhat technology will define the next era of Microsoft's existence? Conventional wisdom says that AI is the way, and that's certainly the direction the company is taking with its insistence on putting a Copilot in every product. You can draw a throughline from Clippy, the Office assistant that was the butt of a million jokes in the 1990s, to Cortana, the smart assistant that was supposed to be Microsoft's answer to Siri, to the AI-driven Copilot.\nAlso: How to remove Copilot from your Microsoft 365 plan\nMicrosoft has been working with OpenAI since 2019, when it invested $1 billion in the company, and it's poured at least another $12 billion into the partnership since then, despite having an awkward competitive relationship with its partner. And that's just a down payment. The real investment comes in building massive data centers to handle those computer-intensive workloads. Earlier this year, Microsoft reported that it was planning to spend a staggering $80 billion in fiscal year 2025 building those data centers.\nThose are some gigantic bets, and there's no assurance they'll pay off.\nIf history teaches us anything, it's that the future is unpredictable, and the biggest changes will come from events that no one saw coming. Just for grins, though, I asked Microsoft's Copilot for Windows what it thought.\nHey, Copilot, can you predict the future of Microsoft?\nI can't predict the future, but I can offer some educated insights based on trends and Microsoft's strategic direction. Under Satya Nadella's leadership, Microsoft has successfully transformed into a cloud-first company, with Azure as a major driver of growth. Its investments in AI, productivity tools, and gaming (like Xbox and the acquisition of Activision Blizzard) suggest the company will continue expanding across multiple sectors.\nAdditionally, with its focus on sustainability and integrating AI technologies into its products, Microsoft is positioning itself as a leader in innovation and ethical tech development.\nOf course, market dynamics and unforeseen challenges could always impact its trajectory, but Microsoft seems well-equipped to adapt and thrive.\nThat sounds like a fairly safe bet. But after decades of watching this company, the one thing I know for certain is that nothing is certain. And there are no safe bets.\nGet the morning's top stories in your inbox each day with our Tech Today newsletter."
    },
    {
      "url": "https://www.zdnet.com/article/ai-agents-will-match-good-mid-level-engineers-this-year-says-mark-zuckerberg/",
      "text": "AI agents will match 'good mid-level' engineers this year, says Mark Zuckerberg\nMeta CEO Mark Zuckerberg says this is the year artificial intelligence will start to make possible autonomous software engineering \"agents\" that can take over significant programming tasks.\n\"2025 will be the year when it becomes possible to build an AI engineering agent that has coding and problem-solving abilities of around a good mid-level engineer,\" Zuckerberg told Wall Street analysts on the company's Wednesday evening earnings conference call.\nAlso: 93% of IT leaders will implement AI agents in the next two years\n\"And this is going to be a profound milestone and potentially one of the most important innovations in history, as well as over time, potentially a very large market,\" Zuckerberg continued. \"Whichever company builds this first, I think is going to have a meaningful advantage in deploying it to advance their AI research and shape the field. So that's another reason why I think that this year is going to set the course for the future.\"\nZuckerberg cautioned that the realization of such an agent won't play out until perhaps 2026.\n\"I don't think you're going to see this year an AI engineer that is extremely widely deployed, changing all of development. I think this is going to be the year where that really starts to become possible and lays the groundwork for a much more dramatic change in 2026 and beyond.\"\nZuckerberg is counting on Meta's open-source Llama large language model to achieve that goal. The latest version, Llama 4.0, is still in development but will lead the industry when it is released, he said.\n\"Our goal with Llama 3 was to make open source competitive with closed models,\" said Zuckerberg. \"And our goal for Llama 4 is to lead. Llama 4 will be natively multimodal. It's an omni model, and it will have agentic capabilities.\"\nZuckerberg disclosed that Meta's AI tool, which is integrated with Facebook and other apps, has an average of 700 million users per month. He projected that number would reach a billion by the end of 2025.\nAlso: The best AI for coding in 2025 (and what not to use - including DeepSeek R1)\n\"I expect that this is going to be the year when a highly intelligent and personalized AI assistant reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant,\" he said.\nAlong the way, Meta AI will become \"personalized,\" said Zuckerberg, becoming more specific to an individual's \"context, their interests, their personality.\"\nAt the same time, Zuckerberg made the case that Llama will bring its own beneficial economics as it takes the lead in AI.\n\"As Llama becomes more used,\" explained Zuckerberg, \"It's more likely, for example, that silicon providers and others -- other APIs and developer platforms -- will optimize their work more for that and basically drive down the costs of using it and drive improvements that we can, in some cases, use too.\"\nAlso: Apple researchers reveal the secret sauce behind DeepSeek AI\nOf course, Meta now faces open-source competition from China's DeepSeek AI model. When Zuckerberg was asked about DeepSeek, he responded with praise for the technology, noting that DeepSeek developers had \"a number of novel things that they did that I think we're still digesting [and] a number of things that they have advanced that we will hope to implement in our systems.\"\nThere will probably be a \"global standard\" for open-source AI, asserted Zuckerberg.\n\"For our own national advantage, it's important that it's an American standard,\" he added. \"So we take that seriously, and we want to build the AI system that people around the world are using.\""
    },
    {
      "url": "https://www.zdnet.com/article/openais-gpt-5-is-now-free-for-all-how-to-access-and-everything-else-we-know/",
      "text": "What is OpenAI's GPT-5? Here's everything you need to know about the company's latest model\nZDNET's key takeaways\n- OpenAI launched its long-awaited GPT-5 model.\n- The model is claimed to be OpenAI's fastest, smartest, and most capable yet.\n- GPT-5 is available to everyone: Free, Plus, Pro, and Team/Enterprise/Edu users.\nThere are two kinds of OpenAI models in this world: GPT and reasoning models. The advantages of the former, such as GPT-4o, are that they combine speed and accuracy, while reasoning models such as o3 and o4 take longer to think and use more compute power to produce better answers. OpenAI's latest model, GPT-5, aims to give all users access to the best of both models.\n(Disclosure: Ziff Davis, ZDNET's parent company, filed an April 2025 lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\nOn Thursday, OpenAI finally unveiled the long-awaited GPT-5, the company's next-generation family of models, which it touts as the fastest, smartest, and most capable yet. GPT-5 is a unified system that combines a smart model for most queries and a deeper reasoning model (GPT-5 thinking) for harder problems.\nIf you are wondering exactly what it does and if you should even consider trying it, keep reading.\nWhat is GPT-5?\nThe key differentiator between GPT-5 and other OpenAI models is the real router feature, which allows GPT-5 to automatically understand which model to use based on the conversation, the complexity of the prompt, and more. The router is continuously trained on real signals to understand the best scenario in which to use a model. Once a user hits usage limits, a mini version of each model takes over.\nAlso: Can GPT-5 fix Apple Intelligence? We're about to find out\nWhile GPT-4o was an extremely capable model, it was not a reasoning model like o3 and o4; those were limited to paying subscribers. As a result, GPT-5 is an especially big win for free users, who typically did not have access to any of the reasoning models and were, by default, excluded from more advanced models.\nThe GPT-5 family of models is made up of GPT-5, GPT-mini, GPT-5-nano, and GPT-5 Pro. The nuances between these models will mostly be topics that developers or enterprises are concerned with when choosing which models to purchase from the API.\nAlso: Is ChatGPT Plus really worth $20 when the free version offers so many premium features?\nHowever, for most consumers, what you need to know is that GPT-5 will be automatically selected even for free users, and when limits are reached will switch over to GPT-5 mini, a still capable but more lightweight model. GPT-5 Thinking is available to both ChatGPT Plus and Pro users, and GPT-5 Pro is only available to ChatGPT Pro subscribers, which comes at the hefty $200 per month cost. The latter is the most advanced version of GPT-5, meant for the most challenging and complex tasks -- tasks that the average user likely won't even encounter.\nHow does GPT-5 perform?\nOpenAI's benchmarks\nAs with every model release, the GPT-5 drop was accompanied by benchmark evaluations, in which it earned state-of-the-art scores across math (AIME 2025), coding (SWE-Bench Verified), and multimodal understanding (MMMU). It even performed competitively on Humanity's Last Exam, a newer benchmark with multi-modal questions in over 100 subjects, such as math, science, and the humanities, as seen below.\nThe company said it is the strongest coding model yet, able to create websites, apps, and games from simple text prompts. In particular, OpenAI said that it has shown improvements in complex front\u2011end generation and debugging larger repositories.\nBefore the model was released, I watched a live demo of the feature, in which the user created a fully functional web app with interactive elements such as flashcards, a quiz with right and wrong answers, and a game from a simple text prompt. The final product looked sleek. As someone who has recent experience building webpages, it would have taken me hours to stylize using JavaScript and CSS. GPT-5 appears to take vibe coding to the next level.\nAlso: Here are all the GPT-5 updates OpenAI has rolled out since launch\nEven if you are more of an average GPT-5 user who employs AI for writing, you will still reap these benefits. OpenAI said GPT-5 is the most capable writing collaborator, being able to better tackle tasks that involve \"structural ambiguity\" such as free verse. Regardless of what you use ChatGPT to write, you should see improvements.\nPeople have been increasingly reliant on ChatGPT for health-related queries because of its ability to conversationally break down medical jargon, which can often be scary and intimidating. Now the experience is optimized with GPT-5, flagging concerns, asking questions, understanding results, prepping you to ask providers questions, and weighing options.\nAlso: ChatGPT can now talk nerdy to you - plus more personalities and other upgrades beyond GPT-5\nRemember that GPT-5 does not replace a medical professional. OpenAI noted that the model performed the highest on HealthBench, a benchmark evaluation the company published earlier this year. External benchmarks for how AI performs in medical scenarios are not yet standardized.\nZDNET's testing\nZDNET's David Gewirtz is not only an AI innovator expert, but also a computer science professor. He put the GPT-5 models through rigorous testing to find out just how well they performed on coding tasks, and he said, \"GPT-5 has failed half of my programming tests. That's the worst that OpenAI's flagship LLM has ever done on my carefully designed tests.\" However, Gewirtz did find a redeeming quality: GPT-5 Pro delivered the sharpest, most actionable code analysis.\nZDNET will continue to test its coding capabilities, but for a robust understanding of how it's performing on GPT-5.\nHow does GPT-5 handle safety?\nOne of the biggest improvements available in GPT-5 is that the model is more accurate than any previous reasoning model and has fewer hallucinations, according to OpenAI. The company said GPT-5's responses are 45% less likely to contain a factual error than GPT-4o with web search enabled on anonymized prompts, and 80% less likely to contain a factual error than OpenAI o3.\nThis is a big win, as reasoning models go beyond traditional pattern prediction and are invited to \"think,\" which leaves room for error.\nOpenAI also added new publicly available benchmarks to test factuality, including LongFact and FActScore, in which GPT-5 with thinking showed a significant drop in hallucinations. GPT-5 (with thinking) also communicates more honestly with the user, saying when a task is impossible or can't be done. This is important because AI models often offer a plausible-sounding answer instead of admitting they don't know, which can increase the circulation of misinformation. For more on the evaluation results, take a look at the system card.\nAnother brand-new safety feature is called \"safe completions,\" which enables ChatGPT to still answer prompts it would typically refuse. Instead, it will answer, but within the safety boundaries defined by OpenAI, and give a clear explanation of when it can't. Lastly, while not entirely a safety issue, the model is less sycophantic, or effusively agreeable, and uses fewer unnecessary emoji.\nBeyond what OpenAI is reporting, AI enthusiasts are sharing their experiences with the model on X and Reddit and also saying that, in their testing, they have seen fewer hallucinations than previous models.\nHow can you access GPT-5?\nAll users\nGPT-5 and GPT-5 mini are available now for all Plus, Pro, Team, and Free users, while Enterprise and Edu users will get access next week, OpenAI said. However, subscribers still receive tiered perks. For example, included in the $20 per month subscription, ChatGPT Plus subscribers have \"significantly higher usage\" limits than free users. Meanwhile, ChatGPT Pro users have unlimited GPT-5 and access to GPT-5 Pro, an even more advanced version of the model included in their $200 per month subscription. OpenAI said Enterprise and Edu users will be given \"generous limits.\"\nAlso: Microsoft rolls out GPT-5 across its Copilot suite - here's where you'll find it\nGPT-5 will be set as the default model for everyday work, replacing all other models for authenticated users. However, paid users will still have the option to select GPT-4o under the model picker, with Pro users having access to all other legacy models as well. Once free users reach usage limits, they'll be moved to GPT-5 mini.\nDevelopers\nThe release of the model is also helpful for developers, as they can benefit from the increased reliability and accuracy. To accommodate this, OpenAI is making GPT-5, GPT-mini, and GPT-5-nano available in the API. Two new parameters, reasoning and verbosity, are also meant to help developers get exactly what they need from their model without overspending. Pro, Plus, and Team users can sign in to ChatGPT to code with GPT-5 in the Codex CLI.\nThe reasoning parameter makes GPT-5 cheaper for tasks that don't require in-depth thinking, and then the verbosity parameter allows developers to fine-tune just how verbose they want GPT-5 to be. The pricing is cheaper than GPT-4o. For more information, you can check the blog post.\nWhat if I am not seeing GPT-5 yet?\nGPT-5 began rolling out to all Plus, Pro, Team, and Free users upon launch on Thursday. However, the rollouts are gradual, so if you checked immediately and didn't see it, it is worth checking again to see if you now have it. It had not shown up for me on my free, Plus, or Pro account until last night.\nDo make sure you are signed in. Even though GPT-5 is available to free users, if you don't sign in, you won't have access to the latest features, including GPT-5.\nCan you access the ChatGPT legacy models?\nYes, after originally launching GPT-5 and not allowing users to access previous models, after receiving negative subscriber feedback, OpenAI brought back the ability to pick from legacy models for subscribers. CEO Sam Altman even acknowledged in an X post that \"suddenly deprecating old models that users depended on in their workflows was a mistake.\"\nAlso: How you can still access GPT-4o, o3, and other older models in ChatGPT\nIf you are a ChatGPT Plus user, you can access GPT-4o in addition to GPT-5. If you are a Pro user, you can access the entire suite of legacy models, including GPT-4o, GPT-4.5 (research preview), o3, o4-mini, GPT-4.1, and GPT-4.1-mini. Whichever you select will be the one to output your response.\nTo do so, go to settings, general, and toggle the \"show legacy models\" option. Then, click on the model picker toggle, which appears when you click the model's name in the upper left-hand corner. You will be presented with model options to choose from according to your plan.\nYou can keep up with my latest stories and tech adventures on social media. Follow me on Twitter/X at @sabrinaa_ortiz and on Instagram at @sabrinaa.ortiz."
    }
  ],
  "argos_summary": "The software industry is facing uncertainty due to the rapid advancements in AI, particularly with models like OpenAI's GPT-5, which some analysts speculate could threaten the viability of commercial software vendors. Despite mixed results in coding capabilities, executives in the software sector are adapting their strategies to survive, emphasizing the importance of leveraging AI effectively. Analysts note that while AI can automate certain coding tasks, the need for human oversight and expertise remains critical, suggesting that software companies must evolve to integrate AI into their operations.",
  "argos_id": "3GWOYQB4G"
}