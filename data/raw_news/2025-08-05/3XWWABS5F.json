{
  "url": "https://techcrunch.com/2025/08/05/deepmind-reveals-genie-3-a-world-model-that-could-be-the-key-to-reaching-agi/",
  "authorsByline": "Rebecca Bellan",
  "articleId": "098fb9e05d394dde93277ab8a8b5cf91",
  "source": {
    "domain": "techcrunch.com",
    "paywall": false,
    "location": {
      "country": "us",
      "state": "CA",
      "county": "San Francisco",
      "city": "San Francisco",
      "coordinates": {
        "lat": 37.7790262,
        "lon": -122.419906
      }
    }
  },
  "imageUrl": "https://techcrunch.com/wp-content/uploads/2025/05/Google-DeepMind.jpg?w=1024",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-05T14:10:14+00:00",
  "addDate": "2025-08-05T14:17:00.164726+00:00",
  "refreshDate": "2025-08-05T14:17:00.164728+00:00",
  "score": 1.0,
  "title": "DeepMind reveals Genie 3, a world model that could be the key to reaching AGI",
  "description": "Google DeepMind has revealed Genie 3, its latest foundation world model that the AI lab says presents a crucial stepping stone on the path to artificial general intelligence, or human-like intelligence.",
  "content": "Google DeepMind has revealed Genie 3, its latest foundation world model that the AI lab says presents a crucial stepping stone on the path to artificial general intelligence, or human-like intelligence.\n\n\u201cGenie 3 is the first real-time interactive general purpose world model,\u201d Shlomi Fruchter, a research director at DeepMind, said during a press briefing. \u201cIt goes beyond narrow world models that existed before. It\u2019s not specific to any particular environment. It can generate both photo-realistic and imaginary worlds, and everything in between.\u201d\n\nGenie 3, which is still in research preview and not publicly available, builds on both its predecessor Genie 2 \u2013 which can generate new environments for agents \u2013 and DeepMind\u2019s latest video generation model Veo 3 \u2013 which exhibits a deep understanding of physics.\n\nWith a simple text prompt, Genie 3 can generate multiple minutes \u2013 up from 10 to 20 seconds in Genie 2 \u2013 of diverse, interactive, 3D environments at 24 frames per second with a resolution of 720p. The model also features \u201cpromptable world events,\u201d or the ability to use a prompt to change the generated world.\n\nPerhaps most importantly, Genie 3\u2019s simulations stay physically consistent over time because the model is able to remember what it had previously generated \u2013 an emergent capability that DeepMind researchers didn\u2019t explicitly program into the model.\n\nFruchter said that while Genie 3 clearly has implications for educational experiences and new generative media like gaming or prototyping creative concepts, its real unlock will manifest in training agents for general purpose tasks, which he said is essential to reaching AGI.\n\n\u201cWe think world models are key on the path to AGI, specifically for embodied agents, where simulating real world scenarios is particularly challenging,\u201dJack Parker-Holder, a research scientist on DeepMind\u2019s open-endedness team, said during a briefing.\n\nGenie 3 is designed to solve that bottleneck. Like Veo, it doesn\u2019t rely on a hard-coded physics engine. Instead, it teaches itself how the world works \u2013 how objects move, fall, and interact \u2013 by remembering what it has generated and reasoning over long time horizons.\n\n\u201cThe model is auto-regressive, meaning it generates one frame at a time,\u201d Fruchter told TechCrunch in a separate interview. \u201cIt has to look back at what was generated before to decide what\u2019s going to happen next. That\u2019s a key part of the architecture.\u201d\n\nThat memory creates consistency in its simulated worlds, and that consistency allows it to develop a kind of intuitive grasp of physics, similar to how humans understand that a glass teetering on the edge of a table is about to fall, or that they should duck to avoid a falling object.\n\nThis ability to simulate coherent, physically plausible environments over time makes Genie 3 much more than a generative model. It becomes an ideal training ground for general-purpose agents. Not only can it generate endless, diverse worlds to explore, but it also has the potential to push agents to their limits \u2013 forcing them to adapt, struggle, and learn from their own experience in a way that mirrors how humans learn in the real world.\n\nCurrently, the range of actions an agent can take is still limited. For example, the promptable world events allow for a wide range of environmental interventions, but they\u2019re not necessarily performed by the agent itself. Similarly, it\u2019s still difficult to accurately model complex interactions between multiple independent agents in a shared environment. Genie 3 can also only support a few minutes of continuous interaction, when hours would be necessary for proper training.\n\nStill, Genie 3 presents a compelling step forward in teaching agents to go beyond reacting to inputs so they can plan, explore, seek out uncertainty, and improve through trial and error \u2013 the kind of self-driven, embodied learning that\u2019s key in moving towards general intelligence.\n\n\u201cWe haven\u2019t really had a Move 37 moment for embodied agents yet, where they can actually take novel actions in the real world,\u201d Parker-Holder said, referring to the legendary moment in the 2016 game of Go between DeepMind\u2019s AI agent AlphaGo and world champion Lee Sedol, in which Alpha Go played an unconventional and brilliant move that became symbolic of AI\u2019s ability to discover new strategies beyond human understanding.\n\n\u201cBut now, we can potentially usher in a new era,\u201d he said.",
  "medium": "Article",
  "links": [
    "https://techcrunch.com/events/tc-disrupt-2025/?utm_source=tc&utm_medium=ad&utm_campaign=disrupt2025&utm_content=ticketsales&promo=tc_inline_rb&display=",
    "https://techcrunch.com/2024/12/04/deepminds-genie-2-can-generate-interactive-worlds-that-look-like-video-games/",
    "https://techcrunch.com/2025/07/03/google-rolls-out-its-new-veo-3-video-generation-model-globally/",
    "https://techcrunch.com/2025/07/02/could-googles-veo-3-be-the-start-of-playable-world-models/"
  ],
  "labels": [
    {
      "name": "Opinion"
    }
  ],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "world models",
      "weight": 0.10771153
    },
    {
      "name": "narrow world models",
      "weight": 0.10115616
    },
    {
      "name": "real world scenarios",
      "weight": 0.09333559
    },
    {
      "name": "world champion Lee Sedol",
      "weight": 0.08156895
    },
    {
      "name": "embodied agents",
      "weight": 0.07945768
    },
    {
      "name": "Genie",
      "weight": 0.07883365
    },
    {
      "name": "multiple independent agents",
      "weight": 0.07722795
    },
    {
      "name": "agents",
      "weight": 0.07583018
    },
    {
      "name": "new environments",
      "weight": 0.06724636
    },
    {
      "name": "DeepMind researchers",
      "weight": 0.06407846
    }
  ],
  "topics": [],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.96875
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.8984375
    }
  ],
  "sentiment": {
    "positive": 0.2512207,
    "negative": 0.16467285,
    "neutral": 0.58447266
  },
  "summary": "Google DeepMind has revealed Genie 3, its latest foundation world model, which the AI lab believes will be crucial for reaching artificial general intelligence (AGI). The model can generate multiple minutes of diverse, interactive environments at 24 frames per second and resolution of 720p, and features \u201cpromptable world events\u201d to change the generated world. It is also able to stay physically consistent over time, allowing it to develop an intuitive grasp of physics. While Genie 3 has implications for educational experiences and new generative media like gaming or prototyping creative concepts, its real unlocking will be in training agents for general purpose tasks. The range of actions an agent can take is still limited, but still difficult to accurately model complex interactions between multiple independent agents in a shared environment.",
  "shortSummary": "Google DeepMind has unveiled Genie 3, a world model capable of generating diverse, interactive environments and teaching embodied agents to act effectively.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "489708d0b7974611a845be046cd94d23",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://techcrunch.com/events/tc-disrupt-2025/?utm_source=tc&utm_medium=ad&utm_campaign=disrupt2025&utm_content=ticketsales&promo=tc_inline_rb&display=",
      "text": "Save up to $675 on your ticket before time runs out. Click here for your discount.\nTechCrunch Disrupt 2025\nTechCrunch Disrupt is where you\u2019ll find innovation for every stage of your startup journey. Whether you\u2019re a budding founder with a revolutionary idea, a seasoned startup looking to scale, or an investor seeking the next big thing, Disrupt offers unparalleled resources, connections, and expert insights to propel your venture forward.\nFind innovation for every stage at Disrupt 2025\nFrom idea to IPO, Disrupt 2025 will map out the path for startups to achieve their next major milestone.\nJoin 10,000 startup and VC leaders\nLooking to meet founders, connect with investors, seek advice, or land your next big role? Disrupt is the must-attend event to make it all happen in person.\nBuild and scale your business faster\nDisrupt is more than a startup launchpad \u2014 it\u2019s a growth accelerator. Dive into sessions on scaling, sales, and leadership, and connect with the investors and tech experts who can help take your business to the next level.\nGain insights from today\u2019s tech giants\nTap into the wisdom of founders and tech titans at Disrupt. From actionable tips to hard-won lessons, they\u2019ll share what works (and what doesn\u2019t) to guide you as you build your own path forward.\nDisrupt 2025 speakers\nPartner Sequoia Capital\nChief Technology Officer US Dept of Navy\nCEO and Co-Founder Writer\nChief Product Officer Netflix\nCEO Wayve\nCo-Founder & CEO Box\nFounder and CEO Pinecone\nCo-CEO Waymo\nCo-Founder ElevenLabs\nCaptain of Moonshots X, The Moonshot Factory\nI\u2019ve always thought, \u201cWhat can I do that opens up possibilities?\u201d I grew up in South Africa and went to an Afrikaans high school, and we didn\u2019t speak English at home. But I pushed myself to go to an English-speaking university, and that opened up a door. Then I chose to work for McKinsey, because I thought it would open another door and maybe I\u2019d get a chance to work overseas. I was reading about what was happening in Silicon Valley in the mid 90s, before I came to the U.S. Already, I\u2019m starting to see the beginnings of the internet. Did I fathom how big it would be? Absolutely not. I didn\u2019t know what venture capital was. I didn\u2019t know that I would join a startup. I just had an intuition that I needed to be here. A friend of mine introduced me to Elon in 1999 and I joined PayPal. Then when Mike Moritz asked me to come interview at Sequoia, that was just another door opening. Where might this one lead? Whenever I interview people, I ask about those key moments in somebody\u2019s life where they\u2019ve made career decisions. And I think about companies in the same way\u2014there are these crucible moments that have an enormous bearing on ultimate outcomes.\nRoelof's Sessions\nWhat Sequoia Sees Coming Next\nAs one of the most influential VCs of the modern era, Roelof Botha has seen it all; booms, busts, and billion-dollar breakout bets. In this fireside chat, the Sequoia Capital managing partner opens up about how today\u2019s most ambitious founders are navigating AI, geopolitics, and a shifting capital landscape.\nJustin Fanelli is the Chief Technology Officer for the Department of the Navy and Technical Director of PEO Digital, driving measurable technology improvements and secure, high-performance digital transformation. He champions private-public collaboration to deliver innovation with unprecedented value. Fanelli advises numerous national science and technology boards and has held key roles including Chief Architect for Defense Health, DARPA Service Chiefs Fellow, and Chief Systems Engineer for Joint Command and Control. He teaches at Georgetown and has lectured all over the country at CMU, MIT, Stanford and others. He recently gave a TED Talk on innovation adoption and the Innovation Adoption Kit covered by TechCrunch, Forbes, CSIS and others. Fanelli holds engineering degrees from Penn State and the University of Pennsylvania and is a Senior Executive Fellow at Harvard Kennedy School. He\u2019s been an angel investor, VC and has been privileged to serve on public and private boards. His work has earned national awards including the Etter Award, Fed100, Defense50, and CMMI Project of the Year. He lives in Arlington, VA and enjoys book recommendations.\nJustin's Sessions\nAI and National Security in the High-Stakes Race to Innovate\nFrom defense labs to Wall Street and naval operations, AI is reshaping how countries protect themselves and project power. DARPA\u2019s Kathleen Fisher, Point72\u2019s Sri Chandrasekar, and Navy CTO Justin Fanelli dive into the cutting-edge AI breakthroughs driving security innovation. They\u2019ll discuss what it means for entrepreneurs, investors, and the future of global stability.\nMay Habib is the CEO and co-founder of Writer, a leader and pioneer in enterprise AI. With Writer\u2019s end-to-end AI agent platform, hundreds of companies like Accenture, Mars, Uber, and Vanguard are building and scaling AI agents that are grounded in their company\u2019s data and fueled by Writer\u2019s enterprise-grade LLMs. From faster product launches to deeper financial research to better clinical trials, companies are quickly transforming their most important business processes for the AI era in partnership with Writer. Writer houses the world\u2019s only enterprise-specific AI research lab. Its family of enterprise-grade Palmyra LLMs includes state-of-the-art frontier models, as well as self-evolving, open-source, and domain-specific models. Palmyra models define industry-leading standards for enterprise-grade transparency, reliability, safety, efficiency, and observability. May is an expert in natural language processing and AI-driven language generation. She has led Writer to become one of the world\u2019s fastest-growing generative AI companies, securing its position as a Forbes 50 AI company and inclusion in the World Economic Forum\u2019s Unicorn Community. Founded in 2020 with its headquarters in San Francisco and offices around the globe, Writer is backed by world-leading investors, including Premji Invest, Radical Ventures, ICONIQ Growth, Insight Partners, Balderton, B Capital, Salesforce Ventures, Adobe Ventures, Citi Ventures, IBM Ventures, and others. May and the Writer team have raised over $326M in funding at a valuation of $1.9B. May graduated with high honors in Economics from Harvard University. She is a World Economic Forum Young Global Leader, a Fellow of the Aspen Global Leadership Network, a recipient of Inc.\u2019s Female Founder Award, and one of Worth\u2019s Groundbreaking Women for 2025.\nMay's Sessions\nWriting the Future with AI?\nWhat happens when AI learns to write with purpose, personality, and persuasion? Writer CEO May Habib joins us to talk about the evolving relationship between language and machines and what the rise of generative content means for the future of brand, business, and beyond.\nEunice Kim was named Chief Product Officer in October 2023. She previously led the company\u2019s global Consumer Product Innovation team. Eunice joined Netflix in early 2021 after having spent 10 years in product leadership roles at Google Play and YouTube. Prior to Google, she worked at several tech startups as well as PepsiCo and Adobe Systems. Eunice holds a B.A. from Columbia University and an M.B.A. from the University of Chicago Booth School of Business. She serves on the Board of Directors for Cure CMD.\nEunice's Sessions\nWhat's Next for Netflix and for Streaming Itself\nAs CPO of Netflix, Eunice Kim is steering the future of entertainment for hundreds of millions of users. In this fireside chat, Kim will break down how Netflix is evolving its product strategy\u2014from personalized discovery to global growth, from ad tiers to gaming. We\u2019ll explore how Netflix is adapting to a shifting content landscape, what it means to innovate at massive scale, and what design surprises Netflix has up its sleeve. For anyone building consumer experiences, this will be a masterclass.\nAlex co-founded Wayve in 2017 to reimagine autonomous mobility through embodied intelligence. From his award-winning research at the University of Cambridge, he seized the opportunity to use deep learning to pioneer an entirely new way to solve self-driving. He showed for the first time that it was possible to teach a machine to understand where it is and what\u2019s around it and then give it the \u201cintelligence\u201d to make its own decisions based on what it sees with computer vision. As CEO, Alex is responsible for the company\u2019s overall strategy, primarily focusing on establishing all necessary ingredients to develop and deploy AV2.0 globally. He also works closely with our partners and investors to ensure that our technology is commercially viable and can be widely adopted. Under Alex\u2019s leadership, Wayve is fast becoming one of the most exciting companies in the autonomous vehicle industry. Before founding Wayve, Alex\u2019s passion for autonomous vehicles began as a research fellow at the University of Cambridge, where he earned his PhD in Computer Vision and Robotics. His research has received numerous awards for scientific impact and made significant contributions to the field of computer vision and AI. He was selected on the Royal Academy of Engineering\u2019s SME Leaders Programme and named on the Forbes 30 Under 30 innovators list.\nAlex's Sessions\nDriving Intelligence\nFrom self-driving cars to self-learning systems, Alex Kendall is rethinking how machines perceive and act in the world. The Wayve CEO joins us to explore how real-world autonomy is shaping the next chapter of AI, and why breakthroughs on the road may unlock progress far beyond it.\nAaron Levie is Chief Executive Officer, Cofounder at Box, which he launched in 2005 with CFO and cofounder Dylan Smith. He is the visionary behind the Box product and platform strategy, incorporating the best of secure content collaboration with an intuitive user experience suited to the way people work today. Aaron leads the company in its mission to transform the way people and businesses work so they can achieve their greatest ambitions. He has served on the Board of Directors since April 2005. Aaron attended the University of Southern California from 2003 to 2005 before leaving to found Box.\nAaron's Sessions\nSurvive, Scale, Reinvent: Lessons from a Cloud OG\nAaron Levie built Box before cloud was cool and he\u2019s still standing while competitors have come and gone. Known for his sharp takes and startup instincts, Levie joins us to unpack how to keep innovating inside a public company, what AI really changes for enterprise software, and why reinvention is the name of the game in tech right now. Expect real talk and a playbook for building companies that last.\nEdo Liberty is the founder and CEO of Pinecone whose mission is to make AI knowledgeable. Pinecone is the leading vector database for building accurate and performant AI applications at scale in production. Prior to founding Pinecone, Edo was a Director of Research at AWS and Head of Amazon AI Labs where his team worked on data systems and services including SageMaker and OpenSearch. Before AWS, Edo was a Senior Research Director at Yahoo and Head of Yahoo\u2019s Research Lab in New York. As an adjunct professor at Princeton and Tel Aviv University, Edo taught long-term memory in AI and data mining. His academic work focuses on numerical linear algebra, streaming algorithms, data mining, and mathematical foundations of machine learning. Edo holds a B.Sc in physics and computer science from Tel Aviv University, and a Ph.D. in computer science from Yale. He has authored more than 75 academic papers and patents.\nEdo's Sessions\nWhy the Next Frontier Is Search\nIn a world overflowing with data, finding what matters is everything. Pinecone founder Edo Liberty unpacks why infrastructure, not algorithms, might be the biggest unlock in AI, and what\u2019s coming next in the race to power smarter applications at scale.\nTekedra N. Mawakana is the co-CEO of Waymo, an autonomous driving technology company. As co-CEO, Tekedra oversees the company\u2019s strategy for the wide adoption of the Waymo Driver. She boasts 20+ years of experience advising consumer technology companies to advance their business interests globally. Tekedra currently serves on the Board of Directors for Intuit and the Advisory Council for Boom Technology. She is a social impact-focused angel investor and an Advisor and LP with the Operator Collective.\nTekedra's Sessions\nThe Self-Driving Reality Check\nAutonomous vehicles have been \u201cjust around the corner\u201d for years\u2014until now. Tekedra Mawakana, Co-CEO of Waymo, takes the Disrupt Stage to talk about where AVs actually stand, what it\u2019s taken to get to real deployments, and why the race isn\u2019t just about tech, it\u2019s about trust. From regulation to rider experience to competition with Tesla and Tesla-adjacent hype, this conversation gets real about what\u2019s next in mobility.\nMati Staniszewski is the co-founder and CEO of ElevenLabs, a research company building audio AI tools to solve audio intelligence and make digital interactions feel more human \u2014 with voice as the most direct path to that. Before founding ElevenLabs, Mati worked at Palantir as a Deployment Strategist, managing large-scale implementations across public and private sectors, and at BlackRock, where he helped launch the Aladdin Wealth platform.\nMati's Sessions\nSynthetic Voices and Real Impact\nFrom audiobooks to avatars, synthetic speech is having a moment. ElevenLabs is helping lead the charge. CEO Mati Staniszewski joins us to explore what it takes to build AI that speaks like us and how voice technology is reshaping the creative industries, accessibility, and entertainment.\nDr. Astro Teller currently oversees X, Alphabet\u2019s moonshot factory for building breakthrough technologies and businesses designed to help tackle huge problems in the world. Before joining Google / Alphabet, Astro was the co-founding CEO of Cerebellum Capital, Inc, an investment management firm whose investments are continuously designed, executed, and improved by a software system based on techniques from statistical machine learning. Before his tenure as a business executive, Dr. Teller taught at Stanford University and was an engineer and researcher for Phoenix Laser Technologies, Stanford\u2019s Center for Integrated Systems, and The Carnegie Group Incorporated. Dr. Teller holds a Bachelor of Science in computer science from Stanford University, Masters of Science in symbolic and heuristic computation, also from Stanford University, and a Ph.D. in artificial intelligence from Carnegie Mellon University, where he was a recipient of the Hertz fellowship.\nAstro's Sessions\nMoonshots, AI, and the Future of Alphabet\nFrom self-driving cars to internet balloons to AI-fueled breakthroughs, Astro Teller leads the lab where Alphabet incubates the nearly impossible. In this rare Disrupt stage appearance, he shares what\u2019s actually working inside X, why \u201cfailing fast\u201d isn\u2019t just a mantra, and how moonshots may evolve in the AI age. If you think your startup is ambitious, wait until you hear what he\u2019s launching next.\nMore reasons to attend Disrupt\nLatest TechCrunch Disrupt 2025 news\nFind Your Ticket Type\nFind the ticket type that fits you best with up to $675 savings until August 7. Groups can save up to 30%.\nPartner with TechCrunch\nTechCrunch offers many ways for partners to engage directly with our attendees before, during, and after the event. Get in touch with us to learn more.\nLocation\nUpcoming TechCrunch events\n-\nGet on waitlist to get exclusive early access to limited tickets!\nTechCrunch Disrupt 2025 is innovation for every stage\n10,000+ tech leaders. 250+ sessions. 200+ speakers. 3 days. 6 stages. One epic experience of insights, strategy, and connections. Save up to $675 before rates increase on August 7.\nSubscribe\nEvent Updates\nGet the latest event announcements, special discounts and other event offers.\nPartner with TechCrunch\nTechCrunch offers many ways for partners to engage directly with our attendees before, during, and after the event. Get in touch with us to learn more."
    },
    {
      "url": "https://techcrunch.com/2025/07/02/could-googles-veo-3-be-the-start-of-playable-world-models/",
      "text": "Demis Hassabis, CEO of Google\u2019s AI research organization DeepMind, appeared to suggest Tuesday evening that Veo 3, Google\u2019s latest video-generating model, could potentially be used for video games.\nIn response to a post on X beseeching Google to \u201cLet me play a video game of my veo 3 videos already,\u201d and asking, \u201cplayable world models wen?\u201d Hassabis responded, \u201cnow wouldn\u2019t that be something.\u201d\nOn Wednesday morning, Logan Kilpatrick, lead product for Google\u2019s AI Studio and Gemini API, chimed in with a reply: \u201c\ud83e\udd10\ud83e\udd10\ud83e\udd10\ud83e\udd10\u201d\nBoth posts from the Google executives are little more than playful suggestions, and a Google spokesperson told TechCrunch the company had nothing to share at the moment. But building playable world models isn\u2019t outside the realm of possibilities for the tech giant.\nWorld models are different from video-generation models. The former simulates the dynamics of a real-world environment, which lets agents predict how the world will evolve in response to their actions. Video-gen models synthesize realistic video sequences.\nGoogle has plans to turn its multimodal foundation model, Gemini 2.5 Pro, into a world model that simulates aspects of the human brain. In December, DeepMind unveiled Genie 2, a model that can generate an \u201cendless\u201d variety of playable worlds. The following month, we reported that Google was forming a new team to work on AI models that can simulate the real world.\nOthers are working on building world models \u2014 most notably, AI pioneer Fei-Fei Li. Li came out of stealth last year with World Labs, a startup that has built its own AI system that generates video game-like, 3D scenes from a single image.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital \u2014 just a few of the heavy hitters joining the Disrupt 2025 agenda. They\u2019re here to deliver the insights that fuel startup growth and sharpen your edge. Don\u2019t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech \u2014 grab your ticket now and save up to $675 before prices rise on August 7.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital \u2014 just a few of the heavy hitters joining the Disrupt 2025 agenda. They\u2019re here to deliver the insights that fuel startup growth and sharpen your edge. Don\u2019t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech \u2014 grab your ticket now and save up to $675 before prices rise.\nVeo 3, which is still in public preview, can create video as well as audio to go along with clips \u2014 anything from speech to soundtracks. While Veo 3 creates realistic movements by simulating real-world physics, it isn\u2019t quite a world model yet. Instead, it could be used for cinematic storytelling in games, like cutscenes, trailers, and narrative prototyping\nThe model is also still a \u201cpassive output\u201d generative model, and it (or a future Veo generation) would need to shift to a simulator that\u2019s more active, interactive, and predictive.\nBut the real challenge with video game production isn\u2019t just impressive visuals; it\u2019s real-time, consistent, and controllable simulation. That\u2019s why it might make sense to see Google take a hybrid approach that leverages Veo and Genie in the future, should it pursue video game or playable world development.\nGoogle could find itself competing with Microsoft, Scenario, Runway, Pika, and, eventually, OpenAI\u2019s video-generating model Sora.\nGiven Google\u2019s planned moves in the world models space and its reputation for using its deep pockets and distribution muscle to steamroll rivals, competitors in this space would be wise to keep a close watch."
    },
    {
      "url": "https://techcrunch.com/2024/12/04/deepminds-genie-2-can-generate-interactive-worlds-that-look-like-video-games/",
      "text": "DeepMind, Google\u2019s AI research org, has unveiled a model that can generate an \u201cendless\u201d variety of playable 3D worlds.\nCalled Genie 2, the model \u2014 the successor to DeepMind\u2019s Genie, which was released earlier this year \u2014 can generate an interactive, real-time scene from a single image and text description (e.g. \u201cA cute humanoid robot in the woods\u201d). In this way, it\u2019s similar to models under development by Fei-Fei Li\u2019s company, World Labs, and Israeli startup Decart.\nDeepMind claims that Genie 2 can generate a \u201cvast diversity of rich 3D worlds,\u201d including worlds in which users can take actions like jumping and swimming by using a mouse or keyboard. Trained on videos, the model\u2019s able to simulate object interactions, animations, lighting, physics, reflections, and the behavior of \u201cNPCs.\u201d\nMany of Genie 2\u2019s simulations look like AAA video games \u2014 and the reason could well be that the model\u2019s training data contains playthroughs of popular titles. But DeepMind, like many AI labs, wouldn\u2019t reveal many details about its data sourcing methods, for competitive reasons or otherwise.\nOne wonders about the IP implications. DeepMind \u2014 being a Google subsidiary \u2014 has unfettered access to YouTube, and Google has previously implied that its ToS gives it permission to use YouTube videos for model training. But is Genie 2 basically creating unauthorized copies of the video games it \u201cwatched\u201d? That\u2019s for the courts to decide.\nDeepMind says that Genie 2 can generate consistent worlds with different perspectives, like first-person and isometric views, for up to a minute, with the majority lasting 10 to 20 seconds.\n\u201cGenie 2 responds intelligently to actions taken by pressing keys on a keyboard, identifying the character and moving it correctly,\u201d DeepMind wrote in a blog post. \u201cFor example, our model [can] figure out that arrow keys should move a robot and not trees or clouds.\u201d\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital \u2014 just a few of the heavy hitters joining the Disrupt 2025 agenda. They\u2019re here to deliver the insights that fuel startup growth and sharpen your edge. Don\u2019t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech \u2014 grab your ticket now and save up to $675 before prices rise on August 7.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital \u2014 just a few of the heavy hitters joining the Disrupt 2025 agenda. They\u2019re here to deliver the insights that fuel startup growth and sharpen your edge. Don\u2019t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech \u2014 grab your ticket now and save up to $675 before prices rise.\nMost models like Genie 2 \u2014 world models, if you will \u2014 can simulate games and 3D environments, but with artifacting, consistency, and hallucination-related issues. For example, Decart\u2019s Minecraft simulator, Oasis, has a low resolution, and quickly \u201cforgets\u201d the layout of levels.\nGenie 2, however, can remember parts of a simulated scene that aren\u2019t in view and render them accurately when they become visible again. (World Labs\u2019 models can do this, too.)\nNow, games created with Genie 2 wouldn\u2019t be all that fun, really, given they\u2019d erase your progress every minute or so. That\u2019s why DeepMind is positioning the model as more of a research and creative tool \u2014 a tool for prototyping \u201cinteractive experiences\u201d and evaluating AI agents.\n\u201cThanks to Genie 2\u2019s out-of-distribution generalization capabilities, concept art and drawings can be turned into fully interactive environments,\u201d DeepMind wrote. \u201cAnd by using Genie 2 to quickly create rich and diverse environments for AI agents, our researchers can generate evaluation tasks that agents have not seen during training.\u201d\nCreatives may have mixed feelings \u2014 particularly those in the video game industry. A recent Wired investigation found that major players like Activision Blizzard, which has laid off scores of workers, are using AI to cut corners, ramp up productivity, and compensate for attrition.\nNevertheless, Google has poured increasing resources into its world model research, which promises to be the next big thing in AI. In October, DeepMind hired Tim Brooks, who was heading development on OpenAI\u2019s Sora video generator, to work on video generation technologies and world simulators. And two years ago, the lab poached Tim Rockt\u00e4schel, best known for his \u201copen-endedness\u201d experiments with video games like NetHack, from Meta.\nTechCrunch has an AI-focused newsletter! Sign up here to get it in your inbox every Wednesday."
    }
  ],
  "argos_summary": "Google DeepMind has introduced Genie 3, a groundbreaking real-time interactive world model that aims to advance artificial general intelligence (AGI). Unlike previous models, Genie 3 can generate diverse, interactive 3D environments with physical consistency over time, allowing for more complex simulations and training of agents. This model builds on its predecessor, Genie 2, and incorporates features from DeepMind's Veo 3, enhancing its capabilities for educational experiences and creative media while pushing the boundaries of agent training.",
  "argos_id": "3XWWABS5F"
}