{
  "url": "https://finance.yahoo.com/news/mark-zuckerberg-issues-bold-claim-235000108.html",
  "authorsByline": "Daniel Gala",
  "articleId": "c845e72bbf294ae3bbd4ffa9ff8dba4d",
  "source": {
    "domain": "finance.yahoo.com",
    "location": {
      "country": "us",
      "state": "CA",
      "county": "Santa Clara County",
      "city": "Sunnyvale",
      "coordinates": {
        "lat": 37.3688301,
        "lon": -122.036349
      }
    }
  },
  "imageUrl": "https://s.yimg.com/ny/api/res/1.2/bB6qEUCmwvuSokh7gxKRaA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/the_cool_down_737/38a148a66210a9469571a4532695f46a",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T23:50:00+00:00",
  "addDate": "2025-08-13T00:11:17.429064+00:00",
  "refreshDate": "2025-08-13T00:11:17.429066+00:00",
  "score": 1.0,
  "title": "Mark Zuckerberg issues bold claim as Meta boosts AI capabilities: 'Superintelligence'",
  "description": "\"The improvement is slow for now, but undeniable.\"",
  "content": "In the lead up to the company's quarterly earnings announcement, Meta head Mark Zuckerberg released a statement on AI superintelligence, proclaiming, \"Developing superintelligence is now in sight.\"\n\nMeta, parent company of Facebook, WhatsApp, and Instagram, has been pouring hundreds of billions of dollars into its AI technology, seeking to build what Zuckerberg has called \"personal superintelligence,\" according to the Guardian.\n\n\"Over the last few months we have begun to see glimpses of our AI systems improving themselves,\" Zuckerberg wrote in the statement. \"The improvement is slow for now, but undeniable.\"\n\nTech companies around the world have been pumping billions of dollars into various artificial-intelligence-based technologies, seeking to control what experts say will be the dominant technology of the near future.\n\nZuckerberg clearly shares the techno-utopian vision of many AI proponents, referring in his statement to the \"profound \u2026 abundance\" that AI might one day produce.\n\nHowever, according to Zuckerberg, Meta's vision for AI's future differs from that of many of its rivals. Rather than building enterprise-level AI aimed at \"automating all valuable work,\" Zuckerberg has set his company's sights on bringing \"personal superintelligence to everyone.\"\n\n\"We believe in putting this power in people's hands to direct it towards what they value in their own lives,\" Zuckerberg wrote.\n\nWhile the overall tone of the statement conveyed great enthusiasm about the potential for AI's future, Zuckerberg also acknowledged that risks do exist.\n\n\"That said, superintelligence will raise novel safety concerns,\" Zuckerberg said. \"We'll still need to be rigorous about mitigating these risks and careful about what we choose to open source.\"\n\n\"Still, we believe that building a free society requires that we aim to empower people as much as possible,\" he continued.\n\nInvestors appeared to approve of Meta's massive investment in AI and so-called \"superintelligence,\" which has been financed by the company's still-booming ad revenues. Meta shares rose 10% after its quarterly financials were released, according to the Guardian.\n\nWhile both advocates and critics of artificial intelligence have deeply held views on opposite ends of the AI debate, one thing that everyone seems to agree on is that AI has the potential to revolutionize human society and change the way the world operates.\n\nDepending on one's perspective, AI either has the power to unleash never-before-seen levels of abundance for all of humanity to share or to amplify existing inequality by rendering millions of people jobless.\n\nIn reality, both scenarios appear to be in play, but the likeliest outcome would be one that falls somewhere between these two extremes.\n\nUltimately, the form AI takes and the impacts it will have on the world will depend heavily on decisions made, or not made, in the next few years.\n\n\"The rest of this decade seems likely to be the decisive period for determining the path this technology will take, and whether superintelligence will be a tool for personal empowerment or a force focused on replacing large swaths of society,\" Zuckerberg wrote in his statement.\n\nWhile AI has the potential to completely upend human society and the world economy, the future of AI also has enormous implications for public health and the environment.\n\nAI technology's existence relies on massive, power-hungry data centers that consume enormous amounts of electricity. Goldman Sachs has projected that by 2030 AI will increase data-center power use by 160%.\n\nAs data centers consume more and more electricity, they will continue to drive demand, causing energy prices to go up for everyone.\n\nAll of this extra demand for electricity could come at an environmental cost, as well. While more data centers are beginning to rely on clean energy, Goldman Sachs forecast in 2024 that the carbon pollution resulting from data center's power use will double between 2022 and 2030.\n\nWhat's being done about AI energy concerns?\n\nWhile the European Union's regulations governing AI went into effect in August 2024, in general, governments around the world have been slow to react to the risks that AI poses to the economy, the environment, and even more specific matters such as copyright enforcement.\n\nPolling has shown that the public favors government regulation of AI by large margins. A poll by the Artificial Intelligence Policy Institute found that 75% of U.S. voters favored government regulation of AI over allowing the industry to self-regulate.\n\nHowever, with AI technology advancing by the day, the time for governments to act within an optimal time frame is running short.\n\nIf you want to use your voice and push for government regulation of AI before it is too late, you can contact your elected officials in Washington and let them know that you support government oversight of the AI industry.\n\nJoin our free newsletter for good news and useful tips, and don't miss this cool list of easy ways to help yourself while helping the planet.",
  "medium": "Article",
  "links": [
    "https://shopping.yahoo.com/rdlw?merchantId=e160a5dc-fb38-4e8b-ae1d-1ad5eb060fbd&siteId=us-y4p&pageId=1p-autolink&contentUuid=49c50848-268a-3709-ac6a-5d8ab20b7ddb&featureId=text-link&merchantName=Meta&linkText=according+to+the+Guardian&custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5tZXRhLmNvbS9zdXBlcmludGVsbGlnZW5jZS8iLCJjb250ZW50VXVpZCI6IjQ5YzUwODQ4LTI2OGEtMzcwOS1hYzZhLTVkOGFiMjBiN2RkYiIsIm9yaWdpbmFsVXJsIjoiaHR0cHM6Ly93d3cubWV0YS5jb20vc3VwZXJpbnRlbGxpZ2VuY2UvIn0&signature=AQAAAUyMXmSE-Af6_MVzSYVa1XGGPabB5b0AEyUq2F_DsT4W&gcReferrer=https%3A%2F%2Fwww.meta.com%2Fsuperintelligence%2F",
    "https://guide.thecooldown.com/recording-votes/do-you-worry-about-companies-having-too-much-of-your-personal-data/?answer=2&article=recob6oAvHAOhKaCi",
    "https://guide.thecooldown.com/recording-votes/do-you-worry-about-companies-having-too-much-of-your-personal-data/?answer=3&article=recob6oAvHAOhKaCi",
    "https://shopping.yahoo.com/rdlw?merchantId=e160a5dc-fb38-4e8b-ae1d-1ad5eb060fbd&siteId=us-y4p&pageId=1p-autolink&contentUuid=49c50848-268a-3709-ac6a-5d8ab20b7ddb&featureId=text-link&merchantName=Meta&linkText=his+statement&custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5tZXRhLmNvbS9zdXBlcmludGVsbGlnZW5jZS8iLCJjb250ZW50VXVpZCI6IjQ5YzUwODQ4LTI2OGEtMzcwOS1hYzZhLTVkOGFiMjBiN2RkYiIsIm9yaWdpbmFsVXJsIjoiaHR0cHM6Ly93d3cubWV0YS5jb20vc3VwZXJpbnRlbGxpZ2VuY2UvIn0&signature=AQAAAUyMXmSE-Af6_MVzSYVa1XGGPabB5b0AEyUq2F_DsT4W&gcReferrer=https%3A%2F%2Fwww.meta.com%2Fsuperintelligence%2F",
    "https://shopping.yahoo.com/rdlw?merchantId=e160a5dc-fb38-4e8b-ae1d-1ad5eb060fbd&siteId=us-y4p&pageId=1p-autolink&contentUuid=49c50848-268a-3709-ac6a-5d8ab20b7ddb&featureId=text-link&merchantName=Meta&linkText=the+statement&custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5tZXRhLmNvbS9zdXBlcmludGVsbGlnZW5jZS8iLCJjb250ZW50VXVpZCI6IjQ5YzUwODQ4LTI2OGEtMzcwOS1hYzZhLTVkOGFiMjBiN2RkYiIsIm9yaWdpbmFsVXJsIjoiaHR0cHM6Ly93d3cubWV0YS5jb20vc3VwZXJpbnRlbGxpZ2VuY2UvIn0&signature=AQAAAUyMXmSE-Af6_MVzSYVa1XGGPabB5b0AEyUq2F_DsT4W&gcReferrer=https%3A%2F%2Fwww.meta.com%2Fsuperintelligence%2F",
    "https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand",
    "https://guide.thecooldown.com/journeys/use-your-voice/",
    "https://artificialintelligenceact.eu/high-level-summary/#:~:text=General%20purpose%20AI%20(GPAI):%20*%20All%20GPAI,report%20serious%20incidents%20and%20ensure%20cybersecurity%20protections.",
    "https://theaipi.org/april-voters-prefer-ai-regulation-over-self-regulation/",
    "https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand#",
    "https://www.theguardian.com/technology/2025/jul/30/zuckerberg-superintelligence-meta-ai",
    "https://www.thecooldown.com/future-newsletter/?recob6oAvHAOhKaCi",
    "https://shopping.yahoo.com/rdlw?merchantId=e160a5dc-fb38-4e8b-ae1d-1ad5eb060fbd&siteId=us-y4p&pageId=1p-autolink&contentUuid=49c50848-268a-3709-ac6a-5d8ab20b7ddb&featureId=text-link&merchantName=Meta&linkText=a+statement&custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5tZXRhLmNvbS9zdXBlcmludGVsbGlnZW5jZS8iLCJjb250ZW50VXVpZCI6IjQ5YzUwODQ4LTI2OGEtMzcwOS1hYzZhLTVkOGFiMjBiN2RkYiIsIm9yaWdpbmFsVXJsIjoiaHR0cHM6Ly93d3cubWV0YS5jb20vc3VwZXJpbnRlbGxpZ2VuY2UvIn0&signature=AQAAAUyMXmSE-Af6_MVzSYVa1XGGPabB5b0AEyUq2F_DsT4W&gcReferrer=https%3A%2F%2Fwww.meta.com%2Fsuperintelligence%2F",
    "https://guide.thecooldown.com/recording-votes/do-you-worry-about-companies-having-too-much-of-your-personal-data/?answer=4&article=recob6oAvHAOhKaCi",
    "https://www.usa.gov/elected-officials",
    "https://guide.thecooldown.com/recording-votes/do-you-worry-about-companies-having-too-much-of-your-personal-data/?answer=1&article=recob6oAvHAOhKaCi",
    "https://rb.gy/ivhzmj"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "AI technology",
      "weight": 0.09883932
    },
    {
      "name": "AI",
      "weight": 0.090954065
    },
    {
      "name": "AI energy concerns",
      "weight": 0.09061797
    },
    {
      "name": "many AI proponents",
      "weight": 0.08593834
    },
    {
      "name": "Meta head Mark Zuckerberg",
      "weight": 0.075201504
    },
    {
      "name": "AI superintelligence",
      "weight": 0.073026046
    },
    {
      "name": "government regulation",
      "weight": 0.07146391
    },
    {
      "name": "Mark Zuckerberg",
      "weight": 0.06864337
    },
    {
      "name": "Zuckerberg",
      "weight": 0.066464804
    },
    {
      "name": "personal superintelligence",
      "weight": 0.061557144
    }
  ],
  "topics": [
    {
      "name": "Business Leaders"
    },
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Business News/Company News",
      "score": 0.96533203125
    },
    {
      "name": "/News/Technology News",
      "score": 0.9453125
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.60107421875
    },
    {
      "name": "/Online Communities/Social Networks",
      "score": 0.43017578125
    },
    {
      "name": "/Arts & Entertainment/Celebrities & Entertainment News",
      "score": 0.35595703125
    }
  ],
  "sentiment": {
    "positive": 0.8357101,
    "negative": 0.045297086,
    "neutral": 0.11899281
  },
  "summary": "Mark Zuckerberg, CEO of Meta, the parent company of Facebook, WhatsApp, and Instagram, has stated that the company is aiming to develop \"personal superintelligence\" in its AI technology, or AI superintelligence, in a statement ahead of its quarterly earnings announcement. The company has been investing hundreds of billions of dollars into AI technology and has been aiming to build what Zuckerberg has called \"personalsuperintelligence\" rather than enterprise-level AI aimed at automating all valuable work. However, Zuckerberg acknowledged that risks of superintelligence will raise novel safety concerns but emphasized the importance of maintaining a free society and focusing on empowering people. The future of AI technology also has significant implications for public health and the environment, as well as public health. While the European Union's regulations governing AI went into effect in August 2024, governments have been slow to respond to the risks it poses to AI, including on issues such as copyright enforcement.",
  "shortSummary": "Mark Zuckerberg's Meta is investing billions in AI technology, focusing on creating \"personal superintelligence\" but acknowledges risks and challenges of its potential impact on human society and the environment.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "d0217dbdb23d4729ab9b008c3fd87719",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand#",
      "text": "On average, a ChatGPT query needs nearly 10 times as much electricity to process as a Google search. In that difference lies a coming sea change in how the US, Europe, and the world at large will consume power \u2014 and how much that will cost.\nFor years, data centers displayed a remarkably stable appetite for power, even as their workloads mounted. Now, as the pace of efficiency gains in electricity use slows and the AI revolution gathers steam, Goldman Sachs Research estimates that data center power demand will grow 160% by 2030.\nAt present, data centers worldwide consume 1-2% of overall power, but this percentage will likely rise to 3-4% by the end of the decade. In the US and Europe, this increased demand will help drive the kind of electricity growth that hasn\u2019t been seen in a generation. Along the way, the carbon dioxide emissions of data centers may more than double between 2022 and 2030.\nIn a series of three reports, Goldman Sachs Research analysts lay out the US, European, and global implications of this spike in electricity demand. It isn\u2019t that our demand for data has been meager in the recent past. In fact, data center workloads nearly tripled between 2015 and 2019. Through that period, though, data centers\u2019 demand for power remained flattish, at about 200 terawatt-hours per year. In part, this was because data centers kept growing more efficient in how they used the power they drew, according to the Goldman Sachs Research reports, led by Carly Davenport, Alberto Gandolfi, and Brian Singer.\nBut since 2020, the efficiency gains appear to have dwindled, and the power consumed by data centers has risen. Some AI innovations will boost computing speed faster than they ramp up their electricity use, but the widening use of AI will still imply an increase in the technology\u2019s consumption of power. A single ChatGPT query requires 2.9 watt-hours of electricity, compared with 0.3 watt-hours for a Google search, according to the International Energy Agency. Goldman Sachs Research estimates the overall increase in data center power consumption from AI to be on the order of 200 terawatt-hours per year between 2023 and 2030. By 2028, our analysts expect AI to represent about 19% of data center power demand.\nIn tandem, the expected rise of data center carbon dioxide emissions will represent a \u201csocial cost\u201d of $125-140 billion (at present value), our analysts believe. \u201cConversations with technology companies indicate continued confidence in driving down energy intensity but less confidence in meeting absolute emissions forecasts on account of rising demand,\u201d they write. They expect substantial investments by tech firms to underwrite new renewables and commercialize emerging nuclear generation capabilities. And AI may also provide benefits by accelerating innovation \u2014 for example, in health care, agriculture, education, or in emissions-reducing energy efficiencies.\nOver the last decade, US power demand growth has been roughly zero, even though the population and its economic activity have increased. Efficiencies have helped; one example is the LED light, which drives lower power use. But that is set to change. Between 2022 and 2030, the demand for power will rise roughly 2.4%, Goldman Sachs Research estimates \u2014 and around 0.9 percent points of that figure will be tied to data centers.\nThat kind of spike in power demand hasn\u2019t been seen in the US since the early years of this century. It will be stoked partly by electrification and industrial reshoring, but also by AI. Data centers will use 8% of US power by 2030, compared with 3% in 2022.\nUS utilities will need to invest around $50 billion in new generation capacity just to support data centers alone. In addition, our analysts expect incremental data center power consumption in the US will drive around 3.3 billion cubic feet per day of new natural gas demand by 2030, which will require new pipeline capacity to be built.\nOver the past 15 years, Europe\u2019s power demand has been severely hit by a sequence of shocks: the global financial crisis, the covid pandemic, and the energy crisis triggered by the war in Ukraine. But it has also suffered due to a slower-than-expected pick up in electrification and the ongoing de-industrialization of the European economy. As a result, since a 2008 peak, electricity demand has cumulatively declined by nearly 10%.\nGoing forward, between 2023 and 2033, thanks to both the expansion of data centers and an acceleration of electrification, Europe\u2019s power demand could grow by 40% and perhaps even 50%, according to Goldman Sachs Research. At the moment, around 15% of the world\u2019s data centers are located in Europe. By 2030, the power needs of these data centers will match the current total consumption of Portugal, Greece, and the Netherlands combined.\nData center power demand will rise in two kinds of European countries, our analysts write. The first sort is those with cheap and abundant power from nuclear, hydro, wind, or solar sources, such as the Nordic nations, Spain and France. The second kind will include countries with large financial services and tech companies, which offer tax breaks or other incentives to attract data centers. The latter category includes Germany, the UK, and Ireland.\nEurope has the oldest power grid in the world, so keeping new data centers electrified will require more investment. Our analysts expect nearly \u20ac800 billion ($861 billion) in spending on transmission and distribution over the coming decade, as well as nearly \u20ac850 billion in investment on solar, onshore wind, and offshore wind energy.\nThis article is being provided for educational purposes only. The information contained in this article does not constitute a recommendation from any Goldman Sachs entity to the recipient, and Goldman Sachs is not providing any financial, economic, legal, investment, accounting, or tax advice through this article or to its recipient. Neither Goldman Sachs nor any of its affiliates makes any representation or warranty, express or implied, as to the accuracy or completeness of the statements or any information contained in this article and any liability therefore (including in respect of direct, indirect, or consequential loss or damage) is expressly disclaimed.\nOur signature newsletter with insights and analysis from across the firm\nBy submitting this information, you agree that the information you are providing is subject to Goldman Sachs\u2019 privacy policy and Terms of Use. You consent to receive our newletter via email."
    },
    {
      "url": "https://rb.gy/ivhzmj",
      "text": "TCD\nMarketplace\nYour go-to resource for helping yourself while\nhelping the planet\ud83d\udca1\nMarketplace Spotlight\n\ud83d\udca1Connect with these trusted partners to save more, waste less, and upgrade your life\nAt The Cool Down, we're all about making it easy to help yourself while helping the planet.\nThe lifestyle solutions we've curated here feature partners we've vetted across a wide range of everyday activities \u2014 everything from the way you power your home to the way you buy your food to the way you get rid of your old stuff. Check out the list below, and don't miss the TCD Guide for a deep dive into all the smart choices you can make for yourself and your family.\nPS: We regularly add new partners to our marketplace, so be sure to sign up for alerts below, and please drop us a line at hello@thecooldown.com if you have specific problems you're trying to solve.\nJump to...\n\ud83c\udfe0 Upgrade your home and lower your bills\n\ud83c\udf54 Eat better food and save money on groceries\n\ud83d\udcb8 Declutter your life and make money on your stuff\n\ud83c\udfe0 Upgrade your home and lower your bills\nThanks to massive tax credits and rapid innovation, it's never been cheaper or easier to cut your utility bills by upgrading your home and using less energy. Here's how to get started:\n\u2705 Rewiring America can help you make sense of all the tax incentives available to you.\n\u2705 EnergySage makes it easy to save thousands on home solar by comparing quotes from trusted installers \u2014 and depending on where you live, they can help you save big on a heat pump or take advantage of community solar too.\n\u2705 Duxtop offers a sleek, affordable induction burner that lets you try the hottest, healthiest cooking technology without tearing out your old stove.\nMore from the TCD Guide\n\ud83c\udf54 Eat better food and save money on groceries\nGrocery bills are officially out of control these days, but there are more options than ever before to save money on delicious food and contribute to waste reduction along the way. These are our favorites:\n\u2705 Flashfood's free app makes it easy to browse for massive deals at local grocery stores on fresh food that's nearing its expiration date.\n\u2705 Too Good To Go's free app lets you pick up surprise bags of extra food from local restaurants at ridiculous discounts.\n\u2705 Martie and Misfits Market both give you ultra-convenient options for steep discounts on home deliveries.\nMore from the TCD Guide\n\ud83d\udcb8 Declutter your life and make money on your stuff\nIf you're like us, you probably have a closet (or closets) full of old stuff you need to get rid of but feel bad about trashing. Fortunately, the circular revolution means there are plenty of ways to give your stuff a second life and make money in the process:\n\u2705 GotSneakers will pay you cash every time you send in a free bag of your old shoes.\n\u2705 Trashie's convenient Take Back Bag can handle everything from clothes to shoes to towels to sheets \u2014 and earns you $30 in rewards every time you use it.\n\u2705 For that junk drawer full of old electronics, Walmart, Best Buy, Target, Costco, and Apple will all give you store credit when you bring in old devices."
    },
    {
      "url": "https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand",
      "text": "On average, a ChatGPT query needs nearly 10 times as much electricity to process as a Google search. In that difference lies a coming sea change in how the US, Europe, and the world at large will consume power \u2014 and how much that will cost.\nFor years, data centers displayed a remarkably stable appetite for power, even as their workloads mounted. Now, as the pace of efficiency gains in electricity use slows and the AI revolution gathers steam, Goldman Sachs Research estimates that data center power demand will grow 160% by 2030.\nAt present, data centers worldwide consume 1-2% of overall power, but this percentage will likely rise to 3-4% by the end of the decade. In the US and Europe, this increased demand will help drive the kind of electricity growth that hasn\u2019t been seen in a generation. Along the way, the carbon dioxide emissions of data centers may more than double between 2022 and 2030.\nIn a series of three reports, Goldman Sachs Research analysts lay out the US, European, and global implications of this spike in electricity demand. It isn\u2019t that our demand for data has been meager in the recent past. In fact, data center workloads nearly tripled between 2015 and 2019. Through that period, though, data centers\u2019 demand for power remained flattish, at about 200 terawatt-hours per year. In part, this was because data centers kept growing more efficient in how they used the power they drew, according to the Goldman Sachs Research reports, led by Carly Davenport, Alberto Gandolfi, and Brian Singer.\nBut since 2020, the efficiency gains appear to have dwindled, and the power consumed by data centers has risen. Some AI innovations will boost computing speed faster than they ramp up their electricity use, but the widening use of AI will still imply an increase in the technology\u2019s consumption of power. A single ChatGPT query requires 2.9 watt-hours of electricity, compared with 0.3 watt-hours for a Google search, according to the International Energy Agency. Goldman Sachs Research estimates the overall increase in data center power consumption from AI to be on the order of 200 terawatt-hours per year between 2023 and 2030. By 2028, our analysts expect AI to represent about 19% of data center power demand.\nIn tandem, the expected rise of data center carbon dioxide emissions will represent a \u201csocial cost\u201d of $125-140 billion (at present value), our analysts believe. \u201cConversations with technology companies indicate continued confidence in driving down energy intensity but less confidence in meeting absolute emissions forecasts on account of rising demand,\u201d they write. They expect substantial investments by tech firms to underwrite new renewables and commercialize emerging nuclear generation capabilities. And AI may also provide benefits by accelerating innovation \u2014 for example, in health care, agriculture, education, or in emissions-reducing energy efficiencies.\nOver the last decade, US power demand growth has been roughly zero, even though the population and its economic activity have increased. Efficiencies have helped; one example is the LED light, which drives lower power use. But that is set to change. Between 2022 and 2030, the demand for power will rise roughly 2.4%, Goldman Sachs Research estimates \u2014 and around 0.9 percent points of that figure will be tied to data centers.\nThat kind of spike in power demand hasn\u2019t been seen in the US since the early years of this century. It will be stoked partly by electrification and industrial reshoring, but also by AI. Data centers will use 8% of US power by 2030, compared with 3% in 2022.\nUS utilities will need to invest around $50 billion in new generation capacity just to support data centers alone. In addition, our analysts expect incremental data center power consumption in the US will drive around 3.3 billion cubic feet per day of new natural gas demand by 2030, which will require new pipeline capacity to be built.\nOver the past 15 years, Europe\u2019s power demand has been severely hit by a sequence of shocks: the global financial crisis, the covid pandemic, and the energy crisis triggered by the war in Ukraine. But it has also suffered due to a slower-than-expected pick up in electrification and the ongoing de-industrialization of the European economy. As a result, since a 2008 peak, electricity demand has cumulatively declined by nearly 10%.\nGoing forward, between 2023 and 2033, thanks to both the expansion of data centers and an acceleration of electrification, Europe\u2019s power demand could grow by 40% and perhaps even 50%, according to Goldman Sachs Research. At the moment, around 15% of the world\u2019s data centers are located in Europe. By 2030, the power needs of these data centers will match the current total consumption of Portugal, Greece, and the Netherlands combined.\nData center power demand will rise in two kinds of European countries, our analysts write. The first sort is those with cheap and abundant power from nuclear, hydro, wind, or solar sources, such as the Nordic nations, Spain and France. The second kind will include countries with large financial services and tech companies, which offer tax breaks or other incentives to attract data centers. The latter category includes Germany, the UK, and Ireland.\nEurope has the oldest power grid in the world, so keeping new data centers electrified will require more investment. Our analysts expect nearly \u20ac800 billion ($861 billion) in spending on transmission and distribution over the coming decade, as well as nearly \u20ac850 billion in investment on solar, onshore wind, and offshore wind energy.\nThis article is being provided for educational purposes only. The information contained in this article does not constitute a recommendation from any Goldman Sachs entity to the recipient, and Goldman Sachs is not providing any financial, economic, legal, investment, accounting, or tax advice through this article or to its recipient. Neither Goldman Sachs nor any of its affiliates makes any representation or warranty, express or implied, as to the accuracy or completeness of the statements or any information contained in this article and any liability therefore (including in respect of direct, indirect, or consequential loss or damage) is expressly disclaimed.\nOur signature newsletter with insights and analysis from across the firm\nBy submitting this information, you agree that the information you are providing is subject to Goldman Sachs\u2019 privacy policy and Terms of Use. You consent to receive our newletter via email."
    },
    {
      "url": "https://artificialintelligenceact.eu/high-level-summary/#:~:text=General%20purpose%20AI%20(GPAI):%20*%20All%20GPAI,report%20serious%20incidents%20and%20ensure%20cybersecurity%20protections.",
      "text": "Updated on 30 May in accordance with the Corrigendum version of the AI Act.\nIn this article we provide you with a high-level summary of the AI Act, selecting the parts which are most likely to be relevant to you regardless of who you are. We provide links to the original document where relevant so that you can always reference the Act text.\nTo explore the full text of the AI Act yourself, use our AI Act Explorer. Alternatively, if you want to know which parts of the text are most relevant to you, use our Compliance Checker.\nFour-point summary\nThe AI Act classifies AI according to its risk:\n- Unacceptable risk is prohibited (e.g. social scoring systems and manipulative AI).\n- Most of the text addresses high-risk AI systems, which are regulated.\n- A smaller section handles limited risk AI systems, subject to lighter transparency obligations: developers and deployers must ensure that end-users are aware that they are interacting with AI (chatbots and deepfakes).\n- Minimal risk is unregulated (including the majority of AI applications currently available on the EU single market, such as AI enabled video games and spam filters \u2013 at least in 2021; this is changing with generative AI).\nThe majority of obligations fall on providers (developers) of high-risk AI systems.\n- Those that intend to place on the market or put into service high-risk AI systems in the EU, regardless of whether they are based in the EU or a third country.\n- And also third country providers where the high risk AI system\u2019s output is used in the EU.\nUsers are natural or legal persons that deploy an AI system in a professional capacity, not affected end-users.\n- Users (deployers) of high-risk AI systems have some obligations, though less than providers (developers).\n- This applies to users located in the EU, and third country users where the AI system\u2019s output is used in the EU.\nGeneral purpose AI (GPAI):\n- All GPAI model providers must provide technical documentation, instructions for use, comply with the Copyright Directive, and publish a summary about the content used for training.\n- Free and open licence GPAI model providers only need to comply with copyright and publish the training data summary, unless they present a systemic risk.\n- All providers of GPAI models that present a systemic risk \u2013 open or closed \u2013 must also conduct model evaluations, adversarial testing, track and report serious incidents and ensure cybersecurity protections.\nProhibited AI systems (Chapter II, Art. 5)\nThe following types of AI system are \u2018Prohibited\u2019 according to the AI Act.\nAI systems:\n- deploying subliminal, manipulative, or deceptive techniques to distort behaviour and impair informed decision-making, causing significant harm.\n- exploiting vulnerabilities related to age, disability, or socio-economic circumstances to distort behaviour, causing significant harm.\n- biometric categorisation systems inferring sensitive attributes (race, political opinions, trade union membership, religious or philosophical beliefs, sex life, or sexual orientation), except labelling or filtering of lawfully acquired biometric datasets or when law enforcement categorises biometric data.\n- social scoring, i.e., evaluating or classifying individuals or groups based on social behaviour or personal traits, causing detrimental or unfavourable treatment of those people.\n- assessing the risk of an individual committing criminal offenses solely based on profiling or personality traits, except when used to augment human assessments based on objective, verifiable facts directly linked to criminal activity.\n- compiling facial recognition databases by untargeted scraping of facial images from the internet or CCTV footage.\n- inferring emotions in workplaces or educational institutions, except for medical or safety reasons.\n- \u2018real-time\u2019 remote biometric identification (RBI) in publicly accessible spaces for law enforcement, except when:\n- searching for missing persons, abduction victims, and people who have been human trafficked or sexually exploited;\n- preventing substantial and imminent threat to life, or foreseeable terrorist attack; or\n- identifying suspects in serious crimes (e.g., murder, rape, armed robbery, narcotic and illegal weapons trafficking, organised crime, and environmental crime, etc.).\nNotes on remote biometric identification:\nUsing AI-enabled real-time RBI is only allowed when not using the tool would cause considerable harm and must account for affected persons\u2019 rights and freedoms.\nBefore deployment, police must complete a fundamental rights impact assessment and register the system in the EU database, though, in duly justified cases of urgency, deployment can commence without registration, provided that it is registered later without undue delay.\nBefore deployment, they also must obtain authorisation from a judicial authority or independent administrative authority[1], though, in duly justified cases of urgency, deployment can commence without authorisation, provided that authorisation is requested within 24 hours. If authorisation is rejected, deployment must cease immediately, deleting all data, results, and outputs.\n\u21b2 [1] Independent administrative authorities may be subject to greater political influence than judicial authorities (Hacker, 2024).\nHigh risk AI systems (Chapter III)\nSome AI systems are considered \u2018High risk\u2019 under the AI Act. Providers of those systems will be subject to additional requirements.\nClassification rules for high-risk AI systems (Art. 6)\nHigh risk AI systems are those:\n- used as a safety component or a product covered by EU laws in Annex I AND required to undergo a third-party conformity assessment under those Annex I laws; OR\n- listed under Annex III use cases (below), except if:\n- the AI system performs a narrow procedural task;\n- improves the result of a previously completed human activity;\n- detects decision-making patterns or deviations from prior decision-making patterns and is not meant to replace or influence the previously completed human assessment without proper human review; or\n- performs a preparatory task to an assessment relevant for the purpose of the use cases listed in Annex III.\n- AI systems listed under Annex III are always considered high-risk if it profiles individuals, i.e. automated processing of personal data to assess various aspects of a person\u2019s life, such as work performance, economic situation, health, preferences, interests, reliability, behaviour, location or movement.\n- Providers whose AI system falls under the use cases in Annex III but believes it is not high-risk must document such an assessment before placing it on the market or putting it into service.\nRequirements for providers of high-risk AI systems (Art. 8\u201317)\nHigh risk AI providers must:\n- Establish a risk management system throughout the high risk AI system\u2019s lifecycle;\n- Conduct data governance, ensuring that training, validation and testing datasets are relevant, sufficiently representative and, to the best extent possible, free of errors and complete according to the intended purpose.\n- Draw up technical documentation to demonstrate compliance and provide authorities with the information to assess that compliance.\n- Design their high risk AI system for record-keeping to enable it to automatically record events relevant for identifying national level risks and substantial modifications throughout the system\u2019s lifecycle.\n- Provide instructions for use to downstream deployers to enable the latter\u2019s compliance.\n- Design their high risk AI system to allow deployers to implement human oversight.\n- Design their high risk AI system to achieve appropriate levels of accuracy, robustness, and cybersecurity.\n- Establish a quality management system to ensure compliance.\n| Annex III use cases |\n|---|\n| Non-banned biometrics: Remote biometric identification systems, excluding biometric verification that confirm a person is who they claim to be. Biometric categorisation systems inferring sensitive or protected attributes or characteristics. Emotion recognition systems. |\n| Critical infrastructure: Safety components in the management and operation of critical digital infrastructure, road traffic and the supply of water, gas, heating and electricity. |\n| Education and vocational training: AI systems determining access, admission or assignment to educational and vocational training institutions at all levels. Evaluating learning outcomes, including those used to steer the student\u2019s learning process. Assessing the appropriate level of education for an individual. Monitoring and detecting prohibited student behaviour during tests. |\n| Employment, workers management and access to self-employment: AI systems used for recruitment or selection, particularly targeted job ads, analysing and filtering applications, and evaluating candidates. Promotion and termination of contracts, allocating tasks based on personality traits or characteristics and behaviour, and monitoring and evaluating performance. |\n| Access to and enjoyment of essential public and private services: AI systems used by public authorities for assessing eligibility to benefits and services, including their allocation, reduction, revocation, or recovery. Evaluating creditworthiness, except when detecting financial fraud. Evaluating and classifying emergency calls, including dispatch prioritising of police, firefighters, medical aid and urgent patient triage services. Risk assessments and pricing in health and life insurance. |\n| Law enforcement: AI systems used to assess an individual\u2019s risk of becoming a crime victim. Polygraphs. Evaluating evidence reliability during criminal investigations or prosecutions. Assessing an individual\u2019s risk of offending or re-offending not solely based on profiling or assessing personality traits or past criminal behaviour. Profiling during criminal detections, investigations or prosecutions. |\n| Migration, asylum and border control management: Polygraphs. Assessments of irregular migration or health risks. Examination of applications for asylum, visa and residence permits, and associated complaints related to eligibility. Detecting, recognising or identifying individuals, except verifying travel documents. |\n| Administration of justice and democratic processes: AI systems used in researching and interpreting facts and applying the law to concrete facts or used in alternative dispute resolution. Influencing elections and referenda outcomes or voting behaviour, excluding outputs that do not directly interact with people, like tools used to organise, optimise and structure political campaigns. |\nGeneral purpose AI (GPAI)\nGPAI model means an AI model, including when trained with a large amount of data using self-supervision at scale, that displays significant generality and is capable to competently perform a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications. This does not cover AI models that are used before release on the market for research, development and prototyping activities.\nGPAI system means an AI system which is based on a general purpose AI model, that has the capability to serve a variety of purposes, both for direct use as well as for integration in other AI systems.\nGPAI systems may be used as high risk AI systems or integrated into them. GPAI system providers should cooperate with such high risk AI system providers to enable the latter\u2019s compliance.\nAll providers of GPAI models must:\n- Draw up technical documentation, including training and testing process and evaluation results.\n- Draw up information and documentation to supply to downstream providers that intend to integrate the GPAI model into their own AI system in order that the latter understands capabilities and limitations and is enabled to comply.\n- Establish a policy to respect the Copyright Directive.\n- Publish a sufficiently detailed summary about the content used for training the GPAI model.\nFree and open licence GPAI models \u2013 whose parameters, including weights, model architecture and model usage are publicly available, allowing for access, usage, modification and distribution of the model \u2013 only have to comply with the latter two obligations above, unless the free and open licence GPAI model is systemic.\nGPAI models present systemic risks when the cumulative amount of compute used for its training is greater than 1025 floating point operations (FLOPs). Providers must notify the Commission if their model meets this criterion within 2 weeks. The provider may present arguments that, despite meeting the criteria, their model does not present systemic risks. The Commission may decide on its own, or via a qualified alert from the scientific panel of independent experts, that a model has high impact capabilities, rendering it systemic.\nIn addition to the four obligations above, providers of GPAI models with systemic risk must also:\n- Perform model evaluations, including conducting and documenting adversarial testing to identify and mitigate systemic risk.\n- Assess and mitigate possible systemic risks, including their sources.\n- Track, document and report serious incidents and possible corrective measures to the AI Office and relevant national competent authorities without undue delay.\n- Ensure an adequate level of cybersecurity protection.\nAll GPAI model providers may demonstrate compliance with their obligations if they voluntarily adhere to a code of practice until European harmonised standards are published, compliance with which will lead to a presumption of conformity. Providers that don\u2019t adhere to codes of practice must demonstrate alternative adequate means of compliance for Commission approval.\nCodes of practice\n- Will account for international approaches.\n- Will cover but not necessarily limited to the above obligations, particularly the relevant information to include in technical documentation for authorities and downstream providers, identification of the type and nature of systemic risks and their sources, and the modalities of risk management accounting for specific challenges in addressing risks due to the way they may emerge and materialise throughout the value chain.\n- AI Office may invite GPAI model providers, relevant national competent authorities to participate in drawing up the codes, while civil society, industry, academia, downstream providers and independent experts may support the process.\nGovernance\nHow will the AI Act be implemented?\n- The AI Office will be established, sitting within the Commission, to monitor the effective implementation and compliance of GPAI model providers.\n- Downstream providers can lodge a complaint regarding the upstream providers infringement to the AI Office.\n- The AI Office may conduct evaluations of the GPAI model to:\n- assess compliance where the information gathered under its powers to request information is insufficient.\n- Investigate systemic risks, particularly following a qualified report from the scientific panel of independent experts.\nTimelines\n- After entry into force, the AI Act will apply by the following deadlines:\n- 6 months for prohibited AI systems.\n- 12 months for GPAI.\n- 24 months for high risk AI systems under Annex III.\n- 36 months for high risk AI systems under Annex I.\n- Codes of practice must be ready 9 months after entry into force.\nSee our full implementation timeline for all key milestones relating to the implementation of the AI Act."
    },
    {
      "url": "https://www.theguardian.com/technology/2025/jul/30/zuckerberg-superintelligence-meta-ai",
      "text": "Whether it\u2019s poaching top talent away from competitors, acquiring AI startups or proclaiming that it will build data centers the size of Manhattan, Meta has been on a spending spree to boost its artificial intelligence capabilities for months now.\nThe massive splurge is paying off, according to Meta\u2019s chief executive. In a new memo posted on Wednesday ahead of the company\u2019s quarterly earnings report, Mark Zuckerberg, describes his ambitions for developing what he calls \u201csuperintelligence\u201d.\n\u201cOver the last few months we have begun to see glimpses of our AI systems improving themselves,\u201d Zuckerberg wrote. \u201cThe improvement is slow for now, but undeniable. Developing superintelligence is now in sight.\u201d\nWall Street investors are happy with the expensive course Zuckerberg is charting. After the company reported better-than-expected financial results for yet another quarter, its stock soared by double digits.\nThough Zuckerberg did not provide any details of what would qualify as \u201csuperintelligence\u201d versus standard artificial intelligence, he did say that it would pose \u201cnovel safety concerns\u201d.\n\u201cWe\u2019ll need to be rigorous about mitigating these risks and careful about what we choose to open source,\u201d he wrote.\nZuckerberg wrote that the company differs from other AI firms in that Meta aims to bring \u201cpersonal superintelligence to everyone\u201d. Other companies are focused on primarily using \u201csuperintelligence\u201d for productivity and to automate \u201call valuable work\u201d, he wrote.\n\u201cThe rest of this decade seems likely to be the decisive period for determining the path this technology will take, and whether superintelligence will be a tool for personal empowerment or a force focused on replacing large swaths of society,\u201d he wrote.\nInvestors want to know: does AI mean cashflow?\nInvestors are looking for signs that the parent company of WhatsApp, Instagram and Facebook is spending its billions efficiently. The social media company reported its second quarter earnings on Wednesday after the close of the New York stock exchange and beat investor expectations yet again sending stocks soaring 10%. Analysts expect Meta will have to answer questions about whether the revenue the company is bringing in will help offset the hundreds of billions the firm is spending on recruiting and infrastructure, collectively known as capital expenditure.\n\u201cAI-driven investments into Meta\u2019s advertising business continue to pay off, bolstering its revenue as the company pours billions of dollars into AI ambitions like superintelligence,\u201d said Minda Smiley, a senior analyst at Emarketer. \u201cBut Meta\u2019s exorbitant spending on its AI visions will continue to draw questions and scrutiny from investors who are eager to see returns.\u201d\nMeta reported $7.14 in earnings per share (EPS) on $47.52bn in revenue, surpassing Wall Street expectations of $5.92 in earnings per share on $44.8bn in revenue. This quarter is the latest in the company\u2019s multiple-quarter streak of exceeding Wall Street\u2019s financial expectations despite enormous spending on AI.\nThe company also said it expects to bring in $47.5bn to $50.5bn in revenue in the third quarter of 2025.\nZuckerberg provided few tangible updates in the memo, but one thing is clear: getting to this so-called higher level of intelligence will require a great deal of capital. Meta reported that the total costs and expenditures for the second quarter of 2025 came in at $27.07bn \u2013 up 12% year over year. Capital expenditures for the quarter were $17.01bn.\nThe company also provided updated guidance on how much the firm expects to spend in the next few months. Meta said it expected to spend between $114bn and $118bn in total expenses in 2025 \u2013 a slight adjustment from its previous projection of between $113bn and $118bn. Of that, Meta said it expected its capital expenditures to amount to somewhere in the range of $66bn and $72bn. The company previously predicted it would spend between $64bn and $72bn which was increased from an even earlier prediction of $60bn to $65bn.\nMeta is still in the process of planning for 2026, but said that it expected total expenses in the next year to increase beyond 2025 spending.\n\u201cThe largest single driver of growth will be infrastructure costs, driven by a sharp acceleration in depreciation expense growth and higher operating costs as we continue to scale up our infrastructure fleet,\u201d the company said in a press release. \u201cAside from infrastructure, we expect the second largest driver of growth to be employee compensation as we add technical talent in priority areas and recognize a full year of compensation expenses for employees hired throughout 2025.\u201d\nThe company has been building out its new superintelligence labs team with talent from competing AI firms. Meta first invested $14.3bn into Scale AI in exchange for a 49% stake in the company, and brought the startup\u2019s CEO, Alexandr Wang, on as chief AI officer. Since then, several reports indicate Meta is attracting engineers and other employees away from firms like Apple, Github and several startups with huge compensation packages \u2013 including at least one that came in over $200m, according to Bloomberg.\n\u201cTo win the superintelligence race requires the best of the best talent and Meta has been on a roll when it comes to recruiting top AI talent,\u201d said Forrester\u2019s research director, Mike Proulx. \u201cMoney talks and Meta has plenty of it \u2013 reaching into the company\u2019s deep pockets to lure luminaries from its competition with lavish compensation packages, while spending hundreds of billions on datacenters to power and scale its AI initiatives.\u201d\nWhile Reality Labs continues to be a small contributor to revenue, bringing in $370m in the second quarter, Zuckerberg remains bullish on the utility and longevity of its AI glasses. He compared wearing AI glasses with wearing contact lenses in that he would be at a cognitive disadvantage without them.\n\u201cI personally think that if you don\u2019t have glasses that have AI you will be at a cognitive disadvantage,\u201d he said. \u201cIt is kind of what we have been maxing out with Reality Labs.\u201d\nAdvertising revenue, the company\u2019s primary source of revenue, continues to grow. Meta brought in $46.6bn in advertising revenue in the second quarter, up from $38.3bn for the same quarter in 2024. Meta chief financial officer, Susan Li, said on the investor call that the company does not expect WhatsApp, one of its newer sources of advertising, to be a \u201cmeaningful contributor\u201d to overall growth of ad revenue for the next few years.\n\u201cWe also expect WhatsApp ads and status to earn a lower average price than Facebook or Instagram ads for the foreseeable future, due in part to WhatsApp\u2019s skew toward lower monetizing markets and more limited information that can be used for targeting,\u201d Li said."
    },
    {
      "url": "https://theaipi.org/april-voters-prefer-ai-regulation-over-self-regulation/",
      "text": "New Poll: Voters Prefer AI Regulation that Mandates Safety Measures Over Industry Self-Regulation\nAn overwhelming majority of American voters prefer regulation that mandates safety testing of frontier AI systems and government oversight to certify new AI models, while 24% prefer a non-restrictive approach.\nAfter being informed of the Senate AI Roadmap priorities and asked to rank their priorities in order, 67% of voters, the highest share, prefer monitoring to prevent AI from falling into the hands of our adversaries.\nMore than three-fourths of voters support federal regulation of AI that mandates safety measures and government oversight of AI labs instead of allowing AI companies to self-regulate, a new poll by the Artificial Intelligence Policy Institute (AIPI) shows.\nWhen presented with four high level approaches to AI governance, 80% of voters prefer a public policy approach that mandates security standards and safety measures for AI systems\u2019 most advanced models. This approach would allow the release of new AI models only after a government oversight board certifies that companies properly account for extreme risks, including the prevention of using AI to create bioweapons and launch cyber attacks. The question forced voters to choose between varying approaches to AI regulation, from pausing the technology as a whole to letting companies freely develop the technology.\nAdditionally, the survey reveals that a plurality of voters support policies to prevent AI from falling into the hands of adversaries and support regulatory measures on AI to prevent misinformation and protect the privacy of users.\n\u201cAIPI\u2019s latest poll makes it clear that voters support an approach to AI development that ensures the safety of the American public and security of the country\u2014not an industry-led approach,\u201d said Daniel Colson, Executive Director of the Artificial Intelligence Policy Institute. \u201cAmericans want transparency between the government and AI companies and support steps to prevent AI from getting out of control, especially preventing its worst possible uses. The bottom line is that voters from across the political spectrum overwhelmingly back an active government approach on AI regulation, one that centers safety and security, not free corporate development.\u201d\nSome key numbers from the poll:\n- 80% of voters\u2014including 76% of Republicans and 84% of Democrats\u2014prefer a regulatory approach that mandates safety measures of the most advanced AI models and government oversight for the certification and release of new AI models, and only 24% prefer AI companies to self-regulate and be prosecuted if models are used for illegal activity.\n- After being informed of the Senate AI Roadmap priorities and asked to rank their priorities in order, 67% of voters prefer monitoring to prevent AI from falling into the hands of our adversaries. 63% of voters\u2014including 69% of Democrats and 63% of Republicans\u2014prefer requiring safety testing and evaluations of powerful AI systems. Meanwhile, just 30% prefer federal funding to advance AI research to keep the US ahead on AI.\n- 72% of voters, including 78% of Democrats and 65% of Republicans, support creating privacy protections when AI is used.\n- 70% of voters support regulations to prevent AI misinformation\u2013including 80% of Democrats, 59% of Republicans, and 77% of voters 65 years and older. Just 7% of voters are against this.\n- 80% of voters\u2014including 84% of Democrats, 84% of Republicans, and 82% of voters 65 years and older\u2014support a law that mandates that all AI labs constructing the most powerful AI models must use state-of-the-art security to prevent the models from being stolen by hostile actors. Just 4% of all voters oppose this policy.\n- 69% of voters support regulation that would make it illegal for an AI company to retaliate against an employee if they leak information to the public suggesting that the AI company is compromising safety, including 75% of Democrats and 68% of Republicans.\n- Voters want to know when political ads are produced with AI. 64% of voters support the requirement for broadcasters to disclose when a political ad is produced with AI\u2014including 73% of Democrats and 53% of Republicans.\nAbout the Poll\nThe poll was taken from June 1 to June 5, and contained a survey of 1,481 voters nationally. The survey was conducted in English. Its margin of error is \u00b15.0 percentage points.\nSee full toplines and crosstabs here.\nAbout the Artificial Intelligence Policy Institute\nThe Artificial Intelligence Policy Institute is an AI policy and research think tank founded by Daniel Colson to advocate for ethical oversight of AI for mitigating potential catastrophic risks posed by AI. AIPI\u2019s core mission is to demonstrate that the general public has valid concerns about the future of AI and is looking for regulation and guidance from their elected representatives. If politicians want to represent the American people effectively, they must act aggressively to regulate AI\u2019s next phases of development. AIPI seeks to work with the media and policymakers to inform them of the risks of artificial intelligence and develop policies that mitigate risks from emerging technology while still benefiting from artificial intelligence.\nWhile much of the public discussion has been oriented around AI\u2019s potential to take away jobs, AIPI will be focused on centering the importance of policies designed to prevent catastrophic outcomes and mitigate the risk of extinction. Currently, most of the AI space comprises those with a vested interest in advancing AI or are academics. The AI space lacks an organization to both gauge and shape public opinion on the issues\u2014as well as to recommend legislation on the matter\u2014 and AIPI will fill that role.\nUltimately, policymakers are political actors, so the country needs an institution that can speak the language of public opinion sentiment. AIPI\u2019s mission is about being able to channel how Americans feel about artificial intelligence and pressure lawmakers to take action.\nAIPI will build relationships with lawmakers by using polling to establish AIPI as a subject matter expert on AI safety and policy issues. Politicians are incentivized to support AI slowdown policies due to the strong majority of voters supporting slowdown and regulation. But AI is currently less salient as a political issue than other topics, as so far, there have only been moderate impacts from emerging AI tech.\nAI technological advancement is and will continue to be an evolving situation, and politicians, the media, and everyday Americans need real-time information to make sense of it all. AIPI\u2019s polling will show where people stand on new developments and provide crucial policy recommendations for policymakers."
    }
  ],
  "argos_summary": "Mark Zuckerberg announced Meta's ambition to develop 'personal superintelligence,' claiming that glimpses of self-improving AI systems are emerging. While investors reacted positively to Meta's substantial AI investments, Zuckerberg acknowledged potential safety concerns associated with superintelligence. The article also highlights a recent poll indicating that a significant majority of American voters support government regulation of AI to ensure safety and prevent misuse, reflecting widespread public concern about the implications of AI technology.",
  "argos_id": "13D8MOAPW"
}