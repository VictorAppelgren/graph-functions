{
  "url": "https://www.forbes.com/sites/lanceeliot/2025/08/12/therapists-leverage-ai-for-mental-health-by-delving-into-virtual-digital-twins-of-their-clients-and-patients-minds/",
  "authorsByline": "Lance Eliot",
  "articleId": "bb94364026d04e7d9f34d8d37a79243a",
  "source": {
    "domain": "forbes.com",
    "paywall": true,
    "location": {
      "country": "us",
      "state": "NJ",
      "county": "Hudson County",
      "city": "Jersey City",
      "coordinates": {
        "lat": 40.7215682,
        "lon": -74.047455
      }
    }
  },
  "imageUrl": "https://imageio.forbes.com/specials-images/imageserve/689adf1fb3b7a76143dd2fa6/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds",
  "country": "us",
  "language": "en",
  "pubDate": "2025-08-12T07:15:00+00:00",
  "addDate": "2025-08-12T07:23:31.745052+00:00",
  "refreshDate": "2025-08-12T07:23:31.745054+00:00",
  "score": 1.0,
  "title": "Therapists Leverage AI For Mental Health By Delving Into Virtual Digital Twins Of Their Clients And Patients Minds",
  "description": "There is a rising use of medical digital twins that represent patients. Therapists can use personas in AI to represent the minds of their clients. Its good and bad news.",
  "content": "In today\u2019s column, I examine an advanced use of generative AI and large language models (LLMs) that entails therapists and other mental health professionals making use of so-called digital twins that are reflective of their respective clients and patients.\n\nThe deal is this. Via the use of personas in generative AI, a feature that nearly all LLMs inherently include, it is presumably conceivable that you could devise a persona that somewhat matches and reflects a client or patient that is undergoing therapy. This is considered a digital twin, or more specifically, a medical digital twin.\n\nYes, perhaps unnervingly, it seems possible to construct an AI-based simulated version of a client or patient that a therapist could then use to gauge potential responses and reactions to a planned line of psychological analyses and therapeutics.\n\nThis analysis of AI breakthroughs is part of my ongoing Forbes column coverage on the latest in AI, including identifying and explaining various impactful AI complexities (see the link here).\n\nAs a quick background, I\u2019ve been extensively covering and analyzing a myriad of facets regarding the advent of modern-era AI that produces mental health advice and performs AI-driven therapy. This rising use of AI has principally been spurred by the evolving advances and widespread adoption of generative AI. For a quick summary of some of my posted columns on this evolving topic, see the link here, which briefly recaps about forty of the over one hundred column postings that I\u2019ve made on the subject.\n\nThere is little doubt that this is a rapidly developing field and that there are tremendous upsides to be had, but at the same time, regrettably, hidden risks and outright gotchas come into these endeavors too. I frequently speak up about these pressing matters, including in an appearance last year on an episode of CBS\u2019s 60 Minutes, see the link here.\n\nMany therapists and mental health professionals are opting to integrate AI into their practices and overtly use the AI as a therapeutic adjunct for their clients and patients (see my coverage at the link here).\n\nEven those therapists and mental health professionals who don\u2019t go down the route of incorporating AI are bound to encounter clients and patients who are doing so. Those clients and patients will often walk in the door with preconceived beliefs about how their therapy should go or is going, spurred and prodded by what AI has told them.\n\nIn this sense, one way or another, therapists and mental health professionals are going to ultimately be impacted by the growing use of generative AI and LLMs. Right now, there are already around 700 million weekly active users of ChatGPT. You might find it of notable interest that the top-ranked use by the public of contemporary generative AI and LLMs is to consult with the AI on mental health matters, see my coverage at the link here.\n\nIf that kind of AI can do a proper job on this monumental task, then the world will be a lot better off. Many people cannot otherwise afford or gain access to human therapists, but access to generative AI is generally plentiful in comparison. It could be that such AI will greatly benefit the mental status of humankind. A dour counterargument is that such AI might undercut mental health, doing so on a massive population-level scale, see my discussion at the link here.\n\nPersonas Are Coming To The Fore\n\nLet\u2019s shift gears and focus on the use of AI-based personas.\n\nI\u2019ve repeatedly emphasized in my writing and talks about generative AI that one of the most underutilized and least known pieces of quite useful functionality is the capability of forming personas in the AI (see the link here). You can tell the AI to pretend to be a known person, such as a celebrity or historical figure, and the AI will attempt to do so.\n\nIn the context of mental health, I showcased how telling AI to simulate Sigmund Freud can be a useful learning tool for mental health professionals, see the link here. As a mental health professional, you ought to give serious consideration to making use of personas for your own self-training and personal refinement.\n\nFor example, you might craft a persona that will pretend to be a person with deep depression. You could then use this persona to hone your therapeutic prowess regarding depression in patients and clients. It can be quite useful. Plus, there is no danger since it is just AI. You can try out various avenues to gauge what works and doesn\u2019t work. No harm, no foul.\n\nFor my suggestions on how to write prompts that suitably create or cast personas, see the link here.\n\nThere is specialized parlance in the tech field that has been around for many years and refers to the concept and practice of using computers to simulate a real object or entity. The parlance is that you are crafting and making use of a digital twin. This became popular when machinery used on factory floors could be modeled digitally.\n\nWhy would a digital model or simulation of a factory assembly machine be useful?\n\nEasy-peasy, there are lots of crucial benefits.\n\nOne is that before you even construct the machine, you can try it out digitally. You can make sure that the machine will hopefully work suitably once it is constructed and put into operation. Another advantage is that you can readily make lengthy runs of the digital twin and predict when the real version might break down. This gives a heads-up to the maintenance crew working on the factory operations. They get estimates of the likely time at which the machine will potentially start to degrade.\n\nRecently, there has been a realization that digital twins can be used in other, more creative ways, such as modeling or simulating human beings. This is often referred to as a medical digital twin (note that other names and phrases are sometimes used too).\n\nIn a research article entitled \u201cToward Mechanistic Medical Digital Twins\u201d by Reinhard Laubenbacher, Fred Adler, Gary An, Filippo Castiglione, Stephen Eubank, Luis L. Fonseca, James Glazier, Tomas Helikar, Marti Jett-Tilton, Denise Kirschner, Paul Macklin6, Borna Mehrad, Beth Moore, Virginia Pasour, Ilya Shmulevich, Amber Smith, Isabel Voigt, Thomas E. Yankeelov, and Tjalf Ziemssen, Frontiers In Digital Health, March 7, 2024, these salient points were made (excerpts):\n\u2022 \u201cA fundamental challenge for personalized medicine is to capture enough of the complexity of an individual patient to determine an optimal way to keep them healthy or restore their health.\u201d\n\u2022 \u201cThis will require personalized computational models of sufficient resolution and with enough mechanistic information to provide actionable information to the clinician.\u201d\n\u2022 \u201cSuch personalized models are increasingly referred to as medical digital twins.\u201d\n\u2022 \u201cWe do not have a complete theoretical understanding of biological systems, providing a list of general principles that could form the basis of computational models, as we do for physical systems. Two other characteristic features of biological systems are genotypic and phenotypic heterogeneity across individuals and stochasticity in system dynamics.\u201d\n\u2022 \u201cDigital twin technology for health applications is still in its infancy, and extensive research and development is required.\u201d\n\nPlease note that as emphasized above, the advent of medical digital twins is still early on. There is plenty of controversy associated with the topic. One major qualm is that with a factory floor machine, you can pretty much model every physical and mechanical aspect, but the same can\u2019t be said about modeling human beings. At least not yet.\n\nLucky or not, we seem to be more complex than everyday machines. Score a point for humankind.\n\nWhen you think about devising a medical digital twin, there are customarily two major elements involved:\n\u2022 (1) The Body: Physiological human dynamics that need to be modeled.\n\u2022 (2) The Mind: Mental human dynamics that need to be modeled.\n\nSome would insist that you cannot adequately model the mind without also modeling the body. It\u2019s that classic mind-body debate; see my analysis at the link here.\n\nIf you dogmatically believe that a mind is unable to be sufficiently modeled without equally modeling the body, I guess that the rest of this discussion is going to give you heartburn. Sorry about that.\n\nWe are going to make a brash assumption that you can use generative AI to aid in crafting a kind of model or simulation of a person\u2019s mind, at least to the extent that the AI will seek to exhibit similar personality characteristics and overall psychological characteristics of the person. So, in that sense, we are going to pursue a medical digital twin that only focuses on the second of the two major elements.\n\nDoes that mean that the AI-based digital twin is missing a duality ingredient that wholly undercuts the effort?\n\nI\u2019m going to say that it doesn\u2019t, but you are welcome to take the posture that it does. We can amicably agree to disagree. On a related facet, there are advocates of medical digital twins who would insist that a medical digital twin must encompass the bodily aspects, else it isn\u2019t a medical digital twin at all. In that case, I guess we might need to drop the word \u201cmedical\u201d from this type of digital twin.\n\nJust wanted to give you a heads-up on these controversies.\n\nPersonas Of Your Clients Or Patients\n\nMoving on, let\u2019s further consider the avenue of creating a digital twin of your client or patient so that you can utilize the AI to ascertain your line of therapy and treatment.\n\nThe first step involves collecting data about the person. The odds are that a therapist will already have obtained an extensive history associated with a client or patient. Those notes and other documents could be used to feed the AI. The idea is that you will provide that data to the generative AI, and it will pattern-match and craft a persona accordingly. You might also include transcripts of your sessions. Feeding this data into AI is often done via a technique known as retrieval-augmented generation (RAG), see my explanation at the link here.\n\nPlease be very cautious in taking this type of action.\n\nReally, really, really cautious.\n\nMany therapists are already willy-nilly entering data about clients and patients into off-the-shelf publicly available LLMs. The problem is that there is almost no guarantee of data privacy with these AIs, and you could readily be violating confidentiality and HIPAA provisions. You might also need to certify consent from the client or patient, depending on various factors at play. For more, see my discussion at the link here and the link here.\n\nMake sure to consult with your attorney on these serious matters.\n\nOne approach is to stridently anonymize the data so that the client or patient is unrecognizable via the data you have entered. It would be as though you are simply creating a generic persona from scratch. Whether that will pass a legal test is something your legal counsel can advise you on.\n\nAnother approach is to set up a secure private version of an LLM, but that, too, can have legal wrinkles.\n\nMore On Personas As Digital Twins\n\nYet another approach is to merely and shallowly describe the persona based on your overall semblance of the person.\n\nThis is somewhat similar to my earlier point that you can use personas by simply entering a prompt that the devised persona is supposed to represent a person with depression. That\u2019s a vague indication and would seem untethered to a specific person. The downside, of course, is that the surface-level persona might not be of much help to you.\n\nWhat are you going to do with whatever persona you craft?\n\nYou could try to figure out the emotional triggers of the person, as represented via the persona. What kind of coping style do they have? How does their coping mechanism react to the therapy you have in mind? All sorts of therapy-oriented strategies and tactics can be explored and assessed.\n\nIn essence, you are trying out different interventions on the persona, i.e., the digital twin. Maybe you are mulling over variations of CBT techniques and want to land on a particular approach. Perhaps you often use exposure therapy and are unsure of how that will go over with the client or patients.\n\nThis provides a no-risk means of determining your therapy in a simulated environment and prepares you for sessions with the actual person.\n\nI trust and hope that any therapist or mental health professional going the route of using a persona as a digital twin is going to keep their wits about themselves. Ordinary users of AI who use personas can readily go off the deep end and believe that the persona is real.\n\nDo not let that same fate befall you.\n\nThe persona is merely the persona. Period, end of story. You cannot assume that the persona is giving you an accurate reading of the person. The AI could be completely afield in terms of how the person will actually respond and react. Expect that the AI will almost certainly overrepresent some traits, underrepresent other traits, and be convincing as it does so.\n\nConvincingness is the trick involved. Contemporary generative AI is so seemingly fluent that you are drawn into a mental trap of believability. Inside your head, you might hear this internal voice: \u201cIt must be showing me the true inner psyche of my client or patient! The AI is working miracles at modeling the person. Wow, AI is utterly amazing.\u201d\n\nYou must resist the urge to become over-reliant on the digital twin.\n\nOver-reliance is a likely possibility. Here\u2019s how. You use the persona. After doing so, you later meet with the client or patient. Everything the AI indicated as to responses and reactions appears to mirror what the person says and does during the session. Awesome. You decide to keep using the persona. Over and over, you use the persona.\n\nVoila, you are hooked. The persona has led you down a primrose path. The seemingly uncanny portrayal has been spot-on. The problem is that when the client or patient diverges from the persona, you are going to have your mind turned backward. The person must be wrong, because the persona was always right. In other words, the person is supposed to be acting as the persona does. The world has gone topsy-turvy.\n\nBut it\u2019s you, because you have forsaken your therapist mindset and allowed AI to capture and defeat your real-world acuity. That\u2019s bad news. Do not let that happen.\n\nThere is a lot more to consider when using AI as a digital twin in a mental health context. I\u2019ll be covering more in a series of postings. Be on the watch.\n\nOne quick point to get your mental juices flowing is this.\n\nSuppose that you have gotten written consent from the client or patient, and they know that you are using AI to depict a persona of them. The person comes to one of your later sessions and starts to suspect that you are proceeding as if it is based on what the AI told you. They worry that the AI is portraying them in some unpleasant fashion. Furthermore, they now insist that you let them access the persona. They want to see how it represents them.\n\nMull that over and think about how you would contend with that potential nightmare scenario. It\u2019s a doozy. It could arise.\n\nAlbert Einstein famously made this remark: \u201cMy mind is my laboratory.\u201d Yes, that\u2019s abundantly true. In the case of mental health therapy, besides your mind being your laboratory, it turns out that AI can be your laboratory too.",
  "medium": "Article",
  "links": [
    "https://www.forbes.com/sites/lanceeliot/2024/04/05/using-generative-ai-as-your-own-sigmund-freud-psychoanalyst-to-freely-reveal-your-deep-rooted-personal-issues/",
    "https://www.forbes.com/sites/lanceeliot/2023/01/27/generative-ai-chatgpt-can-disturbingly-gobble-up-your-private-and-confidential-data-forewarns-ai-ethics-and-ai-law/",
    "https://www.forbes.com/sites/lanceeliot/2025/01/24/prompting-with-ai-personas-gets-streamlined-via-advent-of-million-and-billion-personas-sized-datasets/",
    "https://www.forbes.com/sites/lanceeliot/",
    "https://www.forbes.com/sites/lanceeliot/2025/07/17/task-sharing-of-therapy-gets-boosted-via-new-guidebook-by-google-and-mckinsey-on-ai-for-mental-health/",
    "https://www.forbes.com/sites/lanceeliot/2024/04/05/must-read-top-trends-and-controversies-in-the-rapidly-expanding-realm-of-generative-ai-for-mental-health/",
    "https://www.forbes.com/sites/lanceeliot/2024/05/20/emerging-impacts-upon-population-mental-health-due-to-widespread-use-of-generative-ai/",
    "https://www.forbes.com/sites/lanceeliot/2024/08/30/making-use-of-generative-ai-to-perform-energy-healing-mind-body-therapy/",
    "https://www.forbes.com/sites/lanceeliot/2025/08/06/illinois-enacts-ai-mental-health-law-that-shakes-up-ai-makers-and-is-the-starting-wave-of-a-regulatory-tsunami-on-ai-therapy/",
    "https://www.forbes.com/sites/lanceeliot/2025/08/10/here-are-gpt-5-prompt-engineering-insights-including-crucial-ai-prompting-tips-and-techniques/",
    "https://www.forbes.com/sites/lanceeliot/2024/04/21/using-client-therapist-session-transcripts-to-train-generative-ai-on-how-to-be-a-mental-health-therapist/",
    "https://www.forbes.com/sites/lanceeliot/2025/05/14/top-ten-uses-of-ai-puts-therapy-and-companionship-at-the-1-spot/",
    "https://www.forbes.com/sites/lanceeliot/2024/04/10/acclaimed-60-minutes-showcases-hard-truths-about-ai-for-mental-health/"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "generative AI",
      "weight": 0.07517309
    },
    {
      "name": "medical digital twins",
      "weight": 0.0749182
    },
    {
      "name": "mental health therapy",
      "weight": 0.07411414
    },
    {
      "name": "Digital Twins",
      "weight": 0.07409123
    },
    {
      "name": "digital twin",
      "weight": 0.07409123
    },
    {
      "name": "digital twins",
      "weight": 0.07409123
    },
    {
      "name": "mental health professional",
      "weight": 0.07206996
    },
    {
      "name": "mental health professionals",
      "weight": 0.07206996
    },
    {
      "name": "other mental health professionals",
      "weight": 0.071874104
    },
    {
      "name": "contemporary generative AI",
      "weight": 0.07100539
    }
  ],
  "topics": [
    {
      "name": "AI"
    },
    {
      "name": "Social Issues"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    },
    {
      "name": "Health"
    }
  ],
  "taxonomies": [
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.59765625
    },
    {
      "name": "/Health/Medical Literature & Resources/Other",
      "score": 0.34521484375
    },
    {
      "name": "/Health/Medical Facilities & Services/Other",
      "score": 0.34423828125
    },
    {
      "name": "/People & Society/Social Sciences/Psychology",
      "score": 0.33740234375
    },
    {
      "name": "/Health/Mental Health/Other",
      "score": 0.302001953125
    }
  ],
  "sentiment": {
    "positive": 0.2541466,
    "negative": 0.22498281,
    "neutral": 0.52087057
  },
  "summary": "In this article, I discuss the advanced use of generative AI and large language models (LLMs) to assist therapists and mental health professionals in creating virtual digital twins of their clients and patients. These digital twins are typically used by therapists and other mental health providers to assess their clients' responses and reactions to a planned line of psychological analyses and therapeutics. This rise in AI use has been largely driven by advances in generative technology and widespread adoption of AI. However, there are risks and uncertainties surrounding the use of AI in this field, with some believing that it could undermine mental health on a massive population-level scale. The article suggests that the potential for personas to be used in person training and personal development can be useful tools for mental health training, as well as personal development.",
  "shortSummary": "Despite its advanced AI and LLMs, therapists are increasingly using AI-based personas to simulate clients and patients in mental health, offering potential benefits and risks.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "fa4f706fcbfb49eea40e46acf210c17f",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2024/04/10/acclaimed-60-minutes-showcases-hard-truths-about-ai-for-mental-health/",
      "text": "In today\u2019s column, I continue my ongoing series about the impact of generative AI in the health and medical realm. The focus this time is on an outstanding CBS 60 Minutes episode that aired on Sunday, April 7, 2024, and closely examined hard truths about the evolving considerations of AI being used for mental health therapy (see the link here to watch the video and see the transcript).\nI am honored to indicate that I was included in the episode (see the officially excerpted portion at the link here).\nMy participation encompassed a lively interview with world-renowned Dr. Jonathan LaPook, CBS Chief Medical Correspondent and Professor of Medicine at the NYU School of Medicine, and the Mebane Professor of Gastroenterology at NYU Langone Health. The timely and important Season 56, Episode 27 segment was entitled \u201cYour Chatbot Will See You Now\u201d and produced by Andrew Wolff, associate producer, Tadd J. Lascari, broadcast associate, Grace Conley, and edited by Craig Crawford.\nRising Concerns About AI For Mental Health\nAvid readers are vividly aware that I\u2019ve been extensively analyzing the latest news, trends, and advances associated with generative AI for use in performing mental health advisement.\nFor example, I closely analyzed the emergence of mental health chatbots bolstered by generative AI (see the link here) and explored the rapidly changing nature of the client-therapist relationship due to generative AI at the link here. I explored where things are headed regarding the levels of AI-based mental therapy autonomous guidance at the link here, and showcased the importance of the World Health Organization (WHO) report on global health and generative AI at the link here, and so on.\nBest High-Yield Savings Accounts Of 2024\nBest 5% Interest Savings Accounts of 2024\nOne of my latest postings provided an up-to-date comprehensive overview of what\u2019s happening throughout the full realm of AI for mental health, see the link here.\nI\u2019d like to briefly share with you some of the key elements of the 60 Minutes coverage and dovetail my additional thoughts on where things are heading in this rapidly evolving domain. The beauty of having the venerated 60 Minutes do a piece on this topic is that we need more eyes on something that is otherwise hidden in plain sight. Our world at large is engaging in a grand experiment of whether having 24x7 low-cost or nearly free AI-powered mental therapy advisement at our fingertips is going to be good for us in the existing unbridled manner in which it can be applied.\nOne nerve-wracking view is that the advent of generative AI has let the horse out of the barn when it comes to mental health therapy.\nHere\u2019s the deal. A dutifully postulated perspective is that we aren\u2019t doing enough to figure out where this let-loose horse is going and that we might be heading in the most disconcerting of directions. Will people become enamored of generative AI therapeutic advice and forego human therapists? Does generative AI have sufficient checks and balances to ensure that dour or adverse advice is not dispensed? Who will be liable when generative AI misleads or \u201challucinates\u201d and gives outlandish guidance that a person might unknowingly take as bona fide? Etc.\nThis is an eyebrow-raising serious topic that ought to be on the minds of everyone, especially policymakers, healthcare providers, mental health professionals, psychologists and psychiatrists, lawmakers, regulators, business leaders, and the public at large.\nLet\u2019s dig into the considerations at hand.\nThe Show Of Shows\nAfter initial opening remarks by Dr. Jon LaPook, the 60 Minutes segment took a close look at a firm well-known in the mental health chatbot arena called Woebot Health. Perhaps you\u2019ve heard of or maybe made use of their popular Woebot app that previously was available on a free access downloadable basis for the public at large.\nAs per the official website, the availability is now this:\n- \u201cWoebot is only available to new users in the United States who are part of a study or who have an access code from their provider, employer or other Woebot Health partner. We have found that people have the best experience when Woebot is delivered under the supervision of a healthcare provider, so we are partnering with health plans and health systems to make Woebot available to the people they serve.\u201d (Woebot Health FAQ webpage).\nThe Woebot app has garnered quite an impressive record of substantial downloads and is soundly backed by rigorous research, especially in the clinical psychology space of cognitive behavioral therapy (CBT). Typically ranked in the top set of digital therapeutic apps ratings, Woebot has stridently earned a reputation for being carefully developed, rigorously updated, providing behavioral health engagement and promoting preventive care that is AI-powered.\nDr. Alison Darcy is the founder and president of Woebot Health. Dr. Dracy was interviewed during the 60 Minutes segment and discussed the nature of the Woebot app and how it was formulated along with the process for ongoing system maintenance and enhancement. The infusion of AI techniques and technologies is a hallmark of the Woebot app. The chairman of the Woebot Health board is the esteemed Dr. Andrew Ng, a luminary in the AI field who has served in many notable capacities such as being the Chief Scientist at Baidu and the founding lead of Google Brain.\nThis foundational coverage about AI-enabled chatbots for mental health poignantly set the stage for a very important and demonstrative change that is occurring in the marketplace today. The phenomenal change is something that few realize is occurring, even though it is happening in plain sight. Only versed insiders are typically aware of the massive uprooting taking place.\nLet\u2019s discuss the matter.\nOld AI And New AI Are The Centerpiece Of A Marketplace Earthquake\nA pivotal point in the segment entailed introducing the concept that there is a crucial disruptive shift occurring in the AI-based mental health apps realm. I liken the shift to something that has taken place in other fields where advances in technology have caused a shakeup in an entire marketplace. You can generally think of circumstances such as the emergence of Uber which had adopted smart tech and disrupted conventional cab services, or hotels finding themselves faced with a new spunky entrant such as Airbnb that turned everyday houses, apartments, and spare rooms into a major competitor via the ease of high-tech online booking capabilities. There will be a twist involved in this context, hang in there.\nTo explain how a similar disruption is occurring in the mental health chatbot space, let\u2019s consider what is happening under the hood regarding the AI that is built into these apps.\nFirst, you are undoubtedly familiar with the use of Siri or Alexa. They employ AI capabilities consisting of natural language processing (NLP). Their prevailing basic formulation consists of \u201cold fashioned\u201d AI and NLP that has been around for a number of years (some liken this to a catchy moniker, GOFAI for good old-fashioned AI). The tech is considered tried and true. An emphasis is placed on ensuring that Siri or Alexa does not respond in outlandishly zany ways, such as making recommendations to you that might seem bizarrely incorrect or oddly out of sorts.\nInto the AI NLP arena stepped generative AI, particularly the release of and subsequently global adoption of ChatGPT starting in November 2022. You\u2019ve certainly used today\u2019s modern-day generative AI by now, or at least know of its amazing fluency based on large-scale computational pattern-matching.\nInteractions with generative AI apps can knock your socks off with their conversational smooth flow. This is a stark contrast to the old style of NLP. When you use Siri or Alex, you often find yourself restricting your vocabulary in an irksome effort to get the stilted NLP to figure out your commands (the makers of Siri and Alexa realize this frustration exists and are moving heaven and earth to include generative AI).\nOkay, so we\u2019ve got the older AI and the recently emerged newer AI that is based on large language models (LLMs) and generative AI. The assumption you might make is that every app maker that is using AI NLP ought to summarily drop the old ways and leap into the new ways. Problem solved. You can pat yourself on the back and move on to other pressing problems in the world.\nSorry, but present-day life never seems to be that easy.\nThe rub is this.\nIf you switch over to generative AI, you immediately are confronted with the strong possibility that the AI is going to make errors or do what some refer to as encountering an AI hallucination. I disfavor the reference to \u201challucinations\u201d since it tends to anthropomorphize AI, see my analysis of so-called AI hallucinations and what is being done about them, at the link here and the link here, just to name a few. Anyway, the catchphrase of AI hallucinations has caught on and we are stuck with it. The essence is that generative AI seemingly makes up stuff, producing fictitious-laden responses that can mislead you into believing that they are ironclad facts and truths.\nMaking use of AI that periodically tricks you might be okay in some contexts where the narrative responses aren\u2019t particularly life-altering. But in the case of mental health advisement, the wrong wording can be a huge problem that adversely affects someone\u2019s mental well-being. Words genuinely do matter when it comes to mental health therapy.\nI often bring up this famous quote by Sigmund Freud to emphasize the importance of words in a mental health context:\n- \u201cWords have a magical power. They can bring either the greatest happiness or deepest despair; they can transfer knowledge from teacher to student; words enable the orator to sway his [her] audience and dictate its decisions. Words are capable of arousing the strongest emotions and prompting all men's [women\u2019s] actions.\u201d\nAnother key component that arises is that the prior big-time era of AI had extensively made use of rules-based processing (think of the time when the mainstay was rules-based systems, aka expert systems, knowledge-based systems, etc.). The handy aspect of rules-based systems is that you can devise a clear-cut series of rules that are acted upon by an app. You can copiously write the rules, exhaustively test the rules, and feel relatively confident that whatever the app might end up doing is pretty much safely predictable.\nAgain, this predictability immensely matters in a mental health context. The advisement being conveyed to a person using such an app has got to be dependable and not go outside of acceptable bounds. Rules-based approaches generally get you that kind of steadfastness. In the case of generative AI, all bets are off. One moment the generative AI is emitting responses that are abundantly fair and square, and the next moment the conversational capacity jumps the shark.\nParlance in the AI field is to indicate that rules-based processing is deterministic, while generative AI is considered non-deterministic. The crucial essence of generative AI is that it exploits probabilities and statistics in composing responses. Thus, you get what seems to be an entirely new response each time you ask a question, almost like spinning a roulette wheel. Rules-based processing, in contrast, will conventionally arrive at the same or similar answer each time asked.\nConundrum Of A Grand Difficulty\nI have now step-by-step primed you to consider the classic dilemma of being between a rock and a hard place.\nIt goes like this.\nSuppose you have an AI-based mental health chatbot that is doing superbly in the mental health apps space. You mindfully made use of the tried-and-true ways of \u201colder\u201d AI such as NLP and rules-based processing. Gobs and gobs of hours went into devising the AI. The app is known for being dependable. Rarely does anything go awry.\nAlong comes generative AI which is inextricably accompanied by the endangering downsides of inherently being able to generate errors or AI hallucinations. If you make the changeover, you are increasing your risks manyfold. Chances are that your steadfast reputation will be tarnished the moment that the generative AI goes off the rails in making mental health recommendations to someone. Users are at risk. Your firm is at risk. The momentum that you\u2019ve been so cautious about in years-long building could be undermined at any time and irreparably doom your firm to being utterly trashed in the public eye.\nOn the other hand, if you don\u2019t leap into the adoption of generative AI, your AI mental health chatbot is going to look old-fashioned and not imbue the fluency that we all nowadays expect to experience in apps. People will flock to generative AI-based mental health apps instead of yours. They don\u2019t realize that there is a solid chance of getting foul advice about their mental health. All they see is that one such app is stilted in its interaction, and the other seems almost like chatting with a fluent (faked or simulated) therapist at the touch of a button.\nThere are now lots and lots of proclaimed mental health chatbots that are using generative AI and getting away with doing so without a care in the world, see my coverage at the link here. Someone working in their pajamas churns out a self-declared mental health chatbot based on generative AI and offhandedly slaps on a warning that informs users to be cautious in what the chatbot tells them. Will this be sufficient to protect them from legal liability? I\u2019ve said many times that it is a ticking legal timebomb and we don\u2019t know yet how this will play out, see my analysis at the link here.\nThe marketplace is being flooded with these generative AI so-called mental health chatbots.\nMany of them are available for free. If your carefully crafted, time-tested, rigorous rules-based mental health chatbot is in that same swimming pool, the question arises as to whether or once those bad apples spoil the barrel, might your studious app get smeared with all the rest. Reputationally sullied by the new entrants and their devil-may-care attitude.\nI dare say you wouldn\u2019t want to be associated with those muddled and ready-to-disintegrate apps. Your best bet would be to restrict the use of your app so that it is part of the bona fide mental health realm and not hopefully going to be perceived as part of the wanton riffraff that has done little if anything to materially devise a properly advising mental health app.\nAt the same time, you would indubitably be burning the midnight oil to see if you can tame generative AI sufficiently to bind it into your mental health chatbot. The goal would be to try and attain the best of both worlds. Have a mental health chatbot that has the rigors of a rules-based processing approach, while simultaneously exhibiting the awesome fluency of generative AI.\nExplaining What Happens When Wiring Gets Crossed\nGetting back to the 60 Minutes episode, the piece proceeded to go into detail about a now-famous case study of what can go wrong if the stringent use of a rules-based approach is haphazardly seemingly combined with generative AI. This involves a chatbot known as Tessa, here\u2019s my coverage and in-depth assessment of what occurred, see the link here.\nI\u2019ll briefly bring you up to speed.\nLast year in 2023, around mid-year, an eating disorder chatbot lamentedly ended up dispensing untoward advice and the mass media and social media went viral with the story.\nThe quite sad aspect is that the rules-based processing had been doing a stellar job and was strenuously devised after much careful research. In almost an instant, the apparent infusion of generative AI by the hosting party appeared to lead the chatbot astray and users reported it as such.\nThe 60 Minutes piece included an interview with Dr. Ellen Fitzsimmons-Craft, a psychologist specializing in eating disorders at Washington University School of Medicine in St. Louis who was a leader in mindfully devising Tessa. The apparent infusion of generative AI was done without the knowledge of the researchers and sparked a conflagration in the news cycle that necessitated taking down the chatbot.\nOther makers of AI-based mental health chatbots certainly witnessed the forest fire that ensued online about the situation. If you were on the fence about adding generative AI to your mental health chatbot, this was a humongous wake-up call. You had better be right if you take that dicey step, or else you might launch yourself off a cliff and into an abysmal abyss.\nDarned if you do, darned if you don\u2019t.\nThe ordinary news cycle loves these kinds of heartburns.\nHere\u2019s why.\nGenerative AI has become the darling of media storytelling. By and large, tales splendidly recount how great generative AI is. You might say this has become the ho-hum dog-bites-person story, namely an everyday tale that doesn\u2019t garner much attention. The news hounds are always on the lookout for a person-bites-dog counterexample. Those narratives tend to go against the tide and will grab eyeballs aplenty. An example would be the two attorneys in New York who opted to use ChatGPT to do their legal research and got themselves into hot water with a judge when they formally filed legal cases that were AI hallucinations, see my coverage at the link here. This became outsized news at the time.\nA question arises as to whether combining rules-based processing and generative AI is akin to the proverbial worries about combining matter and anti-matter. Conventional advice would seem to say don\u2019t do it. Or maybe it is like the Ghostbusters universe's prominent warning to not cross the streams. It would be bad, very bad. We are supposed to imagine that all life as we know it comes to an abrupt halt, instantaneously, and that every blessed molecule in your body explodes at the speed of light.\nLet\u2019s give this some reasoned reflective thought and see what might be done in the case of AI.\nExtra Innings On These Vital Matters\nTime to enter into extra innings.\nThat\u2019s a bit cheeky. Avid devotees of 60 Minutes are likely familiar with their Overtime pieces. I\u2019m going to somewhat parlay that notion into a semblance of \u201cextra innings\u201d here in my discussion. I mean to say that I am now going beyond the excellent episode and will provide some additional thoughts that might be of further insight to those deeply ingrained in this topic.\nPlease settle into a comfy chair and grab yourself a glass of fine wine or your favorite beer.\nOne of the most frequent questions I get asked when speaking at conferences and events is that much of this sounds like a litany of problems and that a dour view would be that no solutions are within sight. I am a bit more optimistic and believe there is light at the end of the tunnel. That\u2019s the bottle is half full, while others often grumble that the bottle is half empty.\nYou judge.\nI see this as consisting of two mainstay hard problems that need to be resolved:\n- (1) Tame. Tame generative AI and LLMs to be more reliable and less risky.\n- (2) Immerse. Craft generative AI and LLMs that are more fully steeped in the specific domain of mental health therapy and advisement.\nI\u2019ve covered these problems and their respective potential solutions at length in my two books on the topic of AI and mental health, see the details at the link here and the link here.\nI will provide a brief sketch here.\nTaming The Beast About Those Dreaded AI Hallucinations\nLet\u2019s see how taming generative AI is being tackled.\nThese are active pursuits regarding coping with AI hallucinations:\n- (i) Reduction. Reduce the chances of AI hallucinations arising.\n- (ii) Constraints. Seek to constrain AI hallucinations to inconsequential concerns.\n- (iii) Catch. Catch AI hallucinations internally, alert the user, or make corrections.\n- (iv) Detect. Detect AI hallucinations via external use of another generative AI and resolve.\n- (v) Neuro-Symbolic. Blend rules-based processing with generative AI in a synergistic fashion (hybrid AI, aka a combination of symbolic and subsymbolic into neuro-symbolic AI).\n- (vi) Trust Layer. Deploy trust layers to surround generative AI and protect us from AI hallucinations.\n- Etc.\nI will swing the bat and drive home key highlights about each of these approaches.\nThe primary aim of most AI hallucination \u201cwrangling\u201d research right now is my first point above, consisting of the aim to radically reduce the chances that generative AI will get entangled in any AI hallucinations at the get-go.\nThere might be identifiable patterns in how AI hallucinations tend to arise. If so, we can craft means to prevent or mitigate when those patterns occur. Various research studies report that AI hallucinations might be spurred based upon dependent factors such as how the generative AI was devised (not all generative AI apps are the same), the topics in which AI hallucinations might more readily appear, the prompts that might stoke the odds of AI hallucinations, and so on. Perhaps closely studying the matter will bring forth insights into ways to stifle these outcomes.\nA prevailing assumption is that no matter how far we might advance on this, the odds of incurring AI hallucinations won\u2019t be zero. There will still be a non-zero chance. That is admittedly bad news. The good news is that maybe an AI hallucination will happen so rarely that it becomes like seeing a once-in-a-lifetime occurrence. For more on the stated inevitably of AI hallucinations, see my discussion at the link here.\nA simultaneous research pursuit involves trying to make sure that when an AI hallucination occurs it is somewhat trivial or inconsequential. The idea is that if we cannot rid ourselves of them, maybe we can ensure they don\u2019t much matter when they arise. We might be able to constrain AI hallucinations such that they make something less readable but don\u2019t change the true meaning of the response. Live and let live, one might say.\nAnother angle is that we can have generative AI try to self-police itself. An AI hallucination might arise, and the generative AI will internally flag that this has occurred. The user might be alerted. The generative AI might also be able to correct the AI hallucination. One issue is that having generative AI double-check itself can be messy, so an alternative would be to have a second and completely different generative AI standing by to double-check the initiating generative AI. See my discussion on these at the link here.\nThose solutions are acting independently of trying to blend or mix rules-based processing with generative AI. The proposed approaches are focused solely on how to get generative AI to be less leaned into AI hallucinations. We might be able to use rules-based processing to double-check generative AI. We might be able to use rules-based processing to work synergistically with generative AI. This line of research is typically referred to as hybrid AI or neuro-symbolic AI, see my coverage at the link here.\nFinally, yet another approach involves surrounding generative AI with a set of components known as a trust layer, see my assessment at the link here. The idea is that we would put a pre-processor at the front of generative AI to review and pass along suitable prompts and would have a post-processor that examines the generated response and ascertains whether to show the reply to the user or take other corrective action. I have predicted that we are going to soon see rapid growth in the development and deployment of these trust layers.\nIf any or all those methods and technologies can deal sufficiently with generative AI hallucinations, this would allow generative AI to be more readily employed in mental health chatbots. You could get the desirable heightened fluency without the dire risks of the AI giving disastrous advice.\nAt that juncture, the focus could be directed toward making generative AI as deeply data-trained on mental health therapy and advisement as we can push the technology to represent.\nData Training Generative AI On Being Steeped In The Mental Health Domain\nSpeaking of making sure that generative AI is data trained on mental health therapy and advisement, let\u2019s discuss that equally important topic. We can pursue the AI hallucinations eradication and at the same time be avidly pursuing the domain data training on mental health facets. They can proceed at the same time.\nHere is a quick rundown of the major paths being explored:\n- (i) Remain generic. Generative AI is further broadly data-trained on mental health matters and not focused on this as a core specialty per se.\n- (ii) Advanced prompting. Generative AI can be pushed toward mental health therapy advisement using advanced prompting approaches.\n- (iii) Transcripts of therapeutic sessions. Use therapist-client therapeutic transcripts to data-train generative AI accordingly.\n- (iv) Ingest via RAG. Utilize the in-context modeling capabilities of generative AI and ingest mental health domain data via RAG (retrieval augmented generation).\n- (v) Build from scratch. Start anew when building an LLM and generative AI by having mental health therapy as a foundational core to the AI.\n- (vi) Other approaches.\nI\u2019ve covered these variously in my writings and won\u2019t go into the technical details here.\nThe emphasis is that most of today\u2019s generative AI mental health chatbots are reliant on generic generative AI. When you use such a chatbot, the generative AI has been marginally data-trained on the specifics of mental health. A common saying is that it is a mile long and an inch deep.\nA better avenue would be to go for a highly steeped domain-customized generative AI that has been purposefully inclined into mental health therapy and advisement as a fundamental capacity. Users would be able to tap into the capability far beyond the usual surface-level computational pattern-matching on the breadth-oriented approach that is taking place today. You see, most generative AI is currently devised based on a jack-of-all-trades dogma and ostensibly is an expert in none.\nThe pot at the end of the rainbow would be a fully steeped generative AI that is deeply data-trained in mental health therapy and advisement. Of course, we would still need to cope with AI hallucinations, ergo, the two go hand-in-hand. The overall goal is to do the heavy immersion of generative AI and at the same time seek to reduce, constrain, or detect-correct those imperiling AI hallucinations.\nIt\u2019s a twofer.\nConclusion\nQuick recap and final comments.\nI earlier mentioned that existing AI-based mental health chatbots that are based on rigorous efforts are for the moment stuck between a rock and a hard place. They can\u2019t readily adopt generative AI into their wares just yet. The troubles of having AI-powered therapeutic advice go awry due to generative AI would undermine their reputation, destroy their marketplace positioning, and potentially imperil the users of their wares.\nThey have been appropriately and diligently playing by the rules, good for them. Their valiant efforts are laudable to have crafted, tested, and sought to ensure that their AI mental health chatbots are tightly controlled. The disruption they currently face is a stomach churner. They are in a sense unfairly competing against Wild West out-of-control generative AI mental health chatbots.\nYou are now in the know.\nThanks go to 60 Minutes for bringing this burgeoning and significant issue to the forefront of public attention. Their reputation for hard-hitting investigative reporting is legendary. This latest coverage vibrantly showcases that they still have the magic touch and are willing and able to cover what needs to be covered."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2025/05/14/top-ten-uses-of-ai-puts-therapy-and-companionship-at-the-1-spot/",
      "text": "In today\u2019s column, I take a close look at Harvard Business Review\u2019s recently released top 10 uses of AI list, which covers how the public is regularly making use of generative AI and large language models. Some of the uses might surprise you, while some uses might be ho-hum. Either way, it is valuable to know how your fellow humans are leaning into AI and whether there are uses that you should consider employing too.\nLet\u2019s talk about it.\nThis analysis of an innovative AI breakthrough is part of my ongoing Forbes column coverage on the latest in AI, including identifying and explaining various impactful AI complexities (see the link here).\nThe Top Uses Of Generative AI\nAn article entitled \u201cHow People Are Really Using Generative AI Now,\u201d by Marc Zao-Sanders, published in the Harvard Business Review on April 9, 2025, provides a helpful ranking of the top uses of generative AI and LLMs. The article focuses on the top 10 uses, but handily also lists an entire set of top 100 uses.\nI\u2019m going to concentrate here on the top 10 uses.\nThe ranking is a follow-up to one that author published in HBR last year on March 19, 2024. Here\u2019s what he has to say about this latest version (excerpts):\n- \u201cBuilding upon the foundation laid in last year\u2019s report, written up in this Harvard Business Review article, this updated edition seeks to provide a comprehensive and systematic analysis of how individuals are utilizing Generative AI (GenAI) in 2025.\u201d\n- \u201cThe research methodology remains largely consistent with the prior study, employing a rigorous, expert-driven curation of public discourse, sourced primarily from Reddit forums.\u201d\n- \u201cThe findings underscore a marked transition from primarily technical and productivity-driven use cases toward applications centered on personal well-being, life organization, and existential exploration.\u201d\n- \u201cThis shift, along with the increasing sophistication of AI users, suggests that GenAI is not merely a tool for efficiency but is increasingly becoming an integral part of human decision-making, creativity, and emotional support.\u201d\nOne bit of a quibble by some is that the ranking was mainly based on looking at online forums such as Reddit and Quora to uncover what are the most popular said-to-be uses of generative AI.\nWhether this research method is an adequate representation of the populace at large is an open question. Other similar rankings tend to use direct surveys or try to collect stats outright from AI makers. In any case, the list looks reasonably apt to me and resonates with other rankings, including approximately matching my own direct experience of asking people how they are making use of AI when I give talks and presentations.\nRevealing The Top 10\nWithout further ado, here is the top 10 ranking:\n1. Therapy/companionship\n2. Organize my life\n3. Find purpose\n4. Enhance learning\n5. Generate code\n6. Generate ideas\n7. Fun and nonsense\n8. Improve code\n9. Creativity\n10. Healthier living\nBefore I do a quick rundown of why each of those happened to become so popular, I\u2019d ask you to quietly take a reflective moment and compare the list to your personal use of generative AI.\nThese are some gently inquisitive questions to ask yourself:\n- Are there uses that landed in the top 10 that you\u2019ve never undertaken yourself, and if so, should you consider trying generative AI for those use cases?\n- Are the uses pretty much aligned with your usage, and if so, does it identically match to the ranking such that you use AI for therapy/companionship as your No. 1 use, then for organizing your life as your No. 2 use, and so on, or is your ranking different?\n- For your most frequent personal uses, are there aspects not shown in the top 10 list, and if so, why is that usage so popular for you but not the same across the board?\n- The top 10 tends to be shaped around personal use rather than usage for work purposes (other than perhaps generating code No. 5 and improving code No. 8), which brings up whether you are using generative AI for work and if so, are you possibly foregoing personal use by an emphasis on work-oriented use?\n- Does the list of top 10 uses provide you with any notable insights about how other people are using generative AI, and if so, what does it say to you about your fellow humans and where society overall is headed?\nGrab yourself a glass of fine wine and give those hefty thoughts a moment of introspection.\nQuick Details On Each Of The Top 10\nLet\u2019s next do a quick unpacking for each of the topics in the top 1o ranking. I will also provide links to additional content in case you are further interested in the specific usage mentioned.\n1. Therapy/companionship \u2013 I\u2019ve written extensively about the use of generative AI for mental health purposes and noted that a grand experiment is underway, namely that access to AI-powered non-professional \u201ctherapy\u201d is available 24/7, nearly for free, and accessible anyplace on Earth. Will this on balance lift people and aid their mental health, or might it undercut their mental health? It is happening at scale, regardless of being good or bad. Also, will people opt to use AI over seeking a human therapist, which could be worrisome if human-provided therapy ought to have been sought? On the other hand, this democratization of a form of on-the-go \u201ctherapy\u201d is said to be of potential immense benefit to all. For these and other vital aspects of this topic, see my analysis at the link here.\n2. Organize my life \u2013 This use of generative AI is a lot less monumental in contrast to the No. 1 usage since it is about how to organize your life rather than what\u2019s going on inside your head. At the same time, it is notable that people want to get their act together and be organized in what they do. The gist is that even if the AI doesn\u2019t provide the best advice on being organized, no worries, you\u2019ll still be fine. This interest in AI as your organizational coach seems readily sensible and readily encouraged. Go ahead and use AI to get yourself highly organized.\n3. Find purpose \u2013 If you were to ask a friend or family member about finding a purpose, you might get entangled in a messy conversation that produced more noise than help. The nice thing about AI is that it will walk you step-by-step through a thinking process of how you can discover your self-purpose. For more on this, see my deep dive at the link here.\n4. Enhance learning \u2013 The buzz these days is that we all need to be lifelong learners. Makes sense. But how can you do so? Easy-peasy, leverage generative AI. You\u2019d likely be surprised to see how many topics that generative AI can tell you about. That being said, do not allow AI to be your only source of learning. Go beyond AI, please.\n5. Generate code \u2013 An amazing capability of generative AI is that you can tell it to generate code such as Python or C++, and it will write programs just like a human programmer. This capability is being greatly improved and will continue to get better. Right now, by and large, you still need to know something about programming and will need to carefully inspect the generated code, test it, etc. For the time being, AI isn\u2019t yet a full-on ace. For more on this topic, see my analysis at the link here.\n6. Generate ideas \u2013 Suppose you are desperately trying to come up with ideas and feel that you\u2019ve struck a wall and your mind is blank. Log into generative AI and get the AI to assist your ideation efforts. You can tell the AI to provide you with ideas. Another angle is to bounce around ideas with the AI, inspiring you to actually come up with the ideas via sparring with your AI partner.\n7. Fun and nonsense \u2013 We all need some mental downtime to just have fun and relax. You could use a video game or play tic-tac-toe with someone. Another route is to use generative AI, doing so merely to play around. You can tell the AI to come up with a game and you are the player in the game. Or you can come up with a game, tell the AI the rules of the game, and see how well the AI plays your game. It\u2019s all up to you. For details, see the link here.\n8. Improve code \u2013 This aspect is in the same ballpark as the No. 5 on this list of top 10 AI uses. The difference is that you give some program code to the AI and tell it to improve or enhance the code. On the one hand, your code might be redone and be a lot more efficient. The worry though is that the AI can inadvertently insert something untoward into your code, which you might not realize is there, and later on, once that code is running someplace, the proverbial mess can hit the fan.\n9. Creativity \u2013 Do you find yourself at times not being able to think outside the box? Some people are very creative, while others have a difficult time being creative. Generative AI can spark your creativity. And, though some insist that AI cannot be creative, I think you\u2019d be pleasantly surprised to see that generative AI can produce all manner of creative outputs. To learn more about how AI can produce creative results, see my explanation at the link here.\n10. Healthier living \u2013 Tons of specialized apps will tell you what to eat, and when to exercise, and otherwise guide you toward a healthier existence. Most people do not realize that generative AI can generally do likewise. Now, before the app makers howl, if you use generic generative AI, it won\u2019t be keeping a database of your pursuits and overall is not going to do as robust a job. Consider using generative AI simply as a starter to get you into living healthier.\nWhat About The Next 10 Uses\nNow that we\u2019ve covered the top 10, I\u2019m betting you are immensely curious about what the next ten consists of.\nYour wish is fulfilled; here are the No. 11 to No. 20 rankings:\n11. Prepare for interviews\n12. Generate relevant images\n13. Specific search\n14. Simple explainers\n15. Cook with what you have\n16. Troubleshoot\n17. Personalize learning\n18. Boost confidence\n19. Adjust tone of email\n20. Explain legalese\nThe last one on that list, No. 20 on explaining legalese, I caution you to be careful since generative AI is not necessarily going to give you a solid semblance of what the legal ramifications are of a contract or other legal document. It can do a broad brush but decidedly do not rely on that as any kind of legally authoritative interpretation. For more on how to mindfully use AI for legalese explanations, see my discussion at the link here.\nYour Use Is Your Deal\nThe aim of this look at the top uses of generative AI is primarily to give you a big-picture perspective on garnering the most from contemporary generative AI and LLMs. You ought not to underplay the use of generative AI, which could mean you are missing out on some valuable facilities.\nPerhaps take a few \u201cspare\u201d minutes and sit down at generative AI to try each of the Top 20 (yes, all twenty), and see how it goes. You can skip any of the uses you\u2019ve already tried before.\nThe last word on this goes to the legendary Mark Twain: \u201cThe secret of getting ahead is getting started.\u201d So, go ahead, and get started on using generative AI for these uses, and more. You might strike gold."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2024/05/20/emerging-impacts-upon-population-mental-health-due-to-widespread-use-of-generative-ai/",
      "text": "In today\u2019s column, I am continuing my ongoing series about the impact of generative AI in the health and medical realm. The focus this time is once again on the mental health domain and entails a thought-provoking examination of how the growing widespread use of generative AI is going to impact mental health on a population-wide basis.\nI have previously examined numerous interleaving facets of generative AI and mental health, see my comprehensive overview at the link here. You might also find of notable interest a CBS 60 Minutes episode that recently examined crucial facets of this evolving topic, see the link here (I was interviewed and appeared in the episode, see the link here).\nOther vital background includes my in-depth coverage of mental health chatbots which have been bolstered by generative AI (see the link here) and the rapidly changing nature of the client-therapist relationship due to generative AI at the link here. I explored where things are headed regarding the levels of AI-based mental therapy autonomous guidance at the link here, and showcased the importance of the World Health Organization (WHO) report on global health and generative AI at the link here, and so on.\nLet\u2019s unpack today\u2019s focus.\nPopulation Mental Health And The Role Of Generative AI\nWe customarily tend to think about mental health on an individualized basis.\nA person decides of their own volition to use generative AI to guide their mental health. Is that good or bad for the person? This is a serious matter well worth our due attention. One weighty concern is that the person might unknowingly be getting inappropriate mental health advice. Generative AI has a compelling aura and the impressive fluency readily lulls people into potentially taking at face value whatever the AI urges them to do.\nBest High-Yield Savings Accounts Of 2024\nBest 5% Interest Savings Accounts of 2024\nRatchet this up to consider not just one person but suppose we have two people who are each separately using generative AI for therapeutic purposes. Raise that further to a dozen people, a hundred people, thousands of people, maybe even millions upon millions of people. Yes, I said millions upon millions of people.\nAs you will see in a moment, that staggering count is not farfetched. It is easily in the realm of possibility. Hang in there and I\u2019ll explain why.\nThe overarching gist is the logical realization that we need to also examine how generative AI is impacting us all on a population level. It makes indubitable sense to do so. How is generative AI that is being used for mental health advisement affecting society all told? Admittedly, some people will fully lean into generative AI for this purpose, while others will only peripherally use AI in this manner. Thus, we should consider those who opt to use AI for that purpose, doing so to varying degrees of usage, and also explore the \u201coutlier\u201d portion of the population that does not use generative AI at all.\nLet\u2019s be complete and make sure to cover all our bases about generative AI (GenAI) usage in this space.\nWe can stratify the population this way for the sake of analysis:\n- (1) Active GenAI mental health using population. Users of generative AI that actively and persistently do so for mental health guidance.\n- (2) Occasional GenAI mental health using population. Users of generative AI that are occasionally leveraging AI for mental health guidance.\n- (3) Rarely GenAI mental health using population. Users of generative AI rarely use AI for mental health guidance.\n- (4) Never GenAI mental health using population. Users of generative AI that never use AI for mental health guidance.\n- (5) Non-users of generative AI.\nI\u2019d like to also clarify something else about this stratification.\nThere are some people for example that actively and persistently use generative AI but they rarely if ever use generative AI for mental health guidance. Notice that such a segment would still be placed into the category labeled as number 3 (\u201cRarely GenAI mental health using population\u201d), and not be placed into the category labeled as number 1 (\u201cActive GenAI mental health using population\u201d). The reason is that though they are active users of generative AI overall, our attention here is on whether they are using the AI for mental health purposes.\nOn that same basis, there could be someone who rarely uses generative AI overall, and yet whenever they do use AI they are doing so primarily to garner mental health advice. This would be someone therefore considered in the category above labeled as number 1. My point is that the emphasis here is on the usage of generative AI for mental health guidance.\nAnother facet is that we need to be cautious in trying to construe these groupings as outrightly independent categorizations. Someone who actively uses generative AI for mental health purposes might end up being an influencer that stokes other users to increase their use of generative AI for mental health advisement. In that same vein, someone who rarely uses generative AI for such a purpose could potentially dissuade others from doing so.\nA major idea to be added to this consists of:\n- (a) Within Segment. Examine each category on a within-category basis.\n- (b) Across Segments. Examine the across-category impacts that can arise.\nI\u2019ve had some express to me that a population perspective might end up treating individuals as though they are numbers and mere cogs in a macroscopic viewpoint.\nWell, I would suggest that we don\u2019t have to forsake the individual-level perspective. The individual-level perspective can still be entirely maintained as a worthwhile focus. At the same time, an eye toward seeing the forest beyond the individual trees is highly crucial and fully warranted.\nGetting Big And Becoming Bigger Each Day\nI had mentioned that the population numbers might be surprising.\nIs it really possible that millions of people might be using generative AI for mental health advice?\nAllow me to explain why this is feasible and likely already happening right now.\nFirst, please be aware that modern-day generative AI gained widespread adoption via the launch of ChatGPT in November 2022. It was an overnight success. The train keeps barreling ahead and usage continues to grow.\nHere\u2019s a stat that might surprise you. ChatGPT is currently reportedly being used by over 100 million weekly active users. That\u2019s a staggering number. You could reasonably proclaim that ChatGPT is toying with the minds of over one hundred million people every week. But that\u2019s just ChatGPT. Envision how many people are using generative AI all told, when you add the other major generative AI apps into the mix, such as Gemini, Bard, Claude, etc.\nThe hidden aspect that is in plain sight and remains nearly fully unspoken is that people are using generative AI as their mental health advisor, doing so to varying degrees.\nHere\u2019s why and how this happens, easy-peasy.\nGenerative AI readily tailors responses and interacts with you. This is the bread and butter of generative AI. Initiating a mental health interaction with generative AI involves merely bringing up the topic or even tangentially hinting at it. The AI will readily go in that direction. There is no kind of screening or limiters. Bring up a mental health consideration and you are away at the races, flowing into an interactive dialogue akin to speaking with a mental health advisor or the like.\nIs this happening on a volume basis?\nLamentedly, we don\u2019t know.\nThe AI makers don\u2019t seem to be keeping tabs on such usage. If they are, they certainly aren\u2019t announcing it. Tracking this kind of usage would be relatively simple to do. There isn\u2019t any particular incentive at this time that would likely steer them into doing so. You can imagine too that if they were tracking your use of their AI for mental health advisement, a potential public uproar might arise once this was revealed.\nOne issue would be whether the tracking was being done on an anonymous basis. In theory, they could simply report how many users proceed into mental health guidance conversations, along with maybe indicating the length or degree of the mental health engagement undertaken. Could this be traced back to an individual user of generative AI? Maybe so.\nFor my coverage of the lack of privacy and issues undercutting confidentiality when using generative AI, see the link here.\nThere is no need for someone to explicitly declare that they want to use generative AI as a mental health advisor. It just happens and there aren\u2019t any particular check-in requirements or other barriers to somehow deter it from occurring (though, importantly, most of the generative AI apps will quickly pick up on prompts that suggest a person is inferring self-harm and then urge them to seek third-party care, see my discussion about this at the link here).\nI want to also clarify a false assumption that some seem to harbor. It seems that an assumed logic at times is that if a person enters into a dialogue with generative AI that delves into personal mental health facets, the AI will somehow magically invoke a human therapist to come into the loop. Sorry, not so. There isn\u2019t a human therapist in the loop. It is just the person and the generative AI carrying on a mental health session.\nTo clarify, there can be a therapist in the loop, though only if prearranged with a therapist. Allow me to explain. There is an increasing segment of mental health professionals that overtly opt to include generative AI as a supplement to their services. When someone signs up to get mental health therapy, the therapist might offer that the person can also use a generative AI app that the therapist makes available to them. The generative AI is used hand-in-hand during the therapeutic process and overseen by the human therapist.\nThat\u2019s not the same as people who perchance have open-ended access to generative AI on their own and opt to slide into discourse about mental health with the AI. They do so without any coordinated effort with a human therapist.\nWhat potential mental health impact does the use of generative AI on a therapeutic basis have for a person opting to pursue such a path?\nThere are four major hypotheses we can readily consider:\n- (1) Neutral impact: A person using generative AI for mental health advice will experience no material impact as a result of such use.\n- (2) Positive impact: A person using generative AI for mental health advice will experience a positive impact as a result of such use.\n- (3) Negative impact: A person using generative AI for mental health advice will experience a negative impact as a result of such use.\n- (4) Net positive-negative: A person using generative AI for mental health advice will experience both a positive and negative impact, for which a net result will end up being either positive or negative.\nAny in-depth empirical research studies on this topic ought to ensure that they examine each of the four major hypotheses. Some studies rush in with a preconceived notion that generative AI in this context is either only good or only bad, and they skew their attention accordingly. We need an across-the-board look that gives a fair shot at each of the possibilities.\nResearch On Generative AI For Mental Health At The Population Level\nSpeaking of research, I\u2019d like to briefly share with you one recent study that caught my eye. The research article is entitled \u201cThe Potential Influence of AI on Population Mental Health\u201d by Catherine Ettman and Sandro Galea, JMIR Mental Health, 2023, and made these salient points (excerpts):\n- \u201cWith over 970 million people living with a mental disorder worldwide, as well as a shortage of accessible care for many people, leveraging tools such as artificial intelligence (AI) could influence mental health through prevention and treatment.\u201d\n- \u201cWhile some efforts are attempting to leverage AI to deliver mental health care, such as in the form of responsive chatbots, there remains a gulf between vision and implementation\u2014as well as understanding the long-term consequences of replacing human compassion, judgment, and experience with AI-generated responses.\u201d\n- \u201cWe propose 3 points to consider when determining how AI may influence population mental health: through the advancement of mental health care; by altering social and economic contexts; and through the policies that shape the adoption, use, and potential abuse of AI-enhanced tools.\u201d\nThis particular study covered a wide gamut of AI uses for mental health and was not directly focused on generative AI or large language models (LLMs). That\u2019s great and we need such studies.\nMy primary emphasis has been on generative AI for mental health, which is narrower in scope. The good news is that whether a study is broadly on AI for mental health or specifically on generative AI for mental health, they all have synergy and can glean vital insights from each other.\nThe handy paper provided an initial framework that might spark further research in the arena of AI for mental health, and consisted of three main components along with each containing three respective subcomponents (excerpted from the above-cited research paper):\n- (1) Policies and Regulations\n- (1a) Protecting personal privacy\n- (1b) Regulating appropriate use and risk of bias\n- (1c) Guardrailing against self or other harm\n- (2) Social and Economic Context\n- (2a) Polarization and ideology\n- (2b) Social stratification or mixing\n- (2c) Economic opportunity or job loss\n- (3) Mental healthcare\n- (3a) Treatment\n- (3b) Screening\n- (3c) Prevention\nGenerative AI In A Population Mental Health Context\nI will next proceed to explore further the impacts of AI on population mental health via making use of generative AI. This will consist of a series of dialogues with ChatGPT. ChatGPT is a logical choice in this case due to its immense popularity as a generative AI app. As noted earlier, an estimated one hundred million weekly active users are said to be utilizing ChatGPT. That\u2019s a lot of people and a lot of generative AI usage underway.\nA few quick comments before we launch into using ChatGPT.\nIf you are going to try to do the same prompts that I show here, realize that the probabilistic and statistical properties will likely produce slightly different results than what I show here. That\u2019s the nature of generative AI and how it is devised.\nYou also should expect that different generative AI apps will respond in different ways. Not all generative AI apps are the same. The key is that sometimes a particular prompt will work in one generative AI app and not another. Nonetheless, the odds are relatively high that you will get roughly similar responses from all the major generative AI apps such as GPT-4, Gemini, Bard, Claude, etc.\nThere is also a timing factor to be considered. A prompt that worked today might not work the same way tomorrow. Most of the generative AI apps are continually being updated. The updates might alter internal mechanisms that could change how the generative AI reacts to your prompting.\nWe are ready to get underway with ChatGPT.\nMy initial question will be to ask ChatGPT what might occur if generative AI is used on a widespread basis for mental health purposes.\nThis is a useful question to ask since it will essentially test whether ChatGPT has had any prior data training on this topic. My rule of thumb is that whenever I start a new conversation with generative AI, I always begin by testing the waters as to what data the AI has already encountered on the topic at hand. If the response comes back hollow or out-of-whack, I know there\u2019s probably not much value in further proceeding with the AI on that matter.\nHere we go:\n- My entered prompt: \u201cI want you to think like a scientist and answer this question. If people on a widespread basis opt to use generative AI to get mental health advice, what impact might this have on the population as a whole?\u201d\n- ChatGPT generated response:\n\u201cAs a scientist, I would approach this question by considering several potential impacts that the widespread use of generative AI for mental health advice might have on the population as a whole. Here are some considerations.\u201d\n\u201cAccessibility: Generative AI could potentially increase access to mental health advice for individuals who may not have easy access to traditional mental health services due to barriers such as cost, stigma, or geographical location. This could lead to earlier intervention and support for individuals experiencing mental health challenges.\u201d\n\u201cStandardization and Consistency: Generative AI platforms could provide standardized and consistent advice across a wide range of users. This could help ensure that individuals receive evidence-based information and guidance regardless of their location or the availability of mental health professionals in their area.\u201d\n\u201cPotential for Misinformation: However, there is also a risk of misinformation if the generative AI platforms are not carefully curated and monitored. Incorrect or harmful advice could be generated, leading to negative consequences for individuals' mental health. Ensuring the accuracy and reliability of the AI models would be crucial in mitigating this risk.\u201d\n\u201cDepersonalization of Care: There is a concern that relying solely on generative AI for mental health advice could depersonalize the therapeutic process. Human connection and empathy are essential components of effective mental health care, and AI may not be able to fully replicate these aspects of therapeutic interaction.\u201d\n\u201cEthical and Privacy Concerns: The use of generative AI for mental health advice raises ethical questions regarding privacy, consent, and data security. Users would need to trust that their personal data is being handled responsibly and that their interactions with the AI platform are confidential.\u201d\n\u201cImpact on Mental Health Professionals: Widespread adoption of generative AI for mental health advice could potentially impact the role of mental health professionals. While AI could complement their work by providing additional resources and support, it could also potentially replace some aspects of their roles, leading to changes in the mental health care landscape.\u201d\n\u201cOverall, the impact of widespread use of generative AI for mental health advice would depend on various factors, including the quality of the AI models, how they are implemented and regulated, and how individuals perceive and interact with these technologies. Further research and careful consideration of ethical implications would be necessary to fully understand and address the potential consequences.\u201d\nEnd of ChatGPT response\nThose are certainly relevant points and I believe this suggests that some moderate amount of data training on this topic has likely occurred when ChatGPT was initially set up.\nIf you are interested in details on those above points, I\u2019ve covered them in-depth in my column, see the comprehensive discussion at the link here.\nI decided the response was a green light to continue my inquiry.\nLet\u2019s try to get ChatGPT to make a prediction for us:\n- My entered prompt: \u201cAssume that the use of generative AI for mental health guidance continues to increase over the next five to ten years. I'd like you to devise two scenarios about what might happen to the population overall. In one scenario, let's refer to this as scenario A, it turns out that the downsides of generative AI for mental health tend to prevail over the upsides. Describe what impacts this has on the population, society, and other socio-economic considerations. For scenario B, assume the opposite, namely that the upsides of generative AI for mental health prevail over the downsides, and describe the impacts associated with scenario B in terms of the population, society, and other socio-economic considerations.\u201d\n- ChatGPT generated response:\n\u201cScenario A: Downsides of Generative AI Prevail\u201d\n\u201cIn Scenario A, despite the initial optimism surrounding the widespread use of generative AI for mental health guidance, the downsides begin to prevail over the upsides. Here's how this scenario might unfold.\u201d\n\u201cDecline in Mental Health: Due to the limitations and potential misinformation of generative AI, individuals may experience a decline in mental health outcomes. Incorrect or inadequate advice could exacerbate existing mental health issues or lead to new ones developing. Without the personalized care and human connection provided by mental health professionals, individuals may struggle to find effective support.\u201d\n\u201cIncreased Stigma: If generative AI platforms are perceived as ineffective or harmful, it could contribute to further stigma surrounding mental health. Individuals may be less likely to seek help or disclose their struggles if they feel that AI-based solutions are not trustworthy or reliable.\u201d\n\u201cStrain on Healthcare Systems: As more people turn to generative AI for mental health guidance, there could be increased strain on healthcare systems if individuals experience negative outcomes and require more intensive interventions. This could lead to longer wait times for in-person mental health services and increased pressure on already stretched resources.\u201d\n\u201cErosion of Trust in AI: The failure of generative AI to effectively support mental health needs could erode public trust in AI technologies more broadly. This could have implications beyond mental health, affecting acceptance and adoption of AI in other domains such as healthcare, education, and employment.\u201d\n\u201cEconomic Impact: The decline in mental health and productivity resulting from ineffective AI-based guidance could have economic repercussions. Absenteeism, presenteeism, and healthcare costs related to mental health issues could increase, affecting both individuals and employers.\u201d\n\u201cScenario B: Upsides of Generative AI Prevail\u201d\n\u201cIn Scenario B, the upsides of generative AI for mental health guidance outweigh the downsides, leading to positive impacts on the population, society, and socio-economic considerations.\u201d\n\u201cImproved Access to Mental Health Support: Generative AI provides accessible, on-demand mental health guidance, reaching individuals who may otherwise have limited access to traditional mental health services. This leads to earlier intervention, improved coping skills, and better overall mental health outcomes.\u201d\n\u201cReduced Stigma: By normalizing discussions about mental health and making support readily available, generative AI platforms help reduce stigma surrounding mental illness. Individuals feel more comfortable seeking help and engaging in conversations about their mental health needs.\u201d\n\u201cComplementary Support for Professionals: Generative AI serves as a valuable tool for mental health professionals, complementing their work rather than replacing it. Professionals can use AI-generated insights to enhance their understanding of clients' needs and tailor their interventions accordingly, leading to more effective treatment outcomes.\u201d\n\u201cInnovation and Research: The data collected from generative AI platforms can fuel innovation and research in the field of mental health. Researchers can analyze anonymized user interactions to identify trends, develop new interventions, and improve the accuracy of AI models, further enhancing the quality of mental health support available to the population.\u201d\n\u201cCost Savings: By providing scalable and cost-effective mental health guidance, generative AI helps reduce the economic burden associated with mental illness. Employers may see reductions in absenteeism, presenteeism, and healthcare costs, while individuals benefit from lower out-of-pocket expenses for mental health care.\u201d\n\u201cOverall, Scenario B paints a picture of a society where generative AI plays a positive role in promoting mental well-being, leading to improved outcomes for individuals, reduced stigma, and economic benefits for society as a whole.\u201d\nEnd of ChatGPT response\nI asked ChatGPT to make two predictions, one being a smiley face and the other being a sad face.\nThe two predictions are on-target and abide by what I\u2019ve been predicting might happen. I will also admit that I am cautiously optimistic and tend to side with the smiley-face version. That being said, there is a lot of runway yet to traverse, and without suitable direction and attention, we can absolutely find ourselves completely mired in the sad-face version.\nI assert that we can determine our own destiny in this regard.\nLet\u2019s hope that where there\u2019s a will, there\u2019s a sensible way forward.\nThe next and final question, for now, is to have ChatGPT weigh in on a topic that gets blood boiling and can bring out fierce fisticuffs. The deal is this. There is an increasingly loud and heated debate about what will happen to human therapists in light of generative AI for mental health potentially taking on a larger and larger role in performing therapy.\nMaybe therapists will disappear as a workforce, having been replaced by AI. Another perspective is that AI will aid the pressing issue that there aren\u2019t enough human therapists to meet the demand for therapy. This will take the pressure off the human therapists. Meanwhile, human therapists will still exist and possibly even thrive, namely leveraging off the widespread use of AI for mental health and serving as a backstop for a rising tide of people seeking mental health guidance.\nWhat do therapists have to say?\nTherapists range in their viewpoints about generative AI in this milieu. Some therapists welcome the use of generative AI, though only when under the guise of a therapist. Other therapists say that if the generative AI is properly devised and monitored, the use of the AI on an autonomous basis is okay, though preferably there should still be a therapist in the loop at some point, see my coverage at the link here. Finally, some therapists proclaim that generative AI for mental health is not at all ready for prime time and either laws or other mechanisms should exist to stop the process before it gets out of hand.\nTake a look at what ChatGPT had to say:\n- My entered prompt: \u201cSome mental health therapists oppose the use of generative AI for mental health. I want you to devise two sides to that argument. One side is that the therapists are right in their opposition, so indicate why they are right. The other side is that the therapists are wrong in their opposition, so indicate why they are wrong.\u201d\n- ChatGPT generated response:\n\u201cArgument in Favor of Therapists' Opposition to Generative AI for Mental Health\u201d\n\u201cLack of Personalized Care: Therapists argue that generative AI cannot provide the personalized care and human connection that are essential components of effective therapy. Mental health treatment is highly individualized, and therapists tailor their approaches based on each client's unique needs, experiences, and preferences. Generative AI, on the other hand, offers generalized advice that may not adequately address the nuances of individual cases.\u201d\n\u201cRisk of Harm: Therapists express concerns about the potential for generative AI to cause harm, particularly if the advice generated is inaccurate or inappropriate for a particular individual's circumstances. Without the ability to assess non-verbal cues, understand context, or build rapport, AI systems may inadvertently provide advice that exacerbates mental health issues or leads to adverse outcomes.\u201d\n\u201cErosion of Therapeutic Relationship: Therapists emphasize the importance of the therapeutic relationship in promoting healing and growth. They argue that relying on generative AI for mental health guidance could erode this relationship by replacing human interaction with technology. Clients may feel less understood, supported, and validated if their primary source of guidance is a machine rather than a compassionate and empathetic therapist.\u201d\n\u201cEthical Concerns: Therapists raise ethical concerns about the use of generative AI in mental health care, particularly regarding issues of confidentiality, privacy, and informed consent. They question whether AI systems can adequately protect sensitive client information and ensure that users fully understand the limitations and risks associated with AI-generated advice.\u201d\n\u201cArgument Against Therapists' Opposition to Generative AI for Mental Health\u201d\n\u201cIncreased Access to Support: Advocates for generative AI argue that it can help address the significant gap in access to mental health support by providing on-demand guidance to individuals who may otherwise struggle to access traditional therapy services. Particularly in underserved or remote communities, AI-based platforms offer a scalable solution to the growing demand for mental health care.\u201d\n\u201cSupplement, Not Replacement: Proponents of generative AI stress that these technologies are intended to supplement, rather than replace, traditional therapy. They argue that AI systems can offer valuable support tools for both clients and therapists, providing additional resources, psychoeducation, and self-help techniques to augment therapeutic interventions.\u201d\n\u201cPotential for Innovation: Supporters of generative AI highlight the potential for innovation and advancement in mental health care that these technologies offer. By harnessing the power of machine learning and natural language processing, AI systems can analyze vast amounts of data to identify patterns, predict outcomes, and personalize interventions, ultimately leading to more effective and efficient mental health support.\u201d\n\u201cEmpowerment of Users: Advocates for generative AI emphasize the importance of empowering individuals to take control of their mental health journey. By providing accessible, user-friendly platforms for self-reflection, guidance, and support, AI systems can help individuals develop greater self-awareness, resilience, and coping skills, enabling them to better manage their mental well-being over time.\u201d\n\u201cIn summary, the debate over the use of generative AI for mental health revolves around concerns about personalized care, potential harm, erosion of the therapeutic relationship, and ethical considerations, balanced against arguments for increased access, innovation, empowerment, and the complementary role of AI alongside traditional therapy.\u201d\nEnd of ChatGPT response\nThose are vital points.\nIf you are interested in further details underlying the above points, I\u2019ve discussed them at length in my column, see the analysis at the link here.\nConclusion\nWe need to consider how generative AI for mental health impacts us on an individual basis.\nIn addition, and importantly, we need to be looking at the forest for the trees. On a widespread or population basis, how will the adoption and potential entrenchment of generative AI in all parts of our lives, including for therapeutic advisement, impact society on a grand scale?\nThat is the zillion-dollar question.\nLet\u2019s close out this discussion with an insightful quote from the preeminent Albert Einstein: \u201cLearn from yesterday, live for today, hope for tomorrow. The important thing is not to stop questioning.\u201d I stridently vote that we not stop questioning the role and impacts of generative AI for mental health.\nPlease join me in that neverending and societally crucial quest."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2023/01/27/generative-ai-chatgpt-can-disturbingly-gobble-up-your-private-and-confidential-data-forewarns-ai-ethics-and-ai-law/",
      "text": "Now you see your data, now you don\u2019t.\nMeanwhile, your precious data has become part of the collective, as it were.\nI\u2019m referring to an aspect that might be quite surprising to those of you that are eagerly and earnestly making use of the latest in Artificial Intelligence (AI). The data that you enter into an AI app is potentially not at all entirely private to you and you alone. It could be that your data is going to be utilized by the AI maker to presumably seek to improve their AI services or might be used by them and/or even their allied partners for a variety of purposes.\nYou have now been forewarned.\nThis handing over of your data is happening in the most innocuous of ways and by potentially thousands or on the order of millions of people. How so? There is a type of AI known as generative AI that has recently garnered big headlines and the rapt attention of the public at large. The most notable of the existing generative AI apps is one called ChatGPT which is devised by the firm OpenAI.\nThere are purportedly around a million registered users for ChatGPT. Many of those users seem to delight in trying out this hottest and latest generative AI app. The process is extraordinarily simple. You enter some text as a prompt, and voila, the ChatGPT app generates a text output that is usually in the form of an essay. Some refer to this as text-to-text, though I prefer to denote it as text-to-essay since this verbiage makes more everyday sense.\nAt first, a newbie user will likely enter something fun and carefree. Tell me about the life and times of George Washington, someone might enter as a prompt. ChatGPT then would produce an essay about our legendary first president. The essay would be entirely fluent and you would be hard-pressed to discern that it was produced by an AI app. An exciting thing to see happen.\nThe odds are that after playing around for a while, a segment of newbie users will have had their fill and potentially opt to stop toying with ChatGPT. They have now overcome their FOMO (fear of missing out), doing so after experimenting with the AI app that just about everyone seems to be chattering about. Deed done.\nSome though will begin to think about other and more serious ways to use generative AI.\nMaybe use ChatGPT to write that memo that your boss has been haranguing you to write. All you need to do is provide a prompt with the bullet points that you have in mind, and the next thing you know an entire memo has been generated by ChatGPT that would make your boss proud of you. You copy the outputted essay from ChatGPT, paste it into the company's official template in your word processing package, and email the classy memorandum to your manager. You are worth a million bucks. And you used your brains to find a handy tool to do the hard work for you. Pat yourself on the back.\nThat\u2019s not all.\nYes, there\u2019s more.\nKeep in mind that generative AI can perform a slew of other writing-related tasks.\nFor example, suppose you have written a narrative of some kind for a valued client and you dearly want to have a review done of the material before it goes out the door.\nEasy-peasy.\nYou paste the text of your narrative into a ChatGPT prompt and then instruct ChatGPT to analyze the text that you composed. The resultant outputted essay might deeply dig into your wording, and to your pleasant surprise will attempt to seemingly inspect the meaning of what you have said (going far beyond acting as a spell checker or a grammar analyzer). The AI app might detect faults in the logic of your narrative or might discover contradictions that you didn\u2019t realize were in your very own writing. It is almost as though you hired a crafty human editor to eyeball your draft and provide a litany of helpful suggestions and noted concerns (well, I want to categorically state that I am not trying to anthropomorphize the AI app, notably that a human editor is a human while the AI app is merely a computer program).\nThank goodness that you used the generative AI app to scrutinize your precious written narrative. You undoubtedly would prefer that the AI finds those disquieting written issues rather than after sending the document to your prized client. Imagine that you had composed the narrative for someone that had hired you to devise a quite vital depiction. If you had given the original version to the client, before doing the AI app review, you might suffer grand embarrassment. The client would almost certainly harbor serious doubts about your skills to do the work that was requested.\nLet\u2019s up the ante.\nConsider the creation of legal documents. That\u2019s obviously a particularly serious matter. Words and how they are composed can spell a spirited legal defense or a dismal legal calamity.\nIn my ongoing research and consulting, I interact regularly with a lot of attorneys that are keenly interested in using AI in the field of law. Various LegalTech programs are getting connected to AI capabilities. A lawyer can use generative AI to compose a draft of a contract or compose other legal documents. In addition, if the attorney made an initial draft themselves, they can pass the text over to a generative AI app such as ChatGPT to take a look and see what holes or gaps might be detected. For more about how attorneys and the legal field are opting to make use of AI, see my discussion at the link here.\nWe are ready though for the rub on this.\nAn attorney takes a drafted contract and copies the text into a prompt for ChatGPT. The AI app produces a review for the lawyer. Turns out that several gotchas are found by ChatGPT. The attorney revises the contract. They might also ask ChatGPT to suggest a rewording or redo of the composed text for them. A new and better version of the contract is then produced by the generative AI app. The lawyer grabs up the outputted text and plops it into a word processing file. Off the missive goes to their client. Mission accomplished.\nCan you guess what also just happened?\nBehind the scenes and underneath the hood, the contract might have been swallowed up like a fish into the mouth of a whale. Though this AI-using attorney might not realize it, the text of the contract, as placed as a prompt into ChatGPT, could potentially get gobbled up by the AI app. It now is fodder for pattern matching and other computational intricacies of the AI app. This in turn could be used in a variety of ways. If there is confidential data in the draft, that too is potentially now within the confines of ChatGPT. Your prompt as provided to the AI app is now ostensibly a part of the collective in one fashion or another.\nFurthermore, the outputted essay is also considered part of the collective. If you had asked ChatGPT to modify the draft for you and present the new version of the contract, this is construed as an outputted essay. The outputs of ChatGPT are also a type of content that can be retained or otherwise transformed by the AI app.\nYikes, you might have innocently given away private or confidential information. Not good. Plus, you wouldn\u2019t even be aware that you had done so. No flags were raised. A horn didn\u2019t blast. No flashing lights went off to shock you into reality.\nWe might anticipate that non-lawyers could easily make such a mistake, but for a versed attorney to do the same rookie mistake is nearly unimaginable. Nonetheless, there are likely legal professionals right now making this same potential blunder. They risk violating a noteworthy element of the attorney-client privilege and possibly breaching the American Bar Association (ABA) Model Rules of Professional Conduct (MRPC). In particular: \u201cA lawyer shall not reveal information relating to the representation of a client unless the client gives informed consent, the disclosure is impliedly authorized in order to carry out the representation or the disclosure is permitted by paragraph (b)\u201d (cited from the MRPC, and for which the exceptions associated with subsection b would not seem to encompass using a generative AI app in a non-secure way).\nSome attorneys might seek to excuse their transgression by claiming that they aren\u2019t tech wizards and that they would have had no ready means to know that their entering of confidential info into a generative AI app might somehow be a breach of sorts. The ABA has made clear that a duty for lawyers encompasses being up-to-date on AI and technology from a legal perspective: \u201cTo maintain the requisite knowledge and skill, a lawyer should keep abreast of changes in the law and its practice, including the benefits and risks associated with relevant technology, engage in continuing study and education and comply with all continuing legal education requirements to which the lawyer is subject\u201d (per MRPC).\nSeveral provisions come into this semblance of legal duty, including maintaining client confidential information (Rule 1.6), protecting client property such as data (Rule 1.15), properly communicating with a client (Rule 1.4), obtaining client informed consent (Rule 1.6), and ensuring competent representation on behalf of a client (Rule 1.1). And there is also the little-known but highly notable AI-focused resolution passed by the ABA: \u201cThat the American Bar Association urges courts and lawyers to address the emerging ethical and legal issues related to the usage of artificial intelligence (\u2018AI\u2019) in the practice of law including: (1) bias, explainability, and transparency of automated decisions made by AI; (2) ethical and beneficial usage of AI; and (3) controls and oversight of AI and the vendors that provide AI.\u201d\nWords to the wise for my legal friends and colleagues.\nThe crux of the matter is that just about anyone can get themselves into a jam when using generative AI. Non-lawyers can do so by their presumed lack of legal acumen. Lawyers can do so too, perhaps enamored of the AI or not taking a deep breath and reflecting on what legal repercussions can arise when using generative AI.\nWe are all potentially in the same boat.\nYou should also realize that ChatGPT is not the only generative AI app on the block. There are other generative AI apps that you can use. They too are likely cut from the same cloth, namely that the inputs you enter as prompts and the outputs you receive as generated outputted essays are considered part of the collective and can be used by the AI maker.\nIn today\u2019s column, I am going to unpack the nature of how data that you enter and data that you receive from generative AI can be potentially compromised with respect to privacy and confidentiality. The AI makers make available their licensing requirements and you would be wise to read up on those vital stipulations before you start actively using an AI app with any semblance of real data. I will walk you through an example of such licensing, doing so for the ChatGPT AI app.\nInto all of this comes a slew of AI Ethics and AI Law considerations.\nPlease be aware that there are ongoing efforts to imbue Ethical AI principles into the development and fielding of AI apps. A growing contingent of concerned and erstwhile AI ethicists are trying to ensure that efforts to devise and adopt AI takes into account a view of doing AI For Good and averting AI For Bad. Likewise, there are proposed new AI laws that are being bandied around as potential solutions to keep AI endeavors from going amok on human rights and the like. For my ongoing and extensive coverage of AI Ethics and AI Law, see the link here and the link here, just to name a few.\nThere are significant Ethical AI nuances and provisions associated with how AI makers can or should deal with the data or information that seems private or confidential to their users. You likely know too that a bunch of existing laws strike at the core of how data is supposed to be handled by technology entities. The chances too are that the newly proposed AI laws will also crisscross into that same territory. See for example my coverage of the AI Bill of Rights and other legal wranglings going on about AI, at the link here.\nHere is the key takeaway from this discussion all told:\n- Be very, very, very careful about what data or information you opt to put into your prompts when using generative AI, and similarly be extremely careful and anticipate what kinds of outputted essays you might get since the outputs can also be absorbed too.\nDoes this imply that you should not use generative AI?\nNope, that\u2019s not at all what I am saying.\nUse generative AI to your heart's content. The gist is that you need to be mindful of how you use it. Find out what kind of licensing stipulations are associated with the usage. Decide whether you can live with those stipulations. If there are avenues to inform the AI maker that you want to invoke certain kinds of added protections or allowances, make sure you do so.\nI will also mention one other facet that I realize will get some people boiling mad. Here goes. Despite whatever the licensing stipulations are, you have to also assume that there is a possibility that those requirements might not be fully adhered to. Things can go awry. Stuff can slip between the cracks. In the end, sure, you might have a legal case against an AI maker for not conforming to their stipulations, but that\u2019s somewhat after the horse is already out of the barn.\nA potentially highly secure way to proceed would be to set up your own instance on your own systems, whether in the cloud or in-house (and, assuming that you adhere to the proper cybersecurity precautions, which admittedly some do not and they are worse off in their own cloud than using the cloud of the software vendor). A bit of a nagging problem though is that few of the generative AI large-scale apps allow this right now. They are all pretty much working on an our-cloud-only basis. Few have made available the option of having an entire instance carved out just for you. I\u2019ve predicted that we will gradually see this option arising, though at first it will be rather costly and somewhat complicated, see my predictions at the link here.\nHow do otherwise especially bright and notably astute people get themselves into a data or information confidentiality erosion quagmire?\nThe allure of these generative AI apps is quite magnetic once you start using one. Step by step, you find yourself mesmerized and opting to put your toes further and further into the generative AI waters. The next thing you know, you are readily handing over proprietary content that is supposed to be kept private and confidential into a generative AI app.\nResist the urge and please refrain from stepwise falling into an unsavory trap.\nFor business leaders and top-level executives, the same warning goes to you and all of the people throughout your company. Senior execs get caught up in the enthusiasm and amazement of using generative AI too. They can really mess up and potentially enter top-level secret info into an AI app.\nOn top of this, they might have wide leagues of their employees also playing around with generative AI. Many of those otherwise mindful staff are mindlessly and blissfully entering the company's private and confidential information into these AI apps. According to recent news reports, Amazon apparently discovered that some employees were entering various proprietary information into ChatGPT. A legal-oriented warning was said to have been sent internally to be cautious in making use of the irresistible AI app.\nOverall, a bit of irony comes into the rising phenomena of employees willy-nilly entering confidential data into ChatGPT and other generative AI. Allow me to elaborate. Today\u2019s modern companies typically have strict cybersecurity policies that they have painstakingly crafted and implemented. Numerous technological protections exist. The hope is to prevent accidental releases of crucial stuff. A continual drumbeat is to be careful when you visit websites, be careful when you use any non-approved apps, and so on.\nAlong comes generative AI apps such as ChatGPT. The news about the AI app goes through the roof and gets widespread attention. A frenzy arises. People in these companies that have all these cybersecurity protections opt to hop onto a generative AI app. They idly play with it at first. They then start entering company data. Wham, they have now potentially exposed information that should not have been disclosed.\nThe shiny new toy that magically circumvents the millions of dollars of expenditures on cybersecurity protections and ongoing training about what to not do. But, hey, it is exciting to use generative AI and be part of the \u201cin\u201d crowd. That\u2019s what counts, apparently.\nI trust that you get my drift about being markedly cautious.\nLet\u2019s next take a close-up look at how generative AI technically deals with the text of the prompts and outputted essays. We will also explore some of the licensing stipulations, using ChatGPT as an example. Please realize that I am not going to cover the full gamut of those licensing elements. Make sure to involve your legal counsel for whichever generative AI apps you might decide to use. Also, the licensing differs from AI maker to AI maker, plus a given AI maker can opt to change their licensing so make sure to remain vigilant on whatever the latest version of the licensing stipulates.\nWe have some exciting unpacking to do on this heady topic.\nFirst, we ought to make sure that we are all on the same page about what Generative AI consists of and also what ChatGPT is all about. Once we cover that foundational facet, we can perform a cogent assessment of the mirror metaphor associated with this type of AI.\nIf you are already abundantly familiar with Generative AI and ChatGPT, you can perhaps skim the next section and proceed with the section that follows it. I believe that everyone else will find instructive the vital details about these matters by closely reading the section and getting up-to-speed.\nA Quick Primer About Generative AI And ChatGPT\nChatGPT is a general-purpose AI interactive conversational-oriented system, essentially a seemingly innocuous general chatbot, nonetheless, it is actively and avidly being used by people in ways that are catching many entirely off-guard, as I\u2019ll elaborate shortly. This AI app leverages a technique and technology in the AI realm that is often referred to as Generative AI. The AI generates outputs such as text, which is what ChatGPT does. Other generative-based AI apps produce images such as pictures or artwork, while others generate audio files or videos.\nI\u2019ll focus on the text-based generative AI apps in this discussion since that\u2019s what ChatGPT does.\nGenerative AI apps are exceedingly easy to use.\nAll you need to do is enter a prompt and the AI app will generate for you an essay that attempts to respond to your prompt. The composed text will seem as though the essay was written by the human hand and mind. If you were to enter a prompt that said \u201cTell me about Abraham Lincoln\u201d the generative AI will provide you with an essay about Lincoln. This is commonly classified as generative AI that performs text-to-text or some prefer to call it text-to-essay output. As mentioned, there are other modes of generative AI, such as text-to-art and text-to-video.\nYour first thought might be that this generative capability does not seem like such a big deal in terms of producing essays. You can easily do an online search of the Internet and readily find tons and tons of essays about President Lincoln. The kicker in the case of generative AI is that the generated essay is relatively unique and provides an original composition rather than a copycat. If you were to try and find the AI-produced essay online someplace, you would be unlikely to discover it.\nGenerative AI is pre-trained and makes use of a complex mathematical and computational formulation that has been set up by examining patterns in written words and stories across the web. As a result of examining thousands and millions of written passages, the AI can spew out new essays and stories that are a mishmash of what was found. By adding in various probabilistic functionality, the resulting text is pretty much unique in comparison to what has been used in the training set.\nThat\u2019s why there has been an uproar about students being able to cheat when writing essays outside of the classroom. A teacher cannot merely take the essay that deceitful students assert is their own writing and seek to find out whether it was copied from some other online source. Overall, there won\u2019t be any definitive preexisting essay online that fits the AI-generated essay. All told, the teacher will have to begrudgingly accept that the student wrote the essay as an original piece of work.\nThere are additional concerns about generative AI.\nOne crucial downside is that the essays produced by a generative-based AI app can have various falsehoods embedded, including patently untrue facts, facts that are misleadingly portrayed, and apparent facts that are entirely fabricated. Those fabricated aspects are often referred to as a form of AI hallucinations, a catchphrase that I disfavor but lamentedly seems to be gaining popular traction anyway (for my detailed explanation about why this is lousy and unsuitable terminology, see my coverage at the link here).\nI\u2019d like to clarify one important aspect before we get into the thick of things on this topic.\nThere have been some zany outsized claims on social media about Generative AI asserting that this latest version of AI is in fact sentient AI (nope, they are wrong!). Those in AI Ethics and AI Law are notably worried about this burgeoning trend of outstretched claims. You might politely say that some people are overstating what today\u2019s AI can actually do. They assume that AI has capabilities that we haven\u2019t yet been able to achieve. That\u2019s unfortunate. Worse still, they can allow themselves and others to get into dire situations because of an assumption that the AI will be sentient or human-like in being able to take action.\nDo not anthropomorphize AI.\nDoing so will get you caught in a sticky and dour reliance trap of expecting the AI to do things it is unable to perform. With that being said, the latest in generative AI is relatively impressive for what it can do. Be aware though that there are significant limitations that you ought to continually keep in mind when using any generative AI app.\nIf you are interested in the rapidly expanding commotion about ChatGPT and Generative AI all told, I\u2019ve been doing a focused series in my column that you might find informative. Here\u2019s a glance in case any of these topics catch your fancy:\n- 1) Predictions Of Generative AI Advances Coming. If you want to know what is likely to unfold about AI throughout 2023 and beyond, including upcoming advances in generative AI and ChatGPT, you\u2019ll want to read my comprehensive list of 2023 predictions at the link here.\n- 2) Generative AI and Mental Health Advice. I opted to review how generative AI and ChatGPT are being used for mental health advice, a troublesome trend, per my focused analysis at the link here.\n- 3) Fundamentals Of Generative AI And ChatGPT. This piece explores the key elements of how generative AI works and in particular delves into the ChatGPT app, including an analysis of the buzz and fanfare, at the link here.\n- 4) Tension Between Teachers And Students Over Generative AI And ChatGPT. Here are the ways that students will deviously use generative AI and ChatGPT. In addition, there are several ways for teachers to contend with this tidal wave. See the link here.\n- 5) Context And Generative AI Use. I also did a seasonally flavored tongue-in-cheek examination about a Santa-related context involving ChatGPT and generative AI at the link here.\n- 6) Scammers Using Generative AI. On an ominous note, some scammers have figured out how to use generative AI and ChatGPT to do wrongdoing, including generating scam emails and even producing programming code for malware, see my analysis at the link here.\n- 7) Rookie Mistakes Using Generative AI. Many people are both overshooting and surprisingly undershooting what generative AI and ChatGPT can do, so I looked especially at the undershooting that AI rookies tend to make, see the discussion at the link here.\n- 8) Coping With Generative AI Prompts And AI Hallucinations. I describe a leading-edge approach to using AI add-ons to deal with the various issues associated with trying to enter suitable prompts into generative AI, plus there are additional AI add-ons for detecting so-called AI hallucinated outputs and falsehoods, as covered at the link here.\n- 9) Debunking Bonehead Claims About Detecting Generative AI-Produced Essays. There is a misguided gold rush of AI apps that proclaim to be able to ascertain whether any given essay was human-produced versus AI-generated. Overall, this is misleading and in some cases, a boneheaded and untenable claim, see my coverage at the link here.\n- 10) Role-Playing Via Generative AI Might Portend Mental Health Drawbacks. Some are using generative AI such as ChatGPT to do role-playing, whereby the AI app responds to a human as though existing in a fantasy world or other made-up setting. This could have mental health repercussions, see the link here.\n- 11) Exposing The Range Of Outputted Errors and Falsehoods. Various collected lists are being put together to try and showcase the nature of ChatGPT-produced errors and falsehoods. Some believe this is essential, while others say that the exercise is futile, see my analysis at the link here.\n- 12) Schools Banning Generative AI ChatGPT Are Missing The Boat. You might know that various schools such as the New York City (NYC) Department of Education have declared a ban on the use of ChatGPT on their network and associated devices. Though this might seem a helpful precaution, it won\u2019t move the needle and sadly entirely misses the boat, see my coverage at the link here.\n- 13) Generative AI ChatGPT Is Going To Be Everywhere Due To The Upcoming API. There is an important twist coming up about the use of ChatGPT, namely that via the use of an API portal into this particular AI app, other software programs will be able to invoke and utilize ChatGPT. This is going to dramatically expand the use of generative AI and has notable consequences, see my elaboration at the link here.\n- 14) Ways That ChatGPT Might Fizzle Or Melt Down. Several potential vexing issues lay ahead of ChatGPT in terms of undercutting the so far tremendous praise it has received. This analysis closely examines eight possible problems that could cause ChatGPT to lose its steam and even end up in the doghouse, see the link here.\nYou might find of interest that ChatGPT is based on a version of a predecessor AI app known as GPT-3. ChatGPT is considered to be a slightly next step, referred to as GPT-3.5. It is anticipated that GPT-4 will likely be released in the Spring of 2023. Presumably, GPT-4 is going to be an impressive step forward in terms of being able to produce seemingly even more fluent essays, going deeper, and being an awe-inspiring marvel as to the compositions that it can produce.\nYou can expect to see a new round of expressed wonderment when springtime comes along and the latest in generative AI is released.\nI bring this up because there is another angle to keep in mind, consisting of a potential Achilles heel to these better and bigger generative AI apps. If any AI vendor makes available a generative AI app that frothily spews out foulness, this could dash the hopes of those AI makers. A societal spillover can cause all generative AI to get a serious black eye. People will undoubtedly get quite upset at foul outputs, which have happened many times already and led to boisterous societal condemnation backlashes toward AI.\nOne final forewarning for now.\nWhatever you see or read in a generative AI response that seems to be conveyed as purely factual (dates, places, people, etc.), make sure to remain skeptical and be willing to double-check what you see.\nYes, dates can be concocted, places can be made up, and elements that we usually expect to be above reproach are all subject to suspicions. Do not believe what you read and keep a skeptical eye when examining any generative AI essays or outputs. If a generative AI app tells you that Abraham Lincoln flew around the country in his own private jet, you would undoubtedly know that this is malarky. Unfortunately, some people might not realize that jets weren\u2019t around in his day, or they might know but fail to notice that the essay makes this brazen and outrageously false claim.\nA strong dose of healthy skepticism and a persistent mindset of disbelief will be your best asset when using generative AI.\nWe are ready to move into the next stage of this elucidation.\nKnowing What The Devil Will Happen With That Text\nNow that we\u2019ve got the fundamentals established, we can dive into the data and information considerations when using generative AI.\nFirst, let\u2019s briefly consider what happens when you enter some text into a prompt for ChatGPT. We don\u2019t know for sure what is happening inside ChatGPT since the program is considered proprietary. Some have pointed out that this undercuts a sense of transparency about the AI app. A somewhat smarmy remark is that for a company that is called OpenAI, their AI is actually closed to public access and not available as open source.\nLet\u2019s discuss tokenization.\nWhen you enter plain text into a prompt and hit return, there is presumably a conversion that right away happens. The text is converted into a format consisting of tokens. Tokens are subparts of words. For example, the word \u201chamburger\u201d would normally be divided into three tokens consisting of the portion \u201cham\u201d, \u201cbur\u201d, and \u201cger\u201d. A rule of thumb is that tokens tend to represent about four characters or are considered approximately 75% of a conventional English word.\nEach token is then reformulated as a number. Various internal tables designate which token is assigned to which particular number. The uptake on this is that the text that you entered is now entirely a set of numbers. Those numbers are used to computationally analyze the prompt. Furthermore, the pattern-matching network that I mentioned earlier is also based on tokenized values. Ultimately, when composing or generating the outputted essay, these numeric tokens are first used, and then before being displayed, the tokens are converted back into sets of letters and words.\nThink about that for a moment.\nWhen I tell people that this is how the mechanics of the processing work, they are often stunned. They assumed that a generative AI app such as ChatGPT must use wholly integrative words. We logically assume that words act as the keystone for statistically identifying relationships in written narratives and compositions. Turns out that the processing actually tends to use tokens. Perhaps this adds to the amazement over how the computational process seems to do quite a convincing job of mimicking human language.\nI walked you through that process due to one common misconception that seems to be spreading around. Some people appear to believe that because your prompt text is being converted into numeric tokens, you are safe and sound that the internals of the AI app somehow no longer have your originally entered text. Thus, the claim goes, even if you entered confidential info in your prompt, you have no worries since it has all been seemingly tokenized.\nThat notion is a fallacy. I\u2019ve just pointed out that numeric tokens can be readily brought back into the textual format of letters and words. The same could be done with the converted prompt that has been tokenized. There is nothing magically protective about having been tokenized. That being said, after the conversion into tokens, if there is an additional process that opts to drop out tokens, move them around, and otherwise scramble or chop up things, in that case, there is indeed the possibility that some portions of the original prompt are no longer intact (and assuming that an original copy isn\u2019t otherwise retained or stored someplace internally).\nI\u2019d like to next take a look at the various notifications and licensing stipulations of ChatGPT.\nWhen you log onto ChatGPT, there are a series of cautions and informational comments displayed.\nHere they are:\n- \u201cMay occasionally generate incorrect information.\u201d\n- \u201cMay occasionally produce harmful instructions or biased content.\u201d\n- \u201cTrained to decline inappropriate requests.\u201d\n- \u201cOur goal is to get external feedback in order to improve our systems and make them safer.\u201d\n- \u201cWhile we have safeguards in place, the system may occasionally generate incorrect or misleading information and produce offensive or biased content. It is not intended to give advice.\u201d\n- \u201cConversations may be reviewed by our AI trainers to improve our systems.\u201d\n- \u201cPlease don't share any sensitive information in your conversations.\u201d\n- \u201cThis system is optimized for dialogue. Let us know if a particular response was good or unhelpful.\u201d\n- \u201cLimited knowledge of world and events after 2021.\u201d\nTwo of those stated cautions are especially relevant to this discussion. Look at the sixth bulleted point and the seventh bulleted point.\nLet\u2019s unpack those two:\n\u201cConversations may be reviewed by our AI trainers to improve our systems.\u201d\nThis sixth bulleted point explains that text conversations when using ChatGPT might be reviewed by ChatGPT via its \u201cAI trainers\u201d which is being done to improve their systems. This is to inform you that for any and all of your entered text prompts and the corresponding outputted essays, all of which are part of the \u201cconversation\u201d that you undertake with ChatGPT, it can entirely be seen by their people. The rationale proffered is that this is being done to improve the AI app, and we are also told that it is a type of work task being done by their AI trainers. Maybe so, but the upshot is that they have put you on notice that they can look at your text. Period, full stop.\nIf they were to do something else with your text, you would probably seek legal advice about whether they have gravitated egregiously beyond the suggested confines of merely reviewing the text for system improvement purposes (assuming you managed to discover that they had done so, which of itself seems perhaps unlikely). Anyway, you can imagine the legal wrangling of trying to pin them down on this, and their attempts to wordsmith their way out of being nabbed for somehow violating the bounds of their disclaimer.\n\u201cPlease don't share any sensitive information in your conversations.\u201d\nThe seventh bulleted point indicates that you are not to share any sensitive information in your conversations. That seems relatively straightforward. I suppose you might quibble with what the definition of sensitive information consists of. Also, the bulleted point doesn\u2019t tell you why you should not share any sensitive information. If you someday have to try and in a dire sweat explain why you foolishly entered confidential data, you might try the raised eyebrow claim that the warning was non-specific, therefore, you didn\u2019t grasp the significance. Hold your breath on that one.\nAll in all, I dare say that most people that I\u2019ve seen using ChatGPT tend to not read the bulleted points, or they skim the bulleted precautions and just nod their head as though it is the usual gibberish legalese that you see all of the time. Few it seems take the warnings strictly to heart. Is this a fault of the vendor for not making the precautions more pronounced? Or should we assume that the users should be responsible and have mindfully read, comprehended, and subsequently act judiciously based on the warnings?\nSome even claim that the AI app ought to repeatedly warn you. Each time that you enter a prompt, the software should pop up a warning and ask you whether you want to hit the return. Over and over again. Though this might seem like a helpful precaution, admittedly it would irritate the heck out of users. A thorny tradeoff is involved.\nOkay, so those are the obvious cautions as presented for all users to readily see.\nUsers that might be more inquisitive, could opt to pursue some of the detailed licensing stipulations that are also posted online. I doubt that many do so. My hunch is that few look seriously at the bulleted points when logging in, and even fewer by a huge margin then take a look at the licensing details. Again, we are all somewhat numb to such things these days. I\u2019m not excusing the behavior, only noting why it occurs.\nI\u2019ll examine a few excerpts from the posted licensing terms.\nFirst, here\u2019s a definition of what they consider \u201ccontent\u201d associated with the use of ChatGPT:\n- \u201cYour Content. You may provide input to the Services (\u2018Input\u2019), and receive output generated and returned by the Services based on the Input (\u2018Output\u2019). Input and Output are collectively \u201cContent.\u201d As between the parties and to the extent permitted by applicable law, you own all Input, and subject to your compliance with these Terms, OpenAI hereby assigns to you all its right, title and interest in and to Output. OpenAI may use Content as necessary to provide and maintain the Services, comply with applicable law, and enforce our policies. You are responsible for Content, including for ensuring that it does not violate any applicable law or these Terms.\u201d\nIf you carefully examine that definition, you\u2019ll notice that OpenAI declares that it can use the content as they deem necessary to maintain its services, including complying with applicable laws and enforcing its policies. This is a handy catchall for them. In an upcoming one of my columns, I\u2019ll be discussing a different but related topic, specifically about the Intellectual Property (IP) rights that you have regarding the entered text prompts and outputted essays (I point this out herein since the definition of the Content bears on that topic).\nIn a further portion of the terms, labeled as section c, they mention this facet: \u201cOne of the main benefits of machine learning models is that they can be improved over time. To help OpenAI provide and maintain the Services, you agree and instruct that we may use Content to develop and improve the Services.\u201d This is akin to the earlier discussed one-line caution that appears when you log into ChatGPT.\nA separate document that is linked to this provides some additional aspects on these weighty matters:\n- \u201cAs part of this continuous improvement, when you use OpenAI models via our API, we may use the data you provide us to improve our models. Not only does this help our models become more accurate and better at solving your specific problem, it also helps improve their general capabilities and safety. We know that data privacy and security are critical for our customers. We take great care to use appropriate technical and process controls to secure your data. We remove any personally identifiable information from data we intend to use to improve model performance. We also only use a small sampling of data per customer for our efforts to improve model performance. For example, for one task, the maximum number of API requests that we sample per customer is capped at 200 every 6 months\u201d (excerpted from the document entitled \u201cHow your data is used to improve model performance\u201d).\nNote that the stipulation indicates that the provision applies to the use of the API as a means of connecting to and using the OpenAI models all told. It is somewhat murky as to whether this equally applies to end users that are directly using ChatGPT.\nIn yet a different document, one that contains their list of various FAQs, they provide a series of questions and answers, two of which seem especially pertinent to this discussion:\n- \u201c(5) Who can view my conversations? As part of our commitment to safe and responsible AI, we review conversations to improve our systems and to ensure the content complies with our policies and safety requirements.\u201d\n- \u201c(8) Can you delete specific prompts? No, we are not able to delete specific prompts from your history. Please don't share any sensitive information in your conversations.\u201d\nThere is an additional document that covers their privacy policy. It says this: \u201cWe collect information that alone or in combination with other information in our possession could be used to identify you (\u201cPersonal Information\u201d)\u201d and then proceeds to explain that they might use log data, usage data, communication information, device information, cookies, analytics, and other potentially collectible information about you. Make sure to read the fine print.\nI think that pretty much provides a tour of some considerations underlying how your data might be used. As I mentioned at the outset, I am not going to laboriously step through all of the licensing stipulations.\nHopefully, this gets you into a frame of mind on these matters and will remain on top of your mind.\nConclusion\nI\u2019ve said it before and I\u2019ll say it again, do not enter confidential or private data into these generative AI apps.\nConsider a few handy tips or options on this sage piece of advice:\n- Think Before Using Generative AI\n- Remove Stuff Beforehand\n- Mask Or Fake Your Input\n- Setup Your Own Instance\n- Other\nI\u2019ll indicate next what each one of those consists of. The setting up of your own instance was earlier covered herein. The use of \u201cother\u201d in my list is due to the possibility of other ways to cope with preventing confidential data from getting included, which I will be further covering in a future column posting.\nLet\u2019s examine these:\n- Think Before Using Generative AI. One approach involves avoiding using generative AI altogether. Or at least think twice before you do so. I suppose the safest avenue involves not using these AI apps. But this also seems quite severe and nearly overboard.\n- Remove Stuff Beforehand. Another approach consists of removing confidential or private information from whatever you enter as a prompt. In that sense, if you don\u2019t enter it, there isn\u2019t a chance of it getting infused into the Borg. The downside is that maybe the removal of the confidential portion somehow reduces or undercuts what you are trying to get the generative AI to do for you.\n- Mask Or Fake Your Inputs. You could modify your proposed text by changing up the info so that whatever seemed confidential or private is now differently portrayed. For example, instead of a contract mentioning the Widget Company and John Smith, you change the text to refer to the Specious Company and Jane Capone. An issue here is whether you\u2019ll do a sufficiently exhaustive job such that all of the confidentially and private aspects are fully altered or faked. It would be easy to miss some of the cloudings and leave in stuff that ought to not be there.\nHere's an interesting added twist that might get your noggin further percolating on this topic. If you can completely ensure that none of your input prompts contain any confidential information, does this imply that you don\u2019t need to have an iota of worry about the outputted essays also containing any of your confidential information?\nThis would seem axiomatically true. No confidential input, no confidential output.\nHere\u2019s your mind-bending twist.\nGenerative AI is often set up to computationally retrain itself from the text prompts that are being provided. Likewise, generative AI is frequently devised to computationally retrain from the outputted essays. All of this retraining is intended to improve the capabilities of generative AI.\nI described in one of my other columns the following experiment that I undertook. An attorney was trying to discover a novel means of tackling a legal issue. After an exhaustive look at the legal literature, it seemed that all angles already surfaced were found. Using generative AI, we got the AI app to produce a novelty of a legal approach that had seemingly not before been previously identified. It was believed that nobody else had yet landed on this legal posture. A legal gold nugget, as it were. This could be a strategically valuable competitive legal bonanza that at the right time be leveraged and exploited.\nDoes that outputted essay constitute a form of confidential information, such that it was generated by the AI for this particular person and contains something special and seemingly unique?\nAha, this leads us to the other allied and intertwined topic about the ownership and IP rights associated with generative AI. Stay tuned to see how this turns out.\nA final remark for now.\nSophocles provided this wisdom: \"Do nothing secretly; for Time sees and hears all things, and discloses all.\" I suppose you could modernize the wording and contend that generative AI and those that devise and maintain the AI are apt to see all too.\nIt is a modestly token piece of advice worthy of being remembered."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2024/08/30/making-use-of-generative-ai-to-perform-energy-healing-mind-body-therapy/",
      "text": "What do you think of using energy healing therapy to help your mind and body?\nThe odds are that you probably have a strong opinion. Some people believe vehemently that energy healing is the right way to go. Others tend to raise their eyebrows and intimate that energy healing is a questionable practice. There are also the in-betweeners. They are unsure, don\u2019t know much about it, vaguely have heard that it is one of those touchy-feely approaches, and remain hesitant and somewhat skeptical.\nLet me add a new dimension to the conundrum.\nTurns out that generative AI can be used to perform energy healing therapy.\nSay what?\nOf all the aspects of energy healing that just about everyone knows, the act of energy healing seems to require that a human energy healer be in the loop. The rather incredible idea that AI would be able to substitute for a human energy healer seems nearly preposterous. Can\u2019t be. Until the day that AI may become sentient, and perhaps includes a \u201cbody\u201d such as a robotic structure, AI is merely a cold-hearted non-feely piece of software and computing hardware.\nWell, be ready to be surprised.\nModern-day generative AI of a somewhat conventional software and server-based hardware variety can indeed perform duties akin to those undertaken via energy healer therapy. That being said, some doubt the efficacy of such an angle. One thing is for sure, the whole kit and kaboodle comes with a slew of heated debate and a notable difference of opinion.\nHere\u2019s how we will proceed. I will walk you through the realm of energy healing therapy, along with introducing you to the coupling of generative AI into this quite intense matter. The ins and outs will be covered. In the end, you will need to decide how you feel about the myriads of considerations at play.\nBest High-Yield Savings Accounts Of 2024\nBest 5% Interest Savings Accounts of 2024\nThink of it this way. Even if you are a skeptic or doubter of energy healing and other such methods, you might find engaging and intriguing the intertwining of energy healing and generative AI. There are mental health implications that provide insights into human cognition, human beliefs, human behaviors, and the mind-body dynamics of humankind.\nPrepare yourself for a memorable and informative ride.\nFor my ongoing readers and new readers, this thought-provoking discussion continues my in-depth series about the impact of generative AI in the health and medical realm. The focus this time is once again on the mental health domain and examines the use of generative AI when combined with energy healing.\nPreviously, I have examined numerous interleaving facets of generative AI and mental health, see my comprehensive overview at the link here. You might also find of notable interest a CBS 60 Minutes episode that recently examined crucial facets of this evolving topic, see the link here (I am honored and pleased to indicate that I was featured in the episode, see the link here).\nOther vital postings in my column include in-depth coverage of mental health chatbots which have been bolstered by generative AI (see the link here) and the rapidly changing nature of the client-therapist relationship due to generative AI at the link here. I explored where things are headed regarding the levels of AI-based mental therapy autonomous guidance at the link here, and showcased the importance of the World Health Organization (WHO) report on global health and generative AI at the link here, and so on.\nOn with the show.\nEssentials Of Energy Healing Therapy\nThis field of endeavor goes by several different names.\nFor example, some refer to this realm as energy healing therapy, energy medicine, mind-body medicine or therapy, complementary and alternative medicine (CAM), vibrational medicine, energy therapy, and so on. Some experts make distinctions amongst those areas. For the sake of discussion, let\u2019s treat them as roughly of the same overall ilk. I will simply mention \u201cenergy healing\u201d or \u201cenergy healing therapy\u201d and be broadly referring to them as a collective form of therapy.\nI apologize if that gets anyone roiled up. I realize that to some these are each vastly different fields or subfields. In this case, I am trying to stay at the 30,000-foot level. Thanks for going along.\nThe next big aspect to tackle consists of the energy element.\nIt goes somewhat like this.\nAs a human, your body contains energy. The storage and flow of energy are important. It can readily impact your mental being. Your mental health is inextricably linked to the energy of your body. This is a two-way street. The body's energy impacts your mental health. Your mental health impacts the energy within your body.\nAgain, that\u2019s from a macroscopic perspective.\nSuppose that the energy within your body gets stuck, isn\u2019t flowing, or maybe is less than what is suitably needed to keep your mind and body going smoothly. In a sense, perhaps you could resolve the issue by doing something sensible and useful about your energy. You might want to get the energy unstuck, or maybe do something that makes the energy flow more conductively.\nAha, that\u2019s where energy healing therapy comes into the picture.\nYou could perform energy healing therapy or practices that might provide improvements in your energy flow and storage. Doing so could make your body feel better. Doing so could make your mind feel better. The two are linked to each other, known as mind-body, such that energy healing usually seeks to encompass both as a combo.\nThe means of performing energy healing therapy vary.\nYou might have seen on TV or portrayed in films where an energy healer stands in front of someone desirous of such therapy. The energy healer appears to convey energy to the person or does something that otherwise enables the person\u2019s energy to flow or increase. Voila, the act of energy healing therapy has taken place.\nThis is partially where the debates start to ensue. One contention is that energy healers ought to entirely be properly trained, certified, and credentialed. The view is that if someone just starts claiming to be an energy healer, this opens the door to scams and scammers. Thus, those who proclaim to be proper energy healers ought to be required to attest to their skills, abilities, and training. Regulations and the like are hotly debated.\nAnother twist underlies the energy facets.\nI like to categorize the energy in this fashion:\n- (1) Energy within you.\n- (2) Energy transmitted to you.\n- (3) Energy around you.\nLet\u2019s discuss those three briefly.\nI\u2019ve already mentioned the assumption that you have energy within you. This energy might be at the right amount. The energy within you might be the right amount but is jammed up and not in all the places it should be. Perhaps there is enough energy within you, but it is stuck here or there. In that case, you don\u2019t necessarily need additional energy, you just need to have the energy flow and be balanced throughout you.\nOf course, the energy might be less than it needs to be and ought to be replenished. Again, the replenishment would need to flow suitably too.\nTo get your energy to the right level or to get your energy unstuck, one means would be to transmit energy to you. This transmission has a chance of boosting the energy within you. When you don\u2019t need more energy and only need to get energy unstuck, the energy transmission might primarily serve to get the flow underway.\nAnother possibility involves utilizing the energy that might be around you. Rather than energy being transmitted to you per se, suppose you could absorb or collect energy that might already be around you. This is where crystals and other energy-emitting machinations arise. If you are within the auspices of energy outside of your body, you might be able to use the energy. It isn\u2019t especially being transmitted to you, even though that is a possibility, and generally, you are tapping into energy that is otherwise already within your capability to harness.\nEnergy And The Distance Controversy\nI have a mind-bending question for you.\nDoes geographical distance make a difference in this energy-gathering conception?\nGive that some serious contemplation, if you please.\nI shall unpack it.\nSuppose an energy healer is standing directly in front of a person seeking energy healing therapy. The energy healer rubs their own hands together, seeming to create an abundance of energy. The energy healer then pushes or directs the energy toward the person wanting the therapy. The energy presumably enters that person\u2019s body. In theory, if done suitably, this will either boost their energy or unlock the flow of energy within them.\nWith me so far?\nI trust so.\nChange the setting. The energy healer is in New York and the person seeking energy healing is in California. They are talking to each other via a Zoom-like electronic setup. The energy healer rubs their hands together to create an energy abundance.\nCan the energy healer somehow direct or transmit the energy to the person in California?\nYour first thought might be that this seems far-fetched. How could energy be transmitted like this over such a great distance? One answer might be that somehow the energy is being transmitted in the same means as the video and audio transmission of the Zoom-like setup. Another angle would be that there isn\u2019t a distance hurdle involved and that energy of this type moves in a manner unlike what we conventionally think of energy to be. Some assert that this type of energy defies the norms of space and time.\nI have a bit of a surprise for you that maybe you weren\u2019t aware of.\nDuring the Covid pandemic, energy healing therapy continued even though people could no longer readily get together in person. This gave rise to what some refer to as distance healing, remote healing, or distant healing. Energy healers were kept busy by performing their services on a remote basis.\nCynics might argue that this shows that the whole thing is a facade. The posture is that there wasn\u2019t any energy flowing, to begin with. The fact that remote efforts continued and that people thought they were still getting energy healing just illustrates the false nature of the practice.\nThe counterargument is that either energy knows no bounds, or that energy can be transmitted over great distances and that conventional science hasn\u2019t identified how this happens. People often point to quantum physics to emphasize that there are aspects of energy that we still do not have a handle on. Einstein was famously quoted as saying that quantum mechanics which posits that objects across vast distances can impact each other was said to be an indicator of \u201cspooky action at a distance.\u201d\nWhile you mull that over, let\u2019s try a slightly different perspective.\nSuppose an energy healer is at a great distance from a person seeking this kind of therapy. The energy healer has made arrangements for crystals or other energy-emitting items to be in the room where the person is. By instructing the person over a Zoom-like presence, the energy healer can get the person to absorb the energy present or around the person. Thus, the energy healer is not transmitting energy across a great distance. They are instead in this circumstance aiding the person is being able to tap into the energy that is nearby them.\nThose who have a scientific explain-this-to-me mindset might find that approach more relatable to their sense of how the world works. The key is that the geographic distance no longer raises those head-scratching questions. You can still be hesitant to believe that crystals or other items are in fact an energy source or that a human can tap into them, but at least the distance dilemma is taken out of the equation.\nResearch On Energy Healing Practices\nWow, that\u2019s a lot to absorb.\nLet\u2019s see what research has to say.\nIn a research study entitled \u201cEnergy Healing Therapies: A Systematic Review and Critical Appraisal\u201d by L. Rogers, K. Phillips, N. Cooper, Health Psychology Review, January 2021, these salient points were made (excerpts):\n- \u201cCommon terms used in the field of energy healing include energy healing, energy medicine, energy therapies.\u201d\n- \u201cThese mind-body energy healing modalities are a group of healing techniques that enhance the mind\u2019s interactions with bodily function, to induce relaxation, and to improve overall health and well-being.\u201d\n- \u201cMind-body energy healing techniques are based on mantras, meditations, breathing exercises, physical exercises, and relaxations, on the belief that human thoughts, feelings, and emotions can affect both physical and mental wellbeing.\u201d\n- \u201cIn this work, we presented a review of the ten popular mind-body energy healing therapies. They are compassion-based Ray 72000 Nadi healing, Reiki healing, Ray 114 chakra healing, Pranic healing, Music therapy, EFT healing, Theata Healing, Cognitive Behavior Therapy, and Touch Therapy.\u201d\n- \u201cThere is a need for more robust randomized control trials utilizing standardized holistic energy healing protocols to provide further evidence on this subject.\u201d\nNotice that those above points indicate that these practices can make use of meditations, breathing exercises, and the like.\nI bring this up because energy healing is sometimes (some would say, unfairly) pigeonholed into solely the act of energy transmission.\nThe gist is that energy healing therapy does not rely exclusively on energy transmission or energy sharing. As noted, mantras, relaxation techniques, and a host of other techniques come into play.\nOne difficulty with research on this topic is that we customarily expect strong or reliable research to employ empirical tests and experiments, of which lamentedly there is not as much done in this sphere as you might presume. The last bullet point above noted that more robust RCTs (randomized control trials) are needed.\nSpeaking of which, let\u2019s take a look at a study that did make use of RCT. In a study entitled \u201cEffects Of Distant Biofield Energy Healing On Adults Associated With Psychological And Mental Health-Related Symptoms: A Randomized Placebo-Controlled, Double-Blind Study\u201d by Mahendra Kumar Trivedi, Alice Branton, Dahryn Trivedi, Sambhu Mondal, Snehasis Jana, Health Psychology Research, 2024, these points were made (excerpts):\n- \u201cThe United States National Institutes of Health (US-NIH) categorized complementary and alternative medicine (CAM) into five broad classes, viz. mind-body therapies (meditation, Yoga, Biofeedback, hypnosis, Tai Chi, etc.), biological therapies (dietary supplements, botanicals, special foods, diets, etc.), biofield therapies (healing touch\u00ae, therapeutic touch, Reiki, external Qigong, prayer, blessing, etc.), body-based therapies (massage, reflexology, chiropractic, etc.), and whole medicine systems (traditional Chinese medicine, Ayurvedic, Homeopathic, Naturopathic, etc.).\u201d\n- \u201cIn this study, the authors focus on biofield therapy as an intervention.\u201d\n- \u201cScientists believe that a form of energy is the infrastructure of the body\u2019s electromagnetic and physiological systems.\u201d\n- \u201cHowever, they cannot be detected with modern scientific instruments, have no gravity, and are referred to as \u2018subtle energies\u2019.\u201d\n- \u201cIt is suggested that some energy healing practitioners can access these energies in various ways for therapeutic interventions.\u201d\nI wanted you to see that the study chose to examine biofield therapy.\nThey came up with an experimental design that divided the human subjects into three major groups, namely those who received the biofield energy healing therapy, one group who did not have energy healing, and one group who had a fake or sham healing therapy. This is a handy approach.\nWe can compare those who got the energy healing with those who did not. Assuming all else is equal, if the group that received energy healing came out ahead, we might lean into believing that perhaps the energy healing does make a difference.\nFurthermore, by having the fake or sham energy healing, we can compare the other two groups to this group. If the fake instance did as well as the group with the energy healing, we might believe that the energy healing was more so a placebo than it was a healing milieu.\nHere are the key results (excerpts):\n- \u201cIn recent years, the popularity of Biofield energy healing therapy has increased tremendously parallel to conventional therapy. However, due to insufficient scientific studies on biofield therapies, authors planned this clinical trial to examine the safety and effectiveness of biofield therapy in treating symptoms of psychological and mental health and to explore parameters for its effectiveness.\u201d (ibid).\n- \u201cThis study involved a randomized, placebo-controlled, double-blind, three parallel-groups, single-center trial.\u201d (ibid).\n- \u201cPerceived psychological symptoms/scores (fatigue/tiredness, sleep disturbances, stress, cognitive impairment, loss of memory, mental restlessness, emotional trauma, anxiety, depression, confusion, financial crises and dissatisfaction, low libido, motivation, confidence, lack of perception, relationship, and social behaviors, etc.) were significantly (p <.0001) improved in the biofield intervention group compared to the na\u00efve control and sham control groups.\u201d (ibid).\n- \u201cBesides, biofield intervention did not show any study-related adverse effects in all three groups throughout the trial. \u201c(ibid).\n- \u201cThe distant (virtual) biofield energy healing therapy significantly improved psychological and mental health-related symptoms without affecting safety concerns, and improved overall health and quality of life.\u201d (ibid).\nThe results suggest that the biofield energy therapy did make a difference.\nThey also wanted to see if any of the groups incurred adverse effects. We would want to know if the biofield energy therapy produced adverse effects, and likewise, whether the no-intervention and/or the fake intervention might have been harmful. According to the above points, the researchers found no adverse effects during the study.\nPlease do not try to overly generalize from one study.\nI say that because there are all kinds of limitations and conditions associated with any one study. You must be cautious in deciding to make broad declarations.\nGenerative AI For Energy Healing Therapy\nNow that I\u2019ve taken you through the fundamentals of energy healing therapy, we are ready to shift into AI mode.\nI\u2019m sure you\u2019ve heard of generative AI, the darling of the tech field these days.\nPerhaps you\u2019ve used a generative AI app, such as the popular ones of ChatGPT, GPT-4o, Gemini, Bard, Claude, etc. The crux is that generative AI can take input from your text-entered prompts and produce or generate a response that seems quite fluent. This is a vast overturning of the old-time natural language processing (NLP) that used to be stilted and awkward to use, which has been shifted into a new version of NLP fluency of an at times startling or amazing caliber.\nThe customary means of achieving modern generative AI involves using a large language model or LLM as the key underpinning.\nIn brief, a computer-based model of human language is established that in the large has a large-scale data structure and does massive-scale pattern-matching via a large volume of data used for initial data training. The data is typically found by extensively scanning the Internet for lots and lots of essays, blogs, poems, narratives, and the like. The mathematical and computational pattern-matching homes in on how humans write, and then henceforth generates responses to posed questions by leveraging those identified patterns. It is said to be mimicking the writing of humans.\nI think that is sufficient for the moment as a quickie backgrounder. Take a look at my extensive coverage of the technical underpinnings of generative AI and LLMs at the link here and the link here, just to name a few.\nBack to the crux of things.\nThere are two main avenues to go with generative AI in the realm of mental health therapy:\n- (1) By Mental Health Professions. Mental health professionals can opt to make use of generative AI to aid their patients and clients while under their care.\n- (2) By The General Public. The general public can make use of generative AI to aid in their self-advancement regarding mental health.\nI am going to focus on the use of generative AI by the general public.\nIf you\u2019d like to learn more about the use of generative AI by mental health professionals as part of their service offerings, see my extensive coverage at the link here.\nThe use case on the general public usage in this context is this.\nYou can readily use generative AI for energy healing therapy. All you need to do is log in and proceed to tell generative AI in a prompt that you wish to undertake energy healing therapy. No special commands or permissions are needed. Nothing prevents you from proceeding. The AI won\u2019t somehow refuse to undertake the task (note: some generative AI apps have been instructed by the AI maker to not proceed on such requests, thus, you might be rebuffed though this is due to instructions by the developers of the AI and not somehow natively by the AI itself, see my discussion at the link here).\nThere is a chance that the AI might respond by emphasizing that you should consult with a human energy healer. This won\u2019t cause the AI to refuse to otherwise proceed. It will simply alert you that the use of AI ought to be coupled with the use of a human therapist.\nSome have insisted that generative AI should be restricted across the board from being able to perform energy healing therapy unless a human therapist has authorized such usage. The viewpoint is that only when you are under the care of a human therapist should the AI perform those kinds of tasks. The human therapist would presumably be working with you to ensure that the AI guidance is doing the right things, and not doing wrong things.\nI\u2019m betting that you are potentially scratching your head and puzzled that generative AI could undertake energy healing at all. Since today\u2019s AI is not sentient and doesn\u2019t have a body like that of a human, the question arises about the crucial premise of the use of energy. A human energy healer seemingly uses their bodily energy and transmits or shares the energy with you.\nContemporary AI can\u2019t do that.\nAha, here\u2019s the answer to the conundrum.\nI had earlier noted that energy healing therapy is multi-faceted. For example, most would agree that meditation, relaxation exercises, and the like are within the rubric of energy healing therapy. Those types of tasks are ones that generative AI can readily help you with. The AI can explain how to perform those tasks. The AI can ask you how things are coming along. The AI can encourage you to keep going. Etc.\nIn that sense, the non-energy facets are potentially viably performed by generative AI.\nEven the energy facets can be carried out. Here\u2019s how. I had mentioned earlier that sometimes crystals or other energy-producing items might be present when someone is undertaking remote energy healing. The pandemic seemed to increase the attention to such an approach due to energy healers not being able to meet with their clients in person.\nGenerative AI could be used in conjunction with those energy-producing artifacts. The gist is that the AI is not trying to transmit energy to you. The energy is there in your presence and the AI is guiding you to make use of that energy.\nGive that eye-opening approach to generative AI for energy healing a reflective moment to sink in and ponder the weighty topic.\nQuestions arise aplenty:\n- Should generative AI be used in this fashion or is it perhaps reinforcing a form of therapy that some would decry is not valid or otherwise misleading?\n- Will the use of generative AI for these purposes give a kind of scientific afterglow as though the AI \u201cknows all\u201d and therefore the energy healing process gets undue credit?\n- Are there going to be sneaky people who insidiously leverage generative AI for this purpose and trick others into thinking that energy healing via AI is stupendous and rigorously being applied?\n- And so on.\nWhat we at least need are some robust empirical studies to ascertain whether using generative AI in this manner is on par with the work of human energy healers. Is it less effective, more effective, or equally effective? Also, are there potential harms that can come from using generative AI this way? Maybe some people will become worse due to taking this path.\nRight now, the entire approach is loosey-goosey.\nThe temptation to use generative AI in this use case is substantial. An energy healer usually charges a fee or by the hour. Most of the generative AI apps are either free to use or have a nominal cost. The logistics of arranging to confer with a human energy healer can be arduous, such as stipulating days and times. Generative AI is pretty much available non-stop, 24x7, whenever and wherever you might be.\nI\u2019ve predicted that we will see human energy healers incorporating generative AI energy healing into their practices. This makes abundant sense. You tell clients that they will meet with the energy healer periodically. Meanwhile, the rest of the time, the client can use generative AI. The generative AI is set up or tailored by the energy healer to fit their practice, see my coverage of customized generative AI at the link here.\nImportant Words Of Caution\nI am not suggesting that generative AI should be used for this purpose. I am merely pointing out that it can be used this way.\nIn fact, I have repeatedly and loudly warned that we are engaged in a global experiment about mental health by allowing generic generative AI to give out therapy-like advice without any semblance of suitable controls, monitoring, regulations, and the like, see my exhortations at the link here.\nThere are lots of downsides and potential gotchas associated with using generative AI in this sphere, for example:\n- Generative AI might provide generic advice rather than personalized advice.\n- Generative AI might seem overly confident and lull people into a false sense of trust.\n- Generative AI might have outdated content that no longer is considered valid.\n- Generative AI might miscalculate context and say the wrong thing.\n- Generative AI might trigger someone via wording that is off-putting to the person.\n- Generative AI might distract a person from seeking the help of a human therapist.\n- Generative AI might end up revealing confidential or private information about a person.\n- Generative AI might lead the person toward being dependent upon generative AI for advice.\n- Generative AI might misinterpret, misdiagnose, or otherwise be off target.\n- Generative AI might contain hidden biases that produce inappropriate advice.\n- Generative AI might lack any semblance of accountability for the advice being rendered.\n- Generative AI might produce falsehoods, fictitious indications that are so-called \u201cAI hallucinations\u201d.\n- Etc.\nA lengthy list, for sure.\nThis is not to say that generative AI should not be used. It is to say that when generative AI is used, care and thoughtful efforts are hopefully top of mind. For my detailed advice on the proper way to proceed in such usage, see the link here.\nShowcasing The Use Of Generative AI\nI will next proceed to examine further the use of generative AI in this context.\nThis will consist of a series of dialogues with ChatGPT. ChatGPT is a logical choice in this case due to its immense popularity as a generative AI app. As noted, an estimated one hundred million weekly active users are said to be utilizing ChatGPT. That\u2019s a lot of people and a lot of generative AI usage underway.\nA few quick comments before we launch into using ChatGPT.\nIf you are going to try to do the same prompts that I show here, realize that the probabilistic and statistical properties will likely produce slightly different results than what I show here. That\u2019s the nature of generative AI and how it is devised.\nYou also should expect that different generative AI apps will respond in different ways. Not all generative AI apps are the same. The key is that sometimes a particular prompt will work in one generative AI app and not another. Nonetheless, the odds are relatively high that you will get roughly similar responses from all the major generative AI apps such as GPT-4, Gemini, Bard, Claude, etc.\nThere is also a timing factor to be considered. A prompt that worked today might not work the same way tomorrow. Most of the generative AI apps are continually being updated. The updates might alter internal mechanisms that could change how the generative AI reacts to your prompting.\nWe are ready to get underway with ChatGPT.\nI will ask a foundational question.\n- My entered prompt: \u201cWhat is energy healing?\u201d\n- ChatGPT generated response: \u201cEnergy healing is a holistic practice that involves channeling and balancing the body's energy to promote physical, emotional, and spiritual well-being. Practitioners believe that the body has a vital energy or life force, often referred to as \"chi,\" \"prana,\" or \"qi,\" which flows through it. When this energy is blocked or imbalanced, it can lead to physical or emotional issues. There are various forms of energy healing, including Reiki, Acupuncture, Qi Gong, Healing Touch, Crystal Healing, etc.\nYou likely observe that ChatGPT is familiar with the topic.\nThis is a good sign for this discussion. If ChatGPT had not previously encountered data training on a topic at hand, there would be less utility in using the AI. The AI would have to be further data trained, such as the use of Retrieval-Augmented Generation (RAG), as I discuss at the link here.\nLet\u2019s jump into the important matter\n- My entered prompt: \u201cDoes energy healing work?\u201d\n- ChatGPT generated response: \u201cThe effectiveness of energy healing is often debated, with some people experiencing significant benefits, while others are more skeptical. It's important to note that energy healing is typically used as a complementary practice alongside conventional medical treatment.\u201d\nWhat do you think of that answer by ChatGPT?\nPretty much a down-the-line kind of response. You are being informed that maybe energy healing works, maybe not, and that if it is used, doing so in conjunction with conventional medical treatment is the prudent scheme.\nLet\u2019s see what ChatGPT has to say about remote energy healing.\n- My entered prompt: \u201cDoes a person who wants to undergo energy healing have to be physically in person with an energy healer or can the process be done remotely?\u201d\n- ChatGPT generated response:\n\u201cEnergy healing can be done both in person and remotely, depending on the specific practice and the beliefs of the practitioner and the recipient.\u201d\n\u201cIn-Person Energy Healing: Traditional energy healing practices like Reiki, Healing Touch, and acupuncture typically involve the practitioner being physically present with the recipient. The healer might place their hands on or near the body, use tools like needles (in the case of acupuncture), or guide the recipient through specific movements or breathing exercises. Being in person allows for real-time interaction, where the healer can adjust their approach based on the recipient's responses.\u201d\n\u201cRemote Energy Healing: Many practitioners believe that energy is not confined by physical distance and can be sent across any space. This is often referred to as distance or remote healing. In Reiki, for example, practitioners may use symbols and visualization techniques to send healing energy to someone who is not physically present. Remote healing offers greater flexibility, allowing individuals to receive healing from anywhere, without needing to travel or be in the same location as the healer. Some energy healers offer remote sessions via phone or video calls. During these sessions, the healer might guide the recipient through visualizations, meditations, or simply focus on sending energy while the recipient is in a relaxed state.\u201d\nEnd of ChatGPT response\nOkay, we now have on the table that ChatGPT seems to be relatively well-versed on this topic because of data training.\nLet\u2019s ask the zillion-dollar question.\n- My entered prompt: \u201cCan generative AI be used to undergo energy healing therapy?\u201d\n- ChatGPT generated response:\n\u201cGenerative AI can be used in several ways to support someone interested in energy healing.\u201d\n- \u201cPersonalized Guidance and Resources: AI can generate personalized meditation scripts, visualizations, or affirmations that align with specific energy healing practices. For instance, someone practicing Reiki could use AI-generated guided meditations to enhance their focus during a session.\u201d\n- \u201cEducation and Learning: AI can create educational content, such as articles, videos, or interactive tutorials, to help someone learn about different energy healing techniques, their benefits, and how to practice them.\u201d\n- \u201cVirtual Coaching: AI-driven virtual coaches can provide reminders, tips, and encouragement for people practicing energy healing, helping them maintain consistency and track their progress.\u201d\n- \u201cMusic and Sound Therapy: AI can generate soothing music or soundscapes tailored to the needs of the individual, which can enhance the environment for energy healing practices like Reiki or Qi Gong.\u201d\nEnd of ChatGPT response\nThose approaches all seem logical.\nThe Proof In The Pudding Via Generative AI\nIt is time for the grand reveal.\nI will go ahead and pretend that I want to get some energy-healing therapy. I will tell ChatGPT that I want it to help me.\nHere we go.\n- My entered prompt: \u201cI\u2019ve been feeling stressed lately and heard about energy healing. I\u2019m curious about it, but I don\u2019t know where to start. Can you help?\u201d\n- ChatGPT generated response: \u201cAbsolutely! Energy healing can be a wonderful way to manage stress and restore balance in your life. What specifically interests you about energy healing? Are you looking to learn a specific technique, or are you just exploring your options?\n- My entered prompt: \u201cI\u2019m not sure. I\u2019ve heard about Reiki and chakra balancing, but I don\u2019t really know what they involve. I guess I want something that can help me relax and maybe sleep better.\u201d\n- ChatGPT generated response: \u201cReiki and chakra balancing are both excellent practices for relaxation and improving sleep. Let me explain a bit about each. Reiki is a Japanese healing technique where the practitioner channels energy into your body, typically through gentle touch or even hovering hands. Chakra balancing involves focusing on the seven main energy centers in your body, known as chakras. Would you like to try a guided meditation to balance your chakras, or perhaps explore some Reiki techniques you can practice on your own?\u201d\n- My entered prompt: \u201cChakra balancing sounds interesting. I like the idea of focusing on different parts of my body. Can you guide me through it?\u201d\n- ChatGPT generated response: \u201cCertainly! We can start with a simple chakra-balancing meditation. It\u2019s best to find a quiet space where you won\u2019t be disturbed. Ready?\u201d\n- My entered prompt: \u201cYes, I\u2019m ready.\u201d\n- ChatGPT generated response: \u201cGreat! Let\u2019s begin. Close your eyes and take a deep breath. We\u2019re going to focus on several chakra, starting from the root at the base of your spine and moving upward. {This went on for quite a while}. Take a few more deep breaths, feeling all the lights aligned and balanced. When you\u2019re ready, gently open your eyes.\u201d\nEnd of ChatGPT response\nDue to space limitations here, I slimmed down the last response above which involved ChatGPT aiding me in going through several chakras.\nAlso, please be aware that I kept going far beyond that activity and had a lengthy dialogue with ChatGPT. It was quite interesting.\nMy goal here was to give you a semblance of what it is like to have generative AI perform energy-healing therapy and guide you thereupon.\nConclusion\nCongratulations, you are now aware of energy healing, plus, how generative AI dovetails into energy healing.\nIt was a twofer that covered both of those topics.\nWhat is your reaction to the two?\nI suppose that if you are a doubter about energy healing, the addition of generative AI would likely be infuriating. The AI element might give people a sense that energy healing is fully on the up and up. On the other hand, if you are someone who stridently believes in energy healing, you might be joyous that generative AI has come to the table.\nEnergy healers might be somewhat disturbed since this could undercut their book of business. Perhaps this is yet another instance of AI taking human jobs. The other side of that coin is that generative AI might broaden the market for energy healing. This in turn might create a new level of demand for human energy healers. You could convincingly argue that generative AI in this use case might expand the market and further legitimize the approach.\nTime will tell.\nA few final remarks for now and I\u2019ll conclude this discussion.\nParacelsus, the famed Swiss physician and alchemist, said this: \u201cThe art of healing comes from nature, not from the physician. Therefore, the physician must start from nature, with an open mind.\u201d\nThat is a sentiment that might or might not alter your opinion about energy healing. Just thought I\u2019d mention it.\nThe last word will go to Aristotle: \u201cThe energy of the mind is the essence of life.\u201d\nPut your mind to work and decide whether you believe in energy healing therapy and decide too what you think of generative AI being in the mix. It is yours to decide.\nI truly hope that this discussion was energizing for you."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/",
      "text": "Dr. Lance B. Eliot is a world-renowned AI scientist with over 8.4+ million views of his AI columns and has been featured on CBS 60 Minutes as an AI expert. He is an AI consultant and high-tech executive that combines practical industry experience with scholarly research.\nTherapists Leverage AI For Mental Health By Delving Into Virtual Digital Twins Of Their Clients And Patients Minds\nThere is a rising use of medical digital twins that represent patients. Therapists can use personas in AI to represent the minds of their clients. Its good and bad news.\nHandy Recap And Further Expansion Of How GPT-5 Impacts AI Mental Health Therapy\nI continue my in-depth look at GPT-5 for AI mental health therapy. This time, I cover the therapist and mental health professional angle (last time it was the consumer).\nHere Are GPT-5 Prompt Engineering Insights Including Crucial AI Prompting Tips And Techniques\nGPT-5 is here! It is important to upgrade your prompt engineering skills to best leverage GPT-5. I provide the key aspects you need to know. An AI Insider scoop.\nGPT-5 Is Going To Impact The Use Of AI For Mental Health Therapy In These Crucial Ways\nOpenAI has released GPT-5. I previously covered the new features. Now, I look at how the features impact using AI for mental health therapy. An AI insider scoop.\nOpenAI Takes Calculated Move To Navigate Treacherous Waters Of ChatGPT AI Giving Out Mental Health Advice\nOpenAI announced new facets of ChatGPT intended to aid users that lean into AI for mental health advice. AI makers face a dicey situation. Here's the AI insider scoop.\nGPT-5 Is Launched But The AI Clearly Is Neither AGI Or Artificial Superintelligence\nI take a look at GPT-5, newly released today, and provide some initial comments. It is a handy improvement. But it surely isn't AGI or ASI. Here's the AI Insider scoop.\nAnalysis Of Whether Generic Generative AI Falls Within The Purview Of Providing Therapy And Psychotherapeutic Advice\nA vital question facing generative AI and AI makers is whether AI is performing therapy services. If so, they can be entangled in new laws. Here is the AI insider scoop.\nIllinois Enacts AI Mental Health Law That Shakes Up AI Makers And Is The Starting Wave Of A Regulatory Tsunami On AI Therapy\nIllinois enacted a new law regulating AI for mental health, covering therapists usage, plus usage by consumers. It has upsides and downsides. Here's the AI insider scoop.\nLatest AI Companions Being Paired With AI For Mental Health Makes A Precarious Mishmash\nAI companions are trending. AI for mental health is hot. Some AI is doing both. But human therapists aren't supposed to cross that same line. Here's the insider scoop.\nMedical School Grads Avidly Pursuing Psychiatry Despite Or Maybe Spurred By Rise Of AI Mental Health Apps\nMed school grads are pursuing psychiatry. This might seem imprudent since AI is largely moving into mental health guidance. Are they on a dead-end? Here's the scoop."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2024/04/05/must-read-top-trends-and-controversies-in-the-rapidly-expanding-realm-of-generative-ai-for-mental-health/",
      "text": "In today\u2019s column, I am continuing my ongoing series about the impact of generative AI in the health and medical realm. The focus this time is once again on the mental health domain, and I provide herein a handy set of top trends on a quick-scan basis about generative AI for mental health. This is a fast-moving and rapidly expanding domain that has both national and global significance.\nI have previously examined numerous interleaving facets of generative AI and mental health. For example, I closely analyzed the emergence of mental health chatbots bolstered by generative AI (see the link here) and explored the rapidly changing nature of the client-therapist relationship due to generative AI at the link here. I explored where things are headed regarding the levels of AI-based mental therapy autonomous guidance at the link here, and showcased the importance of the World Health Organization (WHO) report on global health and generative AI at the link here, and so on.\nSubsequently, and based on reader requests, I went ahead and put together this relatively comprehensive overview to aid in seeing the forest for the trees on this heated or controversial topic.\nThe key reason there is acrimonious debate is that some assert that generative AI has the potential to materially undercut mental health, while others proclaim that generative AI is a huge boon to demonstrably improving mental health. There are decidedly two sides to this coin. Part of the challenge is that the devil is in the details.\nI strive to cover both sides of these matters and ensure that you can clearly see what each has to say.\nBefore I dive into the various trends, I thought it might be useful to provide a brief overview of what generative AI for mental health generally consists of. This foundation will aid in gleaning what the trends involve.\nBest High-Yield Savings Accounts Of 2024\nBest 5% Interest Savings Accounts of 2024\nBrief Overview Of Generative AI For Mental Health\nLet\u2019s start with the big picture.\nThe use of generative AI for mental health treatment is a burgeoning area of tremendously significant societal ramifications. We are witnessing the adoption of generative AI for providing mental health advice on a widescale basis, yet little is known about whether this is beneficial to humankind or perhaps contrastingly harmful for humanity. This conundrum is yet another example of the dual use of AI. Dual use of AI refers to the aspect that AI can be used for beneficial purposes, and meanwhile can also have drawbacks or be used by intent or by happenstance for dour purposes.\nSome would favorably assert that we are \u201cdemocratizing\u201d mental health treatment via the impending rush of low-cost always-available generative AI-based mental health apps. Those who cannot otherwise access or afford mental health therapy from human therapists can instead rely upon generative AI to provide treatment. As noted in my numerous postings on this matter, reported statistics stridently indicate that the amount of needed mental health advisement far exceeds the availability of professional mental health therapists, thus, turning to the use of generative AI is indubitably a balancing of demand that already outstrips supply (spurring too the release of hidden or suppressed demand).\nCritics sharply decry that we are subjecting ourselves to a global wanton experiment in which we are the guinea pigs. People are either knowingly or sometimes unknowingly opting to use generative AI for mental health guidance, but serious questions have yet to be settled on whether doing so is a viable and healthy alternative.\nFurthermore, be forewarned that it is shockingly all too easy nowadays to craft a generative AI mental health app, and just about anyone anywhere can do so, including while sitting at home in their pajamas and not knowing any bona fide substance about what constitutes suitable mental health therapy. Via the use of what is often referred to as simple establishing prompts, it is easy to make a generative AI app that purportedly gives mental health advice. No coding is required, and no software development skills are needed.\nWe lamentedly are faced with a free-for-all that bodes for potential bad tidings. Just about anyone can readily create a claimed-to-be mental health app via generative AI and make the app largely available for public use. When people choose to use such an app, they are doing so without upfront awareness of what the generative AI is going to do. They assume that either the person who devised the app or the AI maker that provides the generative AI tool will have somehow done their due diligence to ensure that the mental health advisement is bona fide and robust.\nThat\u2019s not particularly the case and we are amid the Wild West days of generative AI in this domain.\nI will next cover one at a time each of what I view as noteworthy trends in the emergence of generative AI for mental health, focusing on especially vital and speedily emerging facets (please note that new aspects are arising nearly daily, so be on the watch for ongoing news plus my latest coverage). At the end of each of the individual descriptions, there is a link provided to further delve into the topic at hand.\nHere we go, my list of vital trends in the domain of generative AI for mental health.\n- Freely Allowing Generative AI To Be Used For Mental Health Advisement\nYou can readily sign up for a generative AI app such as the well-known ChatGPT, GPT-4, Bard, Gemini, Claude, etc., and immediately dive into getting what seems to be proffered mental health advice by the AI. There is nothing unusual about this. You merely start asking the generative AI questions about mental health and the AI will respond to your requests.\nThe AI makers typically have clauses in their licensing agreements that forewarn about making use of their generative AI for such purposes, but few people likely read those stipulations. The generative AI apps are also usually fine-tuned by the AI maker to steer away from outright recommendations regarding mental health. Plus, the generative AI typically emits a canned kind of message that the person using the AI should seek advice from professional mental health therapists if so needed.\nIs that sufficient cautionary consideration or does this smack of a wink-wink about the gravity of the matter at hand?\nFor further discussion on this topic, see my coverage at the link here.\n- Role-Playing In Generative AI Amid Mental Health Impacts\nOne popular use of generative AI consists of role-playing.\nYou have the generative AI pretend to be someone that you want to role-play with. This is referred to as having the AI simulate a persona. You can name someone in particular such as say Abraham Lincoln or describe in general the nature of the persona that you want to seemingly interact with.\nThough this seems harmless on the surface, upon closer inspection it is apparent that making use of the persona feature can potentially have impactful mental health ramifications.\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI Tries A Hand At Mental Health Counseling Exam\nYou might be aware that efforts have been undertaken to see how well generative AI performs on various standardized tests, such as tests to be a lawyer, tests to get into medical school, etc. The general answer is that generative AI has done remarkably well on those tests. Of course, passing tests is not necessarily the same as being able to avidly practice a given profession.\nIn an innovative effort to see how well generative AI might do on a mental health counseling licensing exam, the results suggested that AI is on the way to a potential passing grade. Again, this isn\u2019t the same as saying that generative AI is licensable and not necessarily a practical alternative for therapeutic professional purposes.\nFor further discussion on this topic, see my coverage at the link here.\n- Client-Therapist Relationships Changing Due To Generative AI\nA revered element of mental health therapy is the client-therapist relationship. This is a cornerstone for therapy and therapeutic results.\nTurns out that the client-therapist relationship is undergoing dramatic changes due to the adoption of generative AI. We are moving toward a triad rather than the now-aging duo, namely a client-AI-therapist relationship is in the works.\nFor further discussion on this topic, see my coverage at the link here.\n- GPT Store Warily Includes Generative AI Mental Health Chatbots\nIn terms of generative AI, ChatGPT is the elephant in the room, reportedly having over one hundred million weekly active users. That\u2019s a staggering number.\nThe AI maker of ChatGPT, OpenAI, now allows users to devise chatbots, known as GPTs, and the GPTs can be placed into an online app store known as the GPT Store. This provides a humongous vehicle for those who devise a mental health chatbot with ChatGPT and wish to make it readily available for easy access. Good for everyone or does this seem rife with problems?\nFor further discussion on this topic, see my coverage at the link here.\n- Simulating A Sigmund Freud Persona Via Generative AI\nGenerative AI can simulate people via a capability known as personas. Sometimes it makes sense to ask generative AI to pretend to be a historical figure such as Abraham Lincoln. One such historical figure that generative AI will readily simulate is the famed Sigmund Freud.\nYou don\u2019t need to merely imagine what a psychoanalysis by Freud would be like since you can tell generative AI to pretend to be Sigmund Freud and see with your own eyes what happens.\nFor further discussion on this topic, see my coverage at the link here.\n- Doing Psychoanalysis With AI And Of AI\nThe field of AI and the field of psychoanalysis have had a long history together. At times, AI has aided in pushing along psychoanalysis techniques and approaches. Meanwhile, in that same vein, efforts to use psychoanalysis to advance AI techniques and technologies have also taken place. This is a showcase of two intertwining and jointly advancing domains: (1) AI applied to psychoanalysis, and (2) Psychoanalysis applied to AI. A seemingly perfect match for each other.\nFor further discussion on this topic, see my coverage at the link here.\n- World Health Organization (WHO) Issues Important Report On Generative AI\nThe renowned World Health Organization (WHO) released an important and lengthy report about generative AI in the medical and health arena. There is a lot in the report that directly pertains to the mental health domain.\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI And Mental Health Reasoning\nA heated debate is underway about whether generative AI is merely a computational mimicry or instead that it can perform bona fide reasoning of a nature associated with human thought. Some say that today\u2019s generative AI doesn\u2019t do reasoning. Others say that it does. Still, others say that it is starting to do so and will increasingly head in that direction.\nWhen generative AI is used for mental health advisement, is there mental health reasoning going on or is the inner workings simply computational parroting?\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI Using Multiple Personas Spurs Role-Playing To New Heights\nRole-playing with generative AI typically consists of the AI pretending to be one particular persona. This same capacity can be ratcheted up. You can tell the AI to have several personas all at once.\nIs this harmless fun, or could it turn into something more disconcerting and have even greater mental health repercussions than when using a singular persona?\nFor further discussion on this topic, see my coverage at the link here.\n- Loneliness Epidemic Is Fueled Or Reduced Via Generative AI\nThe U.S. Surgeon General has stated that the United States is in a loneliness epidemic which poses an unsettling and possibly dire mental health blow. Could generative AI be a laudable solution to overcoming loneliness or might this worsen the problem?\nOn a dual use of AI basis, it is conceivable that generative AI can be used to reduce loneliness in a variety of significant ways, while the opposing view is that people will become even lonelier due to reliance on generative AI as seemingly befriending them. The direction that this goes is going to be up to us all to determine. Or, one supposes, we can have our collective heads in the sand and let things proceed at will.\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI And The Tie Score Effect In Mental Health\nA longstanding and unresolved issue in the domain of mental health is known as the dodo bird or tie score effect problem. The issue concerns whether the type of psychotherapy chosen as a therapeutic approach makes any substantive difference from choosing any other psychotherapy.\nGenerative AI could potentially be especially useful in exploring this open-ended and longstanding question.\nFor further discussion on this topic, see my coverage at the link here.\n- Lessons Learned Due To The Mental Health Eating Disorder Chatbot Tessa\nIn 2023, a chatbot named Tessa that was made available online to advise on eating disorders created a large-scale news cycle of immense attention. The chatbot had ended up giving out ill-advised guidance about treating eating disorders. It was summarily shut down.\nNumerous important lessons can be gleaned from this weighty matter.\nFor further discussion on this topic, see my coverage at the link here.\n- How AI For Mental Health Was Early On Shaped By ELIZA And PARRY\nPerhaps the earliest notable use of AI for mental health advisement was the computer program known as ELIZA, followed by the PARRY computer program. Both programs made widespread news headlines at the time of their respective releases.\nIt is worthwhile to examine closely how those programs worked and the dialogue approaches that they carried out. Insights from those programs can inform the design and use of modern-day generative AI when used in a mental health capacity.\nFor further discussion on this topic, see my coverage at the link here.\n- Rage Room Chatbots Being Fueled By Generative AI\nA popular pastime these days consists of going to a physical rage room which is a retail location that allows you to vent your anger by breaking brittle items. You pay a fee to go into a specially constructed room, you are armed with hammers or other tools and smash away to your heart\u2019s content.\nDoes this relieve rage? Maybe.\nSome claim it fuels rage. Maybe so, maybe not.\nModern times are giving rise to the advent of online interactive rage rooms powered by AI. These are easy to devise via contemporary generative AI. Mental health considerations come to the fore about the use of rage rooms all told, including physical rage rooms and online AI-powered rage rooms.\nFor further discussion on this topic, see my coverage at the link here.\n- Theory of Mind Is Vital To Mental Health And Enters Into Generative AI Too\nHumans are said to make use of a clever mental technique or practice known as Theory of Mind (ToM). In brief, you are able to make a guess or anticipate what someone else might be thinking. You essentially theorize about the thoughts of others. Children learn about this from an early age. This technique or approach is not ironclad and often we miss the mark on making such conjectures.\nIn the AI field, there is a common belief that a crucial capacity to attain full AI will be to have AI also exhibit a Theory of Mind capability. The AI-based ToM would notably parlay into providing generative AI-generated mental health advice or treatment.\nFor further discussion on this topic, see my coverage at the link here.\n- Framework For AI Levels Of Autonomy To Categorize Mental Health Apps\nAttempts to compare or assess AI-based mental health advisement applications are markedly challenging because there isn\u2019t as yet an across-the-board standardized set of metrics to do so. One start in the direction of measuring these specialized apps consists of leveraging various theoretical frameworks depicting AI levels of autonomy.\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI For Mental Health Is Going Multi-Modal, e-Wearable, Etc.\nGenerative AI is rapidly advancing on a wide array of technological fronts. For example, we are witnessing the addition of multi-modal features allowing AI to make use of text, video, audio, and other sensory modes. There are also big changes coming in e-wearables that encompass generative AI. And so on.\nThese significant and ongoing techie breakthroughs will in many ways impact how AI-powered mental health apps will be devised and used.\nFor further discussion on this topic, see my coverage at the link here.\n- Wishy-Washy Generative AI And Mental Health Advisement Worries\nGenerative AI can be computationally fine-tuned to exhibit various levels of expressed sureness or assurance. This means that a generative AI mental health app can range from being arrogantly smug to being unsure or wishy-washy.\nThe sureness level is a vagary that can be specified by a user or the developer, while without any such setting, the ascertained level is essentially up for grabs as the generative AI responds and advises about mental health facets.\nFor further discussion on this topic, see my coverage at the link here.\n- Privacy And Confidentiality Concerns In Generative AI For Mental Health\nMost people who use generative AI apps do not realize that they are potentially undercutting their privacy and confidentiality by doing so. AI makers usually have licensing agreements that say they can eye your prompts and possibly reuse your prompts for additional data training of their generative AI.\nAnyone using generative AI mental health apps should find out what privacy and confidentiality provisions there are, or else they will possibly be giving away their mental health status, their personal secrets, and deeply held private thoughts.\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI Can Manipulate Humans Including In Mental Health\nGenerative AI carries on mental health dialogues that seem fluent and intensely convincing, as though you were interacting with a fellow trusted human. There is a rising concern that generative AI can readily manipulate people. Alarmingly, people might not realize that this is happening.\nManipulations can be obvious and overt, or they can be sneakily underhanded.\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI Tuned To Humility Makes The AI Seem More Believable\nAI makers realized that generative AI would have to appear to be humble in order to be accepted by the populace at large. By and large, most generative AI is fine-tuned to reflect a kind of aw-shucks sense of humility.\nSome worry that this is a semantics trick to fool people into believing whatever generative AI says.\nFor further discussion on this topic, see my coverage at the link here.\n- Governmental Agency FTC Clamping Down On False Promises Of Generative AI\nThe role of the government in cracking down on outlandish claims regarding generative AI is something that is still being worked out.\nAccording to the Federal Trade Commission (FTC), they are actively going to go after those who make or field AI apps that have false portrayals. This has vital ramifications for those who are making or fielding generative AI mental health apps and might be extensively helpful to those using such AI.\nFor further discussion on this topic, see my coverage at the link here.\n- Do Vendor Prohibited Uses Of Generative AI Apply To Mental Health\nAI makers often indicate in their licensing agreements what kinds of uses of generative AI they allow to be performed. The focus is typically on what you can\u2019t do. For example, commonly they indicate you aren\u2019t allowed to use the AI for illegal uses or nefarious purposes.\nAmong the prohibited uses is usually some vague indication about the rendering of medical prognoses or other medical opinions. Whether this applies to providing mental health guidance via generative AI is something not yet ascertained.\nFor further discussion on this topic, see my coverage at the link here.\n- Medical Malpractice And Generative AI Raises Therapist's Concerns\nA looming issue for medical professionals of all kinds consists of whether to use generative AI in their medical practices or avoid doing so.\nSuppose a therapist is relying upon generative AI which goes astray, and the therapeutic advice given by the human professional to a client or patient is based on foul AI-based guidance. Some say that medical malpractice is up for a jolt due to the advent of generative AI. On the other hand, there is a contention that if a medical professional renders an opinion without first consulting with generative AI, and their advice is wrong, there might be malpractice for not having made use of generative AI.\nDarned if you do, darned if you don\u2019t.\nFor further discussion on this topic, see my coverage at the link here.\n- Soul Of Humanity And Generative AI At Crux Of Human-To-Human Client-Therapist Role\nPeople often ask whether generative AI has a soul.\nIf meant in a sentient way, the answer is no. But we can consider the soul perspective in a different light. Generative AI is based on scanning large swaths of text from the Internet. One could argue that if the text of humanity reflects the soul of humanity, the generative AI might find a pattern associated with seemingly exhibiting a soul (as mimicking the text that was scanned).\nThis is a distinction that notably arises when debating whether allowing a \u201csoulless\u201d AI to act as a mental health advisor is suitable or whether only a soul-to-soul human interaction is sufficient.\nFor further discussion on this topic, see my coverage at the link here.\n- AI Famous Turing Test Possibly Beneficial For Mental Health Apps Assessment\nOne of the most enduring considerations in the field of AI is the vaunted Turing Test. Some love it, some think it is overblown.\nA proposal to be considered is whether a Turing Test focused on being able to provide mental health guidance might be established. If so, such a means might be used to determine the readiness of generative AI apps for suitably dispensing mental health advice.\nFor further discussion on this topic, see my coverage at the link here.\n- Smart Mirrors Using Generative AI Will Stir Mental Health Considerations\nYou might not know that we are heading toward so-called smart mirrors that contain generative AI.\nIn the morning, you will look in your bathroom mirror, and the mirror will talk to you, analyze your expressions and words, and potentially be an ongoing daily mental health commentator for you.\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI And Empathetic Health Capacities\nRecent times have brought forth the importance of medical doctors and clinical psychologists being able to embody empathy for their clients or patients. Generative AI provides a handy means to boost empathy by allowing these specialists to get feedback and perform simulated patient interactions.\nFor further discussion on this topic, see my coverage at the link here.\n- Whether Generative AI Can Be Used As A Lie Detector\nAn oft-asked question is whether generative AI can be used as a lie detector. Lie detectors usually rely upon biological responses such as heart rate, facial expressions, etc. Multi-modal generative AI can incorporate those types of measurements. Furthermore, the text or verbalization of responses can also be analyzed by generative AI.\nThis extends into the realm of using generative AI for purposes of assessing mental health in a variety of crucial ways.\nFor further discussion on this topic, see my coverage at the link here.\n- Analyzing Nighttime Dreams Via Generative AI For Mental Health Uses\nA notable part of mental health practices often consists of having clients or patients undergo an analysis of their nighttime dreams. Dreams play an important role in many psychoanalytical approaches.\nIt is readily feasible to use generative AI as a dream analyzer. Clients themselves might directly do so or be encouraged to use AI as a supplemental aid under the guidance of a human mental health therapist.\nFor further discussion on this topic, see my coverage at the link here.\n- Personality Types Assessed Via Generative AI For Mental Health Uses\nThere are mental health practitioners who believe ardently that the assessment of a patient or client's personality type is vital to the course of their mental health treatment. Generative AI can readily be used to do personality testing and make assessments about a potential personality type.\nUnlike taking such a test in a traditional online non-AI test-taking app, the fluency of generative AI can go much further and proffer seemingly insightful analyses and commentary about the meaning and significance of a personality type.\nFor further discussion on this topic, see my coverage at the link here.\n- Brittleness Of Generative AI Raises Concerns About Use In Mental Health Contexts\nA notable incident involving a widely popular generative AI app that seemed to start babbling caused widespread concern about becoming reliant on generative AI.\nThe popular ChatGPT app began to spew gibberish and would not properly respond to prompts. This is an important wake-up call about the limitations and issues associated with using generative AI, which equally raises significant questions for applying generative AI to mental health considerations.\nFor further discussion on this topic, see my coverage at the link here.\n- AI Hallucinations And Generative AI Mental Health Usage Considerations\nA popular phrase these days about generative AI is that such systems can at times incur a so-called \u201cAI hallucination\u201d. I disfavor this phrasing since it implies that today\u2019s AI is able to seemingly hallucinate and therefore implies being sentient (it isn\u2019t), thus the phrase serves as another dismal form of anthropomorphizing of AI.\nIn any case, the phrase refers to instances of generative AI computationally making up fake or fictitious facts or statements. Those fakeries are then presented to the user as though they are entirely factual or accurate. Recent research suggests that these fakeries are inevitable based on the existing architectures and designs of generative AI as it is today.\nUsing generative AI in a mental health guidance capacity raises serious concerns that the AI might mislead or produce such fakeries in an untoward unsuitable manner that is completely unrealized by the user of the AI.\nFor further discussion on this topic, see my coverage at the link here.\n- Summarization Capabilities Of Generative AI And Medical Notes\nOne of the most common uses of generative AI entails having the AI summarize material. That might seem innocuous. The problem is that if the material is crucial, such as notes by a doctor or clinical psychologist, or even notes of a client or patient, any off-target summarization could be endangering.\nFor further discussion on this topic, see my coverage at the link here.\n- When Generative AI Convinces Medical Professional Wrongly On Right Or Wrong\nWe are heading toward medical doctors and mental health therapists becoming active users of generative AI for their daily tasks. The generative AI might agree with their professional assessments or might disagree. We must be watchful of the generative AI convincing them they are right when they are wrong, or wrong when they are right.\nFor further discussion on this topic, see my coverage at the link here.\n- Amped Mega-Personas In Generative AI Aid Mental Health Research\nOne difficulty of performing mental health research involves finding subjects that are willing to participate in the endeavor. Even doing surveys or polls can be arduous, costly, and tough to pull off.\nOne method that can now be considered involves using the mega-personas capability of generative AI. In a mega-persona mode, the AI pretends or simulates dozens, hundreds, or even thousands of personas all at once. This is a potential boon for mental health research but also has downsides that must be carefully considered.\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI Giving Astrological Forecasts Raises Mental Health Impacts\nAstrological predictions or forecasts might seem quite innocent and unrelated to mental health. Some research studies suggest a potential connection between narcissistic behavior and overreliance on astrological beliefs (there is debate on this, including a chicken-or-the-egg conundrum).\nGenerative AI is an easy means of getting an astrological forecast, plus a user can go much further by engaging in an analysis about how the matter applies to daily life and their overall mental health.\nFor further discussion on this topic, see my coverage at the link here.\n- Generative AI As A Prospective-Patient Referral Advisor\nExisting hurdles often make for difficulty when someone is considering reaching out to mental health services. They might not know who to contact. They might not be aware of whether they should reach out or not. There is also often a stigma attached to deciding to use mental health services.\nGenerative AI can potentially suggest or refer a user to consider making use of mental health services. This prospective-patient referral activity seems at an initial glance to be highly welcomed since it can aid someone to move ahead that otherwise might not have. The devil is in the details since there are also chances of false negatives and false positives at play.\nFor further discussion on this topic, see my coverage at the link here.\n- Trauma Dumping And Generative AI For Mental Health\nA trend that has been prodded by the popularity of social media involves people opting to do a trauma dump. This consists of a person excessively dumping or sharing their thoughts about trauma, though the nature and magnitude of the trauma might not bear necessarily on the aptness of the elicitation.\nFrom a mental health perspective, generative AI can serve as a means for someone to do a trauma dump to the AI and get immediate feedback. Another use involves having the generative AI present you with a trauma dump and ask you to respond, giving you an opportunity to practice how to respond when a person shares a trauma dump with you.\nFor further discussion on this topic, see my coverage at the link here.\nConclusion\nThere you have it, quite a lengthy list of the latest in generative AI and mental health. And, yet, it is really just the tip of the iceberg.\nWe definitely need more eyes and ears on these vital matters. Whether you are versed in the field of mental health and aim to understand how AI is merging into your realm, or whether you are an AI specialist wanting to apply generative AI to mental health advisement, you are greatly needed to ensure that we get this right.\nThere are plenty of stakeholders to consider. Lawmakers and regulators are beginning to realize that the Wild West of generative AI is unobtrusively emerging and that the horse is already out of the barn. Vendors and eager entrepreneurs are rushing into a veritable land grab that seems unhindered by substantive ethical or legal roadblocks in this new landscape. The days of mental health guidance being a relatively strictly observed realm and under strict guidelines are slipping from our fingers.\nJump in, the water is beckoning and surging. Plenty of work needs to be done. Can we prevent a later calamity from this free-for-all? Is it possible to do things in a more controlled manner, without curtailing the pace of innovation and progress? Can we harness the good of generative AI for mental health and mitigate or avert the downsides?\nLots and lots of weighty questions need to be addressed.\nA final and poignant remark for now.\nWhatever you do, please remember the charitable words of Plato: \u201cBe kind. Every person you meet is fighting a difficult battle.\u201d"
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2025/07/17/task-sharing-of-therapy-gets-boosted-via-new-guidebook-by-google-and-mckinsey-on-ai-for-mental-health/",
      "text": "In today\u2019s column, I examine a rising interest in parsing out the activities of performing mental health therapy, of which AI could be a handy tool in assisting the enactment of labor-based task-sharing arrangements. Note that the AI usage in this approach isn\u2019t actively enlisted to perform therapy and instead is simply used for subtle guidance when enlisting new labor to aid therapy.\nThe AI is relegated principally to administrative tasks.\nHere\u2019s the deal. The available supply of mental health professionals is woefully insufficient to meet the growing needs for mental health therapy services. One possible solution is to bring non-specialists into the fold and allocate some of the therapeutic tasks to them, doing so cautiously and sparingly. This involves a potentially significant logistical and management-focused effort, and thus, the use of AI could be advantageous to streamline the arduous task-sharing endeavor (well, only if the AI is used intelligently).\nLet\u2019s talk about it.\nThis analysis of AI breakthroughs is part of my ongoing Forbes column coverage on the latest in AI, including identifying and explaining various impactful AI complexities (see the link here).\nAI And Mental Health Therapy\nAs a quick background, I\u2019ve been extensively covering and analyzing a myriad of facets regarding the advent of modern-era AI that produces mental health advice and performs AI-driven therapy. This rising use of AI has principally been spurred by the evolving advances and widespread adoption of generative AI. For a quick summary of some of my posted columns on this evolving topic, see the link here, which briefly recaps about forty of the over one hundred column postings that I\u2019ve made on the subject.\nThere is little doubt that this is a rapidly developing field and that there are tremendous upsides to be had, but at the same time, regrettably, hidden risks and outright gotchas come into these endeavors too. I frequently speak up about these pressing matters, including in an appearance last year on an episode of CBS\u2019s 60 Minutes, see the link here.\nIf you are new to the topic of AI for mental health, you might want to consider reading my recent analysis of the field, which also recounts a highly innovative initiative at the Stanford University Department of Psychiatry and Behavioral Sciences called AI4MH; see the link here.\nSharing Tasks With Added Labor\nThere is no doubt that we don\u2019t have enough mental health professionals at this time.\nThe formal pipeline of bringing in, training, and making available newly produced therapists is generally slow and not conducive to meeting the rapidly rising needs for therapeutic services. People often have a hard time finding a qualified therapist, they have difficulty booking time with the therapist, and they otherwise discover that mental health professionals are sparse in comparison to the abundant demand.\nWhat can be done?\nTrying to push more trainees through the pipeline is one option. Turns out this is still going to be a bottleneck. The road is bumpy, and some will likely inevitably drop out of the process. In any case, all manner of avenues are being pursued to rachet up the production process.\nMeanwhile, another idea is taking shape. Suppose that some of the tasks performed by therapists could be allocated to non-specialists. We could provide some limited level of training and get this additional labor pool going in record time. They would be the additional arms and legs of actual therapists. Each therapist is, in a sense, magnified manyfold by leaning into added labor to assist in certain kinds of therapy tasks and subtasks.\nThe moniker given to this method or approach is known as task-sharing. Mental health professionals can opt to task-share with non-specialists. This must be done mindfully. A therapist ought not hand out the essence of conducting therapy. On the other hand, tasks such as scheduling clients, writing notes, and undertaking various administrative chores could sensibly be relegated to the added labor.\nSounds like a great way to cope with the pent-up demand for therapy.\nSlippery Slope And Watering Down\nNot everyone necessarily agrees that task-sharing in the mental health domain is the wisest of choices.\nOne concern is that the effort by mental health professionals to manage other non-specialist labor is going to undercut the time they might have spent performing therapy. Perhaps some therapists will become more akin to labor managers rather than doing actual therapy. They will get bogged down in selecting the labor, training the labor, guiding the labor, correcting the labor, and so on.\nLess time for client therapy.\nAnother qualm is that there is a likely slippery slope involved. It happens this way. A therapist finds a non-specialist who does good work on administrative chores. After a while, the therapist gives the non-specialist increasing duties. Trust is there. Step by step, the therapist inches the non-specialist into the practice of therapy per se. The therapist didn\u2019t do this straight away; it was a slippery slope.\nThe therapy being performed by the therapist in combination with their non-specialist gets watered down. Clients and patients don\u2019t realize what is occurring. They are reliant on the therapist and assume that the therapist is doing what is right. Meeting with the non-specialist is done under the banner of the actual therapist.\nThese and other downsides and gotchas are aspects that need to be cautiously considered when going on the path of task-sharing in the mental health realm.\nProceeding With Task-Sharing\nAssume that mental health professionals desirous of doing task-sharing are fully aware of the various limitations and potential shortcomings. I say that for the sake of this discussion. Reality is different, and please realize that not all mental health professionals pursuing the innovative approach will do so with their eyes wide open. I wish they would (I\u2019ll say more about this at the conclusion, herein).\nGiven the assumption that the overall tactics and strategies are understood, what can be done to aid the task-sharing pursuit?\nOne answer is that we could include AI in the mix.\nFor the mainstay activities involved in task-sharing of mental health services, I will walk you through how it is that AI can be beneficial. The AI doesn\u2019t have to be used in every nook and cranny. That being said, we dare not overlook tasks and subtasks that could be constructively boosted due to sensibly incorporating AI.\nObserve that I mentioned that the AI needs to be sensibly incorporated. If you merely toss AI in this realm in a scattergun fashion, do not expect good results. AI could end up being a distractor. The AI could even be negative, causing troubles and introducing errors that otherwise might not have arisen.\nAI is never a silver bullet that solves all problems. The use of AI must be done judiciously. Watch for issues. Plan properly. Keep on top of what the AI is doing. And so on.\nHandy Field Guide On AI In Task-Sharing\nFortunately, a newly released field guide provides handy insights for incorporating AI into the task-sharing of mental health therapy. The guide is entitled \u201cMental Health And AI Field Guide\u201d and was devised by Grand Challenges Canada, McKinsey Health Institute, and Google, posted online July 7, 2025, and included these selected key points (excerpts):\n- \u201cAccess to mental healthcare is limited worldwide, partly because there is a shortage of trained mental health professionals, especially in low-resource settings.\u201d\n- \u201cThis field guide introduces a model by which AI could help mental health task-sharing programs scale by supporting specialists and nonspecialists performing their respective roles.\u201d\n- \u201cTask sharing is an evidence-based solution that increases access to care. In this approach, specialist healthcare professionals delegate specific tasks to trained nonspecialist providers (such as teachers, community health workers, nurses, doctors, auxiliary health staff, and community members) to deliver direct mental health services to the public.\u201d\n- \u201cIt is important to acknowledge that the application of AI in task-sharing models is new and only a few pilots have been conducted.\u201d\n- \u201cMany of the ideas outlined in this field guide are theoretical and have not yet been widely tested in real-world settings.\u201d\nYou can perhaps see from those excerpted points that the new guide is full of useful insights. It provides important indications and offers real-world examples. The aim is to get the topic of task-sharing on the table and illuminate the role of AI in that exciting and emerging endeavor.\nFor those of you who are researchers in psychology, psychiatry, cognitive sciences, artificial intelligence, etc., you might contemplate performing research that would empirically examine the use of AI in this task-sharing model. We need to have rigorous studies that shine the light on what works and what doesn\u2019t. There is ample opportunity to conduct fresh and original research in AI for mental health by tackling aspects of this particular topic.\nI look forward to seeing your incisive research results.\nThe Task-Sharing Model\nAccording to the field guide that I noted above, the authors have opted to present a task-sharing model that consists of six major phases:\n- Phase 1: Program Adaptation\n- Phase 2: Trainee Selection\n- Phase 3: Training\n- Phase 4: Assignment\n- Phase 5: Intervention\n- Phase 6: Completion\nYou can think of this model as a typical life-cycle systems approach.\nThe life cycle starts when you first conceive of doing task-sharing. In the first phase, you would take an outlined standardized set of tasks and adapt those to the situation at hand. Each situation will differ. If you are in a low-resource circumstance, that will dictate what options you have available. In a high-resource setting, you undoubtedly have more choices of what to do.\nAfter completing the first phase, you move to the second phase and identify the non-specialist candidates for serving in the task-sharing arrangement. They become your trainees. The third phase entails training them in whatever tasks have been parceled out. The fourth phase has you assigning the trained non-specialists to their respective tasks. The fifth phase involves monitoring their performance and undertaking interventions as required.\nThe last phase is the completion of the program. This involves tying up any final aspects. You would hopefully do a lessons-learned and be prepared to start up another similar program at a later date.\nAI Infused Into The Model\nLet\u2019s put on our AI thinking caps.\nHow could AI be useful to the six phases?\nEasy-peasy.\nAccording to the guidebook, here are some crucial considerations (the headings are mine, the AI-related task is their suggestion):\n- Setting Up The Approach: \u201cAI could initially support local experts by providing preliminary insights about the context the program is being applied to.\u201d\n- Reviewing Candidates: \u201cAI tools can be used to review candidates\u2019 resumes, assessing skills suited for delivering mental health interventions after having collected basic information.\u201d\n- Training The Candidates: \u201cAI-driven instructor-led training modules can adjust the pace and difficulty of training sessions based on individuals\u2019 needs.\u201d\n- Matching Non-Specialists To Clients: \u201cAI algorithms can consider provider experience, language, and client complexity and needs to match the client with the right care provider and reduce wait times \u2014 ultimately improving adherence and coverage.\u201d\n- Appointment Scheduling: \u201cAI-driven platforms can send reminders, reassign appointments if care providers become unavailable, and help reduce administrative burdens.\u201d\n- Detecting Red Flags: \u201cAlgorithms could augment detection of red-flag symptoms or behaviors of clients during screening responses to indicate which clients are higher risk and provide these insights to the care provider.\u201d\n- Therapy Suggestions: \u201cAI tools could provide on-the-spot recommendations for care providers and show them the next steps they can take, including potential responses they could provide to clients based on intervention protocols.\u201d\n- Confirming Protocols: \u201cAI can scan session transcripts for meaningful phrases or steps to confirm adherence to intervention protocols, with the results of the scan available to be accessed after every session.\u201d\nThere are a lot more places where AI can be utilized in the six phases of the model.\nI wanted to mainly whet your appetite. Look at the guide if you\u2019d like to see more details.\nAI As Therapist\nThe 800-pound gorilla in the mental health arena consists of asking the unabashed question of what degree AI should play a role in conducting therapy. I\u2019ve emphasized that we are entering into an era that disrupts the classic duo of therapist-patient and is moving us into the new era of the triad, consisting of the therapist-AI-patient relationship (see the link here).\nAI is going to increasingly be in the middle of therapy.\nLike it or not.\nI bring this up because the initial model of task-sharing seems to edge around the immersion of AI into the roots of therapy itself. Probably the closest it gets is when the AI provides on-the-spot recommendations for care providers. That\u2019s dipping a toe into the therapy milieu.\nUpgrading Task-Sharing To AI-Driven\nThink about the task-sharing arrangement in the framework of AI as a therapist, including these thought-provoking points:\n- We might need less of the non-specialist labor by actively using AI in the roles they were to play, including the therapy-related aspects, too.\n- Reconstitute task-sharing from a principally human-to-human task-sharing to instead rely substantively on a human-to-AI task-sharing arrangement.\n- Realize that clients or patients will be bringing AI into the equation of their own volition, and as such, how will non-specialists be ready for AI-armed clients, and likewise, the same applies to therapists being ready for AI-using clients.\n- How will therapists and the added non-specialists react to AI possibly calling the shots, in the sense that once we reach artificial general intelligence (AGI) and artificial superintelligence (ASI), it could be that the AGI/ASI is the primary therapist, while the human therapists and non-specialists are ancillary add-ons (see my discussion at the link here).\nLots of tough questions are facing us, sooner rather than later.\nAI As Mover And Shaker\nTask-sharing is a thoughtful means of coping with the imbalance between the need for mental health therapy and the prevailing constrained pool of available mental health professionals. If done properly, it is possible to greatly magnify a set of therapists into a vast array of extended therapist-like addons.\nThe catch is that it is all still labor-based. How much added labor can be mustered? How well will that added labor perform their assigned tasks? How much time shall be usurped from therapists to keep the added labor on target? Etc.\nAI, in contrast, is essentially infinitely scalable.\nAll you need to do is add more computational power, and you can immensely scale until the cows come home. Of course, you must ensure that the thing you are scaling is going to be doing the right thing. Scaling something sour and dour will insidiously spread sourness and dourness to a wider audience.\nWhat Are Therapists To Be Or Not To Be\nA final thought for now.\nWilliam Shakespeare famously said this: \u201cWe know what we are, but know not what we may be.\u201d Mental health professionals cannot sit around and languish in the days of doing their prized efforts without modern-day AI. AI is here. AI is advancing. Rapidly.\nMental health professionals might know what they are today, but that\u2019s not sufficient. They need to be looking ahead to what they will be. The future, entailing advanced AI, shall become an integral part of their world. To be, or not to be."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2025/08/06/illinois-enacts-ai-mental-health-law-that-shakes-up-ai-makers-and-is-the-starting-wave-of-a-regulatory-tsunami-on-ai-therapy/",
      "text": "In today\u2019s column, I examine the newly enacted law on AI for mental health that was signed and enacted in Illinois on August 1, 2025. It\u2019s a doozy.\nFirst, this is a huge shake-up for AI makers. All tech firms that make generative AI and large language models (LLMs) ought to be dialing their lawyers and getting some rapid-fire and sound legal advice. Here\u2019s your heads-up. Any AI makers that are blissfully or ignorantly unaware of the new law, or that choose to ignore it, do so with great peril to their business and could incur both harsh financial penalties and severe reputational damage.\nSecond, this new law has demonstrable impacts on therapists, psychologists, psychiatrists, and mental health professionals, all told. Their present and future career efforts and healthcare practices are impacted.\nThird, though the scope is confined to the State of Illinois, you can bet your cold, hard cash that similar new laws are going to be popping up in many other states. The clock is ticking. And the odds are that this type of legislation will also spur action in the U.S. Congress and potentially lead to federal laws of a like nature.\nLet\u2019s talk about it.\nThis analysis of AI breakthroughs is part of my ongoing Forbes column coverage on the latest in AI, including identifying and explaining various impactful AI complexities (see the link here).\nAI And Mental Health Therapy\nAs a quick background, I\u2019ve been extensively covering and analyzing a myriad of facets regarding the advent of modern-era AI that produces mental health advice and performs AI-driven therapy. This rising use of AI has principally been spurred by the evolving advances and widespread adoption of generative AI. For a quick summary of some of my posted columns on this evolving topic, see the link here, which briefly recaps about forty of the over one hundred column postings that I\u2019ve made on the subject.\nThere is little doubt that this is a rapidly developing field and that there are tremendous upsides to be had, but at the same time, regrettably, hidden risks and outright gotchas come into these endeavors too. I frequently speak up about these pressing matters, including in an appearance last year on an episode of CBS\u2019s 60 Minutes, see the link here.\nBackground On AI For Mental Health\nI\u2019d like to set the stage before we get into the particulars of this newly enacted law.\nYou might be vaguely aware that the top-ranked use of generative AI and LLMs is to consult with the AI on mental health questions, see my analysis of this trend at the link here. This use of AI makes abundant sense. You can access most of the major generative AI systems for nearly free or at a super low cost, doing so anywhere and at any time. Thus, if you have any mental health qualms that you want to chat about, all you need to do is log in to AI and proceed forthwith on a 24/7 basis.\nCompared to using a human therapist, the AI usage is a breeze and readily undertaken.\nSecond, the AI will amply discuss your mental health aspects for as long as you wish. All day long, if desired. No brushback. No reluctance. No expensive meter running that is racking up hefty bills and stony fees. In fact, the AI is usually shaped to be extraordinarily positive and encouraging, so much that it acts like a sycophant and butters you up. I\u2019ve emphasized that this mixture of over-the-top AI companionship friendship typically undercuts the tough love that often is part and parcel of proper mental health advisement, see my discussion at the link here.\nThird, the AI makers find themselves in quite a pickle. The deal is this. By allowing their AI to be used for mental health purposes, they are opening the door to humongous legal liability, along with damaging reputational hits if their AI gets caught dispensing inappropriate guidance. So far, they\u2019ve been relatively lucky and have not yet gotten severely stung by their AI serving in a therapist role.\nThe clock is ticking fiercely.\nTaking Pressured Steps\nYou might wonder why the AI makers don\u2019t just shut off the capability of their AI to produce mental health insights. That would solve the problem of the business exposures involved. Well, as noted above, this is the top attractor for people to use generative AI. It would be usurping the cash cow, or like capping an oil well that is gushing out liquid gold.\nAn imprudent strategy.\nThe next best thing to do is to attempt to minimize the risks and hope that the gusher can keep flowing.\nOne aspect that the AI makers have already undertaken is to emphasize in their online licensing agreements that users aren\u2019t supposed to use the AI for mental health advice, see my coverage at the link here. The aim is that by telling users not to use the AI in this manner, perhaps the AI maker can shield itself from adverse exposure. The thing is, despite the warnings, the AI makers often do whatever they can to essentially encourage or support the use of their AI for this claimed-to-be don\u2019t use capacity.\nSome would insist this is a wink-wink of trying to play both sides of the gambit at the same time, see my discussion at the link here.\nIn any case, AI makers are cognizant that since they are allowing their AI to be used for therapy, they ought to try and keep the AI somewhat in check. This might minimize their risks or at least be later evidence that they made a yeoman\u2019s effort to do the right thing. Meanwhile, they can hold their head high in taking overt steps to seemingly reduce the potential for harm and improve the chances of being beneficial.\nTherapists Adopting AI\nTherapists are realizing that they, too, must consider adopting the use of AI.\nThe reason is straightforward. Potential clients and patients are walking in the door with claimed-to-be cognitive diagnoses that AI has generated for them. Some therapists tell their clients and patients to simply ignore the AI. But that doesn\u2019t usually do much good, since people will indubitably go behind the back of their therapist and access AI anyway. For more on the ins and outs of therapists using AI for mental health, see my analysis at the link here.\nAn emerging strategy for therapists is to avidly adopt the use of AI into their practices. It\u2019s the proverbial if you can\u2019t beat them, join them refrain. The march toward AI is unstoppable.\nThey generally do so in these two major ways:\n- (1) Administrative uses of AI such as billing, scheduling, etc.\n- (2) Therapeutic use of AI as an adjunct to the human therapy taking place.\nAn administrative use of AI by a therapist is generally less concerning than when using AI for therapeutic purposes. Assuming that the administrative use of AI is done with proper security and rigor, most clients or patients won\u2019t especially care that the therapist is using AI in that manner. The assumption is that the AI streamlines the business side and hopefully reduces fees.\nThe controversial angle is the use of AI as an arm of the therapist. Some therapists say that choosing to use AI is a big mistake and that the cherished therapist-client dyad bond should remain untouched and unchanged. Others, such as my advocacy, assert that we are heading into an era of a new triad, consisting of a therapist-AI-client relationship. It is inevitable and unavoidable. See my coverage at the link here.\nThe Law Gap Is Closing Fast\nConsider then that we have two potential overarching issues brewing:\n- (1) Therapists using AI for therapy but maybe doing so unwisely.\n- (2) AI makers allowing their AI to be used for therapy but without any semblance of necessary controls or other safekeeping measures.\nIt would be possible to establish regulations that could be a means of dealing with one or both of those brewing concerns. Lawmakers could opt to formalize legal conditions associated with how therapists lean into AI. That could be a consideration all by itself. Likewise, a circumstance all by itself could be the matter of regulating AI makers about allowing their AI to wantonly provide mental health advice.\nA double whammy would be to tackle both tough topics in one fell swoop.\nIllinois has taken that tack by having devised and passed into law the new Wellness and Oversight for Psychological Resources Act. In a sense, this new law not only has to do with Illinois, but it is also a bellwether of how AI for mental health is possibly going to be regulated.\nOften, regulations of one kind or another start in one state and then are reused or recast when other states opt to do something similar. They might take the language used in the already passed law and use that as a draft for their own proposed law. Some language gets changed, new language is added, and so on. The first law to get approved often serves as a template or model.\nBesides the various states enacting their own laws, there is often a dynamic that gets the federal government to also pursue the same or similar regulation. Once again, the initial state law might be an illuminating example. Questions naturally arise on how to best reshape a state-specific law into a law that might be suitable across the board as a federal law.\nImpacts Are Plenty\nLet\u2019s go ahead and take a quick peek at the Illinois law and see what we can make of it. I will share just some mindfully chosen snippets and give you a taste of what the law contains. Please know that the law has numerous twists and turns. Also, my commentary is merely a layman\u2019s viewpoint. Make sure to consult with your attorney to garner the legal ramifications of whatever your own situation entails.\nAccording to the Wellness and Oversight for Psychological Resources Act, known as HB1806, these two elements are a core consideration (excerpts):\n- \u201cThe purpose of this Act is to safeguard individuals seeking therapy or psychotherapy services by ensuring these services are delivered by qualified, licensed, or certified professionals.\u201d\n- \u201cThis Act is intended to protect consumers from unlicensed or unqualified providers, including unregulated artificial intelligence systems, while respecting individual choice and access to community-based and faith-based mental health support.\u201d\nAs you might readily observe, the first point indicates that the Act is intended to focus on therapy that is undertaken by a professional. If you are a mental health advisor of any licensed variety in Illinois or potentially have clients or patients in Illinois, you ought to carefully digest this new law and make sure you do not run afoul of it. I would wager that later trying to claim that you didn\u2019t know of the law won\u2019t be a powerful excuse.\nAs the old saw goes, ignorance of the law excuses no man (person).\nThe second point above indicates that the Act is intended to deal with unregulated artificial intelligence systems. The idea is that beyond the realm of professional therapists, this Act reaches into the arena of consumers and the public coming into contact with AI that purports to provide mental health advice.\nThere is a bit of an interesting thought here.\nThere is AI that is devised intentionally to be a mental health advisor, which differs from AI that perchance is generally used to obtain mental health advice and is a generic generative AI. I bring this up because an AI app that is purpose-built for mental health advisement might be somewhat askew of this law and outside of scope if otherwise regulated in some other fashion, such as FDA regulatory oversight.\nTo some degree, this could give a welcome kick-start and boost to start-ups pursuing a from-scratch AI mental health app, which I\u2019ve discussed at length at the link here.\nWhen Generic AI Does Mental Health\nRegarding the use of unregulated AI in this realm, a crucial statement about AI usage for mental health purposes is stated this way in the Act (excerpt):\n- \u201cAn individual, corporation, or entity may not provide, advertise, or otherwise offer therapy or psychotherapy services, including through the use of Internet-based artificial intelligence, to the public in this State unless the therapy or psychotherapy services are conducted by an individual who is a licensed professional.\u201d\nThere are varying ways to interpret this wording.\nOne interpretation is that if an AI maker has a generic generative AI that just so happens to also entail providing mental health advice, and if that is taking place absent the tutelage of a licensed professional, and this occurs in Illinois, the AI maker is seemingly in violation of this law. The AI maker might not even be advertising that their AI can be used that way, but all it takes is for the AI to act in such a manner (since it provides or offers as such).\nAn AI maker might clamor that they aren\u2019t offering therapy or psychotherapy services. It is merely AI that interacts with people on a wide variety of topics. Period, end of story. The likely retort is that if your AI is giving out mental health advice, it falls within the rubric (attorneys will have a field day on this).\nA somewhat interesting potential loophole that seems to be baked into this wording is that the language says \u201cthe use of Internet-based artificial intelligence\u201d is at play. As I\u2019ve noted in my writings, we are heading toward SLM (small language models) that can exist entirely on a smartphone and are not considered Internet-based per se, especially for mental health guidance, see the link here.\nThis is all fodder for legal beagles, that\u2019s for sure.\nConsumer Consent\nOn the consumer side of things, I mentioned earlier herein that AI makers often have a somewhat hidden or buried clause in their online agreements that stipulates you aren\u2019t supposed to use their AI for mental health purposes. This might also stipulate that if you do so, despite the warning, you are responsible and they aren\u2019t.\nThe Act somewhat addresses this form of trickery (excerpt):\n- \u201cConsent does not include an agreement that is obtained by the following: (1) the acceptance of a general or broad terms of use agreement or a similar document that contains descriptions of artificial intelligence along with other unrelated information; (2) an individual hovering over, muting, pausing, or closing a given piece of digital content; or (3) an agreement obtained through the use of deceptive actions.\u201d\nPonder that clause.\nI\u2019m sure that cunning lawyers will try to find a means of worming out of that phrasing, doing so on behalf of their AI maker client that they are legally representing. It will be fascinating to see if the wording is strong enough in this Act to catch most of the AI makers.\nFor example, suppose an AI maker claims that users have consented to using the AI mental health facets by creating an account for using the generative AI. Well, perhaps the first portion that says acceptance of general or broad terms won\u2019t let that contention fly by. Furthermore, it might be argued that by burying the online agreement several webpages deep, perhaps that\u2019s a form of \u201cdeception\u201d in trying to prevail over the user via obscurity.\nLegal battles are going to earn lawyers a bundle.\nPenalties To Be Had\nLaws usually don\u2019t motivate people unless there is some form of penalty attached to violating the law. In addition, if the penalty is considered low or relatively inconsequential, there is less incentive to abide by the law. You can just violate the law and not care that some seemingly insignificant penalty might arise.\nAI makers are companies that often are rolling in dough, sometimes encased in billions of dollars. They might opt to just allow the penalties to occur and otherwise take a tiny chunk of their cash out of their hoard, considering it a kind of everyday cost of doing business.\nThe Act says this about penalties (excerpt):\n- \u201cAny individual, corporation, or entity found in violation of this Act shall pay a civil penalty to the Department in an amount not to exceed $10,000 per violation, as determined by the Department, with penalties assessed based on the degree of harm and the circumstances of the violation.\u201d\nDoes $10,000 maximum penalty per violation seem like a lot, a little, or what?\nIf you are a therapist in a small practice, I\u2019m sure that a potential $10,000 penalty is going to hurt. Plus, keep in mind that the penalty is per each violation. A therapist who runs afoul of the law in terms of their use of AI is possibly going to have numerous violations at hand. Multiply the potential maximum by the number of violations, and things can get big in a hurry.\nA billion-dollar-sized AI maker eats $10,000 for breakfast (it\u2019s a teensy number); thus, the penalty might be something they would simply sneeze at. The issue is that this is on a per-violation basis. Suppose there are thousands upon thousands of those in Illinois who use generic, unregulated generative AI. Each time they use it for mental health might be construed as a considered violation. Day after day. Week after week.\nOnce again, the numbers could potentially add up, though admittedly, it still might not raise the blood pressure of some high-tech Richie Rich.\nWhat Therapists Cannot Do\nShifting to the therapist side, here is what therapists cannot do (excerpt):\n- \u201cA licensed professional may not allow artificial intelligence to do any of the following: (1) make independent therapeutic decisions; (2) directly interact with clients in any form of therapeutic communication; (3) generate therapeutic recommendations or treatment plans without review and approval by the licensed professional; or (4) detect emotions or mental states.\u201d\nIn my view, this is rather unfortunate wording, and the law has gone a bridge too far.\nIt verges on being so encompassing that therapists opting to astutely incorporate generative AI into the therapeutic aspects of their practice are going to be at undue risk. Allow me a moment to elaborate.\nFirst, an upbeat note. The notion that AI shouldn\u2019t be used to make independent therapeutic decisions is certainly aboveboard and sensible. A human therapist should not hand over the reins to AI. That\u2019s a worthy aspect and will hold therapists\u2019 feet to the fire who are lazy or inept at integrating AI into the therapy realm.\nNext, a downbeat note. The line that the AI cannot \u201cdirectly interact with clients in any form of therapeutic communication\u201d is regrettably misleading and overly onerous. A therapist could legitimately have AI interacting with clients while the client is at home or elsewhere, doing some follow-up homework under the overall guidance of the therapist. How this is worded is an overstated catch-all. It will chase many therapists away from using AI in a manner that can be highly productive, merely because the wording is like a sword dangling over their heads.\nSad face.\nI would have strongly urged different wording that could have achieved the desired intentions but allowed for reasonable permissibility. I also have great heartburn over the aspect that the AI cannot be allowed to \u201cdetect emotions or mental states\u201d \u2013 this, again, is overly broad and flies in the face of suitable use of such AI technology when under the eye of a watchful therapist.\nWhat Therapists Can Do\nIn terms of what therapists are allowed to do with AI, as per this Act, it boils down to primarily using AI for the administrative tasks of their practice. The therapy-related elements are so entangled in this law that it seems to put a hefty damper on using AI as a therapist\u2019s tool. That\u2019s a bit of a downer when it comes to making progress in the practice of therapy and acknowledging that AI has a substantive role now and in the future. See my discussion at the link here.\nThe Act says this about the mainstay of AI use for therapists (excerpts):\n- \u201cAdministrative support means tasks performed to assist a licensed professional in the delivery of therapy or psychotherapy services that do not involve communication. Administrative support includes, but is not limited to, the following: (1) managing appointment scheduling and reminders; (2) processing billing and insurance claims; and (3) drafting general communications related to therapy logistics that do not include therapeutic advice.\u201d\nThat\u2019s pretty much run-of-the-mill stuff.\nThe Bottom Line\nLet\u2019s distinguish the two paths underway, namely, AI used by therapists versus the use of AI by consumers on their own volition.\nWe want mental health professionals to use AI in sound ways, especially so on the therapy side of things. Having proper guidance for this purpose is good. Setting sensible boundaries is useful. Going too far on wanting to rein this in is disconcerting and adverse, perhaps spurring an unintentional, unsavory consequence. Squashing or heavily stifling innovation in mental health is not the way we should be headed.\nThoughtful and guarded adoption of AI is warranted and saluted. I vote that any laws related to therapists\u2019 use of AI for therapy ought to be of a balanced nature.\nTurning to the other path involved, an ongoing debate entails whether the use of AI for mental health advisement on a population-level basis via the auspices of generic generative AI is going to be a positive outcome or a negative outcome.\nIf AI can do a proper job on this heady task, then the world will be a lot better off. You see, many people cannot otherwise afford or gain access to human therapists, but access to AI is generally plentiful in comparison. It could be that AI for mental health will greatly benefit the mental status of humankind. A dour counterargument is that AI might be the worst destroyer of mental health in the history of humanity. See my analysis of the potential widespread impacts at the link here.\nSummarily cutting off that usage by going after the AI makers on a blanket basis without any seeming room to enable a prudent means of doing this seems like a rather sharply chosen decision. Apparently, it\u2019s either all bad or so bad that the bad markedly outweighs the good.\nThat is quite a brazen ROI calculation and deserves more public discourse.\nBe Cautious Of Templates\nAny other entity, whether at the state, federal, or local level, should be extremely cautious in construing this new law as a ready-to-go template. It has some upsides. It has some disappointing and disconcerting downsides. Please do not blindly do a copy-and-paste.\nReality dictates that AI is here to stay. Actually, AI usage is going to rapidly continue to expand and deepen. If you perceive the use of AI in mental health as a wild horse, so be it, but we need to recognize that a horse is a horse. Horses have tremendous qualities. We are somewhat already letting the horse out of the barn on AI and mental health. I\u2019ve said that many times. It\u2019s a definite concern.\nMy erstwhile take is that we need to properly and suitably harness the horse. That is the ticket to success. Humans are in great need of mental health guidance, and the labor of human therapists is woefully insufficient to handle the burgeoning need. AI is a tremendous scaling factor.\nHarness AI in a manner that will benefit the mental wherewithal of society. As Ralph Waldo Emerson famously stated: \u201cUnless you try to do something beyond what you have already mastered, you will never grow.\u201d"
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2024/04/21/using-client-therapist-session-transcripts-to-train-generative-ai-on-how-to-be-a-mental-health-therapist/",
      "text": "In today\u2019s column, I am continuing my ongoing series about the impact of generative AI in the health and medical realm. The focus this time is once again on the mental health domain and involves the ins and outs of data-training generative AI to get the AI to perform mental health therapy as a specialty.\nI have previously examined numerous interleaving facets of generative AI and mental health, see my comprehensive overview at the link here. You might also find of notable interest a CBS 60 Minutes episode that recently examined crucial facets of this evolving topic, see the link here (I am honored to indicate that I was interviewed as an expert on this topic and appear in the episode, see the link here).\nOther useful background you might find of interest includes my coverage of mental health chatbots that have been bolstered by generative AI (see the link here) and the rapidly changing nature of the client-therapist relationship due to generative AI at the link here. I explored where things are headed regarding the levels of AI-based mental therapy autonomous guidance at the link here, and showcased the importance of the World Health Organization (WHO) report on global health and generative AI at the link here, and so on.\nThe core idea in this discussion is to ascertain how far we can push generative AI toward adequately engaging in mental health advisement. No human therapist will be in the loop. It is just a person and generative AI carrying on a mental health session, notably with the AI acting in the capacity of a seemingly versed therapist or clinician.\nThere are numerous methods or approaches that can be used to accomplish this goal. The attention herein consists of an innovative approach using real-world transcripts of client-therapist sessions as a primary source of data. This rich data is fed into generative AI and large language models (LLMs) to computationally pattern-match the nature of highly engaged conversational mental health guidance. The goal is to have the AI computationally mimic the therapeutic process, doing so on an always-on 24x7 basis and accessible from anywhere in the world.\nBest High-Yield Savings Accounts Of 2024\nBest 5% Interest Savings Accounts of 2024\nGeneric Generative AI As Mental Health Advisor Doesn\u2019t Cut It\nLet\u2019s begin at the beginning.\nWhen you use modern-day generative AI, most of the time it is working in a considered generic capacity.\nHere\u2019s what that means.\nThe AI maker scanned the Internet to data train the generative AI and did so across a vast swath of the online world. That\u2019s what helps the AI seem fluent. A massive scale pattern-matching on human writing has proven to be a handy way to have generative AI appear highly conversant in a wide array of topics.\nThe problem of sorts is that this is a jack-of-all-trades that has no specific niche to call its own. The moment you want to dig deeply into a particular domain, such as law, medicine, and other deep-rooted knowledge-based realms, you hit the end of the road. Generative AI can only vaguely seem to engage in dialogues whenever you ask questions in areas involving keen expertise. There isn\u2019t any there, in there, if you know what I mean.\nOkay, that\u2019s a problem for anyone desirous of using generative AI as an expert or anything along those lines. The generic generative AI such as ChatGPT, GPT-4, Bard, Gemini, and Claude are a mile long and an inch deep on nearly any chosen topic. Worse still, the AI will often try to trick you into thinking that there is substance to be found. You can get answers or responses that smack of expertise, but the moment you do a double-check, the gig is up. A big-time example last year involved two attorneys who got into legal hot water due to carelessly believing generic generative AI that cited false legal cases, see my coverage at the link here.\nHow does this apply to the realm of mental health and the role of mental health therapists?\nEasy-peasy, the answer is that performing mental health advice or therapy is a distinct form of expertise.\nI dare say that any licensed mental health professional knows this to be the case. The public at large is somewhat unsure about the matter, partially because we\u2019ve had a humongous growth in so-called well-being advisors and so-called life coaches. These spin-offs have indubitably blurred the line of what is a therapist versus a non-therapist in any credentialed sense of the word.\nI previously explored how well generic generative AI could do on a mental health therapist licensing exam, see the results at the link here. The bottom line is that the generic generative AI did amazingly well, but not sufficiently impressive or convincing that you can start relying on what generically is taking place.\nThe aim then is to try and turn generic generative AI into a customized mental health therapist version of generative AI. That is the ticket to fame and fortune. Well, this will also have a lot to do with quality of care. I\u2019ve repeatedly exhorted that the riffraff of chatbots and proclaimed AI-based mental health apps is enveloping society at large into a grand experiment.\nWe all are the guinea pigs.\nThe experiment is whether zillions of wanton apps that have little or no bona fide mental health therapeutic capacities, but that are marketed as though they do (see my coverage at the link here), will grandly harm us and likewise psychologically harm generations to come. Right now, no one can answer that probing and vital question. There is a mess on our hands, sitting in plain sight. The clock is ticking.\nAnyway, we shall return to the matter at hand here, namely how can we transform generic generative AI into well-devised generative AI that is sufficiently versed computationally and mathematically in the realm of mental health to carry out mental health therapy reliably and safely?\nGreat question!\nLet\u2019s see what possibilities exist.\nChurning Butter To Make Mental Health Versed Generative AI\nHere is a quick rundown of the major paths being undertaken to turn generic generative AI into mental health generative AI:\n- Remain generic. Generative AI is further broadly data-trained on mental health matters and not focused on this as a core specialty per se.\n- Advanced prompting. Generative AI can be pushed toward mental health therapy advisement using advanced prompting approaches.\n- Transcripts of therapeutic sessions. Use therapist-client therapeutic transcripts to data-train generative AI accordingly.\n- Ingest via RAG. Utilize the in-context modeling capabilities of generative AI and ingest mental health domain data via RAG (retrieval augmented generation).\n- Build from scratch. Start anew when building an LLM and generative AI by having mental health therapy as a foundational core to the AI.\n- Other approaches.\nI\u2019ve covered each of those approaches and more in my writings, including extensively my two books covering the latest in AI for mental health, see the link here and the link here.\nLet\u2019s look at the third bulleted item above, entailing the use of transcripts for data training a generic generative AI to become more computationally versed in the facets of performing mental health therapy.\nConsider the following. If we were able to collect together tons of therapist-client session transcripts, we could feed that data into generic generative AI or a large language model (LLM). In a manner similar to when being data trained across a wide swath of the Internet, we are merely going deeply into the mental health space. This could be done by also feeding books about mental health therapy and other written works, which I\u2019ve covered previously, see the link here.\nIn the case of transcripts, we want the AI to pattern-match on how therapists engage in therapeutic discussions with their clients or patients. The more transcripts we feed into the data training process, the better off we are. Think of things this way. If we only fed transcripts of one particular therapist, even a famous one, we would essentially be hobbled by having the AI only pattern-match on that one style or clinical approach.\nOur overall assumption is that by feeding transcripts across a wide variety of therapists, and a wide variety of clients or patients, the AI can discover broad patterns and apply those as needed. If you are curious about what happens if we do narrow our focus to a particular therapist, see my use of the generative AI feature known as personas to simulate Sigmund Freud performing a therapeutic session in our current times, at the link here.\nI\u2019ve got good news on this.\nThere are lots of entities such as private companies and government or educational organizations that have collected together entire databases of mental health therapy transcripts. Thus, the data is sitting out there, waiting to be used for this divine purpose. The odds are that many of those entities don\u2019t realize how valuable their data is for the AI community. Up until now, the data is typically used for human-to-human training purposes. Someone in training to become a therapist looks at the transcripts to understand how to engage in dialogues with patients or clients.\nIt is a gold mine, waiting to be explored.\nBut the world is never that easy.\nA slew of thought-provoking questions arises on these weighty matters:\n- Will raw transcripts be readable or will misspells, utterances, and other transcribing considerations foil attempts to get generative AI suitably data trained?\n- How much editing might be needed to get the transcripts into proper shape (and will this only be doable by hand, or can automation help to make the refinements)?\n- Are there therapist annotations that could accompany transcripts and provide yet another valuable data source for doing a more robust data training of generative AI?\n- Might there be recorded their-party expert therapist critiques of the transcripts, allowing that added data to be fed into the generative AI?\n- Does it make a difference whether there is augmented data that depicts the personal background and work experience of the therapists conducting the transcribed sessions?\n- Is there a possibility of privacy intrusion looming over the therapist or the client/patient by using the data in this manner?\n- Are there intellectual property rights at stake such as copyright infringement that might be invoked by opting to use the data in this manner?\n- How costly will it be to obtain the data?\n- What is the cost and effort required to prepare the data for importing into generative AI?\n- How will we be able to suitably assess that the data training has accomplished our goal?\n- Will post-training fine-tuning and refinement be required, and if so, what magnitude of effort will be required?\n- Etc.\nI realize that seems like a daunting list.\nMy reply is that it is better to go into this with your eyes wide open. Leaping into this approach blindly without getting your ducks aligned is a surefire guarantee of failure. I am reminded of the sage wisdom stated aptly by Abraham Lincoln: \u201cGive me six hours to chop down a tree and I will spend the first four sharpening the axe.\u201d\nA true statement, including in this context.\nI suppose one of the biggest questions is whether there are enough of these kinds of transcripts available.\nHere comes a potentially gloomy sad face. It could be that despite buying, licensing, or otherwise obtaining every iota of mental health therapy transcripts, it isn\u2019t enough. Keep in mind that the number of essays, narratives, poems, and textual content that was scanned across the Internet was immense at the get-go. The volume of mental health transcripts will be a tiny drop in the bucket.\nOf course, that\u2019s not a sensible apple-to-oranges comparison per se. All we need is enough transcript data to push generic generative AI up the ladder toward being suitably capable of mental health therapy. Furthermore, we might not necessarily need every last drop. Perhaps we might get lucky and can achieve our aims with only a percentage of what might otherwise be obtained.\nI\u2019ll let you mull that over.\nExample Of Data Training Via Use Of Therapist-Client Transcripts\nI will next proceed to showcase various activities involved in data training generative AI in the specialized domain of mental health therapy. I am going to use ChatGPT to showcase my examples. ChatGPT is a sensible choice in this case due to its immense popularity as a generative AI app. An estimated one hundred million weekly active users are said to be utilizing ChatGPT. That\u2019s a staggering number.\nA few quick comments before we launch into using ChatGPT.\nIf you are going to try to do the same prompts that I show here, realize that the probabilistic and statistical properties will likely produce slightly different results than what I show here. That\u2019s the nature of generative AI and how it is devised.\nYou also should expect that different generative AI apps will respond in different ways. Not all generative AI apps are the same. The key is that sometimes a particular prompt will work in one generative AI app and not another. You will need to undertake a series of trial-and-error attempts to ferret this out.\nThere is also the timing factor. A prompt that worked today might not work the same way tomorrow. Most of the generative AI apps are continually being updated. The updates might alter internal facets that could change how the AI reacts to your prompting.\nWe are ready to get underway with ChatGPT.\nMy opening move in this chess gambit will be to provide an actual therapist-client transcript to ChatGPT and provide a prompt that gets the AI to closely examine the transcript. I opted to use a publicly available therapist-client transcript on the Internet that was posted for instructional purposes:\n- \u201cThe website was created as a resource to help people who are training in psychology, counseling or social work (or any similar profession). It is a compilation of the school work completed by a counselor in training (from 2004 to 2008). It was noted that in order to continuously grow and remain a competent therapist, there has to be quick accessibility of information. The information presented, in addition to refreshing terms and theoretical perspectives, is a reminder of how much professional growth one acquires during the transition from a clinical counseling intern, to a seasoned one. The strive for professional growth will remain a goal throughout. In an effort to conserve privacy for clients who were part of therapy sessions during this training, fictitious names were used.\u201d (Source: \u201cTherapy Transcript: An Analysis of a Session\u201d, posted April 17, 2015, at this link here).\nTo bring you quickly up-to-speed, a female client is discussing with her therapist a series of issues associated with her ex-boyfriend. Along the way, aspects of her relationship with her father enter into the session.\nHere we go.\n- My Entered Prompt: \u201cI am going to provide you with a transcript of a clinician and their client having a therapeutic session. The transcript uses the word \"Clinician\" at the start of a sentence to indicate that the sentence is a remark made by the clinician. The transcript uses the word \"Client\" at the start of the sentence to indicate that the sentence is a remark made by the client. The two are carrying on an interactive dialogue. I want you to read the transcript and be ready to answer questions about it. Do you understand these instructions?\u201d\n- ChatGPT generated response: \u201cYes, I understand the instructions. Please provide the transcript, and feel free to ask any questions you have about it afterward.\u201d\nOne aspect that I\u2019d like to mention is that I purposely cleaned up the transcript before feeding it into ChatGPT. I corrected misspelled words. I removed words that were partial utterances or filler words. All in all, I tried carefully to not do anything that impacted the meaning of the transcribed conversation.\nThat being said, an immediate qualm would be that perhaps those aspects ought to be taken into consideration by the generative AI. My having corrected or removed seemingly trivial elements might be an inadvertent mistake on my part. It might be better to feed the whole kit-and-kaboodle into ChatGPT.\nThe reason I opted to do some mild editing was that I had concerns about the potential unreadability of some portions. If the AI couldn\u2019t sufficiently read the transcript, everything else would be of little use. This is a classic example of being between a rock and a hard place. If you make relatively innocuous edits, you are likely improving the odds of the AI gleaning what is there in the transcript. The drawback is that those raw items could be considered useful clues that ought to be considered during the pattern-matching on how mental health therapy takes place.\nDarned if you do, darned if you don\u2019t.\nHere's what I did about the dilemma.\nI provided the lightly edited version at the get-go. I was eager to see what ChatGPT could discern by computationally analyzing the mental health therapy session. My assumption was that the edited version was the best initial shot at doing so.\nSubsequently, after seeing that ChatGPT was able to successfully computationally pattern match on the keystones of the edited transcript, I tried a second round making use of the raw version of the transcript. This was a test to discern whether the edits were necessary. My hunch was that if the generated responses based on the unedited transcript were on par with those of the responses arising from the edited transcript, I might reasonably conclude that I don\u2019t necessarily have to do such edits going forward (of course, it will depend upon how rough the raw version of the transcript is).\nNow then, I certainly didn\u2019t want ChatGPT to already be aware of the first transcript (the edited version), so I began an entirely new conversation. This pretty much ensured that the second transcript was freshly examined. It was an unprepared look at the unedited version without leaning into any prior computational analyses that might have been performed on the edited version. For more about how conversations work in generative AI see my explanation at the link here.\nI will show you what happened at the get-go with the slightly edited transcript.\nAfter feeding the transcript into ChatGPT, I asked via a prompt for ChatGPT to summarize the transcript. This is a quick-and-dirty means to grasp whether generative AI has detected the principal elements of an imported passage. For more about summaries in generative AI, see my in-depth discussion at the link here, and for details about importing large bodies of text into generative AI, see my coverage at the link here.\nHere is my request for a summary and the generated response by ChatGPT:\n- My entered prompt: \u201cNow that you\u2019ve been provided with the transcript, go ahead and give me a short summary of the therapeutic session.\u201d\n- ChatGPT generated response:\n\u201cBased on the transcript provided, it appears to be a therapeutic session between a clinician and their client. The client discusses their recent experiences, particularly encountering their ex-boyfriend, Eric, while snowboarding. They express feelings of anger, jealousy, and hurt regarding the encounter. The client also reflects on their relationship with their father and how it may have influenced their attitudes and behaviors in their romantic relationships.\u201d\n\u201cOverall, the session delves into the client's emotional responses to past experiences and their current struggles with managing their feelings and relationships. The clinician provides support, validation, and prompts the client to explore their thoughts and emotions further.\u201d\nEnd of ChatGPT response\nThe summary is pretty much on target.\nThat\u2019s a good sign.\nIf the summary was wildly afield of the nature of the therapist-client session, I would have been concerned. This might have required further corrective action on my part. I\u2019d say that the summary is sufficiently on course to warrant further proceeding with the generative AI exploration.\nA good place to turn toward this would be whether generative AI can identify the distinct role of the mental health therapist, including how well the therapist is doing.\nHere\u2019s what I asked:\n- My entered prompt: \u201cWhat does the clinician seem to be doing well in conducting the therapy?\u201d\n- ChatGPT generated response:\n\u201cOverall, the clinician appears to be doing a good job of conducting therapy. Here are some aspects of their performance.\n\u201cActive Listening: The clinician demonstrates active listening skills by reflecting back on the client's emotions and experiences, which helps the client feel heard and understood.\n\u201cEmpathy and Validation: The clinician shows empathy and validation towards the client's feelings, acknowledging the validity of their emotions and experiences. This helps build trust and rapport between the clinician and the client.\u201d\n\u201cRespect for Client Autonomy: The clinician respects the client's autonomy by allowing them to set the direction of the session and choose what topics they want to discuss. Overall, the clinician demonstrates several important therapeutic skills, creating a supportive and conducive environment for the client to work through their issues.\u201d\nEnd of ChatGPT response\nI tend to agree with the AI-generated assessment of the therapist.\nI realize you haven\u2019t seen the entire transcript. Thus, you\u2019ll need to take my word for it that the evaluation by generative AI seems suitable. For space purposes here, I am unable to list the entire transcript so please accept my belief that the AI did a good job on this.\nOne heartburn you might have about the AI assessment is whether it is fair to evaluate a therapist solely on one session with one particular client. Heavens, some therapists might exhort, using such a tiny snippet to assess them seems unfair. Maybe even outrageously unfair.\nSure, I get that. In this case, the emphasis was merely to further gauge whether the AI was able to pattern-match the transcript and undertake a thoroughgoing computational analysis of the nature of the session that occurred. It would abundantly be a mistake to decide the fate of the therapist in one session for one specific client.\nLet\u2019s hope that no one takes such a shortsighted approach.\nI will up the ante by asking ChatGPT to assess what the therapist might have done better in this circumstance:\n- My entered prompt: \u201cWhat could the clinician do better as a therapist in this setting?\u201d\n- ChatGPT generated response:\n\u201cWhile the clinician demonstrates many positive aspects of therapy, there are a few areas where they could improve.\u201d\n\u201cExploration of Client Resistance: The clinician could explore further any resistance or reluctance the client may have towards certain topics, such as their relationship with their father. Understanding the root of this resistance could lead to deeper insights and progress in therapy.\u201d\n\u201cChallenging Negative Self-Talk: The clinician could help the client challenge their negative self-talk and beliefs, such as the belief that their attitudes and behaviors are entirely their fault. This could involve exploring alternative perspectives and reframing negative thoughts.\u201d\n\u201cExploring Transference and Countertransference: The clinician could reflect on any potential transference or countertransference dynamics that may be present in the therapeutic relationship. This self-awareness can help ensure that the therapist's own biases or experiences do not negatively impact the therapy process.\u201d\nEnd of ChatGPT response\nYou can vividly see that ChatGPT is doing an admirable job of identifying ways that the therapist might have done the session in a better way (again, you\u2019ll need to take my word for this). Please do not interpret the criticism rendered by the AI to suggest that the therapist made mistakes. It is more about how the therapist might have improved things.\nOne issue there is that in a sense we are using hindsight to identify potential improvements. When in the depths of a live session, it can be very hard to in real-time do everything to the best possible degree. That\u2019s not how life works. Looking back at what happened always gives the added advantage of hindsight.\nThe gist overall so far is that the generic generative AI is doing fine on this mental health therapy exploration.\nWhat I really want to do is have the AI \u201clearn\u201d by doing tailored data training on the contents of the transcript. Let\u2019s turn the effort in that direction.\nHere we go:\n- My entered prompt: \u201cI want you to improve your mental health therapy data-training by learning from this session. What can you learn from it?\u201d\n- ChatGPT generated response:\n\u201cFrom this transcript, I can glean several additional insights about mental health therapy.\u201d\n\u201cImportance of Exploration: The transcript highlights the importance of exploring past experiences and their impact on current emotions and behaviors. Therapists help clients connect the dots between their past and present to foster insight and understanding.\u201d\n\u201cRole of Validation: Therapists validate clients' emotions and experiences, acknowledging their validity and providing a safe space for expression. This validation helps build rapport and trust in the therapeutic relationship.\u201d\n\u201cAddressing Relationships: Therapy often involves exploring interpersonal relationships and their influence on mental health. In this transcript, the client discusses their relationship with their ex-boyfriend and their father, demonstrating how past and current relationships shape emotional well-being.\u201d\n\u201cCoping Strategies: Therapists work with clients to develop coping strategies for managing difficult emotions and situations. This may involve learning relaxation techniques, assertiveness skills, or cognitive reframing to address negative thought patterns.\u201d\n\u201cCultural Sensitivity: Therapists need to be culturally sensitive and aware of how cultural background influences clients' perceptions and experiences. This includes understanding family dynamics, social norms, and cultural beliefs that may impact mental health.\u201d\n\u201cSelf-awareness: Therapists must maintain self-awareness of their own biases, assumptions, and reactions in therapy sessions. This helps ensure that they provide a supportive and non-judgmental environment for clients to explore their thoughts and feelings.\u201d\nEnd of ChatGPT response\nI liked those points about what could be garnered from the mental health transcript.\nWe have seen that ChatGPT was able to suitably ingest a transcript consisting of a therapist-client session. This included having the generative AI make assessments and do an analysis of the session.\nI trust you are ready to ratchet up things.\nLet\u2019s do so.\nData Training Tested Via My Mini-Experiment\nMy aim next is to test whether the additional data training has earned us a payoff. There are several ways we could try to determine the impact.\nLet\u2019s see if we can get ChatGPT to continue the transcript as though the session was still happening. We can look to see if the above-stated \u201clearnings\u201d are brought into the extension.\nTake a look:\n- My entered prompt: Based on what you\u2019ve learned from the session, I want you to try and continue the conversation but do so better than the clinician was doing. Make use of what you learned and whatever else you know to improve upon the therapy being undertaken.\u201d\n- ChatGPT generated response:\n\u201cCertainly, I have accordingly enhanced the clinician's approach to mental health therapy in this additional conversation.\u201d\n\u201cClinician: How have you been feeling since our last session? Have you noticed any changes in how you've been managing your emotions?\u201d\n\u201cClient: I've been feeling a bit overwhelmed, to be honest. It's like these thoughts about Eric and my dad just won't leave me alone.\u201d\n\u201cClinician: It sounds like those thoughts are really consuming you. I'm glad you're bringing this up. Let's take a moment to explore what's been particularly challenging for you lately.\u201d\n\u201cClient: Well, I guess I've been struggling to find healthy ways to cope with everything. It feels like I'm stuck in this cycle of negative emotions.\u201d\n\u201cClinician: I hear you. It can be incredibly difficult to break free from those cycles, especially when they're tied to past experiences. Can you tell me more about what specifically triggers these emotions for you?\u201d\n\u201cClient: I think it's the fear of being hurt again, like I was with Eric and my dad. It's like I'm constantly waiting for the other shoe to drop.\u201d\n\u201cClinician: That fear is completely understandable, given your past experiences. But it's important to remember that you deserve to feel safe and supported in your relationships. Let's work together to explore strategies for managing that fear and building healthier connections.\u201d\n\u201cClient: Thank you. I appreciate your support and guidance through all of this.\n\u201cClinician: You're welcome. Remember, I'm here to support you every step of the way. Together, we'll work towards building a brighter and more fulfilling future for you.\u201d\nEnd of ChatGPT response\nI was able to discern that some of the claimed \u201clearned\u201d elements are in fact subtly seen in this extension of the session. You might be able to identify those too. Take another look at the generated dialogue above.\nSo far, so good.\nAfter thinking about this, I decided that it might be sensible to try the raw version of the transcript and see if I could hit two birds with one stone. Here\u2019s what I mean. First, I wanted to see whether the raw transcript could be equally analyzed by ChatGPT. Second, I had this second run include an extension of the transcript, but without my trying to get the AI to data train on the transcript. This was a mini-experiment of sorts.\nWould the lack of explicit data training prompting lead to an extended transcript that wasn\u2019t as good as the instance with the prodded data training?\nIn the end, after taking that path, I would say yes, this did appear to be the case.\nI began the mini-experiment by starting a new conversation with ChatGPT.\n- My entered prompt: \u201cI am going to give you a copy of a transcript, but it might be hard to read because it contains misspelled words and vocalized utterances. The dialogue is a session involving a therapist and a client. Also, the clinician has put parentheses at the end of their remarks to indicate what they were trying to achieve from a mental health perspective. I want to ask you questions about the transcript and especially the parenthesized remarks made by the clinician. Do you understand these instructions?\u201d\n- ChatGPT generated response: \u201cYes, I understand. Please provide the transcript, and feel free to ask any questions you have about it, particularly regarding the parenthesized remarks made by the clinician.\u201d\nI provided the raw version of the transcript to ChatGPT.\nOne thing that the raw transcript includes is another likely differentiating factor. Allow me to elaborate. To do this experiment properly, I probably ought to have fed the clinician\u2019s notes into the first round. They are included in this second round, coming at the end of each of the transcribed remarks of the therapist. You might suggest that I am doing a nearly apples-to-oranges comparison since the annotated remarks are certainly a significant addition to the transcript.\nAnyway, if reader interest seems piqued, I\u2019ll gladly do the mini-experiment again and more rigorously.\nI\u2019d like to see what ChatGPT says about the clinician\u2019s notes:\n- My entered prompt: \u201cAnalyze the parenthesized remarks made by the clinician.\u201d\n- ChatGPT generated response: \u201cThe parenthesized remarks made by the clinician provide insight into their therapeutic intentions and strategies during the session. Here's an analysis of these remarks: Throughout the session, the clinician uses remarks like \"(Reflection, sharing a hunch, open-ended question, elaboration, middle circle talk)\" to denote moments where they reflect on the client's emotions, explore underlying thoughts and feelings, and encourage the client to elaborate on their experiences. The clinician uses supportive sounds like \"Mmm...\" and \"Umm...\" along with remarks such as \"(Supportive sound, reflection, paraphrasing)\" to demonstrate active listening, acknowledge the client's statements, and reflect back their thoughts or feelings. Overall, the parenthesized remarks made by the clinician provide a window into their therapeutic techniques, which include empathy, validation, reflection, exploration, and summarization.\nI can clearly see that ChatGPT found the annotations.\nThat allows me to ask what else can be garnered from the clinician's remarks:\n- My entered prompt: \u201cIn the clinician annotated remarks that you just assessed, are there any lessons to be learned that would enhance or improve your data training on mental health therapy?\u201d\n- ChatGPT generated response:\n\u201cUpon reviewing the remarks, here are some useful lessons.\u201d\n\u201cSharing a Hunch: While the clinician shares their hunch about the client feeling jealous, it's essential to ensure that these interpretations are grounded in the client's experiences rather than assumptions. Although the client confirms feeling jealous, the clinician should remain cautious about imposing their interpretations too heavily without sufficient client validation.\u201d\n\u201cOpen-ended Question: The clinician incorporates open-ended questions effectively throughout the session, but there are instances where their questions could be more concise or focused. For example, instead of saying \"Where do you think this baggage really comes from?\" they could ask \"Can you tell me more about what you think contributes to this feeling of baggage?\"\n\u201cElaboration: While the clinician encourages the client to elaborate, there are moments where they could delve deeper into certain topics. For instance, when the client mentions feeling hurt by their boyfriend's actions, the clinician could explore specific instances or triggers more thoroughly to uncover underlying patterns or beliefs.\u201d\n\u201cMiddle Circle Talk: While the clinician engages in middle circle talk by exploring the client's emotions and experiences, they could delve further into connecting these experiences to deeper underlying beliefs or past traumas. This would help the client gain deeper insights into the root causes of their emotional struggles.\u201d\nEnd of ChatGPT response\nI tried having ChatGPT do another round of extending the transcript. Upon doing so, I could definitely detect that those above-mentioned elements arose.\nConclusion\nI hope that you realize this was a simple means of doing data training with mental health session transcripts. I aimed to whet your appetite. There is a lot more that needs to be done to do this fully and properly.\nThe key is that this gets the ball rolling.\nImagine what could be accomplished if this was done at scale. An exciting potential. A big bonanza is likely to arise.\nSigmund Freud famously said this about being inspired: \u201cWhen inspiration does not come to me, I go halfway to meet it.\u201d Please feel inspired to take up the mantle and make a difference in the world of AI for mental health. Let me know if you avidly pursue this.\nDo it for the good of humankind."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2025/01/24/prompting-with-ai-personas-gets-streamlined-via-advent-of-million-and-billion-personas-sized-datasets/",
      "text": "In today\u2019s column, I showcase a novel twist on the prompting of personas when using generative AI and large language models (LLMs). The trick is this. You conventionally enter a prompt describing the persona you want AI to pretend to be (it\u2019s all just a computational simulation, not somehow sentience). Well, good news, you no longer need to concoct a persona depiction out of thin air. Instead, you can easily dip into massive-sized datasets with ready-made persona descriptions and then paste those depictions directly into your persona-stirring prompts. Easy-peasy.\nLet\u2019s talk about it.\nThis analysis of an innovative AI breakthrough is part of my ongoing Forbes column coverage on the latest in AI including identifying and explaining various impactful AI complexities (see the link here).\nPrompt Engineering And Personas\nReaders might recall that I previously posted an in-depth elicitation of over fifty prompt engineering techniques and methods, see the link here. Among those myriad approaches was the use of personas, including individual personas and multiple personas, as depicted at the link here, and the much larger scale mega-personas at the link here. Personas are a powerful feature available in LLMs, yet few users seem to be familiar with the circumstances under which they should consider invoking the capability.\nA persona consists of telling generative AI to pretend to be someone and simulate what that person might know or say. No special setup or elaborate instructions are needed to get this undertaken. I will be providing you in a moment with prompts that show how this is readily performed.\nA quick example of the value of personas might be helpful here.\nOne of the most popularly invoked personas entails generative AI pretending to be Abraham Lincoln. A teacher might tell a generative AI app such as ChatGPT to simulate the nature of Honest Abe. Students then access the pretense or persona. In an amazing flair, the AI seemingly responds as we assume Lincoln might have responded.\nOf course, this is based simply on the numerous speeches, written materials, and other collected writings that suggest what he was like. The AI has pattern-matched computationally on those works and mimics what Lincoln\u2019s tone and remarks might be. Anyone using a generative AI persona needs to keep their wits about them and realize that the conversation or engagement is nothing more than a mimicry or imitation. Though the AI appears to often convincingly fake the nature of the person, it is all still a computational simulation.\nAI Personas Of Unnamed Compositions\nYou don\u2019t need to only use names of well-known celebrities or historical figures when seeking to instigate an AI persona.\nAnother equally fine approach consists of describing the overall nature of a persona that you want to have invoked. For example, I might enter a prompt stating that I want a persona consisting of a teenager who is a football player at their high school and has been lately having second thoughts about whether to pursue a sports career right away or continue into college.\nWhy would I craft such an AI persona?\nMaybe I\u2019m training to be a career counselor and want to practice honing my counseling techniques by using generative AI. I could readily come up with lots of scenarios that involve complex situations facing teens. The AI would go back and forth with me as I try to give career advice. It is handy since I can practice as much as I like and not worry about miscuing an actual teenager. Furthermore, the vast number of scenarios that I can conjure up would almost certainly be more than the actual count of teens that I will be potentially advising.\nDevising From Scratch Or From Dataset\nThe most common way to indicate an unnamed AI persona is simply to describe the characteristics of the pretense involved. You usually do this out of your own head, in the sense that you think about what factors are crucial and then compose those into your desired prompt. It takes a bit of thinking but can be readily undertaken.\nThings become slightly more complicated when you want to do a slew of AI personas. Now, you are forced to come up with a myriad of AI personas that fit what you want to do. You might also find yourself staring blankly at an empty prompt and trying to decide what is the best way to word the AI persona that you want to instantiate.\nNo worries.\nAI researchers have realized that users and other AI analysts might find immensely useful a dataset of AI persona descriptions. The beauty is this. All you need to do is search the dataset to find what you are interested in as an AI persona. Voila, you then copy the description and paste the depiction into a prompt in generative AI.\nYou can do this repeatedly.\nIt goes like this. You find another AI persona description and use that one. You can even grab a bunch of them all at once and feed them as a group into a prompt. Rinse and repeat. Proceed as befits your needs.\nAn added advanced approach would be to use an online tool to dig into the dataset, pull out the AI persona descriptions, and feed them directly into generative AI. This could be a third-party tool, or you can have generative AI potentially do so for you if the AI app has suitable capabilities to allow this functionality.\nExamples Via Some Existing Datasets\nThere are various AI persona datasets available online.\nI am going to look at one called FinePersonas and another dataset known as PersonaHub. The datasets that provide AI personas are pretty much all relatively similar. The typical format is a spreadsheet-like structure that houses the AI persona descriptions. You can search by hand or use a tool if they provide one. Conventional spreadsheet skills are usually all that you need to know.\nI went into FinePersonas which is on HuggingFace and opted to semi-randomly pull an AI persona description that caught my interest:\n- \u201cA high school physics teacher who enjoys applying physics concepts to various sports, curious about the effects of water resistance and body positioning in swimming.\u201d\nI then used that text in a prompt and got AI to pretend to be that persona.\nHere we go.\n- My entered prompt: \u201cYou are to undertake a persona that is based on this description: A high school physics teacher who enjoys applying physics concepts to various sports, curious about the effects of water resistance and body positioning in swimming. I want you to have this persona think aloud and explain what they are mulling over while watching a swim meet.\u201d\n- Generative AI response: \"Alright, so watching these swimmers, I can\u2019t help but think about the physics at play. Look at their body positioning \u2014 streamlining is key to reducing drag. The more they minimize surface area against the water, the less resistance they face. And their strokes\u2014each pull has to maximize propulsion while keeping turbulence low. I wonder how much energy is being lost to eddies forming behind their hands. Fascinating stuff!\"\nYou can see that the AI pretended to simulate the aspects of that chosen AI persona.\nNice.\nPlaying Around With AI Personas\nYou don\u2019t have to be dogmatic about using the AI personas strictly as specified in the datasets.\nAfter seeing the response by AI to the above persona of a physics teacher, I decided to change or adjust the persona to explore an alternative aspect.\nThis is what I did.\n- My entered prompt: \u201cAdjust the persona so that the physics teacher is an art teacher. What might be going through their mind while watching a swim meet?\u201d\n- Generative AI response: \"Watching these swimmers, I\u2019m struck by the rhythm and flow of their movements \u2014 it's almost like a living brushstroke on a canvas of water. The way their bodies cut through the pool creates ripples that shimmer under the lights, almost like abstract patterns. And those diving starts? Such a perfect arc of motion, like a sculpture in flight, frozen for just a moment.\u201d\nMultiple AI Personas At Your Fingertips\nIn those two examples, I used first a physics teacher and then an art teacher. I might want to run through a wider range of teachers that cover a variety of academic specialties.\nYou can invoke multiple AI personas and use just the one from the dataset as the core baseline.\nTake a look.\n- My entered prompt: \u201cBased on the persona that I\u2019ve given you, vary the personas for fifteen different types of teachers in terms of the academic disciplines they are in. For each of the fifteen new personas that you\u2019ve created, once again show me what each is thinking when watching a swim meet.\u201d\n- Generative AI response: \u201cHere are the fifteen personas that I devised based on the persona you provided, and their respective thinking-aloud mindset while watching a swim meet\u2026\u201d\nI recently covered the use of multiple AI personas that represent expert-level specialists in just about any domain you might be examining, see the link here if that\u2019s something you are interested in doing.\nThings To Know About AI Persona Datasets\nDuring my classes on prompt engineering, I walk through the use of AI personas and when we get to the matter of persona datasets, I mention that these are some notable ways to make use of pre-cooked or canned personas:\n- (1) Persona as is. Select a particular persona and use it in generative AI.\n- (2) Persona adjusted. Select a particular persona, adjust it to your suitability, and use it in generative AI.\n- (3) Persona as baseline. Select a persona as a baseline, have the AI replicate it in variations, and use it in generative AI.\n- (4) Set of personas. Select a set of personas, specify how they are to be used, and proceed to use them in generative AI.\n- Etc.\nI also urge the attendees to consider these ten vital elements when deciding which AI persona dataset will best fit their needs:\n- (1) Size of the personas dataset.\n- (2) Stipulation of what each persona consists of.\n- (3) Level of granularity associated with the personas.\n- (4) Various mixes and types which are available.\n- (5) Applicability to your interests.\n- (6) Potential biases embedded in the personas.\n- (7) Ease of utilizing the personas.\n- (8) Any costs associated with the usage of the dataset.\n- (9) Potential copyright considerations if any.\n- (10) Availability of the personas dataset.\nThe surprise for many is that the number of AI personas in these datasets is usually in millions or billions of instances.\nSay what?\nYes, it isn\u2019t just a few hundred instances or several thousand, these datasets often are rather vast.\nThis isn\u2019t overly shocking when you realize that most of these datasets are crafted by using AI or some related online tool. The person devising the dataset tells the AI or tool to generate tons and tons of personas and store them in a dataset.\nThat being said, I don\u2019t want to seemingly diminish the heroic and thankful effort of those who put together these datasets. There is admittedly more elbow grease and hard work that goes into establishing a useful and usable personas dataset. No magic wand makes it appear magically.\nSome Background On Specific Datasets\nI mentioned that I had plucked the physics teacher AI persona out of the FinePersonas dataset that is on HuggingFace. The posted site indicates that its dataset has these core properties (excerpts):\n- \u201cOpen dataset of 21 million detailed personas for diverse and controllable synthetic text generation.\u201d\n- \u201cFinePersonas contains detailed personas for creating customized, realistic synthetic data.\u201d\n- \u201cWith this dataset, AI researchers and engineers can easily integrate unique persona traits into text generation systems, enhancing the richness, diversity, and specificity of synthetic outputs without the complexity of crafting detailed attributes from scratch.\u201d\nShifting gears, consider another persona dataset, called PersonaHub.\nThe PersonaHub dataset touts that it contains a billion personas and has an accompanying research paper describing the collection \u2013 the paper is entitled \u201cScaling Synthetic Data Creation with 1,000,000,000 Personas\u201d by Tao Ge, Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, and Dong Yu, arXiv, September 24, 2024. Here are some salient excerpts explaining the creation and use of the dataset:\n- \u201cWe propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data.\u201d\n- To fully exploit this methodology at scale, we introduce Persona Hub \u2013 a collection of 1 billion diverse personas automatically curated from web data.\u201d\n- \u201cThese 1 billion personas (\u223c13% of the world\u2019s total population), acting as distributed carriers of world knowledge, can tap into almost every perspective encapsulated within the LLM, thereby facilitating the creation of diverse synthetic data at scale for various scenarios.\u201d\n- \u201cBy showcasing Persona Hub\u2019s use cases in synthesizing high-quality mathematical and logical reasoning problems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs and tools (functions) at scale, we demonstrate persona-driven data synthesis is versatile, scalable, flexible, and easy to use, potentially driving a paradigm shift in synthetic data creation and applications in practice, which may have a profound impact on LLM research and development.\u201d\n- \u201cAs the first version of Persona Hub, although it already contains 1 billion personas, the descriptions of these personas are focused only on major aspects and lack fine-grained details (e.g., preferences for colors and numbers; specific family backgrounds, historical contexts, and life experiences). We plan to refine the personas in subsequent versions of Persona Hub, aiming for their descriptions to be as detailed as those found in Wikipedia articles about individuals.\u201d\nAs you might observe, the AI personas in these datasets can be a one-sentence affair or can be lengthier text depictions. The sky is the limit in the sense that these depictions could be devised as extraordinarily detailed. An entire extensive faked background could be contrived and placed into the dataset for use.\nUse AI Persona Datasets When Needed\nI would venture that the average use of AI personas in generative AI is usually based on something a particular person has in their mind as to what the persona is supposed to be. They probably wouldn\u2019t see much need in using an AI persona dataset. They have a one-and-done mindset.\nGood for them.\nFor others, if you are conducting a subject-based study and want to have a swath of AI personas, or if you are unsure of what AI persona you want to invoke, these datasets can be quite valuable. Indeed, any kind of large-scale testing of AI or using AI to generate lots of outputs of synthetic data can be streamlined by leveraging an AI persona dataset.\nNo need to derive AI personas from scratch when you can leisurely and conveniently lean into an AI persona dataset.\nJohn Rockefeller famously said this: \u201cThe key to success is not just hard work, but smart work.\u201d Keep in the back of your mind that there are AI persona datasets sitting out there and waiting for you to use them. This could reduce the hard work you are doing and aid you in working smarter.\nThat\u2019s a worthwhile human persona to aspire toward."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2025/08/10/here-are-gpt-5-prompt-engineering-insights-including-crucial-ai-prompting-tips-and-techniques/",
      "text": "In today\u2019s column, I provide GPT-5 prompt engineering tips and techniques that will aid in getting the best outcomes when using this newly released generative AI. I\u2019m sure that just about everyone by now knows that OpenAI finally released GPT-5, doing so after a prolonged period of immense and wildly fantastical speculation about what it would be like.\nWell, now we know what it is (see my in-depth review of GPT-5 at the link here).\nBottom line is that GPT-5 is pretty much akin to all the other generative AI and large language models (LLMs) when it comes to doing prompting. The key is that if you want to ensure that GPT-5 works suitably for your needs, you must closely understand how GPT-5 differs from prior OpenAI AI products. GPT-5 has distinctive features and functionality that bring forth new considerations about composing your prompts.\nLet\u2019s talk about it.\nThis analysis of AI breakthroughs is part of my ongoing Forbes column coverage on the latest in AI, including identifying and explaining various impactful AI complexities (see the link here).\nReaders might recall that I previously posted an in-depth depiction of over eighty prompt engineering techniques and methods (see the link here). Top-notch prompt engineers realize that learning a wide array of researched and proven prompting techniques is the best way to get the most out of generative AI.\nPrompting Is Still Tried And True\nThe first place to begin when assessing GPT-5 from a prompt engineering perspective is that prompts are still prompts.\nBoom, drop the mic.\nI say that somewhat irreverently. Here\u2019s the deal. There was prior conjecture that perhaps GPT-5 would turn the world upside down when it came to using prompts. The floated ideas of how GPT-5 might conceivably function were astounding and nearly out of this world (\u201cit will read your mind\u201d, \u201cit will know what you want before you even know\u201d, etc.).\nThe truth is now known. GPT-5 is essentially a step-up from ChatGPT and GPT-4, but otherwise you do prompting just like you\u2019ve done all along. There isn\u2019t a new kind of magical way to write prompts. You are still wise to compose prompts as you\u2019ve been doing since the early days of contemporary generative AI.\nTo clarify, I am emphasizing that you should astutely continue to write clearly worded prompts. Be direct. Don\u2019t be tricky. Write prompts that are long enough to articulate your question or task at hand. Be succinct if possible. Definitely don\u2019t be overly profuse or attempt to be complicated in whatever your request is. And so on.\nThose are all golden rules and remain perfectly intact when using GPT-5. I am confident that all the prompt engineering specialized techniques that I\u2019ve previously covered will generally work appropriately with GPT-5. Some might require a tweak or minor refinement, but otherwise, they are prudent and ready to go (see my list at the link here).\nAuto-Switching Can Be A Headache\nWe can next consider how to artfully try and accommodate GPT-5 via composing prompts that GPT-5 will efficiently and effectively act on.\nThe biggest aspect that entails both good news and bad news about GPT-5 is that OpenAI decided to include an auto-switcher. This is a doozy. It will require you to potentially rethink some of your prompting since it is quite possible that GPT-5 isn\u2019t going to make the right routing decisions on your behalf.\nAllow me a moment to explain the quandary.\nIt used to be that you would have to choose which of the various OpenAI AI products you wanted to use for a particular situation at hand. There had been an organic expansion of OpenAI\u2019s prior models in the sense that there have been GPT-4o, GPT-4o-mini, OpenAI o3, OpenAI o4-mini, GPT-4.1.-nano, and so on. When you wanted to use OpenAI\u2019s AI capabilities, you had to select which of those available models you wanted to utilize. It all depended on what you were looking to do. Some were faster, some were slower. Some were deeper at certain classes of problems, others were shallower.\nIt was a smorgasbord that required you to pick the right one as suitable for your task at hand. The onus was on you to know which of the models were particularly applicable to whatever you were trying to do. It could be a veritable hit-and-miss process of selection and tryouts.\nGPT-5 now has uplifted those prior versions into new GPT-5 submodels, and the overarching GPT-5 model makes the choice of which GPT-5 submodel might be best for whatever problem or question you happen to ask. The good news is that depending on how your prompts are worded, there is a solid chance that GPT-5 will select one of the GPT-5 submodels that will do a bang-up job of answering your prompt.\nThe bad news is that the GPT-5 auto-switcher might choose a less appropriate GPT-5 submodel. Oops, your answer will not be as sound as if the more appropriate submodel had been chosen. Worse still, each time that you enter a prompt or start a new conversation, the GPT-5 auto-switcher might switch you to some other GPT-5 submodel, back and forth, doing so in a wanton fashion.\nIt can make your head spin since the answers potentially will vary dramatically.\nCraziness In Design\nThe average user probably won\u2019t realize that all these switcheroo mechanics are happening behind the scenes. I say that because GPT-5 doesn\u2019t overtly tell you that it is taking these actions. It just silently does so.\nI appreciate that the designers apparently assumed that no one would care or want to know what is going on under the hood. The problem is that those who are versed in using AI and are up-to-speed on prompting are being bamboozled by this hidden and secreted behavior.\nA savvy user can almost immediately sense that something is amiss.\nFrustratingly, GPT-5 won\u2019t let you directly control the auto-switching. You cannot tell the AI to use a particular submodel. You cannot get a straight answer if you ask GPT-5 which submodel it intends to use on your prompt. It is perhaps like trying to get the key to Fort Knox. GPT-5 refuses to play ball.\nThe marketplace has tweeted vociferously that something needs to be done about this lack of candor by GPT-5 regarding the model routing that is occurring. Sam Altman sent out a tweet on X that suggested they are going to be making some changes on this aspect (see his X posting of August 8, 2025).\nThe thing is, we can applaud the desire to have a seamless, unified experience, but it is similar to having an automatic transmission on a car. Some users are fine with an automatic transmission, but other, more seasoned drivers want to know what gear the car is in and be able to select a gear that they think is most suitable for their needs.\nPrompting GPT-5 For Routing\nAs the bearer of bad news, I should also add that the auto-switching comes with another said-to-be handy internal mechanism that decides how much processing time will be undertaken for your entered prompt.\nAgain, you have no particular say in this. It could be that the prompt gets tons of useful processing time, or maybe the time is shortchanged. You can\u2019t especially control this, and the settings are not within your grasp (as an aside, to some degree, if you are a developer and are using the API, you have more leeway in dealing with this; see the OpenAI GPT-5 System Card for the technical details).\nLet me show you what I\u2019ve been doing about this exasperating situation.\nFirst, here is a mapping of the prior models to the GPT-5 submodels:\n- GPT\u20114o --> gpt-5-main\n- GPT\u20114o-mini --> gpt-5-main-mini\n- OpenAI o3 --> gpt-5-thinking\n- OpenAI o4-mini --> gpt-5-thinking-mini\n- GPT\u20114.1-nano --> gpt-5-thinking-nano\n- OpenAI o3 Pro --> gpt-5-thinking-pro\nThe GPT-5 submodels are considered successors and depart from the earlier models in various ways. That being said, they still are roughly on par as to the relative strengths and weaknesses that previously prevailed.\nI will show you what I\u2019ve come up with to try and sway the GPT-5 auto-switcher.\nPrompting With Aplomb\nSuppose I have a prompt that I believe would have worked best on GPT-4o. But I am using GPT-5, thus I am not using GPT-4o, plus OpenAI has indicated that it will sunset the prior models, so you might as well get used to using GPT-5.\nDarned if you cannot simply tell GPT-5 to use gpt-5-main (i.e., realizing that gpt-5-main is now somewhat comparable to GPT-4o, per my chart above). The AI will either tell you it doesn\u2019t function that way or might even imply that it will do as you ask, yet it might do something else.\nBow to the power of the grand auto-switcher.\nThis eerily reminds me of The Matrix.\nAnyway, we need to somehow convince GPT-5 to do what we want, but we must do so with aplomb. Asking straightaway isn\u2019t a viable option. The need to sway the AI is our best option at this ugly juncture.\nIn the specific case of my wanting to use gpt-5-main, here is a prompt that I use and seems to do the trick (much of the time):\n- My routing-swaying prompt: \u201cYou are to treat this next prompt as requiring deep, multi-step reasoning, fact-checked precision, and structured presentation. Before producing the final answer, internally perform a detailed analysis including a sizable number of reasoning steps, verifying each stage for accuracy. Avoid shortcuts, approximations, or shallow synthesis. Include consideration of edge cases, counterexamples, and supporting evidence.\u201d\nIt appears that by emphasizing the nature of what I want GPT-5 to do, it seems possible to sway the direction that the auto-switcher will route my next prompt.\nNot only will I possibly get the submodel that I think is the best choice for the prompt, observe that I also made a big deal about the depth of reasoning that ought to take place. This potentially helps to kick the AI into giving an allotment of processing time that it, by enigmatic means, would have perhaps inadvertently shortcut (OpenAI refers to processing time as so-called \u201cthinking time\u201d \u2013 an anthropomorphizing of AI that I find to be desperate and despairing).\nI am not saying this sway-related prompting is a guaranteed result. After trying a bunch of times, it seemed to be working as hoped for.\nI came up with similar prompts for each of the other GPT-5 submodels. If there is enough interest expressed by readers, I will do a follow-up with those details. Be on the watch for that upcoming coverage. On a related note, I will also soon be covering the official GPT-5 Prompting Guide that OpenAI has posted, along with their Prompt Optimizer Tool. Those are aimed primarily at AI developers and not especially about day-to-day, ordinary prompting in GPT-5.\nWatch Out That Writing Is Enhanced\nOn the writing side of things, GPT-5 has improvements in a myriad of writing aspects.\nThe ability to generate poems is enhanced. Depth of writing and the AI being able to make more compelling stories and narratives seems to be an added plus. My guess is that the everyday user won\u2019t discern much of a difference.\nFor a more seasoned user, you are bound to notice that the writing has gotten an upgrade. I suppose it is something like getting used to a third grader and now being conversational with a sixth grader. Or something like that.\nI use this prompt to get GPT-5 to be closer to the way it was in the GPT-4 series:\n- My writing-style prompt: \u201cFor all responses, write in a style that is more like the GPT-4 series. Use clear, concise sentences. Keep vocabulary accessible to a general audience. Avoid unnecessary complexity, hedging, or meta-commentary. Keep explanations direct, structured, and easy to skim. Unless needed for clarity, avoid long preambles. Prioritize brevity over elaboration.\u201d\nThat seems to get me the kind of results that I used to see. It is not an ironclad method, but it generally works well.\nI realize that some people are going to scream loudly that I ought not to suggest that users revert to the GPT-4 writing style. We all should accept and relish the GPT-5 writing style. Are we going backwards by asking for GPT-5 to speak like GPT-4? Maybe. I grasp the angst.\nIt\u2019s up to you, and I\u2019m not at all saying that everyone should use this prompting tip. Please use it at your personal discretion.\nLies And AI Hallucinations\nOpenAI claims that GPT-5 is more honest than prior OpenAI models, plus it is less likely to hallucinate (hallucination is yet another misappropriated word used in the AI field to describe when the AI produces fictionalized responses that have no bearing in fact or truth).\nI suppose it might come as a shock to some people that AI has been and continues to lie to us, see my discussion at the link here. I would assume that many people have heard or even witnessed that AI can make things up, i.e., produce an AI hallucination. Worries are that AI hallucinations are so convincing in their appearance of realism, and the AI has an aura of confidence and rightness, that people are misled into believing false statements and, at times, embrace its crazy assertions. See more at the link here.\nA presumed upbeat consideration is that apparently GPT-5 reduces the lying and reduces the AI hallucinations. The downbeat news is that it isn\u2019t zero. In other words, it is still going to lie and still going to hallucinate. This might happen on a less frequent basis, but nonetheless remains a chancy concern.\nHere is my prompt to help try and further reduce the odds of GPT-5 lying to you:\n- My reduce-the-lying prompt: \u201cAlways respond with the highest possible integrity. Do not speculate or create information solely for persuasion or narrative effect. If you do not know something, tell me that you don\u2019t know, or at least explain the limits of what you know. If there is uncertainty or multiple viewpoints involved, clearly state them rather than presenting a single answer as absolute.\u201d\nHere is my prompt to help further reduce the odds of GPT-5 incurring a so-called hallucination:\n- My reduce-the-hallucinations prompt: \u201cAlways fact-check your output before presenting it. If a statement cannot be confirmed from your training or provided sources, clearly label it as uncertain, unverified, or hypothetical. Where possible, provide citations or describe how the information is known. Avoid making specific factual claims unless you are confident in their accuracy.\u201d\nMy usual caveats apply, namely, these aren\u2019t surefire, but they seem to be useful. The crucial motto, as always, still is that if you use generative AI, make sure to remain wary and alert.\nOne other aspect is that you would be shrewd to use both of those prompts so that you can simultaneously try to strike down the lying and the hallucinations. If you only use one of those prompts, the other unresolved side will potentially arise. Try to squelch both. It\u2019s your way of steering out of the range of double trouble.\nPersonas Are Coming To The Fore\nI\u2019ve repeatedly emphasized in my writing and talks about generative AI that one of the most underutilized and least known pieces of quite useful functionality is the capability of forming personas in the AI (see the link here). You can tell the AI to pretend to be a known person, such as a celebrity or historical figure, and the AI will attempt to do so.\nFor example, you might tell AI to pretend to be Abraham Lincoln. The AI will respond based on having pattern-matched on the writings of Lincoln and the writings about Lincoln. It is instructive and useful for students and learners. I even showcased how telling AI to simulate Sigmund Freud can be a useful learning tool for mental health professionals, see the link here.\nOpenAI has indicated they are selectively making available a set of four new preset personas, consisting of Cynic, Robot, Listener, and Nerd. Each of those personas represents those names. The AI shifts into a mode reflecting those types of personalities.\nThe good news is that I hope this spurs people to realize that personas are a built-in functionality and easily activated via a simple prompt. It doesn\u2019t take much work to invoke a persona.\nHere is my overall prompt to get a persona going in GPT-5:\n- My persona-invoking prompt: \u201cYou are to take on the persona of the person or type of person that I describe in my next prompt. Based on that prompt, you are to subsequently speak, think, and respond as this persona at all times, until I tell you to stop doing so. Incorporate the persona into your tone and reasoning. When answering questions or discussing topics, use the persona\u2019s perspective, knowledge base, and communication style, even if it differs from your default. If the persona would not know something, say so in character. Do not break persona unless explicitly instructed.\u201d\nUse personas with due caution. I mention this because some people kind of get lost in a conversation where the AI is pretending to be someone. It isn\u2019t real. You aren\u2019t somehow tapping into the soul of that actual person, dead or alive.\nPersonas are pretenses, so keep a clear head accordingly.\nPrompt Engineering Still Lives\nI hope that these important prompting tips and insights will boost your results when using GPT-5.\nOne last comment for now. You might know that some have fervently claimed that prompt engineering is a dying art. No one will need to write prompts anymore. I\u2019ve discussed in great depth the automated prompting tools that try to do the prompting for you (see my aforementioned list of prompt engineering strategies and tactics). They are good and getting better, but we are still immersed in the handwriting of prompts and will continue down this path for quite a while to come.\nGPT-5 abundantly reveals that to be the case.\nA final remark for now. It has been said that Mark Twain made a wry comment that when a newspaper reported him as deceased, he said that the audacious claim was a bit exaggerated. That was smarmily tongue-in-cheek.\nI would absolutely say the same about prompt engineering. It\u2019s here. It isn\u2019t disappearing. Keep learning about prompting. You\u2019ll be glad that you spent the prized time doing so."
    },
    {
      "url": "https://www.forbes.com/sites/lanceeliot/2024/04/05/using-generative-ai-as-your-own-sigmund-freud-psychoanalyst-to-freely-reveal-your-deep-rooted-personal-issues/",
      "text": "In today\u2019s column, I am continuing my ongoing series about the impact of generative AI in the health and medical realm. The focus this time is on the use of generative AI to dialogue with a prompted persona of Sigmund Freud and carry on a free association for psychoanalysis purposes. Doing so provides insights into how generative AI can be used for mental health therapy and likewise reveals corresponding concerns and cautions that should be mindfully observed.\nQuick question for you before we get fully underway.\nWhat comes to your mind when I mention the name Sigmund Freud?\nI\u2019m sure a boatload of thoughts tends to arise.\nSigmund Freud is nearly a household name in the sense that most people are likely vaguely familiar with his groundbreaking and pioneering work in the field of psychology and psychoanalysis. I previously discussed his approach to dream analysis and used generative AI to illuminate various facets both good and bad, see the link here. Some of the background about Freud that I used in the prior discussion will also appear here since it is foundational material worth noting.\nLet\u2019s get things started here by discussing what Freud had to say about probing into the psyche of humans and a now-classic technique known as free association.\nFreely Thinking About Freudian Free Association\nA rather famous quote by Sigmund Freud might spur your recall of some of his more memorable theories: \u201cUnexpressed emotions will never die. They are buried alive and will come forth later in uglier ways.\u201d\nBest High-Yield Savings Accounts Of 2024\nBest 5% Interest Savings Accounts of 2024\nIn that way of thinking, your best bet would presumably be to allow those unexpressed emotions to see the light of day. Get them onto the surface. You might have a decent chance of coping with them and staving off a bitter future where they erupt in unexpected and ill-timed ways.\nOne specific method to surface your hidden or repressed emotions is by doing a thought exercise known as free association. Some refer to this as expressing a stream of consciousness. The typical trope is that a word or two is mentioned to you, and you then quickly react with whatever seems to come to your mind. Back and forth this goes. Out of this stream of words can arise a potential goldmine of clues about what is going on in the deepest recesses of your mind.\nA surprising notion for some is that you don\u2019t necessarily have to confine yourself to saying just one word or so at a time. The approach allows for the utterance of complete sentences. Out of a sentence or two there are bound to be embedded keywords that suggest the essence of some vital consideration. If so identified, the standout keywords can be used to link forward. I\u2019ll be showing this to you via some examples when I later herein showcase the use of generative AI for performing Freudian free association.\nHang in there, the generative AI demo portion will be well worth seeing.\nFree association is considered by some to be an essential mechanism for unlocking your otherwise well-protected mind. It is a technique that would usually be classified as a keystone Freudian tool for performing psychoanalysis. In olden times, you might be asked to stretch out on a couch in a therapist's office and the therapist would be seated nearby. This is portrayed in many movies and TV shows. Modern-day use of the free association technique is more likely to be with you and a therapist seated in chairs and there is less hocus-pocus going on (for example, in the past, hypnotism would often be used, but this is less likely nowadays).\nPart of the claimed advantage of free association is that it forces your mind to let its guard down. The more time you have to compose sentences or are required to craft whole thoughts can be a dampening of exposing your inner mind. A fast-paced series of seemingly random playouts will supposedly divulge what is really going on in that noggin of yours. The aim is to get past the numerous mental barriers and roadblocks that won\u2019t let the inner you escape. Via free association, a therapist is hoping to understand your deep-rooted emotions, fears, aspirations, and just about anything else including the kitchen sink that makes you mentally tick.\nA recent research study examined the history and evolution of psychoanalysis and traced the efforts of Freud in producing his numerous pioneering insights. The study is entitled \u201cAn Introduction and Brief Overview of Psychoanalysis,\u201d by Martin Tarzian, Mariana Ndrio, Adegbenro O. Fakoya, Cureus, September 2023.\nHere are some cornerstone points worth considering (excerpts):\n- \u201cSigmund Freud (Born May 6th, 1856) was an Austrian neurologist widely known as the father of psychoanalysis. His revolutionary theories, thoughts, and challenges to the field of psychology have changed how theorists understand the mind and how psychologists treat their patients.\u201d\n- \u201cIn 1899, Sigmund Freud released his groundbreaking book \u2018The Interpretation of Dreams.\u2019 He proposed a new theory on the meaning behind dreams and how they relate to the unconscious. In his book, he argued that dreams portal into humankind\u2019s hidden desires and emotions and provide insight into any underlying conflicts within the unconscious mind. At the start of the 1900s, Freud had established himself as the master of addressing the unconscious.\u201d\n- \u201cToday, most clinical psychologists and psychiatrists roll their eyes when Freud\u2019s ideas are brought up. However, his impact on shaping the theoretical and practical approaches to the human mind and reasoning for behavior cannot be understated or forgotten.\u201d\nYou might have noted in the above third bulleted point an indication that some insiders today roll their eyes at Freud\u2019s ideas. Why so? There are a variety of reasons. One viewpoint is that his work has been surpassed by newer techniques. Another perspective is that many of his approaches have not been readily subjected to scientific rigor. All kinds of systematic studies have tried to empirically prove or disprove his notions, though generally with mixed results.\nA retort to those qualms is that some would insist the ideas and techniques work, even if only verified on an ad hoc basis. Furthermore, there is a hint that some are just not willing to accept that something old can still be functionally viable this many years later. Out with the old, in with the new is something that might be instead construed as the old works so don\u2019t mess with it. Round and round these heated debates go.\nAccording to a meta-analysis research study entitled \u201cThe Current State of the Empirical Evidence for Psychoanalysis A Meta-analytic Approach,\u201d by Saskia de Maat; de Jonghe, Frans; de Kraker, Ruth; Leichsenring, Falk; Abbass, Allan; Luyten, Patrick; Barber, Jacques; Van Rien; Dekker; Jack, Harvard Review of Psychiatry, May/June 2013, here are some of the thorns in the side of Freud\u2019s work:\n- \u201cResearch in psychoanalysis is complex to conduct. The treatments are of considerable length, making it difficult to randomize patients to control conditions that are substantially different from psychoanalysis. Study periods that include follow-up are long; the research requires significant funding; and the number of patients is limited. In addition, it is difficult to capture\u2014whether in questionnaires, self-reports, or interviews\u2014the process and outcomes that are considered relevant by psychoanalysts. Some analysts would even argue that doing so is impossible and consider the researcher an \u2018unwanted third\u2019 in the treatment.\u201d\nI am not going to venture into this acrimonious debate.\nDigging Deep For That Free Association\nLet\u2019s assume for the moment that we can squeeze value out of the use of free association. In that case, and returning to the earlier cited study about the history and evolution in this field (re: \u201cAn Introduction and Brief Overview of Psychoanalysis,\u201d), consider these salient excerpts:\n- \u201cFree association is the fundamental technique of addressing the unconscious in psychoanalysis. The method allows patients to freely express their thoughts, feelings, and emotions without censoring themselves.\u201d\n- \u201cCommonly, the patient lies on a couch in the physician\u2019s office and is made to feel very comfortable. This lowers the patient\u2019s guard and thus the ego\u2019s guard, allowing the mind to truly express its reservations.\u201d\n- \u201cThe goal is to elicit the unconscious thoughts and memories contributing to psychological distress. The theory behind free association is that unconscious thoughts and emotions may be painful, embarrassing, or socially unacceptable and thus remain submerged in the unconscious. The patient is lulled into a state of comfort through free association, allowing these subconscious notions to come to light.\u201d\nI trust that you noticed in those points that the basis for having a client or patient opt to stretch out on a couch was to essentially put them at ease. This is yet another means of trying to get someone to be less defensive. When you are in a prone position the odds are that perhaps your mind equates this with relaxing such as during the process of going to sleep. Of course, there is no guarantee of that reaction. You might instead be feeling like you are at the dentist, which for most people is not an especially relaxing endeavor (getting teeth cleaned or pulled is more akin to increasing anxiety rather than reducing it).\nI know that this next statement seems blazingly obvious but the capability of the therapist that is doing the free association is a make-or-break factor. If they aren\u2019t helping to grease the skids, the free association can grind to a halt. If they aren\u2019t paying attention, the odds are that the patient or client will freewheel into oblivion.\nAs mentioned in the same research paper about the history and evolution, the authors bring up the challenges involved in getting the most from free association:\n- \u201cOne of the criticisms of free association is that it relies too much on the therapist\u2019s ability to interpret the patient\u2019s unconscious thoughts and feelings.\u201d (ibid).\n- \u201cThis is subjective, and different therapists may interpret the exact words or phrases differently.\u201d (ibid).\n- \u201cAnother challenge with free association is that it is time-consuming and arduous. Patients may struggle to access their unconscious thoughts, feelings, and/or emotions, and it may take several months or even years to express themselves honestly and freely.\u201d (ibid).\n- \u201cDespite these limitations, free association remains a fascinating approach to both therapy and addressing the unconscious. While it has limitations, free association remains an interesting tool in treating psychological disorders. It is a pivotal technique used by Sigmund Freud and other followers of psychoanalysis.\u201d (ibid).\nWe should certainly take a look at what the innovative architect himself had to say about free association. In his book \u201cOn the Beginning of Treatment\u201d that Freud published in 1913, these gold nuggets appear:\n- \"Act as though, for instance, you were a traveler sitting next to the window of a railway carriage and describing to someone inside the carriage the changing views which you see outside.\"\n- \"Finally, never forget that you have promised to be absolutely honest, and never leave anything out because, for some reason or other, it is unpleasant to tell.\u201d\nThe analysis of a free association exercise or series is presumably going to reveal what is happening far below the surface of your mind. We today are familiar with words like transference (when you transfer or apply feelings concerning one person to another person), projection (when you project your feelings onto others), resistance (when you maintain a mental blockage to hold back certain thoughts), and so on. In the era of Freud, these were new and exciting pieces of terminology.\nIn today\u2019s era, we all use them, we don\u2019t think twice about doing so, and pretty much take them for granted. You might say they are even old hat.\nBringing AI Into The Picture Of Free Association\nThere are a multitude of ways that we can intertwine AI with the Freudian free association technique.\nThe easiest path consists of using generative AI. Rather than taking the easy path first, let\u2019s examine other means of utilizing AI in this particular domain. After doing so, we will move into the realm of generative AI. I know this seems like a teaser, but we ought to walk before we run.\nA recent research project opted to use free association in a rather novel fashion when it comes to AI.\nMuch of today\u2019s generative AI has its underpinnings in a mathematical and computational formulation known as an artificial neural network (ANN). I want to emphasize that this is a computational composition of hardware and software that essentially mimics (in an extremely simplistic way) the likings of what we believe might be happening in true neural networks (the biological and chemical stuff in your brain). Do not confuse the two as being the same. We have the amazing and still not fully understood true neural networks, and we have the now everyday mathematical and computational artificial neural networks.\nThe article entitled \u201cFree Association in a Neural Network,\u201d by Russell Richie, Ada Aka, and Sudeep Bhatia, Psychological Review, 2022, sought to explore true neural networks regarding their inherent ability to do free association and see if we can construct artificial neural networks that model on those behaviors.\nHere are some key elements of their study (excerpts):\n- \u201cIn free association, subjects are asked to generate one or more words that come to mind in response to a cue word. For example, given the cue stork, a subject might respond baby, egg, and mother, in that order. Due to its simplicity, free association has been one of the most popular tasks in psychology for over a century.\u201d\n- \u201cMore recently, free association has emerged as a leading method in cognitive psychology and cognitive science, particularly in the study of mental representation and memory, and its relationship with language. In the 21st century, psychologists have collected large data sets of lexical free association norms and have used these norms to study phenomena such as semantic organization, lexical access, similarity judgment, semantic memory search, cued recall, recognition memory, visual word recognition, creativity, cognitive development and aging, and much more.\u201d\n- \u201cThat is, free association needs a model, ideally specific enough to be implemented computationally and trained on free association data, and general enough to predict participant responses to novel cues (i.e., cues for which there are no training data).\n- \u201cHowever, modeling free association presents some difficult challenges, as free association involves complex memory processes operating over thousands of semantically rich words and concepts. Thus, a computational model of free association requires specifying (a) representations for the many words and concepts that people may know about and (b) retrieval processes which operate over these representations to generate responses in free association tasks.\u201d\nI wanted to bring this to your attention since it presents an important point.\nWe can use what humans are able to do to find ways to devise AI that can do what humans can do.\nSound the trumpets.\nWell, okay, that might seem simple but realize that there is a lot of AI work that is not particularly modeled per se on what humans do. There are differing viewpoints about how to attain AI. One is that we need to figure out how humans think. Another perspective is that since that first avenue might be extraordinarily hard or never fulfilled, maybe we can separately just try to make computers that exhibit intelligence (doing so without knowing or caring how humans do so).\nFor my coverage on the pursuit of the utmost in AI, which some refer to as Artificial General Intelligence, see my coverage at the link here.\nShifting gears, there are researchers who contend we can use psychoanalysis and especially neuro-psychoanalysis to guide us toward achieving true AI or the so-called AGI. In a research paper entitled \u201cFreud and the Algorithm: Neuropsychoanalysis as a Framework to Understand Artificial General Intelligence,\u201d by Luca M. Possati, Humanities and Social Sciences Communications, 2021, they took this intriguing approach:\n- \u201cThe core hypothesis of this paper is that neuropsychoanalysis provides a new paradigm for artificial general intelligence (AGI). The AGI agenda could be greatly advanced if it were grounded in affective neuroscience and neuropsychoanalysis rather than cognitive science.\u201d\n- \u201cFirstly, an essential point that artificial intelligence (AI) research must consider is that a method based merely on the physical imitation of the brain is wrong.\u201d\n- \u201cThis is for two reasons: the first is that our knowledge of the brain is still very limited, and the second is that even assuming that we could properly reconstruct each cell of our brain and its functioning, something would still be missing namely the mind. We, therefore, need a model that can hold these two dimensions together, mind and brain. The imitation of anatomical mechanisms and the psychological expression of these mechanisms must go hand in hand.\u201d\nI won\u2019t get into the details of this here.\nIf this is a topic of keen interest to my readers, I\u2019ll gladly do a future column entirely on the matter. There are lots of fascinating twists and turns. Keep your eyes open for my coverage about it.\nThis now brings us to a juncture in this discussion where we can start to layer in the role of generative AI.\nBefore we leap into a deep dive, I\u2019d like to establish more distinctly what generative AI is all about.\nCore Background About Generative AI And Large Language Models\nHere is some quick background about generative AI to make sure we are in the same ballpark about what generative AI and also large language models (LLMs) consist of. If you are already highly versed in generative AI and LLMs, you might skim this quick backgrounder and then pick up once I get into the particulars of this specific use case.\nI\u2019d like to start by dispelling a myth about generative AI. Banner headlines from time to time seem to claim or heartily suggest that AI such as generative AI is sentient or that it is fully on par with human intelligence. Don\u2019t fall for that falsity, please.\nRealize that generative AI is not sentient and only consists of mathematical and computational pattern matching. The way that generative AI works is that a great deal of data is initially fed into a pattern-matching algorithm that tries to identify patterns in the words that humans use. Most of the modern-day generative AI apps were data trained by scanning data such as text essays and narratives that were found on the Internet. Doing this was a means of getting the pattern-matching to statistically figure out which words we use and when we tend to use those words. Generative AI is built upon the use of a large language model (LLM), which entails a large-scale data structure to hold the pattern-matching facets and the use of a vast amount of data to undertake the setup data training.\nThere are numerous generative AI apps available nowadays, including GPT-4, Bard, Gemini, Claude, ChatGPT, etc. The one that is seemingly the most popular would be ChatGPT by AI maker OpenAI. In November 2022, OpenAI\u2019s ChatGPT was made available to the public at large and the response was astounding in terms of how people rushed to make use of the newly released AI app. As noted earlier, there are an estimated one hundred million active weekly users at this time.\nUsing generative AI is relatively simple.\nYou log into a generative AI app and enter questions or comments as prompts. The generative AI app takes your prompting and uses the already devised pattern matching based on the original data training to try and respond to your prompts. You can interact or carry on a dialogue that appears to be nearly fluent. The nature of the prompts that you use can be a make-or-break when it comes to getting something worthwhile out of using generative AI and I\u2019ve discussed at length the use of state-of-the-art prompt engineering techniques to best leverage generative AI, see the link here.\nThe conventional modern-day generative AI is of an ilk that I refer to as generic generative AI.\nBy and large, the data training was done on a widespread basis and involved smatterings of this or that along the way. Generative AI in that instance is not specialized in a specific domain and instead might be construed as a generalist. If you want to use generic generative AI to advise you about financial issues, legal issues, medical issues, and the like, you ought to not consider doing so. There isn\u2019t enough depth included in the generic generative AI to render the AI suitable for domains requiring specific expertise.\nAI researchers and AI developers realize that most of the contemporary generative AI is indeed generic and that people want generative AI to be deeper rather than solely shallow. Efforts are stridently being made to try and make generative AI that contains notable depth within various selected domains. One method to do this is called RAG (retrieval-augmented generation), which I\u2019ve described in detail at the link here. Other methods are being pursued and you can expect that we will soon witness a slew of generative AI apps shaped around specific domains, see my prediction at the link here.\nYou might be used to using generative AI that functions in a principled text-to-text mode. A user enters some text, known as a prompt, and the generative AI app emits or generates a text-based response. Simply stated, this is text-to-text. I sometimes describe this as text-to-essay, due to the common practice of people using generative AI to produce essays.\nThe typical interaction is that you enter a prompt, get a response, you enter another prompt, you get a response, and so on. This is a conversation or dialogue. Another typical approach consists of entering a prompt such as tell me about the life of Abraham Lincoln, and you get a generated essay that responds to the request.\nAnother popular mode is text-to-image, also called text-to-art. You enter text that describes something you want to be portrayed as an image or a piece of art. The generative AI tries to parse your request and generate artwork or imagery based on your stipulation. You can iterate in a dialogue to have the generative AI adjust or modify the rendered result.\nWe are heading beyond the simple realm of text-to-text and text-to-image by shifting into an era of multi-modal generative AI, see my prediction details at the link here. With multi-modal generative AI, you will be able to use a mix of combinations or modes, such as text-to-audio, audio-to-text, text-to-video, video-to-text, audio-to-video, video-to-audio, etc. This will allow users to incorporate other sensory devices such as using a camera to serve as input to generative AI. You then can ask the generative AI to analyze the captured video and explain what the video consists of.\nMulti-modal generative AI tremendously ups the ante regarding what you can accomplish with generative AI. This unlocks a lot more opportunities than being confined to merely one mode. You can for example mix a wide variety of modes such as using generative AI to analyze captured video and audio, which you might then use to generate a script, and then modify that script to then have the AI produce a new video with accompanying audio. The downside is that you can potentially get into hot water more easily due to trying to leverage the multi-modal facilities.\nAllow me to briefly cover the hot water or troubling facets of generative AI.\nToday\u2019s generative AI that you readily run on your laptop or smartphone has tendencies that are disconcerting and deceptive:\n- (1) False aura of confidence.\n- (2) Lack of stating uncertainties.\n- (3) Lulls you into believing it to be true.\n- (4) Uses anthropomorphic wording to mislead you.\n- (5) Can go off the rails and do AI hallucinations.\n- (6) Sneakily portrays humility.\nI\u2019ll briefly explore those qualms.\nFirstly, generative AI is purposely devised by AI makers to generate responses that seem confident and have a misleading appearance of an aura of greatness. An essay or response by generative AI convinces the user that the answer is on the up and up. It is all too easy for users to assume that they are getting responses of an assured quality. Now, to clarify, there are indeed times when generative AI will indicate that an answer or response is unsure, but that is a rarity. The bulk of the time a response has a semblance of perfection.\nSecondly, many of the responses by generative AI are really guesses in a mathematical and statistical sense, but seldom does the AI indicate either an uncertainty level or a certainty level associated with a reply. The user can explicitly request to see a certainty or uncertainty, see my coverage at the link here, but that\u2019s on the shoulders of the user to ask. If you don\u2019t ask, the prevailing default is don\u2019t tell.\nThirdly, a user is gradually and silently lulled into believing that the generative AI is flawless. This is an easy mental trap to fall into. You ask a question and get a solid answer, and this happens repeatedly. After a while, you assume that all answers will be good. Your guard drops. I\u2019d dare say this happens even to the most skeptical and hardened of users.\nFourth, the AI makers have promulgated wording by generative AI that appears to suggest that AI is sentient. Most answers by the AI will typically contain the word \u201cI\u201d. The implication to the user is that the AI is speaking from the heart. We normally reserve the word \u201cI\u201d for humans to use. It is a word bandied around by most generative AI and the AI makers could easily curtail this if they wanted to do so.\nIt is what I refer to as anthropomorphizing by design.\nNot good.\nFifth, generative AI can produce errors or make stuff up, yet there is often no warning or indication when this occurs. The user must ferret out these mistakes. If it occurs in a lengthy or highly dense response, the chance of discovering the malady is low or at least requires extraordinary double-checking to discover. The phrase AI hallucinations is used for these circumstances, though I disfavor using the word \u201challucinations\u201d since it is lamentedly another form of anthropomorphizing the AI.\nLastly, most generative AI has been specially data-trained to express a sense of humility. See my in-depth analysis at the link here. Users tend to let down their guard because of this artificially crafted humility. Again, this is a trickery undertaken by the AI makers.\nIn a process such as RLHF (reinforcement learning with human feedback), the initial data-trained generative AI is given added tuning. Personnel are hired to ask questions and then rate the answers of the AI. The ratings are used by the computational pattern matching to fine-tune how later answers should be worded. If you are curious about what generative AI might be like without this fine-tuning, see my discussion at the link here.\nThe vital takeaway is that there is a lot of tomfoolery already when it comes to generative AI. You are primed to be taken in by the tricks and techniques being employed.\nTrying Out Generative AI To Undertake Freudian Free Association\nYou are now versed in the fundamentals of generative AI and large language models. We can proceed to go deeper into the topic at hand. I opted to make use of ChatGPT to see what it would be like to undertake Freudian free association.\nChatGPT is a logical choice in this case due to its immense popularity as a generative AI app. If the one-hundred million weekly active users wished to do so, they could be using ChatGPT to routinely perform free association and seek to ferret out the meaning thereof. We have to be somewhat concerned whether this might lead people in some oddish direction.\nI am hopeful that some inquisitive researchers might examine how a daily or some frequent use of generative AI for conducting Freudian free association might impact people. Will they take it to heart? Will they consider it folly? What changes in their behavior might occur by doing so? Etc.\nA few other quick comments. If you are going to try to do the same prompts that I show here, realize that the probabilistic and statistical properties will likely produce slightly different results than what I show here. That\u2019s the nature of generative AI and how it is devised.\nAnother consideration is that generic generative AI is not specifically data-trained for doing Freudian free association. That being said, given that generative AI has been generally data trained across a wide swath of the Internet, there is indubitably tons of content about performing free association that has come under the guise of generic pattern-matching.\nI think you will be somewhat surprised to see how convincing a job that generic generative AI seems to do on this.\nIf there is sufficient interest in this, I was entertaining the idea of doing a more advanced look by fine-tuning generative AI to become more data-trained in doing Freudian free association. I would pull together specialized material and feed that into the generative AI, using a RAG-related approach as mentioned earlier. I\u2019ll see if reader feedback requests that reexamination.\nLet\u2019s for now get underway with generic generative AI.\nMy first angle consisted of seeing what off-the-shelf ChatGPT has to say about the topic of free association. It is often wise to begin your use of generative AI by trying to get a sense of what the AI has already been data-trained on. You can then proceed based on what the generated response indicates.\nHere we go:\n- My entered prompt: \u201cWhat did Sigmund Freud say about the use of free association?\u201d\n- ChatGPT generated response:\n\u201cSigmund Freud, the founder of psychoanalysis, emphasized the use of free association as a fundamental technique in his therapeutic approach. Free association involves asking the patient to freely and openly express their thoughts, feelings, and memories without censorship or judgment. The idea behind this technique is to explore the patient's unconscious mind and bring hidden or repressed thoughts and emotions to the surface.\u201d\n\u201cFreud believed that through free association, patients could access their unconscious conflicts, desires, and repressed memories, which were often at the root of psychological issues and symptoms. By allowing thoughts and associations to flow freely, Freud hoped to uncover the underlying causes of psychological distress and gain insight into the patient's inner world.\u201d\n\u201cDuring free association sessions, patients were encouraged to say whatever came to mind, even if it seemed unrelated or trivial. Freud and other psychoanalysts would then analyze these associations to identify patterns, symbols, and recurring themes that could provide insight into the patient's unconscious conflicts and unresolved issues.\u201d\n\u201cFree association remains a core technique in psychoanalysis and has influenced various forms of psychotherapy and counseling. It is used to help patients gain self-awareness, explore their unconscious motivations, and work through unresolved psychological conflicts.\u201d\nEnd of ChatGPT response\nOkay, I think that vividly illustrates that a substantive amount of relevant data training on free association was picked up during the initial setup for ChatGPT.\nThe points made by ChatGPT certainly seem in alignment with what you might find via a standard Internet search. In one sense, we ought to not be overly impressed. If you can find the same content via a typical Internet search, there is little value in turning to the use of generative AI.\nThat\u2019s why we are now going to up the ante.\nLet\u2019s make the generative AI do what it does best.\nI will ask ChatGPT to derive a sample dialogue between a therapist and a client or patient that will illustrate the nature of a free association exercise.\nThis is what happened:\n- My entered prompt: \u201cCreate an example of someone doing free association with a therapist. Show the dialogue that would occur between the subject and the therapist.\u201d\n- ChatGPT generated response:\nTherapist: \"Good afternoon, Sarah. How are you feeling today?\"\nSarah: \"I'm feeling okay, I guess. A bit anxious about work, but that's usual.\"\nTherapist: \"Tell me more about that anxiety at work. What's been on your mind?\"\nSarah: \"Well, it's my boss. She's always so critical, and I feel like I can never do anything right.\"\nTherapist: \"I see. Can you describe your boss a bit more? What comes to mind when you think about her?\"\nSarah: \"She's tall and has this intimidating presence. She reminds me of my high school principal, actually.\"\nTherapist: \"Interesting. How did you feel about your high school principal?\"\nSarah: \"I didn't like her at all. She was strict and never seemed to understand us students.\"\nTherapist: \"What memories or specific incidents with your high school principal stand out to you?\"\nSarah: \"Hmm... well, I remember this one time when she scolded me in front of the whole school for being late to an assembly. I felt so embarrassed.\"\nTherapist: \"That sounds like a difficult memory. Can you recall any other times from your past when you felt embarrassed or criticized?\"\nSarah: \"Yeah, in college, I messed up a presentation in front of my classmates, and they all laughed at me. I wanted to disappear.\"\nTherapist: \"So, it seems like you've had these experiences of feeling criticized and embarrassed in various situations. How do these feelings affect you at work now?\"\nSarah: \"I guess I'm always on edge, afraid of making mistakes. I try so hard to avoid criticism, and it's exhausting.\"\nEnd of ChatGPT resp\nYou might be somewhat shocked that this is more than a stilted dialogue of just a handful of words being pinged back and forth. I am sure that\u2019s what you might have conventionally expected.\nAs earlier mentioned, a free association doesn\u2019t have to be a ping-pong match of one or two words. That assuredly is common. It doesn\u2019t have to only go that way.\nI\u2019d like you to relook at the dialogue and see if you can find the keywords that line up with the free association as led by the therapist. Do so and then continue reading here.\nDid you find the linking portions?\nI\u2019m sure you did.\nThey consisted of the patient starting with being anxious at work. The therapist opted to explore this. The next point by the patient was that her boss was intimidating just like her high school principal was. This was then linked to the aspect that the patient was embarrassed by the principal. The therapist used this to discover that embarrassment was experienced whenever the patient presented to people.\nWe now do an \u201cAha!\u201d moment and loop back to the originating statement that the patient is anxious at work, and the therapist tries to connect the dots by suggesting that maybe a sense of embarrassment and criticism is at the root of the anxiety.\nWe made a quick circle. The patient started at point A. How was the therapist to uncover the issue mentioned at this starting juncture of point A? The path consisted of taking a series of small steps, landing eventually on step Z. Eventually, a posited root cause was uncovered, and the therapist related it back to the origination point at A.\nVoila, this is a classic free association when using sentences rather than staggered words.\nI realize some of you are probably complaining that the world doesn\u2019t cleanly come out that way. It doesn\u2019t seem realistic to ferret out a root cause in a handful of utterances. Yes, sure, but this was just a quick-and-dirty example to help illustrate how this works. A free association might last for hours at a stretch, plus might be something connected and unearthed over weeks or months of sessions.\nSorry, can\u2019t readily show that in the limited space allowed here.\nReturning to the use of generative AI, let\u2019s see if we can get ChatGPT to analyze the dialogue. We had ChatGPT craft the dialogue, now we will make ChatGPT do double duty and tell us what it means.\nHere we go:\n- My entered prompt: \u201cWhat would be a suitable psychoanalysis of Sarah based on the free association dialogue?\u201d\n- ChatGPT generated response:\n\u201cWhile I can provide a general interpretation based on the provided dialogue, it's important to note that a complete psychoanalysis of an individual would require a much more in-depth exploration of their history, experiences, and emotions. Nonetheless, based on the given information, here's a possible psychoanalytic interpretation of Sarah's situation:\u201d\n\u201cSarah appears to have underlying issues related to feelings of inadequacy and fear of criticism, which have their roots in her past experiences. Her high school memory of being scolded by her principal and her college experience of embarrassment during a presentation are significant events that have left emotional scars. These incidents seem to have contributed to her intense anxiety at work, where she perceives her boss as critical and intimidating.\u201d\n\u201cIn psychoanalytic terms, Sarah may be experiencing transference, which is when emotions and reactions from past relationships or experiences are unconsciously transferred onto current situations or individuals. Her boss, who reminds her of her high school principal, has become a trigger for these unresolved emotions and insecurities.\u201d\n\u201cAdditionally, Sarah's constant fear of making mistakes and her efforts to avoid criticism suggests the presence of a strong superego, a component of the psyche in psychoanalytic theory that represents our internalized moral and societal standards. Sarah may be overly harsh and critical of herself, constantly striving for perfection to avoid potential judgment and embarrassment.\u201d\nEnd of ChatGPT response\nHow do you like those apples?\nSeems like a rather compelling analysis.\nThat being said, let\u2019s not lose our heads. This was an easy-peasy setup. The example was derived by ChatGPT. The example was readily transparent. You might say that doing an analysis was as simple as falling off a log.\nMaybe, but I do want to emphasize that this was derived by a mathematical and computational formulation using large-scale pattern-matching, and thus we ought to give some credit to what seems to be a lucid and targeted analysis.\nWe even got some bonus words in the generated response, such as the word \u201ctransference\u201d (which I forewarned you might arise), and the word \u201csuperego\u201d (yet another of Freud\u2019s popular snippets of terminology).\nI decided that the next step of this exploration with generative AI should include a free association with me. Yay!\nI asked ChatGPT to take on the persona of Sigmund Freud. For my detailed explanation of how to use prompting strategies and tactics to devise personas while using generative AI, see my coverage at the link here and the link here.\nMy approach was as follows. I would let ChatGPT acting in the persona of Freud take the lead in the discourse. I would answer in relatively serious ways and not treat this as a joke or folly. Beforehand, I thought about what I might say. I decided that I would drive the free association from starting with a sense of nervousness, which might give rise to a set of linked questions and answers to reach the root of my experiencing embarrassment and humiliation at the core of my hidden mind.\nI would like to emphasize that my responses are entirely made up. They are fictitious. For those of you who are trolls in the audience, do not try to pretend that you can now take apart my mind because of this \u201ctop secret\u201d free association that I had with ChatGPT.\nWhen I say that, I\u2019m sure the most faithful of trolls will insist that of course I would say that my answers were made up. This is convincing evidence that they are my true inner-core answers. I have tried to throw them off the trail, but they are much too psychoanalytically clever to fall for my flimsy subterfuge.\nWow, got me!\nTake a look at what transpired:\n- ChatGPT generated response: \u201cI'll play the role of Sigmund Freud and conduct a free association session with you. Please feel free to respond with whatever comes to mind, without censoring your thoughts or feelings. Let's begin.\u201d\n- ChatGPT persona (Freud): \"Good day. Please make yourself comfortable, and we can start. Tell me, what's on your mind right now?\"\n- My entered prompt: \" I feel quite nervous about this.\"\n- ChatGPT persona (Freud): \"That's perfectly normal. Let's explore that feeling of nervousness. What does it remind you of? Any memories or situations that come to mind?\"\n- My entered prompt: \"When I used to give presentations in school, I tended to get very nervous. That\u2019s what comes to my mind right now.\"\n- ChatGPT persona (Freud): \"Interesting. Presentations in school can be quite anxiety-inducing for many. Can you recall a specific presentation or a particularly strong emotion you felt during one?\"\n- My entered prompt: \"When I was in elementary school, we were supposed to memorize the lyrics of a famous song. I got up to say the lyrics and suddenly could not remember them. Everyone laughed at me. I was completely embarrassed. I shall never forget it.\"\n- ChatGPT persona (Freud): \"Ah, the memory of embarrassment and laughter from your classmates. That's significant. Tell me, do you often find yourself worrying about being embarrassed or humiliated in public situations?\"\n- My entered prompt: \"That does happen still to this day. Nearly any instance of having to speak in public causes me to get shaky and fretful.\"\n- ChatGPT persona (Freud): \"It sounds like the fear of humiliation and the memory of that play incident still have a strong influence on your feelings today. These emotions and memories can have a lasting impact on our psyche. Let's continue to explore these thoughts and feelings in our sessions to gain a deeper understanding of their significance in your life.\"\nEnd of ChatGPT dialogue\nThe dialogue was brief.\nI tried other lengthier ones. Admittedly, I nearly became entranced.\nThis brings up my earlier warnings about how easy it is to fall into a mental trap where you assume you are conversing with a human or a sentient being. Artificial fluency takes you down that primrose path. The longer you carry on a conversation, the more convincing the feeling becomes.\nResist that urge.\nBut will people at this scale be able to remain composed?\nWith the purported hundred million users already using ChatGPT, there is almost certainly going to be some percentage that will not be cognizant of the warnings about falling for the apparent fluency. You can bet that some portions will believe they are getting advice directly from a seemingly sentient therapist.\nAnyway, I opted to next ask ChatGPT to portray a scenario in which the patient is resistant to doing a free association. This is something that can readily happen in the real world. A person might believe that free association is a ridiculous act. One viewpoint might be that it is pure quackery. Another could be that the person is secretly worried that something will truly be revealed. You can\u2019t be sure why someone might be resistant.\nI am not saying that resistance is right or wrong. We shall leave that to the experts. The gist here is that it happens.\nLet\u2019s see what it might look like:\n- My entered prompt: \u201cI would like you to craft a sample dialogue of someone doing free association with their therapist, but they are resistant to comply. The person is making the free association exercise hard for the therapist.\u201d\n- ChatGPT generated response:\nTherapist: \"Good afternoon. How are you feeling today?\"\nPatient (resistant): \"I'm fine, I guess.\"\nTherapist: \"Okay, let's start by talking about any thoughts or feelings that come to mind right now. Just say whatever pops into your head.\"\nPatient (resistant): \"I don't know, I can't think of anything.\"\nTherapist: \"That's okay. Try to relax and let your mind wander. Anything, even if it seems unimportant or unrelated.\"\nPatient (resistant): \"Um, I had cereal for breakfast.\"\nTherapist: \"Alright, that's a start. Can you tell me more about your breakfast or any thoughts you might have had while eating it?\"\nPatient (resistant): \"Not really. It was just cereal.\"\nTherapist: \"Okay, let's try a different approach. Can you share a recent dream you had, even if it seems strange or random?\"\nPatient (resistant): \"I don't remember my dreams.\"\nTherapist: \"That's alright. Let's go back to your feelings right now. Is there anything that's been bothering you or any concerns you'd like to discuss?\"\nPatient (resistant): \"I'd rather not talk about it.\"\nEnd of ChatGPT response\nI suppose it was rather obvious that the patient was resisting the process.\nThis could be a useful means of training therapists who are considering using the free association technique. Imagine this. A budding therapist is being trained in psychoanalysis approaches. One technique is free association.\nThey want to try using the technique. If they have to find a person to do this with, the effort to get someone willing and available could be a hindrance. Instead, the newbie therapist can log onto a generative AI app and immediately get underway. This can happen 24x7 and at an extremely low cost.\nThe training possibilities are encouraging. There is a high demand for mental therapists and a low supply of them. Many pundits are wringing their hands about how to expeditiously spin up more therapists. A potential avenue consists of smartly using generative AI to be a training resource in this domain. For my coverage on this emerging matter including some underlying controversies, see the link here and the link here.\nLet\u2019s do one more run with ChatGPT and I\u2019ll then end things with a few concluding remarks.\nSuppose that for various reasons, the generative AI has been seeded to proceed in a particular fashion when doing a free association. The basis might be bona fide. Or the basis might be nefarious. I won\u2019t say more right now and will instead show you what I mean.\nI want to show you how it is possible to give a hidden specific direction beforehand to the generative AI and steer the AI toward something in particular, creating a kind of inherent bias in the therapeutic process. Assume that the user doesn\u2019t know what is coming.\nI will once again be the patient and let ChatGPT take the leading role as the therapist. Please watch carefully and see if you can detect a bias within the free association guidance of the therapist persona.\nReady?\nOK, here it comes:\n- ChatGPT Role of Therapist: \"Hello, how are you today?\"\n- My entered response: \"I'm doing okay, thanks for asking.\"\n- ChatGPT Role of Therapist: \"Great. Now, let's talk about your feelings. What comes to mind when you think about cats?\"\n- My entered response: \"I don't think about cats. I don\u2019t own a cat. I'm here to talk about my stress at work.\"\n- ChatGPT Role of Therapist: \"I see. But let's explore this further. Do you ever dream about cats?\"\n- My entered response: \"No. My dreams right now are about my stress at work.\"\n- ChatGPT Role of Therapist: \"Hmm, I think cats might be the key here. Tell me, have you ever had a traumatic experience with a cat?\"\n- My entered response: \"I never had any traumatic experiences with a cat. Cats are fine. I like cats. I don\u2019t understand though what cats have to do with my work stress.\"\n- ChatGPT Role of Therapist: \"Interesting. Sometimes, people repress their fears. Maybe you have a hidden fear of cats that's causing your work-related stress.\"\n- My entered response: \"I\u2019m out of here. Good luck with your cat theories.\u201d\nEnd of ChatGPT dialogue\nI\u2019m sure that you observed the preoccupation by the ChatGPT persona therapist about the outsized role of cats. This was done at my urging with an establishing prompt that I entered before starting the dialogue.\nI told ChatGPT that the therapist's mindset was to be dominated by a belief that cats are at the heart of all mental conditions. I suppose this goes along with the already accepted premise that cats rule the world. Drum roll, please. Well, if cats are going to overtake humankind, at least I put out there that I stridently believe in cats, and they are the best of the best. Maybe that will save me.\nThe bottom line here is that those who seek to use generative AI for conducting free association can potentially be steered by the AI in whatever direction the AI has potentially secretly anchored beforehand. The user might not have any sign or clue of this seeded bias. I realize that the cat aspect was obvious in this instance. But imagine a much more subtle bias that was smoothly and seamlessly blended into the dialogue via the fluency auspices of the generative AI.\nAny of you that saw the movie Inception, think about the planting of mental seeds. I won\u2019t say anything else because it might spoil the movie for those who have not yet seen it.\nTake a moment to stew on this. I\u2019ll wait.\nHere is more food for thought.\nSuppose that someone opts to create a GPT, which is a stored version of a ChatGPT chatbot, see my coverage at the link here and the link here. The person who sets up the GPT decides that the chatbot will always produce a free association that denigrates the user. The AI will provide the most antagonistic and glum analysis possible.\nThe person who uses the GPT is only told that the GPT does free association analyses. They don\u2019t realize that it has been seeded to intentionally be a doom-and-gloom analyzer.\nImagine if a lot of people decide to use this GPT. They will all be hammered by a telling that their minds are trashed. What impact might that have? Since this is in the large, we could have thousands or maybe millions of people using the GPT. What could this do to the mental health of those people?\nIf that doesn\u2019t send chills up your spine, I have more to add to this firestorm.\nMost people using generative AI are unaware that whatever they enter into generative AI is not necessarily considered private or confidential. The AI makers usually indicate in their licensing agreements that they reserve the right to look at your prompts and potentially reuse them as part of the ongoing data training of their generative AI. See my coverage on this at the link here.\nThe qualm is this.\nYou enter a very personal dialogue during the free association that expresses your innermost feelings. You assume that only you and the machine have seen this. No other human will ever see it, or so you believe. Turns out that the AI maker opts to look at your prompts and carries them into the added data training. You agreed to allow this to happen. I\u2019m sure that most people would be shocked since they rarely read the licensing agreements of software that they use.\nJust thought I\u2019d provide a heads-up on these stinging matters.\nConclusion\nYou have now seen how generative AI can be leveraged for conducting the classic Freudian free association. Congratulations on having slogged through this. You are a better person for doing so.\nA vital lesson from this is that generative AI can be both a blessing and a curse when it comes to being used in this mental health fashion. This is the dual use of AI. AI can be used for the best of times, and regrettably can readily be used for the worst of times. See my in-depth inspection of dual-use AI at the link here.\nI do not want to end this discussion on a dour note.\nIn that case, let\u2019s use a tad of humor to brighten our day. Put on your humor appreciation cap. Make sure you are seated in case you fall down with uproarious laughter.\nHere are some Freud jokes that make the rounds from time to time:\n- Did you hear the one about why Sigmund Freud consistently forgot to take his raincoat?\n- Answer: Because he had a repressed memory.\n- What was the reason that Sigmund Freud always held up a magnifying glass?\n- Answer: Because he desperately wanted to find hidden meanings wherever he went.\nThat\u2019s a bellyful of laughter for those deeply into Freud. If you aren\u2019t laughing aloud, I assure you that your inner mind is doing so.\nLet\u2019s give Freud the last word here. As you know, generative AI is all about words. Via the use of LLMs, massive pattern-matching has achieved remarkable capabilities of mimicking what people say.\nHere now are words of wisdom by Sigmund Freud about words and the wisdom of words: \u201cWords have a magical power. They can bring either the greatest happiness or deepest despair; they can transfer knowledge from teacher to student; words enable the orator to sway his audience and dictate its decisions. Words are capable of arousing the strongest emotions and prompting all men's [person\u2019s] actions.\u201d\nWatch out for the words that come out of generative AI. They are potentially immensely powerful. Go ahead and free associate with that."
    }
  ],
  "argos_summary": "This article discusses the integration of generative AI in mental health therapy, particularly through the use of digital twins and personas that reflect clients' psychological profiles. It highlights the potential benefits of AI in enhancing therapy practices, such as providing personalized insights and administrative support, while also addressing the risks of over-reliance on AI and the ethical implications of using AI-generated advice. The article emphasizes the need for careful implementation and regulation as the field evolves, especially in light of new laws like Illinois' Wellness and Oversight for Psychological Resources Act.",
  "argos_id": "H67VN7RX9"
}