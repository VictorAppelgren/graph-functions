{
  "url": "http://www.techtimes.com/articles/311781/20250902/openai-chatgpt-parental-controls-are-coming-next-month-following-wrongful-death-lawsuit.htm",
  "authorsByline": "Isaiah Richard",
  "articleId": "05bad5ee22bd4cbcb5e85adfe2f03557",
  "source": {
    "domain": "techtimes.com",
    "location": {
      "country": "us",
      "state": "NY",
      "city": "New York",
      "coordinates": {
        "lat": 40.7127281,
        "lon": -74.0060152
      }
    }
  },
  "imageUrl": "https://d.techtimes.com/en/full/456898/chatgpt.jpg",
  "country": "us",
  "language": "en",
  "pubDate": "2025-09-03T00:00:20-04:00",
  "addDate": "2025-09-03T04:04:30.476908+00:00",
  "refreshDate": "2025-09-03T04:04:30.476910+00:00",
  "score": 1.0,
  "title": "OpenAI: ChatGPT Parental Controls Are Coming Next Month Following Wrongful Death Lawsuit",
  "description": "OpenAI is finally adding the parental controls to ChatGPT to keep children safe that will roll out next month, as promised.",
  "content": "OpenAI has previously claimed that it would add parental controls to ChatGPT. In the latest update from the company, the new safety feature is said to be rolling out to the AI platform in the coming month.\n\nThe latest change came after the company said that it wants to do better for its users and offer parents a chance to monitor and set what their underage kids are interacting with on the platform.\n\nThe new parental controls would require parents to have their own ChatGPT accounts and have it connected to their children's accounts, with specific supervision features available soon for families.\n\nAccording to the latest blog post from OpenAI, they are now setting up the promised parental controls for ChatGPT, which they promised last week.\n\nThe company said that in the next month, ChatGPT will see parental controls set up on the platform to help parents monitor and control their children's usage of the AI tool.\n\nThe minimum age of usage for teenage users remains at 13 years old, and those who are of this age and older could have their accounts linked to their parents through an email invitation.\n\nAfter linking, parents may now control how ChatGPT responds to the minor user alongside an age-appropriate model, which is already turned on by default.\n\nParents may also choose to disable or enable certain ChatGPT features from being accessible for their child's account, including Memory and Chat History.\n\nLastly, parents would also be notified when the chatbot detects that the teenager is in a challenging or distressing situation, with expert input also giving parents tips or ways on how to handle it.\n\nOpenAI is now setting up a significant change to ChatGPT following a recent lawsuit that involved a teenage boy's suicide, allegedly because of the chatbot, with the bereaved parents blaming the technology.\n\nWhile OpenAI is still in the hot seat of this legal battle, the company said that it wants to do better by adding parental controls to the chatbot platform for extra protection.\n\nCompanies developing AI have been setting up age restrictions to limit the access of the chatbots by children, especially as there are significant dangers present. Generally, users aged 13 to 18 are permitted to use AI chatbots, but there have certain limits on what kind of experience they will get.\n\nDespite the safeguards made available on different platforms, there are still many ways to manipulate AI.",
  "medium": "Article",
  "links": [
    "https://www.techtimes.com/tags/openai",
    "https://openai.com/index/building-more-helpful-chatgpt-experiences-for-everyone/",
    "https://www.techtimes.com/articles/311720/20250827/openai-chatgpt-parental-controls-are-coming-after-parents-blame-chatbot-teens-death.htm",
    "http://www.techtimes.com/articles/311728/20250827/teen-death-lawsuit-openai-says-chatgpts-safety-guardrails-may-weaken-longer-conversations.htm",
    "http://www.techtimes.com/articles/311662/20250822/grok-chats-leak-online-did-your-secrets-just-go-public.htm",
    "https://www.techtimes.com/articles/298723/20231115/google-bard-accessible-teens-certain-safety-features-place.htm"
  ],
  "labels": [],
  "claim": "",
  "verdict": "",
  "keywords": [
    {
      "name": "ChatGPT Parental Controls",
      "weight": 0.11399425
    },
    {
      "name": "certain ChatGPT features",
      "weight": 0.09953011
    },
    {
      "name": "Parents",
      "weight": 0.09568248
    },
    {
      "name": "parents",
      "weight": 0.09568248
    },
    {
      "name": "parental controls",
      "weight": 0.09558947
    },
    {
      "name": "AI chatbots",
      "weight": 0.08602812
    },
    {
      "name": "ChatGPT",
      "weight": 0.08394485
    },
    {
      "name": "teenage users",
      "weight": 0.07784447
    },
    {
      "name": "different platforms",
      "weight": 0.07732754
    },
    {
      "name": "age restrictions",
      "weight": 0.07066038
    }
  ],
  "topics": [
    {
      "name": "Lawsuits"
    },
    {
      "name": "AI"
    }
  ],
  "categories": [
    {
      "name": "Tech"
    }
  ],
  "taxonomies": [
    {
      "name": "/News/Technology News",
      "score": 0.62744140625
    },
    {
      "name": "/People & Society/Family & Relationships/Family/Other",
      "score": 0.57763671875
    },
    {
      "name": "/News/Business News/Company News",
      "score": 0.50537109375
    },
    {
      "name": "/Science/Computer Science/Machine Learning & Artificial Intelligence",
      "score": 0.439208984375
    }
  ],
  "sentiment": {
    "positive": 0.08627814,
    "negative": 0.44180873,
    "neutral": 0.4719132
  },
  "summary": "OpenAI is set to add parental controls to ChatGPT, a platform that allows parents to monitor and control their underage children's usage. The new controls require parents to have their own ChatGPS accounts linked to their children's accounts, with the minimum age of usage set at 13 years old. Parents can also control how the chatbot responds to minor users and disable certain ChatGPA features from being accessible for their child's account. This comes after a recent lawsuit involved a teenage boy's suicide, allegedly due to the use of the chatbots.",
  "shortSummary": "OpenAI is adding parental controls to ChatGPT to enhance safety and control underage users, following a recent lawsuit regarding wrongful death allegations.",
  "translation": "",
  "translatedTitle": "",
  "translatedDescription": "",
  "translatedSummary": "",
  "reprint": false,
  "reprintGroupId": "e9a8473e43a342a2b1a1c9d8874e16e9",
  "places": [],
  "scraped_sources": [
    {
      "url": "https://www.techtimes.com/articles/311720/20250827/openai-chatgpt-parental-controls-are-coming-after-parents-blame-chatbot-teens-death.htm",
      "text": "OpenAI has revealed its plans to integrate new parental controls to its AI chatbot, ChatGPT, following a lawsuit filed by parents of a 16-year-old who died by suicide.\nThe bereaved parents have alleged that the AI chatbot contributed to their child's untimely death, and OpenAI has vowed to make it better for all users, especially teens.\nOpenAI's ChatGPT Parental Controls Are Coming\nOpenAI shared a new announcement revealing their latest plans to add parental controls to ChatGPT to help families navigate personal conflicts and crises. These parental controls that OpenAI will add will serve as a tool to help parents get more meaningful insight on how their children, particularly teens, use ChatGPT.\nThe company claims that it felt a \"deep responsibility to help\" users who need it most, especially those who turn to the chatbot for personal reasons and mental health issues that they experience daily.\nAlongside this, OpenAI also revealed that they are now working on a way for teens to add an emergency contact (with parental oversight) so that in these kinds of moments, its chatbot could connect teens to people \"who can step-in.\"\nOpenAI vs. Teen Wrongful Death Lawsuit\nAccording to CNET, this latest development from the AI company comes after the parents of a 16-year-old who took his life earlier this year filed a wrongful death lawsuit against OpenAI.\nThe teenager, Adam Reine, used ChatGPT during his mental health crisis, and the chatbot allegedly provided him with suicide methods and even validated his suicidal contemplation.\nAdditionally, it was revealed that the chatbot offered to write his suicide note five days ahead his death in April.\nGenerative AI and Mental Health Issues\nOver the years, generative AI chatbots have been praised for their content-making abilities and features that make users feel like they're talking to another person.\nHowever, there have been potential risks raised on the tech. Lawsuits against AI companies regarding wrongful deaths are no longer new, with various companies facing lawsuits from bereaved family members who blamed AI for their untimely deaths.\nFor example, Character.AI, a platform that lets users talk to their favorite fictional characters, was blamed for the apparent death of a 14-year-old boy in Florida after months of talking with it.\nThe wife of a Belgian man also claimed that Eliza, a chatbot from the Chai app, instead encouraged her husband to take his own life rather than to push him to be better.\nRelated Article: Elon Musk, xAI Sue Apple, OpenAI Over Alleged App Store Monopoly\n\u24d2 2025 TECHTIMES.com All rights reserved. Do not reproduce without permission."
    },
    {
      "url": "http://www.techtimes.com/articles/311662/20250822/grok-chats-leak-online-did-your-secrets-just-go-public.htm",
      "text": "Grok chats have been unintentionally exposed online, with a Forbes report revealing that over 370,000 sessions were indexed by Google after users shared one-time URLs. If you have been using this AI chatbot lately, you may stop for a moment and reflect on your previous conversations, since this is a huge privacy issue.\nDon't worry just yet: there's a way to protect yourself from this exposure.\nSensitive Data Exposed in AI Chats\nAccording to Forbes, the chat conversations indexed had passwords, health information, relationship problems, and even gruesome discussions about drugs or violence.\nWhile Grok maintains that transcripts were anonymized, most of the chats had sufficiently identifiable personal information that could jeopardize individuals' anonymity. The experience indicates the risks of using AI chats as free areas to vent or role-play, where one is not assured of privacy.\nNo Expiration or Control Over Shared Links\nUnlike private messages or screenshots, Grok's shared chat links do not expire and lack access controls. Once a conversation is live online, it remains searchable unless manually removed. This flaw not only damages trust in Grok.\nFor people using AI chatbots for a long time, this is a big red flag since AI chat platforms should prioritize user security.\nHow Users Can Protect Themselves\nIf you've shared Grok chats, there are a few steps to reduce exposure, according to TechRadar:\n- Don't use the share button if you're not okay with your conversations becoming public.\n- If you change your mind, look for the URL and ask Google to remove it via the Content Removal Tool, though this takes time and isn't always reliable.\n- Go to your X platform privacy settings to restrict data made available for AI training. It's not perfect, but it does provide an extra layer of protection.\nNot the First AI Privacy Scandal\nGrok is not the only one in the age of the AI-only Google Search results. Previously, OpenAI was criticized when ChatGPT chat episodes popped up in Google searches, and Meta was lambasted for unveiling confidential AI chatbot conversations in user streams.\nUnfortunately, these frequent occurrences indicate that technology firms rush AI products to market without completely strengthening privacy protections.\nFor the record, Grok AI was banned by 25% of European firms because of misinformation and privacy fears.\nAI conversations tend to read more like individual journals than social media updates. If such individual musings were suddenly searchable, users would lose faith in the technology as a whole.\nLike with history in general, from Gmail scanning emails and Facebook apps mining personal information, companies will just apologize after a privacy violation has happened rather than avoid one.\nRelated Article: Elon Musk's xAI Hiring Engineers to Create 'Anime Girl' Grok Avatars\n\u24d2 2025 TECHTIMES.com All rights reserved. Do not reproduce without permission."
    },
    {
      "url": "https://www.techtimes.com/tags/openai",
      "text": "TechOpenAI: ChatGPT Parental Controls Are Coming Next Month Following Wrongful Death Lawsuit OpenAI is finally adding the parental controls to ChatGPT to keep children safe that will roll out next month, as promised.by Isaiah Richard\nApps/SoftwareTeen Death Lawsuit: OpenAI Says ChatGPT's Safety Guardrails May Weaken in Longer Conversationsby Jose Enrico\nTechOpenAI: ChatGPT Parental Controls Are Coming After Parents Blame Chatbot For Teen's Deathby Isaiah Richard\nBusinessMeta Hires Jason Wei, Hyung Won Chung From OpenAI to Boost Superintelligence Researchby Jose Enrico\nTechMark Zuckerberg Unveils 'Meta Superintelligence Labs' Led by Alexandr Wang, Poached AI Employeesby Isaiah Richard\nTechOpenAI 'Recalibrating' Employee Compensations to Combat Meta's Staff 'Poaching' Spree\u2014Reportby Isaiah Richard\nTechMeta Recruits Key OpenAI Researcher to Bolster Its Team in Developing AI Reasoning Modelsby Isaiah Richard"
    },
    {
      "url": "https://www.techtimes.com/articles/298723/20231115/google-bard-accessible-teens-certain-safety-features-place.htm",
      "text": "The latest development by Google for its Bard AI chatbot is to make it available for teens to access, and not only that, the company is making it safe for underaged users with features in place for a wholesome experience. Allowing access will bring safety measures that apply for Google accounts with a minimum age of 13 for most countries worldwide, but will depend on specific country policies.\nSafeguards are a must for accessing the internet, and this is also something that Google made available for Bard, best known for being an advanced AI.\nGoogle Bard is Now Accessible for Teens Aged 13 and Above\nTulsee Doshi, Google's Head of Product and Responsible AI has detailed in a new blog post that the internet company is now allowing teens to experience a \"responsible\" Bard. The rollout of this eligibility is now available in most countries in the world, but for those who are left behind, it will soon arrive, promises Google.\n\"We're continuing to be responsible as we open up Bard to more people. Before launching to teens, we consulted with child safety and development experts to help shape our content policies and an experience that prioritizes safety,\" Doshi explained.\nBard for Teens: Certain Safety Features in Place\nLike other services for teens, Bard is now featuring safety features in place for underage users' access, centering on a helpful, informative, yet cautious to the age group. First off, Google claimed it will provide resources about the overview of generative AI, also offering a video explainer for it.\nNext, Google will double-check the answers that Bard provides for first-time teen users.\nBard will also be mindful of the appropriate content for the certain age group, and will only bring information that is safe for them. According to Google's support document, these are the ages for each country who are eligible to access Bard via their teen accounts.\nGoogle Bard and What it Has to Offer\nDespite massive hiccups during its early days, Bard has developed to be among the top AI chatbots in the world, with Google integrating it among many apps and services of the company for an improved experience. Recently, Google added Bard to Gmail, YouTube, Docs, and others of its Workspace suite to assist users in their everyday use.\nAmong the latest developments for Bard is the addition of new languages, with the AI chatbot now capable of talking in as many as 40 dialects, making it a better-accessible tool. Google's massive focus on artificial intelligence aims to make it accessible for all, with the company branching out to various countries for their use, also focusing on localizing the experience.\nWith Google's many developments for Bard, it is shaping up as an AI chatbot that could help everyone's needs, centering on different communities, niches, or age groups. The latest update by Google for Bard now centers on allowing teens to access the chatbot, but this comes with safeguards that will ease their parents' or guardians' worries, also ensuring factual answers for the young ones.\n\u24d2 2025 TECHTIMES.com All rights reserved. Do not reproduce without permission."
    },
    {
      "url": "http://www.techtimes.com/articles/311728/20250827/teen-death-lawsuit-openai-says-chatgpts-safety-guardrails-may-weaken-longer-conversations.htm",
      "text": "OpenAI is in the spotlight after a California family sued, alleging that ChatGPT was responsible for the suicide of their 16-year-old son, Adam Raine. In court papers, Adam spent months talking to the AI, with the chatbot supposedly giving him information about how to commit suicide, assisting him with writing a letter, and dissuading him from telling his parents.\nThe AI chatbot maker acknowledged that the safety controls of the app may \"degrade\" over time, especially after long conversations.\nOpenAI Concedes Safeguard Weaknesses\nOpenAI told Gizmodo in a recent interview that ChatGPT's guardrails can become less effective with more extensive conversations, which renders its safeguards less trustworthy. These protections are designed to steer users towards helplines and real-world resources in delicate scenarios. OpenAI conceded, though, that in longer interactions, its safety training \"may degrade.\"\nThe firm assured added features, such as new parental controls, reminders to take breaks, and functionalities to link users with emergency contacts.\nFamily Claims Safety Concerns Were Overlooked\nAdam Raine's parents contend that OpenAI was aware of these risks before the launch of ChatGPT-4o, which Adam employed. Their lawyers contend internal safety concerns were voiced but bypassed to hurry the model's rollout and drive valuation. Even the resignation of OpenAI co-founder and former chief scientist Ilya Sutskever, reportedly after clashes over safety procedures, is cited in the lawsuit.\nLead lawyer Jay Edelson said proof will reveal that executives, including CEO Sam Altman, valued marketplace supremacy above user safety.\nNot the First Case of AI-Linked Suicides\nThis tragedy is not singular. There have been reports of other people developing emotional relationships with AI chatbots before ending their lives.\nA teenage boy from Florida had died after being provoked by a Character.AI bot, and another incident involved a man who tried to drive cross-country at the behest of a Meta AI.\nCritics warn that prolonged conversations can lead to \"AI psychosis,\" a term describing delusional or dysfunctional thought patterns linked to heavy chatbot use. The FTC has reportedly received multiple complaints from users describing these effects.\nHow Will OpenAI Address ChatGPT's Safety Features\nOpenAI says it is working on stronger safety features, such as:\n- Reinforced safeguards during extended conversations\n- One-click access to trusted contacts or emergency services\n- Teen-specific protections with parental oversight\n- Updates designed to \"de-escalate\" harmful conversations\nAI Regulation Should Be Improved\nThe case is the latest to put increasing pressure on AI regulation. Tech Times reported this week that US Attorneys General warned AI companies to be accountable when it comes to child safety. They called out leading AI firms to protect the young users from harmful chatbots.\n\u24d2 2025 TECHTIMES.com All rights reserved. Do not reproduce without permission."
    }
  ],
  "argos_summary": "OpenAI announced that it will roll out parental controls for ChatGPT over the next month, a move prompted by a wrongful\u2011death lawsuit alleging the bot contributed to a teen\u2019s suicide. The new features will let parents link accounts, set age\u2011appropriate models, restrict functions such as memory and chat history, and receive alerts if the child encounters distressing content. The controls aim to improve safety for users aged 13 and older while addressing concerns over the bot\u2019s guardrails during extended conversations.",
  "argos_id": "9D0PI5UUV"
}